{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "original_Adam_lr=0_00002_ 1000 epoch_try1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9SRCO-a_AlH5",
        "outputId": "3f127f77-dbf8-4344-9760-c4d1db8bd21b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install librosa"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oi8pWV3yBVjO",
        "outputId": "3004044b-c67d-4403-8d1c-d64ca6cddb05"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.7/dist-packages (0.8.1)\n",
            "Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.6.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (21.3)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.1.0)\n",
            "Requirement already satisfied: audioread>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (2.1.9)\n",
            "Requirement already satisfied: decorator>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied: resampy>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from librosa) (0.2.2)\n",
            "Requirement already satisfied: numba>=0.43.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (0.51.2)\n",
            "Requirement already satisfied: soundfile>=0.10.2 in /usr/local/lib/python3.7/dist-packages (from librosa) (0.10.3.post1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.21.6)\n",
            "Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.0.2)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.4.1)\n",
            "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba>=0.43.0->librosa) (0.34.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba>=0.43.0->librosa) (57.4.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->librosa) (3.0.9)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from pooch>=1.0->librosa) (2.23.0)\n",
            "Requirement already satisfied: appdirs>=1.3.0 in /usr/local/lib/python3.7/dist-packages (from pooch>=1.0->librosa) (1.4.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2022.5.18.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (1.24.3)\n",
            "Requirement already satisfied: six>=1.3 in /usr/local/lib/python3.7/dist-packages (from resampy>=0.2.2->librosa) (1.15.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn!=0.19.0,>=0.14.0->librosa) (3.1.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.7/dist-packages (from soundfile>=0.10.2->librosa) (1.15.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.0->soundfile>=0.10.2->librosa) (2.21)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HJjcbxwy46bG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "db7805c4-2a04-4322-fb73-fa7dde9152a8"
      },
      "source": [
        "# Orignial Notebook: https://github.com/MITESHPUTHRANNEU/Speech-Emotion-Analyzer/blob/master/final_results_gender_test.ipynb\n",
        "# This notebook author: Reza Chu\n",
        "# Last Editing Date: 31st May 2019\n",
        "\n",
        "## Python\n",
        "import os\n",
        "import random\n",
        "import sys\n",
        "\n",
        "import IPython\n",
        "from IPython.display import Audio\n",
        "from IPython.display import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "## Package\n",
        "import glob \n",
        "import keras\n",
        "import IPython.display as ipd\n",
        "import librosa\n",
        "import librosa.display\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import plotly.graph_objs as go\n",
        "import plotly.offline as py\n",
        "import plotly.tools as tls\n",
        "import seaborn as sns\n",
        "import scipy.io.wavfile\n",
        "import tensorflow as tf\n",
        "py.init_notebook_mode(connected=True)\n",
        "\n",
        "## Keras\n",
        "from keras import regularizers\n",
        "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping\n",
        "from keras.callbacks import  History, ReduceLROnPlateau, CSVLogger\n",
        "from keras.models import Model, Sequential\n",
        "from keras.layers import Dense, Embedding, LSTM\n",
        "from keras.layers import Input, Flatten, Dropout, Activation, BatchNormalization\n",
        "from keras.layers import Conv1D, MaxPooling1D, AveragePooling1D\n",
        "from keras.preprocessing import sequence\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.utils import np_utils\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "## Sklearn\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "## Rest\n",
        "from scipy.fftpack import fft\n",
        "from scipy import signal\n",
        "from scipy.io import wavfile\n",
        "from tqdm import tqdm\n",
        "\n",
        "input_duration=3\n",
        "# % pylab inline"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "        <script type=\"text/javascript\">\n",
              "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
              "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
              "        if (typeof require !== 'undefined') {\n",
              "        require.undef(\"plotly\");\n",
              "        requirejs.config({\n",
              "            paths: {\n",
              "                'plotly': ['https://cdn.plot.ly/plotly-2.8.3.min']\n",
              "            }\n",
              "        });\n",
              "        require(['plotly'], function(Plotly) {\n",
              "            window._Plotly = Plotly;\n",
              "        });\n",
              "        }\n",
              "        </script>\n",
              "        "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#radvass speech and song\n",
        "import time\n",
        "import os\n",
        "import librosa\n",
        "from librosa import display\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "count=0\n",
        "path1 = '/content/drive/MyDrive/RAVDESS_speech'\n",
        "path2 = '/content/drive/MyDrive/RAVDESS_song'\n",
        "\n",
        "lst = []\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "for subdir, dirs, files in os.walk(path2):\n",
        "  print(dirs)\n",
        "  print(subdir)\n",
        "  #print(files)\n",
        "  for file in files:\n",
        "      try:\n",
        "        count +=1\n",
        "        #Load librosa array, obtain mfcss, store the file and the mcss information in a new array\n",
        "        X, sample_rate = librosa.load(os.path.join(subdir,file), res_type='kaiser_fast')\n",
        "        mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T,axis=0) \n",
        "        # The instruction below converts the labels (from 1 to 8) to a series from 0 to 7\n",
        "        # This is because our predictor needs to start from 0 otherwise it will try to predict also 0.\n",
        "        file = int(file[7:8]) - 1 \n",
        "        arr = mfccs, file\n",
        "        lst.append(arr)\n",
        "      # If the file is not valid, skip it\n",
        "      except ValueError:\n",
        "        continue\n",
        "\n",
        "for subdir, dirs, files in os.walk(path1):\n",
        "  print(dirs)\n",
        "  print(subdir)\n",
        " # print(files)\n",
        "  for file in files:\n",
        "      try:\n",
        "        #Load librosa array, obtain mfcss, store the file and the mcss information in a new array\n",
        "        X, sample_rate = librosa.load(os.path.join(subdir,file), res_type='kaiser_fast')\n",
        "        mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T,axis=0) \n",
        "        # The instruction below converts the labels (from 1 to 8) to a series from 0 to 7\n",
        "        # This is because our predictor needs to start from 0 otherwise it will try to predict also 0.\n",
        "        file = int(file[7:8]) - 1 \n",
        "        if(file ==6 or file==7):\n",
        "          continue\n",
        "        count +=1\n",
        "        arr = mfccs, file\n",
        "        lst.append(arr)\n",
        "      # If the file is not valid, skip it\n",
        "      except ValueError:\n",
        "        continue\n",
        "\n",
        "\n",
        "\n",
        "print(\"--- Data loaded. Loading time: %s seconds ---\" % (time.time() - start_time))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IfuyRZl42ccZ",
        "outputId": "bdfc4ad0-aee0-488e-e41c-588b6ac8b74a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Actor_10', 'Actor_11', 'Actor_13', 'Actor_12', 'Actor_14', 'Actor_15', 'Actor_16', 'Actor_17', 'Actor_18', 'Actor_19', 'Actor_21', 'Actor_22', 'Actor_23', 'Actor_09', 'Actor_24', 'Actor_04', 'Actor_08', 'Actor_03', 'Actor_02', 'Actor_06', 'Actor_05', 'Actor_01', 'Actor_07', 'Actor_20']\n",
            "/content/drive/MyDrive/RAVDESS_song\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_10\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_11\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_13\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_12\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_14\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_15\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_16\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_17\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_18\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_19\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_21\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_22\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_23\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_09\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_24\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_04\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_08\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_03\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_02\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_06\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_05\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_01\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_07\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_20\n",
            "['Actor_05', 'Actor_08', 'Actor_10', 'Actor_04', 'Actor_09', 'Actor_14', 'Actor_12', 'Actor_13', 'Actor_11', 'Actor_06', 'Actor_24', 'Actor_07', 'Actor_23', 'Actor_22', 'Actor_21', 'Actor_20', 'Actor_02', 'Actor_19', 'Actor_18', 'Actor_17', 'Actor_16', 'Actor_15', 'Actor_03', 'Actor_01']\n",
            "/content/drive/MyDrive/RAVDESS_speech\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_05\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_08\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_10\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_04\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_09\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_14\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_12\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_13\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_11\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_06\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_24\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_07\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_23\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_22\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_21\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_20\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_02\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_19\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_18\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_17\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_16\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_15\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_03\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_01\n",
            "--- Data loaded. Loading time: 716.5096759796143 seconds ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "count"
      ],
      "metadata": {
        "id": "Ltlhi25L2AI5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "30b2c003-d311-45f8-b8b5-24dc1fbf23ff"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2068"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy.core.fromnumeric import size\n",
        "size(lst)"
      ],
      "metadata": {
        "id": "HMOH7d7mzHB7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "55f67a5a-22ec-4fcd-e887-c2411e5a0f8e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/core/fromnumeric.py:3208: VisibleDeprecationWarning:\n",
            "\n",
            "Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4136"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating X and y: zip makes a list of all the first elements, and a list of all the second elements.\n",
        "X, y = zip(*lst)"
      ],
      "metadata": {
        "id": "ocdL7tSTBoMt"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "X = np.asarray(X)\n",
        "y = np.asarray(y)\n",
        "X.shape, y.shape"
      ],
      "metadata": {
        "id": "vHKwUGTbBtnF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a62fbdb-62c8-469f-9561-e13a9b780ba2"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((2068, 40), (2068,))"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "id": "2sUCtbfMztE5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1885a511-a815-4f85-b61b-d5f558fae6ef"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2068, 40)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Saving joblib files to not load them again with the loop above\n",
        "\n",
        "# import joblib\n",
        "\n",
        "# X_name = 'x.joblib'\n",
        "# y_name = 'y.joblib'\n",
        "# save_dir = '/content/drive/My Drive/graduation project/audio/paper_code/features'\n",
        "\n",
        "# savedX = joblib.dump(X, os.path.join(save_dir, X_name))\n",
        "# savedy = joblib.dump(y, os.path.join(save_dir, y_name))"
      ],
      "metadata": {
        "id": "UCzic8rlDcuk"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Loading saved models\n",
        "# import joblib\n",
        "# X = joblib.load('/content/drive/My Drive/graduation project/audio/paper_code/features/x.joblib')\n",
        "# y = joblib.load('/content/drive/My Drive/graduation project/audio/paper_code/features/y.joblib')"
      ],
      "metadata": {
        "id": "Q35CN6zDrzg1"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7PSTurzjCo5K",
        "outputId": "e3ed877b-4ad5-4d18-8616-87e6f7636a08"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2068, 40)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2,train_size=0.8, random_state=42)\n",
        "X_valid, X_test, y_valid, y_test = train_test_split(X_test,y_test, test_size=0.5,train_size=0.5, random_state=42)"
      ],
      "metadata": {
        "id": "Ai4Fy5cPCiq1"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "x_traincnn = np.expand_dims(X_train, axis=2)\n",
        "x_testcnn = np.expand_dims(X_test, axis=2)\n",
        "X_valid= np.expand_dims(X_valid, axis=2)"
      ],
      "metadata": {
        "id": "tp1Fm5K3CEXu"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_traincnn.shape, x_testcnn.shape , X_valid.shape"
      ],
      "metadata": {
        "id": "RI0MxoIPBws5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f06df3e-f67e-4091-a3a8-b78be0ed7591"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1654, 40, 1), (207, 40, 1), (207, 40, 1))"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow"
      ],
      "metadata": {
        "id": "goxL4Y3jKICC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0ea8fe2-ec7a-452f-9f20-966e1630096f"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (2.8.2+zzzcolab20220527125636)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (14.0.1)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.5.3)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.0.0)\n",
            "Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.21.6)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (4.2.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow) (57.4.0)\n",
            "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.46.3)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.26.0)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.17.3)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow) (1.5.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.4.6)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.35.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.8.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (3.3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.6.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.23.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (4.11.4)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (3.8.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2022.5.18.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (1.24.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (3.2.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keras"
      ],
      "metadata": {
        "id": "EkcmN9UrKSxj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c6eb93ca-a604-4dae-fe8a-da3961c9749b"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.7/dist-packages (2.8.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from keras.preprocessing import sequence\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from keras.layers import Input, Flatten, Dropout, Activation\n",
        "from keras.layers import Conv1D, MaxPooling1D\n",
        "from keras.models import Model\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras import optimizers\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv1D(128, 8,padding='same', #classifier.add(Convolution2D(64, (3, 3), padding = 'same', input_shape = (128, 128, 3), activation = 'relu'))\n",
        "                 input_shape=(40,1)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(MaxPooling1D(pool_size=(5)))\n",
        "\n",
        "\n",
        "model.add(Conv1D(256,8,padding='same',))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(MaxPooling1D(pool_size=(5)))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(256))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(256))\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "model.add(Dense(6))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "opt = tf.keras.optimizers.Adam(lr=0.00002)\n",
        "#opt = tf.keras.optimizers.RMSprop(lr=0.0001, rho=0.9, epsilon=1e-07, decay=0.0)\n",
        "#opt = tf.keras.optimizers.SGD(lr=0.001, momentum=0.0, decay=0.0, nesterov=False)"
      ],
      "metadata": {
        "id": "g74fXWVAC4Cr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80829883-ea97-4003-ef3f-0fb415adb642"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning:\n",
            "\n",
            "The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H6ukOxAGC_I4",
        "outputId": "a07c7252-83de-459b-ae87-de4ebdea0264"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d (Conv1D)             (None, 40, 128)           1152      \n",
            "                                                                 \n",
            " activation (Activation)     (None, 40, 128)           0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 40, 128)           0         \n",
            "                                                                 \n",
            " max_pooling1d (MaxPooling1D  (None, 8, 128)           0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv1d_1 (Conv1D)           (None, 8, 256)            262400    \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 8, 256)            0         \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 8, 256)            0         \n",
            "                                                                 \n",
            " max_pooling1d_1 (MaxPooling  (None, 1, 256)           0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 256)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 256)               65792     \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 256)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 256)               65792     \n",
            "                                                                 \n",
            " activation_3 (Activation)   (None, 256)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 6)                 1542      \n",
            "                                                                 \n",
            " activation_4 (Activation)   (None, 6)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 396,678\n",
            "Trainable params: 396,678\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='sparse_categorical_crossentropy',\n",
        "              optimizer=opt,\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "AbMlLNk4DCBM"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#cnnhistory=model.fit(x_traincnn, y_train, batch_size=16, epochs=700, validation_data=(x_testcnn, y_test))\n",
        "cnnhistory=model.fit(x_traincnn, y_train, batch_size=16, epochs=1000 , validation_data=(X_valid, y_valid))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RI1v2AuADFhy",
        "outputId": "2bb5e539-946a-4d97-da26-204ef3c7c017"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "104/104 [==============================] - 16s 15ms/step - loss: 6.9224 - accuracy: 0.1790 - val_loss: 2.1758 - val_accuracy: 0.1643\n",
            "Epoch 2/1000\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 5.1058 - accuracy: 0.1651 - val_loss: 2.1121 - val_accuracy: 0.2222\n",
            "Epoch 3/1000\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 4.4522 - accuracy: 0.1747 - val_loss: 2.0369 - val_accuracy: 0.2029\n",
            "Epoch 4/1000\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 3.8213 - accuracy: 0.1759 - val_loss: 1.7587 - val_accuracy: 0.2899\n",
            "Epoch 5/1000\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 3.5243 - accuracy: 0.1796 - val_loss: 1.7427 - val_accuracy: 0.2899\n",
            "Epoch 6/1000\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 3.2085 - accuracy: 0.1765 - val_loss: 1.7426 - val_accuracy: 0.2609\n",
            "Epoch 7/1000\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 3.0893 - accuracy: 0.1862 - val_loss: 1.7498 - val_accuracy: 0.2222\n",
            "Epoch 8/1000\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 2.8635 - accuracy: 0.1953 - val_loss: 1.7009 - val_accuracy: 0.2560\n",
            "Epoch 9/1000\n",
            "104/104 [==============================] - 1s 9ms/step - loss: 2.7469 - accuracy: 0.1868 - val_loss: 1.7338 - val_accuracy: 0.2367\n",
            "Epoch 10/1000\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 2.6548 - accuracy: 0.1753 - val_loss: 1.7446 - val_accuracy: 0.2126\n",
            "Epoch 11/1000\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 2.4263 - accuracy: 0.2086 - val_loss: 1.7955 - val_accuracy: 0.1836\n",
            "Epoch 12/1000\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 2.3869 - accuracy: 0.2013 - val_loss: 1.7567 - val_accuracy: 0.2029\n",
            "Epoch 13/1000\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 2.2956 - accuracy: 0.2116 - val_loss: 1.7359 - val_accuracy: 0.2754\n",
            "Epoch 14/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 2.2579 - accuracy: 0.2098 - val_loss: 1.7128 - val_accuracy: 0.2850\n",
            "Epoch 15/1000\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 2.2190 - accuracy: 0.1935 - val_loss: 1.7383 - val_accuracy: 0.1787\n",
            "Epoch 16/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 2.2020 - accuracy: 0.1995 - val_loss: 1.7368 - val_accuracy: 0.1981\n",
            "Epoch 17/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 2.1526 - accuracy: 0.2128 - val_loss: 1.7305 - val_accuracy: 0.2657\n",
            "Epoch 18/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 2.1210 - accuracy: 0.1989 - val_loss: 1.7104 - val_accuracy: 0.2754\n",
            "Epoch 19/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 2.0807 - accuracy: 0.2207 - val_loss: 1.7247 - val_accuracy: 0.2029\n",
            "Epoch 20/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 2.0507 - accuracy: 0.2122 - val_loss: 1.6816 - val_accuracy: 0.3430\n",
            "Epoch 21/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 2.0409 - accuracy: 0.2201 - val_loss: 1.7436 - val_accuracy: 0.2705\n",
            "Epoch 22/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 2.0174 - accuracy: 0.2201 - val_loss: 1.7024 - val_accuracy: 0.2367\n",
            "Epoch 23/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 2.0113 - accuracy: 0.2273 - val_loss: 1.6937 - val_accuracy: 0.2899\n",
            "Epoch 24/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.9816 - accuracy: 0.2285 - val_loss: 1.6919 - val_accuracy: 0.3092\n",
            "Epoch 25/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.9602 - accuracy: 0.2279 - val_loss: 1.6729 - val_accuracy: 0.3527\n",
            "Epoch 26/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.9293 - accuracy: 0.2189 - val_loss: 1.6690 - val_accuracy: 0.3527\n",
            "Epoch 27/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.8879 - accuracy: 0.2503 - val_loss: 1.6628 - val_accuracy: 0.3623\n",
            "Epoch 28/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.9240 - accuracy: 0.2201 - val_loss: 1.6942 - val_accuracy: 0.2899\n",
            "Epoch 29/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.8712 - accuracy: 0.2418 - val_loss: 1.6639 - val_accuracy: 0.3913\n",
            "Epoch 30/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.9061 - accuracy: 0.2249 - val_loss: 1.6772 - val_accuracy: 0.2415\n",
            "Epoch 31/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.8857 - accuracy: 0.2237 - val_loss: 1.6742 - val_accuracy: 0.3043\n",
            "Epoch 32/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.8414 - accuracy: 0.2503 - val_loss: 1.6782 - val_accuracy: 0.2126\n",
            "Epoch 33/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.8507 - accuracy: 0.2406 - val_loss: 1.7135 - val_accuracy: 0.3140\n",
            "Epoch 34/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.8290 - accuracy: 0.2563 - val_loss: 1.7194 - val_accuracy: 0.2560\n",
            "Epoch 35/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.8323 - accuracy: 0.2551 - val_loss: 1.6625 - val_accuracy: 0.3623\n",
            "Epoch 36/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.8413 - accuracy: 0.2443 - val_loss: 1.6641 - val_accuracy: 0.3140\n",
            "Epoch 37/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.8020 - accuracy: 0.2684 - val_loss: 1.6673 - val_accuracy: 0.3671\n",
            "Epoch 38/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.8194 - accuracy: 0.2612 - val_loss: 1.6595 - val_accuracy: 0.3333\n",
            "Epoch 39/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.7691 - accuracy: 0.2527 - val_loss: 1.6517 - val_accuracy: 0.3188\n",
            "Epoch 40/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.8114 - accuracy: 0.2539 - val_loss: 1.6541 - val_accuracy: 0.3671\n",
            "Epoch 41/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.8043 - accuracy: 0.2443 - val_loss: 1.6519 - val_accuracy: 0.3333\n",
            "Epoch 42/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.7878 - accuracy: 0.2588 - val_loss: 1.6498 - val_accuracy: 0.4106\n",
            "Epoch 43/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.7672 - accuracy: 0.2854 - val_loss: 1.6657 - val_accuracy: 0.3285\n",
            "Epoch 44/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.7715 - accuracy: 0.2709 - val_loss: 1.6332 - val_accuracy: 0.3816\n",
            "Epoch 45/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.7460 - accuracy: 0.2654 - val_loss: 1.6333 - val_accuracy: 0.4010\n",
            "Epoch 46/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.7610 - accuracy: 0.2769 - val_loss: 1.6533 - val_accuracy: 0.3527\n",
            "Epoch 47/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.7390 - accuracy: 0.2860 - val_loss: 1.6396 - val_accuracy: 0.3768\n",
            "Epoch 48/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.7254 - accuracy: 0.2787 - val_loss: 1.6443 - val_accuracy: 0.3382\n",
            "Epoch 49/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.7583 - accuracy: 0.2709 - val_loss: 1.6374 - val_accuracy: 0.4203\n",
            "Epoch 50/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.7315 - accuracy: 0.2872 - val_loss: 1.6528 - val_accuracy: 0.3188\n",
            "Epoch 51/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.7158 - accuracy: 0.2781 - val_loss: 1.6251 - val_accuracy: 0.3430\n",
            "Epoch 52/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.7265 - accuracy: 0.2672 - val_loss: 1.6087 - val_accuracy: 0.3913\n",
            "Epoch 53/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.7103 - accuracy: 0.2787 - val_loss: 1.5948 - val_accuracy: 0.3623\n",
            "Epoch 54/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.7119 - accuracy: 0.2787 - val_loss: 1.5972 - val_accuracy: 0.3961\n",
            "Epoch 55/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.6819 - accuracy: 0.3023 - val_loss: 1.5803 - val_accuracy: 0.4010\n",
            "Epoch 56/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.6967 - accuracy: 0.3035 - val_loss: 1.6022 - val_accuracy: 0.3961\n",
            "Epoch 57/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.6738 - accuracy: 0.3041 - val_loss: 1.6000 - val_accuracy: 0.3816\n",
            "Epoch 58/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.6783 - accuracy: 0.2932 - val_loss: 1.6051 - val_accuracy: 0.3333\n",
            "Epoch 59/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.6871 - accuracy: 0.2938 - val_loss: 1.6073 - val_accuracy: 0.3140\n",
            "Epoch 60/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.6566 - accuracy: 0.3168 - val_loss: 1.5880 - val_accuracy: 0.4106\n",
            "Epoch 61/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.6603 - accuracy: 0.3120 - val_loss: 1.5975 - val_accuracy: 0.3865\n",
            "Epoch 62/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.6444 - accuracy: 0.3204 - val_loss: 1.5922 - val_accuracy: 0.4203\n",
            "Epoch 63/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.6517 - accuracy: 0.3071 - val_loss: 1.5633 - val_accuracy: 0.3865\n",
            "Epoch 64/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.6531 - accuracy: 0.3041 - val_loss: 1.5565 - val_accuracy: 0.4203\n",
            "Epoch 65/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.6339 - accuracy: 0.3144 - val_loss: 1.5514 - val_accuracy: 0.4058\n",
            "Epoch 66/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.6389 - accuracy: 0.3126 - val_loss: 1.5596 - val_accuracy: 0.4300\n",
            "Epoch 67/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.6274 - accuracy: 0.3380 - val_loss: 1.5311 - val_accuracy: 0.4251\n",
            "Epoch 68/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.6276 - accuracy: 0.3210 - val_loss: 1.5406 - val_accuracy: 0.4300\n",
            "Epoch 69/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.6361 - accuracy: 0.3198 - val_loss: 1.5473 - val_accuracy: 0.4155\n",
            "Epoch 70/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.6146 - accuracy: 0.3271 - val_loss: 1.5403 - val_accuracy: 0.3720\n",
            "Epoch 71/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 1.5945 - accuracy: 0.3241 - val_loss: 1.5311 - val_accuracy: 0.4493\n",
            "Epoch 72/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 1.5925 - accuracy: 0.3374 - val_loss: 1.5272 - val_accuracy: 0.3913\n",
            "Epoch 73/1000\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 1.6030 - accuracy: 0.3132 - val_loss: 1.5496 - val_accuracy: 0.3430\n",
            "Epoch 74/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 1.5767 - accuracy: 0.3482 - val_loss: 1.5426 - val_accuracy: 0.3961\n",
            "Epoch 75/1000\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 1.5852 - accuracy: 0.3446 - val_loss: 1.5098 - val_accuracy: 0.3623\n",
            "Epoch 76/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.5892 - accuracy: 0.3319 - val_loss: 1.4941 - val_accuracy: 0.4203\n",
            "Epoch 77/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.5708 - accuracy: 0.3525 - val_loss: 1.4909 - val_accuracy: 0.4010\n",
            "Epoch 78/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.5806 - accuracy: 0.3482 - val_loss: 1.4954 - val_accuracy: 0.4493\n",
            "Epoch 79/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.5566 - accuracy: 0.3658 - val_loss: 1.4851 - val_accuracy: 0.4493\n",
            "Epoch 80/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.5576 - accuracy: 0.3561 - val_loss: 1.4861 - val_accuracy: 0.4348\n",
            "Epoch 81/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.5558 - accuracy: 0.3434 - val_loss: 1.4882 - val_accuracy: 0.4010\n",
            "Epoch 82/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.5478 - accuracy: 0.3640 - val_loss: 1.4767 - val_accuracy: 0.4348\n",
            "Epoch 83/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.5328 - accuracy: 0.3712 - val_loss: 1.4735 - val_accuracy: 0.4348\n",
            "Epoch 84/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.5355 - accuracy: 0.3827 - val_loss: 1.4795 - val_accuracy: 0.4300\n",
            "Epoch 85/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.5025 - accuracy: 0.3857 - val_loss: 1.4608 - val_accuracy: 0.4058\n",
            "Epoch 86/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.5369 - accuracy: 0.3706 - val_loss: 1.4734 - val_accuracy: 0.4251\n",
            "Epoch 87/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.5314 - accuracy: 0.3646 - val_loss: 1.4501 - val_accuracy: 0.4589\n",
            "Epoch 88/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.5262 - accuracy: 0.3682 - val_loss: 1.4447 - val_accuracy: 0.5121\n",
            "Epoch 89/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.5071 - accuracy: 0.3682 - val_loss: 1.4417 - val_accuracy: 0.4734\n",
            "Epoch 90/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.5122 - accuracy: 0.3779 - val_loss: 1.4430 - val_accuracy: 0.4638\n",
            "Epoch 91/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.4954 - accuracy: 0.3827 - val_loss: 1.4257 - val_accuracy: 0.4976\n",
            "Epoch 92/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.5153 - accuracy: 0.3646 - val_loss: 1.4533 - val_accuracy: 0.4203\n",
            "Epoch 93/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.4864 - accuracy: 0.3875 - val_loss: 1.4364 - val_accuracy: 0.4493\n",
            "Epoch 94/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.4822 - accuracy: 0.3942 - val_loss: 1.4720 - val_accuracy: 0.4203\n",
            "Epoch 95/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.4937 - accuracy: 0.3755 - val_loss: 1.4657 - val_accuracy: 0.4155\n",
            "Epoch 96/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.4983 - accuracy: 0.3797 - val_loss: 1.4448 - val_accuracy: 0.4444\n",
            "Epoch 97/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.4788 - accuracy: 0.3942 - val_loss: 1.4151 - val_accuracy: 0.4879\n",
            "Epoch 98/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.4812 - accuracy: 0.3918 - val_loss: 1.4056 - val_accuracy: 0.5024\n",
            "Epoch 99/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.4569 - accuracy: 0.4081 - val_loss: 1.4057 - val_accuracy: 0.5121\n",
            "Epoch 100/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.4502 - accuracy: 0.4160 - val_loss: 1.4002 - val_accuracy: 0.5072\n",
            "Epoch 101/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.4599 - accuracy: 0.4045 - val_loss: 1.3859 - val_accuracy: 0.4783\n",
            "Epoch 102/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.4282 - accuracy: 0.4178 - val_loss: 1.3750 - val_accuracy: 0.5169\n",
            "Epoch 103/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.4522 - accuracy: 0.4154 - val_loss: 1.3642 - val_accuracy: 0.5121\n",
            "Epoch 104/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.4281 - accuracy: 0.4202 - val_loss: 1.3696 - val_accuracy: 0.4734\n",
            "Epoch 105/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.4403 - accuracy: 0.4015 - val_loss: 1.3633 - val_accuracy: 0.5169\n",
            "Epoch 106/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.4257 - accuracy: 0.4250 - val_loss: 1.3504 - val_accuracy: 0.5266\n",
            "Epoch 107/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.4165 - accuracy: 0.4232 - val_loss: 1.3424 - val_accuracy: 0.5121\n",
            "Epoch 108/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.4484 - accuracy: 0.4111 - val_loss: 1.3639 - val_accuracy: 0.4589\n",
            "Epoch 109/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.4179 - accuracy: 0.4081 - val_loss: 1.3461 - val_accuracy: 0.5024\n",
            "Epoch 110/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.4180 - accuracy: 0.4268 - val_loss: 1.3607 - val_accuracy: 0.5121\n",
            "Epoch 111/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.4120 - accuracy: 0.4238 - val_loss: 1.3688 - val_accuracy: 0.4783\n",
            "Epoch 112/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.4032 - accuracy: 0.4244 - val_loss: 1.3395 - val_accuracy: 0.5121\n",
            "Epoch 113/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.4010 - accuracy: 0.4262 - val_loss: 1.3436 - val_accuracy: 0.4879\n",
            "Epoch 114/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.4028 - accuracy: 0.4262 - val_loss: 1.3273 - val_accuracy: 0.5266\n",
            "Epoch 115/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.3946 - accuracy: 0.4426 - val_loss: 1.3251 - val_accuracy: 0.5507\n",
            "Epoch 116/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.3740 - accuracy: 0.4444 - val_loss: 1.3138 - val_accuracy: 0.5362\n",
            "Epoch 117/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.4022 - accuracy: 0.4329 - val_loss: 1.3150 - val_accuracy: 0.4976\n",
            "Epoch 118/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.3597 - accuracy: 0.4395 - val_loss: 1.3107 - val_accuracy: 0.5749\n",
            "Epoch 119/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.3593 - accuracy: 0.4516 - val_loss: 1.3032 - val_accuracy: 0.5700\n",
            "Epoch 120/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.3694 - accuracy: 0.4377 - val_loss: 1.2927 - val_accuracy: 0.5652\n",
            "Epoch 121/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.3699 - accuracy: 0.4456 - val_loss: 1.3084 - val_accuracy: 0.4879\n",
            "Epoch 122/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.3690 - accuracy: 0.4480 - val_loss: 1.2846 - val_accuracy: 0.5942\n",
            "Epoch 123/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.3538 - accuracy: 0.4407 - val_loss: 1.2890 - val_accuracy: 0.5314\n",
            "Epoch 124/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.3631 - accuracy: 0.4401 - val_loss: 1.2621 - val_accuracy: 0.5604\n",
            "Epoch 125/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.3300 - accuracy: 0.4583 - val_loss: 1.2732 - val_accuracy: 0.5459\n",
            "Epoch 126/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.3633 - accuracy: 0.4510 - val_loss: 1.2881 - val_accuracy: 0.5362\n",
            "Epoch 127/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.3475 - accuracy: 0.4456 - val_loss: 1.2764 - val_accuracy: 0.5314\n",
            "Epoch 128/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.3505 - accuracy: 0.4559 - val_loss: 1.2854 - val_accuracy: 0.4976\n",
            "Epoch 129/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.3196 - accuracy: 0.4595 - val_loss: 1.2619 - val_accuracy: 0.5411\n",
            "Epoch 130/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.3304 - accuracy: 0.4565 - val_loss: 1.2714 - val_accuracy: 0.5652\n",
            "Epoch 131/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.3093 - accuracy: 0.4577 - val_loss: 1.2697 - val_accuracy: 0.5362\n",
            "Epoch 132/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.3101 - accuracy: 0.4637 - val_loss: 1.2616 - val_accuracy: 0.5362\n",
            "Epoch 133/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.3203 - accuracy: 0.4740 - val_loss: 1.2381 - val_accuracy: 0.5797\n",
            "Epoch 134/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.3079 - accuracy: 0.4728 - val_loss: 1.2486 - val_accuracy: 0.5266\n",
            "Epoch 135/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.3079 - accuracy: 0.4734 - val_loss: 1.2440 - val_accuracy: 0.5411\n",
            "Epoch 136/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.3125 - accuracy: 0.4710 - val_loss: 1.2450 - val_accuracy: 0.5266\n",
            "Epoch 137/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.3160 - accuracy: 0.4565 - val_loss: 1.2406 - val_accuracy: 0.5604\n",
            "Epoch 138/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.2985 - accuracy: 0.4782 - val_loss: 1.2401 - val_accuracy: 0.5797\n",
            "Epoch 139/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.3229 - accuracy: 0.4607 - val_loss: 1.2342 - val_accuracy: 0.5700\n",
            "Epoch 140/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.2944 - accuracy: 0.4728 - val_loss: 1.2292 - val_accuracy: 0.5604\n",
            "Epoch 141/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.2774 - accuracy: 0.4849 - val_loss: 1.2219 - val_accuracy: 0.5604\n",
            "Epoch 142/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.2775 - accuracy: 0.4958 - val_loss: 1.2264 - val_accuracy: 0.5266\n",
            "Epoch 143/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.2708 - accuracy: 0.4867 - val_loss: 1.2075 - val_accuracy: 0.5700\n",
            "Epoch 144/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.2745 - accuracy: 0.4831 - val_loss: 1.2045 - val_accuracy: 0.6087\n",
            "Epoch 145/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.2740 - accuracy: 0.4807 - val_loss: 1.1893 - val_accuracy: 0.5845\n",
            "Epoch 146/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.2528 - accuracy: 0.4964 - val_loss: 1.1863 - val_accuracy: 0.5797\n",
            "Epoch 147/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.2927 - accuracy: 0.4813 - val_loss: 1.2089 - val_accuracy: 0.5362\n",
            "Epoch 148/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.2833 - accuracy: 0.4825 - val_loss: 1.1966 - val_accuracy: 0.5314\n",
            "Epoch 149/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.2485 - accuracy: 0.4952 - val_loss: 1.1925 - val_accuracy: 0.5990\n",
            "Epoch 150/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.2594 - accuracy: 0.4873 - val_loss: 1.1943 - val_accuracy: 0.5894\n",
            "Epoch 151/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.2532 - accuracy: 0.4933 - val_loss: 1.1833 - val_accuracy: 0.5845\n",
            "Epoch 152/1000\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 1.2397 - accuracy: 0.4915 - val_loss: 1.1818 - val_accuracy: 0.5942\n",
            "Epoch 153/1000\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 1.2371 - accuracy: 0.4933 - val_loss: 1.1790 - val_accuracy: 0.6232\n",
            "Epoch 154/1000\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 1.2504 - accuracy: 0.4897 - val_loss: 1.1941 - val_accuracy: 0.5556\n",
            "Epoch 155/1000\n",
            "104/104 [==============================] - 1s 9ms/step - loss: 1.2414 - accuracy: 0.4903 - val_loss: 1.1649 - val_accuracy: 0.6087\n",
            "Epoch 156/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 1.2300 - accuracy: 0.4976 - val_loss: 1.1696 - val_accuracy: 0.5749\n",
            "Epoch 157/1000\n",
            "104/104 [==============================] - 1s 10ms/step - loss: 1.2554 - accuracy: 0.4946 - val_loss: 1.1716 - val_accuracy: 0.5604\n",
            "Epoch 158/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.2203 - accuracy: 0.5079 - val_loss: 1.1588 - val_accuracy: 0.5652\n",
            "Epoch 159/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.2532 - accuracy: 0.4958 - val_loss: 1.1594 - val_accuracy: 0.5894\n",
            "Epoch 160/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.2084 - accuracy: 0.5121 - val_loss: 1.1539 - val_accuracy: 0.5990\n",
            "Epoch 161/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.2088 - accuracy: 0.5067 - val_loss: 1.1495 - val_accuracy: 0.5990\n",
            "Epoch 162/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.2006 - accuracy: 0.5260 - val_loss: 1.1641 - val_accuracy: 0.5749\n",
            "Epoch 163/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.2114 - accuracy: 0.5230 - val_loss: 1.1518 - val_accuracy: 0.5700\n",
            "Epoch 164/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.2031 - accuracy: 0.5212 - val_loss: 1.1258 - val_accuracy: 0.5700\n",
            "Epoch 165/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.1875 - accuracy: 0.5326 - val_loss: 1.1308 - val_accuracy: 0.5894\n",
            "Epoch 166/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.2097 - accuracy: 0.5006 - val_loss: 1.1367 - val_accuracy: 0.6039\n",
            "Epoch 167/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.1935 - accuracy: 0.5163 - val_loss: 1.1343 - val_accuracy: 0.5362\n",
            "Epoch 168/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.1878 - accuracy: 0.5115 - val_loss: 1.1295 - val_accuracy: 0.6232\n",
            "Epoch 169/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.2027 - accuracy: 0.5060 - val_loss: 1.1231 - val_accuracy: 0.5894\n",
            "Epoch 170/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.2027 - accuracy: 0.5127 - val_loss: 1.1416 - val_accuracy: 0.5507\n",
            "Epoch 171/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.1853 - accuracy: 0.5224 - val_loss: 1.1266 - val_accuracy: 0.6184\n",
            "Epoch 172/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.1870 - accuracy: 0.5133 - val_loss: 1.1229 - val_accuracy: 0.5894\n",
            "Epoch 173/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.1535 - accuracy: 0.5363 - val_loss: 1.1063 - val_accuracy: 0.5894\n",
            "Epoch 174/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.1617 - accuracy: 0.5411 - val_loss: 1.1140 - val_accuracy: 0.5894\n",
            "Epoch 175/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.1711 - accuracy: 0.5314 - val_loss: 1.1077 - val_accuracy: 0.6280\n",
            "Epoch 176/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.1564 - accuracy: 0.5399 - val_loss: 1.1069 - val_accuracy: 0.6087\n",
            "Epoch 177/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.1648 - accuracy: 0.5302 - val_loss: 1.1094 - val_accuracy: 0.5845\n",
            "Epoch 178/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.1907 - accuracy: 0.5200 - val_loss: 1.1087 - val_accuracy: 0.6039\n",
            "Epoch 179/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.1514 - accuracy: 0.5320 - val_loss: 1.1158 - val_accuracy: 0.5700\n",
            "Epoch 180/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.1617 - accuracy: 0.5266 - val_loss: 1.1017 - val_accuracy: 0.5700\n",
            "Epoch 181/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.1607 - accuracy: 0.5278 - val_loss: 1.1004 - val_accuracy: 0.5894\n",
            "Epoch 182/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.1561 - accuracy: 0.5429 - val_loss: 1.0980 - val_accuracy: 0.6377\n",
            "Epoch 183/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.1614 - accuracy: 0.5417 - val_loss: 1.0960 - val_accuracy: 0.5990\n",
            "Epoch 184/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.1537 - accuracy: 0.5387 - val_loss: 1.0971 - val_accuracy: 0.6280\n",
            "Epoch 185/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.1382 - accuracy: 0.5363 - val_loss: 1.0866 - val_accuracy: 0.5990\n",
            "Epoch 186/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.1382 - accuracy: 0.5411 - val_loss: 1.0896 - val_accuracy: 0.6039\n",
            "Epoch 187/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.1364 - accuracy: 0.5345 - val_loss: 1.0752 - val_accuracy: 0.6135\n",
            "Epoch 188/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.1377 - accuracy: 0.5357 - val_loss: 1.0687 - val_accuracy: 0.6473\n",
            "Epoch 189/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.1217 - accuracy: 0.5435 - val_loss: 1.0743 - val_accuracy: 0.6473\n",
            "Epoch 190/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.1264 - accuracy: 0.5532 - val_loss: 1.0797 - val_accuracy: 0.6135\n",
            "Epoch 191/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.1109 - accuracy: 0.5532 - val_loss: 1.0721 - val_accuracy: 0.6473\n",
            "Epoch 192/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.1098 - accuracy: 0.5466 - val_loss: 1.0909 - val_accuracy: 0.5845\n",
            "Epoch 193/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.1220 - accuracy: 0.5514 - val_loss: 1.0695 - val_accuracy: 0.6377\n",
            "Epoch 194/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.1229 - accuracy: 0.5447 - val_loss: 1.0682 - val_accuracy: 0.6232\n",
            "Epoch 195/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.1286 - accuracy: 0.5490 - val_loss: 1.0790 - val_accuracy: 0.6280\n",
            "Epoch 196/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0938 - accuracy: 0.5762 - val_loss: 1.0844 - val_accuracy: 0.5990\n",
            "Epoch 197/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.1034 - accuracy: 0.5568 - val_loss: 1.0588 - val_accuracy: 0.6087\n",
            "Epoch 198/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.0920 - accuracy: 0.5683 - val_loss: 1.0607 - val_accuracy: 0.6184\n",
            "Epoch 199/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.1041 - accuracy: 0.5683 - val_loss: 1.0699 - val_accuracy: 0.6087\n",
            "Epoch 200/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.1083 - accuracy: 0.5647 - val_loss: 1.0686 - val_accuracy: 0.6232\n",
            "Epoch 201/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.1169 - accuracy: 0.5550 - val_loss: 1.0736 - val_accuracy: 0.6232\n",
            "Epoch 202/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.1025 - accuracy: 0.5586 - val_loss: 1.0620 - val_accuracy: 0.6232\n",
            "Epoch 203/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0845 - accuracy: 0.5562 - val_loss: 1.0528 - val_accuracy: 0.6232\n",
            "Epoch 204/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0711 - accuracy: 0.5713 - val_loss: 1.0663 - val_accuracy: 0.6329\n",
            "Epoch 205/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.0909 - accuracy: 0.5538 - val_loss: 1.0736 - val_accuracy: 0.6232\n",
            "Epoch 206/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0759 - accuracy: 0.5677 - val_loss: 1.0607 - val_accuracy: 0.5990\n",
            "Epoch 207/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0767 - accuracy: 0.5738 - val_loss: 1.0467 - val_accuracy: 0.6377\n",
            "Epoch 208/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0809 - accuracy: 0.5629 - val_loss: 1.0459 - val_accuracy: 0.5990\n",
            "Epoch 209/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.0745 - accuracy: 0.5750 - val_loss: 1.0344 - val_accuracy: 0.6425\n",
            "Epoch 210/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.0554 - accuracy: 0.5804 - val_loss: 1.0347 - val_accuracy: 0.6280\n",
            "Epoch 211/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0732 - accuracy: 0.5726 - val_loss: 1.0279 - val_accuracy: 0.6232\n",
            "Epoch 212/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.0720 - accuracy: 0.5707 - val_loss: 1.0376 - val_accuracy: 0.5990\n",
            "Epoch 213/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0767 - accuracy: 0.5574 - val_loss: 1.0301 - val_accuracy: 0.6473\n",
            "Epoch 214/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0519 - accuracy: 0.5798 - val_loss: 1.0407 - val_accuracy: 0.6039\n",
            "Epoch 215/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.0433 - accuracy: 0.5967 - val_loss: 1.0317 - val_accuracy: 0.6329\n",
            "Epoch 216/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0552 - accuracy: 0.5865 - val_loss: 1.0339 - val_accuracy: 0.6184\n",
            "Epoch 217/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0455 - accuracy: 0.5883 - val_loss: 1.0177 - val_accuracy: 0.6280\n",
            "Epoch 218/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0472 - accuracy: 0.5659 - val_loss: 1.0235 - val_accuracy: 0.6135\n",
            "Epoch 219/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0646 - accuracy: 0.5744 - val_loss: 1.0289 - val_accuracy: 0.6329\n",
            "Epoch 220/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.0631 - accuracy: 0.5756 - val_loss: 1.0202 - val_accuracy: 0.6377\n",
            "Epoch 221/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0487 - accuracy: 0.5822 - val_loss: 1.0251 - val_accuracy: 0.6184\n",
            "Epoch 222/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0480 - accuracy: 0.5834 - val_loss: 1.0132 - val_accuracy: 0.6473\n",
            "Epoch 223/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0323 - accuracy: 0.5901 - val_loss: 1.0141 - val_accuracy: 0.6184\n",
            "Epoch 224/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0440 - accuracy: 0.5774 - val_loss: 1.0207 - val_accuracy: 0.6135\n",
            "Epoch 225/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.0313 - accuracy: 0.5931 - val_loss: 0.9978 - val_accuracy: 0.6473\n",
            "Epoch 226/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0097 - accuracy: 0.5937 - val_loss: 1.0145 - val_accuracy: 0.6135\n",
            "Epoch 227/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0325 - accuracy: 0.5828 - val_loss: 1.0081 - val_accuracy: 0.6329\n",
            "Epoch 228/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.0211 - accuracy: 0.6004 - val_loss: 1.0005 - val_accuracy: 0.6329\n",
            "Epoch 229/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.0119 - accuracy: 0.5949 - val_loss: 0.9935 - val_accuracy: 0.6377\n",
            "Epoch 230/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.0254 - accuracy: 0.5913 - val_loss: 0.9935 - val_accuracy: 0.6280\n",
            "Epoch 231/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.0171 - accuracy: 0.5949 - val_loss: 1.0005 - val_accuracy: 0.6184\n",
            "Epoch 232/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.0121 - accuracy: 0.6028 - val_loss: 0.9928 - val_accuracy: 0.6570\n",
            "Epoch 233/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0035 - accuracy: 0.5961 - val_loss: 0.9839 - val_accuracy: 0.6425\n",
            "Epoch 234/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.9764 - accuracy: 0.6300 - val_loss: 0.9882 - val_accuracy: 0.6570\n",
            "Epoch 235/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0213 - accuracy: 0.5883 - val_loss: 0.9815 - val_accuracy: 0.6425\n",
            "Epoch 236/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0022 - accuracy: 0.6082 - val_loss: 0.9801 - val_accuracy: 0.6473\n",
            "Epoch 237/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9940 - accuracy: 0.6100 - val_loss: 0.9918 - val_accuracy: 0.6280\n",
            "Epoch 238/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0190 - accuracy: 0.5919 - val_loss: 0.9850 - val_accuracy: 0.6522\n",
            "Epoch 239/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9933 - accuracy: 0.5949 - val_loss: 0.9775 - val_accuracy: 0.6570\n",
            "Epoch 240/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0189 - accuracy: 0.5949 - val_loss: 0.9878 - val_accuracy: 0.6522\n",
            "Epoch 241/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9861 - accuracy: 0.5998 - val_loss: 0.9865 - val_accuracy: 0.6425\n",
            "Epoch 242/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.9882 - accuracy: 0.5998 - val_loss: 0.9757 - val_accuracy: 0.6473\n",
            "Epoch 243/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.9714 - accuracy: 0.6197 - val_loss: 0.9733 - val_accuracy: 0.6570\n",
            "Epoch 244/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9892 - accuracy: 0.6209 - val_loss: 0.9705 - val_accuracy: 0.6425\n",
            "Epoch 245/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.9954 - accuracy: 0.5998 - val_loss: 0.9776 - val_accuracy: 0.6618\n",
            "Epoch 246/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9850 - accuracy: 0.6028 - val_loss: 0.9739 - val_accuracy: 0.6425\n",
            "Epoch 247/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.9713 - accuracy: 0.6125 - val_loss: 0.9721 - val_accuracy: 0.6329\n",
            "Epoch 248/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9913 - accuracy: 0.5973 - val_loss: 0.9733 - val_accuracy: 0.6232\n",
            "Epoch 249/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9988 - accuracy: 0.5919 - val_loss: 0.9845 - val_accuracy: 0.6087\n",
            "Epoch 250/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9647 - accuracy: 0.6143 - val_loss: 0.9591 - val_accuracy: 0.6473\n",
            "Epoch 251/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9640 - accuracy: 0.6191 - val_loss: 0.9592 - val_accuracy: 0.6570\n",
            "Epoch 252/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9862 - accuracy: 0.5985 - val_loss: 0.9547 - val_accuracy: 0.6425\n",
            "Epoch 253/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.9653 - accuracy: 0.6227 - val_loss: 0.9708 - val_accuracy: 0.6280\n",
            "Epoch 254/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.9708 - accuracy: 0.6185 - val_loss: 0.9601 - val_accuracy: 0.6377\n",
            "Epoch 255/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.9633 - accuracy: 0.6300 - val_loss: 0.9503 - val_accuracy: 0.6522\n",
            "Epoch 256/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.9845 - accuracy: 0.6179 - val_loss: 0.9535 - val_accuracy: 0.6425\n",
            "Epoch 257/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.9651 - accuracy: 0.6179 - val_loss: 0.9371 - val_accuracy: 0.6812\n",
            "Epoch 258/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9483 - accuracy: 0.6245 - val_loss: 0.9334 - val_accuracy: 0.6715\n",
            "Epoch 259/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9685 - accuracy: 0.6082 - val_loss: 0.9331 - val_accuracy: 0.6667\n",
            "Epoch 260/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9483 - accuracy: 0.6409 - val_loss: 0.9356 - val_accuracy: 0.6473\n",
            "Epoch 261/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.9599 - accuracy: 0.6185 - val_loss: 0.9512 - val_accuracy: 0.6425\n",
            "Epoch 262/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9549 - accuracy: 0.6294 - val_loss: 0.9489 - val_accuracy: 0.6957\n",
            "Epoch 263/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9386 - accuracy: 0.6312 - val_loss: 0.9703 - val_accuracy: 0.6184\n",
            "Epoch 264/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9540 - accuracy: 0.6258 - val_loss: 0.9364 - val_accuracy: 0.6618\n",
            "Epoch 265/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9406 - accuracy: 0.6366 - val_loss: 0.9434 - val_accuracy: 0.6522\n",
            "Epoch 266/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9333 - accuracy: 0.6348 - val_loss: 0.9448 - val_accuracy: 0.6377\n",
            "Epoch 267/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9488 - accuracy: 0.6276 - val_loss: 0.9487 - val_accuracy: 0.6425\n",
            "Epoch 268/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9540 - accuracy: 0.6143 - val_loss: 0.9545 - val_accuracy: 0.6280\n",
            "Epoch 269/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9356 - accuracy: 0.6330 - val_loss: 0.9488 - val_accuracy: 0.6377\n",
            "Epoch 270/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.9337 - accuracy: 0.6330 - val_loss: 0.9600 - val_accuracy: 0.6329\n",
            "Epoch 271/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.9348 - accuracy: 0.6463 - val_loss: 0.9685 - val_accuracy: 0.6232\n",
            "Epoch 272/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9467 - accuracy: 0.6324 - val_loss: 0.9548 - val_accuracy: 0.6329\n",
            "Epoch 273/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9456 - accuracy: 0.6221 - val_loss: 0.9411 - val_accuracy: 0.6570\n",
            "Epoch 274/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9364 - accuracy: 0.6209 - val_loss: 0.9410 - val_accuracy: 0.6377\n",
            "Epoch 275/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8973 - accuracy: 0.6566 - val_loss: 0.9277 - val_accuracy: 0.6522\n",
            "Epoch 276/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9298 - accuracy: 0.6258 - val_loss: 0.9203 - val_accuracy: 0.6812\n",
            "Epoch 277/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9148 - accuracy: 0.6421 - val_loss: 0.9200 - val_accuracy: 0.6763\n",
            "Epoch 278/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9398 - accuracy: 0.6245 - val_loss: 0.9243 - val_accuracy: 0.6812\n",
            "Epoch 279/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9219 - accuracy: 0.6270 - val_loss: 0.9124 - val_accuracy: 0.6763\n",
            "Epoch 280/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9319 - accuracy: 0.6433 - val_loss: 0.9254 - val_accuracy: 0.6425\n",
            "Epoch 281/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8990 - accuracy: 0.6300 - val_loss: 0.9203 - val_accuracy: 0.6812\n",
            "Epoch 282/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9209 - accuracy: 0.6306 - val_loss: 0.9226 - val_accuracy: 0.6618\n",
            "Epoch 283/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9192 - accuracy: 0.6457 - val_loss: 0.9187 - val_accuracy: 0.6618\n",
            "Epoch 284/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8864 - accuracy: 0.6439 - val_loss: 0.9657 - val_accuracy: 0.6329\n",
            "Epoch 285/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.8987 - accuracy: 0.6354 - val_loss: 0.9160 - val_accuracy: 0.6522\n",
            "Epoch 286/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9142 - accuracy: 0.6524 - val_loss: 0.9213 - val_accuracy: 0.6522\n",
            "Epoch 287/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9045 - accuracy: 0.6360 - val_loss: 0.9101 - val_accuracy: 0.6425\n",
            "Epoch 288/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8893 - accuracy: 0.6457 - val_loss: 0.9095 - val_accuracy: 0.6715\n",
            "Epoch 289/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9130 - accuracy: 0.6463 - val_loss: 0.9065 - val_accuracy: 0.6715\n",
            "Epoch 290/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9376 - accuracy: 0.6276 - val_loss: 0.9123 - val_accuracy: 0.7053\n",
            "Epoch 291/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.9021 - accuracy: 0.6354 - val_loss: 0.9042 - val_accuracy: 0.6957\n",
            "Epoch 292/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9064 - accuracy: 0.6372 - val_loss: 0.9222 - val_accuracy: 0.6570\n",
            "Epoch 293/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.8954 - accuracy: 0.6493 - val_loss: 0.9030 - val_accuracy: 0.6812\n",
            "Epoch 294/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8972 - accuracy: 0.6542 - val_loss: 0.9041 - val_accuracy: 0.6473\n",
            "Epoch 295/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8806 - accuracy: 0.6536 - val_loss: 0.9037 - val_accuracy: 0.6570\n",
            "Epoch 296/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8937 - accuracy: 0.6481 - val_loss: 0.9090 - val_accuracy: 0.6425\n",
            "Epoch 297/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.8871 - accuracy: 0.6421 - val_loss: 0.8936 - val_accuracy: 0.6860\n",
            "Epoch 298/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8804 - accuracy: 0.6584 - val_loss: 0.8960 - val_accuracy: 0.6860\n",
            "Epoch 299/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8745 - accuracy: 0.6632 - val_loss: 0.9025 - val_accuracy: 0.6522\n",
            "Epoch 300/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8965 - accuracy: 0.6475 - val_loss: 0.8953 - val_accuracy: 0.6715\n",
            "Epoch 301/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8921 - accuracy: 0.6505 - val_loss: 0.9023 - val_accuracy: 0.6860\n",
            "Epoch 302/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8766 - accuracy: 0.6481 - val_loss: 0.9187 - val_accuracy: 0.6570\n",
            "Epoch 303/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.8786 - accuracy: 0.6493 - val_loss: 0.8961 - val_accuracy: 0.6812\n",
            "Epoch 304/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8881 - accuracy: 0.6439 - val_loss: 0.9072 - val_accuracy: 0.6667\n",
            "Epoch 305/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8934 - accuracy: 0.6457 - val_loss: 0.8935 - val_accuracy: 0.6715\n",
            "Epoch 306/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8716 - accuracy: 0.6451 - val_loss: 0.9010 - val_accuracy: 0.6812\n",
            "Epoch 307/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8804 - accuracy: 0.6385 - val_loss: 0.9033 - val_accuracy: 0.6763\n",
            "Epoch 308/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.8744 - accuracy: 0.6499 - val_loss: 0.9153 - val_accuracy: 0.6812\n",
            "Epoch 309/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8870 - accuracy: 0.6675 - val_loss: 0.8995 - val_accuracy: 0.6860\n",
            "Epoch 310/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8789 - accuracy: 0.6620 - val_loss: 0.8956 - val_accuracy: 0.6860\n",
            "Epoch 311/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8434 - accuracy: 0.6729 - val_loss: 0.9026 - val_accuracy: 0.6715\n",
            "Epoch 312/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8717 - accuracy: 0.6590 - val_loss: 0.8850 - val_accuracy: 0.7005\n",
            "Epoch 313/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8890 - accuracy: 0.6457 - val_loss: 0.9090 - val_accuracy: 0.6812\n",
            "Epoch 314/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8548 - accuracy: 0.6578 - val_loss: 0.8901 - val_accuracy: 0.7005\n",
            "Epoch 315/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8776 - accuracy: 0.6505 - val_loss: 0.8855 - val_accuracy: 0.6763\n",
            "Epoch 316/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8656 - accuracy: 0.6632 - val_loss: 0.9020 - val_accuracy: 0.6715\n",
            "Epoch 317/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.8751 - accuracy: 0.6548 - val_loss: 0.8826 - val_accuracy: 0.7005\n",
            "Epoch 318/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8572 - accuracy: 0.6723 - val_loss: 0.8768 - val_accuracy: 0.7150\n",
            "Epoch 319/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8506 - accuracy: 0.6663 - val_loss: 0.8838 - val_accuracy: 0.6957\n",
            "Epoch 320/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8504 - accuracy: 0.6675 - val_loss: 0.8982 - val_accuracy: 0.6667\n",
            "Epoch 321/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8299 - accuracy: 0.6765 - val_loss: 0.8857 - val_accuracy: 0.6667\n",
            "Epoch 322/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8476 - accuracy: 0.6657 - val_loss: 0.8921 - val_accuracy: 0.6667\n",
            "Epoch 323/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8593 - accuracy: 0.6499 - val_loss: 0.8931 - val_accuracy: 0.6618\n",
            "Epoch 324/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.8428 - accuracy: 0.6669 - val_loss: 0.8822 - val_accuracy: 0.6618\n",
            "Epoch 325/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8605 - accuracy: 0.6572 - val_loss: 0.8699 - val_accuracy: 0.6957\n",
            "Epoch 326/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8294 - accuracy: 0.6681 - val_loss: 0.8793 - val_accuracy: 0.6812\n",
            "Epoch 327/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8480 - accuracy: 0.6784 - val_loss: 0.8738 - val_accuracy: 0.6812\n",
            "Epoch 328/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8429 - accuracy: 0.6669 - val_loss: 0.8830 - val_accuracy: 0.6812\n",
            "Epoch 329/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8263 - accuracy: 0.6705 - val_loss: 0.9007 - val_accuracy: 0.6667\n",
            "Epoch 330/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8335 - accuracy: 0.6699 - val_loss: 0.8890 - val_accuracy: 0.6860\n",
            "Epoch 331/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8252 - accuracy: 0.6784 - val_loss: 0.8774 - val_accuracy: 0.6763\n",
            "Epoch 332/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8256 - accuracy: 0.6911 - val_loss: 0.8695 - val_accuracy: 0.6715\n",
            "Epoch 333/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8343 - accuracy: 0.6735 - val_loss: 0.8775 - val_accuracy: 0.6908\n",
            "Epoch 334/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8106 - accuracy: 0.6820 - val_loss: 0.8703 - val_accuracy: 0.6763\n",
            "Epoch 335/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8370 - accuracy: 0.6699 - val_loss: 0.8515 - val_accuracy: 0.7053\n",
            "Epoch 336/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8296 - accuracy: 0.6614 - val_loss: 0.8764 - val_accuracy: 0.6812\n",
            "Epoch 337/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8221 - accuracy: 0.6693 - val_loss: 0.8740 - val_accuracy: 0.6860\n",
            "Epoch 338/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8263 - accuracy: 0.6820 - val_loss: 0.8606 - val_accuracy: 0.7005\n",
            "Epoch 339/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8149 - accuracy: 0.6771 - val_loss: 0.8635 - val_accuracy: 0.6957\n",
            "Epoch 340/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8261 - accuracy: 0.6802 - val_loss: 0.8606 - val_accuracy: 0.7053\n",
            "Epoch 341/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8258 - accuracy: 0.6753 - val_loss: 0.8691 - val_accuracy: 0.6908\n",
            "Epoch 342/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8023 - accuracy: 0.6935 - val_loss: 0.8559 - val_accuracy: 0.6957\n",
            "Epoch 343/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8213 - accuracy: 0.6741 - val_loss: 0.8717 - val_accuracy: 0.6618\n",
            "Epoch 344/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8300 - accuracy: 0.6765 - val_loss: 0.8558 - val_accuracy: 0.7005\n",
            "Epoch 345/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8139 - accuracy: 0.6892 - val_loss: 0.8402 - val_accuracy: 0.7198\n",
            "Epoch 346/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8289 - accuracy: 0.6729 - val_loss: 0.8536 - val_accuracy: 0.6860\n",
            "Epoch 347/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8235 - accuracy: 0.6741 - val_loss: 0.8621 - val_accuracy: 0.6860\n",
            "Epoch 348/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7847 - accuracy: 0.6880 - val_loss: 0.8494 - val_accuracy: 0.7005\n",
            "Epoch 349/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8097 - accuracy: 0.6711 - val_loss: 0.8470 - val_accuracy: 0.6908\n",
            "Epoch 350/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8123 - accuracy: 0.6765 - val_loss: 0.8507 - val_accuracy: 0.6957\n",
            "Epoch 351/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8228 - accuracy: 0.6687 - val_loss: 0.8703 - val_accuracy: 0.6860\n",
            "Epoch 352/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8241 - accuracy: 0.6638 - val_loss: 0.8687 - val_accuracy: 0.6957\n",
            "Epoch 353/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7896 - accuracy: 0.7007 - val_loss: 0.8563 - val_accuracy: 0.6763\n",
            "Epoch 354/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8111 - accuracy: 0.6790 - val_loss: 0.8458 - val_accuracy: 0.6957\n",
            "Epoch 355/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.8023 - accuracy: 0.6784 - val_loss: 0.8332 - val_accuracy: 0.7150\n",
            "Epoch 356/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7947 - accuracy: 0.6802 - val_loss: 0.8483 - val_accuracy: 0.6908\n",
            "Epoch 357/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8142 - accuracy: 0.6796 - val_loss: 0.8415 - val_accuracy: 0.7246\n",
            "Epoch 358/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8056 - accuracy: 0.6868 - val_loss: 0.8397 - val_accuracy: 0.7101\n",
            "Epoch 359/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8047 - accuracy: 0.6868 - val_loss: 0.8386 - val_accuracy: 0.7053\n",
            "Epoch 360/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8028 - accuracy: 0.6759 - val_loss: 0.8536 - val_accuracy: 0.6908\n",
            "Epoch 361/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8089 - accuracy: 0.6765 - val_loss: 0.8575 - val_accuracy: 0.6957\n",
            "Epoch 362/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7854 - accuracy: 0.6953 - val_loss: 0.8517 - val_accuracy: 0.6618\n",
            "Epoch 363/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7875 - accuracy: 0.6917 - val_loss: 0.8431 - val_accuracy: 0.6763\n",
            "Epoch 364/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7854 - accuracy: 0.6838 - val_loss: 0.8411 - val_accuracy: 0.7005\n",
            "Epoch 365/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7987 - accuracy: 0.6965 - val_loss: 0.8490 - val_accuracy: 0.7198\n",
            "Epoch 366/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8012 - accuracy: 0.6717 - val_loss: 0.8444 - val_accuracy: 0.6957\n",
            "Epoch 367/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7905 - accuracy: 0.6929 - val_loss: 0.8552 - val_accuracy: 0.6812\n",
            "Epoch 368/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7893 - accuracy: 0.6790 - val_loss: 0.8559 - val_accuracy: 0.6667\n",
            "Epoch 369/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8105 - accuracy: 0.6802 - val_loss: 0.8547 - val_accuracy: 0.6812\n",
            "Epoch 370/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7977 - accuracy: 0.6892 - val_loss: 0.8506 - val_accuracy: 0.6812\n",
            "Epoch 371/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7806 - accuracy: 0.6971 - val_loss: 0.8365 - val_accuracy: 0.6908\n",
            "Epoch 372/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8100 - accuracy: 0.6802 - val_loss: 0.8293 - val_accuracy: 0.7198\n",
            "Epoch 373/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7856 - accuracy: 0.6832 - val_loss: 0.8336 - val_accuracy: 0.6908\n",
            "Epoch 374/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7775 - accuracy: 0.6802 - val_loss: 0.8387 - val_accuracy: 0.7053\n",
            "Epoch 375/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7793 - accuracy: 0.6911 - val_loss: 0.8524 - val_accuracy: 0.6715\n",
            "Epoch 376/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7810 - accuracy: 0.6832 - val_loss: 0.8413 - val_accuracy: 0.7005\n",
            "Epoch 377/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7960 - accuracy: 0.6983 - val_loss: 0.8448 - val_accuracy: 0.6957\n",
            "Epoch 378/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7892 - accuracy: 0.6917 - val_loss: 0.8464 - val_accuracy: 0.6908\n",
            "Epoch 379/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7773 - accuracy: 0.6953 - val_loss: 0.8340 - val_accuracy: 0.6860\n",
            "Epoch 380/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7856 - accuracy: 0.6947 - val_loss: 0.8564 - val_accuracy: 0.6522\n",
            "Epoch 381/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7805 - accuracy: 0.6838 - val_loss: 0.8414 - val_accuracy: 0.7101\n",
            "Epoch 382/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7699 - accuracy: 0.7001 - val_loss: 0.8230 - val_accuracy: 0.7005\n",
            "Epoch 383/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7778 - accuracy: 0.7031 - val_loss: 0.8398 - val_accuracy: 0.6715\n",
            "Epoch 384/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7767 - accuracy: 0.6971 - val_loss: 0.8314 - val_accuracy: 0.6957\n",
            "Epoch 385/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7776 - accuracy: 0.6929 - val_loss: 0.8179 - val_accuracy: 0.7101\n",
            "Epoch 386/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7702 - accuracy: 0.6995 - val_loss: 0.8311 - val_accuracy: 0.6908\n",
            "Epoch 387/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7756 - accuracy: 0.6862 - val_loss: 0.8206 - val_accuracy: 0.7101\n",
            "Epoch 388/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7606 - accuracy: 0.6874 - val_loss: 0.8279 - val_accuracy: 0.7150\n",
            "Epoch 389/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7648 - accuracy: 0.7013 - val_loss: 0.8333 - val_accuracy: 0.6860\n",
            "Epoch 390/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7632 - accuracy: 0.6971 - val_loss: 0.8380 - val_accuracy: 0.6957\n",
            "Epoch 391/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7621 - accuracy: 0.7031 - val_loss: 0.8316 - val_accuracy: 0.6908\n",
            "Epoch 392/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7576 - accuracy: 0.7001 - val_loss: 0.8320 - val_accuracy: 0.7295\n",
            "Epoch 393/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7737 - accuracy: 0.6923 - val_loss: 0.8153 - val_accuracy: 0.7005\n",
            "Epoch 394/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.7670 - accuracy: 0.6989 - val_loss: 0.8226 - val_accuracy: 0.7053\n",
            "Epoch 395/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7497 - accuracy: 0.7080 - val_loss: 0.8225 - val_accuracy: 0.6763\n",
            "Epoch 396/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7669 - accuracy: 0.6977 - val_loss: 0.8258 - val_accuracy: 0.7150\n",
            "Epoch 397/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7590 - accuracy: 0.7037 - val_loss: 0.8166 - val_accuracy: 0.7101\n",
            "Epoch 398/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7504 - accuracy: 0.6989 - val_loss: 0.8163 - val_accuracy: 0.7005\n",
            "Epoch 399/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7582 - accuracy: 0.6929 - val_loss: 0.8333 - val_accuracy: 0.7053\n",
            "Epoch 400/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7651 - accuracy: 0.6959 - val_loss: 0.8015 - val_accuracy: 0.7053\n",
            "Epoch 401/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7475 - accuracy: 0.7098 - val_loss: 0.8258 - val_accuracy: 0.6763\n",
            "Epoch 402/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7642 - accuracy: 0.6971 - val_loss: 0.8285 - val_accuracy: 0.7101\n",
            "Epoch 403/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7503 - accuracy: 0.7086 - val_loss: 0.8209 - val_accuracy: 0.6860\n",
            "Epoch 404/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7543 - accuracy: 0.7037 - val_loss: 0.8247 - val_accuracy: 0.6957\n",
            "Epoch 405/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7333 - accuracy: 0.7092 - val_loss: 0.8211 - val_accuracy: 0.7005\n",
            "Epoch 406/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7413 - accuracy: 0.7062 - val_loss: 0.8194 - val_accuracy: 0.7295\n",
            "Epoch 407/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7564 - accuracy: 0.6995 - val_loss: 0.8356 - val_accuracy: 0.6860\n",
            "Epoch 408/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7484 - accuracy: 0.7231 - val_loss: 0.8215 - val_accuracy: 0.7005\n",
            "Epoch 409/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7411 - accuracy: 0.7007 - val_loss: 0.8146 - val_accuracy: 0.7150\n",
            "Epoch 410/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7445 - accuracy: 0.7207 - val_loss: 0.8044 - val_accuracy: 0.7198\n",
            "Epoch 411/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7339 - accuracy: 0.7056 - val_loss: 0.8116 - val_accuracy: 0.7101\n",
            "Epoch 412/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7572 - accuracy: 0.7044 - val_loss: 0.8162 - val_accuracy: 0.6812\n",
            "Epoch 413/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7365 - accuracy: 0.7183 - val_loss: 0.8079 - val_accuracy: 0.7005\n",
            "Epoch 414/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7122 - accuracy: 0.7261 - val_loss: 0.8110 - val_accuracy: 0.6908\n",
            "Epoch 415/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7266 - accuracy: 0.7104 - val_loss: 0.8158 - val_accuracy: 0.7053\n",
            "Epoch 416/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7469 - accuracy: 0.7031 - val_loss: 0.8276 - val_accuracy: 0.7101\n",
            "Epoch 417/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7305 - accuracy: 0.7177 - val_loss: 0.8145 - val_accuracy: 0.6957\n",
            "Epoch 418/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7336 - accuracy: 0.7249 - val_loss: 0.8233 - val_accuracy: 0.6908\n",
            "Epoch 419/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7314 - accuracy: 0.7080 - val_loss: 0.8110 - val_accuracy: 0.7101\n",
            "Epoch 420/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7245 - accuracy: 0.7195 - val_loss: 0.8033 - val_accuracy: 0.7005\n",
            "Epoch 421/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7103 - accuracy: 0.7358 - val_loss: 0.8197 - val_accuracy: 0.6957\n",
            "Epoch 422/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7400 - accuracy: 0.7050 - val_loss: 0.8088 - val_accuracy: 0.6957\n",
            "Epoch 423/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7166 - accuracy: 0.7225 - val_loss: 0.8123 - val_accuracy: 0.7053\n",
            "Epoch 424/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7165 - accuracy: 0.7195 - val_loss: 0.8140 - val_accuracy: 0.6908\n",
            "Epoch 425/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7117 - accuracy: 0.7183 - val_loss: 0.8055 - val_accuracy: 0.6957\n",
            "Epoch 426/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.7083 - accuracy: 0.7116 - val_loss: 0.7999 - val_accuracy: 0.7053\n",
            "Epoch 427/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7197 - accuracy: 0.7219 - val_loss: 0.8115 - val_accuracy: 0.7053\n",
            "Epoch 428/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7282 - accuracy: 0.7158 - val_loss: 0.8064 - val_accuracy: 0.7246\n",
            "Epoch 429/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7113 - accuracy: 0.7328 - val_loss: 0.8033 - val_accuracy: 0.6908\n",
            "Epoch 430/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7249 - accuracy: 0.7201 - val_loss: 0.7904 - val_accuracy: 0.7053\n",
            "Epoch 431/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7248 - accuracy: 0.7128 - val_loss: 0.8043 - val_accuracy: 0.7005\n",
            "Epoch 432/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7220 - accuracy: 0.7140 - val_loss: 0.8017 - val_accuracy: 0.6957\n",
            "Epoch 433/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7163 - accuracy: 0.7170 - val_loss: 0.8001 - val_accuracy: 0.7246\n",
            "Epoch 434/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7089 - accuracy: 0.7140 - val_loss: 0.7945 - val_accuracy: 0.7005\n",
            "Epoch 435/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7423 - accuracy: 0.7025 - val_loss: 0.8019 - val_accuracy: 0.7150\n",
            "Epoch 436/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7353 - accuracy: 0.7128 - val_loss: 0.7936 - val_accuracy: 0.6812\n",
            "Epoch 437/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7021 - accuracy: 0.7279 - val_loss: 0.8002 - val_accuracy: 0.6908\n",
            "Epoch 438/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7207 - accuracy: 0.7195 - val_loss: 0.8131 - val_accuracy: 0.7005\n",
            "Epoch 439/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7017 - accuracy: 0.7255 - val_loss: 0.8055 - val_accuracy: 0.7005\n",
            "Epoch 440/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6815 - accuracy: 0.7273 - val_loss: 0.8056 - val_accuracy: 0.6763\n",
            "Epoch 441/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7051 - accuracy: 0.7255 - val_loss: 0.7997 - val_accuracy: 0.7150\n",
            "Epoch 442/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6934 - accuracy: 0.7388 - val_loss: 0.8041 - val_accuracy: 0.7150\n",
            "Epoch 443/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7093 - accuracy: 0.7322 - val_loss: 0.8009 - val_accuracy: 0.7053\n",
            "Epoch 444/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7020 - accuracy: 0.7183 - val_loss: 0.7928 - val_accuracy: 0.6957\n",
            "Epoch 445/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6897 - accuracy: 0.7285 - val_loss: 0.7778 - val_accuracy: 0.7150\n",
            "Epoch 446/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.7070 - accuracy: 0.7243 - val_loss: 0.7960 - val_accuracy: 0.7053\n",
            "Epoch 447/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7167 - accuracy: 0.7231 - val_loss: 0.7976 - val_accuracy: 0.6860\n",
            "Epoch 448/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6925 - accuracy: 0.7225 - val_loss: 0.7994 - val_accuracy: 0.7101\n",
            "Epoch 449/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7071 - accuracy: 0.7310 - val_loss: 0.7967 - val_accuracy: 0.7246\n",
            "Epoch 450/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7039 - accuracy: 0.7195 - val_loss: 0.7977 - val_accuracy: 0.7053\n",
            "Epoch 451/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7071 - accuracy: 0.7231 - val_loss: 0.7921 - val_accuracy: 0.7295\n",
            "Epoch 452/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7189 - accuracy: 0.7164 - val_loss: 0.7874 - val_accuracy: 0.7053\n",
            "Epoch 453/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7095 - accuracy: 0.7140 - val_loss: 0.7956 - val_accuracy: 0.7005\n",
            "Epoch 454/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6970 - accuracy: 0.7285 - val_loss: 0.7977 - val_accuracy: 0.7005\n",
            "Epoch 455/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7049 - accuracy: 0.7249 - val_loss: 0.7897 - val_accuracy: 0.7053\n",
            "Epoch 456/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6928 - accuracy: 0.7279 - val_loss: 0.7930 - val_accuracy: 0.7101\n",
            "Epoch 457/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6982 - accuracy: 0.7243 - val_loss: 0.7829 - val_accuracy: 0.6812\n",
            "Epoch 458/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6988 - accuracy: 0.7322 - val_loss: 0.7788 - val_accuracy: 0.7198\n",
            "Epoch 459/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7105 - accuracy: 0.7255 - val_loss: 0.7846 - val_accuracy: 0.6812\n",
            "Epoch 460/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7064 - accuracy: 0.7219 - val_loss: 0.7746 - val_accuracy: 0.7295\n",
            "Epoch 461/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6875 - accuracy: 0.7267 - val_loss: 0.7997 - val_accuracy: 0.6812\n",
            "Epoch 462/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6665 - accuracy: 0.7491 - val_loss: 0.7794 - val_accuracy: 0.7053\n",
            "Epoch 463/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6665 - accuracy: 0.7412 - val_loss: 0.7801 - val_accuracy: 0.7005\n",
            "Epoch 464/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6580 - accuracy: 0.7443 - val_loss: 0.7863 - val_accuracy: 0.7005\n",
            "Epoch 465/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6831 - accuracy: 0.7382 - val_loss: 0.7902 - val_accuracy: 0.7101\n",
            "Epoch 466/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6515 - accuracy: 0.7473 - val_loss: 0.7867 - val_accuracy: 0.7053\n",
            "Epoch 467/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6671 - accuracy: 0.7376 - val_loss: 0.7879 - val_accuracy: 0.7053\n",
            "Epoch 468/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6817 - accuracy: 0.7322 - val_loss: 0.8048 - val_accuracy: 0.7053\n",
            "Epoch 469/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6743 - accuracy: 0.7400 - val_loss: 0.7818 - val_accuracy: 0.7150\n",
            "Epoch 470/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7073 - accuracy: 0.7189 - val_loss: 0.7848 - val_accuracy: 0.7053\n",
            "Epoch 471/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6811 - accuracy: 0.7346 - val_loss: 0.7829 - val_accuracy: 0.6908\n",
            "Epoch 472/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6849 - accuracy: 0.7261 - val_loss: 0.7955 - val_accuracy: 0.7150\n",
            "Epoch 473/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6817 - accuracy: 0.7370 - val_loss: 0.7983 - val_accuracy: 0.6957\n",
            "Epoch 474/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6569 - accuracy: 0.7400 - val_loss: 0.7809 - val_accuracy: 0.7198\n",
            "Epoch 475/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6675 - accuracy: 0.7449 - val_loss: 0.7834 - val_accuracy: 0.6957\n",
            "Epoch 476/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6663 - accuracy: 0.7473 - val_loss: 0.7743 - val_accuracy: 0.7101\n",
            "Epoch 477/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6662 - accuracy: 0.7352 - val_loss: 0.7894 - val_accuracy: 0.6812\n",
            "Epoch 478/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6656 - accuracy: 0.7479 - val_loss: 0.7804 - val_accuracy: 0.6908\n",
            "Epoch 479/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6638 - accuracy: 0.7400 - val_loss: 0.7681 - val_accuracy: 0.7101\n",
            "Epoch 480/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6749 - accuracy: 0.7443 - val_loss: 0.7777 - val_accuracy: 0.7101\n",
            "Epoch 481/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6731 - accuracy: 0.7388 - val_loss: 0.7812 - val_accuracy: 0.7053\n",
            "Epoch 482/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6524 - accuracy: 0.7424 - val_loss: 0.7740 - val_accuracy: 0.7005\n",
            "Epoch 483/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6672 - accuracy: 0.7388 - val_loss: 0.7864 - val_accuracy: 0.7246\n",
            "Epoch 484/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6626 - accuracy: 0.7412 - val_loss: 0.7682 - val_accuracy: 0.7150\n",
            "Epoch 485/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6599 - accuracy: 0.7491 - val_loss: 0.8070 - val_accuracy: 0.6812\n",
            "Epoch 486/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6653 - accuracy: 0.7424 - val_loss: 0.7635 - val_accuracy: 0.7295\n",
            "Epoch 487/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6474 - accuracy: 0.7479 - val_loss: 0.7893 - val_accuracy: 0.6763\n",
            "Epoch 488/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6319 - accuracy: 0.7527 - val_loss: 0.7661 - val_accuracy: 0.7101\n",
            "Epoch 489/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6452 - accuracy: 0.7497 - val_loss: 0.7765 - val_accuracy: 0.7005\n",
            "Epoch 490/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6625 - accuracy: 0.7285 - val_loss: 0.7611 - val_accuracy: 0.7101\n",
            "Epoch 491/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6488 - accuracy: 0.7412 - val_loss: 0.7784 - val_accuracy: 0.7005\n",
            "Epoch 492/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6467 - accuracy: 0.7539 - val_loss: 0.7756 - val_accuracy: 0.7053\n",
            "Epoch 493/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6471 - accuracy: 0.7388 - val_loss: 0.7793 - val_accuracy: 0.6860\n",
            "Epoch 494/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6630 - accuracy: 0.7437 - val_loss: 0.7684 - val_accuracy: 0.7246\n",
            "Epoch 495/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6348 - accuracy: 0.7527 - val_loss: 0.7830 - val_accuracy: 0.7198\n",
            "Epoch 496/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6577 - accuracy: 0.7437 - val_loss: 0.7529 - val_accuracy: 0.7150\n",
            "Epoch 497/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6413 - accuracy: 0.7461 - val_loss: 0.7597 - val_accuracy: 0.7005\n",
            "Epoch 498/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6651 - accuracy: 0.7418 - val_loss: 0.7586 - val_accuracy: 0.7150\n",
            "Epoch 499/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6384 - accuracy: 0.7576 - val_loss: 0.7676 - val_accuracy: 0.7005\n",
            "Epoch 500/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6347 - accuracy: 0.7636 - val_loss: 0.7615 - val_accuracy: 0.7005\n",
            "Epoch 501/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6622 - accuracy: 0.7370 - val_loss: 0.7588 - val_accuracy: 0.7101\n",
            "Epoch 502/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6567 - accuracy: 0.7358 - val_loss: 0.7536 - val_accuracy: 0.7198\n",
            "Epoch 503/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6308 - accuracy: 0.7491 - val_loss: 0.7691 - val_accuracy: 0.7150\n",
            "Epoch 504/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6422 - accuracy: 0.7443 - val_loss: 0.7703 - val_accuracy: 0.7053\n",
            "Epoch 505/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6223 - accuracy: 0.7527 - val_loss: 0.7569 - val_accuracy: 0.7246\n",
            "Epoch 506/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6463 - accuracy: 0.7636 - val_loss: 0.7751 - val_accuracy: 0.7101\n",
            "Epoch 507/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6398 - accuracy: 0.7515 - val_loss: 0.7727 - val_accuracy: 0.6860\n",
            "Epoch 508/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6306 - accuracy: 0.7588 - val_loss: 0.7709 - val_accuracy: 0.6957\n",
            "Epoch 509/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6211 - accuracy: 0.7533 - val_loss: 0.7681 - val_accuracy: 0.7053\n",
            "Epoch 510/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6424 - accuracy: 0.7479 - val_loss: 0.7613 - val_accuracy: 0.6957\n",
            "Epoch 511/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6145 - accuracy: 0.7709 - val_loss: 0.7753 - val_accuracy: 0.6860\n",
            "Epoch 512/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6118 - accuracy: 0.7648 - val_loss: 0.7726 - val_accuracy: 0.6860\n",
            "Epoch 513/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6268 - accuracy: 0.7588 - val_loss: 0.7665 - val_accuracy: 0.6812\n",
            "Epoch 514/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6406 - accuracy: 0.7503 - val_loss: 0.7567 - val_accuracy: 0.7246\n",
            "Epoch 515/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6386 - accuracy: 0.7485 - val_loss: 0.7567 - val_accuracy: 0.7246\n",
            "Epoch 516/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6251 - accuracy: 0.7430 - val_loss: 0.7628 - val_accuracy: 0.7198\n",
            "Epoch 517/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6428 - accuracy: 0.7467 - val_loss: 0.7670 - val_accuracy: 0.6860\n",
            "Epoch 518/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6356 - accuracy: 0.7509 - val_loss: 0.7858 - val_accuracy: 0.6908\n",
            "Epoch 519/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6326 - accuracy: 0.7340 - val_loss: 0.7677 - val_accuracy: 0.6957\n",
            "Epoch 520/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6303 - accuracy: 0.7479 - val_loss: 0.7763 - val_accuracy: 0.6860\n",
            "Epoch 521/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6453 - accuracy: 0.7509 - val_loss: 0.7589 - val_accuracy: 0.7295\n",
            "Epoch 522/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6206 - accuracy: 0.7678 - val_loss: 0.7738 - val_accuracy: 0.7053\n",
            "Epoch 523/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6322 - accuracy: 0.7594 - val_loss: 0.7680 - val_accuracy: 0.7246\n",
            "Epoch 524/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6192 - accuracy: 0.7612 - val_loss: 0.7651 - val_accuracy: 0.7101\n",
            "Epoch 525/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6205 - accuracy: 0.7594 - val_loss: 0.7674 - val_accuracy: 0.7053\n",
            "Epoch 526/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6186 - accuracy: 0.7503 - val_loss: 0.7763 - val_accuracy: 0.7150\n",
            "Epoch 527/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6112 - accuracy: 0.7624 - val_loss: 0.7484 - val_accuracy: 0.7101\n",
            "Epoch 528/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6026 - accuracy: 0.7793 - val_loss: 0.7474 - val_accuracy: 0.7246\n",
            "Epoch 529/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6334 - accuracy: 0.7527 - val_loss: 0.7542 - val_accuracy: 0.7005\n",
            "Epoch 530/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6183 - accuracy: 0.7660 - val_loss: 0.7560 - val_accuracy: 0.7101\n",
            "Epoch 531/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5955 - accuracy: 0.7696 - val_loss: 0.7441 - val_accuracy: 0.7198\n",
            "Epoch 532/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6172 - accuracy: 0.7539 - val_loss: 0.7588 - val_accuracy: 0.6957\n",
            "Epoch 533/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6116 - accuracy: 0.7521 - val_loss: 0.7509 - val_accuracy: 0.7246\n",
            "Epoch 534/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6073 - accuracy: 0.7654 - val_loss: 0.7755 - val_accuracy: 0.6763\n",
            "Epoch 535/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6222 - accuracy: 0.7479 - val_loss: 0.7613 - val_accuracy: 0.6812\n",
            "Epoch 536/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6092 - accuracy: 0.7648 - val_loss: 0.7573 - val_accuracy: 0.7101\n",
            "Epoch 537/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6055 - accuracy: 0.7582 - val_loss: 0.7605 - val_accuracy: 0.6812\n",
            "Epoch 538/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6063 - accuracy: 0.7666 - val_loss: 0.7539 - val_accuracy: 0.7053\n",
            "Epoch 539/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6147 - accuracy: 0.7576 - val_loss: 0.7552 - val_accuracy: 0.7246\n",
            "Epoch 540/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6100 - accuracy: 0.7678 - val_loss: 0.7684 - val_accuracy: 0.6957\n",
            "Epoch 541/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6043 - accuracy: 0.7739 - val_loss: 0.7658 - val_accuracy: 0.7005\n",
            "Epoch 542/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5970 - accuracy: 0.7696 - val_loss: 0.7380 - val_accuracy: 0.7391\n",
            "Epoch 543/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6057 - accuracy: 0.7696 - val_loss: 0.7575 - val_accuracy: 0.7198\n",
            "Epoch 544/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6083 - accuracy: 0.7636 - val_loss: 0.7697 - val_accuracy: 0.6812\n",
            "Epoch 545/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6189 - accuracy: 0.7563 - val_loss: 0.7481 - val_accuracy: 0.7150\n",
            "Epoch 546/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.5936 - accuracy: 0.7684 - val_loss: 0.7752 - val_accuracy: 0.6908\n",
            "Epoch 547/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6055 - accuracy: 0.7642 - val_loss: 0.7565 - val_accuracy: 0.7101\n",
            "Epoch 548/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5945 - accuracy: 0.7545 - val_loss: 0.7813 - val_accuracy: 0.6618\n",
            "Epoch 549/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5880 - accuracy: 0.7606 - val_loss: 0.7633 - val_accuracy: 0.6618\n",
            "Epoch 550/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6037 - accuracy: 0.7739 - val_loss: 0.7366 - val_accuracy: 0.7053\n",
            "Epoch 551/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5965 - accuracy: 0.7690 - val_loss: 0.7400 - val_accuracy: 0.6957\n",
            "Epoch 552/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6134 - accuracy: 0.7636 - val_loss: 0.7602 - val_accuracy: 0.6763\n",
            "Epoch 553/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6020 - accuracy: 0.7666 - val_loss: 0.7440 - val_accuracy: 0.7005\n",
            "Epoch 554/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5946 - accuracy: 0.7793 - val_loss: 0.7548 - val_accuracy: 0.7053\n",
            "Epoch 555/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5931 - accuracy: 0.7624 - val_loss: 0.7698 - val_accuracy: 0.6812\n",
            "Epoch 556/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6069 - accuracy: 0.7618 - val_loss: 0.7516 - val_accuracy: 0.7053\n",
            "Epoch 557/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6212 - accuracy: 0.7527 - val_loss: 0.7593 - val_accuracy: 0.7198\n",
            "Epoch 558/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6013 - accuracy: 0.7618 - val_loss: 0.7588 - val_accuracy: 0.7150\n",
            "Epoch 559/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5869 - accuracy: 0.7666 - val_loss: 0.7555 - val_accuracy: 0.7198\n",
            "Epoch 560/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.5901 - accuracy: 0.7763 - val_loss: 0.7534 - val_accuracy: 0.7198\n",
            "Epoch 561/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6001 - accuracy: 0.7624 - val_loss: 0.7442 - val_accuracy: 0.7295\n",
            "Epoch 562/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6203 - accuracy: 0.7570 - val_loss: 0.7440 - val_accuracy: 0.7150\n",
            "Epoch 563/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5849 - accuracy: 0.7703 - val_loss: 0.7494 - val_accuracy: 0.7053\n",
            "Epoch 564/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.5696 - accuracy: 0.7781 - val_loss: 0.7394 - val_accuracy: 0.7150\n",
            "Epoch 565/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5767 - accuracy: 0.7830 - val_loss: 0.7286 - val_accuracy: 0.7391\n",
            "Epoch 566/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5909 - accuracy: 0.7739 - val_loss: 0.7274 - val_accuracy: 0.7246\n",
            "Epoch 567/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5755 - accuracy: 0.7842 - val_loss: 0.7268 - val_accuracy: 0.7343\n",
            "Epoch 568/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.5731 - accuracy: 0.7848 - val_loss: 0.7491 - val_accuracy: 0.6957\n",
            "Epoch 569/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.5881 - accuracy: 0.7830 - val_loss: 0.7445 - val_accuracy: 0.7101\n",
            "Epoch 570/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.5572 - accuracy: 0.7890 - val_loss: 0.7503 - val_accuracy: 0.6957\n",
            "Epoch 571/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5801 - accuracy: 0.7690 - val_loss: 0.7405 - val_accuracy: 0.7295\n",
            "Epoch 572/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5626 - accuracy: 0.7805 - val_loss: 0.7529 - val_accuracy: 0.7053\n",
            "Epoch 573/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5814 - accuracy: 0.7751 - val_loss: 0.7473 - val_accuracy: 0.7150\n",
            "Epoch 574/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5898 - accuracy: 0.7582 - val_loss: 0.7380 - val_accuracy: 0.7005\n",
            "Epoch 575/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5678 - accuracy: 0.7866 - val_loss: 0.7383 - val_accuracy: 0.7150\n",
            "Epoch 576/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5749 - accuracy: 0.7757 - val_loss: 0.7563 - val_accuracy: 0.6812\n",
            "Epoch 577/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5758 - accuracy: 0.7733 - val_loss: 0.7563 - val_accuracy: 0.7005\n",
            "Epoch 578/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5527 - accuracy: 0.7805 - val_loss: 0.7396 - val_accuracy: 0.7246\n",
            "Epoch 579/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5972 - accuracy: 0.7636 - val_loss: 0.7449 - val_accuracy: 0.7150\n",
            "Epoch 580/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5571 - accuracy: 0.7817 - val_loss: 0.7402 - val_accuracy: 0.7053\n",
            "Epoch 581/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5689 - accuracy: 0.7823 - val_loss: 0.7329 - val_accuracy: 0.7053\n",
            "Epoch 582/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5774 - accuracy: 0.7606 - val_loss: 0.7411 - val_accuracy: 0.7101\n",
            "Epoch 583/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5601 - accuracy: 0.7823 - val_loss: 0.7401 - val_accuracy: 0.7101\n",
            "Epoch 584/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5557 - accuracy: 0.7860 - val_loss: 0.7445 - val_accuracy: 0.7198\n",
            "Epoch 585/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.5690 - accuracy: 0.7860 - val_loss: 0.7421 - val_accuracy: 0.7101\n",
            "Epoch 586/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5491 - accuracy: 0.7938 - val_loss: 0.7589 - val_accuracy: 0.7053\n",
            "Epoch 587/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5910 - accuracy: 0.7721 - val_loss: 0.7398 - val_accuracy: 0.7053\n",
            "Epoch 588/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.5541 - accuracy: 0.7872 - val_loss: 0.7416 - val_accuracy: 0.7295\n",
            "Epoch 589/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.5448 - accuracy: 0.7908 - val_loss: 0.7416 - val_accuracy: 0.7246\n",
            "Epoch 590/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5457 - accuracy: 0.7999 - val_loss: 0.7419 - val_accuracy: 0.6908\n",
            "Epoch 591/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5431 - accuracy: 0.7975 - val_loss: 0.7561 - val_accuracy: 0.6715\n",
            "Epoch 592/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5771 - accuracy: 0.7660 - val_loss: 0.7358 - val_accuracy: 0.7053\n",
            "Epoch 593/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5597 - accuracy: 0.7884 - val_loss: 0.7275 - val_accuracy: 0.7295\n",
            "Epoch 594/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5729 - accuracy: 0.7793 - val_loss: 0.7393 - val_accuracy: 0.7295\n",
            "Epoch 595/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5624 - accuracy: 0.7932 - val_loss: 0.7489 - val_accuracy: 0.6715\n",
            "Epoch 596/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5634 - accuracy: 0.7975 - val_loss: 0.7326 - val_accuracy: 0.7150\n",
            "Epoch 597/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5363 - accuracy: 0.7848 - val_loss: 0.7322 - val_accuracy: 0.7005\n",
            "Epoch 598/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5454 - accuracy: 0.7842 - val_loss: 0.7229 - val_accuracy: 0.7440\n",
            "Epoch 599/1000\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.5442 - accuracy: 0.7890 - val_loss: 0.7360 - val_accuracy: 0.6715\n",
            "Epoch 600/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5571 - accuracy: 0.7866 - val_loss: 0.7134 - val_accuracy: 0.7053\n",
            "Epoch 601/1000\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.5528 - accuracy: 0.7709 - val_loss: 0.7135 - val_accuracy: 0.7053\n",
            "Epoch 602/1000\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.5392 - accuracy: 0.7938 - val_loss: 0.7250 - val_accuracy: 0.6860\n",
            "Epoch 603/1000\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.5467 - accuracy: 0.7902 - val_loss: 0.7116 - val_accuracy: 0.7391\n",
            "Epoch 604/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5664 - accuracy: 0.7751 - val_loss: 0.7341 - val_accuracy: 0.7005\n",
            "Epoch 605/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5315 - accuracy: 0.7963 - val_loss: 0.7220 - val_accuracy: 0.6860\n",
            "Epoch 606/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5480 - accuracy: 0.7793 - val_loss: 0.7226 - val_accuracy: 0.7101\n",
            "Epoch 607/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5398 - accuracy: 0.7975 - val_loss: 0.7259 - val_accuracy: 0.7101\n",
            "Epoch 608/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5455 - accuracy: 0.7963 - val_loss: 0.7290 - val_accuracy: 0.7005\n",
            "Epoch 609/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5559 - accuracy: 0.7775 - val_loss: 0.7223 - val_accuracy: 0.7295\n",
            "Epoch 610/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5484 - accuracy: 0.7890 - val_loss: 0.7401 - val_accuracy: 0.6957\n",
            "Epoch 611/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5465 - accuracy: 0.7896 - val_loss: 0.7387 - val_accuracy: 0.6763\n",
            "Epoch 612/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5431 - accuracy: 0.7842 - val_loss: 0.7139 - val_accuracy: 0.7246\n",
            "Epoch 613/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5595 - accuracy: 0.7775 - val_loss: 0.7242 - val_accuracy: 0.7198\n",
            "Epoch 614/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5238 - accuracy: 0.8017 - val_loss: 0.7249 - val_accuracy: 0.6860\n",
            "Epoch 615/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5338 - accuracy: 0.7932 - val_loss: 0.7332 - val_accuracy: 0.6860\n",
            "Epoch 616/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.5267 - accuracy: 0.7981 - val_loss: 0.7375 - val_accuracy: 0.6570\n",
            "Epoch 617/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5394 - accuracy: 0.7878 - val_loss: 0.7339 - val_accuracy: 0.7198\n",
            "Epoch 618/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5331 - accuracy: 0.7860 - val_loss: 0.7377 - val_accuracy: 0.6763\n",
            "Epoch 619/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5475 - accuracy: 0.7908 - val_loss: 0.7290 - val_accuracy: 0.7198\n",
            "Epoch 620/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5377 - accuracy: 0.7908 - val_loss: 0.7392 - val_accuracy: 0.7150\n",
            "Epoch 621/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5279 - accuracy: 0.8029 - val_loss: 0.7334 - val_accuracy: 0.7101\n",
            "Epoch 622/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5208 - accuracy: 0.8029 - val_loss: 0.7309 - val_accuracy: 0.6957\n",
            "Epoch 623/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5279 - accuracy: 0.8023 - val_loss: 0.7223 - val_accuracy: 0.7198\n",
            "Epoch 624/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5520 - accuracy: 0.7823 - val_loss: 0.7228 - val_accuracy: 0.7005\n",
            "Epoch 625/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5492 - accuracy: 0.7860 - val_loss: 0.7213 - val_accuracy: 0.7295\n",
            "Epoch 626/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.5391 - accuracy: 0.7866 - val_loss: 0.7380 - val_accuracy: 0.6860\n",
            "Epoch 627/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5377 - accuracy: 0.7715 - val_loss: 0.7250 - val_accuracy: 0.7198\n",
            "Epoch 628/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5123 - accuracy: 0.7956 - val_loss: 0.7381 - val_accuracy: 0.7005\n",
            "Epoch 629/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5157 - accuracy: 0.8005 - val_loss: 0.7133 - val_accuracy: 0.7343\n",
            "Epoch 630/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5176 - accuracy: 0.7993 - val_loss: 0.7358 - val_accuracy: 0.7150\n",
            "Epoch 631/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5317 - accuracy: 0.7963 - val_loss: 0.7314 - val_accuracy: 0.7246\n",
            "Epoch 632/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5166 - accuracy: 0.8035 - val_loss: 0.7346 - val_accuracy: 0.7005\n",
            "Epoch 633/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5330 - accuracy: 0.7872 - val_loss: 0.7155 - val_accuracy: 0.7343\n",
            "Epoch 634/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5195 - accuracy: 0.8029 - val_loss: 0.7157 - val_accuracy: 0.7295\n",
            "Epoch 635/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5175 - accuracy: 0.8041 - val_loss: 0.7356 - val_accuracy: 0.7150\n",
            "Epoch 636/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5052 - accuracy: 0.7987 - val_loss: 0.7190 - val_accuracy: 0.7343\n",
            "Epoch 637/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5304 - accuracy: 0.7926 - val_loss: 0.7181 - val_accuracy: 0.7005\n",
            "Epoch 638/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5029 - accuracy: 0.8065 - val_loss: 0.7112 - val_accuracy: 0.7246\n",
            "Epoch 639/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4991 - accuracy: 0.8065 - val_loss: 0.7096 - val_accuracy: 0.7295\n",
            "Epoch 640/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5109 - accuracy: 0.8071 - val_loss: 0.7158 - val_accuracy: 0.7246\n",
            "Epoch 641/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.5213 - accuracy: 0.7981 - val_loss: 0.7278 - val_accuracy: 0.7150\n",
            "Epoch 642/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5184 - accuracy: 0.7993 - val_loss: 0.7182 - val_accuracy: 0.7101\n",
            "Epoch 643/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5075 - accuracy: 0.8065 - val_loss: 0.7240 - val_accuracy: 0.6957\n",
            "Epoch 644/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4942 - accuracy: 0.8156 - val_loss: 0.7240 - val_accuracy: 0.7053\n",
            "Epoch 645/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5089 - accuracy: 0.8053 - val_loss: 0.7025 - val_accuracy: 0.7536\n",
            "Epoch 646/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5057 - accuracy: 0.8071 - val_loss: 0.7167 - val_accuracy: 0.7343\n",
            "Epoch 647/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4823 - accuracy: 0.8083 - val_loss: 0.7074 - val_accuracy: 0.7198\n",
            "Epoch 648/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4892 - accuracy: 0.8114 - val_loss: 0.7053 - val_accuracy: 0.7295\n",
            "Epoch 649/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5280 - accuracy: 0.7963 - val_loss: 0.7087 - val_accuracy: 0.7391\n",
            "Epoch 650/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5128 - accuracy: 0.8071 - val_loss: 0.7150 - val_accuracy: 0.7391\n",
            "Epoch 651/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5072 - accuracy: 0.7999 - val_loss: 0.7177 - val_accuracy: 0.7150\n",
            "Epoch 652/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5206 - accuracy: 0.7938 - val_loss: 0.7202 - val_accuracy: 0.7150\n",
            "Epoch 653/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4946 - accuracy: 0.8041 - val_loss: 0.7180 - val_accuracy: 0.7101\n",
            "Epoch 654/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4987 - accuracy: 0.8120 - val_loss: 0.7288 - val_accuracy: 0.7005\n",
            "Epoch 655/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5238 - accuracy: 0.8059 - val_loss: 0.7237 - val_accuracy: 0.7295\n",
            "Epoch 656/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5091 - accuracy: 0.7938 - val_loss: 0.7148 - val_accuracy: 0.7198\n",
            "Epoch 657/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5192 - accuracy: 0.8089 - val_loss: 0.7143 - val_accuracy: 0.7198\n",
            "Epoch 658/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5124 - accuracy: 0.8053 - val_loss: 0.7109 - val_accuracy: 0.7101\n",
            "Epoch 659/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5041 - accuracy: 0.7999 - val_loss: 0.7253 - val_accuracy: 0.6908\n",
            "Epoch 660/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4899 - accuracy: 0.8156 - val_loss: 0.7132 - val_accuracy: 0.7150\n",
            "Epoch 661/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4866 - accuracy: 0.8108 - val_loss: 0.7077 - val_accuracy: 0.7150\n",
            "Epoch 662/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4918 - accuracy: 0.8065 - val_loss: 0.7334 - val_accuracy: 0.6715\n",
            "Epoch 663/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4916 - accuracy: 0.8120 - val_loss: 0.7109 - val_accuracy: 0.7150\n",
            "Epoch 664/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5071 - accuracy: 0.8041 - val_loss: 0.7065 - val_accuracy: 0.7246\n",
            "Epoch 665/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5033 - accuracy: 0.8114 - val_loss: 0.7272 - val_accuracy: 0.6957\n",
            "Epoch 666/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5216 - accuracy: 0.7993 - val_loss: 0.7034 - val_accuracy: 0.7101\n",
            "Epoch 667/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4952 - accuracy: 0.8229 - val_loss: 0.7225 - val_accuracy: 0.7198\n",
            "Epoch 668/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4770 - accuracy: 0.8180 - val_loss: 0.7042 - val_accuracy: 0.7343\n",
            "Epoch 669/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4778 - accuracy: 0.8144 - val_loss: 0.7149 - val_accuracy: 0.7005\n",
            "Epoch 670/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4721 - accuracy: 0.8168 - val_loss: 0.7101 - val_accuracy: 0.7198\n",
            "Epoch 671/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5148 - accuracy: 0.7914 - val_loss: 0.7158 - val_accuracy: 0.7150\n",
            "Epoch 672/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4794 - accuracy: 0.8174 - val_loss: 0.7230 - val_accuracy: 0.7101\n",
            "Epoch 673/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.4838 - accuracy: 0.8180 - val_loss: 0.7120 - val_accuracy: 0.7053\n",
            "Epoch 674/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4893 - accuracy: 0.8089 - val_loss: 0.7196 - val_accuracy: 0.7295\n",
            "Epoch 675/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4652 - accuracy: 0.8241 - val_loss: 0.7021 - val_accuracy: 0.7343\n",
            "Epoch 676/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4902 - accuracy: 0.8035 - val_loss: 0.7092 - val_accuracy: 0.7150\n",
            "Epoch 677/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5061 - accuracy: 0.7969 - val_loss: 0.7215 - val_accuracy: 0.7246\n",
            "Epoch 678/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.4715 - accuracy: 0.8180 - val_loss: 0.7111 - val_accuracy: 0.7150\n",
            "Epoch 679/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4799 - accuracy: 0.8216 - val_loss: 0.7313 - val_accuracy: 0.7101\n",
            "Epoch 680/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4852 - accuracy: 0.8168 - val_loss: 0.7173 - val_accuracy: 0.7343\n",
            "Epoch 681/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4947 - accuracy: 0.8247 - val_loss: 0.6983 - val_accuracy: 0.7343\n",
            "Epoch 682/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.4893 - accuracy: 0.8126 - val_loss: 0.6972 - val_accuracy: 0.7343\n",
            "Epoch 683/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4811 - accuracy: 0.8089 - val_loss: 0.7025 - val_accuracy: 0.7150\n",
            "Epoch 684/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4738 - accuracy: 0.8186 - val_loss: 0.7191 - val_accuracy: 0.6860\n",
            "Epoch 685/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4672 - accuracy: 0.8229 - val_loss: 0.7101 - val_accuracy: 0.7295\n",
            "Epoch 686/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4860 - accuracy: 0.8071 - val_loss: 0.7080 - val_accuracy: 0.7295\n",
            "Epoch 687/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4927 - accuracy: 0.8041 - val_loss: 0.7221 - val_accuracy: 0.7198\n",
            "Epoch 688/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4651 - accuracy: 0.8174 - val_loss: 0.7056 - val_accuracy: 0.7295\n",
            "Epoch 689/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.4778 - accuracy: 0.8132 - val_loss: 0.7242 - val_accuracy: 0.7150\n",
            "Epoch 690/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4780 - accuracy: 0.8144 - val_loss: 0.7101 - val_accuracy: 0.7150\n",
            "Epoch 691/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4730 - accuracy: 0.8247 - val_loss: 0.7105 - val_accuracy: 0.7343\n",
            "Epoch 692/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4726 - accuracy: 0.8241 - val_loss: 0.7067 - val_accuracy: 0.7198\n",
            "Epoch 693/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4866 - accuracy: 0.8180 - val_loss: 0.7147 - val_accuracy: 0.7150\n",
            "Epoch 694/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4633 - accuracy: 0.8210 - val_loss: 0.6983 - val_accuracy: 0.7246\n",
            "Epoch 695/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.4730 - accuracy: 0.8210 - val_loss: 0.6999 - val_accuracy: 0.7101\n",
            "Epoch 696/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4668 - accuracy: 0.8102 - val_loss: 0.7042 - val_accuracy: 0.7343\n",
            "Epoch 697/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4607 - accuracy: 0.8235 - val_loss: 0.7024 - val_accuracy: 0.7295\n",
            "Epoch 698/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4699 - accuracy: 0.8096 - val_loss: 0.7073 - val_accuracy: 0.7053\n",
            "Epoch 699/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4781 - accuracy: 0.8168 - val_loss: 0.7219 - val_accuracy: 0.6957\n",
            "Epoch 700/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4843 - accuracy: 0.8222 - val_loss: 0.7232 - val_accuracy: 0.7198\n",
            "Epoch 701/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4676 - accuracy: 0.8216 - val_loss: 0.7226 - val_accuracy: 0.7005\n",
            "Epoch 702/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4742 - accuracy: 0.8186 - val_loss: 0.7162 - val_accuracy: 0.7053\n",
            "Epoch 703/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4640 - accuracy: 0.8289 - val_loss: 0.7272 - val_accuracy: 0.7005\n",
            "Epoch 704/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4527 - accuracy: 0.8265 - val_loss: 0.6950 - val_accuracy: 0.7440\n",
            "Epoch 705/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4617 - accuracy: 0.8162 - val_loss: 0.6917 - val_accuracy: 0.7198\n",
            "Epoch 706/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4464 - accuracy: 0.8271 - val_loss: 0.6966 - val_accuracy: 0.7440\n",
            "Epoch 707/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4746 - accuracy: 0.8216 - val_loss: 0.6931 - val_accuracy: 0.7295\n",
            "Epoch 708/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4564 - accuracy: 0.8301 - val_loss: 0.6914 - val_accuracy: 0.7536\n",
            "Epoch 709/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4462 - accuracy: 0.8229 - val_loss: 0.7069 - val_accuracy: 0.7488\n",
            "Epoch 710/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4608 - accuracy: 0.8247 - val_loss: 0.7050 - val_accuracy: 0.7343\n",
            "Epoch 711/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4534 - accuracy: 0.8168 - val_loss: 0.7157 - val_accuracy: 0.7053\n",
            "Epoch 712/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4518 - accuracy: 0.8343 - val_loss: 0.6802 - val_accuracy: 0.7343\n",
            "Epoch 713/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4508 - accuracy: 0.8265 - val_loss: 0.6850 - val_accuracy: 0.7440\n",
            "Epoch 714/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4475 - accuracy: 0.8229 - val_loss: 0.6944 - val_accuracy: 0.7391\n",
            "Epoch 715/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4322 - accuracy: 0.8337 - val_loss: 0.6854 - val_accuracy: 0.7295\n",
            "Epoch 716/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4440 - accuracy: 0.8386 - val_loss: 0.6794 - val_accuracy: 0.7440\n",
            "Epoch 717/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4640 - accuracy: 0.8222 - val_loss: 0.6932 - val_accuracy: 0.7246\n",
            "Epoch 718/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4602 - accuracy: 0.8156 - val_loss: 0.7078 - val_accuracy: 0.7053\n",
            "Epoch 719/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4649 - accuracy: 0.8204 - val_loss: 0.6978 - val_accuracy: 0.7246\n",
            "Epoch 720/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4421 - accuracy: 0.8307 - val_loss: 0.6774 - val_accuracy: 0.7440\n",
            "Epoch 721/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4296 - accuracy: 0.8331 - val_loss: 0.6923 - val_accuracy: 0.7198\n",
            "Epoch 722/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4536 - accuracy: 0.8271 - val_loss: 0.6920 - val_accuracy: 0.7488\n",
            "Epoch 723/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.4575 - accuracy: 0.8192 - val_loss: 0.6803 - val_accuracy: 0.7488\n",
            "Epoch 724/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4443 - accuracy: 0.8392 - val_loss: 0.7266 - val_accuracy: 0.6715\n",
            "Epoch 725/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4550 - accuracy: 0.8319 - val_loss: 0.6895 - val_accuracy: 0.7633\n",
            "Epoch 726/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4394 - accuracy: 0.8319 - val_loss: 0.6957 - val_accuracy: 0.7343\n",
            "Epoch 727/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.4474 - accuracy: 0.8319 - val_loss: 0.6968 - val_accuracy: 0.7198\n",
            "Epoch 728/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4536 - accuracy: 0.8362 - val_loss: 0.6767 - val_accuracy: 0.7295\n",
            "Epoch 729/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.4537 - accuracy: 0.8186 - val_loss: 0.6795 - val_accuracy: 0.7295\n",
            "Epoch 730/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4390 - accuracy: 0.8374 - val_loss: 0.6917 - val_accuracy: 0.7295\n",
            "Epoch 731/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4577 - accuracy: 0.8174 - val_loss: 0.6972 - val_accuracy: 0.7246\n",
            "Epoch 732/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4471 - accuracy: 0.8235 - val_loss: 0.7028 - val_accuracy: 0.7295\n",
            "Epoch 733/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4471 - accuracy: 0.8319 - val_loss: 0.6905 - val_accuracy: 0.7391\n",
            "Epoch 734/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.4472 - accuracy: 0.8301 - val_loss: 0.6938 - val_accuracy: 0.7246\n",
            "Epoch 735/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4178 - accuracy: 0.8416 - val_loss: 0.6855 - val_accuracy: 0.7343\n",
            "Epoch 736/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4417 - accuracy: 0.8362 - val_loss: 0.6906 - val_accuracy: 0.7295\n",
            "Epoch 737/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4530 - accuracy: 0.8210 - val_loss: 0.6882 - val_accuracy: 0.7295\n",
            "Epoch 738/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4373 - accuracy: 0.8319 - val_loss: 0.6723 - val_accuracy: 0.7440\n",
            "Epoch 739/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4351 - accuracy: 0.8380 - val_loss: 0.6755 - val_accuracy: 0.7391\n",
            "Epoch 740/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4360 - accuracy: 0.8241 - val_loss: 0.6798 - val_accuracy: 0.7391\n",
            "Epoch 741/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4403 - accuracy: 0.8295 - val_loss: 0.6810 - val_accuracy: 0.7295\n",
            "Epoch 742/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4683 - accuracy: 0.8210 - val_loss: 0.6970 - val_accuracy: 0.7246\n",
            "Epoch 743/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.4377 - accuracy: 0.8331 - val_loss: 0.6821 - val_accuracy: 0.7391\n",
            "Epoch 744/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4288 - accuracy: 0.8452 - val_loss: 0.6941 - val_accuracy: 0.7343\n",
            "Epoch 745/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.4225 - accuracy: 0.8446 - val_loss: 0.6720 - val_accuracy: 0.7440\n",
            "Epoch 746/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4315 - accuracy: 0.8295 - val_loss: 0.6830 - val_accuracy: 0.7440\n",
            "Epoch 747/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4399 - accuracy: 0.8283 - val_loss: 0.6688 - val_accuracy: 0.7488\n",
            "Epoch 748/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4174 - accuracy: 0.8482 - val_loss: 0.6571 - val_accuracy: 0.7440\n",
            "Epoch 749/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4280 - accuracy: 0.8362 - val_loss: 0.6816 - val_accuracy: 0.7295\n",
            "Epoch 750/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4278 - accuracy: 0.8386 - val_loss: 0.6776 - val_accuracy: 0.7246\n",
            "Epoch 751/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4369 - accuracy: 0.8404 - val_loss: 0.6957 - val_accuracy: 0.7198\n",
            "Epoch 752/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4235 - accuracy: 0.8368 - val_loss: 0.6899 - val_accuracy: 0.7440\n",
            "Epoch 753/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.4055 - accuracy: 0.8537 - val_loss: 0.6796 - val_accuracy: 0.7391\n",
            "Epoch 754/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4297 - accuracy: 0.8362 - val_loss: 0.6865 - val_accuracy: 0.7391\n",
            "Epoch 755/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4301 - accuracy: 0.8368 - val_loss: 0.6721 - val_accuracy: 0.7585\n",
            "Epoch 756/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4306 - accuracy: 0.8380 - val_loss: 0.6786 - val_accuracy: 0.7585\n",
            "Epoch 757/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4386 - accuracy: 0.8343 - val_loss: 0.6761 - val_accuracy: 0.7295\n",
            "Epoch 758/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4352 - accuracy: 0.8289 - val_loss: 0.6990 - val_accuracy: 0.7150\n",
            "Epoch 759/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4256 - accuracy: 0.8325 - val_loss: 0.6932 - val_accuracy: 0.7295\n",
            "Epoch 760/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4319 - accuracy: 0.8434 - val_loss: 0.6773 - val_accuracy: 0.7440\n",
            "Epoch 761/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4211 - accuracy: 0.8416 - val_loss: 0.6804 - val_accuracy: 0.7488\n",
            "Epoch 762/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4180 - accuracy: 0.8386 - val_loss: 0.6851 - val_accuracy: 0.7295\n",
            "Epoch 763/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4179 - accuracy: 0.8440 - val_loss: 0.6958 - val_accuracy: 0.7150\n",
            "Epoch 764/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4366 - accuracy: 0.8362 - val_loss: 0.6792 - val_accuracy: 0.7295\n",
            "Epoch 765/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4103 - accuracy: 0.8428 - val_loss: 0.6755 - val_accuracy: 0.7343\n",
            "Epoch 766/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4210 - accuracy: 0.8362 - val_loss: 0.6701 - val_accuracy: 0.7536\n",
            "Epoch 767/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4322 - accuracy: 0.8374 - val_loss: 0.6983 - val_accuracy: 0.7198\n",
            "Epoch 768/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4080 - accuracy: 0.8464 - val_loss: 0.6861 - val_accuracy: 0.7343\n",
            "Epoch 769/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4217 - accuracy: 0.8428 - val_loss: 0.6822 - val_accuracy: 0.7246\n",
            "Epoch 770/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.4329 - accuracy: 0.8416 - val_loss: 0.6712 - val_accuracy: 0.7391\n",
            "Epoch 771/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4209 - accuracy: 0.8307 - val_loss: 0.6671 - val_accuracy: 0.7343\n",
            "Epoch 772/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4111 - accuracy: 0.8440 - val_loss: 0.6725 - val_accuracy: 0.7295\n",
            "Epoch 773/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4030 - accuracy: 0.8531 - val_loss: 0.6830 - val_accuracy: 0.7440\n",
            "Epoch 774/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4007 - accuracy: 0.8507 - val_loss: 0.6817 - val_accuracy: 0.7391\n",
            "Epoch 775/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4301 - accuracy: 0.8458 - val_loss: 0.6835 - val_accuracy: 0.7488\n",
            "Epoch 776/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4166 - accuracy: 0.8307 - val_loss: 0.6771 - val_accuracy: 0.7343\n",
            "Epoch 777/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4099 - accuracy: 0.8434 - val_loss: 0.6799 - val_accuracy: 0.7440\n",
            "Epoch 778/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4145 - accuracy: 0.8416 - val_loss: 0.6722 - val_accuracy: 0.7391\n",
            "Epoch 779/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3936 - accuracy: 0.8422 - val_loss: 0.6701 - val_accuracy: 0.7246\n",
            "Epoch 780/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.4126 - accuracy: 0.8410 - val_loss: 0.6707 - val_accuracy: 0.7440\n",
            "Epoch 781/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.4215 - accuracy: 0.8416 - val_loss: 0.6575 - val_accuracy: 0.7681\n",
            "Epoch 782/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3970 - accuracy: 0.8470 - val_loss: 0.6850 - val_accuracy: 0.7391\n",
            "Epoch 783/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3956 - accuracy: 0.8410 - val_loss: 0.6853 - val_accuracy: 0.7585\n",
            "Epoch 784/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3960 - accuracy: 0.8609 - val_loss: 0.6847 - val_accuracy: 0.7295\n",
            "Epoch 785/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4131 - accuracy: 0.8482 - val_loss: 0.6680 - val_accuracy: 0.7295\n",
            "Epoch 786/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4040 - accuracy: 0.8440 - val_loss: 0.6833 - val_accuracy: 0.7295\n",
            "Epoch 787/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4142 - accuracy: 0.8325 - val_loss: 0.6691 - val_accuracy: 0.7295\n",
            "Epoch 788/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4086 - accuracy: 0.8446 - val_loss: 0.6744 - val_accuracy: 0.7246\n",
            "Epoch 789/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3852 - accuracy: 0.8603 - val_loss: 0.6642 - val_accuracy: 0.7585\n",
            "Epoch 790/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3863 - accuracy: 0.8670 - val_loss: 0.6600 - val_accuracy: 0.7633\n",
            "Epoch 791/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3707 - accuracy: 0.8591 - val_loss: 0.6832 - val_accuracy: 0.7295\n",
            "Epoch 792/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4110 - accuracy: 0.8392 - val_loss: 0.6715 - val_accuracy: 0.7198\n",
            "Epoch 793/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4041 - accuracy: 0.8525 - val_loss: 0.6682 - val_accuracy: 0.7536\n",
            "Epoch 794/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4031 - accuracy: 0.8416 - val_loss: 0.6759 - val_accuracy: 0.7488\n",
            "Epoch 795/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3939 - accuracy: 0.8513 - val_loss: 0.6928 - val_accuracy: 0.7343\n",
            "Epoch 796/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3978 - accuracy: 0.8543 - val_loss: 0.6680 - val_accuracy: 0.7536\n",
            "Epoch 797/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3822 - accuracy: 0.8513 - val_loss: 0.6749 - val_accuracy: 0.7488\n",
            "Epoch 798/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.3800 - accuracy: 0.8573 - val_loss: 0.7016 - val_accuracy: 0.7101\n",
            "Epoch 799/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3834 - accuracy: 0.8525 - val_loss: 0.6786 - val_accuracy: 0.7246\n",
            "Epoch 800/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3858 - accuracy: 0.8513 - val_loss: 0.6598 - val_accuracy: 0.7488\n",
            "Epoch 801/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3821 - accuracy: 0.8597 - val_loss: 0.6619 - val_accuracy: 0.7729\n",
            "Epoch 802/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3927 - accuracy: 0.8458 - val_loss: 0.6616 - val_accuracy: 0.7536\n",
            "Epoch 803/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3945 - accuracy: 0.8543 - val_loss: 0.6731 - val_accuracy: 0.7295\n",
            "Epoch 804/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3962 - accuracy: 0.8428 - val_loss: 0.6598 - val_accuracy: 0.7633\n",
            "Epoch 805/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3896 - accuracy: 0.8428 - val_loss: 0.6783 - val_accuracy: 0.7343\n",
            "Epoch 806/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3897 - accuracy: 0.8531 - val_loss: 0.6692 - val_accuracy: 0.7585\n",
            "Epoch 807/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3734 - accuracy: 0.8646 - val_loss: 0.6744 - val_accuracy: 0.7391\n",
            "Epoch 808/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3777 - accuracy: 0.8609 - val_loss: 0.6802 - val_accuracy: 0.7295\n",
            "Epoch 809/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3820 - accuracy: 0.8609 - val_loss: 0.6859 - val_accuracy: 0.7295\n",
            "Epoch 810/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3842 - accuracy: 0.8597 - val_loss: 0.6814 - val_accuracy: 0.7295\n",
            "Epoch 811/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3880 - accuracy: 0.8658 - val_loss: 0.6895 - val_accuracy: 0.7198\n",
            "Epoch 812/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3780 - accuracy: 0.8591 - val_loss: 0.6752 - val_accuracy: 0.7391\n",
            "Epoch 813/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.3914 - accuracy: 0.8519 - val_loss: 0.6689 - val_accuracy: 0.7536\n",
            "Epoch 814/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.3808 - accuracy: 0.8458 - val_loss: 0.6852 - val_accuracy: 0.7150\n",
            "Epoch 815/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3937 - accuracy: 0.8537 - val_loss: 0.6726 - val_accuracy: 0.7295\n",
            "Epoch 816/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3796 - accuracy: 0.8525 - val_loss: 0.6710 - val_accuracy: 0.7585\n",
            "Epoch 817/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3938 - accuracy: 0.8549 - val_loss: 0.6850 - val_accuracy: 0.7585\n",
            "Epoch 818/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3744 - accuracy: 0.8597 - val_loss: 0.6830 - val_accuracy: 0.7440\n",
            "Epoch 819/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3647 - accuracy: 0.8694 - val_loss: 0.6769 - val_accuracy: 0.7536\n",
            "Epoch 820/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3687 - accuracy: 0.8622 - val_loss: 0.6700 - val_accuracy: 0.7536\n",
            "Epoch 821/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3846 - accuracy: 0.8555 - val_loss: 0.6671 - val_accuracy: 0.7440\n",
            "Epoch 822/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4004 - accuracy: 0.8543 - val_loss: 0.6698 - val_accuracy: 0.7343\n",
            "Epoch 823/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3785 - accuracy: 0.8724 - val_loss: 0.6701 - val_accuracy: 0.7440\n",
            "Epoch 824/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3851 - accuracy: 0.8591 - val_loss: 0.6894 - val_accuracy: 0.7246\n",
            "Epoch 825/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3785 - accuracy: 0.8597 - val_loss: 0.6765 - val_accuracy: 0.7536\n",
            "Epoch 826/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3775 - accuracy: 0.8561 - val_loss: 0.6704 - val_accuracy: 0.7440\n",
            "Epoch 827/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3805 - accuracy: 0.8513 - val_loss: 0.6728 - val_accuracy: 0.7585\n",
            "Epoch 828/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3598 - accuracy: 0.8670 - val_loss: 0.6673 - val_accuracy: 0.7440\n",
            "Epoch 829/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3878 - accuracy: 0.8591 - val_loss: 0.6860 - val_accuracy: 0.7198\n",
            "Epoch 830/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3701 - accuracy: 0.8573 - val_loss: 0.6847 - val_accuracy: 0.7343\n",
            "Epoch 831/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.3737 - accuracy: 0.8603 - val_loss: 0.6757 - val_accuracy: 0.7295\n",
            "Epoch 832/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.3810 - accuracy: 0.8531 - val_loss: 0.6535 - val_accuracy: 0.7633\n",
            "Epoch 833/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3554 - accuracy: 0.8664 - val_loss: 0.6429 - val_accuracy: 0.7585\n",
            "Epoch 834/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3720 - accuracy: 0.8628 - val_loss: 0.6699 - val_accuracy: 0.7488\n",
            "Epoch 835/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.3669 - accuracy: 0.8513 - val_loss: 0.6620 - val_accuracy: 0.7536\n",
            "Epoch 836/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3723 - accuracy: 0.8652 - val_loss: 0.6583 - val_accuracy: 0.7343\n",
            "Epoch 837/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3631 - accuracy: 0.8688 - val_loss: 0.6619 - val_accuracy: 0.7343\n",
            "Epoch 838/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.3629 - accuracy: 0.8628 - val_loss: 0.6712 - val_accuracy: 0.7391\n",
            "Epoch 839/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3624 - accuracy: 0.8573 - val_loss: 0.6648 - val_accuracy: 0.7440\n",
            "Epoch 840/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3490 - accuracy: 0.8815 - val_loss: 0.6619 - val_accuracy: 0.7681\n",
            "Epoch 841/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3505 - accuracy: 0.8694 - val_loss: 0.6646 - val_accuracy: 0.7536\n",
            "Epoch 842/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.3737 - accuracy: 0.8646 - val_loss: 0.6792 - val_accuracy: 0.7343\n",
            "Epoch 843/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3720 - accuracy: 0.8603 - val_loss: 0.6649 - val_accuracy: 0.7488\n",
            "Epoch 844/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3297 - accuracy: 0.8748 - val_loss: 0.6577 - val_accuracy: 0.7440\n",
            "Epoch 845/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3386 - accuracy: 0.8712 - val_loss: 0.6420 - val_accuracy: 0.7778\n",
            "Epoch 846/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3546 - accuracy: 0.8676 - val_loss: 0.6685 - val_accuracy: 0.7536\n",
            "Epoch 847/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3632 - accuracy: 0.8622 - val_loss: 0.6668 - val_accuracy: 0.7440\n",
            "Epoch 848/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3618 - accuracy: 0.8634 - val_loss: 0.6739 - val_accuracy: 0.7681\n",
            "Epoch 849/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3691 - accuracy: 0.8585 - val_loss: 0.6754 - val_accuracy: 0.7440\n",
            "Epoch 850/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3401 - accuracy: 0.8652 - val_loss: 0.6870 - val_accuracy: 0.7246\n",
            "Epoch 851/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3747 - accuracy: 0.8531 - val_loss: 0.6984 - val_accuracy: 0.7295\n",
            "Epoch 852/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3555 - accuracy: 0.8513 - val_loss: 0.6603 - val_accuracy: 0.7440\n",
            "Epoch 853/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.3526 - accuracy: 0.8670 - val_loss: 0.6540 - val_accuracy: 0.7488\n",
            "Epoch 854/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3706 - accuracy: 0.8700 - val_loss: 0.6646 - val_accuracy: 0.7343\n",
            "Epoch 855/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3640 - accuracy: 0.8640 - val_loss: 0.6737 - val_accuracy: 0.7633\n",
            "Epoch 856/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3600 - accuracy: 0.8597 - val_loss: 0.6609 - val_accuracy: 0.7391\n",
            "Epoch 857/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3559 - accuracy: 0.8622 - val_loss: 0.6769 - val_accuracy: 0.7295\n",
            "Epoch 858/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3661 - accuracy: 0.8622 - val_loss: 0.6778 - val_accuracy: 0.7246\n",
            "Epoch 859/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.3746 - accuracy: 0.8519 - val_loss: 0.6710 - val_accuracy: 0.7343\n",
            "Epoch 860/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3436 - accuracy: 0.8748 - val_loss: 0.6773 - val_accuracy: 0.7488\n",
            "Epoch 861/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3554 - accuracy: 0.8688 - val_loss: 0.6562 - val_accuracy: 0.7488\n",
            "Epoch 862/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3510 - accuracy: 0.8652 - val_loss: 0.6787 - val_accuracy: 0.7101\n",
            "Epoch 863/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3402 - accuracy: 0.8706 - val_loss: 0.6757 - val_accuracy: 0.7391\n",
            "Epoch 864/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3547 - accuracy: 0.8712 - val_loss: 0.6680 - val_accuracy: 0.7295\n",
            "Epoch 865/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3514 - accuracy: 0.8628 - val_loss: 0.6836 - val_accuracy: 0.7488\n",
            "Epoch 866/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.3693 - accuracy: 0.8519 - val_loss: 0.6642 - val_accuracy: 0.7391\n",
            "Epoch 867/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3484 - accuracy: 0.8646 - val_loss: 0.6746 - val_accuracy: 0.7295\n",
            "Epoch 868/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3313 - accuracy: 0.8797 - val_loss: 0.6737 - val_accuracy: 0.7488\n",
            "Epoch 869/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3359 - accuracy: 0.8694 - val_loss: 0.6603 - val_accuracy: 0.7343\n",
            "Epoch 870/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3372 - accuracy: 0.8748 - val_loss: 0.6633 - val_accuracy: 0.7391\n",
            "Epoch 871/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3718 - accuracy: 0.8531 - val_loss: 0.6642 - val_accuracy: 0.7536\n",
            "Epoch 872/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3444 - accuracy: 0.8779 - val_loss: 0.6536 - val_accuracy: 0.7536\n",
            "Epoch 873/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.3436 - accuracy: 0.8761 - val_loss: 0.6616 - val_accuracy: 0.7488\n",
            "Epoch 874/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3296 - accuracy: 0.8809 - val_loss: 0.6591 - val_accuracy: 0.7488\n",
            "Epoch 875/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3571 - accuracy: 0.8628 - val_loss: 0.6641 - val_accuracy: 0.7585\n",
            "Epoch 876/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3331 - accuracy: 0.8742 - val_loss: 0.6866 - val_accuracy: 0.7295\n",
            "Epoch 877/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.3425 - accuracy: 0.8670 - val_loss: 0.6776 - val_accuracy: 0.7295\n",
            "Epoch 878/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3480 - accuracy: 0.8603 - val_loss: 0.7072 - val_accuracy: 0.7536\n",
            "Epoch 879/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3331 - accuracy: 0.8736 - val_loss: 0.6698 - val_accuracy: 0.7681\n",
            "Epoch 880/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.3337 - accuracy: 0.8767 - val_loss: 0.6847 - val_accuracy: 0.7246\n",
            "Epoch 881/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3424 - accuracy: 0.8748 - val_loss: 0.6753 - val_accuracy: 0.7198\n",
            "Epoch 882/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3475 - accuracy: 0.8682 - val_loss: 0.6588 - val_accuracy: 0.7391\n",
            "Epoch 883/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3374 - accuracy: 0.8767 - val_loss: 0.6764 - val_accuracy: 0.7536\n",
            "Epoch 884/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3334 - accuracy: 0.8779 - val_loss: 0.6428 - val_accuracy: 0.7681\n",
            "Epoch 885/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3353 - accuracy: 0.8736 - val_loss: 0.6567 - val_accuracy: 0.7488\n",
            "Epoch 886/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3427 - accuracy: 0.8700 - val_loss: 0.6733 - val_accuracy: 0.7536\n",
            "Epoch 887/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3425 - accuracy: 0.8706 - val_loss: 0.6675 - val_accuracy: 0.7536\n",
            "Epoch 888/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3401 - accuracy: 0.8694 - val_loss: 0.6727 - val_accuracy: 0.7391\n",
            "Epoch 889/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3321 - accuracy: 0.8700 - val_loss: 0.6605 - val_accuracy: 0.7536\n",
            "Epoch 890/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3291 - accuracy: 0.8724 - val_loss: 0.6599 - val_accuracy: 0.7440\n",
            "Epoch 891/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3249 - accuracy: 0.8773 - val_loss: 0.6703 - val_accuracy: 0.7246\n",
            "Epoch 892/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3270 - accuracy: 0.8809 - val_loss: 0.6571 - val_accuracy: 0.7391\n",
            "Epoch 893/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3247 - accuracy: 0.8767 - val_loss: 0.6620 - val_accuracy: 0.7681\n",
            "Epoch 894/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3212 - accuracy: 0.8712 - val_loss: 0.6578 - val_accuracy: 0.7488\n",
            "Epoch 895/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3499 - accuracy: 0.8706 - val_loss: 0.6633 - val_accuracy: 0.7440\n",
            "Epoch 896/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3325 - accuracy: 0.8785 - val_loss: 0.6641 - val_accuracy: 0.7488\n",
            "Epoch 897/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3214 - accuracy: 0.8821 - val_loss: 0.6377 - val_accuracy: 0.7826\n",
            "Epoch 898/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3483 - accuracy: 0.8694 - val_loss: 0.6720 - val_accuracy: 0.7536\n",
            "Epoch 899/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3206 - accuracy: 0.8785 - val_loss: 0.6788 - val_accuracy: 0.7536\n",
            "Epoch 900/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3231 - accuracy: 0.8767 - val_loss: 0.6725 - val_accuracy: 0.7585\n",
            "Epoch 901/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3364 - accuracy: 0.8706 - val_loss: 0.6674 - val_accuracy: 0.7536\n",
            "Epoch 902/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.3398 - accuracy: 0.8682 - val_loss: 0.6751 - val_accuracy: 0.7536\n",
            "Epoch 903/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3146 - accuracy: 0.8875 - val_loss: 0.6777 - val_accuracy: 0.7440\n",
            "Epoch 904/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.3153 - accuracy: 0.8845 - val_loss: 0.6656 - val_accuracy: 0.7488\n",
            "Epoch 905/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3118 - accuracy: 0.8894 - val_loss: 0.6719 - val_accuracy: 0.7391\n",
            "Epoch 906/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3185 - accuracy: 0.8791 - val_loss: 0.6574 - val_accuracy: 0.7488\n",
            "Epoch 907/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3312 - accuracy: 0.8694 - val_loss: 0.6811 - val_accuracy: 0.7295\n",
            "Epoch 908/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3448 - accuracy: 0.8730 - val_loss: 0.6578 - val_accuracy: 0.7874\n",
            "Epoch 909/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3276 - accuracy: 0.8694 - val_loss: 0.6513 - val_accuracy: 0.7536\n",
            "Epoch 910/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3034 - accuracy: 0.8918 - val_loss: 0.6499 - val_accuracy: 0.7585\n",
            "Epoch 911/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3326 - accuracy: 0.8761 - val_loss: 0.6790 - val_accuracy: 0.7343\n",
            "Epoch 912/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3089 - accuracy: 0.8984 - val_loss: 0.6680 - val_accuracy: 0.7488\n",
            "Epoch 913/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3142 - accuracy: 0.8827 - val_loss: 0.6670 - val_accuracy: 0.7391\n",
            "Epoch 914/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3325 - accuracy: 0.8712 - val_loss: 0.6423 - val_accuracy: 0.7536\n",
            "Epoch 915/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3256 - accuracy: 0.8767 - val_loss: 0.6612 - val_accuracy: 0.7295\n",
            "Epoch 916/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3357 - accuracy: 0.8785 - val_loss: 0.6570 - val_accuracy: 0.7536\n",
            "Epoch 917/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3323 - accuracy: 0.8724 - val_loss: 0.6534 - val_accuracy: 0.7585\n",
            "Epoch 918/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3154 - accuracy: 0.8815 - val_loss: 0.6534 - val_accuracy: 0.7440\n",
            "Epoch 919/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3097 - accuracy: 0.8881 - val_loss: 0.6440 - val_accuracy: 0.7633\n",
            "Epoch 920/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2903 - accuracy: 0.8960 - val_loss: 0.6627 - val_accuracy: 0.7488\n",
            "Epoch 921/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2952 - accuracy: 0.8966 - val_loss: 0.6500 - val_accuracy: 0.7633\n",
            "Epoch 922/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3113 - accuracy: 0.8791 - val_loss: 0.6545 - val_accuracy: 0.7585\n",
            "Epoch 923/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2950 - accuracy: 0.8894 - val_loss: 0.6414 - val_accuracy: 0.7536\n",
            "Epoch 924/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3190 - accuracy: 0.8791 - val_loss: 0.6554 - val_accuracy: 0.7585\n",
            "Epoch 925/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3301 - accuracy: 0.8700 - val_loss: 0.6509 - val_accuracy: 0.7729\n",
            "Epoch 926/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3131 - accuracy: 0.8881 - val_loss: 0.6552 - val_accuracy: 0.7633\n",
            "Epoch 927/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.3291 - accuracy: 0.8724 - val_loss: 0.6717 - val_accuracy: 0.7343\n",
            "Epoch 928/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.3029 - accuracy: 0.8863 - val_loss: 0.6530 - val_accuracy: 0.7585\n",
            "Epoch 929/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2913 - accuracy: 0.8978 - val_loss: 0.6586 - val_accuracy: 0.7440\n",
            "Epoch 930/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2910 - accuracy: 0.8990 - val_loss: 0.6771 - val_accuracy: 0.7488\n",
            "Epoch 931/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3258 - accuracy: 0.8712 - val_loss: 0.6346 - val_accuracy: 0.7585\n",
            "Epoch 932/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2879 - accuracy: 0.8972 - val_loss: 0.6448 - val_accuracy: 0.7633\n",
            "Epoch 933/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3035 - accuracy: 0.8845 - val_loss: 0.6463 - val_accuracy: 0.7585\n",
            "Epoch 934/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3157 - accuracy: 0.8748 - val_loss: 0.6436 - val_accuracy: 0.7488\n",
            "Epoch 935/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3104 - accuracy: 0.8894 - val_loss: 0.6526 - val_accuracy: 0.7633\n",
            "Epoch 936/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.3093 - accuracy: 0.8706 - val_loss: 0.6583 - val_accuracy: 0.7633\n",
            "Epoch 937/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3140 - accuracy: 0.8857 - val_loss: 0.6551 - val_accuracy: 0.7488\n",
            "Epoch 938/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2898 - accuracy: 0.8936 - val_loss: 0.6381 - val_accuracy: 0.7729\n",
            "Epoch 939/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3017 - accuracy: 0.8888 - val_loss: 0.6222 - val_accuracy: 0.7729\n",
            "Epoch 940/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2923 - accuracy: 0.8912 - val_loss: 0.6323 - val_accuracy: 0.7778\n",
            "Epoch 941/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2887 - accuracy: 0.8936 - val_loss: 0.6430 - val_accuracy: 0.7729\n",
            "Epoch 942/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2982 - accuracy: 0.8906 - val_loss: 0.6484 - val_accuracy: 0.7729\n",
            "Epoch 943/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2953 - accuracy: 0.8984 - val_loss: 0.6479 - val_accuracy: 0.7633\n",
            "Epoch 944/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2957 - accuracy: 0.8906 - val_loss: 0.6571 - val_accuracy: 0.7391\n",
            "Epoch 945/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2977 - accuracy: 0.8906 - val_loss: 0.6675 - val_accuracy: 0.7536\n",
            "Epoch 946/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2945 - accuracy: 0.8930 - val_loss: 0.6506 - val_accuracy: 0.7585\n",
            "Epoch 947/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3025 - accuracy: 0.8881 - val_loss: 0.6473 - val_accuracy: 0.7681\n",
            "Epoch 948/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3078 - accuracy: 0.8869 - val_loss: 0.6360 - val_accuracy: 0.7874\n",
            "Epoch 949/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2794 - accuracy: 0.8978 - val_loss: 0.6215 - val_accuracy: 0.7923\n",
            "Epoch 950/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.3159 - accuracy: 0.8851 - val_loss: 0.6506 - val_accuracy: 0.7585\n",
            "Epoch 951/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2960 - accuracy: 0.8863 - val_loss: 0.6543 - val_accuracy: 0.7343\n",
            "Epoch 952/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2987 - accuracy: 0.8875 - val_loss: 0.6538 - val_accuracy: 0.7391\n",
            "Epoch 953/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3109 - accuracy: 0.8881 - val_loss: 0.6456 - val_accuracy: 0.7633\n",
            "Epoch 954/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2933 - accuracy: 0.8936 - val_loss: 0.6449 - val_accuracy: 0.7536\n",
            "Epoch 955/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.3002 - accuracy: 0.8900 - val_loss: 0.6623 - val_accuracy: 0.7295\n",
            "Epoch 956/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2893 - accuracy: 0.8918 - val_loss: 0.6510 - val_accuracy: 0.7343\n",
            "Epoch 957/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2881 - accuracy: 0.8972 - val_loss: 0.6449 - val_accuracy: 0.7633\n",
            "Epoch 958/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2972 - accuracy: 0.8863 - val_loss: 0.6349 - val_accuracy: 0.7633\n",
            "Epoch 959/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2871 - accuracy: 0.8930 - val_loss: 0.6485 - val_accuracy: 0.7681\n",
            "Epoch 960/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2847 - accuracy: 0.8936 - val_loss: 0.6697 - val_accuracy: 0.7633\n",
            "Epoch 961/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2945 - accuracy: 0.8857 - val_loss: 0.6492 - val_accuracy: 0.7585\n",
            "Epoch 962/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.3057 - accuracy: 0.8912 - val_loss: 0.6512 - val_accuracy: 0.7681\n",
            "Epoch 963/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2796 - accuracy: 0.9039 - val_loss: 0.6458 - val_accuracy: 0.7729\n",
            "Epoch 964/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2829 - accuracy: 0.8912 - val_loss: 0.6463 - val_accuracy: 0.7536\n",
            "Epoch 965/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2997 - accuracy: 0.8863 - val_loss: 0.6345 - val_accuracy: 0.7681\n",
            "Epoch 966/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2965 - accuracy: 0.8912 - val_loss: 0.6366 - val_accuracy: 0.7778\n",
            "Epoch 967/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2958 - accuracy: 0.8821 - val_loss: 0.6203 - val_accuracy: 0.7681\n",
            "Epoch 968/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2773 - accuracy: 0.8984 - val_loss: 0.6382 - val_accuracy: 0.7778\n",
            "Epoch 969/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2798 - accuracy: 0.8924 - val_loss: 0.6338 - val_accuracy: 0.7923\n",
            "Epoch 970/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2920 - accuracy: 0.8906 - val_loss: 0.6518 - val_accuracy: 0.7826\n",
            "Epoch 971/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2755 - accuracy: 0.8918 - val_loss: 0.6421 - val_accuracy: 0.7681\n",
            "Epoch 972/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2856 - accuracy: 0.8851 - val_loss: 0.6470 - val_accuracy: 0.7826\n",
            "Epoch 973/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2903 - accuracy: 0.8900 - val_loss: 0.6370 - val_accuracy: 0.7633\n",
            "Epoch 974/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2908 - accuracy: 0.9015 - val_loss: 0.6482 - val_accuracy: 0.7681\n",
            "Epoch 975/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2966 - accuracy: 0.8845 - val_loss: 0.6356 - val_accuracy: 0.7826\n",
            "Epoch 976/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2789 - accuracy: 0.8996 - val_loss: 0.6745 - val_accuracy: 0.7633\n",
            "Epoch 977/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2986 - accuracy: 0.8906 - val_loss: 0.6580 - val_accuracy: 0.7488\n",
            "Epoch 978/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2962 - accuracy: 0.8839 - val_loss: 0.6491 - val_accuracy: 0.7681\n",
            "Epoch 979/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2903 - accuracy: 0.8906 - val_loss: 0.6613 - val_accuracy: 0.7633\n",
            "Epoch 980/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2881 - accuracy: 0.8833 - val_loss: 0.6550 - val_accuracy: 0.7729\n",
            "Epoch 981/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2835 - accuracy: 0.8954 - val_loss: 0.6383 - val_accuracy: 0.7681\n",
            "Epoch 982/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2604 - accuracy: 0.9129 - val_loss: 0.6649 - val_accuracy: 0.7536\n",
            "Epoch 983/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2795 - accuracy: 0.8966 - val_loss: 0.6545 - val_accuracy: 0.7729\n",
            "Epoch 984/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2624 - accuracy: 0.9135 - val_loss: 0.6701 - val_accuracy: 0.7633\n",
            "Epoch 985/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2748 - accuracy: 0.8978 - val_loss: 0.6512 - val_accuracy: 0.7633\n",
            "Epoch 986/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2835 - accuracy: 0.8869 - val_loss: 0.6519 - val_accuracy: 0.7585\n",
            "Epoch 987/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2691 - accuracy: 0.9027 - val_loss: 0.6348 - val_accuracy: 0.7826\n",
            "Epoch 988/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2759 - accuracy: 0.8990 - val_loss: 0.6547 - val_accuracy: 0.7585\n",
            "Epoch 989/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2845 - accuracy: 0.8960 - val_loss: 0.6452 - val_accuracy: 0.7729\n",
            "Epoch 990/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2583 - accuracy: 0.9027 - val_loss: 0.6426 - val_accuracy: 0.7585\n",
            "Epoch 991/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2682 - accuracy: 0.9045 - val_loss: 0.6633 - val_accuracy: 0.7585\n",
            "Epoch 992/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2858 - accuracy: 0.9002 - val_loss: 0.6323 - val_accuracy: 0.7778\n",
            "Epoch 993/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2654 - accuracy: 0.9051 - val_loss: 0.6364 - val_accuracy: 0.7585\n",
            "Epoch 994/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2611 - accuracy: 0.9002 - val_loss: 0.6429 - val_accuracy: 0.7585\n",
            "Epoch 995/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2795 - accuracy: 0.8978 - val_loss: 0.6452 - val_accuracy: 0.7778\n",
            "Epoch 996/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2680 - accuracy: 0.9021 - val_loss: 0.6471 - val_accuracy: 0.7778\n",
            "Epoch 997/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2978 - accuracy: 0.8894 - val_loss: 0.6768 - val_accuracy: 0.7440\n",
            "Epoch 998/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2652 - accuracy: 0.9045 - val_loss: 0.6577 - val_accuracy: 0.7536\n",
            "Epoch 999/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2803 - accuracy: 0.8912 - val_loss: 0.6499 - val_accuracy: 0.7923\n",
            "Epoch 1000/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2552 - accuracy: 0.9051 - val_loss: 0.6606 - val_accuracy: 0.7633\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(cnnhistory.history['loss'])\n",
        "plt.plot(cnnhistory.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train','test'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "oQYnuaCrDH_A",
        "outputId": "459fac7f-7f22-4111-8c94-2affffd7b6c0"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(cnnhistory.history['accuracy'])\n",
        "plt.plot(cnnhistory.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train','test'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "IFkTuO8nDNdq",
        "outputId": "66648a68-d6af-4763-91fd-f96e2ad806b3"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#predictions = model.predict_classes(x_testcnn)\n",
        "predictions = model.predict(x_testcnn)"
      ],
      "metadata": {
        "id": "A2xtrN5wDQgY"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_f_ohjXKDUpY",
        "outputId": "6e2317da-9bf5-4a18-e257-1665daa4bb80"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.9950068e-05, 2.0924854e-06, 4.1681236e-01, 5.4011689e-05,\n",
              "        3.7990069e-01, 2.0321088e-01],\n",
              "       [5.4065090e-02, 9.3750113e-01, 1.0647473e-03, 4.1052662e-03,\n",
              "        1.7279952e-03, 1.5357636e-03],\n",
              "       [3.4225204e-07, 1.9746194e-04, 9.7901523e-01, 2.9360568e-05,\n",
              "        2.0251786e-02, 5.0568604e-04],\n",
              "       ...,\n",
              "       [4.8653976e-05, 2.2169617e-07, 6.3995263e-05, 2.4442843e-04,\n",
              "        9.8899031e-01, 1.0652296e-02],\n",
              "       [3.0752137e-02, 1.0657061e-03, 8.8646980e-03, 5.9438080e-01,\n",
              "        7.3238872e-03, 3.5761276e-01],\n",
              "       [5.2027743e-02, 5.0206669e-02, 6.1665680e-02, 7.8066662e-02,\n",
              "        7.5728458e-01, 7.4867532e-04]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cmA2bFgsDW3D",
        "outputId": "67db0342-c86b-4864-e6ae-da536d4128cb"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5, 1, 2, 5, 3, 4, 2, 0, 3, 1, 3, 2, 1, 4, 3, 0, 5, 0, 2, 5, 0, 0,\n",
              "       1, 3, 2, 3, 2, 5, 4, 2, 2, 3, 1, 2, 5, 5, 3, 5, 3, 3, 4, 1, 3, 2,\n",
              "       3, 1, 5, 3, 1, 2, 4, 4, 5, 5, 5, 1, 2, 3, 2, 5, 0, 2, 4, 2, 5, 4,\n",
              "       3, 0, 1, 2, 5, 2, 1, 2, 4, 5, 4, 1, 5, 5, 3, 1, 5, 3, 2, 4, 2, 5,\n",
              "       0, 5, 0, 5, 4, 0, 2, 4, 0, 2, 2, 0, 2, 3, 5, 3, 5, 5, 3, 1, 2, 2,\n",
              "       2, 1, 3, 2, 1, 3, 4, 4, 1, 1, 2, 4, 4, 1, 4, 2, 0, 4, 5, 5, 3, 1,\n",
              "       2, 1, 5, 5, 1, 2, 3, 3, 0, 3, 3, 0, 1, 0, 1, 2, 1, 5, 1, 2, 2, 0,\n",
              "       1, 1, 1, 1, 1, 4, 0, 1, 5, 1, 4, 5, 5, 4, 1, 0, 3, 5, 2, 3, 0, 4,\n",
              "       1, 3, 1, 0, 5, 5, 3, 5, 4, 5, 4, 0, 4, 1, 2, 1, 5, 0, 4, 3, 2, 1,\n",
              "       0, 3, 5, 0, 4, 5, 4, 5, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_Ytest = y_test.astype(int)"
      ],
      "metadata": {
        "id": "0PHDKWJWDY3g"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_Ytest"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k68v2i-pDbZE",
        "outputId": "c8219e76-0d45-430d-c6e8-916a572c8366"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5, 1, 2, 5, 3, 4, 2, 0, 3, 1, 3, 2, 1, 4, 3, 0, 5, 0, 2, 5, 0, 0,\n",
              "       1, 3, 2, 3, 2, 5, 4, 2, 2, 3, 1, 2, 5, 5, 3, 5, 3, 3, 4, 1, 3, 2,\n",
              "       3, 1, 5, 3, 1, 2, 4, 4, 5, 5, 5, 1, 2, 3, 2, 5, 0, 2, 4, 2, 5, 4,\n",
              "       3, 0, 1, 2, 5, 2, 1, 2, 4, 5, 4, 1, 5, 5, 3, 1, 5, 3, 2, 4, 2, 5,\n",
              "       0, 5, 0, 5, 4, 0, 2, 4, 0, 2, 2, 0, 2, 3, 5, 3, 5, 5, 3, 1, 2, 2,\n",
              "       2, 1, 3, 2, 1, 3, 4, 4, 1, 1, 2, 4, 4, 1, 4, 2, 0, 4, 5, 5, 3, 1,\n",
              "       2, 1, 5, 5, 1, 2, 3, 3, 0, 3, 3, 0, 1, 0, 1, 2, 1, 5, 1, 2, 2, 0,\n",
              "       1, 1, 1, 1, 1, 4, 0, 1, 5, 1, 4, 5, 5, 4, 1, 0, 3, 5, 2, 3, 0, 4,\n",
              "       1, 3, 1, 0, 5, 5, 3, 5, 4, 5, 4, 0, 4, 1, 2, 1, 5, 0, 4, 3, 2, 1,\n",
              "       0, 3, 5, 0, 4, 5, 4, 5, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds1=predictions.argmax(axis=1)\n",
        "preds1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4_cAI39VFhtp",
        "outputId": "53aa0bcb-2cfb-4dbe-ef8c-40ac6abc8a51"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2, 1, 2, 5, 3, 4, 2, 0, 3, 0, 3, 2, 1, 4, 3, 0, 4, 3, 2, 5, 2, 0,\n",
              "       1, 3, 2, 5, 2, 5, 4, 2, 2, 3, 1, 2, 5, 5, 1, 2, 3, 2, 4, 1, 3, 2,\n",
              "       3, 1, 5, 3, 1, 4, 4, 4, 5, 2, 4, 1, 2, 3, 2, 5, 0, 2, 4, 2, 5, 4,\n",
              "       0, 1, 1, 2, 3, 2, 1, 2, 4, 3, 4, 1, 5, 5, 3, 1, 5, 3, 2, 4, 2, 3,\n",
              "       0, 5, 0, 5, 4, 0, 3, 4, 3, 4, 2, 1, 2, 3, 5, 3, 5, 2, 5, 1, 2, 2,\n",
              "       2, 1, 3, 2, 1, 4, 4, 4, 1, 4, 2, 4, 4, 1, 4, 2, 2, 4, 4, 5, 5, 1,\n",
              "       2, 1, 2, 5, 1, 2, 3, 3, 0, 3, 5, 0, 1, 0, 1, 2, 1, 5, 1, 2, 4, 0,\n",
              "       1, 1, 1, 1, 2, 4, 0, 1, 5, 1, 4, 5, 5, 2, 1, 0, 5, 5, 2, 3, 3, 4,\n",
              "       1, 5, 1, 5, 5, 2, 3, 5, 4, 5, 4, 0, 4, 0, 2, 1, 5, 0, 4, 1, 2, 2,\n",
              "       1, 4, 5, 3, 2, 5, 4, 3, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "abc = preds1.astype(int).flatten()"
      ],
      "metadata": {
        "id": "H4WEmM60NfQn"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "c = confusion_matrix(new_Ytest, abc) \n",
        "c"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bKEBeEBlFjB8",
        "outputId": "3e767ebc-d563-401b-acba-65d614c96847"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[15,  3,  2,  4,  0,  1],\n",
              "       [ 2, 34,  2,  0,  1,  0],\n",
              "       [ 0,  0, 34,  1,  3,  0],\n",
              "       [ 1,  2,  1, 21,  2,  6],\n",
              "       [ 0,  0,  2,  0, 28,  0],\n",
              "       [ 0,  0,  6,  4,  3, 29]])"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m4RjG7LWLSQx",
        "outputId": "c7589455-ef89-40b8-cf67-a5c306696e7f"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5, 1, 2, 5, 3, 4, 2, 0, 3, 1, 3, 2, 1, 4, 3, 0, 5, 0, 2, 5, 0, 0,\n",
              "       1, 3, 2, 3, 2, 5, 4, 2, 2, 3, 1, 2, 5, 5, 3, 5, 3, 3, 4, 1, 3, 2,\n",
              "       3, 1, 5, 3, 1, 2, 4, 4, 5, 5, 5, 1, 2, 3, 2, 5, 0, 2, 4, 2, 5, 4,\n",
              "       3, 0, 1, 2, 5, 2, 1, 2, 4, 5, 4, 1, 5, 5, 3, 1, 5, 3, 2, 4, 2, 5,\n",
              "       0, 5, 0, 5, 4, 0, 2, 4, 0, 2, 2, 0, 2, 3, 5, 3, 5, 5, 3, 1, 2, 2,\n",
              "       2, 1, 3, 2, 1, 3, 4, 4, 1, 1, 2, 4, 4, 1, 4, 2, 0, 4, 5, 5, 3, 1,\n",
              "       2, 1, 5, 5, 1, 2, 3, 3, 0, 3, 3, 0, 1, 0, 1, 2, 1, 5, 1, 2, 2, 0,\n",
              "       1, 1, 1, 1, 1, 4, 0, 1, 5, 1, 4, 5, 5, 4, 1, 0, 3, 5, 2, 3, 0, 4,\n",
              "       1, 3, 1, 0, 5, 5, 3, 5, 4, 5, 4, 0, 4, 1, 2, 1, 5, 0, 4, 3, 2, 1,\n",
              "       0, 3, 5, 0, 4, 5, 4, 5, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('/content/drive/My Drive/graduation project/audio/paper_code/mariam/original_500 epoch_with_valid_Adam2_3')\n",
        "print(\"MODEL SAVED\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lsJBNeMWDl6Z",
        "outputId": "a726bfde-ac69-47f8-851d-09dfc4b11cf7"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/graduation project/audio/paper_code/mariam/original_500 epoch_with_valid_Adam2_3/assets\n",
            "MODEL SAVED\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_model=keras.models.load_model('/content/drive/My Drive/graduation project/audio/paper_code/mariam/original_500 epoch_with_valid_Adam2_3')\n",
        "new_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q3KjaO9GDoNl",
        "outputId": "8b317b0d-01b5-45e3-d6ed-7cb591f59de6"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d (Conv1D)             (None, 40, 128)           1152      \n",
            "                                                                 \n",
            " activation (Activation)     (None, 40, 128)           0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 40, 128)           0         \n",
            "                                                                 \n",
            " max_pooling1d (MaxPooling1D  (None, 8, 128)           0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv1d_1 (Conv1D)           (None, 8, 256)            262400    \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 8, 256)            0         \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 8, 256)            0         \n",
            "                                                                 \n",
            " max_pooling1d_1 (MaxPooling  (None, 1, 256)           0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 256)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 256)               65792     \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 256)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 256)               65792     \n",
            "                                                                 \n",
            " activation_3 (Activation)   (None, 256)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 6)                 1542      \n",
            "                                                                 \n",
            " activation_4 (Activation)   (None, 6)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 396,678\n",
            "Trainable params: 396,678\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss, acc =model.evaluate(x_testcnn, y_test)\n",
        "print(\"Restored model, accuracy: {:5.2f}%\".format(100*acc))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n3kzoqPkDqqS",
        "outputId": "2d8a892a-8699-43cf-ba0f-2d8480e4a3fe"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7/7 [==============================] - 0s 3ms/step - loss: 0.6149 - accuracy: 0.7778\n",
            "Restored model, accuracy: 77.78%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss, acc =model.evaluate(X_train, y_train)\n",
        "print(\"Restored model train, accuracy: {:5.2f}%\".format(100*acc))"
      ],
      "metadata": {
        "id": "fJDTGH_OUX0z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "823f0d04-e72c-473e-b94f-b42cbf7c3d0a"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "52/52 [==============================] - 0s 4ms/step - loss: 0.2388 - accuracy: 0.9420\n",
            "Restored model train, accuracy: 94.20%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix,accuracy_score\n",
        "import seaborn as sn\n",
        "\n",
        "print(classification_report(new_Ytest,abc))\n",
        "\n",
        "acc = float(accuracy_score(new_Ytest,abc))*100\n",
        "print(\"----accuracy score %s ----\" % acc)\n",
        "\n",
        "cm = confusion_matrix(new_Ytest,abc)\n",
        "#df_cm = pd.DataFrame(cm)\n",
        "class_names = ['neutral','calm', 'happy','sad','angry', 'fearful' ]\n",
        "df_cm = pd.DataFrame(cm, index=class_names, columns=class_names,)\n",
        "sn.heatmap(df_cm, annot=True, fmt='')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 517
        },
        "id": "SfSC3El94LZg",
        "outputId": "c91666eb-e847-4658-ff73-e7586ad05e27"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.60      0.70        25\n",
            "           1       0.87      0.87      0.87        39\n",
            "           2       0.72      0.89      0.80        38\n",
            "           3       0.70      0.64      0.67        33\n",
            "           4       0.76      0.93      0.84        30\n",
            "           5       0.81      0.69      0.74        42\n",
            "\n",
            "    accuracy                           0.78       207\n",
            "   macro avg       0.78      0.77      0.77       207\n",
            "weighted avg       0.78      0.78      0.77       207\n",
            "\n",
            "----accuracy score 77.77777777777779 ----\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "LGpgwFQqkpyU"
      },
      "execution_count": 38,
      "outputs": []
    }
  ]
}