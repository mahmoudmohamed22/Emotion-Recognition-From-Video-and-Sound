{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "original model no augmentation speech&song RMS try 5.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9SRCO-a_AlH5",
        "outputId": "5bb31e02-dab6-48f8-f59b-5ce5fcdade9f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install librosa"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oi8pWV3yBVjO",
        "outputId": "ae5e1abe-a3be-4de0-b04e-c7895f02cf94"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.7/dist-packages (0.8.1)\n",
            "Requirement already satisfied: resampy>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from librosa) (0.2.2)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.1.0)\n",
            "Requirement already satisfied: decorator>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.21.6)\n",
            "Requirement already satisfied: numba>=0.43.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (0.51.2)\n",
            "Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.0.2)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.4.1)\n",
            "Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.6.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (21.3)\n",
            "Requirement already satisfied: soundfile>=0.10.2 in /usr/local/lib/python3.7/dist-packages (from librosa) (0.10.3.post1)\n",
            "Requirement already satisfied: audioread>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (2.1.9)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba>=0.43.0->librosa) (57.4.0)\n",
            "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba>=0.43.0->librosa) (0.34.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->librosa) (3.0.9)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from pooch>=1.0->librosa) (2.23.0)\n",
            "Requirement already satisfied: appdirs>=1.3.0 in /usr/local/lib/python3.7/dist-packages (from pooch>=1.0->librosa) (1.4.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2022.5.18.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (3.0.4)\n",
            "Requirement already satisfied: six>=1.3 in /usr/local/lib/python3.7/dist-packages (from resampy>=0.2.2->librosa) (1.15.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn!=0.19.0,>=0.14.0->librosa) (3.1.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.7/dist-packages (from soundfile>=0.10.2->librosa) (1.15.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.0->soundfile>=0.10.2->librosa) (2.21)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HJjcbxwy46bG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "a3a8ee3c-7861-4a29-dbbf-78785b03e3f0"
      },
      "source": [
        "# Orignial Notebook: https://github.com/MITESHPUTHRANNEU/Speech-Emotion-Analyzer/blob/master/final_results_gender_test.ipynb\n",
        "# This notebook author: Reza Chu\n",
        "# Last Editing Date: 31st May 2019\n",
        "\n",
        "## Python\n",
        "import os\n",
        "import random\n",
        "import sys\n",
        "\n",
        "import IPython\n",
        "from IPython.display import Audio\n",
        "from IPython.display import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "## Package\n",
        "import glob \n",
        "import keras\n",
        "import IPython.display as ipd\n",
        "import librosa\n",
        "import librosa.display\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import plotly.graph_objs as go\n",
        "import plotly.offline as py\n",
        "import plotly.tools as tls\n",
        "import seaborn as sns\n",
        "import scipy.io.wavfile\n",
        "import tensorflow as tf\n",
        "py.init_notebook_mode(connected=True)\n",
        "\n",
        "## Keras\n",
        "from keras import regularizers\n",
        "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping\n",
        "from keras.callbacks import  History, ReduceLROnPlateau, CSVLogger\n",
        "from keras.models import Model, Sequential\n",
        "from keras.layers import Dense, Embedding, LSTM\n",
        "from keras.layers import Input, Flatten, Dropout, Activation, BatchNormalization\n",
        "from keras.layers import Conv1D, MaxPooling1D, AveragePooling1D\n",
        "from keras.preprocessing import sequence\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.utils import np_utils\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "## Sklearn\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "## Rest\n",
        "from scipy.fftpack import fft\n",
        "from scipy import signal\n",
        "from scipy.io import wavfile\n",
        "from tqdm import tqdm\n",
        "\n",
        "input_duration=3\n",
        "# % pylab inline"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "        <script type=\"text/javascript\">\n",
              "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
              "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
              "        if (typeof require !== 'undefined') {\n",
              "        require.undef(\"plotly\");\n",
              "        requirejs.config({\n",
              "            paths: {\n",
              "                'plotly': ['https://cdn.plot.ly/plotly-2.8.3.min']\n",
              "            }\n",
              "        });\n",
              "        require(['plotly'], function(Plotly) {\n",
              "            window._Plotly = Plotly;\n",
              "        });\n",
              "        }\n",
              "        </script>\n",
              "        "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#radvass speech and song\n",
        "import time\n",
        "import os\n",
        "import librosa\n",
        "from librosa import display\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "count=0\n",
        "path1 = '/content/drive/MyDrive/RAVDESS_speech'\n",
        "path2 = '/content/drive/MyDrive/RAVDESS_song'\n",
        "\n",
        "lst = []\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "for subdir, dirs, files in os.walk(path2):\n",
        "  #print(dirs)\n",
        "  #print(subdir)\n",
        "  #print(files)\n",
        "  for file in files:\n",
        "      try:\n",
        "        count +=1\n",
        "        #Load librosa array, obtain mfcss, store the file and the mcss information in a new array\n",
        "        X, sample_rate = librosa.load(os.path.join(subdir,file), res_type='kaiser_fast')\n",
        "        mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T,axis=0) \n",
        "        # The instruction below converts the labels (from 1 to 8) to a series from 0 to 7\n",
        "        # This is because our predictor needs to start from 0 otherwise it will try to predict also 0.\n",
        "        file = int(file[7:8]) - 1 \n",
        "        arr = mfccs, file\n",
        "        lst.append(arr)\n",
        "      # If the file is not valid, skip it\n",
        "      except ValueError:\n",
        "        continue\n",
        "\n",
        "for subdir, dirs, files in os.walk(path1):\n",
        "  #print(dirs)\n",
        "  #print(subdir)\n",
        " # print(files)\n",
        "  for file in files:\n",
        "      try:\n",
        "        #Load librosa array, obtain mfcss, store the file and the mcss information in a new array\n",
        "        X, sample_rate = librosa.load(os.path.join(subdir,file), res_type='kaiser_fast')\n",
        "        mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T,axis=0) \n",
        "        # The instruction below converts the labels (from 1 to 8) to a series from 0 to 7\n",
        "        # This is because our predictor needs to start from 0 otherwise it will try to predict also 0.\n",
        "        file = int(file[7:8]) - 1 \n",
        "        if(file ==6 or file==7):\n",
        "          continue\n",
        "        count +=1\n",
        "        arr = mfccs, file\n",
        "        lst.append(arr)\n",
        "      # If the file is not valid, skip it\n",
        "      except ValueError:\n",
        "        continue\n",
        "\n",
        "\n",
        "\n",
        "print(\"--- Data loaded. Loading time: %s seconds ---\" % (time.time() - start_time))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IfuyRZl42ccZ",
        "outputId": "b1bff222-f82e-4f2c-d145-54716f64c4e9"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Data loaded. Loading time: 206.6529712677002 seconds ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "count"
      ],
      "metadata": {
        "id": "Ltlhi25L2AI5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2650feff-8855-48f9-df2a-c55677527b59"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2068"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy.core.fromnumeric import size\n",
        "size(lst)"
      ],
      "metadata": {
        "id": "HMOH7d7mzHB7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25d08442-e99f-4ee8-bc18-be8394e6e8ce"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/core/fromnumeric.py:3208: VisibleDeprecationWarning:\n",
            "\n",
            "Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4136"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating X and y: zip makes a list of all the first elements, and a list of all the second elements.\n",
        "X, y = zip(*lst)"
      ],
      "metadata": {
        "id": "ocdL7tSTBoMt"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "X = np.asarray(X)\n",
        "y = np.asarray(y)\n",
        "X.shape, y.shape"
      ],
      "metadata": {
        "id": "vHKwUGTbBtnF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae350117-6bb2-4f35-a4c7-2a11aa3483ff"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((2068, 40), (2068,))"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "id": "2sUCtbfMztE5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0dcaa670-69da-4421-f81c-b7abb529248b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2068, 40)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7PSTurzjCo5K",
        "outputId": "272e4012-0a6e-4bb4-da6a-d880204407e8"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2068, 40)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2,train_size=0.8, random_state=42)\n",
        "X_valid, X_test, y_valid, y_test = train_test_split(X_test,y_test, test_size=0.5,train_size=0.5, random_state=42)"
      ],
      "metadata": {
        "id": "Ai4Fy5cPCiq1"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "x_traincnn = np.expand_dims(X_train, axis=2)\n",
        "x_testcnn = np.expand_dims(X_test, axis=2)\n",
        "X_valid= np.expand_dims(X_valid, axis=2)"
      ],
      "metadata": {
        "id": "tp1Fm5K3CEXu"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_traincnn.shape, x_testcnn.shape , X_valid.shape"
      ],
      "metadata": {
        "id": "RI0MxoIPBws5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "812c1a8a-c23c-4307-b1af-e1bf678dd44b"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1654, 40, 1), (207, 40, 1), (207, 40, 1))"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow"
      ],
      "metadata": {
        "id": "goxL4Y3jKICC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d40a2963-ce42-4df0-e9e2-f7ad6e62e73b"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (2.8.2+zzzcolab20220527125636)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.17.3)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.5.3)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.0.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (4.2.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow) (57.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.46.3)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (14.0.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.26.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.21.6)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow) (1.5.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.6.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (3.3.7)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.8.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.4.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.23.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.35.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.2.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (4.11.4)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (3.8.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2022.5.18.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (3.2.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keras"
      ],
      "metadata": {
        "id": "EkcmN9UrKSxj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "801c4945-4821-4144-f6af-0f4c29705833"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.7/dist-packages (2.8.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from keras.preprocessing import sequence\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from keras.layers import Input, Flatten, Dropout, Activation\n",
        "from keras.layers import Conv1D, MaxPooling1D\n",
        "from keras.models import Model\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras import optimizers\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv1D(128, 8,padding='same', #classifier.add(Convolution2D(64, (3, 3), padding = 'same', input_shape = (128, 128, 3), activation = 'relu'))\n",
        "                 input_shape=(40,1)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(MaxPooling1D(pool_size=(5)))\n",
        "\n",
        "\n",
        "model.add(Conv1D(256,8,padding='same',))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(MaxPooling1D(pool_size=(5)))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(256))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(256))\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "model.add(Dense(6))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "#opt = tf.keras.optimizers.Adam(lr=0.00002)\n",
        "opt = tf.keras.optimizers.RMSprop(lr=0.00002, rho=0.9, epsilon=1e-07, decay=0.0)\n",
        "#opt = tf.keras.optimizers.SGD(lr=0.001, momentum=0.0, decay=0.0, nesterov=False)"
      ],
      "metadata": {
        "id": "g74fXWVAC4Cr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "51705024-23c8-4a1c-ca89-e1d68201feee"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/rmsprop.py:130: UserWarning:\n",
            "\n",
            "The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H6ukOxAGC_I4",
        "outputId": "c600f3ca-d445-43c7-82e9-854206075ee0"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d (Conv1D)             (None, 40, 128)           1152      \n",
            "                                                                 \n",
            " activation (Activation)     (None, 40, 128)           0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 40, 128)           0         \n",
            "                                                                 \n",
            " max_pooling1d (MaxPooling1D  (None, 8, 128)           0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv1d_1 (Conv1D)           (None, 8, 256)            262400    \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 8, 256)            0         \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 8, 256)            0         \n",
            "                                                                 \n",
            " max_pooling1d_1 (MaxPooling  (None, 1, 256)           0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 256)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 256)               65792     \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 256)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 256)               65792     \n",
            "                                                                 \n",
            " activation_3 (Activation)   (None, 256)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 6)                 1542      \n",
            "                                                                 \n",
            " activation_4 (Activation)   (None, 6)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 396,678\n",
            "Trainable params: 396,678\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='sparse_categorical_crossentropy',\n",
        "              optimizer=opt,\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "AbMlLNk4DCBM"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#cnnhistory=model.fit(x_traincnn, y_train, batch_size=16, epochs=700, validation_data=(x_testcnn, y_test))\n",
        "cnnhistory=model.fit(x_traincnn, y_train, batch_size=16, epochs=500 , validation_data=(X_valid, y_valid))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RI1v2AuADFhy",
        "outputId": "05eb7418-731b-4d5d-c843-58be510df870"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "104/104 [==============================] - 4s 12ms/step - loss: 5.3870 - accuracy: 0.1614 - val_loss: 2.0924 - val_accuracy: 0.1932\n",
            "Epoch 2/500\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 4.1516 - accuracy: 0.1826 - val_loss: 1.7886 - val_accuracy: 0.2319\n",
            "Epoch 3/500\n",
            "104/104 [==============================] - 1s 9ms/step - loss: 3.6429 - accuracy: 0.1784 - val_loss: 1.9338 - val_accuracy: 0.1787\n",
            "Epoch 4/500\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 3.1420 - accuracy: 0.1723 - val_loss: 1.7467 - val_accuracy: 0.2222\n",
            "Epoch 5/500\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 2.9252 - accuracy: 0.1784 - val_loss: 1.7834 - val_accuracy: 0.2271\n",
            "Epoch 6/500\n",
            "104/104 [==============================] - 1s 9ms/step - loss: 2.6706 - accuracy: 0.1911 - val_loss: 1.7602 - val_accuracy: 0.2609\n",
            "Epoch 7/500\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 2.5424 - accuracy: 0.1935 - val_loss: 1.7002 - val_accuracy: 0.2899\n",
            "Epoch 8/500\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 2.3519 - accuracy: 0.1947 - val_loss: 1.7731 - val_accuracy: 0.2174\n",
            "Epoch 9/500\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 2.2166 - accuracy: 0.2164 - val_loss: 1.7352 - val_accuracy: 0.2657\n",
            "Epoch 10/500\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 2.1941 - accuracy: 0.1989 - val_loss: 1.7612 - val_accuracy: 0.2126\n",
            "Epoch 11/500\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 2.1354 - accuracy: 0.2007 - val_loss: 1.7272 - val_accuracy: 0.1981\n",
            "Epoch 12/500\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 2.0433 - accuracy: 0.2255 - val_loss: 1.7073 - val_accuracy: 0.2222\n",
            "Epoch 13/500\n",
            "104/104 [==============================] - 1s 9ms/step - loss: 2.0651 - accuracy: 0.2074 - val_loss: 1.7402 - val_accuracy: 0.2367\n",
            "Epoch 14/500\n",
            "104/104 [==============================] - 1s 9ms/step - loss: 2.0098 - accuracy: 0.2031 - val_loss: 1.7277 - val_accuracy: 0.2271\n",
            "Epoch 15/500\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 1.9698 - accuracy: 0.2243 - val_loss: 1.7036 - val_accuracy: 0.2464\n",
            "Epoch 16/500\n",
            "104/104 [==============================] - 1s 9ms/step - loss: 1.9396 - accuracy: 0.2267 - val_loss: 1.7356 - val_accuracy: 0.2029\n",
            "Epoch 17/500\n",
            "104/104 [==============================] - 1s 9ms/step - loss: 1.9390 - accuracy: 0.2134 - val_loss: 1.6725 - val_accuracy: 0.2705\n",
            "Epoch 18/500\n",
            "104/104 [==============================] - 1s 9ms/step - loss: 1.9164 - accuracy: 0.2225 - val_loss: 1.6932 - val_accuracy: 0.2415\n",
            "Epoch 19/500\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 1.9027 - accuracy: 0.2285 - val_loss: 1.6956 - val_accuracy: 0.2802\n",
            "Epoch 20/500\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 1.8702 - accuracy: 0.2291 - val_loss: 1.6859 - val_accuracy: 0.2899\n",
            "Epoch 21/500\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 1.8714 - accuracy: 0.2370 - val_loss: 1.6734 - val_accuracy: 0.3043\n",
            "Epoch 22/500\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 1.8327 - accuracy: 0.2304 - val_loss: 1.6664 - val_accuracy: 0.2947\n",
            "Epoch 23/500\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 1.8506 - accuracy: 0.2237 - val_loss: 1.6475 - val_accuracy: 0.3575\n",
            "Epoch 24/500\n",
            "104/104 [==============================] - 1s 9ms/step - loss: 1.8284 - accuracy: 0.2110 - val_loss: 1.6493 - val_accuracy: 0.2657\n",
            "Epoch 25/500\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 1.8295 - accuracy: 0.2382 - val_loss: 1.6671 - val_accuracy: 0.2415\n",
            "Epoch 26/500\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 1.8323 - accuracy: 0.2406 - val_loss: 1.6534 - val_accuracy: 0.2995\n",
            "Epoch 27/500\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 1.7961 - accuracy: 0.2527 - val_loss: 1.6250 - val_accuracy: 0.3623\n",
            "Epoch 28/500\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 1.8050 - accuracy: 0.2521 - val_loss: 1.6282 - val_accuracy: 0.3575\n",
            "Epoch 29/500\n",
            "104/104 [==============================] - 1s 9ms/step - loss: 1.7899 - accuracy: 0.2388 - val_loss: 1.6254 - val_accuracy: 0.3913\n",
            "Epoch 30/500\n",
            "104/104 [==============================] - 1s 9ms/step - loss: 1.7699 - accuracy: 0.2588 - val_loss: 1.6400 - val_accuracy: 0.3237\n",
            "Epoch 31/500\n",
            "104/104 [==============================] - 1s 9ms/step - loss: 1.7747 - accuracy: 0.2503 - val_loss: 1.6255 - val_accuracy: 0.3575\n",
            "Epoch 32/500\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 1.7626 - accuracy: 0.2479 - val_loss: 1.6331 - val_accuracy: 0.3575\n",
            "Epoch 33/500\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 1.7470 - accuracy: 0.2715 - val_loss: 1.6253 - val_accuracy: 0.3816\n",
            "Epoch 34/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.7244 - accuracy: 0.2739 - val_loss: 1.6151 - val_accuracy: 0.3575\n",
            "Epoch 35/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.7511 - accuracy: 0.2654 - val_loss: 1.6087 - val_accuracy: 0.3961\n",
            "Epoch 36/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.7376 - accuracy: 0.2684 - val_loss: 1.6147 - val_accuracy: 0.3575\n",
            "Epoch 37/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.7484 - accuracy: 0.2509 - val_loss: 1.6125 - val_accuracy: 0.3720\n",
            "Epoch 38/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.7113 - accuracy: 0.2763 - val_loss: 1.6088 - val_accuracy: 0.4010\n",
            "Epoch 39/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.7231 - accuracy: 0.2842 - val_loss: 1.6331 - val_accuracy: 0.3285\n",
            "Epoch 40/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.6977 - accuracy: 0.2999 - val_loss: 1.6204 - val_accuracy: 0.3285\n",
            "Epoch 41/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.7084 - accuracy: 0.2684 - val_loss: 1.6084 - val_accuracy: 0.3865\n",
            "Epoch 42/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.6932 - accuracy: 0.2975 - val_loss: 1.5797 - val_accuracy: 0.3913\n",
            "Epoch 43/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.6858 - accuracy: 0.2751 - val_loss: 1.6002 - val_accuracy: 0.3623\n",
            "Epoch 44/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.6774 - accuracy: 0.2938 - val_loss: 1.5856 - val_accuracy: 0.4106\n",
            "Epoch 45/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.7102 - accuracy: 0.2709 - val_loss: 1.5835 - val_accuracy: 0.3575\n",
            "Epoch 46/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.6754 - accuracy: 0.3011 - val_loss: 1.5910 - val_accuracy: 0.3382\n",
            "Epoch 47/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.6720 - accuracy: 0.2938 - val_loss: 1.6053 - val_accuracy: 0.3913\n",
            "Epoch 48/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.6723 - accuracy: 0.2956 - val_loss: 1.6031 - val_accuracy: 0.3671\n",
            "Epoch 49/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.6661 - accuracy: 0.2963 - val_loss: 1.5726 - val_accuracy: 0.3768\n",
            "Epoch 50/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.6628 - accuracy: 0.3047 - val_loss: 1.5747 - val_accuracy: 0.3865\n",
            "Epoch 51/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.6426 - accuracy: 0.2993 - val_loss: 1.5653 - val_accuracy: 0.4010\n",
            "Epoch 52/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.6606 - accuracy: 0.3023 - val_loss: 1.5483 - val_accuracy: 0.3961\n",
            "Epoch 53/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.6258 - accuracy: 0.3150 - val_loss: 1.5419 - val_accuracy: 0.3816\n",
            "Epoch 54/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.6301 - accuracy: 0.3204 - val_loss: 1.5739 - val_accuracy: 0.3575\n",
            "Epoch 55/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.6345 - accuracy: 0.3180 - val_loss: 1.5557 - val_accuracy: 0.4106\n",
            "Epoch 56/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.6278 - accuracy: 0.3089 - val_loss: 1.5884 - val_accuracy: 0.3333\n",
            "Epoch 57/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.6237 - accuracy: 0.3289 - val_loss: 1.5512 - val_accuracy: 0.4010\n",
            "Epoch 58/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.6272 - accuracy: 0.3301 - val_loss: 1.5431 - val_accuracy: 0.4058\n",
            "Epoch 59/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.6241 - accuracy: 0.3150 - val_loss: 1.5351 - val_accuracy: 0.3720\n",
            "Epoch 60/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.6291 - accuracy: 0.3192 - val_loss: 1.5360 - val_accuracy: 0.4058\n",
            "Epoch 61/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.6135 - accuracy: 0.3331 - val_loss: 1.5236 - val_accuracy: 0.4589\n",
            "Epoch 62/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.6319 - accuracy: 0.3186 - val_loss: 1.5600 - val_accuracy: 0.4106\n",
            "Epoch 63/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.6028 - accuracy: 0.3331 - val_loss: 1.5459 - val_accuracy: 0.4010\n",
            "Epoch 64/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.5942 - accuracy: 0.3301 - val_loss: 1.5313 - val_accuracy: 0.3527\n",
            "Epoch 65/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.5899 - accuracy: 0.3277 - val_loss: 1.5280 - val_accuracy: 0.4589\n",
            "Epoch 66/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.6073 - accuracy: 0.3156 - val_loss: 1.5418 - val_accuracy: 0.4058\n",
            "Epoch 67/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.5816 - accuracy: 0.3265 - val_loss: 1.5439 - val_accuracy: 0.3285\n",
            "Epoch 68/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.5781 - accuracy: 0.3301 - val_loss: 1.5191 - val_accuracy: 0.4300\n",
            "Epoch 69/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.5727 - accuracy: 0.3392 - val_loss: 1.5147 - val_accuracy: 0.3768\n",
            "Epoch 70/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.5690 - accuracy: 0.3567 - val_loss: 1.5235 - val_accuracy: 0.4058\n",
            "Epoch 71/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.5771 - accuracy: 0.3392 - val_loss: 1.5015 - val_accuracy: 0.4106\n",
            "Epoch 72/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.5603 - accuracy: 0.3597 - val_loss: 1.4941 - val_accuracy: 0.4155\n",
            "Epoch 73/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.5762 - accuracy: 0.3585 - val_loss: 1.5005 - val_accuracy: 0.4444\n",
            "Epoch 74/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.5752 - accuracy: 0.3482 - val_loss: 1.5107 - val_accuracy: 0.3816\n",
            "Epoch 75/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.5523 - accuracy: 0.3664 - val_loss: 1.5047 - val_accuracy: 0.3720\n",
            "Epoch 76/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.5543 - accuracy: 0.3706 - val_loss: 1.4861 - val_accuracy: 0.4251\n",
            "Epoch 77/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.5547 - accuracy: 0.3513 - val_loss: 1.4988 - val_accuracy: 0.3865\n",
            "Epoch 78/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.5554 - accuracy: 0.3476 - val_loss: 1.5067 - val_accuracy: 0.3671\n",
            "Epoch 79/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.5489 - accuracy: 0.3495 - val_loss: 1.4788 - val_accuracy: 0.4300\n",
            "Epoch 80/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.5404 - accuracy: 0.3464 - val_loss: 1.4835 - val_accuracy: 0.4734\n",
            "Epoch 81/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.5380 - accuracy: 0.3670 - val_loss: 1.4740 - val_accuracy: 0.4638\n",
            "Epoch 82/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.5222 - accuracy: 0.3676 - val_loss: 1.4917 - val_accuracy: 0.3720\n",
            "Epoch 83/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.5224 - accuracy: 0.3694 - val_loss: 1.4714 - val_accuracy: 0.3961\n",
            "Epoch 84/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.5138 - accuracy: 0.3773 - val_loss: 1.4770 - val_accuracy: 0.4300\n",
            "Epoch 85/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.5136 - accuracy: 0.3585 - val_loss: 1.4496 - val_accuracy: 0.4589\n",
            "Epoch 86/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.5252 - accuracy: 0.3827 - val_loss: 1.4775 - val_accuracy: 0.4203\n",
            "Epoch 87/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.5074 - accuracy: 0.3628 - val_loss: 1.4535 - val_accuracy: 0.4541\n",
            "Epoch 88/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.4943 - accuracy: 0.3990 - val_loss: 1.4688 - val_accuracy: 0.4396\n",
            "Epoch 89/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.4850 - accuracy: 0.3851 - val_loss: 1.4436 - val_accuracy: 0.4493\n",
            "Epoch 90/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.4947 - accuracy: 0.3748 - val_loss: 1.4559 - val_accuracy: 0.4058\n",
            "Epoch 91/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.4936 - accuracy: 0.3803 - val_loss: 1.4239 - val_accuracy: 0.4734\n",
            "Epoch 92/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.4863 - accuracy: 0.3797 - val_loss: 1.4341 - val_accuracy: 0.4251\n",
            "Epoch 93/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.4813 - accuracy: 0.4008 - val_loss: 1.4305 - val_accuracy: 0.4493\n",
            "Epoch 94/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.4608 - accuracy: 0.4015 - val_loss: 1.4330 - val_accuracy: 0.4686\n",
            "Epoch 95/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.4719 - accuracy: 0.3724 - val_loss: 1.4348 - val_accuracy: 0.3816\n",
            "Epoch 96/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.4781 - accuracy: 0.3960 - val_loss: 1.4188 - val_accuracy: 0.4444\n",
            "Epoch 97/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.4680 - accuracy: 0.3869 - val_loss: 1.4295 - val_accuracy: 0.3865\n",
            "Epoch 98/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.4602 - accuracy: 0.4015 - val_loss: 1.4010 - val_accuracy: 0.4783\n",
            "Epoch 99/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.4552 - accuracy: 0.3978 - val_loss: 1.4088 - val_accuracy: 0.4348\n",
            "Epoch 100/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.4544 - accuracy: 0.3936 - val_loss: 1.4077 - val_accuracy: 0.4300\n",
            "Epoch 101/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.4445 - accuracy: 0.4172 - val_loss: 1.3857 - val_accuracy: 0.4831\n",
            "Epoch 102/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.4484 - accuracy: 0.4027 - val_loss: 1.4073 - val_accuracy: 0.4734\n",
            "Epoch 103/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.4396 - accuracy: 0.4057 - val_loss: 1.3917 - val_accuracy: 0.4831\n",
            "Epoch 104/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.4554 - accuracy: 0.4129 - val_loss: 1.3907 - val_accuracy: 0.4638\n",
            "Epoch 105/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.4359 - accuracy: 0.4087 - val_loss: 1.3867 - val_accuracy: 0.4686\n",
            "Epoch 106/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.4296 - accuracy: 0.4160 - val_loss: 1.3826 - val_accuracy: 0.4686\n",
            "Epoch 107/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.4166 - accuracy: 0.4172 - val_loss: 1.3833 - val_accuracy: 0.4444\n",
            "Epoch 108/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.4126 - accuracy: 0.4238 - val_loss: 1.3677 - val_accuracy: 0.4831\n",
            "Epoch 109/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.4249 - accuracy: 0.4099 - val_loss: 1.3678 - val_accuracy: 0.4879\n",
            "Epoch 110/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.4273 - accuracy: 0.4208 - val_loss: 1.3610 - val_accuracy: 0.4734\n",
            "Epoch 111/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.3960 - accuracy: 0.4335 - val_loss: 1.3759 - val_accuracy: 0.4831\n",
            "Epoch 112/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.4023 - accuracy: 0.4190 - val_loss: 1.3563 - val_accuracy: 0.4783\n",
            "Epoch 113/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.3989 - accuracy: 0.4281 - val_loss: 1.3395 - val_accuracy: 0.5121\n",
            "Epoch 114/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.3943 - accuracy: 0.4244 - val_loss: 1.3655 - val_accuracy: 0.4493\n",
            "Epoch 115/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.3765 - accuracy: 0.4395 - val_loss: 1.3333 - val_accuracy: 0.4976\n",
            "Epoch 116/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.3989 - accuracy: 0.4305 - val_loss: 1.3491 - val_accuracy: 0.4734\n",
            "Epoch 117/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.3693 - accuracy: 0.4347 - val_loss: 1.3250 - val_accuracy: 0.4928\n",
            "Epoch 118/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.3640 - accuracy: 0.4492 - val_loss: 1.3434 - val_accuracy: 0.4686\n",
            "Epoch 119/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.3661 - accuracy: 0.4468 - val_loss: 1.3325 - val_accuracy: 0.4686\n",
            "Epoch 120/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.3618 - accuracy: 0.4522 - val_loss: 1.3166 - val_accuracy: 0.5024\n",
            "Epoch 121/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.3678 - accuracy: 0.4456 - val_loss: 1.3273 - val_accuracy: 0.4879\n",
            "Epoch 122/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.3631 - accuracy: 0.4383 - val_loss: 1.3150 - val_accuracy: 0.5121\n",
            "Epoch 123/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.3530 - accuracy: 0.4492 - val_loss: 1.3246 - val_accuracy: 0.4928\n",
            "Epoch 124/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.3631 - accuracy: 0.4450 - val_loss: 1.3196 - val_accuracy: 0.5072\n",
            "Epoch 125/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.3443 - accuracy: 0.4577 - val_loss: 1.2925 - val_accuracy: 0.5024\n",
            "Epoch 126/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.3429 - accuracy: 0.4456 - val_loss: 1.3011 - val_accuracy: 0.4976\n",
            "Epoch 127/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.3511 - accuracy: 0.4649 - val_loss: 1.2853 - val_accuracy: 0.4976\n",
            "Epoch 128/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.3268 - accuracy: 0.4565 - val_loss: 1.2862 - val_accuracy: 0.5072\n",
            "Epoch 129/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.3355 - accuracy: 0.4528 - val_loss: 1.3015 - val_accuracy: 0.4638\n",
            "Epoch 130/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.3279 - accuracy: 0.4686 - val_loss: 1.2855 - val_accuracy: 0.4976\n",
            "Epoch 131/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.3536 - accuracy: 0.4577 - val_loss: 1.2937 - val_accuracy: 0.5217\n",
            "Epoch 132/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.3184 - accuracy: 0.4595 - val_loss: 1.2739 - val_accuracy: 0.5507\n",
            "Epoch 133/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.3043 - accuracy: 0.4553 - val_loss: 1.2774 - val_accuracy: 0.5169\n",
            "Epoch 134/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.3018 - accuracy: 0.4740 - val_loss: 1.2534 - val_accuracy: 0.5507\n",
            "Epoch 135/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.3253 - accuracy: 0.4547 - val_loss: 1.2491 - val_accuracy: 0.5266\n",
            "Epoch 136/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.2951 - accuracy: 0.4782 - val_loss: 1.2620 - val_accuracy: 0.5169\n",
            "Epoch 137/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.3023 - accuracy: 0.4788 - val_loss: 1.2531 - val_accuracy: 0.5459\n",
            "Epoch 138/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.3108 - accuracy: 0.4661 - val_loss: 1.2226 - val_accuracy: 0.5507\n",
            "Epoch 139/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.3099 - accuracy: 0.4746 - val_loss: 1.2406 - val_accuracy: 0.5556\n",
            "Epoch 140/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.2945 - accuracy: 0.4788 - val_loss: 1.2321 - val_accuracy: 0.5556\n",
            "Epoch 141/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.3070 - accuracy: 0.4565 - val_loss: 1.2403 - val_accuracy: 0.5556\n",
            "Epoch 142/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.2893 - accuracy: 0.4752 - val_loss: 1.2469 - val_accuracy: 0.5362\n",
            "Epoch 143/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.2999 - accuracy: 0.4831 - val_loss: 1.2331 - val_accuracy: 0.5507\n",
            "Epoch 144/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.2746 - accuracy: 0.4897 - val_loss: 1.2210 - val_accuracy: 0.5072\n",
            "Epoch 145/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.2795 - accuracy: 0.4861 - val_loss: 1.2249 - val_accuracy: 0.5314\n",
            "Epoch 146/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.2778 - accuracy: 0.4740 - val_loss: 1.2167 - val_accuracy: 0.5556\n",
            "Epoch 147/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.2687 - accuracy: 0.4752 - val_loss: 1.1981 - val_accuracy: 0.5507\n",
            "Epoch 148/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.2803 - accuracy: 0.4873 - val_loss: 1.2032 - val_accuracy: 0.5314\n",
            "Epoch 149/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.2755 - accuracy: 0.4825 - val_loss: 1.2025 - val_accuracy: 0.5507\n",
            "Epoch 150/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.2652 - accuracy: 0.4776 - val_loss: 1.1851 - val_accuracy: 0.5749\n",
            "Epoch 151/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.2646 - accuracy: 0.4867 - val_loss: 1.1962 - val_accuracy: 0.5749\n",
            "Epoch 152/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.2465 - accuracy: 0.4909 - val_loss: 1.1882 - val_accuracy: 0.5411\n",
            "Epoch 153/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.2498 - accuracy: 0.4873 - val_loss: 1.1813 - val_accuracy: 0.5845\n",
            "Epoch 154/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.2500 - accuracy: 0.4879 - val_loss: 1.1938 - val_accuracy: 0.5604\n",
            "Epoch 155/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.2674 - accuracy: 0.5012 - val_loss: 1.1940 - val_accuracy: 0.5700\n",
            "Epoch 156/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.2489 - accuracy: 0.4970 - val_loss: 1.1860 - val_accuracy: 0.5507\n",
            "Epoch 157/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.2717 - accuracy: 0.4728 - val_loss: 1.1729 - val_accuracy: 0.5556\n",
            "Epoch 158/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.2318 - accuracy: 0.4976 - val_loss: 1.1812 - val_accuracy: 0.5507\n",
            "Epoch 159/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.2524 - accuracy: 0.4861 - val_loss: 1.2003 - val_accuracy: 0.5121\n",
            "Epoch 160/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.2426 - accuracy: 0.5006 - val_loss: 1.1984 - val_accuracy: 0.5459\n",
            "Epoch 161/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.2543 - accuracy: 0.4770 - val_loss: 1.1835 - val_accuracy: 0.5556\n",
            "Epoch 162/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.2254 - accuracy: 0.5073 - val_loss: 1.1725 - val_accuracy: 0.5411\n",
            "Epoch 163/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.2357 - accuracy: 0.4970 - val_loss: 1.1787 - val_accuracy: 0.5556\n",
            "Epoch 164/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.2360 - accuracy: 0.4952 - val_loss: 1.1801 - val_accuracy: 0.5700\n",
            "Epoch 165/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.2493 - accuracy: 0.4831 - val_loss: 1.1622 - val_accuracy: 0.5700\n",
            "Epoch 166/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.2137 - accuracy: 0.5115 - val_loss: 1.1717 - val_accuracy: 0.5894\n",
            "Epoch 167/500\n",
            "104/104 [==============================] - 1s 9ms/step - loss: 1.2024 - accuracy: 0.5169 - val_loss: 1.1600 - val_accuracy: 0.5894\n",
            "Epoch 168/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 1.2122 - accuracy: 0.5073 - val_loss: 1.1648 - val_accuracy: 0.5411\n",
            "Epoch 169/500\n",
            "104/104 [==============================] - 1s 9ms/step - loss: 1.2182 - accuracy: 0.5054 - val_loss: 1.1557 - val_accuracy: 0.5894\n",
            "Epoch 170/500\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 1.2004 - accuracy: 0.5230 - val_loss: 1.1454 - val_accuracy: 0.5797\n",
            "Epoch 171/500\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 1.1912 - accuracy: 0.5151 - val_loss: 1.1420 - val_accuracy: 0.6039\n",
            "Epoch 172/500\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 1.2021 - accuracy: 0.5097 - val_loss: 1.1309 - val_accuracy: 0.5894\n",
            "Epoch 173/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.1985 - accuracy: 0.5175 - val_loss: 1.1627 - val_accuracy: 0.5459\n",
            "Epoch 174/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.2065 - accuracy: 0.5000 - val_loss: 1.1448 - val_accuracy: 0.5604\n",
            "Epoch 175/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.1914 - accuracy: 0.4988 - val_loss: 1.1287 - val_accuracy: 0.5797\n",
            "Epoch 176/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.2078 - accuracy: 0.5236 - val_loss: 1.1580 - val_accuracy: 0.5604\n",
            "Epoch 177/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 1.1737 - accuracy: 0.5187 - val_loss: 1.1349 - val_accuracy: 0.5652\n",
            "Epoch 178/500\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 1.1777 - accuracy: 0.5181 - val_loss: 1.1266 - val_accuracy: 0.5700\n",
            "Epoch 179/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 1.1631 - accuracy: 0.5296 - val_loss: 1.1341 - val_accuracy: 0.5797\n",
            "Epoch 180/500\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 1.2101 - accuracy: 0.5139 - val_loss: 1.1276 - val_accuracy: 0.5507\n",
            "Epoch 181/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 1.1694 - accuracy: 0.5314 - val_loss: 1.1290 - val_accuracy: 0.5797\n",
            "Epoch 182/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.1806 - accuracy: 0.5230 - val_loss: 1.1354 - val_accuracy: 0.5652\n",
            "Epoch 183/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.1496 - accuracy: 0.5429 - val_loss: 1.1288 - val_accuracy: 0.5459\n",
            "Epoch 184/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.1757 - accuracy: 0.5218 - val_loss: 1.1211 - val_accuracy: 0.5652\n",
            "Epoch 185/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.1621 - accuracy: 0.5290 - val_loss: 1.1212 - val_accuracy: 0.5507\n",
            "Epoch 186/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.1557 - accuracy: 0.5381 - val_loss: 1.1005 - val_accuracy: 0.6135\n",
            "Epoch 187/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.1618 - accuracy: 0.5290 - val_loss: 1.1383 - val_accuracy: 0.5700\n",
            "Epoch 188/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.1699 - accuracy: 0.5417 - val_loss: 1.1240 - val_accuracy: 0.5700\n",
            "Epoch 189/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.1682 - accuracy: 0.5266 - val_loss: 1.1156 - val_accuracy: 0.5652\n",
            "Epoch 190/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.1400 - accuracy: 0.5278 - val_loss: 1.1243 - val_accuracy: 0.5942\n",
            "Epoch 191/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.1349 - accuracy: 0.5423 - val_loss: 1.0968 - val_accuracy: 0.5845\n",
            "Epoch 192/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.1309 - accuracy: 0.5411 - val_loss: 1.1008 - val_accuracy: 0.6039\n",
            "Epoch 193/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.1236 - accuracy: 0.5526 - val_loss: 1.1079 - val_accuracy: 0.5700\n",
            "Epoch 194/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.1461 - accuracy: 0.5611 - val_loss: 1.1089 - val_accuracy: 0.5845\n",
            "Epoch 195/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.1537 - accuracy: 0.5333 - val_loss: 1.1024 - val_accuracy: 0.5942\n",
            "Epoch 196/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.1648 - accuracy: 0.5357 - val_loss: 1.0937 - val_accuracy: 0.6184\n",
            "Epoch 197/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.1184 - accuracy: 0.5453 - val_loss: 1.0987 - val_accuracy: 0.5700\n",
            "Epoch 198/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.1168 - accuracy: 0.5466 - val_loss: 1.0747 - val_accuracy: 0.6087\n",
            "Epoch 199/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.1267 - accuracy: 0.5387 - val_loss: 1.0918 - val_accuracy: 0.5845\n",
            "Epoch 200/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.1309 - accuracy: 0.5502 - val_loss: 1.0939 - val_accuracy: 0.5990\n",
            "Epoch 201/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.1099 - accuracy: 0.5441 - val_loss: 1.0926 - val_accuracy: 0.5990\n",
            "Epoch 202/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.1112 - accuracy: 0.5550 - val_loss: 1.0810 - val_accuracy: 0.5894\n",
            "Epoch 203/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.1325 - accuracy: 0.5411 - val_loss: 1.0879 - val_accuracy: 0.5942\n",
            "Epoch 204/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.1236 - accuracy: 0.5514 - val_loss: 1.0778 - val_accuracy: 0.5749\n",
            "Epoch 205/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.1103 - accuracy: 0.5544 - val_loss: 1.0722 - val_accuracy: 0.6039\n",
            "Epoch 206/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.1139 - accuracy: 0.5653 - val_loss: 1.0676 - val_accuracy: 0.6087\n",
            "Epoch 207/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0974 - accuracy: 0.5665 - val_loss: 1.0662 - val_accuracy: 0.5942\n",
            "Epoch 208/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.1007 - accuracy: 0.5629 - val_loss: 1.0666 - val_accuracy: 0.5942\n",
            "Epoch 209/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.1118 - accuracy: 0.5623 - val_loss: 1.0813 - val_accuracy: 0.5507\n",
            "Epoch 210/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0927 - accuracy: 0.5466 - val_loss: 1.0586 - val_accuracy: 0.5942\n",
            "Epoch 211/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0931 - accuracy: 0.5713 - val_loss: 1.0549 - val_accuracy: 0.6135\n",
            "Epoch 212/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0955 - accuracy: 0.5472 - val_loss: 1.0976 - val_accuracy: 0.5845\n",
            "Epoch 213/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0872 - accuracy: 0.5580 - val_loss: 1.0441 - val_accuracy: 0.6232\n",
            "Epoch 214/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.1006 - accuracy: 0.5526 - val_loss: 1.0683 - val_accuracy: 0.6184\n",
            "Epoch 215/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.0906 - accuracy: 0.5593 - val_loss: 1.0614 - val_accuracy: 0.6039\n",
            "Epoch 216/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.1060 - accuracy: 0.5478 - val_loss: 1.0649 - val_accuracy: 0.5990\n",
            "Epoch 217/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.1148 - accuracy: 0.5423 - val_loss: 1.0649 - val_accuracy: 0.6039\n",
            "Epoch 218/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.1026 - accuracy: 0.5502 - val_loss: 1.0688 - val_accuracy: 0.6087\n",
            "Epoch 219/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.0702 - accuracy: 0.5750 - val_loss: 1.0414 - val_accuracy: 0.6087\n",
            "Epoch 220/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.1065 - accuracy: 0.5387 - val_loss: 1.0365 - val_accuracy: 0.6039\n",
            "Epoch 221/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0785 - accuracy: 0.5804 - val_loss: 1.0407 - val_accuracy: 0.6087\n",
            "Epoch 222/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0920 - accuracy: 0.5750 - val_loss: 1.0543 - val_accuracy: 0.5942\n",
            "Epoch 223/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0726 - accuracy: 0.5611 - val_loss: 1.0444 - val_accuracy: 0.5797\n",
            "Epoch 224/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.0618 - accuracy: 0.5659 - val_loss: 1.0526 - val_accuracy: 0.6039\n",
            "Epoch 225/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.0980 - accuracy: 0.5635 - val_loss: 1.0435 - val_accuracy: 0.6184\n",
            "Epoch 226/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0869 - accuracy: 0.5629 - val_loss: 1.0438 - val_accuracy: 0.6280\n",
            "Epoch 227/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0627 - accuracy: 0.5701 - val_loss: 1.0401 - val_accuracy: 0.5942\n",
            "Epoch 228/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0486 - accuracy: 0.5822 - val_loss: 1.0254 - val_accuracy: 0.6232\n",
            "Epoch 229/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0688 - accuracy: 0.5726 - val_loss: 1.0228 - val_accuracy: 0.6280\n",
            "Epoch 230/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0507 - accuracy: 0.5774 - val_loss: 1.0406 - val_accuracy: 0.5990\n",
            "Epoch 231/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0733 - accuracy: 0.5683 - val_loss: 1.0178 - val_accuracy: 0.6377\n",
            "Epoch 232/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0596 - accuracy: 0.5744 - val_loss: 1.0290 - val_accuracy: 0.6039\n",
            "Epoch 233/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0635 - accuracy: 0.5774 - val_loss: 1.0053 - val_accuracy: 0.6329\n",
            "Epoch 234/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0381 - accuracy: 0.5901 - val_loss: 1.0249 - val_accuracy: 0.5894\n",
            "Epoch 235/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.0505 - accuracy: 0.5780 - val_loss: 1.0081 - val_accuracy: 0.6135\n",
            "Epoch 236/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0483 - accuracy: 0.5852 - val_loss: 1.0144 - val_accuracy: 0.6135\n",
            "Epoch 237/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0530 - accuracy: 0.5901 - val_loss: 1.0008 - val_accuracy: 0.6377\n",
            "Epoch 238/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0363 - accuracy: 0.5846 - val_loss: 1.0212 - val_accuracy: 0.5990\n",
            "Epoch 239/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.0444 - accuracy: 0.5762 - val_loss: 1.0182 - val_accuracy: 0.6329\n",
            "Epoch 240/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0409 - accuracy: 0.5834 - val_loss: 1.0096 - val_accuracy: 0.6377\n",
            "Epoch 241/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0255 - accuracy: 0.5816 - val_loss: 1.0194 - val_accuracy: 0.6039\n",
            "Epoch 242/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0477 - accuracy: 0.5822 - val_loss: 1.0144 - val_accuracy: 0.6232\n",
            "Epoch 243/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0307 - accuracy: 0.5925 - val_loss: 1.0184 - val_accuracy: 0.6087\n",
            "Epoch 244/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0108 - accuracy: 0.5949 - val_loss: 1.0029 - val_accuracy: 0.6377\n",
            "Epoch 245/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0193 - accuracy: 0.5883 - val_loss: 1.0060 - val_accuracy: 0.6232\n",
            "Epoch 246/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0307 - accuracy: 0.5895 - val_loss: 1.0163 - val_accuracy: 0.5990\n",
            "Epoch 247/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0066 - accuracy: 0.6088 - val_loss: 1.0056 - val_accuracy: 0.5942\n",
            "Epoch 248/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0311 - accuracy: 0.5943 - val_loss: 0.9969 - val_accuracy: 0.6522\n",
            "Epoch 249/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0285 - accuracy: 0.5798 - val_loss: 1.0105 - val_accuracy: 0.6232\n",
            "Epoch 250/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0284 - accuracy: 0.5859 - val_loss: 1.0067 - val_accuracy: 0.6329\n",
            "Epoch 251/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0070 - accuracy: 0.5973 - val_loss: 1.0195 - val_accuracy: 0.6184\n",
            "Epoch 252/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0159 - accuracy: 0.5931 - val_loss: 0.9838 - val_accuracy: 0.6329\n",
            "Epoch 253/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9958 - accuracy: 0.6010 - val_loss: 0.9870 - val_accuracy: 0.6329\n",
            "Epoch 254/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0240 - accuracy: 0.5895 - val_loss: 1.0043 - val_accuracy: 0.6039\n",
            "Epoch 255/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0123 - accuracy: 0.5895 - val_loss: 0.9746 - val_accuracy: 0.6522\n",
            "Epoch 256/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0249 - accuracy: 0.6119 - val_loss: 1.0075 - val_accuracy: 0.6135\n",
            "Epoch 257/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9991 - accuracy: 0.5925 - val_loss: 0.9825 - val_accuracy: 0.6232\n",
            "Epoch 258/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0044 - accuracy: 0.5949 - val_loss: 0.9855 - val_accuracy: 0.6280\n",
            "Epoch 259/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9977 - accuracy: 0.5895 - val_loss: 1.0046 - val_accuracy: 0.6087\n",
            "Epoch 260/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0082 - accuracy: 0.5889 - val_loss: 0.9841 - val_accuracy: 0.6473\n",
            "Epoch 261/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9895 - accuracy: 0.6076 - val_loss: 0.9863 - val_accuracy: 0.6039\n",
            "Epoch 262/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9849 - accuracy: 0.6040 - val_loss: 0.9739 - val_accuracy: 0.6473\n",
            "Epoch 263/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0024 - accuracy: 0.6016 - val_loss: 0.9748 - val_accuracy: 0.6715\n",
            "Epoch 264/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9824 - accuracy: 0.6028 - val_loss: 0.9889 - val_accuracy: 0.6232\n",
            "Epoch 265/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0158 - accuracy: 0.5931 - val_loss: 0.9793 - val_accuracy: 0.6280\n",
            "Epoch 266/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9881 - accuracy: 0.6028 - val_loss: 0.9607 - val_accuracy: 0.6377\n",
            "Epoch 267/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9767 - accuracy: 0.6191 - val_loss: 0.9639 - val_accuracy: 0.6522\n",
            "Epoch 268/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9868 - accuracy: 0.5985 - val_loss: 0.9616 - val_accuracy: 0.6618\n",
            "Epoch 269/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9964 - accuracy: 0.6016 - val_loss: 0.9732 - val_accuracy: 0.6570\n",
            "Epoch 270/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9867 - accuracy: 0.6131 - val_loss: 0.9677 - val_accuracy: 0.6280\n",
            "Epoch 271/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9867 - accuracy: 0.6094 - val_loss: 0.9803 - val_accuracy: 0.6135\n",
            "Epoch 272/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9766 - accuracy: 0.6185 - val_loss: 0.9536 - val_accuracy: 0.6618\n",
            "Epoch 273/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9862 - accuracy: 0.6106 - val_loss: 0.9470 - val_accuracy: 0.6667\n",
            "Epoch 274/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9819 - accuracy: 0.6082 - val_loss: 0.9719 - val_accuracy: 0.6425\n",
            "Epoch 275/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9723 - accuracy: 0.6137 - val_loss: 0.9639 - val_accuracy: 0.6377\n",
            "Epoch 276/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9559 - accuracy: 0.6131 - val_loss: 0.9730 - val_accuracy: 0.6473\n",
            "Epoch 277/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9670 - accuracy: 0.6082 - val_loss: 0.9590 - val_accuracy: 0.6522\n",
            "Epoch 278/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9483 - accuracy: 0.6276 - val_loss: 0.9642 - val_accuracy: 0.6618\n",
            "Epoch 279/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9908 - accuracy: 0.5919 - val_loss: 0.9802 - val_accuracy: 0.6425\n",
            "Epoch 280/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9793 - accuracy: 0.6100 - val_loss: 0.9842 - val_accuracy: 0.6280\n",
            "Epoch 281/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9646 - accuracy: 0.6167 - val_loss: 0.9817 - val_accuracy: 0.6135\n",
            "Epoch 282/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9624 - accuracy: 0.6336 - val_loss: 0.9567 - val_accuracy: 0.6812\n",
            "Epoch 283/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9629 - accuracy: 0.6227 - val_loss: 0.9618 - val_accuracy: 0.6473\n",
            "Epoch 284/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9441 - accuracy: 0.6167 - val_loss: 0.9529 - val_accuracy: 0.6522\n",
            "Epoch 285/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9655 - accuracy: 0.6276 - val_loss: 0.9595 - val_accuracy: 0.6377\n",
            "Epoch 286/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9592 - accuracy: 0.6088 - val_loss: 0.9478 - val_accuracy: 0.6425\n",
            "Epoch 287/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9637 - accuracy: 0.6100 - val_loss: 0.9407 - val_accuracy: 0.6522\n",
            "Epoch 288/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9508 - accuracy: 0.6179 - val_loss: 0.9441 - val_accuracy: 0.6715\n",
            "Epoch 289/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9622 - accuracy: 0.6221 - val_loss: 0.9623 - val_accuracy: 0.6329\n",
            "Epoch 290/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9468 - accuracy: 0.6264 - val_loss: 0.9422 - val_accuracy: 0.6667\n",
            "Epoch 291/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9434 - accuracy: 0.6306 - val_loss: 0.9452 - val_accuracy: 0.6425\n",
            "Epoch 292/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9517 - accuracy: 0.6264 - val_loss: 0.9548 - val_accuracy: 0.6570\n",
            "Epoch 293/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9655 - accuracy: 0.6076 - val_loss: 0.9513 - val_accuracy: 0.6280\n",
            "Epoch 294/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9503 - accuracy: 0.6131 - val_loss: 0.9467 - val_accuracy: 0.6570\n",
            "Epoch 295/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9349 - accuracy: 0.6324 - val_loss: 0.9368 - val_accuracy: 0.6570\n",
            "Epoch 296/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9155 - accuracy: 0.6324 - val_loss: 0.9446 - val_accuracy: 0.6715\n",
            "Epoch 297/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9381 - accuracy: 0.6324 - val_loss: 0.9318 - val_accuracy: 0.6763\n",
            "Epoch 298/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9420 - accuracy: 0.6282 - val_loss: 0.9383 - val_accuracy: 0.6715\n",
            "Epoch 299/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9341 - accuracy: 0.6215 - val_loss: 0.9526 - val_accuracy: 0.6618\n",
            "Epoch 300/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9351 - accuracy: 0.6040 - val_loss: 0.9224 - val_accuracy: 0.6763\n",
            "Epoch 301/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9498 - accuracy: 0.6185 - val_loss: 0.9319 - val_accuracy: 0.6763\n",
            "Epoch 302/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9491 - accuracy: 0.6276 - val_loss: 0.9336 - val_accuracy: 0.6715\n",
            "Epoch 303/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9369 - accuracy: 0.6191 - val_loss: 0.9439 - val_accuracy: 0.6522\n",
            "Epoch 304/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9206 - accuracy: 0.6306 - val_loss: 0.9462 - val_accuracy: 0.6667\n",
            "Epoch 305/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9197 - accuracy: 0.6439 - val_loss: 0.9306 - val_accuracy: 0.6812\n",
            "Epoch 306/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9397 - accuracy: 0.6270 - val_loss: 0.9132 - val_accuracy: 0.6763\n",
            "Epoch 307/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9478 - accuracy: 0.6191 - val_loss: 0.9254 - val_accuracy: 0.6715\n",
            "Epoch 308/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9296 - accuracy: 0.6348 - val_loss: 0.9218 - val_accuracy: 0.6473\n",
            "Epoch 309/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9206 - accuracy: 0.6366 - val_loss: 0.9391 - val_accuracy: 0.6618\n",
            "Epoch 310/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9151 - accuracy: 0.6318 - val_loss: 0.9144 - val_accuracy: 0.6715\n",
            "Epoch 311/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8959 - accuracy: 0.6397 - val_loss: 0.9148 - val_accuracy: 0.6715\n",
            "Epoch 312/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9243 - accuracy: 0.6258 - val_loss: 0.9174 - val_accuracy: 0.6812\n",
            "Epoch 313/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9077 - accuracy: 0.6427 - val_loss: 0.9212 - val_accuracy: 0.6522\n",
            "Epoch 314/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8974 - accuracy: 0.6457 - val_loss: 0.9289 - val_accuracy: 0.6425\n",
            "Epoch 315/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9317 - accuracy: 0.6421 - val_loss: 0.9206 - val_accuracy: 0.6667\n",
            "Epoch 316/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9025 - accuracy: 0.6505 - val_loss: 0.9302 - val_accuracy: 0.6425\n",
            "Epoch 317/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9277 - accuracy: 0.6378 - val_loss: 0.9126 - val_accuracy: 0.6763\n",
            "Epoch 318/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9050 - accuracy: 0.6372 - val_loss: 0.9306 - val_accuracy: 0.6522\n",
            "Epoch 319/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9116 - accuracy: 0.6421 - val_loss: 0.9307 - val_accuracy: 0.6425\n",
            "Epoch 320/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9165 - accuracy: 0.6294 - val_loss: 0.9317 - val_accuracy: 0.6570\n",
            "Epoch 321/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8999 - accuracy: 0.6421 - val_loss: 0.9121 - val_accuracy: 0.6763\n",
            "Epoch 322/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9057 - accuracy: 0.6457 - val_loss: 0.9010 - val_accuracy: 0.6957\n",
            "Epoch 323/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8845 - accuracy: 0.6318 - val_loss: 0.9205 - val_accuracy: 0.6908\n",
            "Epoch 324/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9003 - accuracy: 0.6415 - val_loss: 0.9103 - val_accuracy: 0.6667\n",
            "Epoch 325/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8974 - accuracy: 0.6397 - val_loss: 0.9084 - val_accuracy: 0.6860\n",
            "Epoch 326/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9130 - accuracy: 0.6354 - val_loss: 0.9332 - val_accuracy: 0.6522\n",
            "Epoch 327/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8813 - accuracy: 0.6542 - val_loss: 0.8935 - val_accuracy: 0.6812\n",
            "Epoch 328/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8756 - accuracy: 0.6475 - val_loss: 0.9187 - val_accuracy: 0.6522\n",
            "Epoch 329/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9005 - accuracy: 0.6475 - val_loss: 0.8990 - val_accuracy: 0.6763\n",
            "Epoch 330/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8744 - accuracy: 0.6626 - val_loss: 0.9002 - val_accuracy: 0.6763\n",
            "Epoch 331/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8763 - accuracy: 0.6475 - val_loss: 0.8996 - val_accuracy: 0.6812\n",
            "Epoch 332/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8822 - accuracy: 0.6511 - val_loss: 0.9003 - val_accuracy: 0.6860\n",
            "Epoch 333/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8745 - accuracy: 0.6481 - val_loss: 0.9076 - val_accuracy: 0.6715\n",
            "Epoch 334/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8712 - accuracy: 0.6578 - val_loss: 0.8948 - val_accuracy: 0.6908\n",
            "Epoch 335/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8864 - accuracy: 0.6536 - val_loss: 0.8918 - val_accuracy: 0.6908\n",
            "Epoch 336/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9143 - accuracy: 0.6342 - val_loss: 0.9016 - val_accuracy: 0.7005\n",
            "Epoch 337/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8726 - accuracy: 0.6620 - val_loss: 0.9001 - val_accuracy: 0.6812\n",
            "Epoch 338/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8859 - accuracy: 0.6421 - val_loss: 0.8847 - val_accuracy: 0.6860\n",
            "Epoch 339/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8611 - accuracy: 0.6626 - val_loss: 0.8883 - val_accuracy: 0.7101\n",
            "Epoch 340/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8837 - accuracy: 0.6409 - val_loss: 0.8871 - val_accuracy: 0.7005\n",
            "Epoch 341/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.8861 - accuracy: 0.6566 - val_loss: 0.8985 - val_accuracy: 0.6908\n",
            "Epoch 342/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8651 - accuracy: 0.6657 - val_loss: 0.8982 - val_accuracy: 0.6715\n",
            "Epoch 343/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8709 - accuracy: 0.6421 - val_loss: 0.9008 - val_accuracy: 0.6473\n",
            "Epoch 344/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8884 - accuracy: 0.6554 - val_loss: 0.8902 - val_accuracy: 0.6763\n",
            "Epoch 345/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8762 - accuracy: 0.6620 - val_loss: 0.8812 - val_accuracy: 0.7005\n",
            "Epoch 346/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8587 - accuracy: 0.6584 - val_loss: 0.8912 - val_accuracy: 0.6908\n",
            "Epoch 347/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8607 - accuracy: 0.6669 - val_loss: 0.8887 - val_accuracy: 0.7053\n",
            "Epoch 348/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8664 - accuracy: 0.6572 - val_loss: 0.8816 - val_accuracy: 0.7053\n",
            "Epoch 349/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8687 - accuracy: 0.6554 - val_loss: 0.8726 - val_accuracy: 0.6957\n",
            "Epoch 350/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8538 - accuracy: 0.6602 - val_loss: 0.8821 - val_accuracy: 0.6812\n",
            "Epoch 351/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8757 - accuracy: 0.6445 - val_loss: 0.9058 - val_accuracy: 0.6570\n",
            "Epoch 352/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8733 - accuracy: 0.6475 - val_loss: 0.8820 - val_accuracy: 0.7053\n",
            "Epoch 353/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8590 - accuracy: 0.6499 - val_loss: 0.8814 - val_accuracy: 0.7005\n",
            "Epoch 354/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8606 - accuracy: 0.6578 - val_loss: 0.8705 - val_accuracy: 0.6812\n",
            "Epoch 355/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8558 - accuracy: 0.6602 - val_loss: 0.8885 - val_accuracy: 0.6618\n",
            "Epoch 356/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8532 - accuracy: 0.6644 - val_loss: 0.8718 - val_accuracy: 0.7150\n",
            "Epoch 357/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8431 - accuracy: 0.6638 - val_loss: 0.8579 - val_accuracy: 0.7198\n",
            "Epoch 358/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8390 - accuracy: 0.6765 - val_loss: 0.8712 - val_accuracy: 0.6715\n",
            "Epoch 359/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8822 - accuracy: 0.6487 - val_loss: 0.8888 - val_accuracy: 0.6860\n",
            "Epoch 360/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8424 - accuracy: 0.6675 - val_loss: 0.8702 - val_accuracy: 0.6957\n",
            "Epoch 361/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8280 - accuracy: 0.6778 - val_loss: 0.8652 - val_accuracy: 0.7101\n",
            "Epoch 362/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8492 - accuracy: 0.6681 - val_loss: 0.8531 - val_accuracy: 0.7005\n",
            "Epoch 363/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8251 - accuracy: 0.6693 - val_loss: 0.8582 - val_accuracy: 0.7005\n",
            "Epoch 364/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8349 - accuracy: 0.6699 - val_loss: 0.8629 - val_accuracy: 0.7150\n",
            "Epoch 365/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8305 - accuracy: 0.6723 - val_loss: 0.8580 - val_accuracy: 0.6812\n",
            "Epoch 366/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8574 - accuracy: 0.6638 - val_loss: 0.8611 - val_accuracy: 0.6763\n",
            "Epoch 367/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8426 - accuracy: 0.6675 - val_loss: 0.8565 - val_accuracy: 0.7053\n",
            "Epoch 368/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8414 - accuracy: 0.6644 - val_loss: 0.8573 - val_accuracy: 0.7053\n",
            "Epoch 369/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8423 - accuracy: 0.6554 - val_loss: 0.8619 - val_accuracy: 0.6957\n",
            "Epoch 370/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8302 - accuracy: 0.6687 - val_loss: 0.8631 - val_accuracy: 0.6860\n",
            "Epoch 371/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8404 - accuracy: 0.6644 - val_loss: 0.8514 - val_accuracy: 0.7150\n",
            "Epoch 372/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8296 - accuracy: 0.6765 - val_loss: 0.8676 - val_accuracy: 0.6763\n",
            "Epoch 373/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8330 - accuracy: 0.6729 - val_loss: 0.8561 - val_accuracy: 0.6812\n",
            "Epoch 374/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8344 - accuracy: 0.6651 - val_loss: 0.8738 - val_accuracy: 0.6425\n",
            "Epoch 375/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8400 - accuracy: 0.6584 - val_loss: 0.8699 - val_accuracy: 0.6812\n",
            "Epoch 376/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8454 - accuracy: 0.6644 - val_loss: 0.8735 - val_accuracy: 0.6957\n",
            "Epoch 377/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8296 - accuracy: 0.6844 - val_loss: 0.8614 - val_accuracy: 0.6908\n",
            "Epoch 378/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8269 - accuracy: 0.6808 - val_loss: 0.8661 - val_accuracy: 0.6957\n",
            "Epoch 379/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8538 - accuracy: 0.6548 - val_loss: 0.8624 - val_accuracy: 0.7005\n",
            "Epoch 380/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8328 - accuracy: 0.6753 - val_loss: 0.8643 - val_accuracy: 0.6860\n",
            "Epoch 381/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8225 - accuracy: 0.6832 - val_loss: 0.8502 - val_accuracy: 0.6957\n",
            "Epoch 382/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8272 - accuracy: 0.6759 - val_loss: 0.8835 - val_accuracy: 0.6522\n",
            "Epoch 383/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8344 - accuracy: 0.6626 - val_loss: 0.8658 - val_accuracy: 0.7005\n",
            "Epoch 384/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8314 - accuracy: 0.6687 - val_loss: 0.8906 - val_accuracy: 0.6763\n",
            "Epoch 385/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8264 - accuracy: 0.6790 - val_loss: 0.8690 - val_accuracy: 0.6763\n",
            "Epoch 386/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.8179 - accuracy: 0.6753 - val_loss: 0.8542 - val_accuracy: 0.7101\n",
            "Epoch 387/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8146 - accuracy: 0.6771 - val_loss: 0.8827 - val_accuracy: 0.6715\n",
            "Epoch 388/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8085 - accuracy: 0.6729 - val_loss: 0.8561 - val_accuracy: 0.7053\n",
            "Epoch 389/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8138 - accuracy: 0.6771 - val_loss: 0.8622 - val_accuracy: 0.6860\n",
            "Epoch 390/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8221 - accuracy: 0.6759 - val_loss: 0.8412 - val_accuracy: 0.6957\n",
            "Epoch 391/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8190 - accuracy: 0.6771 - val_loss: 0.8653 - val_accuracy: 0.6812\n",
            "Epoch 392/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8204 - accuracy: 0.6832 - val_loss: 0.8477 - val_accuracy: 0.6908\n",
            "Epoch 393/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8096 - accuracy: 0.6717 - val_loss: 0.8559 - val_accuracy: 0.6812\n",
            "Epoch 394/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7948 - accuracy: 0.6935 - val_loss: 0.8327 - val_accuracy: 0.7101\n",
            "Epoch 395/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8041 - accuracy: 0.6826 - val_loss: 0.8510 - val_accuracy: 0.6957\n",
            "Epoch 396/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8133 - accuracy: 0.6796 - val_loss: 0.8578 - val_accuracy: 0.7005\n",
            "Epoch 397/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7964 - accuracy: 0.6856 - val_loss: 0.8601 - val_accuracy: 0.6957\n",
            "Epoch 398/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7896 - accuracy: 0.7007 - val_loss: 0.8700 - val_accuracy: 0.6473\n",
            "Epoch 399/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7959 - accuracy: 0.6856 - val_loss: 0.8198 - val_accuracy: 0.7005\n",
            "Epoch 400/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7958 - accuracy: 0.6826 - val_loss: 0.8507 - val_accuracy: 0.6908\n",
            "Epoch 401/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7674 - accuracy: 0.6911 - val_loss: 0.8194 - val_accuracy: 0.6957\n",
            "Epoch 402/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8150 - accuracy: 0.6784 - val_loss: 0.8474 - val_accuracy: 0.7053\n",
            "Epoch 403/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7743 - accuracy: 0.6977 - val_loss: 0.8254 - val_accuracy: 0.6957\n",
            "Epoch 404/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8146 - accuracy: 0.6669 - val_loss: 0.8327 - val_accuracy: 0.6860\n",
            "Epoch 405/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.7972 - accuracy: 0.6917 - val_loss: 0.8325 - val_accuracy: 0.7198\n",
            "Epoch 406/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7857 - accuracy: 0.6904 - val_loss: 0.8304 - val_accuracy: 0.6908\n",
            "Epoch 407/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7942 - accuracy: 0.6838 - val_loss: 0.8317 - val_accuracy: 0.7150\n",
            "Epoch 408/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8154 - accuracy: 0.6850 - val_loss: 0.8236 - val_accuracy: 0.7295\n",
            "Epoch 409/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7906 - accuracy: 0.6880 - val_loss: 0.8309 - val_accuracy: 0.6715\n",
            "Epoch 410/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7712 - accuracy: 0.6953 - val_loss: 0.8188 - val_accuracy: 0.7101\n",
            "Epoch 411/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7882 - accuracy: 0.6862 - val_loss: 0.8499 - val_accuracy: 0.6473\n",
            "Epoch 412/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8014 - accuracy: 0.6965 - val_loss: 0.8310 - val_accuracy: 0.6860\n",
            "Epoch 413/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7826 - accuracy: 0.6886 - val_loss: 0.8278 - val_accuracy: 0.6715\n",
            "Epoch 414/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7962 - accuracy: 0.6802 - val_loss: 0.8536 - val_accuracy: 0.6377\n",
            "Epoch 415/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8049 - accuracy: 0.6711 - val_loss: 0.8423 - val_accuracy: 0.6957\n",
            "Epoch 416/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7698 - accuracy: 0.6971 - val_loss: 0.8355 - val_accuracy: 0.6812\n",
            "Epoch 417/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7747 - accuracy: 0.6923 - val_loss: 0.8361 - val_accuracy: 0.6957\n",
            "Epoch 418/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7789 - accuracy: 0.6778 - val_loss: 0.8409 - val_accuracy: 0.6763\n",
            "Epoch 419/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7541 - accuracy: 0.6959 - val_loss: 0.8186 - val_accuracy: 0.7295\n",
            "Epoch 420/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7802 - accuracy: 0.6904 - val_loss: 0.8233 - val_accuracy: 0.7005\n",
            "Epoch 421/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7679 - accuracy: 0.6953 - val_loss: 0.8296 - val_accuracy: 0.6860\n",
            "Epoch 422/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7859 - accuracy: 0.6814 - val_loss: 0.8340 - val_accuracy: 0.6860\n",
            "Epoch 423/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.7846 - accuracy: 0.6904 - val_loss: 0.8316 - val_accuracy: 0.6908\n",
            "Epoch 424/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7733 - accuracy: 0.6856 - val_loss: 0.8282 - val_accuracy: 0.6860\n",
            "Epoch 425/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7586 - accuracy: 0.6995 - val_loss: 0.8213 - val_accuracy: 0.7005\n",
            "Epoch 426/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7792 - accuracy: 0.6898 - val_loss: 0.8289 - val_accuracy: 0.6957\n",
            "Epoch 427/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8080 - accuracy: 0.6759 - val_loss: 0.8213 - val_accuracy: 0.7101\n",
            "Epoch 428/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7629 - accuracy: 0.6989 - val_loss: 0.8151 - val_accuracy: 0.7101\n",
            "Epoch 429/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7761 - accuracy: 0.6995 - val_loss: 0.8041 - val_accuracy: 0.7246\n",
            "Epoch 430/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7639 - accuracy: 0.6995 - val_loss: 0.8200 - val_accuracy: 0.6957\n",
            "Epoch 431/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7779 - accuracy: 0.6989 - val_loss: 0.8248 - val_accuracy: 0.7053\n",
            "Epoch 432/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7712 - accuracy: 0.6947 - val_loss: 0.8304 - val_accuracy: 0.7198\n",
            "Epoch 433/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7632 - accuracy: 0.7062 - val_loss: 0.8369 - val_accuracy: 0.6812\n",
            "Epoch 434/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7791 - accuracy: 0.6923 - val_loss: 0.8278 - val_accuracy: 0.7053\n",
            "Epoch 435/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7643 - accuracy: 0.6917 - val_loss: 0.8281 - val_accuracy: 0.6908\n",
            "Epoch 436/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7596 - accuracy: 0.7031 - val_loss: 0.8387 - val_accuracy: 0.6860\n",
            "Epoch 437/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7777 - accuracy: 0.6947 - val_loss: 0.8337 - val_accuracy: 0.7053\n",
            "Epoch 438/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7720 - accuracy: 0.6917 - val_loss: 0.8247 - val_accuracy: 0.7005\n",
            "Epoch 439/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7483 - accuracy: 0.7025 - val_loss: 0.8304 - val_accuracy: 0.6957\n",
            "Epoch 440/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7944 - accuracy: 0.6814 - val_loss: 0.8303 - val_accuracy: 0.7198\n",
            "Epoch 441/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7704 - accuracy: 0.6874 - val_loss: 0.8360 - val_accuracy: 0.6667\n",
            "Epoch 442/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7803 - accuracy: 0.6959 - val_loss: 0.8164 - val_accuracy: 0.6860\n",
            "Epoch 443/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7591 - accuracy: 0.7013 - val_loss: 0.8205 - val_accuracy: 0.6908\n",
            "Epoch 444/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7623 - accuracy: 0.6989 - val_loss: 0.8157 - val_accuracy: 0.7150\n",
            "Epoch 445/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7653 - accuracy: 0.6904 - val_loss: 0.8018 - val_accuracy: 0.7101\n",
            "Epoch 446/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7632 - accuracy: 0.6935 - val_loss: 0.8151 - val_accuracy: 0.6908\n",
            "Epoch 447/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.7453 - accuracy: 0.7080 - val_loss: 0.8084 - val_accuracy: 0.6860\n",
            "Epoch 448/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7476 - accuracy: 0.6917 - val_loss: 0.8114 - val_accuracy: 0.6957\n",
            "Epoch 449/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7399 - accuracy: 0.7092 - val_loss: 0.8220 - val_accuracy: 0.6957\n",
            "Epoch 450/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7488 - accuracy: 0.6953 - val_loss: 0.8043 - val_accuracy: 0.6957\n",
            "Epoch 451/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7483 - accuracy: 0.7080 - val_loss: 0.8029 - val_accuracy: 0.7150\n",
            "Epoch 452/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7261 - accuracy: 0.7134 - val_loss: 0.8129 - val_accuracy: 0.7101\n",
            "Epoch 453/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7579 - accuracy: 0.7050 - val_loss: 0.7990 - val_accuracy: 0.7053\n",
            "Epoch 454/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7397 - accuracy: 0.7213 - val_loss: 0.8036 - val_accuracy: 0.7391\n",
            "Epoch 455/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7518 - accuracy: 0.7013 - val_loss: 0.8083 - val_accuracy: 0.7246\n",
            "Epoch 456/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7307 - accuracy: 0.7110 - val_loss: 0.8142 - val_accuracy: 0.7005\n",
            "Epoch 457/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7486 - accuracy: 0.6983 - val_loss: 0.8050 - val_accuracy: 0.7150\n",
            "Epoch 458/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7375 - accuracy: 0.7050 - val_loss: 0.8022 - val_accuracy: 0.7295\n",
            "Epoch 459/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7341 - accuracy: 0.7134 - val_loss: 0.8031 - val_accuracy: 0.6860\n",
            "Epoch 460/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.7517 - accuracy: 0.6911 - val_loss: 0.8140 - val_accuracy: 0.7005\n",
            "Epoch 461/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7263 - accuracy: 0.7158 - val_loss: 0.8076 - val_accuracy: 0.6957\n",
            "Epoch 462/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.7351 - accuracy: 0.7007 - val_loss: 0.8237 - val_accuracy: 0.6908\n",
            "Epoch 463/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7377 - accuracy: 0.7092 - val_loss: 0.8301 - val_accuracy: 0.6860\n",
            "Epoch 464/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.7346 - accuracy: 0.7098 - val_loss: 0.8150 - val_accuracy: 0.6908\n",
            "Epoch 465/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7438 - accuracy: 0.7116 - val_loss: 0.8021 - val_accuracy: 0.7005\n",
            "Epoch 466/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7632 - accuracy: 0.6826 - val_loss: 0.8049 - val_accuracy: 0.6812\n",
            "Epoch 467/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7188 - accuracy: 0.7146 - val_loss: 0.8225 - val_accuracy: 0.6570\n",
            "Epoch 468/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7393 - accuracy: 0.7128 - val_loss: 0.8126 - val_accuracy: 0.6812\n",
            "Epoch 469/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7323 - accuracy: 0.7134 - val_loss: 0.7930 - val_accuracy: 0.7246\n",
            "Epoch 470/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.7230 - accuracy: 0.7092 - val_loss: 0.8011 - val_accuracy: 0.7005\n",
            "Epoch 471/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.7226 - accuracy: 0.7164 - val_loss: 0.8021 - val_accuracy: 0.7101\n",
            "Epoch 472/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7335 - accuracy: 0.7092 - val_loss: 0.8096 - val_accuracy: 0.6860\n",
            "Epoch 473/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.7224 - accuracy: 0.7044 - val_loss: 0.8083 - val_accuracy: 0.6812\n",
            "Epoch 474/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7107 - accuracy: 0.7110 - val_loss: 0.8007 - val_accuracy: 0.7198\n",
            "Epoch 475/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7117 - accuracy: 0.7056 - val_loss: 0.7755 - val_accuracy: 0.7101\n",
            "Epoch 476/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.7275 - accuracy: 0.7134 - val_loss: 0.7861 - val_accuracy: 0.7005\n",
            "Epoch 477/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7248 - accuracy: 0.7152 - val_loss: 0.8042 - val_accuracy: 0.6860\n",
            "Epoch 478/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7370 - accuracy: 0.7225 - val_loss: 0.8123 - val_accuracy: 0.6812\n",
            "Epoch 479/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7218 - accuracy: 0.7195 - val_loss: 0.8057 - val_accuracy: 0.6957\n",
            "Epoch 480/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7332 - accuracy: 0.7189 - val_loss: 0.8119 - val_accuracy: 0.6763\n",
            "Epoch 481/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7241 - accuracy: 0.7158 - val_loss: 0.7911 - val_accuracy: 0.6908\n",
            "Epoch 482/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7131 - accuracy: 0.7128 - val_loss: 0.7885 - val_accuracy: 0.7101\n",
            "Epoch 483/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7343 - accuracy: 0.7110 - val_loss: 0.8013 - val_accuracy: 0.7053\n",
            "Epoch 484/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.7280 - accuracy: 0.7189 - val_loss: 0.8304 - val_accuracy: 0.6715\n",
            "Epoch 485/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7156 - accuracy: 0.7207 - val_loss: 0.7955 - val_accuracy: 0.7295\n",
            "Epoch 486/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7169 - accuracy: 0.7225 - val_loss: 0.7933 - val_accuracy: 0.7150\n",
            "Epoch 487/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7168 - accuracy: 0.7213 - val_loss: 0.7945 - val_accuracy: 0.6908\n",
            "Epoch 488/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7040 - accuracy: 0.7291 - val_loss: 0.7898 - val_accuracy: 0.7101\n",
            "Epoch 489/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7125 - accuracy: 0.7025 - val_loss: 0.7962 - val_accuracy: 0.6957\n",
            "Epoch 490/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.7155 - accuracy: 0.7231 - val_loss: 0.8018 - val_accuracy: 0.6908\n",
            "Epoch 491/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.7364 - accuracy: 0.7207 - val_loss: 0.7816 - val_accuracy: 0.7150\n",
            "Epoch 492/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.7242 - accuracy: 0.7237 - val_loss: 0.7823 - val_accuracy: 0.7005\n",
            "Epoch 493/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7018 - accuracy: 0.7219 - val_loss: 0.8006 - val_accuracy: 0.6957\n",
            "Epoch 494/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7026 - accuracy: 0.7273 - val_loss: 0.7889 - val_accuracy: 0.6957\n",
            "Epoch 495/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7141 - accuracy: 0.7249 - val_loss: 0.8099 - val_accuracy: 0.6860\n",
            "Epoch 496/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7185 - accuracy: 0.7177 - val_loss: 0.7887 - val_accuracy: 0.7246\n",
            "Epoch 497/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7469 - accuracy: 0.7007 - val_loss: 0.7978 - val_accuracy: 0.6957\n",
            "Epoch 498/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7033 - accuracy: 0.7285 - val_loss: 0.8033 - val_accuracy: 0.7005\n",
            "Epoch 499/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7101 - accuracy: 0.7158 - val_loss: 0.8141 - val_accuracy: 0.6667\n",
            "Epoch 500/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7299 - accuracy: 0.7056 - val_loss: 0.8127 - val_accuracy: 0.7005\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(cnnhistory.history['loss'])\n",
        "plt.plot(cnnhistory.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train','test'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "oQYnuaCrDH_A",
        "outputId": "fb88a1e9-73d1-4778-9862-8836efab341d"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(cnnhistory.history['accuracy'])\n",
        "plt.plot(cnnhistory.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train','test'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "IFkTuO8nDNdq",
        "outputId": "ca5b08c5-6b79-4c23-d987-b36fb2ad09e4"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#predictions = model.predict_classes(x_testcnn)\n",
        "predictions = model.predict(x_testcnn)"
      ],
      "metadata": {
        "id": "A2xtrN5wDQgY"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_f_ohjXKDUpY",
        "outputId": "525914ed-0363-468b-f184-27fdbb6a9565"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[9.4453210e-04, 5.4121279e-04, 5.6306511e-02, 3.3903938e-02,\n",
              "        3.0966913e-02, 8.7733692e-01],\n",
              "       [1.2123181e-01, 6.5883386e-01, 8.0423787e-02, 6.7805342e-02,\n",
              "        2.5972595e-02, 4.5732565e-02],\n",
              "       [6.5230350e-05, 4.5736548e-03, 8.7787259e-01, 2.5060500e-03,\n",
              "        8.3951302e-02, 3.1031191e-02],\n",
              "       ...,\n",
              "       [2.8099468e-02, 1.2191996e-03, 1.5913999e-02, 4.5832761e-02,\n",
              "        6.3320380e-01, 2.7573076e-01],\n",
              "       [7.1584441e-02, 4.7539271e-02, 5.4103352e-02, 5.4771030e-01,\n",
              "        1.4261686e-02, 2.6480094e-01],\n",
              "       [1.8827081e-01, 1.7608345e-01, 1.5167679e-01, 1.1295052e-01,\n",
              "        3.3223999e-01, 3.8778424e-02]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cmA2bFgsDW3D",
        "outputId": "53dbefea-f279-423f-b43b-2500b46989b0"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5, 1, 2, 5, 3, 4, 2, 0, 3, 1, 3, 2, 1, 4, 3, 0, 5, 0, 2, 5, 0, 0,\n",
              "       1, 3, 2, 3, 2, 5, 4, 2, 2, 3, 1, 2, 5, 5, 3, 5, 3, 3, 4, 1, 3, 2,\n",
              "       3, 1, 5, 3, 1, 2, 4, 4, 5, 5, 5, 1, 2, 3, 2, 5, 0, 2, 4, 2, 5, 4,\n",
              "       3, 0, 1, 2, 5, 2, 1, 2, 4, 5, 4, 1, 5, 5, 3, 1, 5, 3, 2, 4, 2, 5,\n",
              "       0, 5, 0, 5, 4, 0, 2, 4, 0, 2, 2, 0, 2, 3, 5, 3, 5, 5, 3, 1, 2, 2,\n",
              "       2, 1, 3, 2, 1, 3, 4, 4, 1, 1, 2, 4, 4, 1, 4, 2, 0, 4, 5, 5, 3, 1,\n",
              "       2, 1, 5, 5, 1, 2, 3, 3, 0, 3, 3, 0, 1, 0, 1, 2, 1, 5, 1, 2, 2, 0,\n",
              "       1, 1, 1, 1, 1, 4, 0, 1, 5, 1, 4, 5, 5, 4, 1, 0, 3, 5, 2, 3, 0, 4,\n",
              "       1, 3, 1, 0, 5, 5, 3, 5, 4, 5, 4, 0, 4, 1, 2, 1, 5, 0, 4, 3, 2, 1,\n",
              "       0, 3, 5, 0, 4, 5, 4, 5, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_Ytest = y_test.astype(int)"
      ],
      "metadata": {
        "id": "0PHDKWJWDY3g"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_Ytest"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k68v2i-pDbZE",
        "outputId": "7bceb6eb-9b89-4051-e4c1-bdb90b412fee"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5, 1, 2, 5, 3, 4, 2, 0, 3, 1, 3, 2, 1, 4, 3, 0, 5, 0, 2, 5, 0, 0,\n",
              "       1, 3, 2, 3, 2, 5, 4, 2, 2, 3, 1, 2, 5, 5, 3, 5, 3, 3, 4, 1, 3, 2,\n",
              "       3, 1, 5, 3, 1, 2, 4, 4, 5, 5, 5, 1, 2, 3, 2, 5, 0, 2, 4, 2, 5, 4,\n",
              "       3, 0, 1, 2, 5, 2, 1, 2, 4, 5, 4, 1, 5, 5, 3, 1, 5, 3, 2, 4, 2, 5,\n",
              "       0, 5, 0, 5, 4, 0, 2, 4, 0, 2, 2, 0, 2, 3, 5, 3, 5, 5, 3, 1, 2, 2,\n",
              "       2, 1, 3, 2, 1, 3, 4, 4, 1, 1, 2, 4, 4, 1, 4, 2, 0, 4, 5, 5, 3, 1,\n",
              "       2, 1, 5, 5, 1, 2, 3, 3, 0, 3, 3, 0, 1, 0, 1, 2, 1, 5, 1, 2, 2, 0,\n",
              "       1, 1, 1, 1, 1, 4, 0, 1, 5, 1, 4, 5, 5, 4, 1, 0, 3, 5, 2, 3, 0, 4,\n",
              "       1, 3, 1, 0, 5, 5, 3, 5, 4, 5, 4, 0, 4, 1, 2, 1, 5, 0, 4, 3, 2, 1,\n",
              "       0, 3, 5, 0, 4, 5, 4, 5, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds1=predictions.argmax(axis=1)\n",
        "preds1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4_cAI39VFhtp",
        "outputId": "19c6f577-d9cf-4696-b07a-7f18c7378e2f"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5, 1, 2, 5, 0, 4, 2, 0, 3, 1, 3, 2, 1, 4, 3, 0, 5, 1, 2, 5, 3, 1,\n",
              "       1, 3, 2, 3, 2, 0, 2, 4, 2, 3, 1, 2, 5, 4, 1, 5, 3, 2, 3, 1, 2, 2,\n",
              "       3, 1, 3, 3, 1, 3, 4, 4, 5, 3, 3, 1, 2, 3, 2, 5, 0, 2, 2, 4, 5, 4,\n",
              "       2, 1, 0, 2, 5, 2, 1, 1, 4, 3, 4, 3, 5, 2, 3, 2, 5, 3, 2, 4, 2, 3,\n",
              "       0, 5, 0, 3, 4, 0, 3, 4, 3, 2, 2, 1, 2, 1, 0, 3, 5, 5, 5, 1, 2, 2,\n",
              "       2, 1, 3, 2, 1, 4, 4, 4, 1, 0, 2, 4, 4, 1, 4, 2, 3, 4, 3, 5, 5, 1,\n",
              "       1, 1, 2, 4, 1, 3, 3, 3, 0, 3, 3, 0, 0, 0, 1, 2, 0, 5, 1, 2, 4, 0,\n",
              "       1, 1, 1, 1, 0, 4, 0, 1, 5, 0, 5, 5, 4, 2, 1, 0, 5, 3, 2, 3, 3, 4,\n",
              "       1, 3, 1, 0, 5, 2, 3, 3, 4, 3, 4, 1, 3, 1, 2, 1, 3, 0, 4, 1, 2, 1,\n",
              "       1, 4, 5, 0, 5, 5, 4, 3, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "abc = preds1.astype(int).flatten()"
      ],
      "metadata": {
        "id": "H4WEmM60NfQn"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "c = confusion_matrix(new_Ytest, abc) \n",
        "c"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bKEBeEBlFjB8",
        "outputId": "bb6024a9-e7a9-4e63-cc3a-39b5e52657fd"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[15,  6,  0,  4,  0,  0],\n",
              "       [ 6, 31,  1,  1,  0,  0],\n",
              "       [ 0,  2, 30,  3,  3,  0],\n",
              "       [ 1,  3,  3, 21,  2,  3],\n",
              "       [ 0,  0,  3,  2, 23,  2],\n",
              "       [ 2,  0,  3, 12,  3, 22]])"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m4RjG7LWLSQx",
        "outputId": "bc78fafc-50c0-4567-85fb-45e40d65ee4b"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5, 1, 2, 5, 3, 4, 2, 0, 3, 1, 3, 2, 1, 4, 3, 0, 5, 0, 2, 5, 0, 0,\n",
              "       1, 3, 2, 3, 2, 5, 4, 2, 2, 3, 1, 2, 5, 5, 3, 5, 3, 3, 4, 1, 3, 2,\n",
              "       3, 1, 5, 3, 1, 2, 4, 4, 5, 5, 5, 1, 2, 3, 2, 5, 0, 2, 4, 2, 5, 4,\n",
              "       3, 0, 1, 2, 5, 2, 1, 2, 4, 5, 4, 1, 5, 5, 3, 1, 5, 3, 2, 4, 2, 5,\n",
              "       0, 5, 0, 5, 4, 0, 2, 4, 0, 2, 2, 0, 2, 3, 5, 3, 5, 5, 3, 1, 2, 2,\n",
              "       2, 1, 3, 2, 1, 3, 4, 4, 1, 1, 2, 4, 4, 1, 4, 2, 0, 4, 5, 5, 3, 1,\n",
              "       2, 1, 5, 5, 1, 2, 3, 3, 0, 3, 3, 0, 1, 0, 1, 2, 1, 5, 1, 2, 2, 0,\n",
              "       1, 1, 1, 1, 1, 4, 0, 1, 5, 1, 4, 5, 5, 4, 1, 0, 3, 5, 2, 3, 0, 4,\n",
              "       1, 3, 1, 0, 5, 5, 3, 5, 4, 5, 4, 0, 4, 1, 2, 1, 5, 0, 4, 3, 2, 1,\n",
              "       0, 3, 5, 0, 4, 5, 4, 5, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('/content/drive/MyDrive/model2')\n",
        "print(\"MODEL SAVED\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lsJBNeMWDl6Z",
        "outputId": "8335b8f8-9e3c-47f8-db10-05d4c02ee8e5"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/model2/assets\n",
            "MODEL SAVED\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_model=keras.models.load_model('/content/drive/MyDrive/model2')\n",
        "new_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q3KjaO9GDoNl",
        "outputId": "72f3fb09-78d2-42a3-bdd3-33279ad44d23"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d (Conv1D)             (None, 40, 128)           1152      \n",
            "                                                                 \n",
            " activation (Activation)     (None, 40, 128)           0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 40, 128)           0         \n",
            "                                                                 \n",
            " max_pooling1d (MaxPooling1D  (None, 8, 128)           0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv1d_1 (Conv1D)           (None, 8, 256)            262400    \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 8, 256)            0         \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 8, 256)            0         \n",
            "                                                                 \n",
            " max_pooling1d_1 (MaxPooling  (None, 1, 256)           0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 256)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 256)               65792     \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 256)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 256)               65792     \n",
            "                                                                 \n",
            " activation_3 (Activation)   (None, 256)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 6)                 1542      \n",
            "                                                                 \n",
            " activation_4 (Activation)   (None, 6)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 396,678\n",
            "Trainable params: 396,678\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss, acc =model.evaluate(x_testcnn, y_test)\n",
        "print(\"Restored model, accuracy: {:5.2f}%\".format(100*acc))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n3kzoqPkDqqS",
        "outputId": "ba00c6b3-52f4-4186-fc6e-2290c91126e2"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7/7 [==============================] - 0s 3ms/step - loss: 0.7819 - accuracy: 0.6860\n",
            "Restored model, accuracy: 68.60%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss, acc =model.evaluate(X_train, y_train)\n",
        "print(\"Restored model train, accuracy: {:5.2f}%\".format(100*acc))"
      ],
      "metadata": {
        "id": "fJDTGH_OUX0z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "171a5ecc-c6aa-4ef1-9306-18ba99363992"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "52/52 [==============================] - 0s 4ms/step - loss: 0.6293 - accuracy: 0.8083\n",
            "Restored model train, accuracy: 80.83%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix,accuracy_score\n",
        "import seaborn as sn\n",
        "\n",
        "print(classification_report(new_Ytest,abc))\n",
        "\n",
        "acc = float(accuracy_score(new_Ytest,abc))*100\n",
        "print(\"----accuracy score %s ----\" % acc)\n",
        "\n",
        "cm = confusion_matrix(new_Ytest,abc)\n",
        "#df_cm = pd.DataFrame(cm)\n",
        "class_names = ['neutral','calm', 'happy','sad','angry', 'fearful' ]\n",
        "df_cm = pd.DataFrame(cm, index=class_names, columns=class_names,)\n",
        "sn.heatmap(df_cm, annot=True, fmt='')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 508
        },
        "id": "SfSC3El94LZg",
        "outputId": "91958ebc-6be8-4720-c87f-b2fe363c1af9"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.62      0.60      0.61        25\n",
            "           1       0.74      0.79      0.77        39\n",
            "           2       0.75      0.79      0.77        38\n",
            "           3       0.49      0.64      0.55        33\n",
            "           4       0.74      0.77      0.75        30\n",
            "           5       0.81      0.52      0.64        42\n",
            "\n",
            "    accuracy                           0.69       207\n",
            "   macro avg       0.69      0.69      0.68       207\n",
            "weighted avg       0.70      0.69      0.69       207\n",
            "\n",
            "----accuracy score 68.59903381642512 ----\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}