{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "original_rms_0.00002_without decay_1000_1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9SRCO-a_AlH5",
        "outputId": "1d36f44b-ef9f-461d-9a8b-9a2681d7d0e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install librosa"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Lo4mUwG9RMd",
        "outputId": "5433d296-d2b0-4099-fb2f-81e5566bd917"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.7/dist-packages (0.8.1)\n",
            "Requirement already satisfied: soundfile>=0.10.2 in /usr/local/lib/python3.7/dist-packages (from librosa) (0.10.3.post1)\n",
            "Requirement already satisfied: audioread>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (2.1.9)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.1.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.21.6)\n",
            "Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.6.0)\n",
            "Requirement already satisfied: numba>=0.43.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (0.51.2)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.0.2)\n",
            "Requirement already satisfied: resampy>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from librosa) (0.2.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (21.3)\n",
            "Requirement already satisfied: decorator>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba>=0.43.0->librosa) (0.34.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba>=0.43.0->librosa) (57.4.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->librosa) (3.0.9)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from pooch>=1.0->librosa) (2.23.0)\n",
            "Requirement already satisfied: appdirs>=1.3.0 in /usr/local/lib/python3.7/dist-packages (from pooch>=1.0->librosa) (1.4.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2022.5.18.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2.10)\n",
            "Requirement already satisfied: six>=1.3 in /usr/local/lib/python3.7/dist-packages (from resampy>=0.2.2->librosa) (1.15.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn!=0.19.0,>=0.14.0->librosa) (3.1.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.7/dist-packages (from soundfile>=0.10.2->librosa) (1.15.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.0->soundfile>=0.10.2->librosa) (2.21)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HJjcbxwy46bG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "4194d72e-98b5-427a-f835-23bc6f820e6d"
      },
      "source": [
        "# Orignial Notebook: https://github.com/MITESHPUTHRANNEU/Speech-Emotion-Analyzer/blob/master/final_results_gender_test.ipynb\n",
        "# This notebook author: Reza Chu\n",
        "# Last Editing Date: 31st May 2019\n",
        "\n",
        "## Python\n",
        "import os\n",
        "import random\n",
        "import sys\n",
        "\n",
        "import IPython\n",
        "from IPython.display import Audio\n",
        "from IPython.display import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "## Package\n",
        "import glob \n",
        "import keras\n",
        "import IPython.display as ipd\n",
        "import librosa\n",
        "import librosa.display\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import plotly.graph_objs as go\n",
        "import plotly.offline as py\n",
        "import plotly.tools as tls\n",
        "import seaborn as sns\n",
        "import scipy.io.wavfile\n",
        "import tensorflow as tf\n",
        "py.init_notebook_mode(connected=True)\n",
        "\n",
        "## Keras\n",
        "from keras import regularizers\n",
        "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping\n",
        "from keras.callbacks import  History, ReduceLROnPlateau, CSVLogger\n",
        "from keras.models import Model, Sequential\n",
        "from keras.layers import Dense, Embedding, LSTM\n",
        "from keras.layers import Input, Flatten, Dropout, Activation, BatchNormalization\n",
        "from keras.layers import Conv1D, MaxPooling1D, AveragePooling1D\n",
        "from keras.preprocessing import sequence\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.utils import np_utils\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "## Sklearn\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "## Rest\n",
        "from scipy.fftpack import fft\n",
        "from scipy import signal\n",
        "from scipy.io import wavfile\n",
        "from tqdm import tqdm\n",
        "\n",
        "input_duration=3\n",
        "# % pylab inline"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "        <script type=\"text/javascript\">\n",
              "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
              "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
              "        if (typeof require !== 'undefined') {\n",
              "        require.undef(\"plotly\");\n",
              "        requirejs.config({\n",
              "            paths: {\n",
              "                'plotly': ['https://cdn.plot.ly/plotly-2.8.3.min']\n",
              "            }\n",
              "        });\n",
              "        require(['plotly'], function(Plotly) {\n",
              "            window._Plotly = Plotly;\n",
              "        });\n",
              "        }\n",
              "        </script>\n",
              "        "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Saving joblib files to not load them again with the loop above\n",
        "\n",
        "# import joblib\n",
        "\n",
        "# X_name = 'x.joblib'\n",
        "# y_name = 'y.joblib'\n",
        "# save_dir = '/content/drive/My Drive/graduation project/audio/paper_code/features'\n",
        "\n",
        "# savedX = joblib.dump(X, os.path.join(save_dir, X_name))\n",
        "# savedy = joblib.dump(y, os.path.join(save_dir, y_name))"
      ],
      "metadata": {
        "id": "UCzic8rlDcuk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Loading saved models\n",
        "import joblib\n",
        "X = joblib.load('/content/drive/My Drive/graduation project/audio/paper_code/features/x.joblib')\n",
        "y = joblib.load('/content/drive/My Drive/graduation project/audio/paper_code/features/y.joblib')"
      ],
      "metadata": {
        "id": "Q35CN6zDrzg1"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7PSTurzjCo5K",
        "outputId": "5a1052e7-7a5f-45f1-b877-01690fe1298f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2068, 40)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.1 ,shuffle = True\n",
        "                                                    , random_state=42)\n",
        "X_train , X_valid, y_train, y_valid = train_test_split(X_train,y_train, test_size=0.1112305212 , shuffle = True \n",
        "                                                       , random_state=42)"
      ],
      "metadata": {
        "id": "Ai4Fy5cPCiq1"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "x_traincnn = np.expand_dims(X_train, axis=2)\n",
        "x_testcnn = np.expand_dims(X_test, axis=2)\n",
        "X_valid= np.expand_dims(X_valid, axis=2)"
      ],
      "metadata": {
        "id": "tp1Fm5K3CEXu"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_traincnn.shape, x_testcnn.shape , X_valid.shape\n",
        "#1861"
      ],
      "metadata": {
        "id": "RI0MxoIPBws5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2bb41abc-80a1-4df4-a0ba-6cc35c4a41f0"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1654, 40, 1), (207, 40, 1), (207, 40, 1))"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oALhiMUd9G2Y",
        "outputId": "030c8553-d577-4414-a37e-e4f7ab161da5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (2.8.2+zzzcolab20220527125636)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (4.2.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.46.3)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.0.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.26.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.5.3)\n",
            "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n",
            "Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.17.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow) (57.4.0)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (14.0.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.21.6)\n",
            "Requirement already satisfied: tensorflow-estimator<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow) (1.5.2)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.8.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (3.3.7)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.23.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.6.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.4.6)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.35.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (4.11.4)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (3.8.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2022.5.18.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (3.2.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from keras.preprocessing import sequence\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from keras.layers import Input, Flatten, Dropout, Activation\n",
        "from keras.layers import Conv1D, MaxPooling1D\n",
        "from keras.models import Model\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras import optimizers\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv1D(128, 8,padding='same', #classifier.add(Convolution2D(64, (3, 3), padding = 'same', input_shape = (128, 128, 3), activation = 'relu'))\n",
        "                 input_shape=(40,1)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(MaxPooling1D(pool_size=(5)))\n",
        "\n",
        "\n",
        "model.add(Conv1D(256,8,padding='same',))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(MaxPooling1D(pool_size=(5)))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(256))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(256))\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "model.add(Dense(6))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "opt = tf.keras.optimizers.RMSprop(lr=0.00002 , decay=0.0)\n",
        "#opt = tf.keras.optimizers.RMSprop(lr=0.0001, rho=0.9, epsilon=1e-07, decay=0.0)\n",
        "#opt = tf.keras.optimizers.SGD(lr=0.001, momentum=0.0, decay=0.0, nesterov=False)"
      ],
      "metadata": {
        "id": "g74fXWVAC4Cr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e410dcd3-896e-41c2-dd58-32db583f3dd7"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/rmsprop.py:130: UserWarning:\n",
            "\n",
            "The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H6ukOxAGC_I4",
        "outputId": "049b0e2e-900a-4211-d6aa-386cce6b6ff5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d (Conv1D)             (None, 40, 128)           1152      \n",
            "                                                                 \n",
            " activation (Activation)     (None, 40, 128)           0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 40, 128)           0         \n",
            "                                                                 \n",
            " max_pooling1d (MaxPooling1D  (None, 8, 128)           0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv1d_1 (Conv1D)           (None, 8, 256)            262400    \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 8, 256)            0         \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 8, 256)            0         \n",
            "                                                                 \n",
            " max_pooling1d_1 (MaxPooling  (None, 1, 256)           0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 256)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 256)               65792     \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 256)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 256)               65792     \n",
            "                                                                 \n",
            " activation_3 (Activation)   (None, 256)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 6)                 1542      \n",
            "                                                                 \n",
            " activation_4 (Activation)   (None, 6)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 396,678\n",
            "Trainable params: 396,678\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='sparse_categorical_crossentropy',\n",
        "              optimizer=opt,\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "AbMlLNk4DCBM"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an Instance of Early Stopping Callback.\n",
        "early_stopping_callback = EarlyStopping(monitor = 'val_loss', patience = 25, mode = 'min', restore_best_weights = True)\n",
        "\n",
        "cnnhistory=model.fit(x_traincnn, y_train, batch_size=16, epochs=1000 , shuffle = True, \n",
        "                     validation_data=(X_valid, y_valid) , callbacks = [early_stopping_callback])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RI1v2AuADFhy",
        "outputId": "e289db95-de17-4033-cd10-cf872d8a94df"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "104/104 [==============================] - 12s 7ms/step - loss: 5.7561 - accuracy: 0.1663 - val_loss: 2.2692 - val_accuracy: 0.1498\n",
            "Epoch 2/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 4.5580 - accuracy: 0.1765 - val_loss: 2.1389 - val_accuracy: 0.1643\n",
            "Epoch 3/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 4.0424 - accuracy: 0.1862 - val_loss: 1.9111 - val_accuracy: 0.1546\n",
            "Epoch 4/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 3.5261 - accuracy: 0.1929 - val_loss: 1.9381 - val_accuracy: 0.2029\n",
            "Epoch 5/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 3.1646 - accuracy: 0.2110 - val_loss: 1.8314 - val_accuracy: 0.2222\n",
            "Epoch 6/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 2.9008 - accuracy: 0.2080 - val_loss: 1.8690 - val_accuracy: 0.2077\n",
            "Epoch 7/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 2.8047 - accuracy: 0.1898 - val_loss: 1.7444 - val_accuracy: 0.2609\n",
            "Epoch 8/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 2.6052 - accuracy: 0.2225 - val_loss: 1.7530 - val_accuracy: 0.2802\n",
            "Epoch 9/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 2.5298 - accuracy: 0.2062 - val_loss: 1.7915 - val_accuracy: 0.2415\n",
            "Epoch 10/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 2.4261 - accuracy: 0.2177 - val_loss: 1.8134 - val_accuracy: 0.2415\n",
            "Epoch 11/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 2.3624 - accuracy: 0.2050 - val_loss: 1.7809 - val_accuracy: 0.2754\n",
            "Epoch 12/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 2.2385 - accuracy: 0.2328 - val_loss: 1.7100 - val_accuracy: 0.2222\n",
            "Epoch 13/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 2.2127 - accuracy: 0.2237 - val_loss: 1.7420 - val_accuracy: 0.2560\n",
            "Epoch 14/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 2.1461 - accuracy: 0.2213 - val_loss: 1.7152 - val_accuracy: 0.2512\n",
            "Epoch 15/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 2.1067 - accuracy: 0.2243 - val_loss: 1.7008 - val_accuracy: 0.2415\n",
            "Epoch 16/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 2.0853 - accuracy: 0.2195 - val_loss: 1.7049 - val_accuracy: 0.2947\n",
            "Epoch 17/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 2.0446 - accuracy: 0.2322 - val_loss: 1.6923 - val_accuracy: 0.2802\n",
            "Epoch 18/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.9741 - accuracy: 0.2473 - val_loss: 1.7251 - val_accuracy: 0.2850\n",
            "Epoch 19/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 2.0113 - accuracy: 0.2261 - val_loss: 1.6916 - val_accuracy: 0.3382\n",
            "Epoch 20/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.9558 - accuracy: 0.2467 - val_loss: 1.6953 - val_accuracy: 0.2367\n",
            "Epoch 21/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.9491 - accuracy: 0.2376 - val_loss: 1.6858 - val_accuracy: 0.3527\n",
            "Epoch 22/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.9357 - accuracy: 0.2358 - val_loss: 1.6634 - val_accuracy: 0.3575\n",
            "Epoch 23/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.8944 - accuracy: 0.2418 - val_loss: 1.6887 - val_accuracy: 0.2754\n",
            "Epoch 24/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.8947 - accuracy: 0.2430 - val_loss: 1.6828 - val_accuracy: 0.2705\n",
            "Epoch 25/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.8714 - accuracy: 0.2430 - val_loss: 1.6761 - val_accuracy: 0.2657\n",
            "Epoch 26/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.8570 - accuracy: 0.2551 - val_loss: 1.6810 - val_accuracy: 0.2271\n",
            "Epoch 27/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.8780 - accuracy: 0.2340 - val_loss: 1.6871 - val_accuracy: 0.2802\n",
            "Epoch 28/1000\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 1.8234 - accuracy: 0.2715 - val_loss: 1.6615 - val_accuracy: 0.3140\n",
            "Epoch 29/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 1.8374 - accuracy: 0.2606 - val_loss: 1.6640 - val_accuracy: 0.2802\n",
            "Epoch 30/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 1.8241 - accuracy: 0.2630 - val_loss: 1.6672 - val_accuracy: 0.3092\n",
            "Epoch 31/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 1.7876 - accuracy: 0.2660 - val_loss: 1.6685 - val_accuracy: 0.3527\n",
            "Epoch 32/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.7931 - accuracy: 0.2588 - val_loss: 1.6526 - val_accuracy: 0.3285\n",
            "Epoch 33/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.7846 - accuracy: 0.2690 - val_loss: 1.6679 - val_accuracy: 0.3043\n",
            "Epoch 34/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.7704 - accuracy: 0.2654 - val_loss: 1.6592 - val_accuracy: 0.3478\n",
            "Epoch 35/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.7710 - accuracy: 0.2545 - val_loss: 1.6404 - val_accuracy: 0.3768\n",
            "Epoch 36/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.7776 - accuracy: 0.2709 - val_loss: 1.6320 - val_accuracy: 0.3816\n",
            "Epoch 37/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.7314 - accuracy: 0.2781 - val_loss: 1.6470 - val_accuracy: 0.2754\n",
            "Epoch 38/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.7587 - accuracy: 0.2823 - val_loss: 1.6528 - val_accuracy: 0.3237\n",
            "Epoch 39/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.7467 - accuracy: 0.2805 - val_loss: 1.6428 - val_accuracy: 0.3382\n",
            "Epoch 40/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.7564 - accuracy: 0.2733 - val_loss: 1.6264 - val_accuracy: 0.3913\n",
            "Epoch 41/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.7307 - accuracy: 0.2721 - val_loss: 1.6394 - val_accuracy: 0.3816\n",
            "Epoch 42/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.7402 - accuracy: 0.2817 - val_loss: 1.6190 - val_accuracy: 0.3527\n",
            "Epoch 43/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.7213 - accuracy: 0.2860 - val_loss: 1.6195 - val_accuracy: 0.3527\n",
            "Epoch 44/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.7204 - accuracy: 0.2914 - val_loss: 1.6115 - val_accuracy: 0.4058\n",
            "Epoch 45/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.7015 - accuracy: 0.2866 - val_loss: 1.6048 - val_accuracy: 0.4106\n",
            "Epoch 46/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.7283 - accuracy: 0.2866 - val_loss: 1.6313 - val_accuracy: 0.3961\n",
            "Epoch 47/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.7060 - accuracy: 0.3023 - val_loss: 1.6005 - val_accuracy: 0.3816\n",
            "Epoch 48/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.6797 - accuracy: 0.3162 - val_loss: 1.6011 - val_accuracy: 0.3961\n",
            "Epoch 49/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.6740 - accuracy: 0.3132 - val_loss: 1.6201 - val_accuracy: 0.3043\n",
            "Epoch 50/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.6883 - accuracy: 0.2914 - val_loss: 1.6296 - val_accuracy: 0.3043\n",
            "Epoch 51/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.6418 - accuracy: 0.3186 - val_loss: 1.6057 - val_accuracy: 0.3961\n",
            "Epoch 52/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.6808 - accuracy: 0.3216 - val_loss: 1.5824 - val_accuracy: 0.3768\n",
            "Epoch 53/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.6402 - accuracy: 0.3331 - val_loss: 1.5756 - val_accuracy: 0.3720\n",
            "Epoch 54/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.6728 - accuracy: 0.3138 - val_loss: 1.5876 - val_accuracy: 0.3478\n",
            "Epoch 55/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.6508 - accuracy: 0.3265 - val_loss: 1.5730 - val_accuracy: 0.3865\n",
            "Epoch 56/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.6528 - accuracy: 0.3295 - val_loss: 1.5667 - val_accuracy: 0.4155\n",
            "Epoch 57/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.6262 - accuracy: 0.3452 - val_loss: 1.5812 - val_accuracy: 0.3575\n",
            "Epoch 58/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.6326 - accuracy: 0.3283 - val_loss: 1.5653 - val_accuracy: 0.3961\n",
            "Epoch 59/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.6326 - accuracy: 0.3301 - val_loss: 1.5595 - val_accuracy: 0.4010\n",
            "Epoch 60/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.6096 - accuracy: 0.3283 - val_loss: 1.5873 - val_accuracy: 0.3478\n",
            "Epoch 61/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.6156 - accuracy: 0.3307 - val_loss: 1.5471 - val_accuracy: 0.3913\n",
            "Epoch 62/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.6132 - accuracy: 0.3192 - val_loss: 1.5556 - val_accuracy: 0.4203\n",
            "Epoch 63/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.6014 - accuracy: 0.3428 - val_loss: 1.5270 - val_accuracy: 0.4300\n",
            "Epoch 64/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.6052 - accuracy: 0.3362 - val_loss: 1.5517 - val_accuracy: 0.3527\n",
            "Epoch 65/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.6064 - accuracy: 0.3513 - val_loss: 1.5375 - val_accuracy: 0.3816\n",
            "Epoch 66/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.5802 - accuracy: 0.3271 - val_loss: 1.5430 - val_accuracy: 0.3720\n",
            "Epoch 67/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.5635 - accuracy: 0.3670 - val_loss: 1.5010 - val_accuracy: 0.4976\n",
            "Epoch 68/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.5780 - accuracy: 0.3525 - val_loss: 1.5413 - val_accuracy: 0.4155\n",
            "Epoch 69/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.5874 - accuracy: 0.3476 - val_loss: 1.4926 - val_accuracy: 0.4589\n",
            "Epoch 70/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.5288 - accuracy: 0.3851 - val_loss: 1.5015 - val_accuracy: 0.4396\n",
            "Epoch 71/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.5516 - accuracy: 0.3585 - val_loss: 1.4998 - val_accuracy: 0.4155\n",
            "Epoch 72/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.5567 - accuracy: 0.3622 - val_loss: 1.4984 - val_accuracy: 0.4348\n",
            "Epoch 73/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.5608 - accuracy: 0.3622 - val_loss: 1.4840 - val_accuracy: 0.4589\n",
            "Epoch 74/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.5546 - accuracy: 0.3470 - val_loss: 1.4854 - val_accuracy: 0.4348\n",
            "Epoch 75/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.5362 - accuracy: 0.3567 - val_loss: 1.5018 - val_accuracy: 0.4348\n",
            "Epoch 76/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.5563 - accuracy: 0.3603 - val_loss: 1.4785 - val_accuracy: 0.4638\n",
            "Epoch 77/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.4910 - accuracy: 0.3906 - val_loss: 1.4854 - val_accuracy: 0.4734\n",
            "Epoch 78/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.5278 - accuracy: 0.3779 - val_loss: 1.4688 - val_accuracy: 0.4348\n",
            "Epoch 79/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.4911 - accuracy: 0.4033 - val_loss: 1.4659 - val_accuracy: 0.4686\n",
            "Epoch 80/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.5074 - accuracy: 0.3694 - val_loss: 1.4415 - val_accuracy: 0.5121\n",
            "Epoch 81/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.5224 - accuracy: 0.3640 - val_loss: 1.4570 - val_accuracy: 0.4638\n",
            "Epoch 82/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.5093 - accuracy: 0.3875 - val_loss: 1.4380 - val_accuracy: 0.4589\n",
            "Epoch 83/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.5116 - accuracy: 0.3815 - val_loss: 1.4510 - val_accuracy: 0.4493\n",
            "Epoch 84/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.5152 - accuracy: 0.3888 - val_loss: 1.4498 - val_accuracy: 0.4203\n",
            "Epoch 85/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.4863 - accuracy: 0.3869 - val_loss: 1.4350 - val_accuracy: 0.4928\n",
            "Epoch 86/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.4943 - accuracy: 0.3809 - val_loss: 1.4401 - val_accuracy: 0.4783\n",
            "Epoch 87/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.4665 - accuracy: 0.3972 - val_loss: 1.4166 - val_accuracy: 0.5024\n",
            "Epoch 88/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.4833 - accuracy: 0.3888 - val_loss: 1.4239 - val_accuracy: 0.4493\n",
            "Epoch 89/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.4720 - accuracy: 0.4002 - val_loss: 1.4133 - val_accuracy: 0.4493\n",
            "Epoch 90/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.4622 - accuracy: 0.4208 - val_loss: 1.4060 - val_accuracy: 0.4638\n",
            "Epoch 91/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.4849 - accuracy: 0.3881 - val_loss: 1.4156 - val_accuracy: 0.4589\n",
            "Epoch 92/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.4511 - accuracy: 0.4063 - val_loss: 1.4113 - val_accuracy: 0.5024\n",
            "Epoch 93/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.4256 - accuracy: 0.4281 - val_loss: 1.4070 - val_accuracy: 0.4783\n",
            "Epoch 94/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.4486 - accuracy: 0.4129 - val_loss: 1.3999 - val_accuracy: 0.4928\n",
            "Epoch 95/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.4211 - accuracy: 0.4299 - val_loss: 1.3805 - val_accuracy: 0.5072\n",
            "Epoch 96/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.4368 - accuracy: 0.4141 - val_loss: 1.3703 - val_accuracy: 0.4734\n",
            "Epoch 97/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.4226 - accuracy: 0.4178 - val_loss: 1.3683 - val_accuracy: 0.4831\n",
            "Epoch 98/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.4269 - accuracy: 0.4172 - val_loss: 1.3642 - val_accuracy: 0.5072\n",
            "Epoch 99/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.4137 - accuracy: 0.4293 - val_loss: 1.3644 - val_accuracy: 0.5072\n",
            "Epoch 100/1000\n",
            "104/104 [==============================] - 1s 9ms/step - loss: 1.4186 - accuracy: 0.4299 - val_loss: 1.3821 - val_accuracy: 0.4493\n",
            "Epoch 101/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 1.4030 - accuracy: 0.4281 - val_loss: 1.3495 - val_accuracy: 0.4976\n",
            "Epoch 102/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 1.4178 - accuracy: 0.4244 - val_loss: 1.3578 - val_accuracy: 0.5024\n",
            "Epoch 103/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 1.4034 - accuracy: 0.4232 - val_loss: 1.3500 - val_accuracy: 0.4879\n",
            "Epoch 104/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.4180 - accuracy: 0.4305 - val_loss: 1.3467 - val_accuracy: 0.5072\n",
            "Epoch 105/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.3965 - accuracy: 0.4238 - val_loss: 1.3397 - val_accuracy: 0.5169\n",
            "Epoch 106/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.3980 - accuracy: 0.4468 - val_loss: 1.3551 - val_accuracy: 0.4879\n",
            "Epoch 107/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.3659 - accuracy: 0.4426 - val_loss: 1.3276 - val_accuracy: 0.5024\n",
            "Epoch 108/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.3793 - accuracy: 0.4329 - val_loss: 1.3261 - val_accuracy: 0.5072\n",
            "Epoch 109/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.3812 - accuracy: 0.4341 - val_loss: 1.3303 - val_accuracy: 0.5314\n",
            "Epoch 110/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.3790 - accuracy: 0.4395 - val_loss: 1.3538 - val_accuracy: 0.4686\n",
            "Epoch 111/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.3908 - accuracy: 0.4311 - val_loss: 1.3309 - val_accuracy: 0.5217\n",
            "Epoch 112/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.3611 - accuracy: 0.4414 - val_loss: 1.3232 - val_accuracy: 0.5217\n",
            "Epoch 113/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.3535 - accuracy: 0.4414 - val_loss: 1.3139 - val_accuracy: 0.4638\n",
            "Epoch 114/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.3545 - accuracy: 0.4516 - val_loss: 1.3095 - val_accuracy: 0.5072\n",
            "Epoch 115/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.3421 - accuracy: 0.4559 - val_loss: 1.2979 - val_accuracy: 0.5411\n",
            "Epoch 116/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.3460 - accuracy: 0.4607 - val_loss: 1.3033 - val_accuracy: 0.5314\n",
            "Epoch 117/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.3484 - accuracy: 0.4450 - val_loss: 1.3089 - val_accuracy: 0.5362\n",
            "Epoch 118/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.3105 - accuracy: 0.4547 - val_loss: 1.2804 - val_accuracy: 0.5411\n",
            "Epoch 119/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.3266 - accuracy: 0.4607 - val_loss: 1.2807 - val_accuracy: 0.5411\n",
            "Epoch 120/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.3200 - accuracy: 0.4788 - val_loss: 1.2924 - val_accuracy: 0.5217\n",
            "Epoch 121/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.3266 - accuracy: 0.4613 - val_loss: 1.2928 - val_accuracy: 0.5266\n",
            "Epoch 122/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.3069 - accuracy: 0.4698 - val_loss: 1.2650 - val_accuracy: 0.5314\n",
            "Epoch 123/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.2990 - accuracy: 0.4843 - val_loss: 1.2631 - val_accuracy: 0.5362\n",
            "Epoch 124/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.3171 - accuracy: 0.4764 - val_loss: 1.2550 - val_accuracy: 0.5556\n",
            "Epoch 125/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.3060 - accuracy: 0.4752 - val_loss: 1.2610 - val_accuracy: 0.5217\n",
            "Epoch 126/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.3033 - accuracy: 0.4667 - val_loss: 1.2527 - val_accuracy: 0.5362\n",
            "Epoch 127/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.2961 - accuracy: 0.4940 - val_loss: 1.2480 - val_accuracy: 0.5459\n",
            "Epoch 128/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.2870 - accuracy: 0.4770 - val_loss: 1.2415 - val_accuracy: 0.5217\n",
            "Epoch 129/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.3109 - accuracy: 0.4631 - val_loss: 1.2512 - val_accuracy: 0.5507\n",
            "Epoch 130/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.2645 - accuracy: 0.5000 - val_loss: 1.2343 - val_accuracy: 0.5507\n",
            "Epoch 131/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.2807 - accuracy: 0.4927 - val_loss: 1.2279 - val_accuracy: 0.5652\n",
            "Epoch 132/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.2698 - accuracy: 0.4849 - val_loss: 1.2310 - val_accuracy: 0.5556\n",
            "Epoch 133/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.2689 - accuracy: 0.4861 - val_loss: 1.2176 - val_accuracy: 0.5604\n",
            "Epoch 134/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.2701 - accuracy: 0.4976 - val_loss: 1.2249 - val_accuracy: 0.5894\n",
            "Epoch 135/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.2559 - accuracy: 0.5067 - val_loss: 1.2184 - val_accuracy: 0.5700\n",
            "Epoch 136/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.2650 - accuracy: 0.4982 - val_loss: 1.2130 - val_accuracy: 0.5507\n",
            "Epoch 137/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.2457 - accuracy: 0.5206 - val_loss: 1.2185 - val_accuracy: 0.5217\n",
            "Epoch 138/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.2510 - accuracy: 0.4746 - val_loss: 1.2036 - val_accuracy: 0.6039\n",
            "Epoch 139/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.2526 - accuracy: 0.4837 - val_loss: 1.2132 - val_accuracy: 0.5556\n",
            "Epoch 140/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.2295 - accuracy: 0.4988 - val_loss: 1.2044 - val_accuracy: 0.5749\n",
            "Epoch 141/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.2397 - accuracy: 0.4970 - val_loss: 1.1882 - val_accuracy: 0.5556\n",
            "Epoch 142/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.2328 - accuracy: 0.4976 - val_loss: 1.1909 - val_accuracy: 0.5894\n",
            "Epoch 143/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.2328 - accuracy: 0.5042 - val_loss: 1.1810 - val_accuracy: 0.5459\n",
            "Epoch 144/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.2530 - accuracy: 0.4940 - val_loss: 1.1731 - val_accuracy: 0.5700\n",
            "Epoch 145/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.2208 - accuracy: 0.5030 - val_loss: 1.1788 - val_accuracy: 0.5845\n",
            "Epoch 146/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.2400 - accuracy: 0.4970 - val_loss: 1.1822 - val_accuracy: 0.6135\n",
            "Epoch 147/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.2208 - accuracy: 0.5193 - val_loss: 1.1715 - val_accuracy: 0.5894\n",
            "Epoch 148/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.2125 - accuracy: 0.5127 - val_loss: 1.1779 - val_accuracy: 0.5700\n",
            "Epoch 149/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.2187 - accuracy: 0.5151 - val_loss: 1.1910 - val_accuracy: 0.5459\n",
            "Epoch 150/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.2277 - accuracy: 0.5151 - val_loss: 1.1796 - val_accuracy: 0.5845\n",
            "Epoch 151/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.1883 - accuracy: 0.5333 - val_loss: 1.1724 - val_accuracy: 0.5652\n",
            "Epoch 152/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.1882 - accuracy: 0.5254 - val_loss: 1.1790 - val_accuracy: 0.5266\n",
            "Epoch 153/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.2013 - accuracy: 0.5218 - val_loss: 1.1622 - val_accuracy: 0.5652\n",
            "Epoch 154/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.2015 - accuracy: 0.5133 - val_loss: 1.1468 - val_accuracy: 0.5990\n",
            "Epoch 155/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.1788 - accuracy: 0.5345 - val_loss: 1.1604 - val_accuracy: 0.5700\n",
            "Epoch 156/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.1916 - accuracy: 0.5103 - val_loss: 1.1795 - val_accuracy: 0.5556\n",
            "Epoch 157/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.2086 - accuracy: 0.5151 - val_loss: 1.1731 - val_accuracy: 0.5652\n",
            "Epoch 158/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.1867 - accuracy: 0.5345 - val_loss: 1.1491 - val_accuracy: 0.5797\n",
            "Epoch 159/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.1662 - accuracy: 0.5308 - val_loss: 1.1513 - val_accuracy: 0.5845\n",
            "Epoch 160/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.1965 - accuracy: 0.5266 - val_loss: 1.1454 - val_accuracy: 0.5990\n",
            "Epoch 161/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.1840 - accuracy: 0.5357 - val_loss: 1.1448 - val_accuracy: 0.6087\n",
            "Epoch 162/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.1593 - accuracy: 0.5399 - val_loss: 1.1319 - val_accuracy: 0.6039\n",
            "Epoch 163/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.1467 - accuracy: 0.5393 - val_loss: 1.1337 - val_accuracy: 0.6135\n",
            "Epoch 164/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.1598 - accuracy: 0.5320 - val_loss: 1.1133 - val_accuracy: 0.6135\n",
            "Epoch 165/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.1734 - accuracy: 0.5326 - val_loss: 1.1192 - val_accuracy: 0.6232\n",
            "Epoch 166/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.1313 - accuracy: 0.5544 - val_loss: 1.1119 - val_accuracy: 0.5990\n",
            "Epoch 167/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.1467 - accuracy: 0.5532 - val_loss: 1.1259 - val_accuracy: 0.5845\n",
            "Epoch 168/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.1497 - accuracy: 0.5423 - val_loss: 1.1241 - val_accuracy: 0.5894\n",
            "Epoch 169/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.1531 - accuracy: 0.5357 - val_loss: 1.1003 - val_accuracy: 0.6232\n",
            "Epoch 170/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.1395 - accuracy: 0.5478 - val_loss: 1.1088 - val_accuracy: 0.6184\n",
            "Epoch 171/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.1379 - accuracy: 0.5375 - val_loss: 1.0966 - val_accuracy: 0.6425\n",
            "Epoch 172/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.1494 - accuracy: 0.5472 - val_loss: 1.1069 - val_accuracy: 0.5749\n",
            "Epoch 173/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.1262 - accuracy: 0.5659 - val_loss: 1.1098 - val_accuracy: 0.6184\n",
            "Epoch 174/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.1543 - accuracy: 0.5254 - val_loss: 1.1023 - val_accuracy: 0.5990\n",
            "Epoch 175/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.1227 - accuracy: 0.5459 - val_loss: 1.1021 - val_accuracy: 0.5942\n",
            "Epoch 176/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.1455 - accuracy: 0.5435 - val_loss: 1.1126 - val_accuracy: 0.5894\n",
            "Epoch 177/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.1143 - accuracy: 0.5556 - val_loss: 1.0906 - val_accuracy: 0.6570\n",
            "Epoch 178/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.1299 - accuracy: 0.5320 - val_loss: 1.0827 - val_accuracy: 0.6135\n",
            "Epoch 179/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.1302 - accuracy: 0.5629 - val_loss: 1.0937 - val_accuracy: 0.6039\n",
            "Epoch 180/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.1320 - accuracy: 0.5574 - val_loss: 1.0861 - val_accuracy: 0.6329\n",
            "Epoch 181/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.1167 - accuracy: 0.5599 - val_loss: 1.0817 - val_accuracy: 0.6570\n",
            "Epoch 182/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0995 - accuracy: 0.5617 - val_loss: 1.0774 - val_accuracy: 0.6232\n",
            "Epoch 183/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.1277 - accuracy: 0.5526 - val_loss: 1.0841 - val_accuracy: 0.6087\n",
            "Epoch 184/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.1221 - accuracy: 0.5502 - val_loss: 1.0560 - val_accuracy: 0.6522\n",
            "Epoch 185/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.1184 - accuracy: 0.5526 - val_loss: 1.0900 - val_accuracy: 0.5845\n",
            "Epoch 186/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.1057 - accuracy: 0.5502 - val_loss: 1.0758 - val_accuracy: 0.6135\n",
            "Epoch 187/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.1040 - accuracy: 0.5599 - val_loss: 1.0625 - val_accuracy: 0.6377\n",
            "Epoch 188/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0897 - accuracy: 0.5532 - val_loss: 1.0708 - val_accuracy: 0.6232\n",
            "Epoch 189/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.1050 - accuracy: 0.5574 - val_loss: 1.0795 - val_accuracy: 0.6039\n",
            "Epoch 190/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0742 - accuracy: 0.5701 - val_loss: 1.0733 - val_accuracy: 0.6184\n",
            "Epoch 191/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.0712 - accuracy: 0.5786 - val_loss: 1.0522 - val_accuracy: 0.6329\n",
            "Epoch 192/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0900 - accuracy: 0.5762 - val_loss: 1.0415 - val_accuracy: 0.6232\n",
            "Epoch 193/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.1045 - accuracy: 0.5707 - val_loss: 1.0593 - val_accuracy: 0.6087\n",
            "Epoch 194/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0870 - accuracy: 0.5568 - val_loss: 1.0710 - val_accuracy: 0.5990\n",
            "Epoch 195/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0678 - accuracy: 0.5719 - val_loss: 1.0511 - val_accuracy: 0.6280\n",
            "Epoch 196/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0841 - accuracy: 0.5635 - val_loss: 1.0452 - val_accuracy: 0.6184\n",
            "Epoch 197/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0836 - accuracy: 0.5744 - val_loss: 1.0570 - val_accuracy: 0.6232\n",
            "Epoch 198/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0697 - accuracy: 0.5798 - val_loss: 1.0413 - val_accuracy: 0.6184\n",
            "Epoch 199/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0666 - accuracy: 0.5732 - val_loss: 1.0313 - val_accuracy: 0.6522\n",
            "Epoch 200/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0730 - accuracy: 0.5726 - val_loss: 1.0190 - val_accuracy: 0.6570\n",
            "Epoch 201/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0584 - accuracy: 0.5695 - val_loss: 1.0433 - val_accuracy: 0.6425\n",
            "Epoch 202/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0653 - accuracy: 0.5713 - val_loss: 1.0848 - val_accuracy: 0.5845\n",
            "Epoch 203/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0693 - accuracy: 0.5756 - val_loss: 1.0269 - val_accuracy: 0.6473\n",
            "Epoch 204/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0817 - accuracy: 0.5774 - val_loss: 1.0489 - val_accuracy: 0.6232\n",
            "Epoch 205/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0584 - accuracy: 0.5744 - val_loss: 1.0220 - val_accuracy: 0.6280\n",
            "Epoch 206/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0670 - accuracy: 0.5786 - val_loss: 1.0279 - val_accuracy: 0.6232\n",
            "Epoch 207/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0509 - accuracy: 0.5859 - val_loss: 1.0261 - val_accuracy: 0.6618\n",
            "Epoch 208/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0201 - accuracy: 0.6004 - val_loss: 1.0406 - val_accuracy: 0.6473\n",
            "Epoch 209/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0494 - accuracy: 0.5979 - val_loss: 1.0054 - val_accuracy: 0.6812\n",
            "Epoch 210/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0560 - accuracy: 0.5834 - val_loss: 1.0003 - val_accuracy: 0.6425\n",
            "Epoch 211/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0357 - accuracy: 0.5828 - val_loss: 0.9969 - val_accuracy: 0.6715\n",
            "Epoch 212/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0129 - accuracy: 0.5985 - val_loss: 0.9937 - val_accuracy: 0.6908\n",
            "Epoch 213/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0390 - accuracy: 0.5834 - val_loss: 0.9996 - val_accuracy: 0.6618\n",
            "Epoch 214/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0361 - accuracy: 0.5979 - val_loss: 1.0145 - val_accuracy: 0.6425\n",
            "Epoch 215/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0173 - accuracy: 0.5943 - val_loss: 1.0018 - val_accuracy: 0.6957\n",
            "Epoch 216/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0308 - accuracy: 0.5883 - val_loss: 0.9924 - val_accuracy: 0.6715\n",
            "Epoch 217/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0621 - accuracy: 0.5798 - val_loss: 0.9885 - val_accuracy: 0.6908\n",
            "Epoch 218/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0309 - accuracy: 0.5859 - val_loss: 1.0018 - val_accuracy: 0.6860\n",
            "Epoch 219/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0195 - accuracy: 0.5895 - val_loss: 0.9851 - val_accuracy: 0.6570\n",
            "Epoch 220/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0257 - accuracy: 0.6034 - val_loss: 1.0052 - val_accuracy: 0.6763\n",
            "Epoch 221/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0227 - accuracy: 0.5931 - val_loss: 1.0075 - val_accuracy: 0.6377\n",
            "Epoch 222/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0218 - accuracy: 0.6028 - val_loss: 0.9942 - val_accuracy: 0.6570\n",
            "Epoch 223/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0198 - accuracy: 0.5895 - val_loss: 0.9904 - val_accuracy: 0.6570\n",
            "Epoch 224/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0109 - accuracy: 0.6052 - val_loss: 0.9818 - val_accuracy: 0.6957\n",
            "Epoch 225/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.9890 - accuracy: 0.6010 - val_loss: 1.0036 - val_accuracy: 0.6570\n",
            "Epoch 226/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0074 - accuracy: 0.5937 - val_loss: 0.9978 - val_accuracy: 0.6667\n",
            "Epoch 227/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0117 - accuracy: 0.6046 - val_loss: 1.0268 - val_accuracy: 0.6087\n",
            "Epoch 228/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9972 - accuracy: 0.6070 - val_loss: 0.9867 - val_accuracy: 0.6570\n",
            "Epoch 229/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0153 - accuracy: 0.6004 - val_loss: 0.9702 - val_accuracy: 0.6570\n",
            "Epoch 230/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0092 - accuracy: 0.5925 - val_loss: 0.9799 - val_accuracy: 0.6715\n",
            "Epoch 231/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9908 - accuracy: 0.6197 - val_loss: 0.9775 - val_accuracy: 0.6329\n",
            "Epoch 232/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0115 - accuracy: 0.6082 - val_loss: 0.9767 - val_accuracy: 0.6763\n",
            "Epoch 233/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9899 - accuracy: 0.6082 - val_loss: 0.9594 - val_accuracy: 0.6522\n",
            "Epoch 234/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9944 - accuracy: 0.6010 - val_loss: 0.9726 - val_accuracy: 0.6667\n",
            "Epoch 235/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9952 - accuracy: 0.6016 - val_loss: 0.9895 - val_accuracy: 0.5990\n",
            "Epoch 236/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9941 - accuracy: 0.6119 - val_loss: 0.9841 - val_accuracy: 0.6570\n",
            "Epoch 237/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9747 - accuracy: 0.6161 - val_loss: 0.9608 - val_accuracy: 0.7101\n",
            "Epoch 238/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9671 - accuracy: 0.6203 - val_loss: 0.9670 - val_accuracy: 0.6812\n",
            "Epoch 239/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9954 - accuracy: 0.5967 - val_loss: 0.9664 - val_accuracy: 0.6715\n",
            "Epoch 240/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9761 - accuracy: 0.6131 - val_loss: 0.9715 - val_accuracy: 0.6570\n",
            "Epoch 241/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9876 - accuracy: 0.6264 - val_loss: 0.9878 - val_accuracy: 0.6473\n",
            "Epoch 242/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9757 - accuracy: 0.6058 - val_loss: 0.9581 - val_accuracy: 0.6667\n",
            "Epoch 243/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9824 - accuracy: 0.6022 - val_loss: 0.9524 - val_accuracy: 0.6618\n",
            "Epoch 244/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9754 - accuracy: 0.6106 - val_loss: 0.9470 - val_accuracy: 0.6860\n",
            "Epoch 245/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9783 - accuracy: 0.5998 - val_loss: 0.9541 - val_accuracy: 0.6715\n",
            "Epoch 246/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9647 - accuracy: 0.6137 - val_loss: 0.9529 - val_accuracy: 0.6715\n",
            "Epoch 247/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9749 - accuracy: 0.6209 - val_loss: 0.9624 - val_accuracy: 0.6522\n",
            "Epoch 248/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9818 - accuracy: 0.6016 - val_loss: 0.9479 - val_accuracy: 0.6763\n",
            "Epoch 249/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9838 - accuracy: 0.6004 - val_loss: 0.9652 - val_accuracy: 0.6473\n",
            "Epoch 250/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9548 - accuracy: 0.6179 - val_loss: 0.9469 - val_accuracy: 0.6763\n",
            "Epoch 251/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9801 - accuracy: 0.6016 - val_loss: 0.9375 - val_accuracy: 0.6908\n",
            "Epoch 252/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9614 - accuracy: 0.6239 - val_loss: 0.9277 - val_accuracy: 0.6618\n",
            "Epoch 253/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9710 - accuracy: 0.6221 - val_loss: 0.9489 - val_accuracy: 0.6667\n",
            "Epoch 254/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9652 - accuracy: 0.6300 - val_loss: 0.9404 - val_accuracy: 0.6908\n",
            "Epoch 255/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9703 - accuracy: 0.6125 - val_loss: 0.9275 - val_accuracy: 0.6908\n",
            "Epoch 256/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9627 - accuracy: 0.6239 - val_loss: 0.9339 - val_accuracy: 0.6570\n",
            "Epoch 257/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9668 - accuracy: 0.6161 - val_loss: 0.9262 - val_accuracy: 0.6763\n",
            "Epoch 258/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9304 - accuracy: 0.6282 - val_loss: 0.9560 - val_accuracy: 0.6184\n",
            "Epoch 259/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9566 - accuracy: 0.6203 - val_loss: 0.9261 - val_accuracy: 0.7005\n",
            "Epoch 260/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9569 - accuracy: 0.6312 - val_loss: 0.9251 - val_accuracy: 0.6908\n",
            "Epoch 261/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9575 - accuracy: 0.6288 - val_loss: 0.9373 - val_accuracy: 0.6812\n",
            "Epoch 262/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9582 - accuracy: 0.6233 - val_loss: 0.9515 - val_accuracy: 0.6473\n",
            "Epoch 263/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9281 - accuracy: 0.6403 - val_loss: 0.9096 - val_accuracy: 0.7101\n",
            "Epoch 264/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9512 - accuracy: 0.6233 - val_loss: 0.9189 - val_accuracy: 0.6667\n",
            "Epoch 265/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9354 - accuracy: 0.6294 - val_loss: 0.9190 - val_accuracy: 0.6860\n",
            "Epoch 266/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9477 - accuracy: 0.6258 - val_loss: 0.9104 - val_accuracy: 0.7005\n",
            "Epoch 267/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9133 - accuracy: 0.6360 - val_loss: 0.8959 - val_accuracy: 0.6908\n",
            "Epoch 268/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9394 - accuracy: 0.6306 - val_loss: 0.9117 - val_accuracy: 0.6715\n",
            "Epoch 269/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9420 - accuracy: 0.6233 - val_loss: 0.9027 - val_accuracy: 0.7053\n",
            "Epoch 270/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9387 - accuracy: 0.6421 - val_loss: 0.9086 - val_accuracy: 0.7053\n",
            "Epoch 271/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9273 - accuracy: 0.6415 - val_loss: 0.8996 - val_accuracy: 0.6812\n",
            "Epoch 272/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9094 - accuracy: 0.6372 - val_loss: 0.8932 - val_accuracy: 0.6667\n",
            "Epoch 273/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9132 - accuracy: 0.6366 - val_loss: 0.9022 - val_accuracy: 0.6763\n",
            "Epoch 274/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9253 - accuracy: 0.6245 - val_loss: 0.9007 - val_accuracy: 0.7053\n",
            "Epoch 275/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9138 - accuracy: 0.6397 - val_loss: 0.8972 - val_accuracy: 0.7005\n",
            "Epoch 276/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9068 - accuracy: 0.6451 - val_loss: 0.9103 - val_accuracy: 0.6763\n",
            "Epoch 277/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9310 - accuracy: 0.6403 - val_loss: 0.9103 - val_accuracy: 0.6812\n",
            "Epoch 278/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9378 - accuracy: 0.6306 - val_loss: 0.8933 - val_accuracy: 0.7101\n",
            "Epoch 279/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9169 - accuracy: 0.6378 - val_loss: 0.8986 - val_accuracy: 0.7005\n",
            "Epoch 280/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9371 - accuracy: 0.6245 - val_loss: 0.8976 - val_accuracy: 0.6812\n",
            "Epoch 281/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9263 - accuracy: 0.6306 - val_loss: 0.8976 - val_accuracy: 0.7005\n",
            "Epoch 282/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9215 - accuracy: 0.6312 - val_loss: 0.8995 - val_accuracy: 0.7101\n",
            "Epoch 283/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8901 - accuracy: 0.6457 - val_loss: 0.9083 - val_accuracy: 0.6860\n",
            "Epoch 284/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9117 - accuracy: 0.6391 - val_loss: 0.9156 - val_accuracy: 0.6812\n",
            "Epoch 285/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9139 - accuracy: 0.6439 - val_loss: 0.8916 - val_accuracy: 0.6957\n",
            "Epoch 286/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9099 - accuracy: 0.6415 - val_loss: 0.9044 - val_accuracy: 0.7005\n",
            "Epoch 287/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8889 - accuracy: 0.6421 - val_loss: 0.8894 - val_accuracy: 0.6715\n",
            "Epoch 288/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9087 - accuracy: 0.6391 - val_loss: 0.8953 - val_accuracy: 0.6860\n",
            "Epoch 289/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8938 - accuracy: 0.6475 - val_loss: 0.8803 - val_accuracy: 0.7101\n",
            "Epoch 290/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9299 - accuracy: 0.6354 - val_loss: 0.8811 - val_accuracy: 0.7101\n",
            "Epoch 291/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9028 - accuracy: 0.6421 - val_loss: 0.9019 - val_accuracy: 0.7053\n",
            "Epoch 292/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.8842 - accuracy: 0.6391 - val_loss: 0.8727 - val_accuracy: 0.7053\n",
            "Epoch 293/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9101 - accuracy: 0.6312 - val_loss: 0.8745 - val_accuracy: 0.7053\n",
            "Epoch 294/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8869 - accuracy: 0.6524 - val_loss: 0.8874 - val_accuracy: 0.6715\n",
            "Epoch 295/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8998 - accuracy: 0.6457 - val_loss: 0.8784 - val_accuracy: 0.7101\n",
            "Epoch 296/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8922 - accuracy: 0.6409 - val_loss: 0.8765 - val_accuracy: 0.7101\n",
            "Epoch 297/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9196 - accuracy: 0.6360 - val_loss: 0.8685 - val_accuracy: 0.7150\n",
            "Epoch 298/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8672 - accuracy: 0.6560 - val_loss: 0.8883 - val_accuracy: 0.6957\n",
            "Epoch 299/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9007 - accuracy: 0.6493 - val_loss: 0.8896 - val_accuracy: 0.7150\n",
            "Epoch 300/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8833 - accuracy: 0.6487 - val_loss: 0.8686 - val_accuracy: 0.7295\n",
            "Epoch 301/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8797 - accuracy: 0.6518 - val_loss: 0.8823 - val_accuracy: 0.7053\n",
            "Epoch 302/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8687 - accuracy: 0.6651 - val_loss: 0.8639 - val_accuracy: 0.7150\n",
            "Epoch 303/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8489 - accuracy: 0.6657 - val_loss: 0.8708 - val_accuracy: 0.6763\n",
            "Epoch 304/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8894 - accuracy: 0.6566 - val_loss: 0.8605 - val_accuracy: 0.7295\n",
            "Epoch 305/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8842 - accuracy: 0.6602 - val_loss: 0.8653 - val_accuracy: 0.7246\n",
            "Epoch 306/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8433 - accuracy: 0.6651 - val_loss: 0.8733 - val_accuracy: 0.6812\n",
            "Epoch 307/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8765 - accuracy: 0.6457 - val_loss: 0.8392 - val_accuracy: 0.7101\n",
            "Epoch 308/1000\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.8853 - accuracy: 0.6324 - val_loss: 0.9012 - val_accuracy: 0.6425\n",
            "Epoch 309/1000\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 0.8498 - accuracy: 0.6596 - val_loss: 0.8680 - val_accuracy: 0.6618\n",
            "Epoch 310/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8826 - accuracy: 0.6518 - val_loss: 0.8466 - val_accuracy: 0.7150\n",
            "Epoch 311/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8814 - accuracy: 0.6578 - val_loss: 0.8683 - val_accuracy: 0.7150\n",
            "Epoch 312/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8713 - accuracy: 0.6548 - val_loss: 0.8390 - val_accuracy: 0.7246\n",
            "Epoch 313/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8630 - accuracy: 0.6505 - val_loss: 0.8484 - val_accuracy: 0.7053\n",
            "Epoch 314/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8548 - accuracy: 0.6481 - val_loss: 0.8558 - val_accuracy: 0.6618\n",
            "Epoch 315/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8568 - accuracy: 0.6675 - val_loss: 0.8591 - val_accuracy: 0.6763\n",
            "Epoch 316/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8696 - accuracy: 0.6457 - val_loss: 0.8342 - val_accuracy: 0.7005\n",
            "Epoch 317/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8518 - accuracy: 0.6790 - val_loss: 0.8313 - val_accuracy: 0.7053\n",
            "Epoch 318/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8716 - accuracy: 0.6530 - val_loss: 0.8571 - val_accuracy: 0.7150\n",
            "Epoch 319/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8565 - accuracy: 0.6608 - val_loss: 0.8527 - val_accuracy: 0.7005\n",
            "Epoch 320/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8766 - accuracy: 0.6566 - val_loss: 0.8537 - val_accuracy: 0.7101\n",
            "Epoch 321/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8482 - accuracy: 0.6681 - val_loss: 0.8478 - val_accuracy: 0.7053\n",
            "Epoch 322/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8464 - accuracy: 0.6657 - val_loss: 0.8447 - val_accuracy: 0.6860\n",
            "Epoch 323/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8486 - accuracy: 0.6747 - val_loss: 0.8391 - val_accuracy: 0.7053\n",
            "Epoch 324/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8673 - accuracy: 0.6554 - val_loss: 0.8282 - val_accuracy: 0.6812\n",
            "Epoch 325/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.8329 - accuracy: 0.6644 - val_loss: 0.8312 - val_accuracy: 0.7101\n",
            "Epoch 326/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8285 - accuracy: 0.6753 - val_loss: 0.8282 - val_accuracy: 0.7295\n",
            "Epoch 327/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8425 - accuracy: 0.6856 - val_loss: 0.8256 - val_accuracy: 0.7053\n",
            "Epoch 328/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8483 - accuracy: 0.6584 - val_loss: 0.8249 - val_accuracy: 0.7053\n",
            "Epoch 329/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8261 - accuracy: 0.6626 - val_loss: 0.8478 - val_accuracy: 0.6860\n",
            "Epoch 330/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8112 - accuracy: 0.6904 - val_loss: 0.8326 - val_accuracy: 0.7101\n",
            "Epoch 331/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8535 - accuracy: 0.6669 - val_loss: 0.8414 - val_accuracy: 0.6908\n",
            "Epoch 332/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8544 - accuracy: 0.6590 - val_loss: 0.8300 - val_accuracy: 0.6908\n",
            "Epoch 333/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8453 - accuracy: 0.6614 - val_loss: 0.8287 - val_accuracy: 0.7101\n",
            "Epoch 334/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8537 - accuracy: 0.6657 - val_loss: 0.8394 - val_accuracy: 0.7053\n",
            "Epoch 335/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8407 - accuracy: 0.6590 - val_loss: 0.8357 - val_accuracy: 0.7150\n",
            "Epoch 336/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8271 - accuracy: 0.6723 - val_loss: 0.8216 - val_accuracy: 0.7246\n",
            "Epoch 337/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8277 - accuracy: 0.6778 - val_loss: 0.8532 - val_accuracy: 0.6667\n",
            "Epoch 338/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8433 - accuracy: 0.6590 - val_loss: 0.8301 - val_accuracy: 0.7536\n",
            "Epoch 339/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8298 - accuracy: 0.6632 - val_loss: 0.8295 - val_accuracy: 0.7005\n",
            "Epoch 340/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8379 - accuracy: 0.6596 - val_loss: 0.8333 - val_accuracy: 0.7053\n",
            "Epoch 341/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8374 - accuracy: 0.6620 - val_loss: 0.8344 - val_accuracy: 0.7053\n",
            "Epoch 342/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8327 - accuracy: 0.6759 - val_loss: 0.8204 - val_accuracy: 0.7101\n",
            "Epoch 343/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8427 - accuracy: 0.6699 - val_loss: 0.8139 - val_accuracy: 0.7198\n",
            "Epoch 344/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8635 - accuracy: 0.6578 - val_loss: 0.8427 - val_accuracy: 0.6957\n",
            "Epoch 345/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8246 - accuracy: 0.6711 - val_loss: 0.8243 - val_accuracy: 0.7150\n",
            "Epoch 346/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8277 - accuracy: 0.6657 - val_loss: 0.8421 - val_accuracy: 0.6957\n",
            "Epoch 347/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8459 - accuracy: 0.6651 - val_loss: 0.8155 - val_accuracy: 0.6957\n",
            "Epoch 348/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8200 - accuracy: 0.6717 - val_loss: 0.8238 - val_accuracy: 0.7053\n",
            "Epoch 349/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8505 - accuracy: 0.6566 - val_loss: 0.8291 - val_accuracy: 0.7246\n",
            "Epoch 350/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8269 - accuracy: 0.6765 - val_loss: 0.8170 - val_accuracy: 0.7198\n",
            "Epoch 351/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8324 - accuracy: 0.6602 - val_loss: 0.8379 - val_accuracy: 0.7343\n",
            "Epoch 352/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8352 - accuracy: 0.6657 - val_loss: 0.8354 - val_accuracy: 0.7391\n",
            "Epoch 353/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8491 - accuracy: 0.6584 - val_loss: 0.8266 - val_accuracy: 0.7053\n",
            "Epoch 354/1000\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.8244 - accuracy: 0.6681 - val_loss: 0.8323 - val_accuracy: 0.7101\n",
            "Epoch 355/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.8220 - accuracy: 0.6953 - val_loss: 0.8101 - val_accuracy: 0.7150\n",
            "Epoch 356/1000\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.8143 - accuracy: 0.6735 - val_loss: 0.8115 - val_accuracy: 0.7295\n",
            "Epoch 357/1000\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.8170 - accuracy: 0.6632 - val_loss: 0.8076 - val_accuracy: 0.7198\n",
            "Epoch 358/1000\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.8298 - accuracy: 0.6832 - val_loss: 0.8057 - val_accuracy: 0.7295\n",
            "Epoch 359/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8171 - accuracy: 0.6711 - val_loss: 0.8096 - val_accuracy: 0.7005\n",
            "Epoch 360/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8133 - accuracy: 0.6826 - val_loss: 0.8481 - val_accuracy: 0.6763\n",
            "Epoch 361/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8044 - accuracy: 0.6832 - val_loss: 0.8027 - val_accuracy: 0.7198\n",
            "Epoch 362/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8223 - accuracy: 0.6838 - val_loss: 0.8276 - val_accuracy: 0.7150\n",
            "Epoch 363/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7848 - accuracy: 0.6917 - val_loss: 0.8178 - val_accuracy: 0.7198\n",
            "Epoch 364/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8021 - accuracy: 0.6953 - val_loss: 0.8117 - val_accuracy: 0.7053\n",
            "Epoch 365/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8106 - accuracy: 0.6669 - val_loss: 0.7992 - val_accuracy: 0.7150\n",
            "Epoch 366/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8030 - accuracy: 0.6832 - val_loss: 0.8231 - val_accuracy: 0.7005\n",
            "Epoch 367/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7963 - accuracy: 0.7037 - val_loss: 0.8042 - val_accuracy: 0.7198\n",
            "Epoch 368/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8110 - accuracy: 0.6862 - val_loss: 0.8116 - val_accuracy: 0.7246\n",
            "Epoch 369/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7938 - accuracy: 0.6904 - val_loss: 0.7986 - val_accuracy: 0.7198\n",
            "Epoch 370/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7990 - accuracy: 0.6832 - val_loss: 0.8127 - val_accuracy: 0.6908\n",
            "Epoch 371/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8124 - accuracy: 0.6675 - val_loss: 0.8082 - val_accuracy: 0.6957\n",
            "Epoch 372/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8025 - accuracy: 0.6923 - val_loss: 0.8033 - val_accuracy: 0.7391\n",
            "Epoch 373/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7709 - accuracy: 0.6983 - val_loss: 0.8136 - val_accuracy: 0.7198\n",
            "Epoch 374/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7851 - accuracy: 0.6790 - val_loss: 0.7963 - val_accuracy: 0.7150\n",
            "Epoch 375/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8184 - accuracy: 0.6838 - val_loss: 0.8140 - val_accuracy: 0.6957\n",
            "Epoch 376/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8109 - accuracy: 0.6675 - val_loss: 0.8139 - val_accuracy: 0.6908\n",
            "Epoch 377/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7828 - accuracy: 0.6832 - val_loss: 0.7936 - val_accuracy: 0.7391\n",
            "Epoch 378/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7890 - accuracy: 0.6844 - val_loss: 0.8059 - val_accuracy: 0.7005\n",
            "Epoch 379/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8010 - accuracy: 0.6947 - val_loss: 0.7895 - val_accuracy: 0.7488\n",
            "Epoch 380/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7825 - accuracy: 0.6892 - val_loss: 0.8330 - val_accuracy: 0.6763\n",
            "Epoch 381/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7991 - accuracy: 0.6705 - val_loss: 0.8249 - val_accuracy: 0.6812\n",
            "Epoch 382/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7788 - accuracy: 0.6917 - val_loss: 0.8020 - val_accuracy: 0.7101\n",
            "Epoch 383/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8089 - accuracy: 0.6796 - val_loss: 0.7804 - val_accuracy: 0.7391\n",
            "Epoch 384/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8126 - accuracy: 0.6796 - val_loss: 0.8124 - val_accuracy: 0.7198\n",
            "Epoch 385/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8000 - accuracy: 0.6868 - val_loss: 0.8175 - val_accuracy: 0.7005\n",
            "Epoch 386/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7952 - accuracy: 0.6935 - val_loss: 0.7945 - val_accuracy: 0.7198\n",
            "Epoch 387/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7826 - accuracy: 0.6965 - val_loss: 0.7890 - val_accuracy: 0.6957\n",
            "Epoch 388/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7750 - accuracy: 0.6880 - val_loss: 0.7773 - val_accuracy: 0.7295\n",
            "Epoch 389/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.7878 - accuracy: 0.6820 - val_loss: 0.7856 - val_accuracy: 0.7198\n",
            "Epoch 390/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.7718 - accuracy: 0.6965 - val_loss: 0.7960 - val_accuracy: 0.7150\n",
            "Epoch 391/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7839 - accuracy: 0.6959 - val_loss: 0.7928 - val_accuracy: 0.7295\n",
            "Epoch 392/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7572 - accuracy: 0.6971 - val_loss: 0.8291 - val_accuracy: 0.6860\n",
            "Epoch 393/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7732 - accuracy: 0.6898 - val_loss: 0.7820 - val_accuracy: 0.7246\n",
            "Epoch 394/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7889 - accuracy: 0.6814 - val_loss: 0.8044 - val_accuracy: 0.7198\n",
            "Epoch 395/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7949 - accuracy: 0.6832 - val_loss: 0.7951 - val_accuracy: 0.6957\n",
            "Epoch 396/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7405 - accuracy: 0.7177 - val_loss: 0.8273 - val_accuracy: 0.6860\n",
            "Epoch 397/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7883 - accuracy: 0.6953 - val_loss: 0.7745 - val_accuracy: 0.7295\n",
            "Epoch 398/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7664 - accuracy: 0.7013 - val_loss: 0.8079 - val_accuracy: 0.7005\n",
            "Epoch 399/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7733 - accuracy: 0.6935 - val_loss: 0.7705 - val_accuracy: 0.7391\n",
            "Epoch 400/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7469 - accuracy: 0.7092 - val_loss: 0.7985 - val_accuracy: 0.6812\n",
            "Epoch 401/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7562 - accuracy: 0.7050 - val_loss: 0.7992 - val_accuracy: 0.7150\n",
            "Epoch 402/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7732 - accuracy: 0.7037 - val_loss: 0.7977 - val_accuracy: 0.7005\n",
            "Epoch 403/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7713 - accuracy: 0.7001 - val_loss: 0.7817 - val_accuracy: 0.7101\n",
            "Epoch 404/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7487 - accuracy: 0.7025 - val_loss: 0.7924 - val_accuracy: 0.7005\n",
            "Epoch 405/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7680 - accuracy: 0.6898 - val_loss: 0.7652 - val_accuracy: 0.7343\n",
            "Epoch 406/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7601 - accuracy: 0.6995 - val_loss: 0.7908 - val_accuracy: 0.7198\n",
            "Epoch 407/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7668 - accuracy: 0.6941 - val_loss: 0.7828 - val_accuracy: 0.7101\n",
            "Epoch 408/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7558 - accuracy: 0.6941 - val_loss: 0.7924 - val_accuracy: 0.6812\n",
            "Epoch 409/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7639 - accuracy: 0.7110 - val_loss: 0.7925 - val_accuracy: 0.7295\n",
            "Epoch 410/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7481 - accuracy: 0.7080 - val_loss: 0.7663 - val_accuracy: 0.7295\n",
            "Epoch 411/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7563 - accuracy: 0.7128 - val_loss: 0.7768 - val_accuracy: 0.7053\n",
            "Epoch 412/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7460 - accuracy: 0.7116 - val_loss: 0.7545 - val_accuracy: 0.7198\n",
            "Epoch 413/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7497 - accuracy: 0.7152 - val_loss: 0.7797 - val_accuracy: 0.7053\n",
            "Epoch 414/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7441 - accuracy: 0.7050 - val_loss: 0.7810 - val_accuracy: 0.6860\n",
            "Epoch 415/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7581 - accuracy: 0.6935 - val_loss: 0.7690 - val_accuracy: 0.7391\n",
            "Epoch 416/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7700 - accuracy: 0.6892 - val_loss: 0.7814 - val_accuracy: 0.7343\n",
            "Epoch 417/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7677 - accuracy: 0.6850 - val_loss: 0.7665 - val_accuracy: 0.7343\n",
            "Epoch 418/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7610 - accuracy: 0.6983 - val_loss: 0.7712 - val_accuracy: 0.7150\n",
            "Epoch 419/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7185 - accuracy: 0.7110 - val_loss: 0.7618 - val_accuracy: 0.7391\n",
            "Epoch 420/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7357 - accuracy: 0.7122 - val_loss: 0.7592 - val_accuracy: 0.7246\n",
            "Epoch 421/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7480 - accuracy: 0.7146 - val_loss: 0.7683 - val_accuracy: 0.7343\n",
            "Epoch 422/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7417 - accuracy: 0.7140 - val_loss: 0.7516 - val_accuracy: 0.7391\n",
            "Epoch 423/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7617 - accuracy: 0.6989 - val_loss: 0.7862 - val_accuracy: 0.7053\n",
            "Epoch 424/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7525 - accuracy: 0.6965 - val_loss: 0.7624 - val_accuracy: 0.7150\n",
            "Epoch 425/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7278 - accuracy: 0.7122 - val_loss: 0.7791 - val_accuracy: 0.7295\n",
            "Epoch 426/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7284 - accuracy: 0.7189 - val_loss: 0.7879 - val_accuracy: 0.7101\n",
            "Epoch 427/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7539 - accuracy: 0.7086 - val_loss: 0.7616 - val_accuracy: 0.7246\n",
            "Epoch 428/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7354 - accuracy: 0.7134 - val_loss: 0.7902 - val_accuracy: 0.7198\n",
            "Epoch 429/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7338 - accuracy: 0.7031 - val_loss: 0.7614 - val_accuracy: 0.7440\n",
            "Epoch 430/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7474 - accuracy: 0.7050 - val_loss: 0.7496 - val_accuracy: 0.7198\n",
            "Epoch 431/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7256 - accuracy: 0.7183 - val_loss: 0.7512 - val_accuracy: 0.7391\n",
            "Epoch 432/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7097 - accuracy: 0.7237 - val_loss: 0.7587 - val_accuracy: 0.7150\n",
            "Epoch 433/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7506 - accuracy: 0.6880 - val_loss: 0.7535 - val_accuracy: 0.7391\n",
            "Epoch 434/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7357 - accuracy: 0.7189 - val_loss: 0.7421 - val_accuracy: 0.7150\n",
            "Epoch 435/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.7441 - accuracy: 0.7177 - val_loss: 0.7688 - val_accuracy: 0.7101\n",
            "Epoch 436/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.7280 - accuracy: 0.7007 - val_loss: 0.7661 - val_accuracy: 0.7150\n",
            "Epoch 437/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7043 - accuracy: 0.7261 - val_loss: 0.7439 - val_accuracy: 0.7295\n",
            "Epoch 438/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.7274 - accuracy: 0.7128 - val_loss: 0.7448 - val_accuracy: 0.7343\n",
            "Epoch 439/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7459 - accuracy: 0.7019 - val_loss: 0.7510 - val_accuracy: 0.7343\n",
            "Epoch 440/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7278 - accuracy: 0.7177 - val_loss: 0.7508 - val_accuracy: 0.7343\n",
            "Epoch 441/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7072 - accuracy: 0.7134 - val_loss: 0.7645 - val_accuracy: 0.7150\n",
            "Epoch 442/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7417 - accuracy: 0.7062 - val_loss: 0.7815 - val_accuracy: 0.7198\n",
            "Epoch 443/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7459 - accuracy: 0.7237 - val_loss: 0.7932 - val_accuracy: 0.7150\n",
            "Epoch 444/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7112 - accuracy: 0.7207 - val_loss: 0.7561 - val_accuracy: 0.7295\n",
            "Epoch 445/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7380 - accuracy: 0.7201 - val_loss: 0.7591 - val_accuracy: 0.7440\n",
            "Epoch 446/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7203 - accuracy: 0.7164 - val_loss: 0.7463 - val_accuracy: 0.7198\n",
            "Epoch 447/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7228 - accuracy: 0.7285 - val_loss: 0.7547 - val_accuracy: 0.7198\n",
            "Epoch 448/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.7236 - accuracy: 0.7134 - val_loss: 0.7618 - val_accuracy: 0.7295\n",
            "Epoch 449/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7128 - accuracy: 0.7152 - val_loss: 0.7523 - val_accuracy: 0.7488\n",
            "Epoch 450/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6990 - accuracy: 0.7195 - val_loss: 0.7573 - val_accuracy: 0.7246\n",
            "Epoch 451/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7152 - accuracy: 0.7164 - val_loss: 0.7704 - val_accuracy: 0.7198\n",
            "Epoch 452/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7145 - accuracy: 0.7031 - val_loss: 0.7512 - val_accuracy: 0.7440\n",
            "Epoch 453/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7182 - accuracy: 0.7152 - val_loss: 0.7594 - val_accuracy: 0.7343\n",
            "Epoch 454/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7080 - accuracy: 0.7273 - val_loss: 0.7472 - val_accuracy: 0.7101\n",
            "Epoch 455/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.7083 - accuracy: 0.7201 - val_loss: 0.7533 - val_accuracy: 0.7246\n",
            "Epoch 456/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7064 - accuracy: 0.7092 - val_loss: 0.7564 - val_accuracy: 0.7198\n",
            "Epoch 457/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7125 - accuracy: 0.7201 - val_loss: 0.7344 - val_accuracy: 0.7440\n",
            "Epoch 458/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7143 - accuracy: 0.7237 - val_loss: 0.7487 - val_accuracy: 0.7101\n",
            "Epoch 459/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7169 - accuracy: 0.7116 - val_loss: 0.7704 - val_accuracy: 0.7391\n",
            "Epoch 460/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7274 - accuracy: 0.7183 - val_loss: 0.7652 - val_accuracy: 0.7198\n",
            "Epoch 461/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7070 - accuracy: 0.7279 - val_loss: 0.7349 - val_accuracy: 0.7343\n",
            "Epoch 462/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6961 - accuracy: 0.7273 - val_loss: 0.7392 - val_accuracy: 0.7343\n",
            "Epoch 463/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6822 - accuracy: 0.7370 - val_loss: 0.7505 - val_accuracy: 0.7295\n",
            "Epoch 464/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6939 - accuracy: 0.7316 - val_loss: 0.7349 - val_accuracy: 0.7295\n",
            "Epoch 465/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7021 - accuracy: 0.7273 - val_loss: 0.7446 - val_accuracy: 0.7295\n",
            "Epoch 466/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7022 - accuracy: 0.7273 - val_loss: 0.7589 - val_accuracy: 0.7150\n",
            "Epoch 467/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7034 - accuracy: 0.7183 - val_loss: 0.7348 - val_accuracy: 0.7391\n",
            "Epoch 468/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7100 - accuracy: 0.7291 - val_loss: 0.7320 - val_accuracy: 0.7585\n",
            "Epoch 469/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6957 - accuracy: 0.7285 - val_loss: 0.7349 - val_accuracy: 0.7536\n",
            "Epoch 470/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7020 - accuracy: 0.7261 - val_loss: 0.7545 - val_accuracy: 0.7053\n",
            "Epoch 471/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6923 - accuracy: 0.7267 - val_loss: 0.7487 - val_accuracy: 0.7440\n",
            "Epoch 472/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6958 - accuracy: 0.7285 - val_loss: 0.7310 - val_accuracy: 0.7440\n",
            "Epoch 473/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7281 - accuracy: 0.7140 - val_loss: 0.7433 - val_accuracy: 0.7536\n",
            "Epoch 474/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6994 - accuracy: 0.7255 - val_loss: 0.7316 - val_accuracy: 0.7681\n",
            "Epoch 475/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6891 - accuracy: 0.7158 - val_loss: 0.7533 - val_accuracy: 0.7343\n",
            "Epoch 476/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6833 - accuracy: 0.7310 - val_loss: 0.7624 - val_accuracy: 0.7198\n",
            "Epoch 477/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6940 - accuracy: 0.7304 - val_loss: 0.7533 - val_accuracy: 0.7198\n",
            "Epoch 478/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6871 - accuracy: 0.7231 - val_loss: 0.7425 - val_accuracy: 0.7440\n",
            "Epoch 479/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6982 - accuracy: 0.7316 - val_loss: 0.7234 - val_accuracy: 0.7633\n",
            "Epoch 480/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6865 - accuracy: 0.7243 - val_loss: 0.7346 - val_accuracy: 0.7391\n",
            "Epoch 481/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6955 - accuracy: 0.7310 - val_loss: 0.7313 - val_accuracy: 0.7488\n",
            "Epoch 482/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7040 - accuracy: 0.7297 - val_loss: 0.7327 - val_accuracy: 0.7440\n",
            "Epoch 483/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7065 - accuracy: 0.7249 - val_loss: 0.7633 - val_accuracy: 0.7440\n",
            "Epoch 484/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7107 - accuracy: 0.7152 - val_loss: 0.7267 - val_accuracy: 0.7488\n",
            "Epoch 485/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6762 - accuracy: 0.7273 - val_loss: 0.7242 - val_accuracy: 0.7681\n",
            "Epoch 486/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6737 - accuracy: 0.7376 - val_loss: 0.7265 - val_accuracy: 0.7633\n",
            "Epoch 487/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6783 - accuracy: 0.7310 - val_loss: 0.7153 - val_accuracy: 0.7488\n",
            "Epoch 488/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6719 - accuracy: 0.7316 - val_loss: 0.7287 - val_accuracy: 0.7488\n",
            "Epoch 489/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6899 - accuracy: 0.7322 - val_loss: 0.7457 - val_accuracy: 0.7391\n",
            "Epoch 490/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6690 - accuracy: 0.7334 - val_loss: 0.7130 - val_accuracy: 0.7633\n",
            "Epoch 491/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6802 - accuracy: 0.7279 - val_loss: 0.7471 - val_accuracy: 0.7391\n",
            "Epoch 492/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6988 - accuracy: 0.7249 - val_loss: 0.7403 - val_accuracy: 0.7391\n",
            "Epoch 493/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6851 - accuracy: 0.7364 - val_loss: 0.7341 - val_accuracy: 0.7343\n",
            "Epoch 494/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6741 - accuracy: 0.7430 - val_loss: 0.7185 - val_accuracy: 0.7536\n",
            "Epoch 495/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6822 - accuracy: 0.7364 - val_loss: 0.7431 - val_accuracy: 0.7488\n",
            "Epoch 496/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6811 - accuracy: 0.7400 - val_loss: 0.7343 - val_accuracy: 0.7536\n",
            "Epoch 497/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7070 - accuracy: 0.7249 - val_loss: 0.7349 - val_accuracy: 0.7246\n",
            "Epoch 498/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6649 - accuracy: 0.7461 - val_loss: 0.7307 - val_accuracy: 0.7343\n",
            "Epoch 499/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6706 - accuracy: 0.7340 - val_loss: 0.7200 - val_accuracy: 0.7633\n",
            "Epoch 500/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6770 - accuracy: 0.7364 - val_loss: 0.7197 - val_accuracy: 0.7681\n",
            "Epoch 501/1000\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 0.6782 - accuracy: 0.7376 - val_loss: 0.7176 - val_accuracy: 0.7440\n",
            "Epoch 502/1000\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.6880 - accuracy: 0.7376 - val_loss: 0.7043 - val_accuracy: 0.7633\n",
            "Epoch 503/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6596 - accuracy: 0.7376 - val_loss: 0.7307 - val_accuracy: 0.7536\n",
            "Epoch 504/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6818 - accuracy: 0.7424 - val_loss: 0.7417 - val_accuracy: 0.7440\n",
            "Epoch 505/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6795 - accuracy: 0.7364 - val_loss: 0.7440 - val_accuracy: 0.7295\n",
            "Epoch 506/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6639 - accuracy: 0.7340 - val_loss: 0.7181 - val_accuracy: 0.7440\n",
            "Epoch 507/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6453 - accuracy: 0.7406 - val_loss: 0.7123 - val_accuracy: 0.7488\n",
            "Epoch 508/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6713 - accuracy: 0.7437 - val_loss: 0.7133 - val_accuracy: 0.7536\n",
            "Epoch 509/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6729 - accuracy: 0.7340 - val_loss: 0.7319 - val_accuracy: 0.7391\n",
            "Epoch 510/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6696 - accuracy: 0.7449 - val_loss: 0.7117 - val_accuracy: 0.7488\n",
            "Epoch 511/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6922 - accuracy: 0.7267 - val_loss: 0.7355 - val_accuracy: 0.7295\n",
            "Epoch 512/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6537 - accuracy: 0.7412 - val_loss: 0.7256 - val_accuracy: 0.7440\n",
            "Epoch 513/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6825 - accuracy: 0.7394 - val_loss: 0.7270 - val_accuracy: 0.7440\n",
            "Epoch 514/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6571 - accuracy: 0.7334 - val_loss: 0.7052 - val_accuracy: 0.7585\n",
            "Epoch 515/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6545 - accuracy: 0.7424 - val_loss: 0.7345 - val_accuracy: 0.7391\n",
            "Epoch 516/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6445 - accuracy: 0.7479 - val_loss: 0.7266 - val_accuracy: 0.7440\n",
            "Epoch 517/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6416 - accuracy: 0.7600 - val_loss: 0.7379 - val_accuracy: 0.7536\n",
            "Epoch 518/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6604 - accuracy: 0.7449 - val_loss: 0.7421 - val_accuracy: 0.7343\n",
            "Epoch 519/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6636 - accuracy: 0.7304 - val_loss: 0.7136 - val_accuracy: 0.7536\n",
            "Epoch 520/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6638 - accuracy: 0.7394 - val_loss: 0.7030 - val_accuracy: 0.7633\n",
            "Epoch 521/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6642 - accuracy: 0.7424 - val_loss: 0.7024 - val_accuracy: 0.7440\n",
            "Epoch 522/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6521 - accuracy: 0.7394 - val_loss: 0.7135 - val_accuracy: 0.7536\n",
            "Epoch 523/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6423 - accuracy: 0.7503 - val_loss: 0.6988 - val_accuracy: 0.7681\n",
            "Epoch 524/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6385 - accuracy: 0.7533 - val_loss: 0.7168 - val_accuracy: 0.7488\n",
            "Epoch 525/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6248 - accuracy: 0.7527 - val_loss: 0.7005 - val_accuracy: 0.7729\n",
            "Epoch 526/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6517 - accuracy: 0.7370 - val_loss: 0.7092 - val_accuracy: 0.7729\n",
            "Epoch 527/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6571 - accuracy: 0.7412 - val_loss: 0.6964 - val_accuracy: 0.7585\n",
            "Epoch 528/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6582 - accuracy: 0.7418 - val_loss: 0.7226 - val_accuracy: 0.7536\n",
            "Epoch 529/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6591 - accuracy: 0.7334 - val_loss: 0.7119 - val_accuracy: 0.7536\n",
            "Epoch 530/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6432 - accuracy: 0.7503 - val_loss: 0.7061 - val_accuracy: 0.7585\n",
            "Epoch 531/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6580 - accuracy: 0.7340 - val_loss: 0.7149 - val_accuracy: 0.7585\n",
            "Epoch 532/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6404 - accuracy: 0.7509 - val_loss: 0.7174 - val_accuracy: 0.7585\n",
            "Epoch 533/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6468 - accuracy: 0.7406 - val_loss: 0.7107 - val_accuracy: 0.7585\n",
            "Epoch 534/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6535 - accuracy: 0.7473 - val_loss: 0.7103 - val_accuracy: 0.7729\n",
            "Epoch 535/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6573 - accuracy: 0.7424 - val_loss: 0.7396 - val_accuracy: 0.7295\n",
            "Epoch 536/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6471 - accuracy: 0.7424 - val_loss: 0.7247 - val_accuracy: 0.7729\n",
            "Epoch 537/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6292 - accuracy: 0.7467 - val_loss: 0.7291 - val_accuracy: 0.7295\n",
            "Epoch 538/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6478 - accuracy: 0.7424 - val_loss: 0.7085 - val_accuracy: 0.7681\n",
            "Epoch 539/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6602 - accuracy: 0.7322 - val_loss: 0.7246 - val_accuracy: 0.7488\n",
            "Epoch 540/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6299 - accuracy: 0.7521 - val_loss: 0.7017 - val_accuracy: 0.7729\n",
            "Epoch 541/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6246 - accuracy: 0.7563 - val_loss: 0.7050 - val_accuracy: 0.7681\n",
            "Epoch 542/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6375 - accuracy: 0.7527 - val_loss: 0.7194 - val_accuracy: 0.7585\n",
            "Epoch 543/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6531 - accuracy: 0.7485 - val_loss: 0.7234 - val_accuracy: 0.7488\n",
            "Epoch 544/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6044 - accuracy: 0.7594 - val_loss: 0.7037 - val_accuracy: 0.7343\n",
            "Epoch 545/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6317 - accuracy: 0.7539 - val_loss: 0.7153 - val_accuracy: 0.7633\n",
            "Epoch 546/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6365 - accuracy: 0.7545 - val_loss: 0.7152 - val_accuracy: 0.7681\n",
            "Epoch 547/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6550 - accuracy: 0.7557 - val_loss: 0.7113 - val_accuracy: 0.7440\n",
            "Epoch 548/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6477 - accuracy: 0.7600 - val_loss: 0.7110 - val_accuracy: 0.7681\n",
            "Epoch 549/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6177 - accuracy: 0.7690 - val_loss: 0.7173 - val_accuracy: 0.7391\n",
            "Epoch 550/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6253 - accuracy: 0.7570 - val_loss: 0.6899 - val_accuracy: 0.7440\n",
            "Epoch 551/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6310 - accuracy: 0.7539 - val_loss: 0.7154 - val_accuracy: 0.7440\n",
            "Epoch 552/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6179 - accuracy: 0.7600 - val_loss: 0.7022 - val_accuracy: 0.7536\n",
            "Epoch 553/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6357 - accuracy: 0.7467 - val_loss: 0.7068 - val_accuracy: 0.7585\n",
            "Epoch 554/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6259 - accuracy: 0.7570 - val_loss: 0.7207 - val_accuracy: 0.7343\n",
            "Epoch 555/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6365 - accuracy: 0.7497 - val_loss: 0.7184 - val_accuracy: 0.7295\n",
            "Epoch 556/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6465 - accuracy: 0.7418 - val_loss: 0.7091 - val_accuracy: 0.7246\n",
            "Epoch 557/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6367 - accuracy: 0.7551 - val_loss: 0.7104 - val_accuracy: 0.7343\n",
            "Epoch 558/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6239 - accuracy: 0.7509 - val_loss: 0.7039 - val_accuracy: 0.7488\n",
            "Epoch 559/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6266 - accuracy: 0.7533 - val_loss: 0.7164 - val_accuracy: 0.7488\n",
            "Epoch 560/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6527 - accuracy: 0.7473 - val_loss: 0.7077 - val_accuracy: 0.7633\n",
            "Epoch 561/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6469 - accuracy: 0.7443 - val_loss: 0.7094 - val_accuracy: 0.7633\n",
            "Epoch 562/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6246 - accuracy: 0.7527 - val_loss: 0.7191 - val_accuracy: 0.7536\n",
            "Epoch 563/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6230 - accuracy: 0.7551 - val_loss: 0.7007 - val_accuracy: 0.7488\n",
            "Epoch 564/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6037 - accuracy: 0.7545 - val_loss: 0.6998 - val_accuracy: 0.7585\n",
            "Epoch 565/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6098 - accuracy: 0.7545 - val_loss: 0.6996 - val_accuracy: 0.7681\n",
            "Epoch 566/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6048 - accuracy: 0.7545 - val_loss: 0.7101 - val_accuracy: 0.7585\n",
            "Epoch 567/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6215 - accuracy: 0.7473 - val_loss: 0.6870 - val_accuracy: 0.7681\n",
            "Epoch 568/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6348 - accuracy: 0.7527 - val_loss: 0.7040 - val_accuracy: 0.7729\n",
            "Epoch 569/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6325 - accuracy: 0.7563 - val_loss: 0.6973 - val_accuracy: 0.7729\n",
            "Epoch 570/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6022 - accuracy: 0.7672 - val_loss: 0.6906 - val_accuracy: 0.7681\n",
            "Epoch 571/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6021 - accuracy: 0.7648 - val_loss: 0.6861 - val_accuracy: 0.7729\n",
            "Epoch 572/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6169 - accuracy: 0.7582 - val_loss: 0.7019 - val_accuracy: 0.7681\n",
            "Epoch 573/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6124 - accuracy: 0.7503 - val_loss: 0.7231 - val_accuracy: 0.7633\n",
            "Epoch 574/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6157 - accuracy: 0.7588 - val_loss: 0.6966 - val_accuracy: 0.7488\n",
            "Epoch 575/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6221 - accuracy: 0.7660 - val_loss: 0.6761 - val_accuracy: 0.7729\n",
            "Epoch 576/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6157 - accuracy: 0.7672 - val_loss: 0.6926 - val_accuracy: 0.7681\n",
            "Epoch 577/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6218 - accuracy: 0.7557 - val_loss: 0.6904 - val_accuracy: 0.7729\n",
            "Epoch 578/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5913 - accuracy: 0.7733 - val_loss: 0.6912 - val_accuracy: 0.7585\n",
            "Epoch 579/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5970 - accuracy: 0.7684 - val_loss: 0.6838 - val_accuracy: 0.7681\n",
            "Epoch 580/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6169 - accuracy: 0.7545 - val_loss: 0.6892 - val_accuracy: 0.7681\n",
            "Epoch 581/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6006 - accuracy: 0.7727 - val_loss: 0.7009 - val_accuracy: 0.7681\n",
            "Epoch 582/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6155 - accuracy: 0.7588 - val_loss: 0.6712 - val_accuracy: 0.7681\n",
            "Epoch 583/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6202 - accuracy: 0.7533 - val_loss: 0.6992 - val_accuracy: 0.7536\n",
            "Epoch 584/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5781 - accuracy: 0.7751 - val_loss: 0.6986 - val_accuracy: 0.7536\n",
            "Epoch 585/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6042 - accuracy: 0.7727 - val_loss: 0.6915 - val_accuracy: 0.7633\n",
            "Epoch 586/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5966 - accuracy: 0.7654 - val_loss: 0.6906 - val_accuracy: 0.7536\n",
            "Epoch 587/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5896 - accuracy: 0.7690 - val_loss: 0.6892 - val_accuracy: 0.7585\n",
            "Epoch 588/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6054 - accuracy: 0.7721 - val_loss: 0.6925 - val_accuracy: 0.7681\n",
            "Epoch 589/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5763 - accuracy: 0.7684 - val_loss: 0.6750 - val_accuracy: 0.7778\n",
            "Epoch 590/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5889 - accuracy: 0.7690 - val_loss: 0.6620 - val_accuracy: 0.7729\n",
            "Epoch 591/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6167 - accuracy: 0.7563 - val_loss: 0.6799 - val_accuracy: 0.7778\n",
            "Epoch 592/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5871 - accuracy: 0.7733 - val_loss: 0.6685 - val_accuracy: 0.7778\n",
            "Epoch 593/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5986 - accuracy: 0.7684 - val_loss: 0.6837 - val_accuracy: 0.7488\n",
            "Epoch 594/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5834 - accuracy: 0.7654 - val_loss: 0.6624 - val_accuracy: 0.7681\n",
            "Epoch 595/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5732 - accuracy: 0.7811 - val_loss: 0.6778 - val_accuracy: 0.7729\n",
            "Epoch 596/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5809 - accuracy: 0.7721 - val_loss: 0.6738 - val_accuracy: 0.7585\n",
            "Epoch 597/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6080 - accuracy: 0.7715 - val_loss: 0.6701 - val_accuracy: 0.7778\n",
            "Epoch 598/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6132 - accuracy: 0.7557 - val_loss: 0.6756 - val_accuracy: 0.7633\n",
            "Epoch 599/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5845 - accuracy: 0.7636 - val_loss: 0.6733 - val_accuracy: 0.7633\n",
            "Epoch 600/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5695 - accuracy: 0.7769 - val_loss: 0.6750 - val_accuracy: 0.7681\n",
            "Epoch 601/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5927 - accuracy: 0.7672 - val_loss: 0.6641 - val_accuracy: 0.7729\n",
            "Epoch 602/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6017 - accuracy: 0.7648 - val_loss: 0.6720 - val_accuracy: 0.7778\n",
            "Epoch 603/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5884 - accuracy: 0.7690 - val_loss: 0.6944 - val_accuracy: 0.7633\n",
            "Epoch 604/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5835 - accuracy: 0.7618 - val_loss: 0.6759 - val_accuracy: 0.7633\n",
            "Epoch 605/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5818 - accuracy: 0.7715 - val_loss: 0.6661 - val_accuracy: 0.7681\n",
            "Epoch 606/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5909 - accuracy: 0.7678 - val_loss: 0.6997 - val_accuracy: 0.7391\n",
            "Epoch 607/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5685 - accuracy: 0.7787 - val_loss: 0.6736 - val_accuracy: 0.7633\n",
            "Epoch 608/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5932 - accuracy: 0.7751 - val_loss: 0.6642 - val_accuracy: 0.7778\n",
            "Epoch 609/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5989 - accuracy: 0.7618 - val_loss: 0.6693 - val_accuracy: 0.7729\n",
            "Epoch 610/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5993 - accuracy: 0.7793 - val_loss: 0.6759 - val_accuracy: 0.7778\n",
            "Epoch 611/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5932 - accuracy: 0.7612 - val_loss: 0.6732 - val_accuracy: 0.7778\n",
            "Epoch 612/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5720 - accuracy: 0.7727 - val_loss: 0.6651 - val_accuracy: 0.7874\n",
            "Epoch 613/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5981 - accuracy: 0.7703 - val_loss: 0.6733 - val_accuracy: 0.7681\n",
            "Epoch 614/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5858 - accuracy: 0.7721 - val_loss: 0.6746 - val_accuracy: 0.7729\n",
            "Epoch 615/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5669 - accuracy: 0.7775 - val_loss: 0.6697 - val_accuracy: 0.7874\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(cnnhistory.history['loss'])\n",
        "plt.plot(cnnhistory.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train','test'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "oQYnuaCrDH_A",
        "outputId": "cba2a639-e648-4fe1-b73a-ebfc5db23ed1"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXgAAAEWCAYAAABsY4yMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dd3xc1Z338c9virosq7rJRRQ3jHHDYDAEU21aSGBJQiAhybMm++TZkF2WBPYJsGQ3uyTZh7DJEgIsEBIIhGAICTEBAzYmNGMbA264gItcJFm2rN5mzvPHvTKSJVcYjebq+3699PLMrecI8Z0z5557rjnnEBGR4AkluwAiIpIYCngRkYBSwIuIBJQCXkQkoBTwIiIBpYAXEQkoBbwIYGa/MrN/O8xtN5nZuZ/0OCKJpoAXEQkoBbyISEAp4CVl+F0jN5rZe2bWYGYPmNkgM3vOzOrM7EUzy++0/aVmtsrMasxskZmN67Ruspkt9/f7HZCx37kuNrMV/r6vm9nEoyzz35rZBjPbbWZ/NLOh/nIzs5+aWaWZ1ZrZ+2Y2wV93oZmt9su2zcz+6ah+YdLvKeAl1VwOnAeMBi4BngP+GSjG+3v+NoCZjQYeA77jr5sP/MnM0swsDfgD8BugAPi9f1z8fScDDwLXAYXAvcAfzSz9SApqZmcD/wFcCQwBNgOP+6vPB87065Hnb1Ptr3sAuM45lwtMAF4+kvOKdFDAS6r5uXOuwjm3DXgVeMs5945zrhl4Gpjsb/cF4M/OuQXOuTbgP4FM4DTgVCAK3OWca3POPQm83ekcc4F7nXNvOedizrmHgRZ/vyPxZeBB59xy51wLcDMww8xGAW1ALjAWMOfcGufcDn+/NmC8mQ1wzu1xzi0/wvOKAAp4ST0VnV439fA+x389FK/FDIBzLg5sBYb567a5rjPtbe70eiRwg989U2NmNcBwf78jsX8Z6vFa6cOccy8D/w3cDVSa2X1mNsDf9HLgQmCzmb1iZjOO8LwigAJegms7XlADXp83XkhvA3YAw/xlHUZ0er0V+KFzbmCnnyzn3GOfsAzZeF0+2wCccz9zzk0FxuN11dzoL3/bOfdZoASvK+mJIzyvCKCAl+B6ArjIzM4xsyhwA143y+vAG0A78G0zi5rZ54Hpnfa9H/immZ3iXwzNNrOLzCz3CMvwGPA1M5vk99//O16X0iYzO9k/fhRoAJqBuH+N4Mtmlud3LdUC8U/we5B+TAEvgeSc+wC4Gvg5sAvvguwlzrlW51wr8HngWmA3Xn/9U532XQr8LV4Xyh5gg7/tkZbhReAWYB7et4ZjgS/6qwfgfZDswevGqQZ+4q+7BthkZrXAN/H68kWOmOmBHyIiwaQWvIhIQCngRUQCKqEBb2YDzexJM1trZms03EtEpPdEEnz8/wL+4py7wr97MCvB5xMREV/CLrKaWR6wAjjGHeZJioqK3KhRoxJSHhGRIFq2bNku51xxT+sS2YIvA6qAh8zsJGAZcL1zrqHzRmY2F+/WcEaMGMHSpUsTWCQRkWAxs80HWpfIPvgIMAW4xzk3Ge9mjpv238g5d59zbppzblpxcY8fQiIichQSGfDlQLlz7i3//ZN4gS8iIr0gYQHvnNsJbDWzMf6ic4DViTqfiIh0lehRNH8PPOqPoPkQ+NqRHqCtrY3y8nKam5s/9cL1JRkZGZSWlhKNRpNdFBEJiIQGvHNuBTDtkxyjvLyc3NxcRo0aRdfJ/4LDOUd1dTXl5eWUlZUluzgiEhB9/k7W5uZmCgsLAxvuAGZGYWFh4L+liEjv6vMBDwQ63Dv0hzqKSO9KiYA/lIraZuqa25JdDBGRPiUQAV9V10J9c3tCjl1TU8MvfvGLI97vwgsvpKamJgElEhE5PIEIeAMSNav9gQK+vf3gHyjz589n4MCBCSqViMihJXqYZO9IYPf1TTfdxMaNG5k0aRLRaJSMjAzy8/NZu3Yt69at47LLLmPr1q00Nzdz/fXXM3fuXABGjRrF0qVLqa+vZ86cOcycOZPXX3+dYcOG8cwzz5CZmZm4QouIkGIBf/ufVrF6e2235Y2t7URCIdIiR/6FZPzQAdx2yQkHXH/HHXewcuVKVqxYwaJFi7joootYuXLlvuGMDz74IAUFBTQ1NXHyySdz+eWXU1hY2OUY69ev57HHHuP+++/nyiuvZN68eVx99dVHXFYRkSORUgF/YL03AmX69Oldxqr/7Gc/4+mnnwZg69atrF+/vlvAl5WVMWnSJACmTp3Kpk2beq28ItJ/pVTAH6ilvXpHLQMyIpTmJ366+ezs7H2vFy1axIsvvsgbb7xBVlYWZ511Vo9j2dPT0/e9DofDNDU1JbycIiKBuciaqKusubm51NXV9bhu79695Ofnk5WVxdq1a3nzzTcTUwgRkaOQUi34g0nUKJrCwkJOP/10JkyYQGZmJoMGDdq3bvbs2fzyl79k3LhxjBkzhlNPPTVBpRAROXIJe6LT0Zg2bZrb/4Efa9asYdy4cQfdb+2OWrLTIwwvSO0nAh5OXUVEOjOzZc65Huf8CkQXDZa4FryISKoKRMAbBn3om4iISF8QiIAHteBFRPYXiIDXRIwiIt0FIuBBPTQiIvsLRMCrAS8i0l0gAj6Ro2iOdrpggLvuuovGxsZPuUQiIocnEAFvCWzDK+BFJFUF507WBHXCd54u+LzzzqOkpIQnnniClpYWPve5z3H77bfT0NDAlVdeSXl5ObFYjFtuuYWKigq2b9/OrFmzKCoqYuHChQkpn4jIgaRWwD93E+x8v9viYW0x70U0fOTHHHwizLnjgKs7Txf8wgsv8OSTT7JkyRKcc1x66aUsXryYqqoqhg4dyp///GfAm6MmLy+PO++8k4ULF1JUVHTk5RIR+YQC0UXTW1544QVeeOEFJk+ezJQpU1i7di3r16/nxBNPZMGCBXzve9/j1VdfJS8vL9lFFRFJsRb8AVraO6rqcQ6OLclJ6Omdc9x8881cd9113dYtX76c+fPn8/3vf59zzjmHW2+9NaFlERE5lMC04BM1iqbzdMEXXHABDz74IPX19QBs27aNyspKtm/fTlZWFldffTU33ngjy5cv77aviEhvS60W/AGYJW4ums7TBc+ZM4errrqKGTNmAJCTk8MjjzzChg0buPHGGwmFQkSjUe655x4A5s6dy+zZsxk6dKgusopIrwvEdMEf7WqgPRbn+EG5iSxewmm6YBE5UoGfLlh3soqIdBeIgAfNJikisr+E9sGb2SagDogB7Qf6GnEozjmvn/2A5zmq4vUpfamrTESCoTcuss5yzu062p0zMjKorq6msLDwoCGfyvnonKO6upqMjIxkF0VEAqTPj6IpLS2lvLycqqqqA26zu6GVtlic+J7UDciMjAxKS0uTXQwRCZBEB7wDXjAzB9zrnLtv/w3MbC4wF2DEiBHdDhCNRikrKzvoSb7z+Du8s7WGV26c9akUWkQkCBJ9kXWmc24KMAf4lpmduf8Gzrn7nHPTnHPTiouLj+okITNi8RTuoxERSYCEBrxzbpv/byXwNDA9EecJhYy4Al5EpIuEBbyZZZtZbsdr4HxgZSLOFTYjlspXWUVEEiCRffCDgKf9kS8R4LfOub8k4kShkKEGvIhIVwkLeOfch8BJiTp+ZyFDXTQiIvsJxJ2s4ZC6aERE9heIgNcoGhGR7gIR8GGNohER6SY4Aa98FxHpIhABb4b64EVE9hOIgA+bumhERPYXjIDXKBoRkW4CEfAhM5zTnOoiIp0FJuABXWgVEekkEAEf9muhsfAiIh8LRMCHQh0teAW8iEiHQAR8NORVoy0WT3JJRET6jkAEfFqkI+DVghcR6RCIgI/6nfCt7WrBi4h0CETAf9yCV8CLiHQIRMBHw95F1ha14EVE9glEwKeF1YIXEdlfMAI+oj54EZH9BSLgo2rBi4h0E4iAVwteRKS7QAT8vmGSasGLiOwTiIBP141OIiLdBCLgdaOTiEh3gQh43egkItJdIAK+40YnteBFRD4WiIDfN4pGLXgRkX2CEfDqgxcR6SYYAa8+eBGRbgIR8BpFIyLSXcID3szCZvaOmT2bqHNE/Ef2qQUvIvKx3mjBXw+sSeQJzIy0SIgWBbyIyD4JDXgzKwUuAv4nkecB70JrW7vuZBUR6ZDoFvxdwHeBAzatzWyumS01s6VVVVVHfaK0SIjWWOyo9xcRCZqEBbyZXQxUOueWHWw759x9zrlpzrlpxcXFR32+aNjUghcR6SSRLfjTgUvNbBPwOHC2mT2SqJOlRUK6yCoi0knCAt45d7NzrtQ5Nwr4IvCyc+7qRJ0vGtZFVhGRzgIxDh46LrIq4EVEOkR64yTOuUXAokSew7vIqoAXEekQrBa8Al5EZJ/ABHw0HNJUBSIinQQm4L0uGg2TFBHpEJiAVwteRKSrwAR8WsTUBy8i0klwAl4teBGRLgIT8FGNohER6SIwAZ8WUQteRKSzwAR8NKwbnUREOgtMwKdrsjERkS4CE/AaJiki0lVgAj4tEiLuIBbXzU4iIhCwgAdoaddTnUREIEABn+EHfHObumlERCBIAR8NA9Dcpha8iAgo4EVEAitwAd+kgBcRAQIV8OqDFxHpLEAB77XgW9SCFxEBAhjwzRomKSICHGbAm9n1ZjbAPA+Y2XIzOz/RhTsS6qIREenqcFvwX3fO1QLnA/nANcAdCSvVUcjUKBoRkS4ON+DN//dC4DfOuVWdlvUJGkUjItLV4Qb8MjN7AS/gnzezXKBP9YVkRDpa8H2qWCIiSRM5zO2+AUwCPnTONZpZAfC1xBXryKXv64NXC15EBA6/BT8D+MA5V2NmVwPfB/YmrlhHLj0SwkzDJEVEOhxuwN8DNJrZScANwEbg1wkr1VEwM7KiYRpbFfAiInD4Ad/unHPAZ4H/ds7dDeQmrlhHJys9QkNre7KLISLSJxxuH3ydmd2MNzzyDDMLAdHEFevo5KRHaGhRC15EBA6/Bf8FoAVvPPxOoBT4ycF2MLMMM1tiZu+a2Sozu/0TlvWQstLCNLSoBS8iAocZ8H6oPwrkmdnFQLNz7lB98C3A2c65k/BG4Mw2s1M/UWkPITs9Qr0CXkQEOPypCq4ElgB/A1wJvGVmVxxsH+ep999G/Z+EPjA1R33wIiL7HG4f/P8FTnbOVQKYWTHwIvDkwXYyszCwDDgOuNs591YP28wF5gKMGDHi8Eveg6y0MI3qgxcRAQ6/Dz7UEe6+6sPZ1zkXc85Nwuuzn25mE3rY5j7n3DTn3LTi4uLDLE7PctRFIyKyz+G24P9iZs8Dj/nvvwDMP9yT+DdILQRmAyuPrIiHLystoousIiK+w73IeiNwHzDR/7nPOfe9g+1jZsVmNtB/nQmcB6z9ZMU9uJz0MA2tMeLxhHb1i4ikhMNtweOcmwfMO4JjDwEe9vvhQ8ATzrlnj7B8R6QwJx2AXQ0tlORmJPJUIiJ93kED3szq6Hnki+ENlBlwoH2dc+8Bkz9Z8Y7MiIIsALZUNyrgRaTfO2jAO+f63HQEBzOi0Av4zdWNTBtVkOTSiIgkV2CeyQpQmp+JGWzd05jsooiIJF2gAj49EiY3PcKehtZkF0VEJOkCFfAAeVlRaps1VFJEJHABPyAjyt6mtmQXQ0Qk6QIX8HmZCngREQhowNcq4EVEghnwasGLiAQw4AdkRqltVsCLiAQu4Ity0mhui7O3USEvIv1b4AL++BLv5tt1lXVJLomISHIFLuBHD/YC/oOdCngR6d8CF/BD8zLISgvzYVVDsosiIpJUgQt4M6M0P5NyzUcjIv1c4AIeoDQ/i/I9TckuhohIUgU04DM1o6SI9HuBDPiyomzqmtupqG1OdlFERJImkAE/sTQPgPfK9ya5JCIiyRPIgB8/JA8zWLVdAS8i/VcgAz4zLUxhdjo796qLRkT6r0AGPMDgvHR2qg9eRPqx1A945+DJr8OKx7osHjwgQy14EenXUj/gzeDDRVC+pMviQQMyNIpGRPq11A94gJzBUFfRZdGYwbnsaWxj+ZY9SSqUiEhyBSPgcwdD3Y4uiy6fUkpGNMSz7+44wE4iIsEWkIAfAvVdW/DZ6RHGDxnASg2VFJF+KiABPwjqdkI83mXxhGF5rNq2l7ZY/AA7iogEVzACPqsIXAxaurbWTz+uiIbWGG9srE5SwUREkicYAZ8xwPu3petDPj4zupj8rCh3L9yQhEKJiCRXwgLezIab2UIzW21mq8zs+kSdi3TvKU4013ZZnBEN861Zx/HWR7vZWFWfsNOLiPRFiWzBtwM3OOfGA6cC3zKz8Qk5U3pHC76226qLJg4B4OU1lQk5tYhIX5WwgHfO7XDOLfdf1wFrgGEJOVlHwDd3D/gheZmU5Kbzw/lreG3DroScXkSkL+qVPngzGwVMBt7qYd1cM1tqZkurqqqO7gQH6IPvsKu+BYCbnnrv6I4vIpKCEh7wZpYDzAO+45zr1sR2zt3nnJvmnJtWXFx8dCfZ1wdf0+Pq784eC0BlbYue1Soi/UZCA97Monjh/qhz7qmEnaiji2b+P0F7a7fV3/zMsTzyjVOIhkN85cElxOMuYUUREekrEjmKxoAHgDXOuTsTdR4Aopkfv67d1uMmM48v4rZLxvNhVQP3vfphQosjItIXJLIFfzpwDXC2ma3wfy5MyJnM4HR/FOayXx1ws/NPGIwZ3PHcWmbftZj3ynvu0hERCYJEjqL5q3POnHMTnXOT/J/5iTofU6/1/n3tLmjpecx7XmaUV787C4C1O+u45ZlVxNRdIyIBFYw7WQEGlH78evdG2Pl+j5uV5mex4B/OBODdrTVc//g7vVE6EZFeF5yAj6TBKX/nvb73TPjlTKjd3uOmxw/K5aFrTwbg2fd28J/Pf0C7JiQTkYAJTsADnPyNru/f//0BN501toQ3bj6bSMj474UbOOXfX+KaB96isq6ZptZYggsqIpJ4wQr43MFd3y+4Fao+OODmQ/IyWfr9c7ntkvFUN7Ty6vpdTP/hS4y79S/86d3txONOffQikrLMub4TYNOmTXNLly79ZAd59h+gaDS89jOo2w7hdDj3Nlj9DFw7H8KRHnfbWFXPOf/vlW7Lxw0ZwJ/+z+lEwsH6LBSRYDCzZc65aT2uC1zAd1j8E3j537ouKxoNYy+C0umwtxzGf9Z7WIhv5ba9jB2cy5JNu7lrwXqWbNoNwOcnD2PW2BJOKSugZEDGp1M+EZFPQf8MeOegvRlWzvN+ti3vPpVByXgIp3lhf+FPYPQF4OKQnks87nh5bSV3vbSOlds+nmHh5FH53HfNNPKz0z6dcoqIfAL9M+B7suK3sOZZmPQl2PImvPcENPQwjXDxOPjCIxBJp2Z3Jf/45+2s276Lcleyb5MfXz6RyyYPIy2irhsRSR4F/ME074XdH8KfvuO15M2gofuslo2hHL4x8EHSc/NZ9MHH679+ehnjhw7g0pOGKuxFpNcdLOB7vuLYn2TkwdDJMHcRxNqgrQHWvwir/wBrn923WVa8nsdavw2jvsqmkYN4e105G6sa+OVr3vrXN+4iMxrmu7PHkpcZTUpVREQ6Uwv+YFoboGIV5A2HV34Eyx7qtsmOWT/lR2sK+MMmL9SnlxUwoiCLEQVZnH5cEVNH5vd2qUWkH1EXzafBOahaC9uWwQfPdWndd3io/QJub/9ql2UL/uFMMqJhhhdk9VZJRaQfUcAnylv3wnPf7bLowfxvM+fiK/mXB+bxYnwKMcIAZKWFuWzyMG69eDwZ0XAySisiAaSAT6T2FqhYCfef3ePqOS3/wRo3kuNLclhf6c1y+fkpw9jb2MadX5ik/noR+UQU8L0h1g4bX4ZoBix9CFZ9/AArlzOIpjGf50uvD+F9dwxxf4aIS08ayg3nj2ZkYXaySi0iKU4BnyxV6+Duk7ssioeiLJ7xIN9+qZlavGCfMGwAl08p5fTjikgLhxicl6FuHBE5LAr4ZNqzCcqXeo8VfO57sHfrvlUr4sfy721XscSN67LLoAHpPPq/TqGsKIfqhhZKcjU9goj0TAHfV8TjsOV1WL8A6itg82u4ljoaz7iFnW/+jl/XTOTh1ln7No+EjJhzLPqns9SNIyI9UsD3Vbs2wG8u69KqZ+RMdldt54c15zMrZzPP1o9hSeZMPjO6mOMH5fB3nzkW73nmIiIK+L4t1uZNlbDpVVhyP9RXQtPuLpv8MPsm7q8+kTTasUg6cyYM5rLJwxg3ZABFOenUNrVp8jORfkoBn0pibX7Y/w+kZUHlWqh4n1hWCQ0N9dzZfgW1Loun4md22W3ND2aTmaYLsyL9jQI+lcXa4a17YONC2PjSvsW/zvoqG4vP4eEPPp5O6PIppZTmZ3LtaaPUohfpJxTwQbHqaWjYBX+9C2rLAWjNK+OdmgxuaP0m5a5436Y56RH+7qxjeWLpViYPH8htl5yg0BcJIAV80LQ1eSNxNr/mPVi8sXrfqpU5p1HZHGZe42Tmx6fj/JuqwiEjPyuNH19xIrPGlNDYGqOuuZ3BeRqCKZLKFPBBt225Ny9O+duwe+O+xXvzJ/Dm6Bv5zfLdpDVVUua28lRsJnvIpYA69pDD1JGFfPuc4zlzdPFBTiAifZUCvr9Z/yK897jXuu/BkvgYpth6lrnRfKX1JlpI46KJQ8iMhrn1kvFkRMJEw8aOvc0MHZjZy4UXkSOhgO+vmmu9OeybasBCkD8SXvlx13H3wMuxSdzTfilL3WhyaaI5kktre3zf+n//3IkMzktn6ogCYs5RoL58kT5DAS8fa2+FJffC2Ivhw4Ww+Q14/4kumyyJTGVB0xgayWCw7eah9tnsZgDg9eV/dtJQvjJjFEPyMog7RyQUojg3PRm1Een3FPBycJVr4Zn/TbyhmlDNph432Zg9mXk1o5mZu4NX64byQnwqYeJUZh5DLBbnqlNHcu64QYzPB5Y/zKL8y5k9cTjhkO66FUmkpAS8mT0IXAxUOucmHM4+Cvg+oHY7bHgJsoshcyCsex7evAfn4lispcumcWe87KYwxT7g8djZvBibwt+EX+FLkYX8Y+s3eSp+Jo984xQq65r57KRhhEPGPYs2MmZwDmePHZSkCooES7IC/kygHvi1Aj7FOQfxmPcg8mf/EYafjMsdQsuav5DRXHXA3RbHTsRwfLvt/1AbymPMoFxW76gF4MFrpzGyMJuywmxClSshdyhkF/ZWjUQCI2ldNGY2CnhWAR9Qe7fBu7+F8Z/znlH71r1Qt73bZg+1X8BqN5Krwi/zk/YrGcQexoa2sCg+iePS9/Kv7r9ZFj+e67N/zMmjCrj+nOMpzk3HDDKjYU2uJnIQfTrgzWwuMBdgxIgRUzdv3pyw8kiCNdfCh4vguHOgZiutLQ3Uzr+doh2vHNbuj7afw1o3nM+H/0q5K+JH7V/ktsiveafoEtJOuJi8zChvf1RNdnqUL5w8nOLcdAbnZZAe0Rw80n/16YDvTC34AHIOdrzrzZhZOg2WPezNqTP9OtjzEbveX0Dj+CsZ/votWLytx0M0uTQej83igvDbDLXd/Gvb1ayMl7HRDWWk7eTMjI1sG3wOQ62asukXcuKwPPIyo+RnpRHSRV4JOAW89H271kNWIbx2F4w6g70b32JPU4zhJYWEXr8LazhwX39nX239Hq/HT6CNCMcWZ3PTnHE0trYzb/k2Fq+r4pSyAn5wyTiOKUwnmp7J86t2srexjStPHg7A+oo6jivJUbeQpAwFvKS29hZoqYesAmja492stXIepOd43wx60EgGy90YtsQKGGK7GRPayrL4aNbER3JleBGjQhU80f4Zfh07j1NDa3ias9kdz8Cc48Jj0/mPa2aREQ3jHKRtehlCUTjmM71ccZFDS9YomseAs4AioAK4zTn3wMH2UcDLUXEOXBzeuBsXa8Ve/lcA4qE0QvFW4oQIET/EQWBzvISRocp97/8ndAXLm4fyi7SfAXDTwJ9w4ZzLGDIwk/WV9azeXstpxxUysjCb7LQwA7MOfodvY2s76ZGw7g2QT5VudJL+pbXRe1hK816v5Z9dDO3N0LQHl5nPm+WtTMvawZYVCxm2669kfPg8DqM9kk20vf6gh14RP5YS28NWV0I6bSyNj+b+9osoGjqKr5yUy+iK+cyrHMq6thLmjm1i6u757D7rDtpCafz9z3/PRWMHMGD4eGraInz2mBCvVUa5ZsYor0toxW9hxAwoKOulX5QEgQJe5FCcAzPqqrcTj+RQufUD5j/7FNObFjPDVtJGhCjt3XZrd950zDspIEKMwbanx8O3ujBpFgNgh/O6jTqWLyr6Moujp/NvO68DYNdZP6IgPU7r4ClEBg6jNpZOvKmGLVu3MHnyNOyhC3HHnUv1cZ+nMD2ODZvijWB66m/hjBu8Rz/O+md9UPQTCniRo9TS1o5VriJt6ETvLl8LQfUGbzjomf+Eq9tJ62u/YP3GDeS1VlBR30Y8s4ipxw9j54fvY8017MydwIn1rxGNNXU59p7oIPLbKj5R+WKEqLj41xS/9R9Eq1Z1XVk0GoZPh8EnQd4wr/xDp0DpVG+9/6HmVbTOe1+3Exp3ed8kerrQvOVNyBmkD48+RAEv0ks2VtWTn5XWfcbNtiYvYPPLoL4CMvIgmgmNu6le/gwZDVupqGtj/rtb2OEK+WbGAirbMnAYVS6Ps0MrqCKPUttFi4uQbt2/TRyNnaVzGDzpAnj2O11XXP4AHH++F+gNlXDSVbDmj/Dk16BoDMxd5D17oHyp9+FR9hmwMCx/2Jvi4oTPecdpbYC07I+P21IPe8uhZKxfgJVQcIzXpSZHRQEvkiKaWmNsrKpnwrC8fcueWbGNp9/Zxvdmj2VLVQ201FG57SMuLW2mouhk1j7xL/xqz0T2kk2J1VDEXu6I3s9f4tN5qP0Cnky7nQxr48dtV/Ld6BMHOfuBNacVkNG6m9ZQJmnxpkPvkDfcm5Y6LRdOvAI+eM5r9W95w1s/8x9g5Ex49HKY+AW49Oew+D+hYiWMnu2NnCoog5GneR8Q25bD6mfglOsgswBqt8HAkd6d01ve8qa5OPbsnssSj8HGl70PoUjwprpWwIsEnHOOv27YxZC8DM69czE/vmIiC1ZXcP74QbyzqYqpIweyblcLb36wjZkti5ncGmwAAAt5SURBVHkpdDrfmT2BWx5dyIzQao4J7WBe7AwaXCbH2nauirxEhBgn2UYaySCNNl6LT+AX7Z/lq5EXOMk20pI3iqLiweTsXklu1FG4622awjlEYs09Xq/Yp2g07Fp3ePXKKsSGToYNL3oL8stgz0fdN7QwfOUPsPN97wNgzybvUZbZxfDRYtj8V2+79AEw9aveNNml06B4jNctlTvY276uAoZNhYYq78J86TTvG0bGQO9b17Zl8PYDcNF/dv1mkkQKeBHp0Z0L1rGnoZV/ufQEFq+vYmNlPScOy+N3S7fy1PJt3HrxeH7w7Opu++WkR2iPx2lu+3j46TCqvMdBWh2jh+TT1lTLtppmRls578SP45TQGra7QgaNP4Oztt5NVWuUVa1DmB1ZykXZ6wg17aI1nM2fBnyRM8Ir+Zftp3BbyasMqnkHgNoTr2XA+7/qXokpX4F3HvGGyibSwJFQ40+lkl0CEy6HllpY8SjkDPa+QWTkecsLj/VGceUNh3DE22fLm/DBfNi6xPsGM/qCT6VYCngROWJVdS0U56azctte8jKjtMcdOekRwiGjIDuNdRV1/HHFdr4+s4x3y2sAmHFMIQvXVvLtx99h0IAMPjd5GEs+2k1VXQtpkRC76lvYVd8KQDRsXHvaKO5/9SPAYTgixGkj0qUcpVZJCTUsd6OZUhRn1S7v20GJ7eErk/M59+zzWbL4OcqqX2FiTh1ptFLT0Er5sV8kvbiMsqIstrTmUpqXxqYl8xmT72gvHEs0LZ1dbWkUvfLPsPsjOO92GHEqbHmTNsKEopmENy+G957wrptkFXrXEEIRaGvo/gtLz4OWvd2XZwz0Llg37TfCKqsI4u0QTvPOe/kDR9WFpIAXkV61ubqBwpx0ctK7hnVjazvV9a2UDEjHOciIhpm3rJxlW/bw7tYaxg0ZwEUnDmH1jlp27G1ixdYaThw2kMeWbNl3jMxomKa2WLdzmkFJbjoVtS3d1nV2bHE2m6obOXdcCc+vquB/zSzj/BMGs3LbXl5dX0Vpfhavrq8i5hzzvnkaJQMyWL6pitaYcWppuvdUtA0L4ITPexegl/8Gys6AUTO9D4oHL/A+EAAGT/y4NV+zFfJHQcUqr6U/cDjs2eytx+BLvz2q37UCXkRSWl1zG2bGz19az9WnjiQaDlFR28zrG6t5eW0F379oPJGw8fe/fYcPdzVw9akjyMuMcvfCjcwaU0w4ZLy4pvLQJ+rBjGMKeePDagBOKs0jKy3Chqp6SnLTOXFYHq9t3MXw/Cxuu+QE0iIhduxp5PnVFdx68Xhqmtp4+PVNXDppGEU5aeRlRjEznHM0tMbISY/gnPtEcx8p4EWkX2hpj7FgdQXnjR/UZRpp5xwbKuvJyYiweF0VP/jTauIOXrzhM/z4L2tpaIlRMiCdr502ivKaJppaY2SmhfnWo8tpbI0xoiCLLbsbAcjLjJKdFmb73uZDlqesKJuPdnndOZGQMePYQtIjoS4fNscUZfPw16czvODohooq4EVEOtnT0EooZORlRg+63faaJnY3tHJMcTZbdzdR39LG1JEFANzx3FpCBtPLCrj2obcpyknbd32hs6y0MI2tXpdSeiRES7t3MXjOhME8t3InAFNH5vPEdTOOap6igwV8pKeFIiJBlr//jWgHMHRgJkMHZgIwZnBul3U3zRm77/UbN59NflYaZrC5upHRg3LZXtPEe+V7OXdcCY8t2cJZY0oYNCCDNTtqWbuzliunDWfB6goq6lpYu6OWtliccOjTfXiNWvAiIinsYC34UG8XRkREeocCXkQkoBTwIiIBpYAXEQkoBbyISEAp4EVEAkoBLyISUAp4EZGA6lM3OplZFbD5KHcvAnZ9isVJhiDUAVSPviQIdYBg1CNRdRjpnCvuaUWfCvhPwsyWHuhurlQRhDqA6tGXBKEOEIx6JKMO6qIREQkoBbyISEAFKeDvS3YBPgVBqAOoHn1JEOoAwahHr9chMH3wIiLSVZBa8CIi0okCXkQkoFI+4M1stpl9YGYbzOymZJfnYMzsQTOrNLOVnZYVmNkCM1vv/5vvLzcz+5lfr/fMbErySv4xMxtuZgvNbLWZrTKz6/3lqVaPDDNbYmbv+vW43V9eZmZv+eX9nZml+cvT/fcb/PWjkln+zswsbGbvmNmz/vtUrMMmM3vfzFaY2VJ/WUr9TQGY2UAze9LM1prZGjObkcx6pHTAm1kYuBuYA4wHvmRm45NbqoP6FTB7v2U3AS85544HXvLfg1en4/2fucA9vVTGQ2kHbnDOjQdOBb7l/85TrR4twNnOuZOAScBsMzsV+BHwU+fcccAe4Bv+9t8A9vjLf+pv11dcD6zp9D4V6wAwyzk3qdNY8VT7mwL4L+AvzrmxwEl4/12SVw/nXMr+ADOA5zu9vxm4OdnlOkSZRwErO73/ABjivx4CfOC/vhf4Uk/b9aUf4BngvFSuB5AFLAdOwbvTMLL/3xfwPDDDfx3xt7M+UPZSvNA4G3gWsFSrg1+eTUDRfstS6m8KyAM+2v93msx6pHQLHhgGbO30vtxflkoGOed2+K93AoP8132+bv5X/MnAW6RgPfyujRVAJbAA2AjUOOfa/U06l3VfPfz1e4HC3i1xj+4CvgvE/feFpF4dABzwgpktM7O5/rJU+5sqA6qAh/wus/8xs2ySWI9UD/hAcd7HeEqMWzWzHGAe8B3nXG3ndalSD+dczDk3Ca8VPB0Ym+QiHREzuxiodM4tS3ZZPgUznXNT8LotvmVmZ3ZemSJ/UxFgCnCPc24y0MDH3TFA79cj1QN+GzC80/tSf1kqqTCzIQD+v5X+8j5bNzOL4oX7o865p/zFKVePDs65GmAhXnfGQDOL+Ks6l3VfPfz1eUB1Lxd1f6cDl5rZJuBxvG6a/yK16gCAc26b/28l8DTeB26q/U2VA+XOubf890/iBX7S6pHqAf82cLw/aiAN+CLwxySX6Uj9Efiq//qreH3aHcu/4l9pPxXY2+lrXtKYmQEPAGucc3d2WpVq9Sg2s4H+60y86whr8IL+Cn+z/evRUb8rgJf91ljSOOduds6VOudG4f3tv+yc+zIpVAcAM8s2s9yO18D5wEpS7G/KObcT2GpmY/xF5wCrSWY9kn1h4lO4sHEhsA6v//T/Jrs8hyjrY8AOoA3v0/4beH2gLwHrgReBAn9bwxshtBF4H5iW7PL75ZqJ9xXzPWCF/3NhCtZjIvCOX4+VwK3+8mOAJcAG4PdAur88w3+/wV9/TLLrsF99zgKeTcU6+OV91/9Z1fH/car9TfllmwQs9f+u/gDkJ7MemqpARCSgUr2LRkREDkABLyISUAp4EZGAUsCLiASUAl5EJKAU8CKfAjM7q2M2R5G+QgEvIhJQCnjpV8zsan8e+BVmdq8/4Vi9mf3UvHnhXzKzYn/bSWb2pj9X99Od5vE+zsxeNG8u+eVmdqx/+JxOc4E/6t/1K5I0CnjpN8xsHPAF4HTnTTIWA74MZANLnXMnAK8At/m7/Br4nnNuIt6dhh3LHwXudt5c8qfh3Z0M3sya38F7NsExeHPFiCRN5NCbiATGOcBU4G2/cZ2JN/FTHPidv80jwFNmlgcMdM694i9/GPi9P2fKMOfc0wDOuWYA/3hLnHPl/vsVeHP//zXx1RLpmQJe+hMDHnbO3dxlodkt+213tPN3tHR6HUP/f0mSqYtG+pOXgCvMrAT2PfNzJN7/Bx2zL14F/NU5txfYY2Zn+MuvAV5xztUB5WZ2mX+MdDPL6tVaiBwmtTCk33DOrTaz7+M9OSiEN6vnt/AezDDdX1eJ108P3tSuv/QD/EPga/7ya4B7zewH/jH+pherIXLYNJuk9HtmVu+cy0l2OUQ+beqiEREJKLXgRUQCSi14EZGAUsCLiASUAl5EJKAU8CIiAaWAFxEJqP8PObC3eoPfOnUAAAAASUVORK5CYII=\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(cnnhistory.history['accuracy'])\n",
        "plt.plot(cnnhistory.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train','test'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "IFkTuO8nDNdq",
        "outputId": "dd8a4657-3680-4cbf-a1b6-75e4a79923c5"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model.predict(x_testcnn)"
      ],
      "metadata": {
        "id": "A2xtrN5wDQgY"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_f_ohjXKDUpY",
        "outputId": "01ca6954-bbae-4cae-f255-b39b26083a81"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[2.59630024e-01, 1.03030547e-01, 2.54249960e-01, 1.91078499e-01,\n",
              "        1.62258655e-01, 2.97522824e-02],\n",
              "       [2.29722355e-03, 1.04247456e-05, 9.41716905e-07, 9.84616220e-01,\n",
              "        4.61447082e-04, 1.26138302e-02],\n",
              "       [1.19346730e-01, 6.97022080e-02, 1.36355981e-01, 3.81007493e-01,\n",
              "        6.41948879e-02, 2.29392663e-01],\n",
              "       ...,\n",
              "       [1.24346159e-04, 2.56599742e-06, 1.92294980e-03, 1.71808933e-03,\n",
              "        9.93012965e-01, 3.21916491e-03],\n",
              "       [1.03597567e-05, 3.67877185e-01, 6.28047049e-01, 1.64333533e-03,\n",
              "        1.50627305e-03, 9.15855751e-04],\n",
              "       [2.74007616e-04, 5.54631057e-04, 1.14369564e-01, 3.32627795e-03,\n",
              "        8.20214748e-01, 6.12607338e-02]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cmA2bFgsDW3D",
        "outputId": "994b6595-e8ea-4fd1-87ae-d8e9738ca2ff"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([3, 3, 3, 0, 4, 4, 1, 2, 5, 0, 5, 3, 2, 2, 1, 4, 4, 5, 2, 4, 1, 2,\n",
              "       3, 5, 4, 2, 1, 2, 2, 2, 2, 5, 2, 5, 3, 1, 2, 0, 4, 5, 2, 3, 2, 2,\n",
              "       5, 2, 0, 1, 3, 4, 4, 5, 1, 1, 4, 4, 5, 1, 1, 1, 0, 1, 5, 0, 4, 1,\n",
              "       1, 0, 1, 4, 1, 0, 4, 1, 3, 1, 2, 2, 1, 2, 3, 0, 5, 3, 5, 5, 2, 4,\n",
              "       5, 1, 5, 1, 5, 3, 4, 1, 4, 1, 5, 4, 5, 1, 2, 1, 1, 5, 1, 3, 2, 5,\n",
              "       2, 1, 3, 5, 4, 4, 0, 0, 3, 1, 2, 2, 3, 5, 1, 5, 3, 4, 2, 2, 0, 2,\n",
              "       2, 5, 5, 0, 3, 3, 2, 2, 0, 3, 4, 0, 4, 2, 4, 5, 4, 1, 5, 3, 2, 2,\n",
              "       5, 4, 3, 3, 4, 3, 3, 4, 1, 5, 2, 3, 2, 2, 0, 2, 1, 3, 1, 2, 2, 5,\n",
              "       5, 1, 4, 2, 2, 1, 1, 3, 3, 5, 5, 2, 5, 1, 5, 0, 3, 3, 0, 5, 1, 4,\n",
              "       1, 4, 2, 5, 5, 1, 4, 2, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_Ytest = y_test.astype(int)"
      ],
      "metadata": {
        "id": "0PHDKWJWDY3g"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_Ytest"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k68v2i-pDbZE",
        "outputId": "8f8279b8-1f9a-412f-9a83-f38122e876d7"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([3, 3, 3, 0, 4, 4, 1, 2, 5, 0, 5, 3, 2, 2, 1, 4, 4, 5, 2, 4, 1, 2,\n",
              "       3, 5, 4, 2, 1, 2, 2, 2, 2, 5, 2, 5, 3, 1, 2, 0, 4, 5, 2, 3, 2, 2,\n",
              "       5, 2, 0, 1, 3, 4, 4, 5, 1, 1, 4, 4, 5, 1, 1, 1, 0, 1, 5, 0, 4, 1,\n",
              "       1, 0, 1, 4, 1, 0, 4, 1, 3, 1, 2, 2, 1, 2, 3, 0, 5, 3, 5, 5, 2, 4,\n",
              "       5, 1, 5, 1, 5, 3, 4, 1, 4, 1, 5, 4, 5, 1, 2, 1, 1, 5, 1, 3, 2, 5,\n",
              "       2, 1, 3, 5, 4, 4, 0, 0, 3, 1, 2, 2, 3, 5, 1, 5, 3, 4, 2, 2, 0, 2,\n",
              "       2, 5, 5, 0, 3, 3, 2, 2, 0, 3, 4, 0, 4, 2, 4, 5, 4, 1, 5, 3, 2, 2,\n",
              "       5, 4, 3, 3, 4, 3, 3, 4, 1, 5, 2, 3, 2, 2, 0, 2, 1, 3, 1, 2, 2, 5,\n",
              "       5, 1, 4, 2, 2, 1, 1, 3, 3, 5, 5, 2, 5, 1, 5, 0, 3, 3, 0, 5, 1, 4,\n",
              "       1, 4, 2, 5, 5, 1, 4, 2, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds1=predictions.argmax(axis=1)\n",
        "preds1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4_cAI39VFhtp",
        "outputId": "47f83912-0774-4d36-d664-4405b53cf3cb"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 3, 3, 2, 4, 4, 1, 2, 3, 1, 4, 3, 2, 2, 1, 5, 4, 3, 2, 4, 2, 2,\n",
              "       3, 3, 4, 2, 1, 1, 2, 2, 2, 5, 2, 5, 3, 1, 2, 0, 4, 5, 2, 3, 2, 2,\n",
              "       3, 2, 1, 1, 3, 4, 4, 2, 1, 1, 4, 4, 5, 1, 1, 1, 3, 1, 2, 1, 4, 1,\n",
              "       1, 1, 1, 4, 0, 2, 4, 1, 3, 2, 2, 2, 2, 2, 1, 0, 5, 3, 5, 2, 2, 3,\n",
              "       3, 1, 0, 1, 5, 3, 2, 2, 4, 1, 5, 4, 5, 1, 2, 1, 1, 2, 1, 5, 2, 5,\n",
              "       3, 3, 3, 2, 4, 4, 3, 0, 3, 3, 1, 2, 1, 3, 1, 3, 3, 4, 2, 2, 1, 2,\n",
              "       2, 3, 3, 0, 3, 3, 2, 4, 0, 3, 4, 1, 4, 4, 4, 2, 4, 1, 5, 3, 2, 2,\n",
              "       5, 4, 4, 3, 4, 5, 3, 4, 2, 5, 2, 3, 2, 2, 0, 2, 1, 3, 1, 4, 4, 3,\n",
              "       4, 1, 4, 2, 4, 1, 1, 3, 3, 5, 2, 2, 5, 1, 4, 3, 3, 3, 2, 4, 1, 4,\n",
              "       1, 4, 5, 2, 5, 2, 4, 2, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "abc = preds1.astype(int).flatten()"
      ],
      "metadata": {
        "id": "H4WEmM60NfQn"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "c = confusion_matrix(new_Ytest, abc) \n",
        "c"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bKEBeEBlFjB8",
        "outputId": "1cf42bd6-c3cd-4dab-97a8-abb27e827120"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 6,  6,  3,  3,  0,  0],\n",
              "       [ 1, 32,  6,  2,  0,  0],\n",
              "       [ 0,  2, 36,  1,  5,  1],\n",
              "       [ 1,  2,  0, 25,  1,  2],\n",
              "       [ 0,  0,  1,  1, 30,  1],\n",
              "       [ 1,  0,  8, 10,  4, 16]])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m4RjG7LWLSQx",
        "outputId": "9e49d399-85ee-4495-f655-2932c88c95cc"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([3, 3, 3, 0, 4, 4, 1, 2, 5, 0, 5, 3, 2, 2, 1, 4, 4, 5, 2, 4, 1, 2,\n",
              "       3, 5, 4, 2, 1, 2, 2, 2, 2, 5, 2, 5, 3, 1, 2, 0, 4, 5, 2, 3, 2, 2,\n",
              "       5, 2, 0, 1, 3, 4, 4, 5, 1, 1, 4, 4, 5, 1, 1, 1, 0, 1, 5, 0, 4, 1,\n",
              "       1, 0, 1, 4, 1, 0, 4, 1, 3, 1, 2, 2, 1, 2, 3, 0, 5, 3, 5, 5, 2, 4,\n",
              "       5, 1, 5, 1, 5, 3, 4, 1, 4, 1, 5, 4, 5, 1, 2, 1, 1, 5, 1, 3, 2, 5,\n",
              "       2, 1, 3, 5, 4, 4, 0, 0, 3, 1, 2, 2, 3, 5, 1, 5, 3, 4, 2, 2, 0, 2,\n",
              "       2, 5, 5, 0, 3, 3, 2, 2, 0, 3, 4, 0, 4, 2, 4, 5, 4, 1, 5, 3, 2, 2,\n",
              "       5, 4, 3, 3, 4, 3, 3, 4, 1, 5, 2, 3, 2, 2, 0, 2, 1, 3, 1, 2, 2, 5,\n",
              "       5, 1, 4, 2, 2, 1, 1, 3, 3, 5, 5, 2, 5, 1, 5, 0, 3, 3, 0, 5, 1, 4,\n",
              "       1, 4, 2, 5, 5, 1, 4, 2, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss, acc =model.evaluate(x_testcnn, y_test)\n",
        "print(\"Restored model, accuracy: {:5.2f}%\".format(100*acc))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n3kzoqPkDqqS",
        "outputId": "d9b4c666-c572-4396-c3db-4a90a2037bfb"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7/7 [==============================] - 0s 3ms/step - loss: 0.6996 - accuracy: 0.7005\n",
            "Restored model, accuracy: 70.05%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss, acc =model.evaluate(X_train, y_train)\n",
        "print(\"Restored model train, accuracy: {:5.2f}%\".format(100*acc))"
      ],
      "metadata": {
        "id": "fJDTGH_OUX0z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef08245b-84c5-429c-c67b-d5e507b89728"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "52/52 [==============================] - 0s 4ms/step - loss: 0.4912 - accuracy: 0.8507\n",
            "Restored model train, accuracy: 85.07%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix,accuracy_score\n",
        "import seaborn as sn\n",
        "\n",
        "print(classification_report(new_Ytest,abc))\n",
        "\n",
        "acc = float(accuracy_score(new_Ytest,abc))*100\n",
        "print(\"----accuracy score %s ----\" % acc)\n",
        "\n",
        "cm = confusion_matrix(new_Ytest,abc)\n",
        "#df_cm = pd.DataFrame(cm)\n",
        "class_names = ['neutral','calm', 'happy','sad','angry', 'fearful' ]\n",
        "df_cm = pd.DataFrame(cm, index=class_names, columns=class_names,)\n",
        "sn.heatmap(df_cm, annot=True, fmt='')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 508
        },
        "id": "SfSC3El94LZg",
        "outputId": "06ed1d7e-7852-4fa1-cdd9-b2388752c45b"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      0.33      0.44        18\n",
            "           1       0.76      0.78      0.77        41\n",
            "           2       0.67      0.80      0.73        45\n",
            "           3       0.60      0.81      0.68        31\n",
            "           4       0.75      0.91      0.82        33\n",
            "           5       0.80      0.41      0.54        39\n",
            "\n",
            "    accuracy                           0.70       207\n",
            "   macro avg       0.71      0.67      0.67       207\n",
            "weighted avg       0.71      0.70      0.69       207\n",
            "\n",
            "----accuracy score 70.04830917874396 ----\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVoAAAD4CAYAAACt8i4nAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXxU1f3/8ddnsrCDgMiugOAOCgJicUEqglYE24piXetXakurtH612i/+tIitYkVFVITKIoqaiogsLkgVUURABIGwySaEAEG2sCeTz++Pe4MjJJk7YWbu3Ph58riPzNy5yzvD5OTk3HPPEVXFGGNM4oT8DmCMMRWdFbTGGJNgVtAaY0yCWUFrjDEJZgWtMcYkWHqiT9ClyeXWrSHBNhzI8ztChbcxf7vfEX4SCg/nyPEeo2D7Ws9lTsaJLY77fF5YjdYYYxIs4TVaY4xJqqKw3wmOYQWtMaZiCRfG5TAiUhn4FKiEU1a+paoPi8hY4FJgt7vpbaq6qKxjlVnQikg+UFJ7hwCqqjVjzG6MMQmlWhSvQx0CuqrqXhHJAD4Tkffc1+5T1be8HqjMglZVaxxHSGOMSb6i+BS06oxPsNd9muEu5bq4H9PFMBE5SUROLl7Kc0JjjEkoLfK8iEg/EVkQsfSLPJSIpInIImAbMENVv3RfekxEvhGRp0WkUrRIntpoReQa4CmgkXvCU4DlwNkxfPvGGJN4MVwMU9WRwMgyXg8D54nICcAkETkHeBDYAmS6+/4VGFTWebzWaB8FOgGrVLU58HNgrsd9jTEmeWKo0Xo+pOou4GOgh6rmquMQMAboGG1/rwVtgap+D4REJKSqHwPtPac0xpgk0XCh56UsIlLPrckiIlWAbsAKEWnorhOgN7A0Wiav3bt2iUh1nK4Or4nINmCfx32NMSZ54nQxDGgIjBORNJxKaZaqThWR/4pIPZzeV4uAu6IdyGtB2ws4APwZ+A1QiyhtEsYY44s4de9S1W+AtiWs7xrrsaIWtG5pPlVVLwOKgHGxnsQYY5ImiHeGqWpYRIpEpJaq7o62vTHG+Cp+NyzEjdemg73AEhGZQUTbrKrenZBUUVSvWY37nryX5qc3Q1V54t5/kb1wuR9RPAtS5sxKmWRNHUNmZgZp6em89+4MnnniRb9jlSmImQG6X9GFoUMHkRYKMXrM6wx58nm/I5UpEHnjdAtuPImXyRlF5NYSVquqvhJt30QMk/jA0/ezZN4Spr3+HukZ6VSuUom9e1L72lwiMydimMSq1aqwf98B0tPT+c/0sfz9b0+waMGSuJ8nnhKZORHDJIZCIZYvm02Pq/qyaVMuc7+Yzk03/4Hly1fH/VzxkIy88Rgm8dA3H3gucyq16Z5SwySeoKrjIhegdiKDlaZajWqce0Frpr3u3HJcWFCY8oVsEDPv33cAgPSMdNLT08t542FyBS1zxw5tWbNmPevWfUdBQQFZWZO5pmd3v2OVKih5VcOel2TxWtCWVKO9LY45PGvYtAG7duzmgaH3Mer9Edz35F+oXKWyH1E8C2LmUCjEtE/eZMGKj/ls1lwWfZXatVkIXuZGjRuwcdPmI8835eTSqFEDHxOVLTB5E3DDwvEqs6AVkb4iMgVoLiLvRiwfAzvK2O/I/cOb9+XENXBaehqnndOKyeOncGePuziw/yA39r8hrueItyBmLioq4hddrufC1ldwbttzOO2Mln5HiiqImU0CFBV5X5IkWo12Ds4YByvcr8XLvUCpfzOo6khVba+q7RtVaxyvrADk5eaRl5vH8q9XADBr2qe0at0qrueItyBmLpa/J58vPpvPpT//md9RPAtK5s05W2japNGR500aN2Tz5i0+JipbYPIGrUarqhtU9RNVvVBVZ0UsC1XVl0t7O/J2sm1zHk1bNAHg/IvasWH1Bj+ieBa0zHXq1qZGTWeEzEqVK3Fxl06sWb3e31BRBDHz/AWLaNmyOc2aNSUjI4M+fXoxZeqHfscqVWDyhgu8L0nidfSuyAHAM3HGZdzn18Dfwx4azsDnHiQ9M4PcDbk8fu+TfsSISZAyn1T/RP71/GDS0kJIKMS0dz7kvx9+6nesMgUxczgc5p4BA5k+bQJpoRBjx71JdvYqv2OVKjB5k9gk4JWn7l0/2sEZSKEX0ElVH4i2vc2Cm3g2C27i2Sy4yRGP7l0Hv3jdc5lT+cK+KdW96wh3eLB3KKON1hhjfJOCF8O8Nh38MuJpCGeIxIMJSWSMMccjBZsOvN6C2zPicSGwHqf5wBhjUoom8SKXV54KWlW9PdFBjDEmLlJwUBlPbbQicpqIzBSRpe7zNiIyMLHRjDGmHFKwjdbrxbBROBOSFcCRAXFT+9YmY8xPUwresOC1jbaqqs5zenYdkXpjkRljTIAvhm0XkVNxb1oQkV8DuQlLZYwx5ZWCbbReC9r+OPOXnyEiOcA6nLnDjDEmtRSm3h/bXgvaHJz5yz8G6gB7cIZOtAkajTGpJcA12snALmAhsDnKtsYY4584tdGKSGXgU6ASTln5lqo+LCLNgTeAusBXwM2qerisY3ktaJuoao/jyGyMMckRvxrtIaCrqu4VkQzgMxF5D/gL8LSqviEiI4A7gDInqPPavWuOiLQ+rsjGGJMMcepH647rstd9muEuCnQF3nLXjwN6R4vktUZ7EXCbiKzDKeXFzdEm2o4LdqzxeIrUkPf+w35HiNmVN77qd4SYLc/f5HcEU1HFsY1WRNJwmgdaAs8Da4BdEeNxbwKizm7gtaC9sjwhjTEm6WLodSAi/YB+EatGqurI4ifqzOB4noicAEwCzihPJK9jHaTudADGGBMphjG23UJ1pIftdrlzJV4InCAi6W6ttglOr6wyxTwerTHGpLQ4tdGKSD23JouIVAG6Actxurn+2t3sVpxeWWXy2nRgjDHBEL9bcBsC49x22hCQpapTRSQbeENEBgNfAy9HO5AVtMaYiiVOF8PcwbPalrB+LdAxlmNZQWuMqVjCYb8THMMKWmNMxRLg0buMMSYYrKA1xpgEC/CgMohIG6BZ5D6q+nYCMhljTLlpkfd+tMnidbrx0UAbYBlQ/OtCAStojTGpJcBNB51U9ayEJjHGmHhIwV4HXu8M+0JErKA1xqS+FJwF12uN9hWcwnYLMY7eZYwxSRXgpoOXgZuBJfzQRuuLF0Y8wZU9upKX9z0dO6TuWOSHCgr57ZBXKSgMUxgu4vLzT+cPvS7hwVGTyd6whfS0EOc0b8TAm3qQkZ7md9xjVK9ZjfuevJfmpzdDVXni3n+RvXC537FK1ahxA4aPeIITT6qLqvLq2CxGjRjvd6youl/RhaFDB5EWCjF6zOsMefJ5vyOVKRB5YxhUJllEPYQSkS9U9cLynKB61eZx/a47d+7I3n37GDXqqYQUtPEaj1ZVOXCogKqVMykoDHP7kPHcf303du8/wEXnnArAg6Mm0+60k+nTpd1xnSsR49E+8PT9LJm3hGmvv0d6RjqVq1Ri7559cTt+vMejPal+Peo3qMeSxdlUq16NGbMmctuN/Vm1Mj7jIX9/ID8ux4kUCoVYvmw2Pa7qy6ZNucz9Yjo33fwHli9fHfdzxUMy8hYezpHjPcb+oXd6LnOq/mXUcZ/PC69ttF+LyAQR6SsivyxeEpqsFJ9/Po+dO3b5ceqYiAhVK2cCUBguojBchAhc3LolIoKIcHbzRmzdGf8f4ONVrUY1zr2gNdNefw+AwoLCuBayibBtax5LFmcDsG/vPlavXEODRvV9TlW2jh3asmbNetat+46CggKysiZzTc/ufscqVWDyFqn3JUm8Nh1UwWmbvSJinXXviiJcVETfR8ewMW8n13c5n9YtfhiIvaAwzLS5S7n/+m4+JixZw6YN2LVjNw8MvY9TzzqVVUtW8dz/e4GDBw76Hc2Tpic35pw2Z7JwwWK/o5SpUeMGbNz0w1ynm3Jy6djhmDFMUkZg8ga114Gq3l7C8tvStheRfiKyQEQWFBSmXo0tWdJCIbIevoMPhvyRpes3821O3pHX/jHhA9q1akq705r6mLBkaelpnHZOKyaPn8KdPe7iwP6D3Nj/Br9jeVK1WlVeHj+Mhx78J3vzU7sWbhJDi4o8L8lSZo1WRJ7DqbmWSFXvLmX9kVHL491GG0Q1q1amw+mn8PnStbRsXI8R785mZ/5+Hvr9r/yOVqK83DzycvNY/vUKAGZN+5Qb+/f1OVV06enpjB4/jIlZU5g+ZYbfcaLanLOFpk0aHXnepHFDNm/e4mOisgUmbwreGRatRrsAZ2Ky0hZTih35+9mz3/lT++DhAuZmr6N5gzq8PXsRc7LX8fidvQiFktIOH7MdeTvZtjmPpi2aAHD+Re3YsDr1ZzN6evhgVq9cw0vPj/U7iifzFyyiZcvmNGvWlIyMDPr06cWUqR/6HatUgcmrRd6XJCmzRquq45IVxKsxY5/l4ks6UbdubVaunsNjg5/hlXFZfsc6xvbde3lo9FSKioooUuWK9mdyybmtOP93j9Owbi1u+ecrAPy83en8rudFPqc91rCHhjPwuQdJz8wgd0Muj9/7pN+RytSxUzv69O1N9tKVzJw9CYB/DHqamTM+9TlZ6cLhMPcMGMj0aRNIC4UYO+5NsrNX+R2rVIHJm4I1Wq/du+oBfwXOAioXr1fVrtH2DVrTgU03nhxBm248Ed27zLHi0b1r3/+7wXOZU23QGynVves1nEnJmgN/B9YD8xOUyRhjyi8Fmw68FrR1VfVloEBVZ7k9DqLWZo0xJukC3I+2wP2aKyK/ADYDdRITyRhjyi+Z3ba88lrQDhaRWsC9wHNATWBAwlIZY0x5peDFMK9NB9fhXDhbqqqXAd2AaxMXyxhjyilOTQci0lREPhaRbBFZJiL3uOsfEZEcEVnkLldFi+S1RttGVY8MMKCqO0QkBe+9M8b85MXvFtxC4F5VXSgiNYCvRKT4TpinVfVfXg/ktaANiUhtVd0JICJ1YtjXGGOSJl5zhqlqLpDrPs4XkeVA47L3KpnXpoOncAb+flREHgXmAEPKc0JjjEmoGJoOIsdlcZd+JR1SRJoBbYEv3VV/FJFvRGS0iNSOFslTrVRVXxGRBfzQpeuXqprtZV9jjEmqGHodRI7LUhoRqQ5MBAao6h4ReRF4FGccmEdxKqKlDrIFMfz57xasVrgaY1JbHHsdiEgGTiH7mqq+DaCqWyNeHwVMjXYca2c1xlQscSpoRURwpvFarqpDI9Y3dNtvwel9tTTasaygNcZUKBqO2w0LnXHnShSRRe66vwF9ReQ8nKaD9cDvoh0o4QXtwcLDiT5FXDXr+bjfEWK2ac10vyPErPbJP/c7Qkzanniq3xFitnzXRr8j+CN+vQ4+w5nx+2gx/8BZjdYYU6HEq3tXPFlBa4ypWKygNcaYBEu9MWWsoDXGVCxamHolrRW0xpiKJfXKWW+34IrIn7zcZmaMMX7TIvW8JIvXsQ7qA/NFJEtEergdeY0xJvUUxbAkiaeCVlUHAq1w7pK4DVgtIv8QkeB1LjTGVGhBrtGiznS5W9ylEKgNvCUiNoqXMSZ1pGCN1tPFMHdk8VuA7cC/gftUtUBEQsBq4P7ERTTGGO+00O8Ex/La66AOztCIGyJXqmqRiFwd/1jGGFM+SZxF3DOv49E+LCLtRKQXzkAKn6vqQve15YkMaIwxMUnBgtZr966HgHFAXeBEYIyIDExkMGOMKQ8t8r4ki9emg5uAc1X1IICIPA4sAgYnKpgxxpRHYJsOgM1AZeCg+7wSkJOQRB50v6ILQ4cOIi0UYvSY1xny5PN+RfGkUeMGDB/xBCeeVBdV5dWxWYwaMd7vWD9y6NBhbu1/H4cLCggXhul22UX88X9uRlUZNnIcH378GaFQiOuv/QU3XdfL77jHeGHEE1zZoyt5ed/TsUMPv+N4NvnLN9m/9wBFRWEKC8PcemWJU1aljCC8zxpOvW7+Xgva3cAyd6pdBboB80RkGICq3p2gfMcIhUIMe/YxelzVl02bcpn7xXSmTP2Q5ctXJytCzAoLwzw88AmWLM6mWvVqzJg1kVkfz2HVyjV+RzsiMzOD0cMep2rVKhQUFnLL7/+Xizu1Z+2GjWzZtp0pE0YSCoX4fueu6AfzwWvjJ/LSiFcYNeopv6PE7K7r7mH3jt1+x/AkCO9zkGu0k9yl2Cfxj+JNxw5tWbNmPevWfQdAVtZkrunZPaUL2m1b89i2NQ+AfXv3sXrlGho0qp9SBa2IULVqFQAKCwspLCxERHhz0jSGPPJXQiGnOb9u7RP8jFmqzz+fx8knl2smaBODILzPWhTQGq2qjhORTOAMnBrtSlX1ZeqERo0bsHHT5iPPN+Xk0rFDWz+ilEvTkxtzTpszWbhgsd9RjhEOh+nz27v5LmczfX95NW3OPoONObm8N3MWM2d9QZ3atXhwwF2c0jS1f9CCRBWGv/4Uqsqk8e8y6bUpfkcKvMDWaEXkKuAlYA3O1A7NReR3qvpeKdv3A/oBSFotQqFqcYobbFWrVeXl8cN46MF/sjd/n99xjpGWlsbEcc+zJ38v9zz4KKvXrudwQQGVMjPJGj2MGZ98zkP/eJpXXvyX31ErjDt79ydvy3Zq1z2B4W8MZf233/H1l6n3SzhIVFOvRuv1FtyhwGWq2kVVLwUuA54ubWNVHamq7VW1fbwL2c05W2japNGR500aN2Tz5i1xPUcipKenM3r8MCZmTWH6lBl+xylTzRrV6diuDZ/NXUCDeidy+aWdAbj80p+xas06n9NVLHlbtgOw8/tdfPL+bM5ue6bPiYIvFbt3eS1o81X124jna4H8BOSJav6CRbRs2ZxmzZqSkZFBnz69mDL1Qz+ixOTp4YNZvXINLz0/1u8oJdqxcxd78vcCcPDQIb6Y/zXNT2lK10suZN5Cp4Y1/+sl1mwQR5WrVKZqtSpHHne6tANrVqz1OVXwFYXF85IsXi+GLRCR6UAWThvtdTjDJv4SQFXfTlC+Y4TDYe4ZMJDp0yaQFgoxdtybZGevStbpy6Vjp3b06dub7KUrmTnbuab4j0FPM3PGpz4n+0He9zv5v8H/IlxUhBYp3bteTJfOF9Cuzdn89e9DGP/mO1StUpm/PzDA76glGjP2WS6+pBN169Zm5eo5PDb4GV4Zl+V3rDLVrVebIS8/BkB6ehrvT/qILz6Z53OqsgXhfY7XxTARaQq8gjNMrAIjVfVZEakDvAk0w5luvI+q7izzWM6gXFFPOKaMl1VVf1vai+mZjVNvprQy1K1Sw+8IMbPpxhPvzBOa+h0hZkGcbnzv/nXHXUquP6+b5zKn2aIZpZ5PRBoCDVV1oYjUAL4CeuMMFbtDVR8XkQeA2qr617LO47XXwe1egxtjjJ881B09HkdzgVz3cb6ILAcaA72ALu5m43C6ux5/QSsilYE7gLNx7hArDlJqTdYYY/wQS9NBZA8p10hVHVnCds2AtsCXQH23EAZnfO760c7jtY12PLAC6A4MAn4D2KhdxpiUE0v3LrdQPaZgjSQi1YGJwABV3RM5k5eqqohErUN77XXQUlUfAvap6jjgF8AFHvc1xpikCYfF8xKNiGTgFLKvRVz03+q23xa3426LdhyvBW2B+3WXiJwD1AJO8rivMcYkjap4XsriTkL7MrBcVYdGvPQucKv7+FZgcrRMXpsORrrTjQ90T1IdeMjjvsYYkzRxHOugM3AzsEREFrnr/gY8DmSJyB3ABqBPtAPF0kb7K5x+Y+PcdVEbgI0xJtni2OvgM5whB0oSU/9ErwXtZJyhEr8CDsVyAmOMSabAjt4FNFHV1Bzl1xhjIoSLvF56Sh6vieaISOuEJjHGmDhQ9b4kS5k1WhFZgnOPbzpwu4isxWk6EJwuZG0SH9EYY7wrSsFhEqM1HVydlBTGGBMnqTgebZkFrapuSFYQY4yJh2Q2CXjl9WJYuVVOz0z0KX7yqjS62O8IMdt5V3CmHwJo+O9lfkeIWbWMSn5H8EUQmw6MMSZQUrHXgRW0xpgKJQVbDqygNcZULNZ0YIwxCRa4XgfGGBM0SZzc1jMraI0xFYqWOg6Mf6ygNcZUKIXWdGCMMYllNVpjjEkwa6M1xpgEsxqtMcYkmNVojTEmwcJBq9FGjEdbIhuP1hiTalJwJhvP49H2d7+Od7/+JjFxonthxBNc2aMreXnf07FDMGbXadS4AcNHPMGJJ9VFVXl1bBajRoyPvqOPul/RhaFDB5EWCjF6zOsMefJ5vyMdQ044kco3/wWpcQKoUjDnAwpmvUvmlTeScWF3dO9uAA5NfYVw9gKf0x4raJ/loHyOi1KwRivqYfBGEflaVdsetW6hqraLtm/1qs3jOsZD584d2btvH6NGPZWQD2cihpY7qX496jeox5LF2VSrXo0ZsyZy2439WbVyTVyO//2B/Lgcp1goFGL5stn0uKovmzblMveL6dx08x9Yvnx13M4Rj2ESpWZtpGYdijatgUpVqHbfMxz492DS216MHjpAwX8nxSGpIxHDJAbts5zozzHA1t0rjruUfKfBjZ7LnN5bJpR5PhEZjVPh3Kaq57jrHgHuBPLczf6mqtPLOo7X8cRERDpHPPlZDPvG1eefz2Pnjl1+nLrctm3NY8nibAD27d3H6pVraNAodWdr79ihLWvWrGfduu8oKCggK2sy1/Ts7nesY+ienU4hC3DoAOGtG5Fadf0NFYOgfZaD8jkuimHxYCxQ0m/Bp1X1PHcps5AF7xfD7gBGi0gtnPnCdgK/9bividD05Mac0+ZMFi5Y7HeUUjVq3ICNmzYfeb4pJ5eOHVJ7oG6pcxJpjVtwcMNK0lqcRebFV5PRoStFG7/l4KR/w4F9fkesUFL5c1wk8Ws6UNVPRaTZ8R7HU61UVb9S1XOBc4E2bim+sLTtRaSfiCwQkQUFhfH9szbIqlarysvjh/HQg/9kb7794MdNZmWq3PE3Dr09Cg4eoOCz6ewbdCf7h9xN0e4dVL72f/xOWKGk+uc4HMMSWVa5Sz+Pp/mjiHwjIqNFpHa0jT137xKRXwBnA5XF/Y2hqoNK2lZVRwIjIf5ttEGVnp7O6PHDmJg1helTZvgdp0ybc7bQtEmjI8+bNG7I5s1bfExUhlAaVe74GwULPqHwmy8A0Pwf/hwv+OIDqvR72K90FU4QPsex9DqILKti8CLwKE6PrEeBp4jyF76nGq2IjACuB/6E03RwHXBKjOF+0p4ePpjVK9fw0vNj/Y4S1fwFi2jZsjnNmjUlIyODPn16MWXqh37HKlHlG++haOtGCj5+58g6qflDBSO9zYUU5doco/EShM9xEeJ5KQ9V3aqqYVUtAkYBHaPt4/WC1s9U9RZgp6r+HbgQOK1cKY/TmLHP8t9P3qbVaS1YuXoOt9zax48YMenYqR19+vbmoks6MXP2JGbOnsTPu13id6xShcNh7hkwkOnTJrD0m094660pZGev8jvWMdJanEVGx66ktWpD1fuHUfX+YaSd1Z5KvW6n6gPDqfrX50hv1YZDk0b5HbVEQfssB+VzrDEs5SEiDSOeXgssjbqPx+5d81S1o4jMBX4J7ACWqmrLaPsGrekgiDOHxrt7VzLYLLiJF8TPcjy6d73S+CbPZc4tOa9G6971OtAFOBHYCjzsPj8Pp6xeD/xOVXPLOo7XNtopInIC8CSw0D1BalYTjDE/afEc60BV+5aw+uVYj+O1oF0BhFV1ooicBbQD3omyjzHGJF049W4M89xG+5Cq5ovIRUBX4N84V96MMSalxPmGhbjwWtCG3a+/AEap6jQgMzGRjDGm/IJc0OaIyEs4Xbymi0ilGPY1xpikUfG+JIvXwrIP8AHQXVV3AXWA+xKWyhhjyikVa7SeLoap6n7g7YjnuUCZ3RmMMcYP4eibJJ3NsGCMqVCCOPC3McYEis0ZZowxCWYFrTHGJFgq3vNvBa0xpkKxNlpjjEmwn2Svg4OFhxN9irgKWl6AyunBu0kvaKNh5b1yh98RYlbvlpjHPqkQilKw8cBqtMaYCsUuhhljTIKlXn3WClpjTAVjNVpjjEmwQkm9Oq0VtMaYCiX1ilkraI0xFUwqNh14nW78TyJSO/qWxhjjryLU85IsXsejrQ/MF5EsEekhIil474UxxiR+uvHy8FTQqupAoBXO7I+3AatF5B8icmoCsxljTMziOfC3iIwWkW0isjRiXR0RmSEiq92vUf/a9zwdjaoqsMVdCoHawFsiMsTrMYwxJtHCqOfFg7FAj6PWPQDMVNVWwEz3eZm8ttHeIyJfAUOAz4HWqvp74HzgV16OYYwxyRDPGq2qfgrsOGp1L2Cc+3gc0Dvacbz2OqgN/FJVNxwVokhErvZ4DGOMSTiNofVVRPoB/SJWjVTVkVF2q+9O5wXOX/j1o50nakErImnADar6SEmvq+ryaMcwxphkiaV7l1uoRitYy9pfRaLfIRG16UBVw8BKETm5vGHirfsVXVi29FNWZH/G/ff19zuOJ0HL/MKIJ1i3fj7z5r/vdxRPgpL3UEGY37wwnT7PTeWXz77LCx8tBiBnRz43vTidnk+9w/1vfEpBYSoO9heM9zkJ3bu2ikhDAPfrtmg7eL0YVhtYJiIzReTd4qW8KY9HKBRi2LOPcXXPm2h97mVcf31vzjyzlR9RPAti5tfGT6R379v8juFZUPJmpocYdUc3sv50NW/+8WrmrM7hm+/yeOaDr7mp85lMubc3NStnMumrb/2OWqIgvM9J6N71LnCr+/hWYHK0HbwWtA8BVwODgKcilqTr2KEta9asZ9267ygoKCArazLX9OzuRxTPgpj588/nsXPHLr9jeBaUvCJC1UoZABSGiygMKyIwf+0WLj/7FAB6tjuVj7M3+hmzVEF4nwtRz0s0IvI68AVwuohsEpE7gMeBbiKyGrjcfV4mTxfDVHWWl+2SoVHjBmzctPnI8005uXTs0NbHRNEFMbNJnHBREX2fn87GHflcf8HpNKlTgxqVM0lPc+o99WtWZdue/T6nDK5YLoZFPZZq31Je+nksx/FU0IpIPsfWtHcDC4B7VXXtUdsfuZInabUIharFksmYCi0tFCLrT1ez58Bh/vLaJ6zP2+N3pAolFcc68Nq96xlgEzABEOAG4FRgITAa6BK5ceSVvPTMxnG90wqVA7EAABE7SURBVG1zzhaaNml05HmTxg3ZvHlLPE8Rd0HMbBKvZpVMOrRowOKNeeQfPExhuIj0tBBb9+znpJpV/Y4XWPGs0caL1zbaa1T1JVXNV9U9bkHaXVXfxLlQljTzFyyiZcvmNGvWlIyMDPr06cWUqR8mM0LMgpjZJMaOfQfZc8CZl+5gQSFzv82lRb1atG9Rn4+WOd3UpyxcQ5czm/oZM9DiecNCvHgtaPeLSB8RCblLH+Cg+1pSf32Ew2HuGTCQ6dMmsPSbT3jrrSlkZ69KZoSYBTHzmLHP8t9P3qbVaS1YuXoOt9zax+9IZQpK3u35B7jz5Q+5btgUfvPCdDq1bMglZzRhQPd2jP9sOT2feoddBw5xbfuWfkctURDe57Cq5yVZRD2cTERaAM8CF+IUrHOBPwM5wPmq+llp+8a76cAcK4iz4AaNzYKbHHv3rzvukQFvPOVaz2XOhA2TkjISoddeB2uBnqW8XGoha4wxyZaKbbReex3UA+4EmkXuo6q/TUwsY4wpnyD3OpgMzAY+AlLz3kBjjIGkzpzgldeCtqqq/jWhSYwxJg5SsenAa6+DqSJyVUKTGGNMHKRirwOvNdp7gL+JyCGgAOemBVXVmglLZowx5RDYpgNVrSEidXDmDauc2EjGGFN+gb0YJiL/g1OrbQIsAjoBc4hxYAVjjEm0ILfR3gN0ADao6mVAW5xBZYwxJqUkYeDvmHltoz2oqgdFBBGppKorROT0hCYzxphy8HK3a7J5LWg3icgJwDvADBHZCWyIso8xxiSdx2nEk8rrxbBr3YePiMjHQC0gdScNMsb8ZAW210GkVJptwRhjjhbkpoNyC9rIUgcLD/sdIWZX1mvjd4SYNZRg9RJs33+K3xFi9maNTn5H8EWFqNEaY0wqS8XuXVbQGmMqlGTeWuuVFbTGmAolnk0HIrIeyMcZtbBQVduX5zhW0BpjKpQEtNFepqrbj+cAVtAaYyqUQPU6EJF8Sp540UbuMsakrDjXaBX4UEQUeMmdATxmpRa0qlqjvMmMMcYvsfQ6EJF+QL+IVSOPKkwvUtUcETkJ567YFar6aayZojYdiMjJJa1X1e9iPZkxxiRaWL0PlOgWqqXWUlU1x/26TUQmAR2B+Be0wLSIx5WB5sBK4OxYT2aMMYkWrzZaEakGhFQ13318BTCoPMeKWtCqauujTt4O+EN5TmaMMYkWxzba+sAkEQGnrJygquUa46U8Yx0sFJELynMyY4xJtHjdGaaqa4Fz43EsL220f4l4GgLaAZvjcXJjjIm3oiB174oQ2fugEKfNdmJi4hhjzPEJ1FgHIjJeVW8Gdqnqs0nMZIwx5RZLr4NkKatGe76INAJ+KyKv4NyocISq7khoslK8MOIJruzRlby87+nYoYcfEcql+xVdGDp0EGmhEKPHvM6QJ5/3O1KZfnHHNfz8hm6oKt+t2MAL9w2j4FCB37F+5MYhd3F213bkf7+Hx7v/LwBVa1XjtuEDqNOkHjs25TGm/zMc2LPP56SlC4VCZH04lq1b8uh/071+xzlGm2d+x0nd2nJ4+x4+vfT+I+ub3dGdU27vhoaVbR99zYpHJ/iY8sdSsemgrMkZRwAzgTOAr45aFiQ+WsleGz+R3r1v8+v05RIKhRj27GNc3fMmWp97Gddf35szz2zld6xS1alfh6tuv5oHrr6Xe6+4m1BaiM49L/Y71jG+fGsWL976zx+tu/z3vVk1ZymDLxvAqjlL6faHXj6l8+bmO69n7er1fsco1aY3ZjHvhsd/tK5u57Oo3+N8Znd9gE8vvY+1L071KV3JNIZ/yVJqQauqw1T1TGC0qrZQ1eYRS4ukJTzK55/PY+eOXX6dvlw6dmjLmjXrWbfuOwoKCsjKmsw1Pbv7HatMobQ0MitnEkoLUalKJXZs9eUPmDKtmbec/bv3/mhd627tmfeWMwnIvLdm0bpbBz+ieVK/4Ulc0q0zE1+b7HeUUu2Yu4KCXT9+j0++tRvfPvcuRYcLATi8fY8f0UpVpOp5SZYyL4aJSBpwWZKyVFiNGjdg46YfOmpsysmlY4e2PiYq246tO5gychIvfvFvDh88zOLZi/hm9iK/Y3lSo14t9uQ5v4j35O2iRr1aPicq3QOP/pmnBg2nWvWqfkeJSbVTG1DngjM4/cHrKTpYwPK/v8ruRWv9jnVEKl4MK6vpAFUNAytLuw23NCLST0QWiMiCgsL84wpokq9azWp0uOIC+l/Uj34db6dSlUpcfO2lfscqnxRsrwO4tFtndmzfQfY3K/yOErNQehqZtasz58qHWD7oNdqNusfvSD8S1rDnJVnKLGhdtYFlIjJTRN4tXsraQVVHqmp7VW2fkW5j02zO2ULTJo2OPG/SuCGbN2/xMVHZWl90Lts2bmXPjj2EC8N8+f5cTj//DL9jeZKft5ua9U4AoGa9E8hPsT9ri7XteC5dul/Ch/Mn8a+XBnNB5/Y8/vwjfsfy5MDmHWyZNg+A3V+vQYuUzLqp83Ouqp6XZPHSj/ahhKeo4OYvWETLls1p1qwpOTlb6NOnFzff0t/vWKXavnk7rdqeTmblTA4fPEzrzm1Ys+Rbv2N5svSjBXT89aV89OJkOv76UpbM8O26bZmeeewFnnnsBQA6/Kwdt/3hNzzQ/xF/Q3m09b0F1O18Ft9/nk21Fg0IZaRz+PvU+cs1kJMzptr04mPGPsvFl3Sibt3arFw9h8cGP8Mr47L8jlWmcDjMPQMGMn3aBNJCIcaOe5Ps7FV+xyrVt4tWMXf6HIZMe5pwOMz6ZWv5aMIHfsc6xq3D7qZlp7OoXrsGg754gelP/4cZL07m9ucH0KnPZezM2c6Y/k/7HTPQzhvxJ+r+7Ewy69Sg69fDWf3kW2x8/WPOfeYuLpk1hKLDhSy++0W/Y/5IKg78LdFCiUgn4DngTCATSAP2eR34u3rV5qn3XZchiNONX9uwXNMY+Spo043PPLDe7wgxG4JvnYPK7RdbX5foW5Wt4QlneS5zcndlH/f5vPDSdDAcuAH4D9AeuAU4LZGhjDGmvALX66CYqn4LpKlqWFXHAMG5JcsY85MS1iLPS7J4qdHuF5FMYJGIDAFy8VhAG2NMsqViG62XAvNmd7s/AvuApsCvEhnKGGPKK3B3hgGo6gYRqQI0VNW/JyGTMcaUWyBrtCLSE1gEvO8+Py/aDQvGGOOXItTzkixemg4ewZn5cReAqi7CmaDRGGNSTlDvDCtQ1d3uBGXFUq9ubowxBG/g72LLRORGIE1EWgF3A3MSG8sYY8onUAN/i8h49+Ea4GzgEPA6sAcYkPhoxhgTu6A1HRRPZXM9zpi0T0W8VhU4mMhgxhhTHvG8M0xEegDP4gw98G9VfTzKLiUqq6AtnsqmBT+eukZw2miDdyO1MabCi1dN1Z344HmgG7AJmC8i76pqdqzHKrWgVdVhwDAReVFVf1/utMYYk0RxbKPtCHyrqmsBROQNoBcQv4K22PEWsnv3r0vY6Dgi0k9VRybq+PEWtLwQvMxBywuWOd4KD+d4LnNEpB/QL2LVyIjvqzGwMeK1TcAF5ckU9DEL+kXfJKUELS8EL3PQ8oJl9k3kbDDukpBfHkEvaI0xJlFycMZ2KdbEXRczK2iNMaZk84FWItLcHcHwBqBcww94uWEhlaVkG1EZgpYXgpc5aHnBMqckVS0UkT8CH+B07xqtqsvKc6yoU9kYY4w5PtZ0YIwxCWYFrTHGJFigC1oRaeYOeFOefffGO4+Hc94mIsN9OG8zEVma7POmEnsPjiUid4vIchF5LVnH8uPnLhUE/WJYM+BGYMLRL4hIuqoWJj2RMXGU4M/xH4DLVXVTeQ8Qke+4j1WR+VKjdWsXy0VklIgsE5EPRaSKiJwqIu+LyFciMltEznC3Hysiv47Yv/i34uPAxSKySET+7NYY3xWR/wIzRaS6iMwUkYUiskREeiXo+7lFRL4RkcUiMl5EeorIlyLytYh8JCL1S9hnrIi8KCJzRWStiHQRkdHu+zI2ATHTSni/7xSR+W7uiSJSNSLbCBFZICKrRORqd/1tIjJZRD4RkdUi8rC7fpCIHBnRTUQeE5F7EvA9ICLVRGSam3mpiFwvIv/P/T6WishIcQdPFpHz3e0WA/0TkaeEfO+4n99l7l1HiMhe9z1Z7P5/13fXn+o+XyIig4s/1+5nYbY4M5lkJ+L9FZEROOOVvCci/+d+9ua5n9le7jbN3BwL3eVnpeSLPNafReQREfnfiHMtFZFmx5M38GIZUixeC05NtBA4z32eBdyEM4hNK3fdBcB/3cdjgV9H7L/X/doFmBqx/jac2+TquM/TgZru4xOBb/mhp8XeOH0vZwOrgBPd53WA2hHn+R/gqYh8wyO+pzdwBunphTP8ZGucX35fFb83CX6/60ZsMxj4U0S2990srdz3tLKbPxeoC1QBlgLt3eMvdPcN4QytWTde+Y/6Xn4FjIp4Xqv4/9t9Ph7o6T7+BrjEffwksDQJn+3iz17x+1MXZxCm4kxDgIHu46lAX/fxXUd9rvcBzSP+/+L+/gLr3Z+LfwA3uetOcD/P1XBG6avsrm8FLCgpX+Sx3MePAP8b8dpSoFk8f+6CtvjZdLBOnWlxwClYmgE/A/4jP8zmUKkcx52hqjvcxwL8Q0QuAYpw7l2uD2wpb+gSdAX+o6rbAVR1h4i0Bt4UkYZAJrCulH2nqKqKyBJgq6ouARCRZTjvx6JS9iuPkt7vc0RkMM4PV3Wc/oLFslS1CFgtImuBM9z1M1T1ezfn28BFqvqMiHwvIm1x3t+vi7dJgCXAUyLyBM4v2dki8isRuR+nYKiDM1j9bOAEVf3U3W88cGWCMkW6W0SudR83xSmgDuMUquC8993cxxcCvd3HE4B/RRxnnqquA1DV9Ql+f68AromohVYGTgY2A8NF5DwgDJxWUj4TnZ8F7aGIx2GcD9AuVT2vhG0LcZs5RCSEU3iVZl/E498A9YDzVbVARNbjfIgS7TlgqKq+KyJdcH7Dl6T4PSjix+9HEfH/vzn6/a6CU3PtraqLReQ2nJpKsaM7WGuU9f/GqfE2AEYfd9pSqOoqEWkHXAUMFpGZOM0C7VV1o4g8QnL+j4/h/l9fDlyoqvtF5BM3S4G61Tmc997L/+2+o54n8v0V4FequvJHK533citwLs7PX+QY1Efni3Tk59Xly/9HKkmlXgd7gHUich2AOM51X1sPnO8+vgbIcB/nAzXKOGYtYJtbyF4GnBL31PBf4DoRqQsgInXc8xbfE31rAs4ZLzWAXBHJwPmlFOk6EQmJyKk47W/FP4TdRKSOOFPQ9wY+d9dPAnoAHfhxzTiuxBmMfr+qvorTHNDOfWm7iFQHfg2gqruAXSJykfv60d9fItQCdrqF7BlApyjbz8VpCgHn9s6yJPL9/QD4U0Tbdlt3fS0g1/3L5macu6O8WI/7/+L+UvzJT+aaar0OfgO8KCIDcQrTN4DFwChgsntR431++G36DRB2148Fdh51vNeAKe6f5guAFfEOrKrLROQxYJaIhIGvcWqw/xGRnTgFcap+0B4CvgTy3K+Rv7S+A+YBNYG7VPWg+3M4D5iIM8DGq6q6AEBVD4vIxzh/lYQTmLk18KSIFAEFwO9xCvylOE1C8yO2vR0YLSIKfJjATMXeB+4SkeU4v5jmRtl+APCqiPyfu+/u0jZM8Pv7KPAM8I37F+M64GrgBWCiiNzCj3/uopkI3OI2gX2J0+b7k2a34JpjiNPrYaqqvnXU+ttw/kT/Ywn7hICFwHWqujoZOYNOnF4eB9x2+htwLoyV2DPG3t9gS6WmAxNQInIWTo+OmVYIxOR8YJGIfIPTD/Xekjay9zf4rEZrjDEJZjVaY4xJMCtojTEmwaygNcaYBLOC1hhjEswKWmOMSbD/D/Gk3cZLWkY+AAAAAElFTkSuQmCC\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "A6UOIsB2xKek"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}