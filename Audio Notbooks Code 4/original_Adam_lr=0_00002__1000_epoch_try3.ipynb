{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "original_Adam_lr=0_00002_ 1000 epoch_try3.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9SRCO-a_AlH5",
        "outputId": "01120adf-c7d9-4d4e-fe79-84cbd1da7dac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install librosa"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oi8pWV3yBVjO",
        "outputId": "5e5da197-66f1-4841-e19f-203f172df55f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.7/dist-packages (0.8.1)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.1.0)\n",
            "Requirement already satisfied: resampy>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from librosa) (0.2.2)\n",
            "Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.6.0)\n",
            "Requirement already satisfied: numba>=0.43.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (0.51.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (21.3)\n",
            "Requirement already satisfied: soundfile>=0.10.2 in /usr/local/lib/python3.7/dist-packages (from librosa) (0.10.3.post1)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.21.6)\n",
            "Requirement already satisfied: audioread>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (2.1.9)\n",
            "Requirement already satisfied: decorator>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.0.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba>=0.43.0->librosa) (57.4.0)\n",
            "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba>=0.43.0->librosa) (0.34.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->librosa) (3.0.9)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from pooch>=1.0->librosa) (2.23.0)\n",
            "Requirement already satisfied: appdirs>=1.3.0 in /usr/local/lib/python3.7/dist-packages (from pooch>=1.0->librosa) (1.4.4)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2022.5.18.1)\n",
            "Requirement already satisfied: six>=1.3 in /usr/local/lib/python3.7/dist-packages (from resampy>=0.2.2->librosa) (1.15.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn!=0.19.0,>=0.14.0->librosa) (3.1.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.7/dist-packages (from soundfile>=0.10.2->librosa) (1.15.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.0->soundfile>=0.10.2->librosa) (2.21)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HJjcbxwy46bG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "c686cf90-4b55-4494-96b7-4e39c917926d"
      },
      "source": [
        "# Orignial Notebook: https://github.com/MITESHPUTHRANNEU/Speech-Emotion-Analyzer/blob/master/final_results_gender_test.ipynb\n",
        "# This notebook author: Reza Chu\n",
        "# Last Editing Date: 31st May 2019\n",
        "\n",
        "## Python\n",
        "import os\n",
        "import random\n",
        "import sys\n",
        "\n",
        "import IPython\n",
        "from IPython.display import Audio\n",
        "from IPython.display import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "## Package\n",
        "import glob \n",
        "import keras\n",
        "import IPython.display as ipd\n",
        "import librosa\n",
        "import librosa.display\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import plotly.graph_objs as go\n",
        "import plotly.offline as py\n",
        "import plotly.tools as tls\n",
        "import seaborn as sns\n",
        "import scipy.io.wavfile\n",
        "import tensorflow as tf\n",
        "py.init_notebook_mode(connected=True)\n",
        "\n",
        "## Keras\n",
        "from keras import regularizers\n",
        "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping\n",
        "from keras.callbacks import  History, ReduceLROnPlateau, CSVLogger\n",
        "from keras.models import Model, Sequential\n",
        "from keras.layers import Dense, Embedding, LSTM\n",
        "from keras.layers import Input, Flatten, Dropout, Activation, BatchNormalization\n",
        "from keras.layers import Conv1D, MaxPooling1D, AveragePooling1D\n",
        "from keras.preprocessing import sequence\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.utils import np_utils\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "## Sklearn\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "## Rest\n",
        "from scipy.fftpack import fft\n",
        "from scipy import signal\n",
        "from scipy.io import wavfile\n",
        "from tqdm import tqdm\n",
        "\n",
        "input_duration=3\n",
        "# % pylab inline"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "        <script type=\"text/javascript\">\n",
              "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
              "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
              "        if (typeof require !== 'undefined') {\n",
              "        require.undef(\"plotly\");\n",
              "        requirejs.config({\n",
              "            paths: {\n",
              "                'plotly': ['https://cdn.plot.ly/plotly-2.8.3.min']\n",
              "            }\n",
              "        });\n",
              "        require(['plotly'], function(Plotly) {\n",
              "            window._Plotly = Plotly;\n",
              "        });\n",
              "        }\n",
              "        </script>\n",
              "        "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#radvass speech and song\n",
        "import time\n",
        "import os\n",
        "import librosa\n",
        "from librosa import display\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "count=0\n",
        "path1 = '/content/drive/MyDrive/RAVDESS_speech'\n",
        "path2 = '/content/drive/MyDrive/RAVDESS_song'\n",
        "\n",
        "lst = []\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "for subdir, dirs, files in os.walk(path2):\n",
        "  print(dirs)\n",
        "  print(subdir)\n",
        "  #print(files)\n",
        "  for file in files:\n",
        "      try:\n",
        "        count +=1\n",
        "        #Load librosa array, obtain mfcss, store the file and the mcss information in a new array\n",
        "        X, sample_rate = librosa.load(os.path.join(subdir,file), res_type='kaiser_fast')\n",
        "        mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T,axis=0) \n",
        "        # The instruction below converts the labels (from 1 to 8) to a series from 0 to 7\n",
        "        # This is because our predictor needs to start from 0 otherwise it will try to predict also 0.\n",
        "        file = int(file[7:8]) - 1 \n",
        "        arr = mfccs, file\n",
        "        lst.append(arr)\n",
        "      # If the file is not valid, skip it\n",
        "      except ValueError:\n",
        "        continue\n",
        "\n",
        "for subdir, dirs, files in os.walk(path1):\n",
        "  print(dirs)\n",
        "  print(subdir)\n",
        " # print(files)\n",
        "  for file in files:\n",
        "      try:\n",
        "        #Load librosa array, obtain mfcss, store the file and the mcss information in a new array\n",
        "        X, sample_rate = librosa.load(os.path.join(subdir,file), res_type='kaiser_fast')\n",
        "        mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T,axis=0) \n",
        "        # The instruction below converts the labels (from 1 to 8) to a series from 0 to 7\n",
        "        # This is because our predictor needs to start from 0 otherwise it will try to predict also 0.\n",
        "        file = int(file[7:8]) - 1 \n",
        "        if(file ==6 or file==7):\n",
        "          continue\n",
        "        count +=1\n",
        "        arr = mfccs, file\n",
        "        lst.append(arr)\n",
        "      # If the file is not valid, skip it\n",
        "      except ValueError:\n",
        "        continue\n",
        "\n",
        "\n",
        "\n",
        "print(\"--- Data loaded. Loading time: %s seconds ---\" % (time.time() - start_time))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IfuyRZl42ccZ",
        "outputId": "9006cf62-373a-432b-d161-7072538f7553"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Actor_10', 'Actor_11', 'Actor_13', 'Actor_12', 'Actor_14', 'Actor_15', 'Actor_16', 'Actor_17', 'Actor_18', 'Actor_19', 'Actor_21', 'Actor_22', 'Actor_23', 'Actor_09', 'Actor_24', 'Actor_04', 'Actor_08', 'Actor_03', 'Actor_02', 'Actor_06', 'Actor_05', 'Actor_01', 'Actor_07', 'Actor_20']\n",
            "/content/drive/MyDrive/RAVDESS_song\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_10\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_11\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_13\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_12\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_14\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_15\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_16\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_17\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_18\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_19\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_21\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_22\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_23\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_09\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_24\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_04\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_08\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_03\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_02\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_06\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_05\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_01\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_07\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_20\n",
            "['Actor_05', 'Actor_08', 'Actor_10', 'Actor_04', 'Actor_09', 'Actor_14', 'Actor_12', 'Actor_13', 'Actor_11', 'Actor_06', 'Actor_24', 'Actor_07', 'Actor_23', 'Actor_22', 'Actor_21', 'Actor_20', 'Actor_02', 'Actor_19', 'Actor_18', 'Actor_17', 'Actor_16', 'Actor_15', 'Actor_03', 'Actor_01']\n",
            "/content/drive/MyDrive/RAVDESS_speech\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_05\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_08\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_10\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_04\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_09\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_14\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_12\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_13\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_11\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_06\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_24\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_07\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_23\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_22\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_21\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_20\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_02\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_19\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_18\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_17\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_16\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_15\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_03\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_01\n",
            "--- Data loaded. Loading time: 215.2808015346527 seconds ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "count"
      ],
      "metadata": {
        "id": "Ltlhi25L2AI5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "054150ab-ee7a-4db1-c745-8cb2e0547453"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2068"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy.core.fromnumeric import size\n",
        "size(lst)"
      ],
      "metadata": {
        "id": "HMOH7d7mzHB7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60acca32-ca5a-46bf-9af4-63e6adc69adf"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/core/fromnumeric.py:3208: VisibleDeprecationWarning:\n",
            "\n",
            "Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4136"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating X and y: zip makes a list of all the first elements, and a list of all the second elements.\n",
        "X, y = zip(*lst)"
      ],
      "metadata": {
        "id": "ocdL7tSTBoMt"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "X = np.asarray(X)\n",
        "y = np.asarray(y)\n",
        "X.shape, y.shape"
      ],
      "metadata": {
        "id": "vHKwUGTbBtnF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d43bebd3-0dc0-482d-f76d-d69edb375c9e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((2068, 40), (2068,))"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "id": "2sUCtbfMztE5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be9b640d-b6b1-4f57-a95a-7e22c8b750ed"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2068, 40)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Saving joblib files to not load them again with the loop above\n",
        "\n",
        "# import joblib\n",
        "\n",
        "# X_name = 'x.joblib'\n",
        "# y_name = 'y.joblib'\n",
        "# save_dir = '/content/drive/My Drive/graduation project/audio/paper_code/features'\n",
        "\n",
        "# savedX = joblib.dump(X, os.path.join(save_dir, X_name))\n",
        "# savedy = joblib.dump(y, os.path.join(save_dir, y_name))"
      ],
      "metadata": {
        "id": "UCzic8rlDcuk"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Loading saved models\n",
        "# import joblib\n",
        "# X = joblib.load('/content/drive/My Drive/graduation project/audio/paper_code/features/x.joblib')\n",
        "# y = joblib.load('/content/drive/My Drive/graduation project/audio/paper_code/features/y.joblib')"
      ],
      "metadata": {
        "id": "Q35CN6zDrzg1"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7PSTurzjCo5K",
        "outputId": "94a82ff4-9458-4e46-f105-7f30a4e97f90"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2068, 40)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2,train_size=0.8, random_state=42)\n",
        "X_valid, X_test, y_valid, y_test = train_test_split(X_test,y_test, test_size=0.5,train_size=0.5, random_state=42)"
      ],
      "metadata": {
        "id": "Ai4Fy5cPCiq1"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "x_traincnn = np.expand_dims(X_train, axis=2)\n",
        "x_testcnn = np.expand_dims(X_test, axis=2)\n",
        "X_valid= np.expand_dims(X_valid, axis=2)"
      ],
      "metadata": {
        "id": "tp1Fm5K3CEXu"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_traincnn.shape, x_testcnn.shape , X_valid.shape"
      ],
      "metadata": {
        "id": "RI0MxoIPBws5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d04a382-df5f-48d5-db5a-7d40daee8883"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1654, 40, 1), (207, 40, 1), (207, 40, 1))"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow"
      ],
      "metadata": {
        "id": "goxL4Y3jKICC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "476d545a-85f2-480c-c923-1e90ed9c4000"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (2.8.2+zzzcolab20220527125636)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.17.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow) (57.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (4.2.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (14.0.1)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.0.0)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.0)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.21.6)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.26.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.46.3)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.5.3)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: tensorflow-estimator<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow) (1.5.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (3.3.7)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.35.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.6.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.23.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.8.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.4.6)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (4.11.4)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (3.8.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2022.5.18.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2.10)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (3.2.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keras"
      ],
      "metadata": {
        "id": "EkcmN9UrKSxj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "709b811c-4547-463d-84a3-012f744352fa"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.7/dist-packages (2.8.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from keras.preprocessing import sequence\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from keras.layers import Input, Flatten, Dropout, Activation\n",
        "from keras.layers import Conv1D, MaxPooling1D\n",
        "from keras.models import Model\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras import optimizers\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv1D(128, 8,padding='same', #classifier.add(Convolution2D(64, (3, 3), padding = 'same', input_shape = (128, 128, 3), activation = 'relu'))\n",
        "                 input_shape=(40,1)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(MaxPooling1D(pool_size=(5)))\n",
        "\n",
        "\n",
        "model.add(Conv1D(256,8,padding='same',))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(MaxPooling1D(pool_size=(5)))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(256))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(256))\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "model.add(Dense(6))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "opt = tf.keras.optimizers.Adam(lr=0.00002)\n",
        "#opt = tf.keras.optimizers.RMSprop(lr=0.0001, rho=0.9, epsilon=1e-07, decay=0.0)\n",
        "#opt = tf.keras.optimizers.SGD(lr=0.001, momentum=0.0, decay=0.0, nesterov=False)"
      ],
      "metadata": {
        "id": "g74fXWVAC4Cr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15a24778-b646-44d4-fb95-8fa5bc952e4e"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning:\n",
            "\n",
            "The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H6ukOxAGC_I4",
        "outputId": "06bc05ec-551c-4aaa-a736-c22fc4c0ecbb"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d (Conv1D)             (None, 40, 128)           1152      \n",
            "                                                                 \n",
            " activation (Activation)     (None, 40, 128)           0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 40, 128)           0         \n",
            "                                                                 \n",
            " max_pooling1d (MaxPooling1D  (None, 8, 128)           0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv1d_1 (Conv1D)           (None, 8, 256)            262400    \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 8, 256)            0         \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 8, 256)            0         \n",
            "                                                                 \n",
            " max_pooling1d_1 (MaxPooling  (None, 1, 256)           0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 256)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 256)               65792     \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 256)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 256)               65792     \n",
            "                                                                 \n",
            " activation_3 (Activation)   (None, 256)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 6)                 1542      \n",
            "                                                                 \n",
            " activation_4 (Activation)   (None, 6)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 396,678\n",
            "Trainable params: 396,678\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='sparse_categorical_crossentropy',\n",
        "              optimizer=opt,\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "AbMlLNk4DCBM"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#cnnhistory=model.fit(x_traincnn, y_train, batch_size=16, epochs=700, validation_data=(x_testcnn, y_test))\n",
        "cnnhistory=model.fit(x_traincnn, y_train, batch_size=16, epochs=1000 , validation_data=(X_valid, y_valid))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RI1v2AuADFhy",
        "outputId": "72d94c6d-f9da-49a7-aae2-a0ffaafea174"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "104/104 [==============================] - 4s 7ms/step - loss: 6.3234 - accuracy: 0.1790 - val_loss: 2.0995 - val_accuracy: 0.1594\n",
            "Epoch 2/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 4.3978 - accuracy: 0.1850 - val_loss: 1.9450 - val_accuracy: 0.2126\n",
            "Epoch 3/1000\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 3.9342 - accuracy: 0.1693 - val_loss: 1.9836 - val_accuracy: 0.2174\n",
            "Epoch 4/1000\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 3.4498 - accuracy: 0.1699 - val_loss: 1.8652 - val_accuracy: 0.2754\n",
            "Epoch 5/1000\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 3.0398 - accuracy: 0.1965 - val_loss: 1.7920 - val_accuracy: 0.2705\n",
            "Epoch 6/1000\n",
            "104/104 [==============================] - 1s 9ms/step - loss: 2.9065 - accuracy: 0.1965 - val_loss: 1.7921 - val_accuracy: 0.2367\n",
            "Epoch 7/1000\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 2.7736 - accuracy: 0.1886 - val_loss: 1.7814 - val_accuracy: 0.2415\n",
            "Epoch 8/1000\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 2.5992 - accuracy: 0.1844 - val_loss: 1.7047 - val_accuracy: 0.2850\n",
            "Epoch 9/1000\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 2.4349 - accuracy: 0.1917 - val_loss: 1.6992 - val_accuracy: 0.2657\n",
            "Epoch 10/1000\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 2.3800 - accuracy: 0.2098 - val_loss: 1.6700 - val_accuracy: 0.2947\n",
            "Epoch 11/1000\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 2.3185 - accuracy: 0.1892 - val_loss: 1.7050 - val_accuracy: 0.2367\n",
            "Epoch 12/1000\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 2.2676 - accuracy: 0.2261 - val_loss: 1.6871 - val_accuracy: 0.2367\n",
            "Epoch 13/1000\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 2.2211 - accuracy: 0.2080 - val_loss: 1.6827 - val_accuracy: 0.3140\n",
            "Epoch 14/1000\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 2.1631 - accuracy: 0.2013 - val_loss: 1.6624 - val_accuracy: 0.3575\n",
            "Epoch 15/1000\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 2.1366 - accuracy: 0.2086 - val_loss: 1.7121 - val_accuracy: 0.1884\n",
            "Epoch 16/1000\n",
            "104/104 [==============================] - 1s 9ms/step - loss: 2.0985 - accuracy: 0.2189 - val_loss: 1.6917 - val_accuracy: 0.3140\n",
            "Epoch 17/1000\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 2.0378 - accuracy: 0.2207 - val_loss: 1.6528 - val_accuracy: 0.3188\n",
            "Epoch 18/1000\n",
            "104/104 [==============================] - 1s 9ms/step - loss: 2.0433 - accuracy: 0.2104 - val_loss: 1.6657 - val_accuracy: 0.3092\n",
            "Epoch 19/1000\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 1.9561 - accuracy: 0.2346 - val_loss: 1.6537 - val_accuracy: 0.2802\n",
            "Epoch 20/1000\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 2.0016 - accuracy: 0.2092 - val_loss: 1.6638 - val_accuracy: 0.3140\n",
            "Epoch 21/1000\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 1.9488 - accuracy: 0.2316 - val_loss: 1.6514 - val_accuracy: 0.3478\n",
            "Epoch 22/1000\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 1.9652 - accuracy: 0.2104 - val_loss: 1.6559 - val_accuracy: 0.3575\n",
            "Epoch 23/1000\n",
            "104/104 [==============================] - 1s 9ms/step - loss: 1.9458 - accuracy: 0.2406 - val_loss: 1.6685 - val_accuracy: 0.3043\n",
            "Epoch 24/1000\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 1.8900 - accuracy: 0.2297 - val_loss: 1.6924 - val_accuracy: 0.2802\n",
            "Epoch 25/1000\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 1.9210 - accuracy: 0.2128 - val_loss: 1.6935 - val_accuracy: 0.3092\n",
            "Epoch 26/1000\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 1.8811 - accuracy: 0.2449 - val_loss: 1.6730 - val_accuracy: 0.3333\n",
            "Epoch 27/1000\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 1.8374 - accuracy: 0.2291 - val_loss: 1.6610 - val_accuracy: 0.3188\n",
            "Epoch 28/1000\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 1.8309 - accuracy: 0.2588 - val_loss: 1.6713 - val_accuracy: 0.2657\n",
            "Epoch 29/1000\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 1.8483 - accuracy: 0.2364 - val_loss: 1.6681 - val_accuracy: 0.2802\n",
            "Epoch 30/1000\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 1.8289 - accuracy: 0.2424 - val_loss: 1.6478 - val_accuracy: 0.2947\n",
            "Epoch 31/1000\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 1.8247 - accuracy: 0.2340 - val_loss: 1.6341 - val_accuracy: 0.3430\n",
            "Epoch 32/1000\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 1.8341 - accuracy: 0.2437 - val_loss: 1.6817 - val_accuracy: 0.2657\n",
            "Epoch 33/1000\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 1.7981 - accuracy: 0.2557 - val_loss: 1.6521 - val_accuracy: 0.3575\n",
            "Epoch 34/1000\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 1.7828 - accuracy: 0.2509 - val_loss: 1.6626 - val_accuracy: 0.3237\n",
            "Epoch 35/1000\n",
            "104/104 [==============================] - 1s 9ms/step - loss: 1.7722 - accuracy: 0.2636 - val_loss: 1.6401 - val_accuracy: 0.3913\n",
            "Epoch 36/1000\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 1.7403 - accuracy: 0.2787 - val_loss: 1.6463 - val_accuracy: 0.2947\n",
            "Epoch 37/1000\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 1.7854 - accuracy: 0.2594 - val_loss: 1.6335 - val_accuracy: 0.3623\n",
            "Epoch 38/1000\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 1.7847 - accuracy: 0.2624 - val_loss: 1.6584 - val_accuracy: 0.2947\n",
            "Epoch 39/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.7597 - accuracy: 0.2545 - val_loss: 1.6518 - val_accuracy: 0.2850\n",
            "Epoch 40/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.7726 - accuracy: 0.2642 - val_loss: 1.6211 - val_accuracy: 0.3430\n",
            "Epoch 41/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.7696 - accuracy: 0.2739 - val_loss: 1.6440 - val_accuracy: 0.3043\n",
            "Epoch 42/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.7452 - accuracy: 0.2721 - val_loss: 1.6223 - val_accuracy: 0.3092\n",
            "Epoch 43/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.7262 - accuracy: 0.2805 - val_loss: 1.6306 - val_accuracy: 0.3382\n",
            "Epoch 44/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.7433 - accuracy: 0.2527 - val_loss: 1.6067 - val_accuracy: 0.3333\n",
            "Epoch 45/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.7402 - accuracy: 0.2672 - val_loss: 1.6051 - val_accuracy: 0.3623\n",
            "Epoch 46/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.7149 - accuracy: 0.2848 - val_loss: 1.6116 - val_accuracy: 0.3382\n",
            "Epoch 47/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.6954 - accuracy: 0.2938 - val_loss: 1.6173 - val_accuracy: 0.3285\n",
            "Epoch 48/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.6982 - accuracy: 0.3041 - val_loss: 1.6214 - val_accuracy: 0.3478\n",
            "Epoch 49/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.7033 - accuracy: 0.2805 - val_loss: 1.5977 - val_accuracy: 0.4058\n",
            "Epoch 50/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.7128 - accuracy: 0.2769 - val_loss: 1.6046 - val_accuracy: 0.3140\n",
            "Epoch 51/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.7019 - accuracy: 0.2878 - val_loss: 1.5764 - val_accuracy: 0.3865\n",
            "Epoch 52/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.6924 - accuracy: 0.2872 - val_loss: 1.5857 - val_accuracy: 0.3961\n",
            "Epoch 53/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.6883 - accuracy: 0.2932 - val_loss: 1.6278 - val_accuracy: 0.3333\n",
            "Epoch 54/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.6721 - accuracy: 0.2950 - val_loss: 1.6086 - val_accuracy: 0.3575\n",
            "Epoch 55/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.6731 - accuracy: 0.2787 - val_loss: 1.6143 - val_accuracy: 0.2319\n",
            "Epoch 56/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.6611 - accuracy: 0.2932 - val_loss: 1.5972 - val_accuracy: 0.4058\n",
            "Epoch 57/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.6528 - accuracy: 0.2999 - val_loss: 1.6133 - val_accuracy: 0.3671\n",
            "Epoch 58/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.6351 - accuracy: 0.3156 - val_loss: 1.5716 - val_accuracy: 0.3671\n",
            "Epoch 59/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.6426 - accuracy: 0.3089 - val_loss: 1.5636 - val_accuracy: 0.3768\n",
            "Epoch 60/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.6624 - accuracy: 0.3071 - val_loss: 1.5730 - val_accuracy: 0.3720\n",
            "Epoch 61/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.6318 - accuracy: 0.3222 - val_loss: 1.5661 - val_accuracy: 0.3768\n",
            "Epoch 62/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.6294 - accuracy: 0.3174 - val_loss: 1.5621 - val_accuracy: 0.3865\n",
            "Epoch 63/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.6095 - accuracy: 0.3259 - val_loss: 1.5456 - val_accuracy: 0.3720\n",
            "Epoch 64/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.6383 - accuracy: 0.3089 - val_loss: 1.5457 - val_accuracy: 0.3768\n",
            "Epoch 65/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.6346 - accuracy: 0.3204 - val_loss: 1.5508 - val_accuracy: 0.4058\n",
            "Epoch 66/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.6446 - accuracy: 0.3319 - val_loss: 1.5642 - val_accuracy: 0.3285\n",
            "Epoch 67/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.5987 - accuracy: 0.3265 - val_loss: 1.5508 - val_accuracy: 0.3671\n",
            "Epoch 68/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.6092 - accuracy: 0.3150 - val_loss: 1.5670 - val_accuracy: 0.3043\n",
            "Epoch 69/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.6043 - accuracy: 0.3325 - val_loss: 1.5414 - val_accuracy: 0.3333\n",
            "Epoch 70/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.6103 - accuracy: 0.3458 - val_loss: 1.5409 - val_accuracy: 0.3816\n",
            "Epoch 71/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.5853 - accuracy: 0.3428 - val_loss: 1.5230 - val_accuracy: 0.3768\n",
            "Epoch 72/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.5835 - accuracy: 0.3380 - val_loss: 1.5249 - val_accuracy: 0.3623\n",
            "Epoch 73/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.5858 - accuracy: 0.3392 - val_loss: 1.5225 - val_accuracy: 0.3720\n",
            "Epoch 74/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.5765 - accuracy: 0.3343 - val_loss: 1.5239 - val_accuracy: 0.3913\n",
            "Epoch 75/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.5557 - accuracy: 0.3452 - val_loss: 1.5208 - val_accuracy: 0.3865\n",
            "Epoch 76/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.5656 - accuracy: 0.3531 - val_loss: 1.5066 - val_accuracy: 0.4010\n",
            "Epoch 77/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.5650 - accuracy: 0.3519 - val_loss: 1.5156 - val_accuracy: 0.4058\n",
            "Epoch 78/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.5424 - accuracy: 0.3519 - val_loss: 1.4897 - val_accuracy: 0.3768\n",
            "Epoch 79/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.5486 - accuracy: 0.3742 - val_loss: 1.4981 - val_accuracy: 0.4300\n",
            "Epoch 80/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.5294 - accuracy: 0.3628 - val_loss: 1.5087 - val_accuracy: 0.3671\n",
            "Epoch 81/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.5634 - accuracy: 0.3482 - val_loss: 1.4827 - val_accuracy: 0.4251\n",
            "Epoch 82/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.5408 - accuracy: 0.3489 - val_loss: 1.4937 - val_accuracy: 0.4058\n",
            "Epoch 83/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.5083 - accuracy: 0.3767 - val_loss: 1.4811 - val_accuracy: 0.4300\n",
            "Epoch 84/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.5227 - accuracy: 0.3839 - val_loss: 1.4605 - val_accuracy: 0.4300\n",
            "Epoch 85/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.5248 - accuracy: 0.3628 - val_loss: 1.4663 - val_accuracy: 0.4348\n",
            "Epoch 86/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.5175 - accuracy: 0.3646 - val_loss: 1.4594 - val_accuracy: 0.4638\n",
            "Epoch 87/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.5153 - accuracy: 0.3664 - val_loss: 1.4587 - val_accuracy: 0.4203\n",
            "Epoch 88/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.5108 - accuracy: 0.3767 - val_loss: 1.4664 - val_accuracy: 0.3720\n",
            "Epoch 89/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.4937 - accuracy: 0.4057 - val_loss: 1.4644 - val_accuracy: 0.3768\n",
            "Epoch 90/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.4828 - accuracy: 0.3809 - val_loss: 1.4566 - val_accuracy: 0.3913\n",
            "Epoch 91/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.4845 - accuracy: 0.3875 - val_loss: 1.4589 - val_accuracy: 0.4444\n",
            "Epoch 92/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.4723 - accuracy: 0.3966 - val_loss: 1.4466 - val_accuracy: 0.4493\n",
            "Epoch 93/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.4822 - accuracy: 0.4021 - val_loss: 1.4521 - val_accuracy: 0.4444\n",
            "Epoch 94/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.4672 - accuracy: 0.3990 - val_loss: 1.4372 - val_accuracy: 0.4396\n",
            "Epoch 95/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.4852 - accuracy: 0.3761 - val_loss: 1.4021 - val_accuracy: 0.4638\n",
            "Epoch 96/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.4560 - accuracy: 0.4057 - val_loss: 1.4140 - val_accuracy: 0.4831\n",
            "Epoch 97/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.4760 - accuracy: 0.3948 - val_loss: 1.4023 - val_accuracy: 0.4541\n",
            "Epoch 98/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.4335 - accuracy: 0.4154 - val_loss: 1.3891 - val_accuracy: 0.4686\n",
            "Epoch 99/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.4537 - accuracy: 0.4148 - val_loss: 1.3832 - val_accuracy: 0.4783\n",
            "Epoch 100/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.4447 - accuracy: 0.4057 - val_loss: 1.3876 - val_accuracy: 0.4976\n",
            "Epoch 101/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.4570 - accuracy: 0.3954 - val_loss: 1.3949 - val_accuracy: 0.4734\n",
            "Epoch 102/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.4254 - accuracy: 0.4148 - val_loss: 1.3695 - val_accuracy: 0.4831\n",
            "Epoch 103/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.4346 - accuracy: 0.4148 - val_loss: 1.3721 - val_accuracy: 0.5024\n",
            "Epoch 104/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.4422 - accuracy: 0.4129 - val_loss: 1.3699 - val_accuracy: 0.4928\n",
            "Epoch 105/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.4173 - accuracy: 0.4299 - val_loss: 1.3795 - val_accuracy: 0.5024\n",
            "Epoch 106/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.4078 - accuracy: 0.4256 - val_loss: 1.3675 - val_accuracy: 0.5072\n",
            "Epoch 107/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.4141 - accuracy: 0.4274 - val_loss: 1.3798 - val_accuracy: 0.4976\n",
            "Epoch 108/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.4151 - accuracy: 0.4281 - val_loss: 1.3546 - val_accuracy: 0.5411\n",
            "Epoch 109/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.4197 - accuracy: 0.4214 - val_loss: 1.3592 - val_accuracy: 0.4928\n",
            "Epoch 110/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.4085 - accuracy: 0.4335 - val_loss: 1.3632 - val_accuracy: 0.4879\n",
            "Epoch 111/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.3788 - accuracy: 0.4347 - val_loss: 1.3619 - val_accuracy: 0.5024\n",
            "Epoch 112/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.3768 - accuracy: 0.4534 - val_loss: 1.3423 - val_accuracy: 0.4783\n",
            "Epoch 113/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.3812 - accuracy: 0.4232 - val_loss: 1.3463 - val_accuracy: 0.5169\n",
            "Epoch 114/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.3650 - accuracy: 0.4323 - val_loss: 1.3128 - val_accuracy: 0.5362\n",
            "Epoch 115/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.3701 - accuracy: 0.4359 - val_loss: 1.3134 - val_accuracy: 0.5556\n",
            "Epoch 116/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.3792 - accuracy: 0.4377 - val_loss: 1.3199 - val_accuracy: 0.4928\n",
            "Epoch 117/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.3988 - accuracy: 0.4220 - val_loss: 1.3048 - val_accuracy: 0.5024\n",
            "Epoch 118/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.3728 - accuracy: 0.4522 - val_loss: 1.3073 - val_accuracy: 0.5072\n",
            "Epoch 119/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.3595 - accuracy: 0.4498 - val_loss: 1.3141 - val_accuracy: 0.5121\n",
            "Epoch 120/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.3519 - accuracy: 0.4510 - val_loss: 1.3074 - val_accuracy: 0.5121\n",
            "Epoch 121/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.3432 - accuracy: 0.4516 - val_loss: 1.2987 - val_accuracy: 0.5266\n",
            "Epoch 122/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.3400 - accuracy: 0.4547 - val_loss: 1.2866 - val_accuracy: 0.5266\n",
            "Epoch 123/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.3488 - accuracy: 0.4492 - val_loss: 1.2984 - val_accuracy: 0.5604\n",
            "Epoch 124/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.3514 - accuracy: 0.4541 - val_loss: 1.3012 - val_accuracy: 0.5266\n",
            "Epoch 125/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.3209 - accuracy: 0.4637 - val_loss: 1.2916 - val_accuracy: 0.5507\n",
            "Epoch 126/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.3392 - accuracy: 0.4504 - val_loss: 1.2772 - val_accuracy: 0.5024\n",
            "Epoch 127/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.3294 - accuracy: 0.4637 - val_loss: 1.2764 - val_accuracy: 0.5459\n",
            "Epoch 128/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.3471 - accuracy: 0.4541 - val_loss: 1.2721 - val_accuracy: 0.5507\n",
            "Epoch 129/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.3066 - accuracy: 0.4722 - val_loss: 1.2876 - val_accuracy: 0.4928\n",
            "Epoch 130/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.3183 - accuracy: 0.4686 - val_loss: 1.2731 - val_accuracy: 0.5411\n",
            "Epoch 131/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.3209 - accuracy: 0.4698 - val_loss: 1.2640 - val_accuracy: 0.5411\n",
            "Epoch 132/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.3302 - accuracy: 0.4541 - val_loss: 1.2637 - val_accuracy: 0.5652\n",
            "Epoch 133/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.2774 - accuracy: 0.4800 - val_loss: 1.2561 - val_accuracy: 0.5459\n",
            "Epoch 134/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.3100 - accuracy: 0.4807 - val_loss: 1.2734 - val_accuracy: 0.5362\n",
            "Epoch 135/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.3034 - accuracy: 0.4613 - val_loss: 1.2503 - val_accuracy: 0.5314\n",
            "Epoch 136/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.2799 - accuracy: 0.4873 - val_loss: 1.2368 - val_accuracy: 0.5652\n",
            "Epoch 137/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.2853 - accuracy: 0.4553 - val_loss: 1.2484 - val_accuracy: 0.5459\n",
            "Epoch 138/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.2735 - accuracy: 0.4964 - val_loss: 1.2405 - val_accuracy: 0.5411\n",
            "Epoch 139/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.2823 - accuracy: 0.4843 - val_loss: 1.2276 - val_accuracy: 0.5604\n",
            "Epoch 140/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.2759 - accuracy: 0.4903 - val_loss: 1.2400 - val_accuracy: 0.5266\n",
            "Epoch 141/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.2497 - accuracy: 0.4819 - val_loss: 1.2254 - val_accuracy: 0.5459\n",
            "Epoch 142/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.2617 - accuracy: 0.4946 - val_loss: 1.2261 - val_accuracy: 0.5314\n",
            "Epoch 143/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.2683 - accuracy: 0.4807 - val_loss: 1.2229 - val_accuracy: 0.5604\n",
            "Epoch 144/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.2633 - accuracy: 0.4970 - val_loss: 1.2061 - val_accuracy: 0.5700\n",
            "Epoch 145/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.2532 - accuracy: 0.4921 - val_loss: 1.2020 - val_accuracy: 0.5845\n",
            "Epoch 146/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.2584 - accuracy: 0.4903 - val_loss: 1.1879 - val_accuracy: 0.5700\n",
            "Epoch 147/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.2399 - accuracy: 0.5012 - val_loss: 1.2363 - val_accuracy: 0.5072\n",
            "Epoch 148/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.2566 - accuracy: 0.4964 - val_loss: 1.1954 - val_accuracy: 0.5749\n",
            "Epoch 149/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.2352 - accuracy: 0.5048 - val_loss: 1.1778 - val_accuracy: 0.5700\n",
            "Epoch 150/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.2334 - accuracy: 0.4794 - val_loss: 1.1684 - val_accuracy: 0.5845\n",
            "Epoch 151/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.2225 - accuracy: 0.5151 - val_loss: 1.1785 - val_accuracy: 0.5556\n",
            "Epoch 152/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.2398 - accuracy: 0.5042 - val_loss: 1.1571 - val_accuracy: 0.5894\n",
            "Epoch 153/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.2105 - accuracy: 0.5115 - val_loss: 1.1765 - val_accuracy: 0.5604\n",
            "Epoch 154/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.2577 - accuracy: 0.4837 - val_loss: 1.1651 - val_accuracy: 0.5845\n",
            "Epoch 155/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.2313 - accuracy: 0.4988 - val_loss: 1.1463 - val_accuracy: 0.6184\n",
            "Epoch 156/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.2152 - accuracy: 0.5006 - val_loss: 1.1526 - val_accuracy: 0.5797\n",
            "Epoch 157/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.2207 - accuracy: 0.4982 - val_loss: 1.1535 - val_accuracy: 0.5749\n",
            "Epoch 158/1000\n",
            "104/104 [==============================] - 1s 9ms/step - loss: 1.1937 - accuracy: 0.5151 - val_loss: 1.1420 - val_accuracy: 0.6135\n",
            "Epoch 159/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.2081 - accuracy: 0.5030 - val_loss: 1.1422 - val_accuracy: 0.5604\n",
            "Epoch 160/1000\n",
            "104/104 [==============================] - 1s 9ms/step - loss: 1.1990 - accuracy: 0.5042 - val_loss: 1.1387 - val_accuracy: 0.5894\n",
            "Epoch 161/1000\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 1.2054 - accuracy: 0.5024 - val_loss: 1.1410 - val_accuracy: 0.5990\n",
            "Epoch 162/1000\n",
            "104/104 [==============================] - 1s 9ms/step - loss: 1.2063 - accuracy: 0.5181 - val_loss: 1.1526 - val_accuracy: 0.5845\n",
            "Epoch 163/1000\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 1.2110 - accuracy: 0.5085 - val_loss: 1.1399 - val_accuracy: 0.5652\n",
            "Epoch 164/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.1689 - accuracy: 0.5272 - val_loss: 1.1327 - val_accuracy: 0.6135\n",
            "Epoch 165/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.2037 - accuracy: 0.5085 - val_loss: 1.1263 - val_accuracy: 0.6184\n",
            "Epoch 166/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.2042 - accuracy: 0.5115 - val_loss: 1.1249 - val_accuracy: 0.6087\n",
            "Epoch 167/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.1936 - accuracy: 0.5224 - val_loss: 1.1317 - val_accuracy: 0.5797\n",
            "Epoch 168/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.1702 - accuracy: 0.5339 - val_loss: 1.1297 - val_accuracy: 0.5700\n",
            "Epoch 169/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.1871 - accuracy: 0.5363 - val_loss: 1.1420 - val_accuracy: 0.5845\n",
            "Epoch 170/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.1594 - accuracy: 0.5417 - val_loss: 1.1352 - val_accuracy: 0.5894\n",
            "Epoch 171/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.1535 - accuracy: 0.5357 - val_loss: 1.1143 - val_accuracy: 0.6087\n",
            "Epoch 172/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.1713 - accuracy: 0.5314 - val_loss: 1.1212 - val_accuracy: 0.6039\n",
            "Epoch 173/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.1899 - accuracy: 0.5091 - val_loss: 1.1198 - val_accuracy: 0.5845\n",
            "Epoch 174/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.1680 - accuracy: 0.5260 - val_loss: 1.1130 - val_accuracy: 0.5749\n",
            "Epoch 175/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.1541 - accuracy: 0.5308 - val_loss: 1.1004 - val_accuracy: 0.5845\n",
            "Epoch 176/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.1770 - accuracy: 0.5308 - val_loss: 1.1092 - val_accuracy: 0.5894\n",
            "Epoch 177/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.1468 - accuracy: 0.5435 - val_loss: 1.1007 - val_accuracy: 0.6039\n",
            "Epoch 178/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.1431 - accuracy: 0.5284 - val_loss: 1.1062 - val_accuracy: 0.6087\n",
            "Epoch 179/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.1576 - accuracy: 0.5411 - val_loss: 1.1039 - val_accuracy: 0.6135\n",
            "Epoch 180/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.1570 - accuracy: 0.5308 - val_loss: 1.1049 - val_accuracy: 0.5652\n",
            "Epoch 181/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.1340 - accuracy: 0.5520 - val_loss: 1.0913 - val_accuracy: 0.5749\n",
            "Epoch 182/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.1660 - accuracy: 0.5272 - val_loss: 1.1029 - val_accuracy: 0.6184\n",
            "Epoch 183/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.1204 - accuracy: 0.5441 - val_loss: 1.0958 - val_accuracy: 0.6039\n",
            "Epoch 184/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.1524 - accuracy: 0.5405 - val_loss: 1.1027 - val_accuracy: 0.5894\n",
            "Epoch 185/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.1503 - accuracy: 0.5296 - val_loss: 1.0948 - val_accuracy: 0.6280\n",
            "Epoch 186/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.1369 - accuracy: 0.5447 - val_loss: 1.0878 - val_accuracy: 0.6135\n",
            "Epoch 187/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.1313 - accuracy: 0.5423 - val_loss: 1.0834 - val_accuracy: 0.5990\n",
            "Epoch 188/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.1464 - accuracy: 0.5345 - val_loss: 1.0932 - val_accuracy: 0.6087\n",
            "Epoch 189/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.0973 - accuracy: 0.5683 - val_loss: 1.0861 - val_accuracy: 0.5894\n",
            "Epoch 190/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.1063 - accuracy: 0.5520 - val_loss: 1.0751 - val_accuracy: 0.6329\n",
            "Epoch 191/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.1253 - accuracy: 0.5502 - val_loss: 1.0788 - val_accuracy: 0.5942\n",
            "Epoch 192/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.1040 - accuracy: 0.5502 - val_loss: 1.0646 - val_accuracy: 0.6135\n",
            "Epoch 193/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.1359 - accuracy: 0.5502 - val_loss: 1.0666 - val_accuracy: 0.6087\n",
            "Epoch 194/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.0941 - accuracy: 0.5526 - val_loss: 1.0621 - val_accuracy: 0.6087\n",
            "Epoch 195/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.1158 - accuracy: 0.5544 - val_loss: 1.0761 - val_accuracy: 0.6135\n",
            "Epoch 196/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0978 - accuracy: 0.5671 - val_loss: 1.0592 - val_accuracy: 0.6135\n",
            "Epoch 197/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.1019 - accuracy: 0.5520 - val_loss: 1.0664 - val_accuracy: 0.5990\n",
            "Epoch 198/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.1022 - accuracy: 0.5502 - val_loss: 1.0538 - val_accuracy: 0.6087\n",
            "Epoch 199/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0853 - accuracy: 0.5647 - val_loss: 1.0543 - val_accuracy: 0.6135\n",
            "Epoch 200/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.0829 - accuracy: 0.5599 - val_loss: 1.0427 - val_accuracy: 0.6377\n",
            "Epoch 201/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.0926 - accuracy: 0.5611 - val_loss: 1.0492 - val_accuracy: 0.6087\n",
            "Epoch 202/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0741 - accuracy: 0.5762 - val_loss: 1.0529 - val_accuracy: 0.6280\n",
            "Epoch 203/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0742 - accuracy: 0.5792 - val_loss: 1.0554 - val_accuracy: 0.5894\n",
            "Epoch 204/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0818 - accuracy: 0.5635 - val_loss: 1.0531 - val_accuracy: 0.6184\n",
            "Epoch 205/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0646 - accuracy: 0.5768 - val_loss: 1.0440 - val_accuracy: 0.6135\n",
            "Epoch 206/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0746 - accuracy: 0.5774 - val_loss: 1.0504 - val_accuracy: 0.6184\n",
            "Epoch 207/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0893 - accuracy: 0.5659 - val_loss: 1.0439 - val_accuracy: 0.6232\n",
            "Epoch 208/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0651 - accuracy: 0.5647 - val_loss: 1.0335 - val_accuracy: 0.6135\n",
            "Epoch 209/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0736 - accuracy: 0.5629 - val_loss: 1.0254 - val_accuracy: 0.6087\n",
            "Epoch 210/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.0679 - accuracy: 0.5834 - val_loss: 1.0317 - val_accuracy: 0.6280\n",
            "Epoch 211/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0521 - accuracy: 0.5859 - val_loss: 1.0187 - val_accuracy: 0.6280\n",
            "Epoch 212/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0455 - accuracy: 0.5671 - val_loss: 1.0403 - val_accuracy: 0.6329\n",
            "Epoch 213/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.0598 - accuracy: 0.5834 - val_loss: 1.0168 - val_accuracy: 0.6570\n",
            "Epoch 214/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.0607 - accuracy: 0.5738 - val_loss: 1.0114 - val_accuracy: 0.6329\n",
            "Epoch 215/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0650 - accuracy: 0.5629 - val_loss: 1.0266 - val_accuracy: 0.6184\n",
            "Epoch 216/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.0537 - accuracy: 0.5768 - val_loss: 1.0108 - val_accuracy: 0.6280\n",
            "Epoch 217/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0465 - accuracy: 0.5756 - val_loss: 1.0238 - val_accuracy: 0.5845\n",
            "Epoch 218/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.0345 - accuracy: 0.5901 - val_loss: 1.0152 - val_accuracy: 0.6570\n",
            "Epoch 219/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0449 - accuracy: 0.5756 - val_loss: 1.0093 - val_accuracy: 0.6473\n",
            "Epoch 220/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0364 - accuracy: 0.5925 - val_loss: 1.0155 - val_accuracy: 0.6280\n",
            "Epoch 221/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0356 - accuracy: 0.5822 - val_loss: 0.9991 - val_accuracy: 0.6232\n",
            "Epoch 222/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.0218 - accuracy: 0.5877 - val_loss: 0.9887 - val_accuracy: 0.6377\n",
            "Epoch 223/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.0208 - accuracy: 0.5846 - val_loss: 0.9928 - val_accuracy: 0.6425\n",
            "Epoch 224/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0211 - accuracy: 0.5949 - val_loss: 1.0080 - val_accuracy: 0.5894\n",
            "Epoch 225/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0312 - accuracy: 0.5967 - val_loss: 1.0027 - val_accuracy: 0.6280\n",
            "Epoch 226/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0234 - accuracy: 0.5931 - val_loss: 0.9945 - val_accuracy: 0.6280\n",
            "Epoch 227/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0118 - accuracy: 0.5961 - val_loss: 0.9908 - val_accuracy: 0.6377\n",
            "Epoch 228/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0321 - accuracy: 0.5925 - val_loss: 0.9941 - val_accuracy: 0.6522\n",
            "Epoch 229/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0269 - accuracy: 0.6016 - val_loss: 0.9870 - val_accuracy: 0.6667\n",
            "Epoch 230/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0087 - accuracy: 0.6088 - val_loss: 0.9828 - val_accuracy: 0.6522\n",
            "Epoch 231/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.0099 - accuracy: 0.5871 - val_loss: 1.0109 - val_accuracy: 0.6425\n",
            "Epoch 232/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0022 - accuracy: 0.5943 - val_loss: 0.9754 - val_accuracy: 0.6618\n",
            "Epoch 233/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9881 - accuracy: 0.6276 - val_loss: 0.9673 - val_accuracy: 0.6763\n",
            "Epoch 234/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9951 - accuracy: 0.6052 - val_loss: 0.9773 - val_accuracy: 0.6280\n",
            "Epoch 235/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0035 - accuracy: 0.5961 - val_loss: 0.9902 - val_accuracy: 0.6329\n",
            "Epoch 236/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9964 - accuracy: 0.6028 - val_loss: 0.9955 - val_accuracy: 0.6425\n",
            "Epoch 237/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.9833 - accuracy: 0.6137 - val_loss: 0.9658 - val_accuracy: 0.6570\n",
            "Epoch 238/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.0086 - accuracy: 0.6064 - val_loss: 0.9772 - val_accuracy: 0.6522\n",
            "Epoch 239/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.9964 - accuracy: 0.5979 - val_loss: 0.9655 - val_accuracy: 0.6667\n",
            "Epoch 240/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.9849 - accuracy: 0.6058 - val_loss: 0.9728 - val_accuracy: 0.6763\n",
            "Epoch 241/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9986 - accuracy: 0.5877 - val_loss: 0.9648 - val_accuracy: 0.6860\n",
            "Epoch 242/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0113 - accuracy: 0.5931 - val_loss: 0.9810 - val_accuracy: 0.6763\n",
            "Epoch 243/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.9874 - accuracy: 0.6064 - val_loss: 0.9745 - val_accuracy: 0.6522\n",
            "Epoch 244/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.9740 - accuracy: 0.6209 - val_loss: 0.9704 - val_accuracy: 0.6522\n",
            "Epoch 245/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.9652 - accuracy: 0.6131 - val_loss: 0.9493 - val_accuracy: 0.6715\n",
            "Epoch 246/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9744 - accuracy: 0.6119 - val_loss: 0.9670 - val_accuracy: 0.6473\n",
            "Epoch 247/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9882 - accuracy: 0.6137 - val_loss: 0.9697 - val_accuracy: 0.6522\n",
            "Epoch 248/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.9842 - accuracy: 0.6058 - val_loss: 0.9629 - val_accuracy: 0.6329\n",
            "Epoch 249/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9521 - accuracy: 0.6215 - val_loss: 0.9456 - val_accuracy: 0.6715\n",
            "Epoch 250/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.9793 - accuracy: 0.6191 - val_loss: 0.9436 - val_accuracy: 0.6763\n",
            "Epoch 251/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9770 - accuracy: 0.6046 - val_loss: 0.9621 - val_accuracy: 0.6715\n",
            "Epoch 252/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9610 - accuracy: 0.6149 - val_loss: 0.9632 - val_accuracy: 0.6715\n",
            "Epoch 253/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.9607 - accuracy: 0.6221 - val_loss: 0.9581 - val_accuracy: 0.6329\n",
            "Epoch 254/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9598 - accuracy: 0.6179 - val_loss: 0.9495 - val_accuracy: 0.6522\n",
            "Epoch 255/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9541 - accuracy: 0.6191 - val_loss: 0.9403 - val_accuracy: 0.6522\n",
            "Epoch 256/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9552 - accuracy: 0.6360 - val_loss: 0.9542 - val_accuracy: 0.6522\n",
            "Epoch 257/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9706 - accuracy: 0.6173 - val_loss: 0.9470 - val_accuracy: 0.6812\n",
            "Epoch 258/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9546 - accuracy: 0.6227 - val_loss: 0.9531 - val_accuracy: 0.6280\n",
            "Epoch 259/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9461 - accuracy: 0.6276 - val_loss: 0.9505 - val_accuracy: 0.6473\n",
            "Epoch 260/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9405 - accuracy: 0.6288 - val_loss: 0.9460 - val_accuracy: 0.6473\n",
            "Epoch 261/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9370 - accuracy: 0.6324 - val_loss: 0.9190 - val_accuracy: 0.6667\n",
            "Epoch 262/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9514 - accuracy: 0.6239 - val_loss: 0.9256 - val_accuracy: 0.6908\n",
            "Epoch 263/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9437 - accuracy: 0.6312 - val_loss: 0.9365 - val_accuracy: 0.6763\n",
            "Epoch 264/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9562 - accuracy: 0.6137 - val_loss: 0.9277 - val_accuracy: 0.6763\n",
            "Epoch 265/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9330 - accuracy: 0.6276 - val_loss: 0.9272 - val_accuracy: 0.6667\n",
            "Epoch 266/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9365 - accuracy: 0.6318 - val_loss: 0.9271 - val_accuracy: 0.6522\n",
            "Epoch 267/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9413 - accuracy: 0.6227 - val_loss: 0.9202 - val_accuracy: 0.6763\n",
            "Epoch 268/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9407 - accuracy: 0.6324 - val_loss: 0.9375 - val_accuracy: 0.6522\n",
            "Epoch 269/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9318 - accuracy: 0.6276 - val_loss: 0.9317 - val_accuracy: 0.6473\n",
            "Epoch 270/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9294 - accuracy: 0.6366 - val_loss: 0.9225 - val_accuracy: 0.6957\n",
            "Epoch 271/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9388 - accuracy: 0.6239 - val_loss: 0.9366 - val_accuracy: 0.6377\n",
            "Epoch 272/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9302 - accuracy: 0.6252 - val_loss: 0.9314 - val_accuracy: 0.6570\n",
            "Epoch 273/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9146 - accuracy: 0.6433 - val_loss: 0.9260 - val_accuracy: 0.6473\n",
            "Epoch 274/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9208 - accuracy: 0.6518 - val_loss: 0.9216 - val_accuracy: 0.6570\n",
            "Epoch 275/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9152 - accuracy: 0.6312 - val_loss: 0.9234 - val_accuracy: 0.6570\n",
            "Epoch 276/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9134 - accuracy: 0.6421 - val_loss: 0.9208 - val_accuracy: 0.6570\n",
            "Epoch 277/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9316 - accuracy: 0.6221 - val_loss: 0.9324 - val_accuracy: 0.6377\n",
            "Epoch 278/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9299 - accuracy: 0.6294 - val_loss: 0.9324 - val_accuracy: 0.6473\n",
            "Epoch 279/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9164 - accuracy: 0.6360 - val_loss: 0.9494 - val_accuracy: 0.6618\n",
            "Epoch 280/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9174 - accuracy: 0.6300 - val_loss: 0.9223 - val_accuracy: 0.6812\n",
            "Epoch 281/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9307 - accuracy: 0.6433 - val_loss: 0.9272 - val_accuracy: 0.6618\n",
            "Epoch 282/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9014 - accuracy: 0.6530 - val_loss: 0.9060 - val_accuracy: 0.6908\n",
            "Epoch 283/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9169 - accuracy: 0.6245 - val_loss: 0.9104 - val_accuracy: 0.6715\n",
            "Epoch 284/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8949 - accuracy: 0.6487 - val_loss: 0.9123 - val_accuracy: 0.6763\n",
            "Epoch 285/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8961 - accuracy: 0.6439 - val_loss: 0.9123 - val_accuracy: 0.6715\n",
            "Epoch 286/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9038 - accuracy: 0.6530 - val_loss: 0.9127 - val_accuracy: 0.6763\n",
            "Epoch 287/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9024 - accuracy: 0.6505 - val_loss: 0.9221 - val_accuracy: 0.6570\n",
            "Epoch 288/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9099 - accuracy: 0.6493 - val_loss: 0.9112 - val_accuracy: 0.6715\n",
            "Epoch 289/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8942 - accuracy: 0.6385 - val_loss: 0.9179 - val_accuracy: 0.6570\n",
            "Epoch 290/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8987 - accuracy: 0.6421 - val_loss: 0.9127 - val_accuracy: 0.6522\n",
            "Epoch 291/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9049 - accuracy: 0.6336 - val_loss: 0.9201 - val_accuracy: 0.6522\n",
            "Epoch 292/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8926 - accuracy: 0.6481 - val_loss: 0.9151 - val_accuracy: 0.6715\n",
            "Epoch 293/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9020 - accuracy: 0.6372 - val_loss: 0.8910 - val_accuracy: 0.6812\n",
            "Epoch 294/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8780 - accuracy: 0.6578 - val_loss: 0.8938 - val_accuracy: 0.6715\n",
            "Epoch 295/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8894 - accuracy: 0.6445 - val_loss: 0.9003 - val_accuracy: 0.6473\n",
            "Epoch 296/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8881 - accuracy: 0.6457 - val_loss: 0.8872 - val_accuracy: 0.6715\n",
            "Epoch 297/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8961 - accuracy: 0.6385 - val_loss: 0.9016 - val_accuracy: 0.7150\n",
            "Epoch 298/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8868 - accuracy: 0.6578 - val_loss: 0.8980 - val_accuracy: 0.6715\n",
            "Epoch 299/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8767 - accuracy: 0.6584 - val_loss: 0.8862 - val_accuracy: 0.6667\n",
            "Epoch 300/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8797 - accuracy: 0.6451 - val_loss: 0.8904 - val_accuracy: 0.6667\n",
            "Epoch 301/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8602 - accuracy: 0.6530 - val_loss: 0.8887 - val_accuracy: 0.6908\n",
            "Epoch 302/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8847 - accuracy: 0.6397 - val_loss: 0.8886 - val_accuracy: 0.6812\n",
            "Epoch 303/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8915 - accuracy: 0.6463 - val_loss: 0.8819 - val_accuracy: 0.6715\n",
            "Epoch 304/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8702 - accuracy: 0.6475 - val_loss: 0.8930 - val_accuracy: 0.6812\n",
            "Epoch 305/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8651 - accuracy: 0.6693 - val_loss: 0.8818 - val_accuracy: 0.6860\n",
            "Epoch 306/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8730 - accuracy: 0.6542 - val_loss: 0.8816 - val_accuracy: 0.6957\n",
            "Epoch 307/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8784 - accuracy: 0.6560 - val_loss: 0.8781 - val_accuracy: 0.6812\n",
            "Epoch 308/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8773 - accuracy: 0.6548 - val_loss: 0.9039 - val_accuracy: 0.6618\n",
            "Epoch 309/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8763 - accuracy: 0.6511 - val_loss: 0.8970 - val_accuracy: 0.6667\n",
            "Epoch 310/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8715 - accuracy: 0.6518 - val_loss: 0.8829 - val_accuracy: 0.6957\n",
            "Epoch 311/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8706 - accuracy: 0.6536 - val_loss: 0.8957 - val_accuracy: 0.6425\n",
            "Epoch 312/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.8509 - accuracy: 0.6651 - val_loss: 0.8760 - val_accuracy: 0.6763\n",
            "Epoch 313/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8720 - accuracy: 0.6669 - val_loss: 0.8738 - val_accuracy: 0.6715\n",
            "Epoch 314/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8701 - accuracy: 0.6608 - val_loss: 0.8722 - val_accuracy: 0.6860\n",
            "Epoch 315/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8513 - accuracy: 0.6663 - val_loss: 0.8797 - val_accuracy: 0.7005\n",
            "Epoch 316/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8630 - accuracy: 0.6632 - val_loss: 0.8817 - val_accuracy: 0.6860\n",
            "Epoch 317/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8635 - accuracy: 0.6493 - val_loss: 0.8786 - val_accuracy: 0.6763\n",
            "Epoch 318/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8494 - accuracy: 0.6530 - val_loss: 0.8799 - val_accuracy: 0.6715\n",
            "Epoch 319/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8485 - accuracy: 0.6729 - val_loss: 0.8930 - val_accuracy: 0.6425\n",
            "Epoch 320/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8430 - accuracy: 0.6747 - val_loss: 0.8684 - val_accuracy: 0.7101\n",
            "Epoch 321/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8682 - accuracy: 0.6572 - val_loss: 0.8755 - val_accuracy: 0.6957\n",
            "Epoch 322/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8488 - accuracy: 0.6681 - val_loss: 0.8913 - val_accuracy: 0.6280\n",
            "Epoch 323/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8416 - accuracy: 0.6723 - val_loss: 0.8722 - val_accuracy: 0.6763\n",
            "Epoch 324/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8214 - accuracy: 0.6723 - val_loss: 0.8681 - val_accuracy: 0.6715\n",
            "Epoch 325/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8408 - accuracy: 0.6675 - val_loss: 0.8653 - val_accuracy: 0.6957\n",
            "Epoch 326/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8283 - accuracy: 0.6735 - val_loss: 0.8580 - val_accuracy: 0.6908\n",
            "Epoch 327/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8335 - accuracy: 0.6669 - val_loss: 0.8891 - val_accuracy: 0.6618\n",
            "Epoch 328/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.8419 - accuracy: 0.6753 - val_loss: 0.8617 - val_accuracy: 0.7150\n",
            "Epoch 329/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.8346 - accuracy: 0.6771 - val_loss: 0.8642 - val_accuracy: 0.6860\n",
            "Epoch 330/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.8239 - accuracy: 0.6717 - val_loss: 0.8624 - val_accuracy: 0.6812\n",
            "Epoch 331/1000\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.8181 - accuracy: 0.6771 - val_loss: 0.8516 - val_accuracy: 0.7053\n",
            "Epoch 332/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.8435 - accuracy: 0.6681 - val_loss: 0.8686 - val_accuracy: 0.6957\n",
            "Epoch 333/1000\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.8281 - accuracy: 0.6753 - val_loss: 0.8522 - val_accuracy: 0.7198\n",
            "Epoch 334/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8434 - accuracy: 0.6735 - val_loss: 0.8801 - val_accuracy: 0.6763\n",
            "Epoch 335/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8295 - accuracy: 0.6784 - val_loss: 0.8602 - val_accuracy: 0.6957\n",
            "Epoch 336/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8313 - accuracy: 0.6723 - val_loss: 0.8701 - val_accuracy: 0.6908\n",
            "Epoch 337/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8293 - accuracy: 0.6844 - val_loss: 0.8653 - val_accuracy: 0.6715\n",
            "Epoch 338/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8274 - accuracy: 0.6784 - val_loss: 0.8852 - val_accuracy: 0.6570\n",
            "Epoch 339/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8137 - accuracy: 0.6784 - val_loss: 0.8657 - val_accuracy: 0.6715\n",
            "Epoch 340/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8210 - accuracy: 0.6784 - val_loss: 0.8573 - val_accuracy: 0.6957\n",
            "Epoch 341/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8040 - accuracy: 0.6838 - val_loss: 0.8555 - val_accuracy: 0.7053\n",
            "Epoch 342/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8128 - accuracy: 0.6826 - val_loss: 0.8583 - val_accuracy: 0.6860\n",
            "Epoch 343/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8069 - accuracy: 0.6796 - val_loss: 0.8604 - val_accuracy: 0.6715\n",
            "Epoch 344/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8203 - accuracy: 0.6729 - val_loss: 0.8741 - val_accuracy: 0.6570\n",
            "Epoch 345/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8065 - accuracy: 0.6856 - val_loss: 0.8604 - val_accuracy: 0.6812\n",
            "Epoch 346/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8085 - accuracy: 0.6765 - val_loss: 0.8588 - val_accuracy: 0.6715\n",
            "Epoch 347/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7995 - accuracy: 0.6868 - val_loss: 0.8808 - val_accuracy: 0.6522\n",
            "Epoch 348/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8018 - accuracy: 0.6778 - val_loss: 0.8398 - val_accuracy: 0.7053\n",
            "Epoch 349/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7974 - accuracy: 0.6802 - val_loss: 0.8377 - val_accuracy: 0.6860\n",
            "Epoch 350/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8008 - accuracy: 0.6886 - val_loss: 0.8565 - val_accuracy: 0.6763\n",
            "Epoch 351/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8023 - accuracy: 0.6814 - val_loss: 0.8492 - val_accuracy: 0.6715\n",
            "Epoch 352/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.8024 - accuracy: 0.6808 - val_loss: 0.8587 - val_accuracy: 0.6763\n",
            "Epoch 353/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7933 - accuracy: 0.6892 - val_loss: 0.8378 - val_accuracy: 0.6957\n",
            "Epoch 354/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7906 - accuracy: 0.6935 - val_loss: 0.8568 - val_accuracy: 0.6570\n",
            "Epoch 355/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7967 - accuracy: 0.6844 - val_loss: 0.8507 - val_accuracy: 0.6763\n",
            "Epoch 356/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7935 - accuracy: 0.6850 - val_loss: 0.8441 - val_accuracy: 0.7005\n",
            "Epoch 357/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8133 - accuracy: 0.6802 - val_loss: 0.8448 - val_accuracy: 0.6618\n",
            "Epoch 358/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8059 - accuracy: 0.6778 - val_loss: 0.8441 - val_accuracy: 0.7005\n",
            "Epoch 359/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7802 - accuracy: 0.6953 - val_loss: 0.8671 - val_accuracy: 0.6377\n",
            "Epoch 360/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8107 - accuracy: 0.6778 - val_loss: 0.8339 - val_accuracy: 0.6908\n",
            "Epoch 361/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7886 - accuracy: 0.6892 - val_loss: 0.8489 - val_accuracy: 0.6667\n",
            "Epoch 362/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7800 - accuracy: 0.6941 - val_loss: 0.8400 - val_accuracy: 0.7005\n",
            "Epoch 363/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8012 - accuracy: 0.6699 - val_loss: 0.8550 - val_accuracy: 0.6763\n",
            "Epoch 364/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7684 - accuracy: 0.6983 - val_loss: 0.8405 - val_accuracy: 0.6667\n",
            "Epoch 365/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7681 - accuracy: 0.6838 - val_loss: 0.8423 - val_accuracy: 0.6908\n",
            "Epoch 366/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7988 - accuracy: 0.6856 - val_loss: 0.8307 - val_accuracy: 0.7343\n",
            "Epoch 367/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7880 - accuracy: 0.6911 - val_loss: 0.8456 - val_accuracy: 0.6667\n",
            "Epoch 368/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7696 - accuracy: 0.7062 - val_loss: 0.8254 - val_accuracy: 0.7053\n",
            "Epoch 369/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7818 - accuracy: 0.6892 - val_loss: 0.8345 - val_accuracy: 0.6908\n",
            "Epoch 370/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7831 - accuracy: 0.6947 - val_loss: 0.8361 - val_accuracy: 0.6570\n",
            "Epoch 371/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7754 - accuracy: 0.6935 - val_loss: 0.8274 - val_accuracy: 0.6957\n",
            "Epoch 372/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7764 - accuracy: 0.6977 - val_loss: 0.8471 - val_accuracy: 0.6908\n",
            "Epoch 373/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7824 - accuracy: 0.6874 - val_loss: 0.8308 - val_accuracy: 0.6957\n",
            "Epoch 374/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7790 - accuracy: 0.6959 - val_loss: 0.8389 - val_accuracy: 0.6715\n",
            "Epoch 375/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7744 - accuracy: 0.6929 - val_loss: 0.8491 - val_accuracy: 0.6425\n",
            "Epoch 376/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7661 - accuracy: 0.6917 - val_loss: 0.8342 - val_accuracy: 0.6812\n",
            "Epoch 377/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7800 - accuracy: 0.6874 - val_loss: 0.8337 - val_accuracy: 0.7101\n",
            "Epoch 378/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7789 - accuracy: 0.6904 - val_loss: 0.8447 - val_accuracy: 0.7101\n",
            "Epoch 379/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7717 - accuracy: 0.6947 - val_loss: 0.8341 - val_accuracy: 0.6957\n",
            "Epoch 380/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7580 - accuracy: 0.7050 - val_loss: 0.8361 - val_accuracy: 0.6763\n",
            "Epoch 381/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7687 - accuracy: 0.6917 - val_loss: 0.8231 - val_accuracy: 0.7150\n",
            "Epoch 382/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7463 - accuracy: 0.7086 - val_loss: 0.8211 - val_accuracy: 0.7053\n",
            "Epoch 383/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7721 - accuracy: 0.7019 - val_loss: 0.8111 - val_accuracy: 0.7246\n",
            "Epoch 384/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7767 - accuracy: 0.6959 - val_loss: 0.8463 - val_accuracy: 0.6763\n",
            "Epoch 385/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7623 - accuracy: 0.6971 - val_loss: 0.8494 - val_accuracy: 0.6425\n",
            "Epoch 386/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7669 - accuracy: 0.7013 - val_loss: 0.8217 - val_accuracy: 0.6715\n",
            "Epoch 387/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7629 - accuracy: 0.6904 - val_loss: 0.8221 - val_accuracy: 0.6860\n",
            "Epoch 388/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7694 - accuracy: 0.7164 - val_loss: 0.8194 - val_accuracy: 0.7198\n",
            "Epoch 389/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7534 - accuracy: 0.7056 - val_loss: 0.8257 - val_accuracy: 0.6957\n",
            "Epoch 390/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7513 - accuracy: 0.7031 - val_loss: 0.8232 - val_accuracy: 0.6763\n",
            "Epoch 391/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7552 - accuracy: 0.7104 - val_loss: 0.8238 - val_accuracy: 0.6618\n",
            "Epoch 392/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7501 - accuracy: 0.6995 - val_loss: 0.8273 - val_accuracy: 0.6908\n",
            "Epoch 393/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7657 - accuracy: 0.7044 - val_loss: 0.8123 - val_accuracy: 0.7101\n",
            "Epoch 394/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7424 - accuracy: 0.6953 - val_loss: 0.8305 - val_accuracy: 0.6763\n",
            "Epoch 395/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7376 - accuracy: 0.7116 - val_loss: 0.8227 - val_accuracy: 0.6812\n",
            "Epoch 396/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7376 - accuracy: 0.7140 - val_loss: 0.8250 - val_accuracy: 0.6763\n",
            "Epoch 397/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7388 - accuracy: 0.7080 - val_loss: 0.8045 - val_accuracy: 0.7150\n",
            "Epoch 398/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7451 - accuracy: 0.7068 - val_loss: 0.8132 - val_accuracy: 0.7005\n",
            "Epoch 399/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7350 - accuracy: 0.7044 - val_loss: 0.8038 - val_accuracy: 0.7053\n",
            "Epoch 400/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7440 - accuracy: 0.7086 - val_loss: 0.8130 - val_accuracy: 0.7198\n",
            "Epoch 401/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7295 - accuracy: 0.7237 - val_loss: 0.8061 - val_accuracy: 0.7005\n",
            "Epoch 402/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7461 - accuracy: 0.7116 - val_loss: 0.8147 - val_accuracy: 0.6667\n",
            "Epoch 403/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7311 - accuracy: 0.7189 - val_loss: 0.8110 - val_accuracy: 0.6908\n",
            "Epoch 404/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7438 - accuracy: 0.7062 - val_loss: 0.8230 - val_accuracy: 0.6957\n",
            "Epoch 405/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7503 - accuracy: 0.7128 - val_loss: 0.8123 - val_accuracy: 0.7053\n",
            "Epoch 406/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7424 - accuracy: 0.7001 - val_loss: 0.8064 - val_accuracy: 0.7198\n",
            "Epoch 407/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7283 - accuracy: 0.7134 - val_loss: 0.8070 - val_accuracy: 0.7150\n",
            "Epoch 408/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7224 - accuracy: 0.7134 - val_loss: 0.8040 - val_accuracy: 0.7101\n",
            "Epoch 409/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7195 - accuracy: 0.7237 - val_loss: 0.8065 - val_accuracy: 0.6812\n",
            "Epoch 410/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7237 - accuracy: 0.7013 - val_loss: 0.7966 - val_accuracy: 0.6908\n",
            "Epoch 411/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7306 - accuracy: 0.7146 - val_loss: 0.8063 - val_accuracy: 0.7005\n",
            "Epoch 412/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7289 - accuracy: 0.7001 - val_loss: 0.7998 - val_accuracy: 0.7005\n",
            "Epoch 413/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7321 - accuracy: 0.7140 - val_loss: 0.7926 - val_accuracy: 0.7053\n",
            "Epoch 414/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7208 - accuracy: 0.7104 - val_loss: 0.8023 - val_accuracy: 0.6715\n",
            "Epoch 415/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7309 - accuracy: 0.6989 - val_loss: 0.7969 - val_accuracy: 0.7246\n",
            "Epoch 416/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7496 - accuracy: 0.7056 - val_loss: 0.8097 - val_accuracy: 0.6667\n",
            "Epoch 417/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6915 - accuracy: 0.7340 - val_loss: 0.8073 - val_accuracy: 0.6812\n",
            "Epoch 418/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7121 - accuracy: 0.7219 - val_loss: 0.8064 - val_accuracy: 0.7005\n",
            "Epoch 419/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7302 - accuracy: 0.7170 - val_loss: 0.8011 - val_accuracy: 0.7101\n",
            "Epoch 420/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7327 - accuracy: 0.7183 - val_loss: 0.8056 - val_accuracy: 0.6908\n",
            "Epoch 421/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6945 - accuracy: 0.7358 - val_loss: 0.7996 - val_accuracy: 0.6908\n",
            "Epoch 422/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7103 - accuracy: 0.7207 - val_loss: 0.8040 - val_accuracy: 0.7053\n",
            "Epoch 423/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6956 - accuracy: 0.7237 - val_loss: 0.7861 - val_accuracy: 0.7150\n",
            "Epoch 424/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7010 - accuracy: 0.7219 - val_loss: 0.7952 - val_accuracy: 0.6860\n",
            "Epoch 425/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7116 - accuracy: 0.7382 - val_loss: 0.8058 - val_accuracy: 0.6812\n",
            "Epoch 426/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6945 - accuracy: 0.7219 - val_loss: 0.8039 - val_accuracy: 0.6957\n",
            "Epoch 427/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7043 - accuracy: 0.7261 - val_loss: 0.7904 - val_accuracy: 0.7150\n",
            "Epoch 428/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7092 - accuracy: 0.7243 - val_loss: 0.8003 - val_accuracy: 0.6763\n",
            "Epoch 429/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6921 - accuracy: 0.7310 - val_loss: 0.7924 - val_accuracy: 0.7005\n",
            "Epoch 430/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7041 - accuracy: 0.7243 - val_loss: 0.7876 - val_accuracy: 0.7005\n",
            "Epoch 431/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7205 - accuracy: 0.7267 - val_loss: 0.7972 - val_accuracy: 0.6957\n",
            "Epoch 432/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6954 - accuracy: 0.7291 - val_loss: 0.7911 - val_accuracy: 0.6957\n",
            "Epoch 433/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7122 - accuracy: 0.7158 - val_loss: 0.7847 - val_accuracy: 0.7150\n",
            "Epoch 434/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6931 - accuracy: 0.7158 - val_loss: 0.7735 - val_accuracy: 0.7101\n",
            "Epoch 435/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6896 - accuracy: 0.7152 - val_loss: 0.7796 - val_accuracy: 0.7053\n",
            "Epoch 436/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6950 - accuracy: 0.7213 - val_loss: 0.7830 - val_accuracy: 0.7150\n",
            "Epoch 437/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7008 - accuracy: 0.7279 - val_loss: 0.7850 - val_accuracy: 0.6957\n",
            "Epoch 438/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6891 - accuracy: 0.7237 - val_loss: 0.7873 - val_accuracy: 0.6957\n",
            "Epoch 439/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6905 - accuracy: 0.7310 - val_loss: 0.7958 - val_accuracy: 0.6860\n",
            "Epoch 440/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6749 - accuracy: 0.7376 - val_loss: 0.7785 - val_accuracy: 0.7150\n",
            "Epoch 441/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7018 - accuracy: 0.7128 - val_loss: 0.7949 - val_accuracy: 0.6812\n",
            "Epoch 442/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7027 - accuracy: 0.7237 - val_loss: 0.7847 - val_accuracy: 0.6957\n",
            "Epoch 443/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6970 - accuracy: 0.7261 - val_loss: 0.7857 - val_accuracy: 0.6812\n",
            "Epoch 444/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6875 - accuracy: 0.7267 - val_loss: 0.7717 - val_accuracy: 0.7053\n",
            "Epoch 445/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6883 - accuracy: 0.7322 - val_loss: 0.7737 - val_accuracy: 0.6957\n",
            "Epoch 446/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6826 - accuracy: 0.7219 - val_loss: 0.7797 - val_accuracy: 0.7198\n",
            "Epoch 447/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6964 - accuracy: 0.7310 - val_loss: 0.7844 - val_accuracy: 0.6957\n",
            "Epoch 448/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6769 - accuracy: 0.7370 - val_loss: 0.7976 - val_accuracy: 0.6763\n",
            "Epoch 449/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6709 - accuracy: 0.7370 - val_loss: 0.8001 - val_accuracy: 0.6715\n",
            "Epoch 450/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6759 - accuracy: 0.7461 - val_loss: 0.7865 - val_accuracy: 0.6908\n",
            "Epoch 451/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6826 - accuracy: 0.7279 - val_loss: 0.7770 - val_accuracy: 0.6957\n",
            "Epoch 452/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6808 - accuracy: 0.7255 - val_loss: 0.7827 - val_accuracy: 0.6812\n",
            "Epoch 453/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6560 - accuracy: 0.7491 - val_loss: 0.7775 - val_accuracy: 0.6957\n",
            "Epoch 454/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6780 - accuracy: 0.7291 - val_loss: 0.7806 - val_accuracy: 0.7053\n",
            "Epoch 455/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6743 - accuracy: 0.7346 - val_loss: 0.7709 - val_accuracy: 0.7101\n",
            "Epoch 456/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6587 - accuracy: 0.7455 - val_loss: 0.7842 - val_accuracy: 0.6763\n",
            "Epoch 457/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6695 - accuracy: 0.7394 - val_loss: 0.7763 - val_accuracy: 0.6957\n",
            "Epoch 458/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6553 - accuracy: 0.7382 - val_loss: 0.7787 - val_accuracy: 0.6908\n",
            "Epoch 459/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6631 - accuracy: 0.7485 - val_loss: 0.7745 - val_accuracy: 0.7198\n",
            "Epoch 460/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6791 - accuracy: 0.7328 - val_loss: 0.7711 - val_accuracy: 0.6908\n",
            "Epoch 461/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6749 - accuracy: 0.7340 - val_loss: 0.7662 - val_accuracy: 0.7053\n",
            "Epoch 462/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6673 - accuracy: 0.7370 - val_loss: 0.7780 - val_accuracy: 0.6860\n",
            "Epoch 463/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6476 - accuracy: 0.7449 - val_loss: 0.7762 - val_accuracy: 0.7150\n",
            "Epoch 464/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6864 - accuracy: 0.7310 - val_loss: 0.7802 - val_accuracy: 0.6715\n",
            "Epoch 465/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6459 - accuracy: 0.7400 - val_loss: 0.7772 - val_accuracy: 0.6860\n",
            "Epoch 466/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6688 - accuracy: 0.7430 - val_loss: 0.7884 - val_accuracy: 0.6812\n",
            "Epoch 467/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6663 - accuracy: 0.7485 - val_loss: 0.7952 - val_accuracy: 0.6908\n",
            "Epoch 468/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6518 - accuracy: 0.7521 - val_loss: 0.7920 - val_accuracy: 0.6377\n",
            "Epoch 469/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6447 - accuracy: 0.7418 - val_loss: 0.7917 - val_accuracy: 0.6522\n",
            "Epoch 470/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6690 - accuracy: 0.7352 - val_loss: 0.7833 - val_accuracy: 0.6715\n",
            "Epoch 471/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6569 - accuracy: 0.7388 - val_loss: 0.7725 - val_accuracy: 0.6667\n",
            "Epoch 472/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6561 - accuracy: 0.7449 - val_loss: 0.7615 - val_accuracy: 0.6812\n",
            "Epoch 473/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6360 - accuracy: 0.7467 - val_loss: 0.7796 - val_accuracy: 0.6763\n",
            "Epoch 474/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6272 - accuracy: 0.7515 - val_loss: 0.7693 - val_accuracy: 0.6812\n",
            "Epoch 475/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6523 - accuracy: 0.7394 - val_loss: 0.7647 - val_accuracy: 0.7150\n",
            "Epoch 476/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6788 - accuracy: 0.7267 - val_loss: 0.7789 - val_accuracy: 0.6860\n",
            "Epoch 477/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6342 - accuracy: 0.7557 - val_loss: 0.7848 - val_accuracy: 0.6763\n",
            "Epoch 478/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6423 - accuracy: 0.7491 - val_loss: 0.7648 - val_accuracy: 0.6812\n",
            "Epoch 479/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6658 - accuracy: 0.7437 - val_loss: 0.7602 - val_accuracy: 0.7005\n",
            "Epoch 480/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6594 - accuracy: 0.7394 - val_loss: 0.7632 - val_accuracy: 0.7101\n",
            "Epoch 481/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6227 - accuracy: 0.7527 - val_loss: 0.7672 - val_accuracy: 0.6812\n",
            "Epoch 482/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6485 - accuracy: 0.7576 - val_loss: 0.7583 - val_accuracy: 0.7005\n",
            "Epoch 483/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6350 - accuracy: 0.7521 - val_loss: 0.7834 - val_accuracy: 0.6860\n",
            "Epoch 484/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6488 - accuracy: 0.7443 - val_loss: 0.7752 - val_accuracy: 0.6860\n",
            "Epoch 485/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6359 - accuracy: 0.7461 - val_loss: 0.7585 - val_accuracy: 0.7053\n",
            "Epoch 486/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6332 - accuracy: 0.7473 - val_loss: 0.7662 - val_accuracy: 0.7005\n",
            "Epoch 487/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6107 - accuracy: 0.7690 - val_loss: 0.7870 - val_accuracy: 0.6763\n",
            "Epoch 488/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6505 - accuracy: 0.7479 - val_loss: 0.7780 - val_accuracy: 0.6908\n",
            "Epoch 489/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6351 - accuracy: 0.7521 - val_loss: 0.7762 - val_accuracy: 0.7005\n",
            "Epoch 490/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6336 - accuracy: 0.7461 - val_loss: 0.7630 - val_accuracy: 0.6908\n",
            "Epoch 491/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6446 - accuracy: 0.7473 - val_loss: 0.7623 - val_accuracy: 0.6860\n",
            "Epoch 492/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6328 - accuracy: 0.7600 - val_loss: 0.7550 - val_accuracy: 0.7101\n",
            "Epoch 493/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6200 - accuracy: 0.7660 - val_loss: 0.7480 - val_accuracy: 0.7053\n",
            "Epoch 494/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6279 - accuracy: 0.7557 - val_loss: 0.7470 - val_accuracy: 0.7053\n",
            "Epoch 495/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6558 - accuracy: 0.7237 - val_loss: 0.7619 - val_accuracy: 0.6812\n",
            "Epoch 496/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6223 - accuracy: 0.7557 - val_loss: 0.7645 - val_accuracy: 0.6957\n",
            "Epoch 497/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6251 - accuracy: 0.7630 - val_loss: 0.7649 - val_accuracy: 0.7053\n",
            "Epoch 498/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5983 - accuracy: 0.7678 - val_loss: 0.7945 - val_accuracy: 0.6570\n",
            "Epoch 499/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6197 - accuracy: 0.7588 - val_loss: 0.7519 - val_accuracy: 0.6908\n",
            "Epoch 500/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6095 - accuracy: 0.7624 - val_loss: 0.7540 - val_accuracy: 0.7005\n",
            "Epoch 501/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6215 - accuracy: 0.7606 - val_loss: 0.7525 - val_accuracy: 0.7053\n",
            "Epoch 502/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6297 - accuracy: 0.7406 - val_loss: 0.7582 - val_accuracy: 0.7053\n",
            "Epoch 503/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6276 - accuracy: 0.7449 - val_loss: 0.7511 - val_accuracy: 0.7005\n",
            "Epoch 504/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6151 - accuracy: 0.7654 - val_loss: 0.7569 - val_accuracy: 0.7101\n",
            "Epoch 505/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6144 - accuracy: 0.7703 - val_loss: 0.7480 - val_accuracy: 0.7005\n",
            "Epoch 506/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6294 - accuracy: 0.7551 - val_loss: 0.7517 - val_accuracy: 0.6812\n",
            "Epoch 507/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6210 - accuracy: 0.7733 - val_loss: 0.7608 - val_accuracy: 0.7005\n",
            "Epoch 508/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6199 - accuracy: 0.7582 - val_loss: 0.7509 - val_accuracy: 0.6812\n",
            "Epoch 509/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6057 - accuracy: 0.7563 - val_loss: 0.7713 - val_accuracy: 0.6957\n",
            "Epoch 510/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6053 - accuracy: 0.7654 - val_loss: 0.7394 - val_accuracy: 0.7053\n",
            "Epoch 511/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5919 - accuracy: 0.7696 - val_loss: 0.7342 - val_accuracy: 0.6957\n",
            "Epoch 512/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6020 - accuracy: 0.7666 - val_loss: 0.7817 - val_accuracy: 0.6570\n",
            "Epoch 513/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6065 - accuracy: 0.7576 - val_loss: 0.7436 - val_accuracy: 0.7101\n",
            "Epoch 514/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6009 - accuracy: 0.7769 - val_loss: 0.7458 - val_accuracy: 0.7005\n",
            "Epoch 515/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.5923 - accuracy: 0.7709 - val_loss: 0.7467 - val_accuracy: 0.7198\n",
            "Epoch 516/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6242 - accuracy: 0.7630 - val_loss: 0.7513 - val_accuracy: 0.7005\n",
            "Epoch 517/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6212 - accuracy: 0.7563 - val_loss: 0.7408 - val_accuracy: 0.7053\n",
            "Epoch 518/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6116 - accuracy: 0.7678 - val_loss: 0.7388 - val_accuracy: 0.6957\n",
            "Epoch 519/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6163 - accuracy: 0.7588 - val_loss: 0.7381 - val_accuracy: 0.6957\n",
            "Epoch 520/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5912 - accuracy: 0.7757 - val_loss: 0.7426 - val_accuracy: 0.7053\n",
            "Epoch 521/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5976 - accuracy: 0.7727 - val_loss: 0.7536 - val_accuracy: 0.6860\n",
            "Epoch 522/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6068 - accuracy: 0.7709 - val_loss: 0.7413 - val_accuracy: 0.7150\n",
            "Epoch 523/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5813 - accuracy: 0.7739 - val_loss: 0.7415 - val_accuracy: 0.7005\n",
            "Epoch 524/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.5794 - accuracy: 0.7836 - val_loss: 0.7418 - val_accuracy: 0.7053\n",
            "Epoch 525/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5970 - accuracy: 0.7672 - val_loss: 0.7267 - val_accuracy: 0.6957\n",
            "Epoch 526/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5975 - accuracy: 0.7588 - val_loss: 0.7516 - val_accuracy: 0.6957\n",
            "Epoch 527/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5915 - accuracy: 0.7781 - val_loss: 0.7278 - val_accuracy: 0.7198\n",
            "Epoch 528/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5891 - accuracy: 0.7678 - val_loss: 0.7434 - val_accuracy: 0.7053\n",
            "Epoch 529/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5905 - accuracy: 0.7775 - val_loss: 0.7283 - val_accuracy: 0.6957\n",
            "Epoch 530/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6032 - accuracy: 0.7775 - val_loss: 0.7468 - val_accuracy: 0.6860\n",
            "Epoch 531/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6086 - accuracy: 0.7642 - val_loss: 0.7424 - val_accuracy: 0.6812\n",
            "Epoch 532/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5969 - accuracy: 0.7582 - val_loss: 0.7350 - val_accuracy: 0.6908\n",
            "Epoch 533/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6022 - accuracy: 0.7606 - val_loss: 0.7451 - val_accuracy: 0.6957\n",
            "Epoch 534/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5790 - accuracy: 0.7817 - val_loss: 0.7535 - val_accuracy: 0.7053\n",
            "Epoch 535/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5702 - accuracy: 0.7793 - val_loss: 0.7374 - val_accuracy: 0.7198\n",
            "Epoch 536/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6008 - accuracy: 0.7594 - val_loss: 0.7537 - val_accuracy: 0.7053\n",
            "Epoch 537/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5814 - accuracy: 0.7721 - val_loss: 0.7613 - val_accuracy: 0.6570\n",
            "Epoch 538/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5805 - accuracy: 0.7654 - val_loss: 0.7363 - val_accuracy: 0.7101\n",
            "Epoch 539/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5783 - accuracy: 0.7727 - val_loss: 0.7238 - val_accuracy: 0.7101\n",
            "Epoch 540/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5705 - accuracy: 0.7811 - val_loss: 0.7329 - val_accuracy: 0.7005\n",
            "Epoch 541/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5905 - accuracy: 0.7672 - val_loss: 0.7284 - val_accuracy: 0.7005\n",
            "Epoch 542/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5937 - accuracy: 0.7630 - val_loss: 0.7473 - val_accuracy: 0.6763\n",
            "Epoch 543/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5708 - accuracy: 0.7830 - val_loss: 0.7323 - val_accuracy: 0.7101\n",
            "Epoch 544/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5815 - accuracy: 0.7624 - val_loss: 0.7337 - val_accuracy: 0.6908\n",
            "Epoch 545/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5870 - accuracy: 0.7769 - val_loss: 0.7239 - val_accuracy: 0.7198\n",
            "Epoch 546/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5689 - accuracy: 0.7733 - val_loss: 0.7277 - val_accuracy: 0.7198\n",
            "Epoch 547/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5699 - accuracy: 0.7787 - val_loss: 0.7263 - val_accuracy: 0.7150\n",
            "Epoch 548/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5712 - accuracy: 0.7775 - val_loss: 0.7297 - val_accuracy: 0.7150\n",
            "Epoch 549/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5687 - accuracy: 0.7830 - val_loss: 0.7249 - val_accuracy: 0.7295\n",
            "Epoch 550/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5730 - accuracy: 0.7830 - val_loss: 0.7552 - val_accuracy: 0.7101\n",
            "Epoch 551/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5759 - accuracy: 0.7787 - val_loss: 0.7382 - val_accuracy: 0.7005\n",
            "Epoch 552/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5665 - accuracy: 0.7751 - val_loss: 0.7218 - val_accuracy: 0.7295\n",
            "Epoch 553/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5602 - accuracy: 0.7817 - val_loss: 0.7564 - val_accuracy: 0.6860\n",
            "Epoch 554/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5845 - accuracy: 0.7576 - val_loss: 0.7342 - val_accuracy: 0.7198\n",
            "Epoch 555/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5679 - accuracy: 0.7751 - val_loss: 0.7432 - val_accuracy: 0.7295\n",
            "Epoch 556/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5686 - accuracy: 0.7890 - val_loss: 0.7517 - val_accuracy: 0.6957\n",
            "Epoch 557/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5681 - accuracy: 0.7763 - val_loss: 0.7379 - val_accuracy: 0.7053\n",
            "Epoch 558/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5647 - accuracy: 0.7787 - val_loss: 0.7355 - val_accuracy: 0.7101\n",
            "Epoch 559/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5563 - accuracy: 0.7830 - val_loss: 0.7573 - val_accuracy: 0.7005\n",
            "Epoch 560/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5594 - accuracy: 0.7842 - val_loss: 0.7406 - val_accuracy: 0.7101\n",
            "Epoch 561/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5596 - accuracy: 0.7660 - val_loss: 0.7288 - val_accuracy: 0.7198\n",
            "Epoch 562/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5446 - accuracy: 0.7872 - val_loss: 0.7525 - val_accuracy: 0.7005\n",
            "Epoch 563/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5573 - accuracy: 0.7823 - val_loss: 0.7326 - val_accuracy: 0.7198\n",
            "Epoch 564/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5793 - accuracy: 0.7799 - val_loss: 0.7236 - val_accuracy: 0.7101\n",
            "Epoch 565/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.5573 - accuracy: 0.7836 - val_loss: 0.7277 - val_accuracy: 0.7053\n",
            "Epoch 566/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5699 - accuracy: 0.7823 - val_loss: 0.7288 - val_accuracy: 0.6957\n",
            "Epoch 567/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5609 - accuracy: 0.7751 - val_loss: 0.7152 - val_accuracy: 0.7246\n",
            "Epoch 568/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5692 - accuracy: 0.7781 - val_loss: 0.7211 - val_accuracy: 0.7150\n",
            "Epoch 569/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5438 - accuracy: 0.7896 - val_loss: 0.7173 - val_accuracy: 0.7150\n",
            "Epoch 570/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5513 - accuracy: 0.7805 - val_loss: 0.7165 - val_accuracy: 0.7246\n",
            "Epoch 571/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5079 - accuracy: 0.8017 - val_loss: 0.7254 - val_accuracy: 0.7150\n",
            "Epoch 572/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5586 - accuracy: 0.7811 - val_loss: 0.7209 - val_accuracy: 0.7101\n",
            "Epoch 573/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.5440 - accuracy: 0.7884 - val_loss: 0.7217 - val_accuracy: 0.7150\n",
            "Epoch 574/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5335 - accuracy: 0.7956 - val_loss: 0.7157 - val_accuracy: 0.7053\n",
            "Epoch 575/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5476 - accuracy: 0.7956 - val_loss: 0.7123 - val_accuracy: 0.7198\n",
            "Epoch 576/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5406 - accuracy: 0.7884 - val_loss: 0.7344 - val_accuracy: 0.7150\n",
            "Epoch 577/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5421 - accuracy: 0.7938 - val_loss: 0.7316 - val_accuracy: 0.7101\n",
            "Epoch 578/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5598 - accuracy: 0.7793 - val_loss: 0.7144 - val_accuracy: 0.7391\n",
            "Epoch 579/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.5591 - accuracy: 0.7872 - val_loss: 0.7132 - val_accuracy: 0.7246\n",
            "Epoch 580/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5426 - accuracy: 0.7884 - val_loss: 0.7119 - val_accuracy: 0.7198\n",
            "Epoch 581/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5485 - accuracy: 0.7926 - val_loss: 0.7263 - val_accuracy: 0.7005\n",
            "Epoch 582/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5388 - accuracy: 0.7890 - val_loss: 0.7225 - val_accuracy: 0.7150\n",
            "Epoch 583/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5326 - accuracy: 0.7890 - val_loss: 0.7216 - val_accuracy: 0.7053\n",
            "Epoch 584/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5232 - accuracy: 0.7987 - val_loss: 0.7236 - val_accuracy: 0.7053\n",
            "Epoch 585/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5039 - accuracy: 0.8192 - val_loss: 0.7139 - val_accuracy: 0.7053\n",
            "Epoch 586/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5425 - accuracy: 0.7902 - val_loss: 0.7029 - val_accuracy: 0.7101\n",
            "Epoch 587/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5563 - accuracy: 0.7830 - val_loss: 0.7268 - val_accuracy: 0.7005\n",
            "Epoch 588/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5314 - accuracy: 0.7963 - val_loss: 0.7173 - val_accuracy: 0.7295\n",
            "Epoch 589/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5159 - accuracy: 0.8114 - val_loss: 0.7064 - val_accuracy: 0.7246\n",
            "Epoch 590/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5293 - accuracy: 0.8053 - val_loss: 0.7299 - val_accuracy: 0.7053\n",
            "Epoch 591/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5424 - accuracy: 0.7763 - val_loss: 0.7156 - val_accuracy: 0.7053\n",
            "Epoch 592/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5342 - accuracy: 0.7878 - val_loss: 0.7127 - val_accuracy: 0.7246\n",
            "Epoch 593/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5412 - accuracy: 0.7926 - val_loss: 0.7241 - val_accuracy: 0.7246\n",
            "Epoch 594/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5375 - accuracy: 0.7854 - val_loss: 0.7233 - val_accuracy: 0.7246\n",
            "Epoch 595/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5346 - accuracy: 0.7938 - val_loss: 0.7342 - val_accuracy: 0.7101\n",
            "Epoch 596/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5116 - accuracy: 0.8096 - val_loss: 0.6966 - val_accuracy: 0.7488\n",
            "Epoch 597/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5170 - accuracy: 0.7993 - val_loss: 0.7267 - val_accuracy: 0.7150\n",
            "Epoch 598/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5153 - accuracy: 0.7944 - val_loss: 0.7139 - val_accuracy: 0.7053\n",
            "Epoch 599/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5350 - accuracy: 0.8011 - val_loss: 0.7076 - val_accuracy: 0.7295\n",
            "Epoch 600/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4934 - accuracy: 0.8114 - val_loss: 0.7031 - val_accuracy: 0.7246\n",
            "Epoch 601/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5253 - accuracy: 0.7987 - val_loss: 0.7099 - val_accuracy: 0.7343\n",
            "Epoch 602/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5198 - accuracy: 0.7969 - val_loss: 0.7187 - val_accuracy: 0.7246\n",
            "Epoch 603/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5125 - accuracy: 0.8035 - val_loss: 0.6888 - val_accuracy: 0.7488\n",
            "Epoch 604/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5112 - accuracy: 0.8047 - val_loss: 0.6997 - val_accuracy: 0.7295\n",
            "Epoch 605/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5136 - accuracy: 0.7932 - val_loss: 0.7187 - val_accuracy: 0.7246\n",
            "Epoch 606/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5346 - accuracy: 0.7914 - val_loss: 0.7266 - val_accuracy: 0.7053\n",
            "Epoch 607/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5189 - accuracy: 0.7926 - val_loss: 0.7061 - val_accuracy: 0.7295\n",
            "Epoch 608/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5096 - accuracy: 0.7981 - val_loss: 0.7129 - val_accuracy: 0.7053\n",
            "Epoch 609/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5054 - accuracy: 0.8096 - val_loss: 0.7108 - val_accuracy: 0.7198\n",
            "Epoch 610/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5225 - accuracy: 0.8041 - val_loss: 0.6906 - val_accuracy: 0.7391\n",
            "Epoch 611/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5132 - accuracy: 0.7963 - val_loss: 0.7016 - val_accuracy: 0.7391\n",
            "Epoch 612/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5259 - accuracy: 0.8089 - val_loss: 0.7083 - val_accuracy: 0.7246\n",
            "Epoch 613/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5056 - accuracy: 0.8065 - val_loss: 0.7060 - val_accuracy: 0.7246\n",
            "Epoch 614/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5140 - accuracy: 0.7920 - val_loss: 0.7145 - val_accuracy: 0.7005\n",
            "Epoch 615/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5120 - accuracy: 0.7969 - val_loss: 0.7033 - val_accuracy: 0.7295\n",
            "Epoch 616/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5161 - accuracy: 0.8120 - val_loss: 0.6867 - val_accuracy: 0.7391\n",
            "Epoch 617/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5155 - accuracy: 0.8035 - val_loss: 0.6962 - val_accuracy: 0.7488\n",
            "Epoch 618/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5033 - accuracy: 0.8005 - val_loss: 0.6887 - val_accuracy: 0.7198\n",
            "Epoch 619/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4914 - accuracy: 0.8083 - val_loss: 0.7006 - val_accuracy: 0.7391\n",
            "Epoch 620/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4886 - accuracy: 0.8229 - val_loss: 0.6912 - val_accuracy: 0.7391\n",
            "Epoch 621/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4868 - accuracy: 0.8138 - val_loss: 0.6949 - val_accuracy: 0.7440\n",
            "Epoch 622/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4966 - accuracy: 0.8162 - val_loss: 0.6858 - val_accuracy: 0.7391\n",
            "Epoch 623/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5075 - accuracy: 0.7926 - val_loss: 0.6978 - val_accuracy: 0.7198\n",
            "Epoch 624/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5107 - accuracy: 0.7914 - val_loss: 0.7022 - val_accuracy: 0.7246\n",
            "Epoch 625/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4983 - accuracy: 0.8035 - val_loss: 0.7015 - val_accuracy: 0.7343\n",
            "Epoch 626/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5128 - accuracy: 0.7999 - val_loss: 0.7249 - val_accuracy: 0.7101\n",
            "Epoch 627/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4893 - accuracy: 0.8083 - val_loss: 0.7219 - val_accuracy: 0.7150\n",
            "Epoch 628/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5037 - accuracy: 0.8108 - val_loss: 0.6991 - val_accuracy: 0.7246\n",
            "Epoch 629/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4884 - accuracy: 0.8210 - val_loss: 0.7078 - val_accuracy: 0.7150\n",
            "Epoch 630/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4850 - accuracy: 0.8132 - val_loss: 0.7169 - val_accuracy: 0.7391\n",
            "Epoch 631/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4883 - accuracy: 0.8017 - val_loss: 0.6992 - val_accuracy: 0.7198\n",
            "Epoch 632/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4869 - accuracy: 0.8089 - val_loss: 0.7011 - val_accuracy: 0.7295\n",
            "Epoch 633/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4853 - accuracy: 0.8138 - val_loss: 0.6860 - val_accuracy: 0.7150\n",
            "Epoch 634/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4868 - accuracy: 0.8071 - val_loss: 0.6989 - val_accuracy: 0.7101\n",
            "Epoch 635/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4887 - accuracy: 0.8174 - val_loss: 0.6989 - val_accuracy: 0.7295\n",
            "Epoch 636/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4950 - accuracy: 0.8210 - val_loss: 0.6959 - val_accuracy: 0.7295\n",
            "Epoch 637/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4975 - accuracy: 0.8071 - val_loss: 0.6994 - val_accuracy: 0.7343\n",
            "Epoch 638/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4648 - accuracy: 0.8186 - val_loss: 0.6812 - val_accuracy: 0.7246\n",
            "Epoch 639/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4995 - accuracy: 0.8035 - val_loss: 0.7089 - val_accuracy: 0.7295\n",
            "Epoch 640/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.4917 - accuracy: 0.8096 - val_loss: 0.7066 - val_accuracy: 0.7198\n",
            "Epoch 641/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.4868 - accuracy: 0.8059 - val_loss: 0.7178 - val_accuracy: 0.6957\n",
            "Epoch 642/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4811 - accuracy: 0.8108 - val_loss: 0.7041 - val_accuracy: 0.7246\n",
            "Epoch 643/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4825 - accuracy: 0.8210 - val_loss: 0.7004 - val_accuracy: 0.7343\n",
            "Epoch 644/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4567 - accuracy: 0.8289 - val_loss: 0.6964 - val_accuracy: 0.7198\n",
            "Epoch 645/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4793 - accuracy: 0.8192 - val_loss: 0.6955 - val_accuracy: 0.7343\n",
            "Epoch 646/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4704 - accuracy: 0.8168 - val_loss: 0.7068 - val_accuracy: 0.7198\n",
            "Epoch 647/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4707 - accuracy: 0.8180 - val_loss: 0.6911 - val_accuracy: 0.7343\n",
            "Epoch 648/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4949 - accuracy: 0.8144 - val_loss: 0.7015 - val_accuracy: 0.7391\n",
            "Epoch 649/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4728 - accuracy: 0.8204 - val_loss: 0.6897 - val_accuracy: 0.7391\n",
            "Epoch 650/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4808 - accuracy: 0.8108 - val_loss: 0.6944 - val_accuracy: 0.7391\n",
            "Epoch 651/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4851 - accuracy: 0.8083 - val_loss: 0.6934 - val_accuracy: 0.7391\n",
            "Epoch 652/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.4724 - accuracy: 0.8126 - val_loss: 0.7079 - val_accuracy: 0.7391\n",
            "Epoch 653/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4817 - accuracy: 0.8138 - val_loss: 0.7001 - val_accuracy: 0.7295\n",
            "Epoch 654/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4691 - accuracy: 0.8222 - val_loss: 0.6950 - val_accuracy: 0.7295\n",
            "Epoch 655/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4672 - accuracy: 0.8162 - val_loss: 0.6844 - val_accuracy: 0.7391\n",
            "Epoch 656/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.4805 - accuracy: 0.8144 - val_loss: 0.7400 - val_accuracy: 0.7005\n",
            "Epoch 657/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4600 - accuracy: 0.8289 - val_loss: 0.6950 - val_accuracy: 0.7246\n",
            "Epoch 658/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4643 - accuracy: 0.8325 - val_loss: 0.6879 - val_accuracy: 0.7343\n",
            "Epoch 659/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.4641 - accuracy: 0.8150 - val_loss: 0.6890 - val_accuracy: 0.7343\n",
            "Epoch 660/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4783 - accuracy: 0.8180 - val_loss: 0.6788 - val_accuracy: 0.7343\n",
            "Epoch 661/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4645 - accuracy: 0.8174 - val_loss: 0.6842 - val_accuracy: 0.7343\n",
            "Epoch 662/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4827 - accuracy: 0.8253 - val_loss: 0.6874 - val_accuracy: 0.7295\n",
            "Epoch 663/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4501 - accuracy: 0.8277 - val_loss: 0.6785 - val_accuracy: 0.7295\n",
            "Epoch 664/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4809 - accuracy: 0.8210 - val_loss: 0.6677 - val_accuracy: 0.7488\n",
            "Epoch 665/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4679 - accuracy: 0.8198 - val_loss: 0.6927 - val_accuracy: 0.7343\n",
            "Epoch 666/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4488 - accuracy: 0.8289 - val_loss: 0.6786 - val_accuracy: 0.7488\n",
            "Epoch 667/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4768 - accuracy: 0.8089 - val_loss: 0.6790 - val_accuracy: 0.7295\n",
            "Epoch 668/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4643 - accuracy: 0.8241 - val_loss: 0.6887 - val_accuracy: 0.7198\n",
            "Epoch 669/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4518 - accuracy: 0.8198 - val_loss: 0.6889 - val_accuracy: 0.7295\n",
            "Epoch 670/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4456 - accuracy: 0.8325 - val_loss: 0.6855 - val_accuracy: 0.7246\n",
            "Epoch 671/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4753 - accuracy: 0.8077 - val_loss: 0.6894 - val_accuracy: 0.7343\n",
            "Epoch 672/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4582 - accuracy: 0.8180 - val_loss: 0.6990 - val_accuracy: 0.7150\n",
            "Epoch 673/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4413 - accuracy: 0.8392 - val_loss: 0.7088 - val_accuracy: 0.7198\n",
            "Epoch 674/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4448 - accuracy: 0.8301 - val_loss: 0.6850 - val_accuracy: 0.7343\n",
            "Epoch 675/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4598 - accuracy: 0.8192 - val_loss: 0.6836 - val_accuracy: 0.7391\n",
            "Epoch 676/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4646 - accuracy: 0.8229 - val_loss: 0.6663 - val_accuracy: 0.7343\n",
            "Epoch 677/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4558 - accuracy: 0.8277 - val_loss: 0.6829 - val_accuracy: 0.7246\n",
            "Epoch 678/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4559 - accuracy: 0.8446 - val_loss: 0.6930 - val_accuracy: 0.7440\n",
            "Epoch 679/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4542 - accuracy: 0.8271 - val_loss: 0.6817 - val_accuracy: 0.7343\n",
            "Epoch 680/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4505 - accuracy: 0.8186 - val_loss: 0.6934 - val_accuracy: 0.7246\n",
            "Epoch 681/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4546 - accuracy: 0.8216 - val_loss: 0.6856 - val_accuracy: 0.7295\n",
            "Epoch 682/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4606 - accuracy: 0.8204 - val_loss: 0.6825 - val_accuracy: 0.7391\n",
            "Epoch 683/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4725 - accuracy: 0.8222 - val_loss: 0.6888 - val_accuracy: 0.7198\n",
            "Epoch 684/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4572 - accuracy: 0.8319 - val_loss: 0.6852 - val_accuracy: 0.7343\n",
            "Epoch 685/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.4658 - accuracy: 0.8313 - val_loss: 0.6873 - val_accuracy: 0.7391\n",
            "Epoch 686/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4436 - accuracy: 0.8301 - val_loss: 0.6787 - val_accuracy: 0.7729\n",
            "Epoch 687/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.4699 - accuracy: 0.8174 - val_loss: 0.6953 - val_accuracy: 0.7343\n",
            "Epoch 688/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4388 - accuracy: 0.8289 - val_loss: 0.6841 - val_accuracy: 0.7198\n",
            "Epoch 689/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4336 - accuracy: 0.8271 - val_loss: 0.6676 - val_accuracy: 0.7585\n",
            "Epoch 690/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4510 - accuracy: 0.8277 - val_loss: 0.6995 - val_accuracy: 0.7101\n",
            "Epoch 691/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4521 - accuracy: 0.8210 - val_loss: 0.6791 - val_accuracy: 0.7391\n",
            "Epoch 692/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.4038 - accuracy: 0.8531 - val_loss: 0.6807 - val_accuracy: 0.7246\n",
            "Epoch 693/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4403 - accuracy: 0.8398 - val_loss: 0.6732 - val_accuracy: 0.7536\n",
            "Epoch 694/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4610 - accuracy: 0.8295 - val_loss: 0.7064 - val_accuracy: 0.7246\n",
            "Epoch 695/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4312 - accuracy: 0.8331 - val_loss: 0.6742 - val_accuracy: 0.7391\n",
            "Epoch 696/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4549 - accuracy: 0.8241 - val_loss: 0.6757 - val_accuracy: 0.7295\n",
            "Epoch 697/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4428 - accuracy: 0.8368 - val_loss: 0.6698 - val_accuracy: 0.7488\n",
            "Epoch 698/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4429 - accuracy: 0.8307 - val_loss: 0.6736 - val_accuracy: 0.7440\n",
            "Epoch 699/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4482 - accuracy: 0.8356 - val_loss: 0.6582 - val_accuracy: 0.7633\n",
            "Epoch 700/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4261 - accuracy: 0.8422 - val_loss: 0.6716 - val_accuracy: 0.7440\n",
            "Epoch 701/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4569 - accuracy: 0.8241 - val_loss: 0.6722 - val_accuracy: 0.7585\n",
            "Epoch 702/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4475 - accuracy: 0.8253 - val_loss: 0.6752 - val_accuracy: 0.7295\n",
            "Epoch 703/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4137 - accuracy: 0.8482 - val_loss: 0.6524 - val_accuracy: 0.7585\n",
            "Epoch 704/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4647 - accuracy: 0.8156 - val_loss: 0.6761 - val_accuracy: 0.7391\n",
            "Epoch 705/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4298 - accuracy: 0.8319 - val_loss: 0.6809 - val_accuracy: 0.7295\n",
            "Epoch 706/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4222 - accuracy: 0.8380 - val_loss: 0.6615 - val_accuracy: 0.7681\n",
            "Epoch 707/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4349 - accuracy: 0.8392 - val_loss: 0.6754 - val_accuracy: 0.7343\n",
            "Epoch 708/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4314 - accuracy: 0.8319 - val_loss: 0.6649 - val_accuracy: 0.7440\n",
            "Epoch 709/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4351 - accuracy: 0.8356 - val_loss: 0.6818 - val_accuracy: 0.7488\n",
            "Epoch 710/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4310 - accuracy: 0.8380 - val_loss: 0.6728 - val_accuracy: 0.7391\n",
            "Epoch 711/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4315 - accuracy: 0.8374 - val_loss: 0.6746 - val_accuracy: 0.7391\n",
            "Epoch 712/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4533 - accuracy: 0.8192 - val_loss: 0.6602 - val_accuracy: 0.7536\n",
            "Epoch 713/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4244 - accuracy: 0.8434 - val_loss: 0.6614 - val_accuracy: 0.7488\n",
            "Epoch 714/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4297 - accuracy: 0.8331 - val_loss: 0.6571 - val_accuracy: 0.7536\n",
            "Epoch 715/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4314 - accuracy: 0.8404 - val_loss: 0.6655 - val_accuracy: 0.7488\n",
            "Epoch 716/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.4312 - accuracy: 0.8368 - val_loss: 0.6824 - val_accuracy: 0.7198\n",
            "Epoch 717/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4332 - accuracy: 0.8331 - val_loss: 0.6672 - val_accuracy: 0.7295\n",
            "Epoch 718/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4144 - accuracy: 0.8368 - val_loss: 0.6733 - val_accuracy: 0.7295\n",
            "Epoch 719/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4333 - accuracy: 0.8325 - val_loss: 0.6606 - val_accuracy: 0.7440\n",
            "Epoch 720/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4310 - accuracy: 0.8482 - val_loss: 0.6543 - val_accuracy: 0.7343\n",
            "Epoch 721/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4005 - accuracy: 0.8489 - val_loss: 0.6655 - val_accuracy: 0.7246\n",
            "Epoch 722/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4137 - accuracy: 0.8331 - val_loss: 0.6801 - val_accuracy: 0.7343\n",
            "Epoch 723/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4283 - accuracy: 0.8289 - val_loss: 0.6733 - val_accuracy: 0.7440\n",
            "Epoch 724/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4299 - accuracy: 0.8307 - val_loss: 0.6785 - val_accuracy: 0.7343\n",
            "Epoch 725/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4049 - accuracy: 0.8464 - val_loss: 0.6826 - val_accuracy: 0.7391\n",
            "Epoch 726/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4142 - accuracy: 0.8482 - val_loss: 0.6702 - val_accuracy: 0.7295\n",
            "Epoch 727/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4335 - accuracy: 0.8343 - val_loss: 0.6790 - val_accuracy: 0.7343\n",
            "Epoch 728/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4196 - accuracy: 0.8470 - val_loss: 0.6690 - val_accuracy: 0.7391\n",
            "Epoch 729/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4318 - accuracy: 0.8331 - val_loss: 0.6708 - val_accuracy: 0.7391\n",
            "Epoch 730/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.4165 - accuracy: 0.8362 - val_loss: 0.6706 - val_accuracy: 0.7246\n",
            "Epoch 731/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4043 - accuracy: 0.8446 - val_loss: 0.6896 - val_accuracy: 0.7391\n",
            "Epoch 732/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4209 - accuracy: 0.8446 - val_loss: 0.6674 - val_accuracy: 0.7536\n",
            "Epoch 733/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4224 - accuracy: 0.8404 - val_loss: 0.6827 - val_accuracy: 0.7488\n",
            "Epoch 734/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4213 - accuracy: 0.8404 - val_loss: 0.6642 - val_accuracy: 0.7440\n",
            "Epoch 735/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4070 - accuracy: 0.8476 - val_loss: 0.6743 - val_accuracy: 0.7488\n",
            "Epoch 736/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4113 - accuracy: 0.8452 - val_loss: 0.6695 - val_accuracy: 0.7488\n",
            "Epoch 737/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3963 - accuracy: 0.8507 - val_loss: 0.6601 - val_accuracy: 0.7585\n",
            "Epoch 738/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4144 - accuracy: 0.8446 - val_loss: 0.6683 - val_accuracy: 0.7681\n",
            "Epoch 739/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3991 - accuracy: 0.8597 - val_loss: 0.6602 - val_accuracy: 0.7681\n",
            "Epoch 740/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4127 - accuracy: 0.8428 - val_loss: 0.6624 - val_accuracy: 0.7778\n",
            "Epoch 741/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4044 - accuracy: 0.8501 - val_loss: 0.6684 - val_accuracy: 0.7536\n",
            "Epoch 742/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4093 - accuracy: 0.8446 - val_loss: 0.6547 - val_accuracy: 0.7585\n",
            "Epoch 743/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4075 - accuracy: 0.8537 - val_loss: 0.6526 - val_accuracy: 0.7585\n",
            "Epoch 744/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3876 - accuracy: 0.8470 - val_loss: 0.6659 - val_accuracy: 0.7585\n",
            "Epoch 745/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.4169 - accuracy: 0.8452 - val_loss: 0.6545 - val_accuracy: 0.7633\n",
            "Epoch 746/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4053 - accuracy: 0.8422 - val_loss: 0.6802 - val_accuracy: 0.7440\n",
            "Epoch 747/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4170 - accuracy: 0.8555 - val_loss: 0.6585 - val_accuracy: 0.7391\n",
            "Epoch 748/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4077 - accuracy: 0.8410 - val_loss: 0.6682 - val_accuracy: 0.7488\n",
            "Epoch 749/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4005 - accuracy: 0.8404 - val_loss: 0.6709 - val_accuracy: 0.7440\n",
            "Epoch 750/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3999 - accuracy: 0.8513 - val_loss: 0.6657 - val_accuracy: 0.7729\n",
            "Epoch 751/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4220 - accuracy: 0.8380 - val_loss: 0.6846 - val_accuracy: 0.7391\n",
            "Epoch 752/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4006 - accuracy: 0.8543 - val_loss: 0.6645 - val_accuracy: 0.7585\n",
            "Epoch 753/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3792 - accuracy: 0.8658 - val_loss: 0.6698 - val_accuracy: 0.7343\n",
            "Epoch 754/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3983 - accuracy: 0.8561 - val_loss: 0.6581 - val_accuracy: 0.7826\n",
            "Epoch 755/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4163 - accuracy: 0.8343 - val_loss: 0.6635 - val_accuracy: 0.7391\n",
            "Epoch 756/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3989 - accuracy: 0.8362 - val_loss: 0.6735 - val_accuracy: 0.7295\n",
            "Epoch 757/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4072 - accuracy: 0.8374 - val_loss: 0.6739 - val_accuracy: 0.7488\n",
            "Epoch 758/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4189 - accuracy: 0.8446 - val_loss: 0.6609 - val_accuracy: 0.7391\n",
            "Epoch 759/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3845 - accuracy: 0.8525 - val_loss: 0.6779 - val_accuracy: 0.7391\n",
            "Epoch 760/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3974 - accuracy: 0.8531 - val_loss: 0.6818 - val_accuracy: 0.7391\n",
            "Epoch 761/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4075 - accuracy: 0.8416 - val_loss: 0.6480 - val_accuracy: 0.7778\n",
            "Epoch 762/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3829 - accuracy: 0.8519 - val_loss: 0.6642 - val_accuracy: 0.7536\n",
            "Epoch 763/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3956 - accuracy: 0.8507 - val_loss: 0.6785 - val_accuracy: 0.7343\n",
            "Epoch 764/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3935 - accuracy: 0.8476 - val_loss: 0.6798 - val_accuracy: 0.7295\n",
            "Epoch 765/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3874 - accuracy: 0.8652 - val_loss: 0.6597 - val_accuracy: 0.7536\n",
            "Epoch 766/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.3853 - accuracy: 0.8555 - val_loss: 0.6672 - val_accuracy: 0.7343\n",
            "Epoch 767/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3904 - accuracy: 0.8573 - val_loss: 0.6620 - val_accuracy: 0.7488\n",
            "Epoch 768/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3846 - accuracy: 0.8537 - val_loss: 0.6817 - val_accuracy: 0.7246\n",
            "Epoch 769/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3955 - accuracy: 0.8458 - val_loss: 0.6826 - val_accuracy: 0.7440\n",
            "Epoch 770/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3861 - accuracy: 0.8555 - val_loss: 0.6633 - val_accuracy: 0.7343\n",
            "Epoch 771/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3841 - accuracy: 0.8543 - val_loss: 0.6560 - val_accuracy: 0.7536\n",
            "Epoch 772/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3770 - accuracy: 0.8567 - val_loss: 0.6694 - val_accuracy: 0.7295\n",
            "Epoch 773/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3812 - accuracy: 0.8573 - val_loss: 0.6660 - val_accuracy: 0.7391\n",
            "Epoch 774/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3756 - accuracy: 0.8470 - val_loss: 0.6559 - val_accuracy: 0.7585\n",
            "Epoch 775/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3727 - accuracy: 0.8543 - val_loss: 0.6631 - val_accuracy: 0.7729\n",
            "Epoch 776/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3809 - accuracy: 0.8615 - val_loss: 0.6541 - val_accuracy: 0.7440\n",
            "Epoch 777/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4134 - accuracy: 0.8374 - val_loss: 0.6675 - val_accuracy: 0.7391\n",
            "Epoch 778/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.3842 - accuracy: 0.8615 - val_loss: 0.6596 - val_accuracy: 0.7391\n",
            "Epoch 779/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3859 - accuracy: 0.8525 - val_loss: 0.6423 - val_accuracy: 0.7585\n",
            "Epoch 780/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3880 - accuracy: 0.8513 - val_loss: 0.6548 - val_accuracy: 0.7633\n",
            "Epoch 781/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3766 - accuracy: 0.8615 - val_loss: 0.6309 - val_accuracy: 0.7729\n",
            "Epoch 782/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3712 - accuracy: 0.8525 - val_loss: 0.6615 - val_accuracy: 0.7488\n",
            "Epoch 783/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3760 - accuracy: 0.8615 - val_loss: 0.6398 - val_accuracy: 0.7585\n",
            "Epoch 784/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3604 - accuracy: 0.8718 - val_loss: 0.6575 - val_accuracy: 0.7681\n",
            "Epoch 785/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.3857 - accuracy: 0.8489 - val_loss: 0.6517 - val_accuracy: 0.7633\n",
            "Epoch 786/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3829 - accuracy: 0.8567 - val_loss: 0.6444 - val_accuracy: 0.7585\n",
            "Epoch 787/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3760 - accuracy: 0.8603 - val_loss: 0.6466 - val_accuracy: 0.7633\n",
            "Epoch 788/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3857 - accuracy: 0.8489 - val_loss: 0.6720 - val_accuracy: 0.7440\n",
            "Epoch 789/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3657 - accuracy: 0.8652 - val_loss: 0.6498 - val_accuracy: 0.7585\n",
            "Epoch 790/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3739 - accuracy: 0.8561 - val_loss: 0.6725 - val_accuracy: 0.7391\n",
            "Epoch 791/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3474 - accuracy: 0.8797 - val_loss: 0.6383 - val_accuracy: 0.7826\n",
            "Epoch 792/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.3674 - accuracy: 0.8585 - val_loss: 0.6389 - val_accuracy: 0.7536\n",
            "Epoch 793/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3702 - accuracy: 0.8555 - val_loss: 0.6404 - val_accuracy: 0.7681\n",
            "Epoch 794/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3562 - accuracy: 0.8670 - val_loss: 0.6567 - val_accuracy: 0.7440\n",
            "Epoch 795/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.3578 - accuracy: 0.8682 - val_loss: 0.6594 - val_accuracy: 0.7440\n",
            "Epoch 796/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3626 - accuracy: 0.8634 - val_loss: 0.6507 - val_accuracy: 0.7681\n",
            "Epoch 797/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3697 - accuracy: 0.8640 - val_loss: 0.6549 - val_accuracy: 0.7343\n",
            "Epoch 798/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3810 - accuracy: 0.8549 - val_loss: 0.6222 - val_accuracy: 0.7729\n",
            "Epoch 799/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3532 - accuracy: 0.8646 - val_loss: 0.6356 - val_accuracy: 0.7778\n",
            "Epoch 800/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3575 - accuracy: 0.8658 - val_loss: 0.6398 - val_accuracy: 0.7585\n",
            "Epoch 801/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3636 - accuracy: 0.8579 - val_loss: 0.6462 - val_accuracy: 0.7536\n",
            "Epoch 802/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3723 - accuracy: 0.8555 - val_loss: 0.6460 - val_accuracy: 0.7681\n",
            "Epoch 803/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3569 - accuracy: 0.8640 - val_loss: 0.6587 - val_accuracy: 0.7585\n",
            "Epoch 804/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.3540 - accuracy: 0.8646 - val_loss: 0.6529 - val_accuracy: 0.7585\n",
            "Epoch 805/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.3635 - accuracy: 0.8640 - val_loss: 0.6629 - val_accuracy: 0.7585\n",
            "Epoch 806/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3728 - accuracy: 0.8591 - val_loss: 0.6533 - val_accuracy: 0.7585\n",
            "Epoch 807/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3699 - accuracy: 0.8537 - val_loss: 0.6514 - val_accuracy: 0.7440\n",
            "Epoch 808/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3645 - accuracy: 0.8622 - val_loss: 0.6875 - val_accuracy: 0.7391\n",
            "Epoch 809/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.3466 - accuracy: 0.8706 - val_loss: 0.6588 - val_accuracy: 0.7729\n",
            "Epoch 810/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3647 - accuracy: 0.8585 - val_loss: 0.6808 - val_accuracy: 0.7488\n",
            "Epoch 811/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3561 - accuracy: 0.8634 - val_loss: 0.6699 - val_accuracy: 0.7391\n",
            "Epoch 812/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3548 - accuracy: 0.8597 - val_loss: 0.6503 - val_accuracy: 0.7585\n",
            "Epoch 813/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3557 - accuracy: 0.8658 - val_loss: 0.6629 - val_accuracy: 0.7488\n",
            "Epoch 814/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.3472 - accuracy: 0.8730 - val_loss: 0.6517 - val_accuracy: 0.7536\n",
            "Epoch 815/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3523 - accuracy: 0.8797 - val_loss: 0.6652 - val_accuracy: 0.7536\n",
            "Epoch 816/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3495 - accuracy: 0.8682 - val_loss: 0.6647 - val_accuracy: 0.7585\n",
            "Epoch 817/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3407 - accuracy: 0.8736 - val_loss: 0.6357 - val_accuracy: 0.7729\n",
            "Epoch 818/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3501 - accuracy: 0.8640 - val_loss: 0.6618 - val_accuracy: 0.7633\n",
            "Epoch 819/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3444 - accuracy: 0.8628 - val_loss: 0.6390 - val_accuracy: 0.7681\n",
            "Epoch 820/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.3452 - accuracy: 0.8658 - val_loss: 0.6543 - val_accuracy: 0.7536\n",
            "Epoch 821/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3790 - accuracy: 0.8489 - val_loss: 0.6524 - val_accuracy: 0.7488\n",
            "Epoch 822/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.3638 - accuracy: 0.8615 - val_loss: 0.6584 - val_accuracy: 0.7681\n",
            "Epoch 823/1000\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.3466 - accuracy: 0.8785 - val_loss: 0.6398 - val_accuracy: 0.7826\n",
            "Epoch 824/1000\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.3462 - accuracy: 0.8664 - val_loss: 0.6447 - val_accuracy: 0.7681\n",
            "Epoch 825/1000\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.3509 - accuracy: 0.8579 - val_loss: 0.6560 - val_accuracy: 0.7585\n",
            "Epoch 826/1000\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.3563 - accuracy: 0.8658 - val_loss: 0.6495 - val_accuracy: 0.7729\n",
            "Epoch 827/1000\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 0.3208 - accuracy: 0.8773 - val_loss: 0.6490 - val_accuracy: 0.7729\n",
            "Epoch 828/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.3587 - accuracy: 0.8513 - val_loss: 0.6649 - val_accuracy: 0.7536\n",
            "Epoch 829/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3554 - accuracy: 0.8591 - val_loss: 0.6471 - val_accuracy: 0.7633\n",
            "Epoch 830/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.3444 - accuracy: 0.8730 - val_loss: 0.6498 - val_accuracy: 0.7633\n",
            "Epoch 831/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3513 - accuracy: 0.8670 - val_loss: 0.6470 - val_accuracy: 0.7585\n",
            "Epoch 832/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.3328 - accuracy: 0.8724 - val_loss: 0.6300 - val_accuracy: 0.7826\n",
            "Epoch 833/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3422 - accuracy: 0.8676 - val_loss: 0.6304 - val_accuracy: 0.7536\n",
            "Epoch 834/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3391 - accuracy: 0.8748 - val_loss: 0.6139 - val_accuracy: 0.7778\n",
            "Epoch 835/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3130 - accuracy: 0.8791 - val_loss: 0.6318 - val_accuracy: 0.7633\n",
            "Epoch 836/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.3421 - accuracy: 0.8694 - val_loss: 0.6342 - val_accuracy: 0.7778\n",
            "Epoch 837/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3369 - accuracy: 0.8724 - val_loss: 0.6497 - val_accuracy: 0.7633\n",
            "Epoch 838/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3594 - accuracy: 0.8646 - val_loss: 0.6645 - val_accuracy: 0.7488\n",
            "Epoch 839/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3488 - accuracy: 0.8694 - val_loss: 0.6246 - val_accuracy: 0.7633\n",
            "Epoch 840/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.3416 - accuracy: 0.8803 - val_loss: 0.6409 - val_accuracy: 0.7488\n",
            "Epoch 841/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.3438 - accuracy: 0.8712 - val_loss: 0.6306 - val_accuracy: 0.7633\n",
            "Epoch 842/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3455 - accuracy: 0.8730 - val_loss: 0.6312 - val_accuracy: 0.7778\n",
            "Epoch 843/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3484 - accuracy: 0.8676 - val_loss: 0.6295 - val_accuracy: 0.7585\n",
            "Epoch 844/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.3411 - accuracy: 0.8664 - val_loss: 0.6320 - val_accuracy: 0.7874\n",
            "Epoch 845/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3333 - accuracy: 0.8785 - val_loss: 0.6435 - val_accuracy: 0.7633\n",
            "Epoch 846/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3419 - accuracy: 0.8700 - val_loss: 0.6388 - val_accuracy: 0.7729\n",
            "Epoch 847/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.3330 - accuracy: 0.8730 - val_loss: 0.6261 - val_accuracy: 0.7826\n",
            "Epoch 848/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3423 - accuracy: 0.8748 - val_loss: 0.6387 - val_accuracy: 0.7681\n",
            "Epoch 849/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3236 - accuracy: 0.8724 - val_loss: 0.6291 - val_accuracy: 0.7826\n",
            "Epoch 850/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3282 - accuracy: 0.8851 - val_loss: 0.6410 - val_accuracy: 0.7440\n",
            "Epoch 851/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.3141 - accuracy: 0.8912 - val_loss: 0.6235 - val_accuracy: 0.7874\n",
            "Epoch 852/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3304 - accuracy: 0.8827 - val_loss: 0.6437 - val_accuracy: 0.7585\n",
            "Epoch 853/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3538 - accuracy: 0.8688 - val_loss: 0.6426 - val_accuracy: 0.7681\n",
            "Epoch 854/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3367 - accuracy: 0.8742 - val_loss: 0.6338 - val_accuracy: 0.7585\n",
            "Epoch 855/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3325 - accuracy: 0.8821 - val_loss: 0.6534 - val_accuracy: 0.7391\n",
            "Epoch 856/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3394 - accuracy: 0.8724 - val_loss: 0.6358 - val_accuracy: 0.7440\n",
            "Epoch 857/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3292 - accuracy: 0.8827 - val_loss: 0.6202 - val_accuracy: 0.7923\n",
            "Epoch 858/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3174 - accuracy: 0.8791 - val_loss: 0.6130 - val_accuracy: 0.7923\n",
            "Epoch 859/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3271 - accuracy: 0.8851 - val_loss: 0.6302 - val_accuracy: 0.7874\n",
            "Epoch 860/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3186 - accuracy: 0.8845 - val_loss: 0.6376 - val_accuracy: 0.7681\n",
            "Epoch 861/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3309 - accuracy: 0.8700 - val_loss: 0.6343 - val_accuracy: 0.7681\n",
            "Epoch 862/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3270 - accuracy: 0.8755 - val_loss: 0.6206 - val_accuracy: 0.7681\n",
            "Epoch 863/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.3222 - accuracy: 0.8821 - val_loss: 0.6372 - val_accuracy: 0.7633\n",
            "Epoch 864/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3277 - accuracy: 0.8755 - val_loss: 0.6374 - val_accuracy: 0.7536\n",
            "Epoch 865/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3099 - accuracy: 0.8827 - val_loss: 0.6514 - val_accuracy: 0.7585\n",
            "Epoch 866/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3326 - accuracy: 0.8694 - val_loss: 0.6286 - val_accuracy: 0.7874\n",
            "Epoch 867/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3429 - accuracy: 0.8730 - val_loss: 0.6267 - val_accuracy: 0.7826\n",
            "Epoch 868/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.3154 - accuracy: 0.8815 - val_loss: 0.6311 - val_accuracy: 0.7778\n",
            "Epoch 869/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3177 - accuracy: 0.8821 - val_loss: 0.6568 - val_accuracy: 0.7681\n",
            "Epoch 870/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3269 - accuracy: 0.8748 - val_loss: 0.6363 - val_accuracy: 0.7923\n",
            "Epoch 871/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3178 - accuracy: 0.8857 - val_loss: 0.6397 - val_accuracy: 0.7826\n",
            "Epoch 872/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3240 - accuracy: 0.8682 - val_loss: 0.6538 - val_accuracy: 0.7536\n",
            "Epoch 873/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3182 - accuracy: 0.8881 - val_loss: 0.6600 - val_accuracy: 0.7440\n",
            "Epoch 874/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.3175 - accuracy: 0.8779 - val_loss: 0.6441 - val_accuracy: 0.7681\n",
            "Epoch 875/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3272 - accuracy: 0.8785 - val_loss: 0.6402 - val_accuracy: 0.7681\n",
            "Epoch 876/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3158 - accuracy: 0.8803 - val_loss: 0.6268 - val_accuracy: 0.7729\n",
            "Epoch 877/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3195 - accuracy: 0.8815 - val_loss: 0.6364 - val_accuracy: 0.7681\n",
            "Epoch 878/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3110 - accuracy: 0.8797 - val_loss: 0.6367 - val_accuracy: 0.7681\n",
            "Epoch 879/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3153 - accuracy: 0.8773 - val_loss: 0.6353 - val_accuracy: 0.7874\n",
            "Epoch 880/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.3029 - accuracy: 0.8900 - val_loss: 0.6455 - val_accuracy: 0.7778\n",
            "Epoch 881/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3000 - accuracy: 0.8869 - val_loss: 0.6475 - val_accuracy: 0.7874\n",
            "Epoch 882/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3273 - accuracy: 0.8803 - val_loss: 0.6316 - val_accuracy: 0.7729\n",
            "Epoch 883/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3258 - accuracy: 0.8761 - val_loss: 0.6285 - val_accuracy: 0.7778\n",
            "Epoch 884/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3220 - accuracy: 0.8791 - val_loss: 0.6315 - val_accuracy: 0.7778\n",
            "Epoch 885/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3193 - accuracy: 0.8815 - val_loss: 0.6213 - val_accuracy: 0.7681\n",
            "Epoch 886/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3129 - accuracy: 0.8888 - val_loss: 0.6238 - val_accuracy: 0.7971\n",
            "Epoch 887/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.3054 - accuracy: 0.8821 - val_loss: 0.6211 - val_accuracy: 0.7729\n",
            "Epoch 888/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.3121 - accuracy: 0.8845 - val_loss: 0.6204 - val_accuracy: 0.7923\n",
            "Epoch 889/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.3075 - accuracy: 0.8821 - val_loss: 0.6213 - val_accuracy: 0.7633\n",
            "Epoch 890/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3283 - accuracy: 0.8700 - val_loss: 0.6276 - val_accuracy: 0.7923\n",
            "Epoch 891/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2999 - accuracy: 0.8912 - val_loss: 0.6224 - val_accuracy: 0.7826\n",
            "Epoch 892/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2906 - accuracy: 0.8833 - val_loss: 0.6155 - val_accuracy: 0.7778\n",
            "Epoch 893/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.3288 - accuracy: 0.8857 - val_loss: 0.6305 - val_accuracy: 0.7633\n",
            "Epoch 894/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.3021 - accuracy: 0.8924 - val_loss: 0.6185 - val_accuracy: 0.7923\n",
            "Epoch 895/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3136 - accuracy: 0.8815 - val_loss: 0.6475 - val_accuracy: 0.7681\n",
            "Epoch 896/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.3223 - accuracy: 0.8779 - val_loss: 0.6551 - val_accuracy: 0.7778\n",
            "Epoch 897/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.3141 - accuracy: 0.8767 - val_loss: 0.6520 - val_accuracy: 0.7778\n",
            "Epoch 898/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2992 - accuracy: 0.8906 - val_loss: 0.6309 - val_accuracy: 0.7729\n",
            "Epoch 899/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.3122 - accuracy: 0.8742 - val_loss: 0.6285 - val_accuracy: 0.7681\n",
            "Epoch 900/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.3165 - accuracy: 0.8797 - val_loss: 0.6314 - val_accuracy: 0.7923\n",
            "Epoch 901/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2985 - accuracy: 0.8833 - val_loss: 0.6343 - val_accuracy: 0.7778\n",
            "Epoch 902/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3328 - accuracy: 0.8688 - val_loss: 0.6263 - val_accuracy: 0.7778\n",
            "Epoch 903/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2941 - accuracy: 0.8936 - val_loss: 0.6367 - val_accuracy: 0.7729\n",
            "Epoch 904/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.3147 - accuracy: 0.8869 - val_loss: 0.6310 - val_accuracy: 0.7729\n",
            "Epoch 905/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.3093 - accuracy: 0.8815 - val_loss: 0.6261 - val_accuracy: 0.7874\n",
            "Epoch 906/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.3020 - accuracy: 0.8863 - val_loss: 0.6620 - val_accuracy: 0.7681\n",
            "Epoch 907/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2914 - accuracy: 0.8875 - val_loss: 0.6302 - val_accuracy: 0.7874\n",
            "Epoch 908/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.3058 - accuracy: 0.8821 - val_loss: 0.6264 - val_accuracy: 0.7826\n",
            "Epoch 909/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3100 - accuracy: 0.8833 - val_loss: 0.6174 - val_accuracy: 0.8068\n",
            "Epoch 910/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2867 - accuracy: 0.8900 - val_loss: 0.6353 - val_accuracy: 0.7681\n",
            "Epoch 911/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2959 - accuracy: 0.8863 - val_loss: 0.6302 - val_accuracy: 0.8068\n",
            "Epoch 912/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2933 - accuracy: 0.8924 - val_loss: 0.6272 - val_accuracy: 0.8019\n",
            "Epoch 913/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2782 - accuracy: 0.8990 - val_loss: 0.6386 - val_accuracy: 0.7874\n",
            "Epoch 914/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3030 - accuracy: 0.8881 - val_loss: 0.6366 - val_accuracy: 0.7681\n",
            "Epoch 915/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2967 - accuracy: 0.8875 - val_loss: 0.6258 - val_accuracy: 0.7681\n",
            "Epoch 916/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3086 - accuracy: 0.8894 - val_loss: 0.6351 - val_accuracy: 0.7729\n",
            "Epoch 917/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2920 - accuracy: 0.8954 - val_loss: 0.6210 - val_accuracy: 0.7874\n",
            "Epoch 918/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2877 - accuracy: 0.8942 - val_loss: 0.6636 - val_accuracy: 0.7681\n",
            "Epoch 919/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2957 - accuracy: 0.8936 - val_loss: 0.6405 - val_accuracy: 0.7826\n",
            "Epoch 920/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2983 - accuracy: 0.8906 - val_loss: 0.6184 - val_accuracy: 0.7971\n",
            "Epoch 921/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2925 - accuracy: 0.8833 - val_loss: 0.6297 - val_accuracy: 0.7729\n",
            "Epoch 922/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2962 - accuracy: 0.8881 - val_loss: 0.6582 - val_accuracy: 0.7585\n",
            "Epoch 923/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2749 - accuracy: 0.8954 - val_loss: 0.6301 - val_accuracy: 0.7874\n",
            "Epoch 924/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3115 - accuracy: 0.8815 - val_loss: 0.6371 - val_accuracy: 0.7778\n",
            "Epoch 925/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.3018 - accuracy: 0.8851 - val_loss: 0.6413 - val_accuracy: 0.7971\n",
            "Epoch 926/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2996 - accuracy: 0.8857 - val_loss: 0.6459 - val_accuracy: 0.7826\n",
            "Epoch 927/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2914 - accuracy: 0.8948 - val_loss: 0.6411 - val_accuracy: 0.7585\n",
            "Epoch 928/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3028 - accuracy: 0.8815 - val_loss: 0.6371 - val_accuracy: 0.7778\n",
            "Epoch 929/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2978 - accuracy: 0.8924 - val_loss: 0.6183 - val_accuracy: 0.7874\n",
            "Epoch 930/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2847 - accuracy: 0.8990 - val_loss: 0.6271 - val_accuracy: 0.7826\n",
            "Epoch 931/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2775 - accuracy: 0.8978 - val_loss: 0.6415 - val_accuracy: 0.7681\n",
            "Epoch 932/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2826 - accuracy: 0.8984 - val_loss: 0.6261 - val_accuracy: 0.7826\n",
            "Epoch 933/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2703 - accuracy: 0.9039 - val_loss: 0.6262 - val_accuracy: 0.7729\n",
            "Epoch 934/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2920 - accuracy: 0.8863 - val_loss: 0.6401 - val_accuracy: 0.7826\n",
            "Epoch 935/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2894 - accuracy: 0.8972 - val_loss: 0.6562 - val_accuracy: 0.7633\n",
            "Epoch 936/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2804 - accuracy: 0.8984 - val_loss: 0.6456 - val_accuracy: 0.7633\n",
            "Epoch 937/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2877 - accuracy: 0.8942 - val_loss: 0.6168 - val_accuracy: 0.7778\n",
            "Epoch 938/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2786 - accuracy: 0.8960 - val_loss: 0.6381 - val_accuracy: 0.7778\n",
            "Epoch 939/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2703 - accuracy: 0.8960 - val_loss: 0.6555 - val_accuracy: 0.7681\n",
            "Epoch 940/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2740 - accuracy: 0.9075 - val_loss: 0.6610 - val_accuracy: 0.7536\n",
            "Epoch 941/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2906 - accuracy: 0.8900 - val_loss: 0.6425 - val_accuracy: 0.7729\n",
            "Epoch 942/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2709 - accuracy: 0.9008 - val_loss: 0.6370 - val_accuracy: 0.7826\n",
            "Epoch 943/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2901 - accuracy: 0.8966 - val_loss: 0.6337 - val_accuracy: 0.7778\n",
            "Epoch 944/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2788 - accuracy: 0.9002 - val_loss: 0.6573 - val_accuracy: 0.7729\n",
            "Epoch 945/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2496 - accuracy: 0.9087 - val_loss: 0.6268 - val_accuracy: 0.7729\n",
            "Epoch 946/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2938 - accuracy: 0.8978 - val_loss: 0.6522 - val_accuracy: 0.7536\n",
            "Epoch 947/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3067 - accuracy: 0.8869 - val_loss: 0.6686 - val_accuracy: 0.7585\n",
            "Epoch 948/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2837 - accuracy: 0.8972 - val_loss: 0.6455 - val_accuracy: 0.7633\n",
            "Epoch 949/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3079 - accuracy: 0.8827 - val_loss: 0.6313 - val_accuracy: 0.7826\n",
            "Epoch 950/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2900 - accuracy: 0.8930 - val_loss: 0.6250 - val_accuracy: 0.7923\n",
            "Epoch 951/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2884 - accuracy: 0.8900 - val_loss: 0.6330 - val_accuracy: 0.7778\n",
            "Epoch 952/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2620 - accuracy: 0.9015 - val_loss: 0.6467 - val_accuracy: 0.7729\n",
            "Epoch 953/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2628 - accuracy: 0.9063 - val_loss: 0.6458 - val_accuracy: 0.7681\n",
            "Epoch 954/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2847 - accuracy: 0.8960 - val_loss: 0.6317 - val_accuracy: 0.7633\n",
            "Epoch 955/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2661 - accuracy: 0.9021 - val_loss: 0.6414 - val_accuracy: 0.7729\n",
            "Epoch 956/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2675 - accuracy: 0.8996 - val_loss: 0.6187 - val_accuracy: 0.7923\n",
            "Epoch 957/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2585 - accuracy: 0.8996 - val_loss: 0.6278 - val_accuracy: 0.7729\n",
            "Epoch 958/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2587 - accuracy: 0.9051 - val_loss: 0.6040 - val_accuracy: 0.7923\n",
            "Epoch 959/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2882 - accuracy: 0.8936 - val_loss: 0.6165 - val_accuracy: 0.8116\n",
            "Epoch 960/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2734 - accuracy: 0.8942 - val_loss: 0.6231 - val_accuracy: 0.7874\n",
            "Epoch 961/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2687 - accuracy: 0.9015 - val_loss: 0.6179 - val_accuracy: 0.7826\n",
            "Epoch 962/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2585 - accuracy: 0.9033 - val_loss: 0.6285 - val_accuracy: 0.7923\n",
            "Epoch 963/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2644 - accuracy: 0.8972 - val_loss: 0.6271 - val_accuracy: 0.7874\n",
            "Epoch 964/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2902 - accuracy: 0.8875 - val_loss: 0.6328 - val_accuracy: 0.7826\n",
            "Epoch 965/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2874 - accuracy: 0.8912 - val_loss: 0.6425 - val_accuracy: 0.7826\n",
            "Epoch 966/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2726 - accuracy: 0.8966 - val_loss: 0.6507 - val_accuracy: 0.7729\n",
            "Epoch 967/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2654 - accuracy: 0.9039 - val_loss: 0.6496 - val_accuracy: 0.7729\n",
            "Epoch 968/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2700 - accuracy: 0.9057 - val_loss: 0.6407 - val_accuracy: 0.7874\n",
            "Epoch 969/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2795 - accuracy: 0.8984 - val_loss: 0.6138 - val_accuracy: 0.7923\n",
            "Epoch 970/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2471 - accuracy: 0.9075 - val_loss: 0.6121 - val_accuracy: 0.8068\n",
            "Epoch 971/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2736 - accuracy: 0.9027 - val_loss: 0.6407 - val_accuracy: 0.7633\n",
            "Epoch 972/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2781 - accuracy: 0.8875 - val_loss: 0.6275 - val_accuracy: 0.7729\n",
            "Epoch 973/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2915 - accuracy: 0.8875 - val_loss: 0.6341 - val_accuracy: 0.7729\n",
            "Epoch 974/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2668 - accuracy: 0.8978 - val_loss: 0.6222 - val_accuracy: 0.7826\n",
            "Epoch 975/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2732 - accuracy: 0.8948 - val_loss: 0.6373 - val_accuracy: 0.7729\n",
            "Epoch 976/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2613 - accuracy: 0.9002 - val_loss: 0.6454 - val_accuracy: 0.7826\n",
            "Epoch 977/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2734 - accuracy: 0.8936 - val_loss: 0.6378 - val_accuracy: 0.7729\n",
            "Epoch 978/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2647 - accuracy: 0.9033 - val_loss: 0.6203 - val_accuracy: 0.7971\n",
            "Epoch 979/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2588 - accuracy: 0.9045 - val_loss: 0.6206 - val_accuracy: 0.7778\n",
            "Epoch 980/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2598 - accuracy: 0.8984 - val_loss: 0.6181 - val_accuracy: 0.7923\n",
            "Epoch 981/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2851 - accuracy: 0.9008 - val_loss: 0.6331 - val_accuracy: 0.7971\n",
            "Epoch 982/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2535 - accuracy: 0.9105 - val_loss: 0.6327 - val_accuracy: 0.7729\n",
            "Epoch 983/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2483 - accuracy: 0.9063 - val_loss: 0.6217 - val_accuracy: 0.7729\n",
            "Epoch 984/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2610 - accuracy: 0.9045 - val_loss: 0.6106 - val_accuracy: 0.7923\n",
            "Epoch 985/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2678 - accuracy: 0.9021 - val_loss: 0.6232 - val_accuracy: 0.7681\n",
            "Epoch 986/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2559 - accuracy: 0.9063 - val_loss: 0.6030 - val_accuracy: 0.8164\n",
            "Epoch 987/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2671 - accuracy: 0.8990 - val_loss: 0.5880 - val_accuracy: 0.8164\n",
            "Epoch 988/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2794 - accuracy: 0.8924 - val_loss: 0.6170 - val_accuracy: 0.7681\n",
            "Epoch 989/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2911 - accuracy: 0.8954 - val_loss: 0.6206 - val_accuracy: 0.7681\n",
            "Epoch 990/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2563 - accuracy: 0.9087 - val_loss: 0.6304 - val_accuracy: 0.7826\n",
            "Epoch 991/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2483 - accuracy: 0.9051 - val_loss: 0.6116 - val_accuracy: 0.8068\n",
            "Epoch 992/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2645 - accuracy: 0.9033 - val_loss: 0.6298 - val_accuracy: 0.7923\n",
            "Epoch 993/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2597 - accuracy: 0.8996 - val_loss: 0.6034 - val_accuracy: 0.7778\n",
            "Epoch 994/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2665 - accuracy: 0.8972 - val_loss: 0.6165 - val_accuracy: 0.7778\n",
            "Epoch 995/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2564 - accuracy: 0.9027 - val_loss: 0.6265 - val_accuracy: 0.7681\n",
            "Epoch 996/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2684 - accuracy: 0.9033 - val_loss: 0.6120 - val_accuracy: 0.7923\n",
            "Epoch 997/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2476 - accuracy: 0.9081 - val_loss: 0.6301 - val_accuracy: 0.7923\n",
            "Epoch 998/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2586 - accuracy: 0.9051 - val_loss: 0.6310 - val_accuracy: 0.7729\n",
            "Epoch 999/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2445 - accuracy: 0.9190 - val_loss: 0.6143 - val_accuracy: 0.8019\n",
            "Epoch 1000/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2468 - accuracy: 0.9111 - val_loss: 0.6292 - val_accuracy: 0.7874\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(cnnhistory.history['loss'])\n",
        "plt.plot(cnnhistory.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train','test'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "oQYnuaCrDH_A",
        "outputId": "43edb625-eda9-49a9-d8e9-520c5c789eb9"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(cnnhistory.history['accuracy'])\n",
        "plt.plot(cnnhistory.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train','test'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "IFkTuO8nDNdq",
        "outputId": "10bb122f-a97d-492a-a6a8-59cc47f887a5"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#predictions = model.predict_classes(x_testcnn)\n",
        "predictions = model.predict(x_testcnn)"
      ],
      "metadata": {
        "id": "A2xtrN5wDQgY"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_f_ohjXKDUpY",
        "outputId": "b282caab-3a0b-4c96-b171-0d00e4d34ba6"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.5698417e-05, 4.8300676e-06, 6.0244426e-03, 2.5946557e-04,\n",
              "        4.7409258e-04, 9.9322152e-01],\n",
              "       [4.3586437e-02, 9.4105905e-01, 6.5555406e-04, 9.5835570e-03,\n",
              "        2.1305033e-03, 2.9848695e-03],\n",
              "       [6.2230890e-07, 7.4769778e-05, 9.7116697e-01, 7.4370677e-05,\n",
              "        2.2784002e-02, 5.8993185e-03],\n",
              "       ...,\n",
              "       [4.1580817e-05, 8.5392330e-06, 4.8868440e-04, 7.8204798e-04,\n",
              "        9.6568656e-01, 3.2992572e-02],\n",
              "       [1.1891359e-02, 1.1206580e-03, 7.1643423e-03, 6.5174192e-01,\n",
              "        9.5991176e-03, 3.1848264e-01],\n",
              "       [7.2677232e-02, 2.5357224e-02, 6.7510933e-02, 2.1560255e-02,\n",
              "        8.1272453e-01, 1.6984799e-04]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cmA2bFgsDW3D",
        "outputId": "540f1105-0d4f-40f5-c58f-7ac544f7def0"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5, 1, 2, 5, 3, 4, 2, 0, 3, 1, 3, 2, 1, 4, 3, 0, 5, 0, 2, 5, 0, 0,\n",
              "       1, 3, 2, 3, 2, 5, 4, 2, 2, 3, 1, 2, 5, 5, 3, 5, 3, 3, 4, 1, 3, 2,\n",
              "       3, 1, 5, 3, 1, 2, 4, 4, 5, 5, 5, 1, 2, 3, 2, 5, 0, 2, 4, 2, 5, 4,\n",
              "       3, 0, 1, 2, 5, 2, 1, 2, 4, 5, 4, 1, 5, 5, 3, 1, 5, 3, 2, 4, 2, 5,\n",
              "       0, 5, 0, 5, 4, 0, 2, 4, 0, 2, 2, 0, 2, 3, 5, 3, 5, 5, 3, 1, 2, 2,\n",
              "       2, 1, 3, 2, 1, 3, 4, 4, 1, 1, 2, 4, 4, 1, 4, 2, 0, 4, 5, 5, 3, 1,\n",
              "       2, 1, 5, 5, 1, 2, 3, 3, 0, 3, 3, 0, 1, 0, 1, 2, 1, 5, 1, 2, 2, 0,\n",
              "       1, 1, 1, 1, 1, 4, 0, 1, 5, 1, 4, 5, 5, 4, 1, 0, 3, 5, 2, 3, 0, 4,\n",
              "       1, 3, 1, 0, 5, 5, 3, 5, 4, 5, 4, 0, 4, 1, 2, 1, 5, 0, 4, 3, 2, 1,\n",
              "       0, 3, 5, 0, 4, 5, 4, 5, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_Ytest = y_test.astype(int)"
      ],
      "metadata": {
        "id": "0PHDKWJWDY3g"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_Ytest"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k68v2i-pDbZE",
        "outputId": "3e818df4-2d44-4cc9-98c9-7989d355437b"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5, 1, 2, 5, 3, 4, 2, 0, 3, 1, 3, 2, 1, 4, 3, 0, 5, 0, 2, 5, 0, 0,\n",
              "       1, 3, 2, 3, 2, 5, 4, 2, 2, 3, 1, 2, 5, 5, 3, 5, 3, 3, 4, 1, 3, 2,\n",
              "       3, 1, 5, 3, 1, 2, 4, 4, 5, 5, 5, 1, 2, 3, 2, 5, 0, 2, 4, 2, 5, 4,\n",
              "       3, 0, 1, 2, 5, 2, 1, 2, 4, 5, 4, 1, 5, 5, 3, 1, 5, 3, 2, 4, 2, 5,\n",
              "       0, 5, 0, 5, 4, 0, 2, 4, 0, 2, 2, 0, 2, 3, 5, 3, 5, 5, 3, 1, 2, 2,\n",
              "       2, 1, 3, 2, 1, 3, 4, 4, 1, 1, 2, 4, 4, 1, 4, 2, 0, 4, 5, 5, 3, 1,\n",
              "       2, 1, 5, 5, 1, 2, 3, 3, 0, 3, 3, 0, 1, 0, 1, 2, 1, 5, 1, 2, 2, 0,\n",
              "       1, 1, 1, 1, 1, 4, 0, 1, 5, 1, 4, 5, 5, 4, 1, 0, 3, 5, 2, 3, 0, 4,\n",
              "       1, 3, 1, 0, 5, 5, 3, 5, 4, 5, 4, 0, 4, 1, 2, 1, 5, 0, 4, 3, 2, 1,\n",
              "       0, 3, 5, 0, 4, 5, 4, 5, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds1=predictions.argmax(axis=1)\n",
        "preds1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4_cAI39VFhtp",
        "outputId": "c68173ec-08d9-4f8b-cc0e-e94e5192e0b2"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5, 1, 2, 5, 3, 4, 2, 0, 3, 1, 3, 2, 1, 4, 3, 0, 5, 3, 2, 5, 2, 1,\n",
              "       1, 3, 2, 3, 2, 5, 4, 4, 2, 5, 1, 2, 5, 5, 1, 5, 3, 2, 4, 1, 3, 2,\n",
              "       3, 1, 5, 3, 1, 4, 4, 4, 5, 2, 3, 1, 2, 3, 2, 5, 0, 2, 4, 4, 5, 4,\n",
              "       4, 1, 2, 2, 3, 2, 1, 5, 4, 5, 4, 1, 5, 5, 5, 1, 5, 3, 2, 4, 2, 3,\n",
              "       0, 5, 0, 5, 4, 0, 3, 4, 3, 4, 2, 1, 2, 2, 5, 3, 5, 5, 5, 1, 2, 2,\n",
              "       2, 1, 3, 2, 1, 4, 2, 4, 1, 5, 2, 4, 4, 1, 4, 2, 2, 4, 4, 5, 5, 1,\n",
              "       4, 1, 5, 4, 1, 3, 5, 3, 0, 3, 5, 0, 1, 0, 1, 2, 1, 5, 1, 2, 4, 0,\n",
              "       1, 1, 1, 1, 3, 4, 0, 1, 5, 1, 4, 5, 5, 2, 1, 0, 5, 5, 2, 3, 3, 4,\n",
              "       1, 3, 1, 5, 5, 2, 3, 5, 4, 5, 4, 0, 4, 3, 2, 1, 3, 0, 4, 1, 2, 2,\n",
              "       1, 4, 5, 0, 4, 5, 4, 3, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "abc = preds1.astype(int).flatten()"
      ],
      "metadata": {
        "id": "H4WEmM60NfQn"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "c = confusion_matrix(new_Ytest, abc) \n",
        "c"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bKEBeEBlFjB8",
        "outputId": "c814a02c-8a4a-4c1b-e632-415a330223a7"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[15,  4,  2,  3,  0,  1],\n",
              "       [ 0, 34,  2,  2,  0,  1],\n",
              "       [ 0,  0, 29,  2,  6,  1],\n",
              "       [ 0,  2,  2, 19,  3,  7],\n",
              "       [ 0,  0,  2,  0, 28,  0],\n",
              "       [ 0,  0,  2,  5,  2, 33]])"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m4RjG7LWLSQx",
        "outputId": "0f44104d-c863-4f7f-df68-6e7b25bd64cb"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5, 1, 2, 5, 3, 4, 2, 0, 3, 1, 3, 2, 1, 4, 3, 0, 5, 0, 2, 5, 0, 0,\n",
              "       1, 3, 2, 3, 2, 5, 4, 2, 2, 3, 1, 2, 5, 5, 3, 5, 3, 3, 4, 1, 3, 2,\n",
              "       3, 1, 5, 3, 1, 2, 4, 4, 5, 5, 5, 1, 2, 3, 2, 5, 0, 2, 4, 2, 5, 4,\n",
              "       3, 0, 1, 2, 5, 2, 1, 2, 4, 5, 4, 1, 5, 5, 3, 1, 5, 3, 2, 4, 2, 5,\n",
              "       0, 5, 0, 5, 4, 0, 2, 4, 0, 2, 2, 0, 2, 3, 5, 3, 5, 5, 3, 1, 2, 2,\n",
              "       2, 1, 3, 2, 1, 3, 4, 4, 1, 1, 2, 4, 4, 1, 4, 2, 0, 4, 5, 5, 3, 1,\n",
              "       2, 1, 5, 5, 1, 2, 3, 3, 0, 3, 3, 0, 1, 0, 1, 2, 1, 5, 1, 2, 2, 0,\n",
              "       1, 1, 1, 1, 1, 4, 0, 1, 5, 1, 4, 5, 5, 4, 1, 0, 3, 5, 2, 3, 0, 4,\n",
              "       1, 3, 1, 0, 5, 5, 3, 5, 4, 5, 4, 0, 4, 1, 2, 1, 5, 0, 4, 3, 2, 1,\n",
              "       0, 3, 5, 0, 4, 5, 4, 5, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('/content/drive/My Drive/graduation project/audio/paper_code/mariam/original_500 epoch_with_valid_Adam2_3')\n",
        "print(\"MODEL SAVED\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lsJBNeMWDl6Z",
        "outputId": "ed8bacfb-18de-42ef-d67e-c6ee01fa9ea6"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/graduation project/audio/paper_code/mariam/original_500 epoch_with_valid_Adam2_3/assets\n",
            "MODEL SAVED\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_model=keras.models.load_model('/content/drive/My Drive/graduation project/audio/paper_code/mariam/original_500 epoch_with_valid_Adam2_3')\n",
        "new_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q3KjaO9GDoNl",
        "outputId": "59966afd-067f-4980-df2d-9f7de9a10ae4"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d (Conv1D)             (None, 40, 128)           1152      \n",
            "                                                                 \n",
            " activation (Activation)     (None, 40, 128)           0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 40, 128)           0         \n",
            "                                                                 \n",
            " max_pooling1d (MaxPooling1D  (None, 8, 128)           0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv1d_1 (Conv1D)           (None, 8, 256)            262400    \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 8, 256)            0         \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 8, 256)            0         \n",
            "                                                                 \n",
            " max_pooling1d_1 (MaxPooling  (None, 1, 256)           0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 256)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 256)               65792     \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 256)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 256)               65792     \n",
            "                                                                 \n",
            " activation_3 (Activation)   (None, 256)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 6)                 1542      \n",
            "                                                                 \n",
            " activation_4 (Activation)   (None, 6)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 396,678\n",
            "Trainable params: 396,678\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss, acc =model.evaluate(x_testcnn, y_test)\n",
        "print(\"Restored model, accuracy: {:5.2f}%\".format(100*acc))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n3kzoqPkDqqS",
        "outputId": "2a041174-3a97-403c-d00b-d10d738b38ea"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7/7 [==============================] - 0s 3ms/step - loss: 0.5852 - accuracy: 0.7633\n",
            "Restored model, accuracy: 76.33%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss, acc =model.evaluate(X_train, y_train)\n",
        "print(\"Restored model train, accuracy: {:5.2f}%\".format(100*acc))"
      ],
      "metadata": {
        "id": "fJDTGH_OUX0z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53eb1911-3bf1-4c55-cd4f-7efbfbe482d7"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "52/52 [==============================] - 0s 4ms/step - loss: 0.1978 - accuracy: 0.9595\n",
            "Restored model train, accuracy: 95.95%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix,accuracy_score\n",
        "import seaborn as sn\n",
        "\n",
        "print(classification_report(new_Ytest,abc))\n",
        "\n",
        "acc = float(accuracy_score(new_Ytest,abc))*100\n",
        "print(\"----accuracy score %s ----\" % acc)\n",
        "\n",
        "cm = confusion_matrix(new_Ytest,abc)\n",
        "#df_cm = pd.DataFrame(cm)\n",
        "class_names = ['neutral','calm', 'happy','sad','angry', 'fearful' ]\n",
        "df_cm = pd.DataFrame(cm, index=class_names, columns=class_names,)\n",
        "sn.heatmap(df_cm, annot=True, fmt='')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 517
        },
        "id": "SfSC3El94LZg",
        "outputId": "18093068-7d46-42cd-a55b-d6c123e64a57"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.60      0.75        25\n",
            "           1       0.85      0.87      0.86        39\n",
            "           2       0.74      0.76      0.75        38\n",
            "           3       0.61      0.58      0.59        33\n",
            "           4       0.72      0.93      0.81        30\n",
            "           5       0.77      0.79      0.78        42\n",
            "\n",
            "    accuracy                           0.76       207\n",
            "   macro avg       0.78      0.75      0.76       207\n",
            "weighted avg       0.77      0.76      0.76       207\n",
            "\n",
            "----accuracy score 76.32850241545893 ----\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "LGpgwFQqkpyU"
      },
      "execution_count": 37,
      "outputs": []
    }
  ]
}