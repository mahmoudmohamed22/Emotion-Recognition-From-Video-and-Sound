{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ramadan adam 0.0002 2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9SRCO-a_AlH5",
        "outputId": "db0e51c8-9ce7-4c1c-b82d-04647c1a6430"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install librosa"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oi8pWV3yBVjO",
        "outputId": "ad094f4f-5fe4-423d-ad15-9e405888b641"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.7/dist-packages (0.8.1)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.1.0)\n",
            "Requirement already satisfied: decorator>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (21.3)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.21.6)\n",
            "Requirement already satisfied: audioread>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (2.1.9)\n",
            "Requirement already satisfied: resampy>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from librosa) (0.2.2)\n",
            "Requirement already satisfied: soundfile>=0.10.2 in /usr/local/lib/python3.7/dist-packages (from librosa) (0.10.3.post1)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.4.1)\n",
            "Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.6.0)\n",
            "Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.0.2)\n",
            "Requirement already satisfied: numba>=0.43.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (0.51.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba>=0.43.0->librosa) (57.4.0)\n",
            "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba>=0.43.0->librosa) (0.34.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->librosa) (3.0.9)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from pooch>=1.0->librosa) (2.23.0)\n",
            "Requirement already satisfied: appdirs>=1.3.0 in /usr/local/lib/python3.7/dist-packages (from pooch>=1.0->librosa) (1.4.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2022.5.18.1)\n",
            "Requirement already satisfied: six>=1.3 in /usr/local/lib/python3.7/dist-packages (from resampy>=0.2.2->librosa) (1.15.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn!=0.19.0,>=0.14.0->librosa) (3.1.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.7/dist-packages (from soundfile>=0.10.2->librosa) (1.15.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.0->soundfile>=0.10.2->librosa) (2.21)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HJjcbxwy46bG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "3b4ba01a-cf5d-471a-c5b3-fab69e1ee33b"
      },
      "source": [
        "# Orignial Notebook: https://github.com/MITESHPUTHRANNEU/Speech-Emotion-Analyzer/blob/master/final_results_gender_test.ipynb\n",
        "# This notebook author: Reza Chu\n",
        "# Last Editing Date: 31st May 2019\n",
        "\n",
        "## Python\n",
        "import os\n",
        "import random\n",
        "import sys\n",
        "\n",
        "import IPython\n",
        "from IPython.display import Audio\n",
        "from IPython.display import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "## Package\n",
        "import glob \n",
        "import keras\n",
        "import IPython.display as ipd\n",
        "import librosa\n",
        "import librosa.display\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import plotly.graph_objs as go\n",
        "import plotly.offline as py\n",
        "import plotly.tools as tls\n",
        "import seaborn as sns\n",
        "import scipy.io.wavfile\n",
        "import tensorflow as tf\n",
        "py.init_notebook_mode(connected=True)\n",
        "\n",
        "## Keras\n",
        "from keras import regularizers\n",
        "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping\n",
        "from keras.callbacks import  History, ReduceLROnPlateau, CSVLogger\n",
        "from keras.models import Model, Sequential\n",
        "from keras.layers import Dense, Embedding, LSTM\n",
        "from keras.layers import Input, Flatten, Dropout, Activation, BatchNormalization\n",
        "from keras.layers import Conv1D, MaxPooling1D, AveragePooling1D\n",
        "from keras.preprocessing import sequence\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.utils import np_utils\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "## Sklearn\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "## Rest\n",
        "from scipy.fftpack import fft\n",
        "from scipy import signal\n",
        "from scipy.io import wavfile\n",
        "from tqdm import tqdm\n",
        "\n",
        "input_duration=3\n",
        "# % pylab inline"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "        <script type=\"text/javascript\">\n",
              "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
              "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
              "        if (typeof require !== 'undefined') {\n",
              "        require.undef(\"plotly\");\n",
              "        requirejs.config({\n",
              "            paths: {\n",
              "                'plotly': ['https://cdn.plot.ly/plotly-2.8.3.min']\n",
              "            }\n",
              "        });\n",
              "        require(['plotly'], function(Plotly) {\n",
              "            window._Plotly = Plotly;\n",
              "        });\n",
              "        }\n",
              "        </script>\n",
              "        "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#radvass speech and song\n",
        "import time\n",
        "import os\n",
        "import librosa\n",
        "from librosa import display\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "count=0\n",
        "path1 = '/content/drive/MyDrive/RAVDESS_speech'\n",
        "path2 = '/content/drive/MyDrive/RAVDESS_song'\n",
        "\n",
        "lst = []\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "for subdir, dirs, files in os.walk(path2):\n",
        "  print(dirs)\n",
        "  print(subdir)\n",
        "  #print(files)\n",
        "  for file in files:\n",
        "      try:\n",
        "        count +=1\n",
        "        #Load librosa array, obtain mfcss, store the file and the mcss information in a new array\n",
        "        X, sample_rate = librosa.load(os.path.join(subdir,file), res_type='kaiser_fast')\n",
        "        mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T,axis=0) \n",
        "        # The instruction below converts the labels (from 1 to 8) to a series from 0 to 7\n",
        "        # This is because our predictor needs to start from 0 otherwise it will try to predict also 0.\n",
        "        file = int(file[7:8]) - 1 \n",
        "        arr = mfccs, file\n",
        "        lst.append(arr)\n",
        "      # If the file is not valid, skip it\n",
        "      except ValueError:\n",
        "        continue\n",
        "\n",
        "for subdir, dirs, files in os.walk(path1):\n",
        "  print(dirs)\n",
        "  print(subdir)\n",
        " # print(files)\n",
        "  for file in files:\n",
        "      try:\n",
        "        #Load librosa array, obtain mfcss, store the file and the mcss information in a new array\n",
        "        X, sample_rate = librosa.load(os.path.join(subdir,file), res_type='kaiser_fast')\n",
        "        mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T,axis=0) \n",
        "        # The instruction below converts the labels (from 1 to 8) to a series from 0 to 7\n",
        "        # This is because our predictor needs to start from 0 otherwise it will try to predict also 0.\n",
        "        file = int(file[7:8]) - 1 \n",
        "        if(file ==6 or file==7):\n",
        "          continue\n",
        "        count +=1\n",
        "        arr = mfccs, file\n",
        "        lst.append(arr)\n",
        "      # If the file is not valid, skip it\n",
        "      except ValueError:\n",
        "        continue\n",
        "\n",
        "\n",
        "\n",
        "print(\"--- Data loaded. Loading time: %s seconds ---\" % (time.time() - start_time))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IfuyRZl42ccZ",
        "outputId": "a59d884a-7769-4170-c2de-bf2c8c8d504f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Actor_10', 'Actor_11', 'Actor_13', 'Actor_12', 'Actor_14', 'Actor_15', 'Actor_16', 'Actor_17', 'Actor_18', 'Actor_19', 'Actor_21', 'Actor_22', 'Actor_23', 'Actor_09', 'Actor_24', 'Actor_04', 'Actor_08', 'Actor_03', 'Actor_02', 'Actor_06', 'Actor_05', 'Actor_01', 'Actor_07', 'Actor_20']\n",
            "/content/drive/MyDrive/RAVDESS_song\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_10\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_11\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_13\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_12\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_14\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_15\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_16\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_17\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_18\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_19\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_21\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_22\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_23\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_09\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_24\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_04\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_08\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_03\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_02\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_06\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_05\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_01\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_07\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_20\n",
            "['Actor_05', 'Actor_08', 'Actor_10', 'Actor_04', 'Actor_09', 'Actor_14', 'Actor_12', 'Actor_13', 'Actor_11', 'Actor_06', 'Actor_24', 'Actor_07', 'Actor_23', 'Actor_22', 'Actor_21', 'Actor_20', 'Actor_02', 'Actor_19', 'Actor_18', 'Actor_17', 'Actor_16', 'Actor_15', 'Actor_03', 'Actor_01']\n",
            "/content/drive/MyDrive/RAVDESS_speech\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_05\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_08\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_10\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_04\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_09\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_14\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_12\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_13\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_11\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_06\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_24\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_07\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_23\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_22\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_21\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_20\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_02\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_19\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_18\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_17\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_16\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_15\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_03\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_01\n",
            "--- Data loaded. Loading time: 206.69345927238464 seconds ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "count"
      ],
      "metadata": {
        "id": "Ltlhi25L2AI5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5aa8e5ce-8c69-4b65-d1c9-c1cd27167689"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2068"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy.core.fromnumeric import size\n",
        "size(lst)"
      ],
      "metadata": {
        "id": "HMOH7d7mzHB7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5270302f-0c78-44bf-8a9b-24e1748e1c35"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/core/fromnumeric.py:3208: VisibleDeprecationWarning:\n",
            "\n",
            "Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4136"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating X and y: zip makes a list of all the first elements, and a list of all the second elements.\n",
        "X, y = zip(*lst)"
      ],
      "metadata": {
        "id": "ocdL7tSTBoMt"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "X = np.asarray(X)\n",
        "y = np.asarray(y)\n",
        "X.shape, y.shape"
      ],
      "metadata": {
        "id": "vHKwUGTbBtnF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d2023015-e9bf-4aef-b7d9-d8f15f490fa4"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((2068, 40), (2068,))"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "id": "2sUCtbfMztE5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1eb60bf-d4a7-4022-c1fc-e507c9259f75"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2068, 40)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Saving joblib files to not load them again with the loop above\n",
        "\n",
        "# import joblib\n",
        "\n",
        "# X_name = 'x.joblib'\n",
        "# y_name = 'y.joblib'\n",
        "# save_dir = '/content/drive/My Drive/graduation project/audio/paper_code/features'\n",
        "\n",
        "# savedX = joblib.dump(X, os.path.join(save_dir, X_name))\n",
        "# savedy = joblib.dump(y, os.path.join(save_dir, y_name))"
      ],
      "metadata": {
        "id": "UCzic8rlDcuk"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Loading saved models\n",
        "# import joblib\n",
        "# X = joblib.load('/content/drive/My Drive/graduation project/audio/paper_code/features/x.joblib')\n",
        "# y = joblib.load('/content/drive/My Drive/graduation project/audio/paper_code/features/y.joblib')"
      ],
      "metadata": {
        "id": "Q35CN6zDrzg1"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7PSTurzjCo5K",
        "outputId": "89cb9296-b8a4-4fe8-9586-427b630bad0a"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2068, 40)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2,train_size=0.8, random_state=42)\n",
        "X_valid, X_test, y_valid, y_test = train_test_split(X_test,y_test, test_size=0.5,train_size=0.5, random_state=42)"
      ],
      "metadata": {
        "id": "Ai4Fy5cPCiq1"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "x_traincnn = np.expand_dims(X_train, axis=2)\n",
        "x_testcnn = np.expand_dims(X_test, axis=2)\n",
        "X_valid= np.expand_dims(X_valid, axis=2)"
      ],
      "metadata": {
        "id": "tp1Fm5K3CEXu"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_traincnn.shape, x_testcnn.shape , X_valid.shape"
      ],
      "metadata": {
        "id": "RI0MxoIPBws5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4844d48f-cbb6-401a-a3b0-e3380bc56a76"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1654, 40, 1), (207, 40, 1), (207, 40, 1))"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow"
      ],
      "metadata": {
        "id": "goxL4Y3jKICC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a0c83139-be37-42e8-c56a-dbabaeaee38f"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (2.8.2+zzzcolab20220527125636)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.46.3)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.5.3)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.21.6)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (14.0.1)\n",
            "Requirement already satisfied: tensorflow-estimator<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.17.3)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.26.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (4.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.0.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow) (57.4.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow) (1.5.2)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.4.6)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (3.3.7)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.23.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.6.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.35.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.8.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (4.11.4)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (3.8.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2022.5.18.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (3.2.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keras"
      ],
      "metadata": {
        "id": "EkcmN9UrKSxj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "40416c19-5c0d-46f2-eeba-b8f422b3be95"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.7/dist-packages (2.8.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from keras.preprocessing import sequence\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from keras.layers import Input, Flatten, Dropout, Activation\n",
        "from keras.layers import Conv1D, MaxPooling1D\n",
        "from keras.models import Model\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras import optimizers\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv1D(128, 8,padding='same', #classifier.add(Convolution2D(64, (3, 3), padding = 'same', input_shape = (128, 128, 3), activation = 'relu'))\n",
        "                 input_shape=(40,1)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(MaxPooling1D(pool_size=(5)))\n",
        "\n",
        "\n",
        "model.add(Conv1D(256,8,padding='same',))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(MaxPooling1D(pool_size=(5)))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(256))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(256))\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "model.add(Dense(6))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "opt = tf.keras.optimizers.Adam(lr=0.0002)\n",
        "#opt = tf.keras.optimizers.RMSprop(lr=0.0001, rho=0.9, epsilon=1e-07, decay=0.0)\n",
        "#opt = tf.keras.optimizers.SGD(lr=0.001, momentum=0.0, decay=0.0, nesterov=False)"
      ],
      "metadata": {
        "id": "g74fXWVAC4Cr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "021897f2-4e76-4ba1-b376-72e1cd92c1f7"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning:\n",
            "\n",
            "The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H6ukOxAGC_I4",
        "outputId": "330b217a-05a3-49f6-f537-530f5f9b6b35"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d (Conv1D)             (None, 40, 128)           1152      \n",
            "                                                                 \n",
            " activation (Activation)     (None, 40, 128)           0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 40, 128)           0         \n",
            "                                                                 \n",
            " max_pooling1d (MaxPooling1D  (None, 8, 128)           0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv1d_1 (Conv1D)           (None, 8, 256)            262400    \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 8, 256)            0         \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 8, 256)            0         \n",
            "                                                                 \n",
            " max_pooling1d_1 (MaxPooling  (None, 1, 256)           0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 256)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 256)               65792     \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 256)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 256)               65792     \n",
            "                                                                 \n",
            " activation_3 (Activation)   (None, 256)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 6)                 1542      \n",
            "                                                                 \n",
            " activation_4 (Activation)   (None, 6)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 396,678\n",
            "Trainable params: 396,678\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='sparse_categorical_crossentropy',\n",
        "              optimizer=opt,\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "AbMlLNk4DCBM"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#cnnhistory=model.fit(x_traincnn, y_train, batch_size=16, epochs=700, validation_data=(x_testcnn, y_test))\n",
        "cnnhistory=model.fit(x_traincnn, y_train, batch_size=16, epochs=500 , validation_data=(X_valid, y_valid))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RI1v2AuADFhy",
        "outputId": "3d949747-0d39-4b22-8ca8-123e1d4fca02"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "104/104 [==============================] - 4s 11ms/step - loss: 4.2674 - accuracy: 0.1620 - val_loss: 1.8118 - val_accuracy: 0.2367\n",
            "Epoch 2/500\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 2.5429 - accuracy: 0.1971 - val_loss: 1.7372 - val_accuracy: 0.2271\n",
            "Epoch 3/500\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 2.1849 - accuracy: 0.2116 - val_loss: 1.8135 - val_accuracy: 0.1981\n",
            "Epoch 4/500\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 1.9965 - accuracy: 0.2177 - val_loss: 1.7106 - val_accuracy: 0.2705\n",
            "Epoch 5/500\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 1.9519 - accuracy: 0.2177 - val_loss: 1.7590 - val_accuracy: 0.1981\n",
            "Epoch 6/500\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 1.8632 - accuracy: 0.2116 - val_loss: 1.6776 - val_accuracy: 0.2754\n",
            "Epoch 7/500\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 1.8287 - accuracy: 0.2449 - val_loss: 1.6898 - val_accuracy: 0.2222\n",
            "Epoch 8/500\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 1.7900 - accuracy: 0.2430 - val_loss: 1.6193 - val_accuracy: 0.3478\n",
            "Epoch 9/500\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 1.7878 - accuracy: 0.2418 - val_loss: 1.6908 - val_accuracy: 0.2947\n",
            "Epoch 10/500\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 1.7350 - accuracy: 0.2666 - val_loss: 1.6255 - val_accuracy: 0.3092\n",
            "Epoch 11/500\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 1.7143 - accuracy: 0.2672 - val_loss: 1.6153 - val_accuracy: 0.3382\n",
            "Epoch 12/500\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 1.6884 - accuracy: 0.2926 - val_loss: 1.6016 - val_accuracy: 0.3720\n",
            "Epoch 13/500\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 1.7004 - accuracy: 0.2842 - val_loss: 1.6511 - val_accuracy: 0.3237\n",
            "Epoch 14/500\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 1.6231 - accuracy: 0.3247 - val_loss: 1.5563 - val_accuracy: 0.3768\n",
            "Epoch 15/500\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 1.6247 - accuracy: 0.3210 - val_loss: 1.6840 - val_accuracy: 0.2802\n",
            "Epoch 16/500\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 1.6055 - accuracy: 0.3259 - val_loss: 1.5306 - val_accuracy: 0.4010\n",
            "Epoch 17/500\n",
            "104/104 [==============================] - 1s 9ms/step - loss: 1.5805 - accuracy: 0.3470 - val_loss: 1.5801 - val_accuracy: 0.3333\n",
            "Epoch 18/500\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 1.5739 - accuracy: 0.3470 - val_loss: 1.4972 - val_accuracy: 0.4251\n",
            "Epoch 19/500\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 1.5390 - accuracy: 0.3573 - val_loss: 1.4854 - val_accuracy: 0.4010\n",
            "Epoch 20/500\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 1.4908 - accuracy: 0.3900 - val_loss: 1.4518 - val_accuracy: 0.4203\n",
            "Epoch 21/500\n",
            "104/104 [==============================] - 1s 9ms/step - loss: 1.4714 - accuracy: 0.3978 - val_loss: 1.3588 - val_accuracy: 0.4493\n",
            "Epoch 22/500\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 1.4456 - accuracy: 0.4063 - val_loss: 1.4015 - val_accuracy: 0.4251\n",
            "Epoch 23/500\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 1.4221 - accuracy: 0.4093 - val_loss: 1.3445 - val_accuracy: 0.4541\n",
            "Epoch 24/500\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 1.3870 - accuracy: 0.4202 - val_loss: 1.2868 - val_accuracy: 0.4928\n",
            "Epoch 25/500\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 1.3557 - accuracy: 0.4341 - val_loss: 1.2690 - val_accuracy: 0.5556\n",
            "Epoch 26/500\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 1.3508 - accuracy: 0.4407 - val_loss: 1.2556 - val_accuracy: 0.5459\n",
            "Epoch 27/500\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 1.3069 - accuracy: 0.4619 - val_loss: 1.2166 - val_accuracy: 0.5749\n",
            "Epoch 28/500\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 1.2689 - accuracy: 0.4740 - val_loss: 1.1916 - val_accuracy: 0.5604\n",
            "Epoch 29/500\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 1.2648 - accuracy: 0.4770 - val_loss: 1.2089 - val_accuracy: 0.5459\n",
            "Epoch 30/500\n",
            "104/104 [==============================] - 1s 9ms/step - loss: 1.2487 - accuracy: 0.4891 - val_loss: 1.2132 - val_accuracy: 0.5024\n",
            "Epoch 31/500\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 1.2476 - accuracy: 0.4885 - val_loss: 1.1837 - val_accuracy: 0.5556\n",
            "Epoch 32/500\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 1.2183 - accuracy: 0.5012 - val_loss: 1.1604 - val_accuracy: 0.5845\n",
            "Epoch 33/500\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 1.1902 - accuracy: 0.5115 - val_loss: 1.1439 - val_accuracy: 0.5507\n",
            "Epoch 34/500\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 1.1740 - accuracy: 0.5079 - val_loss: 1.0819 - val_accuracy: 0.5845\n",
            "Epoch 35/500\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 1.1604 - accuracy: 0.5242 - val_loss: 1.0539 - val_accuracy: 0.6280\n",
            "Epoch 36/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 1.1391 - accuracy: 0.5357 - val_loss: 1.0722 - val_accuracy: 0.5894\n",
            "Epoch 37/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.1048 - accuracy: 0.5520 - val_loss: 1.0442 - val_accuracy: 0.6184\n",
            "Epoch 38/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.1182 - accuracy: 0.5399 - val_loss: 1.0783 - val_accuracy: 0.6087\n",
            "Epoch 39/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.1072 - accuracy: 0.5417 - val_loss: 1.0824 - val_accuracy: 0.5700\n",
            "Epoch 40/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0912 - accuracy: 0.5484 - val_loss: 1.0759 - val_accuracy: 0.5700\n",
            "Epoch 41/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.0628 - accuracy: 0.5653 - val_loss: 1.0369 - val_accuracy: 0.6039\n",
            "Epoch 42/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0606 - accuracy: 0.5574 - val_loss: 1.0048 - val_accuracy: 0.6473\n",
            "Epoch 43/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.0476 - accuracy: 0.5768 - val_loss: 1.0275 - val_accuracy: 0.6280\n",
            "Epoch 44/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.0274 - accuracy: 0.5780 - val_loss: 0.9518 - val_accuracy: 0.6763\n",
            "Epoch 45/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0243 - accuracy: 0.5804 - val_loss: 0.9783 - val_accuracy: 0.6377\n",
            "Epoch 46/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0125 - accuracy: 0.5901 - val_loss: 0.9717 - val_accuracy: 0.5990\n",
            "Epoch 47/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0094 - accuracy: 0.5810 - val_loss: 0.9933 - val_accuracy: 0.6667\n",
            "Epoch 48/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.9832 - accuracy: 0.6052 - val_loss: 0.9949 - val_accuracy: 0.6232\n",
            "Epoch 49/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9927 - accuracy: 0.5955 - val_loss: 0.9392 - val_accuracy: 0.6184\n",
            "Epoch 50/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.9668 - accuracy: 0.6155 - val_loss: 0.9471 - val_accuracy: 0.6184\n",
            "Epoch 51/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.9561 - accuracy: 0.6070 - val_loss: 0.9748 - val_accuracy: 0.5894\n",
            "Epoch 52/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9542 - accuracy: 0.5937 - val_loss: 0.9032 - val_accuracy: 0.6570\n",
            "Epoch 53/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9352 - accuracy: 0.6155 - val_loss: 0.9324 - val_accuracy: 0.6329\n",
            "Epoch 54/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.9242 - accuracy: 0.6197 - val_loss: 0.9595 - val_accuracy: 0.6232\n",
            "Epoch 55/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.9023 - accuracy: 0.6294 - val_loss: 0.9342 - val_accuracy: 0.6232\n",
            "Epoch 56/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.9161 - accuracy: 0.6143 - val_loss: 0.9244 - val_accuracy: 0.6377\n",
            "Epoch 57/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8991 - accuracy: 0.6318 - val_loss: 0.8871 - val_accuracy: 0.6473\n",
            "Epoch 58/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.9006 - accuracy: 0.6511 - val_loss: 0.8975 - val_accuracy: 0.6860\n",
            "Epoch 59/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8768 - accuracy: 0.6451 - val_loss: 0.9035 - val_accuracy: 0.6184\n",
            "Epoch 60/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.8765 - accuracy: 0.6415 - val_loss: 0.9293 - val_accuracy: 0.6039\n",
            "Epoch 61/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8704 - accuracy: 0.6403 - val_loss: 0.8775 - val_accuracy: 0.6473\n",
            "Epoch 62/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.8685 - accuracy: 0.6554 - val_loss: 0.9039 - val_accuracy: 0.6473\n",
            "Epoch 63/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.8377 - accuracy: 0.6735 - val_loss: 0.8502 - val_accuracy: 0.6812\n",
            "Epoch 64/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8200 - accuracy: 0.6669 - val_loss: 0.8617 - val_accuracy: 0.6570\n",
            "Epoch 65/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.7904 - accuracy: 0.6838 - val_loss: 0.8480 - val_accuracy: 0.6522\n",
            "Epoch 66/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8293 - accuracy: 0.6699 - val_loss: 0.8625 - val_accuracy: 0.6473\n",
            "Epoch 67/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8120 - accuracy: 0.6735 - val_loss: 0.8379 - val_accuracy: 0.6618\n",
            "Epoch 68/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.8010 - accuracy: 0.6862 - val_loss: 0.8371 - val_accuracy: 0.6715\n",
            "Epoch 69/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.7938 - accuracy: 0.6741 - val_loss: 0.8263 - val_accuracy: 0.7005\n",
            "Epoch 70/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.7921 - accuracy: 0.6802 - val_loss: 0.8303 - val_accuracy: 0.6812\n",
            "Epoch 71/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7813 - accuracy: 0.6929 - val_loss: 0.8369 - val_accuracy: 0.6522\n",
            "Epoch 72/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7922 - accuracy: 0.6977 - val_loss: 0.8393 - val_accuracy: 0.6763\n",
            "Epoch 73/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.7742 - accuracy: 0.7013 - val_loss: 0.8012 - val_accuracy: 0.7053\n",
            "Epoch 74/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7708 - accuracy: 0.6959 - val_loss: 0.8458 - val_accuracy: 0.6522\n",
            "Epoch 75/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7542 - accuracy: 0.6838 - val_loss: 0.8112 - val_accuracy: 0.6763\n",
            "Epoch 76/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7319 - accuracy: 0.7110 - val_loss: 0.8147 - val_accuracy: 0.7101\n",
            "Epoch 77/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7388 - accuracy: 0.7001 - val_loss: 0.7869 - val_accuracy: 0.7198\n",
            "Epoch 78/500\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.6943 - accuracy: 0.7340 - val_loss: 0.8127 - val_accuracy: 0.6957\n",
            "Epoch 79/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.7276 - accuracy: 0.7098 - val_loss: 0.7867 - val_accuracy: 0.6908\n",
            "Epoch 80/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.7211 - accuracy: 0.7092 - val_loss: 0.8064 - val_accuracy: 0.6908\n",
            "Epoch 81/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.7077 - accuracy: 0.7056 - val_loss: 0.8271 - val_accuracy: 0.6667\n",
            "Epoch 82/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.6863 - accuracy: 0.7322 - val_loss: 0.7765 - val_accuracy: 0.7198\n",
            "Epoch 83/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6677 - accuracy: 0.7322 - val_loss: 0.7698 - val_accuracy: 0.7343\n",
            "Epoch 84/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.7118 - accuracy: 0.7025 - val_loss: 0.7837 - val_accuracy: 0.7005\n",
            "Epoch 85/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.6786 - accuracy: 0.7370 - val_loss: 0.8293 - val_accuracy: 0.6329\n",
            "Epoch 86/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.6613 - accuracy: 0.7346 - val_loss: 0.7581 - val_accuracy: 0.7391\n",
            "Epoch 87/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.6754 - accuracy: 0.7231 - val_loss: 0.7802 - val_accuracy: 0.6957\n",
            "Epoch 88/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.6328 - accuracy: 0.7551 - val_loss: 0.7952 - val_accuracy: 0.7005\n",
            "Epoch 89/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.6217 - accuracy: 0.7424 - val_loss: 0.7322 - val_accuracy: 0.7343\n",
            "Epoch 90/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.6332 - accuracy: 0.7388 - val_loss: 0.7907 - val_accuracy: 0.7005\n",
            "Epoch 91/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.6320 - accuracy: 0.7400 - val_loss: 0.8048 - val_accuracy: 0.6908\n",
            "Epoch 92/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6268 - accuracy: 0.7570 - val_loss: 0.7670 - val_accuracy: 0.7005\n",
            "Epoch 93/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.6400 - accuracy: 0.7473 - val_loss: 0.7437 - val_accuracy: 0.7198\n",
            "Epoch 94/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.6067 - accuracy: 0.7672 - val_loss: 0.7275 - val_accuracy: 0.7101\n",
            "Epoch 95/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6024 - accuracy: 0.7612 - val_loss: 0.7442 - val_accuracy: 0.7198\n",
            "Epoch 96/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.5888 - accuracy: 0.7654 - val_loss: 0.8142 - val_accuracy: 0.6618\n",
            "Epoch 97/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.6125 - accuracy: 0.7479 - val_loss: 0.7466 - val_accuracy: 0.6618\n",
            "Epoch 98/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.5887 - accuracy: 0.7618 - val_loss: 0.7901 - val_accuracy: 0.6570\n",
            "Epoch 99/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.5551 - accuracy: 0.7763 - val_loss: 0.7316 - val_accuracy: 0.7246\n",
            "Epoch 100/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.5857 - accuracy: 0.7703 - val_loss: 0.7729 - val_accuracy: 0.6715\n",
            "Epoch 101/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.5843 - accuracy: 0.7612 - val_loss: 0.7141 - val_accuracy: 0.7246\n",
            "Epoch 102/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.5733 - accuracy: 0.7642 - val_loss: 0.7262 - val_accuracy: 0.6812\n",
            "Epoch 103/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.5555 - accuracy: 0.7787 - val_loss: 0.7645 - val_accuracy: 0.6522\n",
            "Epoch 104/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.5655 - accuracy: 0.7793 - val_loss: 0.7434 - val_accuracy: 0.6957\n",
            "Epoch 105/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.5481 - accuracy: 0.7842 - val_loss: 0.7127 - val_accuracy: 0.6860\n",
            "Epoch 106/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.5589 - accuracy: 0.7854 - val_loss: 0.7848 - val_accuracy: 0.6618\n",
            "Epoch 107/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5334 - accuracy: 0.7848 - val_loss: 0.7601 - val_accuracy: 0.6860\n",
            "Epoch 108/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.5542 - accuracy: 0.7811 - val_loss: 0.7523 - val_accuracy: 0.6715\n",
            "Epoch 109/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.5300 - accuracy: 0.7908 - val_loss: 0.6868 - val_accuracy: 0.7053\n",
            "Epoch 110/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.5223 - accuracy: 0.7987 - val_loss: 0.7133 - val_accuracy: 0.7198\n",
            "Epoch 111/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.5282 - accuracy: 0.7860 - val_loss: 0.7392 - val_accuracy: 0.7246\n",
            "Epoch 112/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.4757 - accuracy: 0.8083 - val_loss: 0.7658 - val_accuracy: 0.6715\n",
            "Epoch 113/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5300 - accuracy: 0.7854 - val_loss: 0.7392 - val_accuracy: 0.7005\n",
            "Epoch 114/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4985 - accuracy: 0.8059 - val_loss: 0.7160 - val_accuracy: 0.7053\n",
            "Epoch 115/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.5087 - accuracy: 0.7969 - val_loss: 0.7417 - val_accuracy: 0.7150\n",
            "Epoch 116/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.4746 - accuracy: 0.8102 - val_loss: 0.6913 - val_accuracy: 0.7488\n",
            "Epoch 117/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.4564 - accuracy: 0.8210 - val_loss: 0.7444 - val_accuracy: 0.6812\n",
            "Epoch 118/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.4747 - accuracy: 0.8023 - val_loss: 0.7210 - val_accuracy: 0.7005\n",
            "Epoch 119/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.4638 - accuracy: 0.8138 - val_loss: 0.7383 - val_accuracy: 0.7150\n",
            "Epoch 120/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.4971 - accuracy: 0.8023 - val_loss: 0.6899 - val_accuracy: 0.7488\n",
            "Epoch 121/500\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 0.4427 - accuracy: 0.8210 - val_loss: 0.7312 - val_accuracy: 0.7198\n",
            "Epoch 122/500\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.4912 - accuracy: 0.8102 - val_loss: 0.7150 - val_accuracy: 0.7633\n",
            "Epoch 123/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4430 - accuracy: 0.8174 - val_loss: 0.7292 - val_accuracy: 0.6957\n",
            "Epoch 124/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.4601 - accuracy: 0.8180 - val_loss: 0.7224 - val_accuracy: 0.7440\n",
            "Epoch 125/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.4534 - accuracy: 0.8186 - val_loss: 0.7067 - val_accuracy: 0.7246\n",
            "Epoch 126/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.4294 - accuracy: 0.8277 - val_loss: 0.6722 - val_accuracy: 0.7295\n",
            "Epoch 127/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.4553 - accuracy: 0.8192 - val_loss: 0.6900 - val_accuracy: 0.7198\n",
            "Epoch 128/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.4283 - accuracy: 0.8216 - val_loss: 0.7418 - val_accuracy: 0.6812\n",
            "Epoch 129/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.4218 - accuracy: 0.8343 - val_loss: 0.7001 - val_accuracy: 0.7343\n",
            "Epoch 130/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.4251 - accuracy: 0.8331 - val_loss: 0.7042 - val_accuracy: 0.7150\n",
            "Epoch 131/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4140 - accuracy: 0.8337 - val_loss: 0.7170 - val_accuracy: 0.7246\n",
            "Epoch 132/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.4214 - accuracy: 0.8434 - val_loss: 0.6608 - val_accuracy: 0.7778\n",
            "Epoch 133/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.3921 - accuracy: 0.8495 - val_loss: 0.6830 - val_accuracy: 0.7440\n",
            "Epoch 134/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.4437 - accuracy: 0.8229 - val_loss: 0.6803 - val_accuracy: 0.7343\n",
            "Epoch 135/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.4119 - accuracy: 0.8458 - val_loss: 0.6879 - val_accuracy: 0.7536\n",
            "Epoch 136/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.4007 - accuracy: 0.8452 - val_loss: 0.7051 - val_accuracy: 0.7440\n",
            "Epoch 137/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.3862 - accuracy: 0.8585 - val_loss: 0.6928 - val_accuracy: 0.7391\n",
            "Epoch 138/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.4123 - accuracy: 0.8410 - val_loss: 0.7170 - val_accuracy: 0.7391\n",
            "Epoch 139/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.3845 - accuracy: 0.8392 - val_loss: 0.7341 - val_accuracy: 0.7101\n",
            "Epoch 140/500\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.3775 - accuracy: 0.8561 - val_loss: 0.6818 - val_accuracy: 0.7536\n",
            "Epoch 141/500\n",
            "104/104 [==============================] - 1s 9ms/step - loss: 0.3766 - accuracy: 0.8555 - val_loss: 0.6891 - val_accuracy: 0.7005\n",
            "Epoch 142/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.4013 - accuracy: 0.8446 - val_loss: 0.7117 - val_accuracy: 0.7101\n",
            "Epoch 143/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.3729 - accuracy: 0.8555 - val_loss: 0.7010 - val_accuracy: 0.7391\n",
            "Epoch 144/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3849 - accuracy: 0.8507 - val_loss: 0.6530 - val_accuracy: 0.7633\n",
            "Epoch 145/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.3431 - accuracy: 0.8646 - val_loss: 0.6662 - val_accuracy: 0.7198\n",
            "Epoch 146/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3460 - accuracy: 0.8622 - val_loss: 0.6777 - val_accuracy: 0.7440\n",
            "Epoch 147/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.3373 - accuracy: 0.8718 - val_loss: 0.6579 - val_accuracy: 0.7633\n",
            "Epoch 148/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.3310 - accuracy: 0.8694 - val_loss: 0.6635 - val_accuracy: 0.7681\n",
            "Epoch 149/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.3391 - accuracy: 0.8742 - val_loss: 0.6842 - val_accuracy: 0.7633\n",
            "Epoch 150/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.3512 - accuracy: 0.8603 - val_loss: 0.6913 - val_accuracy: 0.7778\n",
            "Epoch 151/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.3377 - accuracy: 0.8712 - val_loss: 0.6513 - val_accuracy: 0.7874\n",
            "Epoch 152/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.3462 - accuracy: 0.8700 - val_loss: 0.6715 - val_accuracy: 0.7633\n",
            "Epoch 153/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.3087 - accuracy: 0.8845 - val_loss: 0.6500 - val_accuracy: 0.7633\n",
            "Epoch 154/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.3570 - accuracy: 0.8664 - val_loss: 0.6549 - val_accuracy: 0.7440\n",
            "Epoch 155/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.3215 - accuracy: 0.8797 - val_loss: 0.6500 - val_accuracy: 0.7826\n",
            "Epoch 156/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.3140 - accuracy: 0.8761 - val_loss: 0.6132 - val_accuracy: 0.7971\n",
            "Epoch 157/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3613 - accuracy: 0.8634 - val_loss: 0.6791 - val_accuracy: 0.7729\n",
            "Epoch 158/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.3159 - accuracy: 0.8706 - val_loss: 0.6357 - val_accuracy: 0.7681\n",
            "Epoch 159/500\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 0.3337 - accuracy: 0.8730 - val_loss: 0.6616 - val_accuracy: 0.7681\n",
            "Epoch 160/500\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 0.3058 - accuracy: 0.8791 - val_loss: 0.6551 - val_accuracy: 0.7488\n",
            "Epoch 161/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.2915 - accuracy: 0.8863 - val_loss: 0.6230 - val_accuracy: 0.7633\n",
            "Epoch 162/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.3081 - accuracy: 0.8851 - val_loss: 0.6476 - val_accuracy: 0.8213\n",
            "Epoch 163/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2988 - accuracy: 0.8875 - val_loss: 0.6507 - val_accuracy: 0.7391\n",
            "Epoch 164/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.3115 - accuracy: 0.8785 - val_loss: 0.6969 - val_accuracy: 0.7440\n",
            "Epoch 165/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2827 - accuracy: 0.8960 - val_loss: 0.6219 - val_accuracy: 0.7923\n",
            "Epoch 166/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2906 - accuracy: 0.8815 - val_loss: 0.6317 - val_accuracy: 0.7971\n",
            "Epoch 167/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.2882 - accuracy: 0.8924 - val_loss: 0.6952 - val_accuracy: 0.7536\n",
            "Epoch 168/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.3082 - accuracy: 0.8821 - val_loss: 0.6544 - val_accuracy: 0.7681\n",
            "Epoch 169/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.2688 - accuracy: 0.8960 - val_loss: 0.7024 - val_accuracy: 0.7585\n",
            "Epoch 170/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.2877 - accuracy: 0.9002 - val_loss: 0.6808 - val_accuracy: 0.7585\n",
            "Epoch 171/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.2821 - accuracy: 0.8984 - val_loss: 0.6596 - val_accuracy: 0.7778\n",
            "Epoch 172/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.3007 - accuracy: 0.8839 - val_loss: 0.6539 - val_accuracy: 0.7729\n",
            "Epoch 173/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.2792 - accuracy: 0.8930 - val_loss: 0.6769 - val_accuracy: 0.7488\n",
            "Epoch 174/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.2522 - accuracy: 0.9099 - val_loss: 0.6558 - val_accuracy: 0.7826\n",
            "Epoch 175/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.2807 - accuracy: 0.8990 - val_loss: 0.6824 - val_accuracy: 0.7681\n",
            "Epoch 176/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.2826 - accuracy: 0.8900 - val_loss: 0.6262 - val_accuracy: 0.7874\n",
            "Epoch 177/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.2520 - accuracy: 0.9063 - val_loss: 0.6969 - val_accuracy: 0.7536\n",
            "Epoch 178/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.2811 - accuracy: 0.8900 - val_loss: 0.7335 - val_accuracy: 0.7633\n",
            "Epoch 179/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.2813 - accuracy: 0.8990 - val_loss: 0.6594 - val_accuracy: 0.7681\n",
            "Epoch 180/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.2911 - accuracy: 0.8978 - val_loss: 0.6298 - val_accuracy: 0.7536\n",
            "Epoch 181/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.2427 - accuracy: 0.9027 - val_loss: 0.6412 - val_accuracy: 0.7633\n",
            "Epoch 182/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.2533 - accuracy: 0.9117 - val_loss: 0.6462 - val_accuracy: 0.7633\n",
            "Epoch 183/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.2484 - accuracy: 0.9045 - val_loss: 0.6324 - val_accuracy: 0.7585\n",
            "Epoch 184/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.2465 - accuracy: 0.9099 - val_loss: 0.6877 - val_accuracy: 0.7778\n",
            "Epoch 185/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2460 - accuracy: 0.9039 - val_loss: 0.7059 - val_accuracy: 0.7391\n",
            "Epoch 186/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.2558 - accuracy: 0.8990 - val_loss: 0.6941 - val_accuracy: 0.7440\n",
            "Epoch 187/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.2651 - accuracy: 0.8990 - val_loss: 0.6275 - val_accuracy: 0.7778\n",
            "Epoch 188/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.2497 - accuracy: 0.9075 - val_loss: 0.6086 - val_accuracy: 0.8019\n",
            "Epoch 189/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.2232 - accuracy: 0.9172 - val_loss: 0.6576 - val_accuracy: 0.7585\n",
            "Epoch 190/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.2310 - accuracy: 0.9063 - val_loss: 0.6907 - val_accuracy: 0.7246\n",
            "Epoch 191/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.2445 - accuracy: 0.9075 - val_loss: 0.6820 - val_accuracy: 0.7488\n",
            "Epoch 192/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.2252 - accuracy: 0.9172 - val_loss: 0.6698 - val_accuracy: 0.7536\n",
            "Epoch 193/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2590 - accuracy: 0.9069 - val_loss: 0.6477 - val_accuracy: 0.7729\n",
            "Epoch 194/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.2227 - accuracy: 0.9087 - val_loss: 0.6825 - val_accuracy: 0.7874\n",
            "Epoch 195/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.2179 - accuracy: 0.9166 - val_loss: 0.6703 - val_accuracy: 0.7536\n",
            "Epoch 196/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.2260 - accuracy: 0.9184 - val_loss: 0.6360 - val_accuracy: 0.7874\n",
            "Epoch 197/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.2029 - accuracy: 0.9208 - val_loss: 0.6354 - val_accuracy: 0.7585\n",
            "Epoch 198/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2101 - accuracy: 0.9202 - val_loss: 0.6610 - val_accuracy: 0.7488\n",
            "Epoch 199/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.2004 - accuracy: 0.9208 - val_loss: 0.5900 - val_accuracy: 0.7874\n",
            "Epoch 200/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2230 - accuracy: 0.9111 - val_loss: 0.6451 - val_accuracy: 0.7729\n",
            "Epoch 201/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.2272 - accuracy: 0.9105 - val_loss: 0.6387 - val_accuracy: 0.7681\n",
            "Epoch 202/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.2487 - accuracy: 0.9111 - val_loss: 0.6272 - val_accuracy: 0.7536\n",
            "Epoch 203/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.2069 - accuracy: 0.9232 - val_loss: 0.6550 - val_accuracy: 0.7391\n",
            "Epoch 204/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1939 - accuracy: 0.9256 - val_loss: 0.6423 - val_accuracy: 0.7633\n",
            "Epoch 205/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2085 - accuracy: 0.9274 - val_loss: 0.6560 - val_accuracy: 0.7874\n",
            "Epoch 206/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2044 - accuracy: 0.9202 - val_loss: 0.6758 - val_accuracy: 0.7633\n",
            "Epoch 207/500\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.2131 - accuracy: 0.9141 - val_loss: 0.6822 - val_accuracy: 0.7681\n",
            "Epoch 208/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2324 - accuracy: 0.9117 - val_loss: 0.5971 - val_accuracy: 0.7971\n",
            "Epoch 209/500\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.2062 - accuracy: 0.9220 - val_loss: 0.6068 - val_accuracy: 0.8019\n",
            "Epoch 210/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2004 - accuracy: 0.9196 - val_loss: 0.6633 - val_accuracy: 0.7778\n",
            "Epoch 211/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.1974 - accuracy: 0.9293 - val_loss: 0.6225 - val_accuracy: 0.7874\n",
            "Epoch 212/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.2118 - accuracy: 0.9226 - val_loss: 0.6750 - val_accuracy: 0.7874\n",
            "Epoch 213/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.2108 - accuracy: 0.9214 - val_loss: 0.6641 - val_accuracy: 0.7778\n",
            "Epoch 214/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.1754 - accuracy: 0.9395 - val_loss: 0.6749 - val_accuracy: 0.7585\n",
            "Epoch 215/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.2005 - accuracy: 0.9226 - val_loss: 0.6671 - val_accuracy: 0.7778\n",
            "Epoch 216/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2001 - accuracy: 0.9202 - val_loss: 0.6990 - val_accuracy: 0.7729\n",
            "Epoch 217/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.1963 - accuracy: 0.9287 - val_loss: 0.6612 - val_accuracy: 0.7778\n",
            "Epoch 218/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.1857 - accuracy: 0.9323 - val_loss: 0.6721 - val_accuracy: 0.7729\n",
            "Epoch 219/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.1914 - accuracy: 0.9299 - val_loss: 0.6281 - val_accuracy: 0.7923\n",
            "Epoch 220/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2085 - accuracy: 0.9262 - val_loss: 0.6297 - val_accuracy: 0.8019\n",
            "Epoch 221/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.1737 - accuracy: 0.9371 - val_loss: 0.7178 - val_accuracy: 0.7391\n",
            "Epoch 222/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.2229 - accuracy: 0.9214 - val_loss: 0.6359 - val_accuracy: 0.7923\n",
            "Epoch 223/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.1791 - accuracy: 0.9329 - val_loss: 0.6320 - val_accuracy: 0.7874\n",
            "Epoch 224/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.1981 - accuracy: 0.9305 - val_loss: 0.6783 - val_accuracy: 0.7971\n",
            "Epoch 225/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.1609 - accuracy: 0.9353 - val_loss: 0.6781 - val_accuracy: 0.7633\n",
            "Epoch 226/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.1834 - accuracy: 0.9299 - val_loss: 0.6815 - val_accuracy: 0.7826\n",
            "Epoch 227/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.2187 - accuracy: 0.9178 - val_loss: 0.6991 - val_accuracy: 0.7633\n",
            "Epoch 228/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1792 - accuracy: 0.9311 - val_loss: 0.6755 - val_accuracy: 0.7778\n",
            "Epoch 229/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1968 - accuracy: 0.9268 - val_loss: 0.6213 - val_accuracy: 0.7826\n",
            "Epoch 230/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.1621 - accuracy: 0.9414 - val_loss: 0.6481 - val_accuracy: 0.7681\n",
            "Epoch 231/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1625 - accuracy: 0.9395 - val_loss: 0.7136 - val_accuracy: 0.7536\n",
            "Epoch 232/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.1727 - accuracy: 0.9420 - val_loss: 0.7025 - val_accuracy: 0.7729\n",
            "Epoch 233/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.2185 - accuracy: 0.9244 - val_loss: 0.6886 - val_accuracy: 0.7681\n",
            "Epoch 234/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.1850 - accuracy: 0.9335 - val_loss: 0.6797 - val_accuracy: 0.7826\n",
            "Epoch 235/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1712 - accuracy: 0.9395 - val_loss: 0.6906 - val_accuracy: 0.7681\n",
            "Epoch 236/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.1792 - accuracy: 0.9305 - val_loss: 0.6932 - val_accuracy: 0.7488\n",
            "Epoch 237/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.1811 - accuracy: 0.9317 - val_loss: 0.6703 - val_accuracy: 0.7971\n",
            "Epoch 238/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.1571 - accuracy: 0.9486 - val_loss: 0.7148 - val_accuracy: 0.7778\n",
            "Epoch 239/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.1685 - accuracy: 0.9395 - val_loss: 0.7287 - val_accuracy: 0.7343\n",
            "Epoch 240/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.1670 - accuracy: 0.9371 - val_loss: 0.6689 - val_accuracy: 0.7826\n",
            "Epoch 241/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.1310 - accuracy: 0.9589 - val_loss: 0.7062 - val_accuracy: 0.7778\n",
            "Epoch 242/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.1820 - accuracy: 0.9311 - val_loss: 0.7045 - val_accuracy: 0.7874\n",
            "Epoch 243/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.1357 - accuracy: 0.9492 - val_loss: 0.7804 - val_accuracy: 0.7729\n",
            "Epoch 244/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.1569 - accuracy: 0.9407 - val_loss: 0.7038 - val_accuracy: 0.7826\n",
            "Epoch 245/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1666 - accuracy: 0.9341 - val_loss: 0.6858 - val_accuracy: 0.7585\n",
            "Epoch 246/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.1664 - accuracy: 0.9426 - val_loss: 0.6568 - val_accuracy: 0.7729\n",
            "Epoch 247/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.1808 - accuracy: 0.9305 - val_loss: 0.6821 - val_accuracy: 0.7826\n",
            "Epoch 248/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.1692 - accuracy: 0.9383 - val_loss: 0.6938 - val_accuracy: 0.7536\n",
            "Epoch 249/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.1947 - accuracy: 0.9323 - val_loss: 0.6957 - val_accuracy: 0.7681\n",
            "Epoch 250/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.1865 - accuracy: 0.9341 - val_loss: 0.6600 - val_accuracy: 0.7923\n",
            "Epoch 251/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.1617 - accuracy: 0.9359 - val_loss: 0.6398 - val_accuracy: 0.7971\n",
            "Epoch 252/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.1465 - accuracy: 0.9462 - val_loss: 0.7031 - val_accuracy: 0.7536\n",
            "Epoch 253/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.1480 - accuracy: 0.9486 - val_loss: 0.7189 - val_accuracy: 0.7585\n",
            "Epoch 254/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.1348 - accuracy: 0.9528 - val_loss: 0.6878 - val_accuracy: 0.7681\n",
            "Epoch 255/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.1356 - accuracy: 0.9504 - val_loss: 0.6817 - val_accuracy: 0.8116\n",
            "Epoch 256/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1408 - accuracy: 0.9426 - val_loss: 0.6655 - val_accuracy: 0.7681\n",
            "Epoch 257/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.1397 - accuracy: 0.9510 - val_loss: 0.6752 - val_accuracy: 0.7585\n",
            "Epoch 258/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1263 - accuracy: 0.9528 - val_loss: 0.7616 - val_accuracy: 0.7391\n",
            "Epoch 259/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1322 - accuracy: 0.9547 - val_loss: 0.6730 - val_accuracy: 0.7633\n",
            "Epoch 260/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.1726 - accuracy: 0.9353 - val_loss: 0.6773 - val_accuracy: 0.7729\n",
            "Epoch 261/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1545 - accuracy: 0.9407 - val_loss: 0.6812 - val_accuracy: 0.7681\n",
            "Epoch 262/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.1444 - accuracy: 0.9468 - val_loss: 0.6590 - val_accuracy: 0.7729\n",
            "Epoch 263/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1711 - accuracy: 0.9329 - val_loss: 0.7742 - val_accuracy: 0.7729\n",
            "Epoch 264/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1639 - accuracy: 0.9395 - val_loss: 0.7206 - val_accuracy: 0.7633\n",
            "Epoch 265/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1598 - accuracy: 0.9377 - val_loss: 0.7342 - val_accuracy: 0.7536\n",
            "Epoch 266/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.1398 - accuracy: 0.9444 - val_loss: 0.6491 - val_accuracy: 0.7923\n",
            "Epoch 267/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.1786 - accuracy: 0.9347 - val_loss: 0.7329 - val_accuracy: 0.7923\n",
            "Epoch 268/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1230 - accuracy: 0.9595 - val_loss: 0.7395 - val_accuracy: 0.7585\n",
            "Epoch 269/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1293 - accuracy: 0.9486 - val_loss: 0.6773 - val_accuracy: 0.7778\n",
            "Epoch 270/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1486 - accuracy: 0.9444 - val_loss: 0.6674 - val_accuracy: 0.8019\n",
            "Epoch 271/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1330 - accuracy: 0.9468 - val_loss: 0.7231 - val_accuracy: 0.7729\n",
            "Epoch 272/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.1357 - accuracy: 0.9547 - val_loss: 0.6799 - val_accuracy: 0.7633\n",
            "Epoch 273/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.1254 - accuracy: 0.9589 - val_loss: 0.6819 - val_accuracy: 0.7826\n",
            "Epoch 274/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.1494 - accuracy: 0.9450 - val_loss: 0.6485 - val_accuracy: 0.7874\n",
            "Epoch 275/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.1447 - accuracy: 0.9401 - val_loss: 0.6708 - val_accuracy: 0.7778\n",
            "Epoch 276/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1293 - accuracy: 0.9486 - val_loss: 0.6264 - val_accuracy: 0.8116\n",
            "Epoch 277/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1180 - accuracy: 0.9607 - val_loss: 0.7159 - val_accuracy: 0.7729\n",
            "Epoch 278/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.1667 - accuracy: 0.9395 - val_loss: 0.7089 - val_accuracy: 0.7874\n",
            "Epoch 279/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1317 - accuracy: 0.9516 - val_loss: 0.7336 - val_accuracy: 0.7585\n",
            "Epoch 280/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1300 - accuracy: 0.9528 - val_loss: 0.6932 - val_accuracy: 0.8019\n",
            "Epoch 281/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1461 - accuracy: 0.9480 - val_loss: 0.7142 - val_accuracy: 0.7488\n",
            "Epoch 282/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1282 - accuracy: 0.9559 - val_loss: 0.6503 - val_accuracy: 0.8068\n",
            "Epoch 283/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1125 - accuracy: 0.9553 - val_loss: 0.7261 - val_accuracy: 0.7778\n",
            "Epoch 284/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.1151 - accuracy: 0.9547 - val_loss: 0.6829 - val_accuracy: 0.7778\n",
            "Epoch 285/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.1283 - accuracy: 0.9541 - val_loss: 0.7613 - val_accuracy: 0.7488\n",
            "Epoch 286/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1368 - accuracy: 0.9468 - val_loss: 0.7099 - val_accuracy: 0.7778\n",
            "Epoch 287/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1386 - accuracy: 0.9504 - val_loss: 0.7952 - val_accuracy: 0.7488\n",
            "Epoch 288/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1224 - accuracy: 0.9541 - val_loss: 0.7089 - val_accuracy: 0.7488\n",
            "Epoch 289/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.1083 - accuracy: 0.9589 - val_loss: 0.7415 - val_accuracy: 0.7778\n",
            "Epoch 290/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.1331 - accuracy: 0.9468 - val_loss: 0.7446 - val_accuracy: 0.7826\n",
            "Epoch 291/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1460 - accuracy: 0.9474 - val_loss: 0.7238 - val_accuracy: 0.8068\n",
            "Epoch 292/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1449 - accuracy: 0.9492 - val_loss: 0.7126 - val_accuracy: 0.8019\n",
            "Epoch 293/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1337 - accuracy: 0.9468 - val_loss: 0.6941 - val_accuracy: 0.7826\n",
            "Epoch 294/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1328 - accuracy: 0.9541 - val_loss: 0.6783 - val_accuracy: 0.8116\n",
            "Epoch 295/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.1266 - accuracy: 0.9504 - val_loss: 0.7027 - val_accuracy: 0.7874\n",
            "Epoch 296/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.1308 - accuracy: 0.9565 - val_loss: 0.6710 - val_accuracy: 0.8019\n",
            "Epoch 297/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1176 - accuracy: 0.9571 - val_loss: 0.7282 - val_accuracy: 0.7536\n",
            "Epoch 298/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1599 - accuracy: 0.9456 - val_loss: 0.7088 - val_accuracy: 0.7633\n",
            "Epoch 299/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.1113 - accuracy: 0.9607 - val_loss: 0.7257 - val_accuracy: 0.8068\n",
            "Epoch 300/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.1183 - accuracy: 0.9553 - val_loss: 0.7426 - val_accuracy: 0.8019\n",
            "Epoch 301/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.1169 - accuracy: 0.9583 - val_loss: 0.7251 - val_accuracy: 0.7971\n",
            "Epoch 302/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.1116 - accuracy: 0.9559 - val_loss: 0.7554 - val_accuracy: 0.7633\n",
            "Epoch 303/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1291 - accuracy: 0.9528 - val_loss: 0.7387 - val_accuracy: 0.7729\n",
            "Epoch 304/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.1236 - accuracy: 0.9553 - val_loss: 0.7426 - val_accuracy: 0.7826\n",
            "Epoch 305/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1310 - accuracy: 0.9571 - val_loss: 0.7046 - val_accuracy: 0.7971\n",
            "Epoch 306/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1098 - accuracy: 0.9601 - val_loss: 0.7233 - val_accuracy: 0.7729\n",
            "Epoch 307/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.1326 - accuracy: 0.9516 - val_loss: 0.6568 - val_accuracy: 0.7729\n",
            "Epoch 308/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.1130 - accuracy: 0.9649 - val_loss: 0.7519 - val_accuracy: 0.7826\n",
            "Epoch 309/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.1074 - accuracy: 0.9655 - val_loss: 0.6895 - val_accuracy: 0.7971\n",
            "Epoch 310/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1117 - accuracy: 0.9577 - val_loss: 0.7076 - val_accuracy: 0.7826\n",
            "Epoch 311/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0931 - accuracy: 0.9655 - val_loss: 0.7105 - val_accuracy: 0.7874\n",
            "Epoch 312/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.1262 - accuracy: 0.9504 - val_loss: 0.6600 - val_accuracy: 0.8357\n",
            "Epoch 313/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0935 - accuracy: 0.9649 - val_loss: 0.7068 - val_accuracy: 0.7633\n",
            "Epoch 314/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1102 - accuracy: 0.9601 - val_loss: 0.6990 - val_accuracy: 0.7729\n",
            "Epoch 315/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1104 - accuracy: 0.9583 - val_loss: 0.6736 - val_accuracy: 0.8068\n",
            "Epoch 316/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1152 - accuracy: 0.9571 - val_loss: 0.7337 - val_accuracy: 0.7826\n",
            "Epoch 317/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.1052 - accuracy: 0.9674 - val_loss: 0.7196 - val_accuracy: 0.7778\n",
            "Epoch 318/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.1079 - accuracy: 0.9607 - val_loss: 0.7089 - val_accuracy: 0.7923\n",
            "Epoch 319/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1433 - accuracy: 0.9438 - val_loss: 0.7564 - val_accuracy: 0.7874\n",
            "Epoch 320/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.1074 - accuracy: 0.9565 - val_loss: 0.6995 - val_accuracy: 0.7729\n",
            "Epoch 321/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1156 - accuracy: 0.9583 - val_loss: 0.7031 - val_accuracy: 0.7778\n",
            "Epoch 322/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1128 - accuracy: 0.9613 - val_loss: 0.6909 - val_accuracy: 0.7874\n",
            "Epoch 323/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1216 - accuracy: 0.9528 - val_loss: 0.7148 - val_accuracy: 0.7633\n",
            "Epoch 324/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1306 - accuracy: 0.9541 - val_loss: 0.7557 - val_accuracy: 0.7826\n",
            "Epoch 325/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.0993 - accuracy: 0.9649 - val_loss: 0.7470 - val_accuracy: 0.7874\n",
            "Epoch 326/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0919 - accuracy: 0.9692 - val_loss: 0.7129 - val_accuracy: 0.7923\n",
            "Epoch 327/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0888 - accuracy: 0.9680 - val_loss: 0.6851 - val_accuracy: 0.7874\n",
            "Epoch 328/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0772 - accuracy: 0.9704 - val_loss: 0.7549 - val_accuracy: 0.7923\n",
            "Epoch 329/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1182 - accuracy: 0.9601 - val_loss: 0.6988 - val_accuracy: 0.7778\n",
            "Epoch 330/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.1165 - accuracy: 0.9577 - val_loss: 0.7364 - val_accuracy: 0.7874\n",
            "Epoch 331/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1216 - accuracy: 0.9541 - val_loss: 0.7259 - val_accuracy: 0.8068\n",
            "Epoch 332/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1295 - accuracy: 0.9541 - val_loss: 0.6593 - val_accuracy: 0.8068\n",
            "Epoch 333/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.0934 - accuracy: 0.9680 - val_loss: 0.7173 - val_accuracy: 0.7971\n",
            "Epoch 334/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0846 - accuracy: 0.9710 - val_loss: 0.7058 - val_accuracy: 0.8068\n",
            "Epoch 335/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0826 - accuracy: 0.9704 - val_loss: 0.7086 - val_accuracy: 0.7923\n",
            "Epoch 336/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.1189 - accuracy: 0.9547 - val_loss: 0.7189 - val_accuracy: 0.7923\n",
            "Epoch 337/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.1377 - accuracy: 0.9498 - val_loss: 0.7846 - val_accuracy: 0.7585\n",
            "Epoch 338/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.1131 - accuracy: 0.9559 - val_loss: 0.6650 - val_accuracy: 0.8116\n",
            "Epoch 339/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.1045 - accuracy: 0.9583 - val_loss: 0.7743 - val_accuracy: 0.7923\n",
            "Epoch 340/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1201 - accuracy: 0.9595 - val_loss: 0.7654 - val_accuracy: 0.7874\n",
            "Epoch 341/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0844 - accuracy: 0.9674 - val_loss: 0.7403 - val_accuracy: 0.7874\n",
            "Epoch 342/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1022 - accuracy: 0.9643 - val_loss: 0.7476 - val_accuracy: 0.7971\n",
            "Epoch 343/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1039 - accuracy: 0.9601 - val_loss: 0.7941 - val_accuracy: 0.8164\n",
            "Epoch 344/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.0950 - accuracy: 0.9655 - val_loss: 0.7079 - val_accuracy: 0.8116\n",
            "Epoch 345/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0965 - accuracy: 0.9643 - val_loss: 0.7407 - val_accuracy: 0.7923\n",
            "Epoch 346/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1111 - accuracy: 0.9649 - val_loss: 0.7278 - val_accuracy: 0.7923\n",
            "Epoch 347/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1106 - accuracy: 0.9547 - val_loss: 0.7816 - val_accuracy: 0.7778\n",
            "Epoch 348/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1162 - accuracy: 0.9565 - val_loss: 0.6782 - val_accuracy: 0.8357\n",
            "Epoch 349/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0737 - accuracy: 0.9758 - val_loss: 0.7138 - val_accuracy: 0.8068\n",
            "Epoch 350/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1013 - accuracy: 0.9631 - val_loss: 0.6948 - val_accuracy: 0.7778\n",
            "Epoch 351/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0886 - accuracy: 0.9686 - val_loss: 0.7363 - val_accuracy: 0.8116\n",
            "Epoch 352/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1046 - accuracy: 0.9547 - val_loss: 0.7718 - val_accuracy: 0.7923\n",
            "Epoch 353/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.0966 - accuracy: 0.9674 - val_loss: 0.7495 - val_accuracy: 0.8019\n",
            "Epoch 354/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1022 - accuracy: 0.9661 - val_loss: 0.7355 - val_accuracy: 0.8357\n",
            "Epoch 355/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0883 - accuracy: 0.9643 - val_loss: 0.7495 - val_accuracy: 0.7971\n",
            "Epoch 356/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0848 - accuracy: 0.9692 - val_loss: 0.7377 - val_accuracy: 0.7681\n",
            "Epoch 357/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0994 - accuracy: 0.9655 - val_loss: 0.7189 - val_accuracy: 0.7826\n",
            "Epoch 358/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1052 - accuracy: 0.9680 - val_loss: 0.7604 - val_accuracy: 0.7826\n",
            "Epoch 359/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1137 - accuracy: 0.9589 - val_loss: 0.8023 - val_accuracy: 0.7536\n",
            "Epoch 360/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0932 - accuracy: 0.9661 - val_loss: 0.7402 - val_accuracy: 0.7874\n",
            "Epoch 361/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.0880 - accuracy: 0.9649 - val_loss: 0.7524 - val_accuracy: 0.7874\n",
            "Epoch 362/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0889 - accuracy: 0.9698 - val_loss: 0.7190 - val_accuracy: 0.7923\n",
            "Epoch 363/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.0949 - accuracy: 0.9649 - val_loss: 0.7938 - val_accuracy: 0.7778\n",
            "Epoch 364/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1135 - accuracy: 0.9571 - val_loss: 0.7597 - val_accuracy: 0.7778\n",
            "Epoch 365/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.0823 - accuracy: 0.9686 - val_loss: 0.7935 - val_accuracy: 0.7585\n",
            "Epoch 366/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0795 - accuracy: 0.9710 - val_loss: 0.7295 - val_accuracy: 0.7826\n",
            "Epoch 367/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0782 - accuracy: 0.9692 - val_loss: 0.6740 - val_accuracy: 0.8019\n",
            "Epoch 368/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.0924 - accuracy: 0.9686 - val_loss: 0.7263 - val_accuracy: 0.7826\n",
            "Epoch 369/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1071 - accuracy: 0.9601 - val_loss: 0.6840 - val_accuracy: 0.7923\n",
            "Epoch 370/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.1177 - accuracy: 0.9547 - val_loss: 0.7409 - val_accuracy: 0.7923\n",
            "Epoch 371/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0943 - accuracy: 0.9686 - val_loss: 0.7136 - val_accuracy: 0.7826\n",
            "Epoch 372/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.0956 - accuracy: 0.9686 - val_loss: 0.6656 - val_accuracy: 0.8164\n",
            "Epoch 373/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.0948 - accuracy: 0.9625 - val_loss: 0.7589 - val_accuracy: 0.7971\n",
            "Epoch 374/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.1013 - accuracy: 0.9649 - val_loss: 0.7669 - val_accuracy: 0.7778\n",
            "Epoch 375/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.1214 - accuracy: 0.9571 - val_loss: 0.9431 - val_accuracy: 0.7198\n",
            "Epoch 376/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1258 - accuracy: 0.9498 - val_loss: 0.7525 - val_accuracy: 0.7681\n",
            "Epoch 377/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.0817 - accuracy: 0.9698 - val_loss: 0.7735 - val_accuracy: 0.7681\n",
            "Epoch 378/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0748 - accuracy: 0.9716 - val_loss: 0.7428 - val_accuracy: 0.7778\n",
            "Epoch 379/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0906 - accuracy: 0.9680 - val_loss: 0.7429 - val_accuracy: 0.7681\n",
            "Epoch 380/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0833 - accuracy: 0.9710 - val_loss: 0.6786 - val_accuracy: 0.7585\n",
            "Epoch 381/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0872 - accuracy: 0.9722 - val_loss: 0.7203 - val_accuracy: 0.7826\n",
            "Epoch 382/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0819 - accuracy: 0.9716 - val_loss: 0.7089 - val_accuracy: 0.7778\n",
            "Epoch 383/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.0919 - accuracy: 0.9716 - val_loss: 0.7043 - val_accuracy: 0.7923\n",
            "Epoch 384/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.0827 - accuracy: 0.9686 - val_loss: 0.6808 - val_accuracy: 0.7826\n",
            "Epoch 385/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0890 - accuracy: 0.9692 - val_loss: 0.7503 - val_accuracy: 0.7971\n",
            "Epoch 386/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0915 - accuracy: 0.9643 - val_loss: 0.6681 - val_accuracy: 0.7923\n",
            "Epoch 387/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.0930 - accuracy: 0.9613 - val_loss: 0.7548 - val_accuracy: 0.7440\n",
            "Epoch 388/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.0932 - accuracy: 0.9674 - val_loss: 0.7542 - val_accuracy: 0.7536\n",
            "Epoch 389/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0976 - accuracy: 0.9619 - val_loss: 0.7625 - val_accuracy: 0.7826\n",
            "Epoch 390/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0969 - accuracy: 0.9674 - val_loss: 0.7001 - val_accuracy: 0.7585\n",
            "Epoch 391/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.0856 - accuracy: 0.9692 - val_loss: 0.7179 - val_accuracy: 0.8068\n",
            "Epoch 392/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0874 - accuracy: 0.9643 - val_loss: 0.7227 - val_accuracy: 0.7778\n",
            "Epoch 393/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0821 - accuracy: 0.9740 - val_loss: 0.8167 - val_accuracy: 0.7681\n",
            "Epoch 394/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.0866 - accuracy: 0.9716 - val_loss: 0.7825 - val_accuracy: 0.7826\n",
            "Epoch 395/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0875 - accuracy: 0.9680 - val_loss: 0.8229 - val_accuracy: 0.7826\n",
            "Epoch 396/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.0739 - accuracy: 0.9740 - val_loss: 0.7306 - val_accuracy: 0.7826\n",
            "Epoch 397/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0881 - accuracy: 0.9674 - val_loss: 0.7110 - val_accuracy: 0.7923\n",
            "Epoch 398/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0699 - accuracy: 0.9752 - val_loss: 0.7609 - val_accuracy: 0.7633\n",
            "Epoch 399/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.0919 - accuracy: 0.9655 - val_loss: 0.7688 - val_accuracy: 0.7826\n",
            "Epoch 400/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1284 - accuracy: 0.9607 - val_loss: 0.8056 - val_accuracy: 0.7585\n",
            "Epoch 401/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1049 - accuracy: 0.9655 - val_loss: 0.8321 - val_accuracy: 0.7778\n",
            "Epoch 402/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.0983 - accuracy: 0.9607 - val_loss: 0.7209 - val_accuracy: 0.8309\n",
            "Epoch 403/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.1056 - accuracy: 0.9643 - val_loss: 0.7437 - val_accuracy: 0.7729\n",
            "Epoch 404/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.0732 - accuracy: 0.9746 - val_loss: 0.7319 - val_accuracy: 0.7874\n",
            "Epoch 405/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.0754 - accuracy: 0.9704 - val_loss: 0.7342 - val_accuracy: 0.7826\n",
            "Epoch 406/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0851 - accuracy: 0.9698 - val_loss: 0.6863 - val_accuracy: 0.7874\n",
            "Epoch 407/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.0663 - accuracy: 0.9746 - val_loss: 0.7557 - val_accuracy: 0.8019\n",
            "Epoch 408/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.0841 - accuracy: 0.9704 - val_loss: 0.7869 - val_accuracy: 0.7729\n",
            "Epoch 409/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0952 - accuracy: 0.9667 - val_loss: 0.8568 - val_accuracy: 0.7585\n",
            "Epoch 410/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0646 - accuracy: 0.9788 - val_loss: 0.7491 - val_accuracy: 0.7971\n",
            "Epoch 411/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0805 - accuracy: 0.9728 - val_loss: 0.7857 - val_accuracy: 0.7923\n",
            "Epoch 412/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0820 - accuracy: 0.9698 - val_loss: 0.8257 - val_accuracy: 0.7729\n",
            "Epoch 413/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0782 - accuracy: 0.9710 - val_loss: 0.8167 - val_accuracy: 0.7778\n",
            "Epoch 414/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0707 - accuracy: 0.9770 - val_loss: 0.8335 - val_accuracy: 0.7778\n",
            "Epoch 415/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.0702 - accuracy: 0.9740 - val_loss: 0.7384 - val_accuracy: 0.7874\n",
            "Epoch 416/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1033 - accuracy: 0.9607 - val_loss: 0.7017 - val_accuracy: 0.7778\n",
            "Epoch 417/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.0700 - accuracy: 0.9776 - val_loss: 0.7853 - val_accuracy: 0.7729\n",
            "Epoch 418/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0647 - accuracy: 0.9764 - val_loss: 0.7448 - val_accuracy: 0.7826\n",
            "Epoch 419/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0523 - accuracy: 0.9788 - val_loss: 0.8703 - val_accuracy: 0.7729\n",
            "Epoch 420/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1014 - accuracy: 0.9655 - val_loss: 0.7234 - val_accuracy: 0.7874\n",
            "Epoch 421/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0762 - accuracy: 0.9752 - val_loss: 0.7977 - val_accuracy: 0.7778\n",
            "Epoch 422/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0933 - accuracy: 0.9692 - val_loss: 0.7567 - val_accuracy: 0.7633\n",
            "Epoch 423/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0950 - accuracy: 0.9667 - val_loss: 0.7715 - val_accuracy: 0.7778\n",
            "Epoch 424/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0631 - accuracy: 0.9758 - val_loss: 0.7340 - val_accuracy: 0.8068\n",
            "Epoch 425/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0672 - accuracy: 0.9710 - val_loss: 0.7299 - val_accuracy: 0.7729\n",
            "Epoch 426/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0801 - accuracy: 0.9698 - val_loss: 0.8080 - val_accuracy: 0.7923\n",
            "Epoch 427/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0782 - accuracy: 0.9728 - val_loss: 0.7044 - val_accuracy: 0.7874\n",
            "Epoch 428/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0819 - accuracy: 0.9686 - val_loss: 0.7239 - val_accuracy: 0.7971\n",
            "Epoch 429/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0759 - accuracy: 0.9716 - val_loss: 0.6945 - val_accuracy: 0.7971\n",
            "Epoch 430/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0904 - accuracy: 0.9667 - val_loss: 0.6310 - val_accuracy: 0.7923\n",
            "Epoch 431/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0688 - accuracy: 0.9692 - val_loss: 0.6890 - val_accuracy: 0.8116\n",
            "Epoch 432/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0639 - accuracy: 0.9776 - val_loss: 0.7650 - val_accuracy: 0.7874\n",
            "Epoch 433/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0681 - accuracy: 0.9764 - val_loss: 0.8053 - val_accuracy: 0.7874\n",
            "Epoch 434/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0809 - accuracy: 0.9680 - val_loss: 0.7504 - val_accuracy: 0.7826\n",
            "Epoch 435/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0692 - accuracy: 0.9740 - val_loss: 0.7414 - val_accuracy: 0.8164\n",
            "Epoch 436/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0762 - accuracy: 0.9740 - val_loss: 0.7333 - val_accuracy: 0.8116\n",
            "Epoch 437/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1019 - accuracy: 0.9613 - val_loss: 0.7151 - val_accuracy: 0.8116\n",
            "Epoch 438/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.0713 - accuracy: 0.9764 - val_loss: 0.8261 - val_accuracy: 0.7778\n",
            "Epoch 439/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0756 - accuracy: 0.9740 - val_loss: 0.7616 - val_accuracy: 0.8019\n",
            "Epoch 440/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.0752 - accuracy: 0.9716 - val_loss: 0.7762 - val_accuracy: 0.7874\n",
            "Epoch 441/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0683 - accuracy: 0.9758 - val_loss: 0.7022 - val_accuracy: 0.8116\n",
            "Epoch 442/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0688 - accuracy: 0.9728 - val_loss: 0.7340 - val_accuracy: 0.7923\n",
            "Epoch 443/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.0660 - accuracy: 0.9758 - val_loss: 0.7134 - val_accuracy: 0.8019\n",
            "Epoch 444/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0722 - accuracy: 0.9740 - val_loss: 0.7777 - val_accuracy: 0.7778\n",
            "Epoch 445/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0729 - accuracy: 0.9734 - val_loss: 0.7094 - val_accuracy: 0.8164\n",
            "Epoch 446/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0743 - accuracy: 0.9746 - val_loss: 0.7563 - val_accuracy: 0.7971\n",
            "Epoch 447/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.0894 - accuracy: 0.9692 - val_loss: 0.7949 - val_accuracy: 0.7923\n",
            "Epoch 448/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0719 - accuracy: 0.9728 - val_loss: 0.6975 - val_accuracy: 0.8068\n",
            "Epoch 449/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0703 - accuracy: 0.9728 - val_loss: 0.7649 - val_accuracy: 0.8116\n",
            "Epoch 450/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0741 - accuracy: 0.9740 - val_loss: 0.7731 - val_accuracy: 0.7874\n",
            "Epoch 451/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0655 - accuracy: 0.9752 - val_loss: 0.8225 - val_accuracy: 0.7874\n",
            "Epoch 452/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0711 - accuracy: 0.9746 - val_loss: 0.8028 - val_accuracy: 0.7681\n",
            "Epoch 453/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0728 - accuracy: 0.9758 - val_loss: 0.8067 - val_accuracy: 0.8116\n",
            "Epoch 454/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0844 - accuracy: 0.9698 - val_loss: 0.8075 - val_accuracy: 0.7826\n",
            "Epoch 455/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0617 - accuracy: 0.9764 - val_loss: 0.7324 - val_accuracy: 0.7874\n",
            "Epoch 456/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0543 - accuracy: 0.9819 - val_loss: 0.7878 - val_accuracy: 0.7874\n",
            "Epoch 457/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0713 - accuracy: 0.9776 - val_loss: 0.8164 - val_accuracy: 0.7826\n",
            "Epoch 458/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0604 - accuracy: 0.9770 - val_loss: 0.8398 - val_accuracy: 0.7874\n",
            "Epoch 459/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0706 - accuracy: 0.9722 - val_loss: 0.8243 - val_accuracy: 0.7826\n",
            "Epoch 460/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0757 - accuracy: 0.9710 - val_loss: 0.7846 - val_accuracy: 0.7971\n",
            "Epoch 461/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0715 - accuracy: 0.9734 - val_loss: 0.7869 - val_accuracy: 0.8019\n",
            "Epoch 462/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1085 - accuracy: 0.9643 - val_loss: 0.7597 - val_accuracy: 0.7778\n",
            "Epoch 463/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0752 - accuracy: 0.9770 - val_loss: 0.8084 - val_accuracy: 0.7729\n",
            "Epoch 464/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.0768 - accuracy: 0.9764 - val_loss: 0.8022 - val_accuracy: 0.7923\n",
            "Epoch 465/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0708 - accuracy: 0.9782 - val_loss: 0.8255 - val_accuracy: 0.7729\n",
            "Epoch 466/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0541 - accuracy: 0.9758 - val_loss: 0.7758 - val_accuracy: 0.7778\n",
            "Epoch 467/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0759 - accuracy: 0.9716 - val_loss: 0.8369 - val_accuracy: 0.7681\n",
            "Epoch 468/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0562 - accuracy: 0.9800 - val_loss: 0.8430 - val_accuracy: 0.7778\n",
            "Epoch 469/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0795 - accuracy: 0.9746 - val_loss: 0.8632 - val_accuracy: 0.7923\n",
            "Epoch 470/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0717 - accuracy: 0.9764 - val_loss: 0.8246 - val_accuracy: 0.7971\n",
            "Epoch 471/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0780 - accuracy: 0.9770 - val_loss: 0.7447 - val_accuracy: 0.8116\n",
            "Epoch 472/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0619 - accuracy: 0.9764 - val_loss: 0.8628 - val_accuracy: 0.7585\n",
            "Epoch 473/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0603 - accuracy: 0.9794 - val_loss: 0.8715 - val_accuracy: 0.7874\n",
            "Epoch 474/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0508 - accuracy: 0.9837 - val_loss: 0.7553 - val_accuracy: 0.7826\n",
            "Epoch 475/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0679 - accuracy: 0.9776 - val_loss: 0.8431 - val_accuracy: 0.7778\n",
            "Epoch 476/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0642 - accuracy: 0.9770 - val_loss: 0.7514 - val_accuracy: 0.7923\n",
            "Epoch 477/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0828 - accuracy: 0.9692 - val_loss: 0.7727 - val_accuracy: 0.8164\n",
            "Epoch 478/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0733 - accuracy: 0.9746 - val_loss: 0.8141 - val_accuracy: 0.7874\n",
            "Epoch 479/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0578 - accuracy: 0.9800 - val_loss: 0.7974 - val_accuracy: 0.8116\n",
            "Epoch 480/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0578 - accuracy: 0.9782 - val_loss: 0.7708 - val_accuracy: 0.7971\n",
            "Epoch 481/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0726 - accuracy: 0.9752 - val_loss: 0.8037 - val_accuracy: 0.8068\n",
            "Epoch 482/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.0784 - accuracy: 0.9758 - val_loss: 0.8092 - val_accuracy: 0.7778\n",
            "Epoch 483/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0722 - accuracy: 0.9728 - val_loss: 0.8117 - val_accuracy: 0.7874\n",
            "Epoch 484/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0823 - accuracy: 0.9740 - val_loss: 0.7796 - val_accuracy: 0.8116\n",
            "Epoch 485/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0753 - accuracy: 0.9746 - val_loss: 0.7470 - val_accuracy: 0.8213\n",
            "Epoch 486/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0818 - accuracy: 0.9728 - val_loss: 0.8333 - val_accuracy: 0.7874\n",
            "Epoch 487/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0646 - accuracy: 0.9770 - val_loss: 0.7355 - val_accuracy: 0.8068\n",
            "Epoch 488/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.0659 - accuracy: 0.9788 - val_loss: 0.7221 - val_accuracy: 0.8068\n",
            "Epoch 489/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0723 - accuracy: 0.9764 - val_loss: 0.7461 - val_accuracy: 0.7971\n",
            "Epoch 490/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0648 - accuracy: 0.9782 - val_loss: 0.8375 - val_accuracy: 0.7778\n",
            "Epoch 491/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0636 - accuracy: 0.9752 - val_loss: 0.7475 - val_accuracy: 0.7729\n",
            "Epoch 492/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0622 - accuracy: 0.9764 - val_loss: 0.7851 - val_accuracy: 0.7923\n",
            "Epoch 493/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0827 - accuracy: 0.9740 - val_loss: 0.8035 - val_accuracy: 0.7874\n",
            "Epoch 494/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0617 - accuracy: 0.9764 - val_loss: 0.8222 - val_accuracy: 0.7681\n",
            "Epoch 495/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0663 - accuracy: 0.9758 - val_loss: 0.7456 - val_accuracy: 0.8116\n",
            "Epoch 496/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0578 - accuracy: 0.9788 - val_loss: 0.8135 - val_accuracy: 0.7923\n",
            "Epoch 497/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0678 - accuracy: 0.9782 - val_loss: 0.8850 - val_accuracy: 0.7633\n",
            "Epoch 498/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0742 - accuracy: 0.9746 - val_loss: 0.8289 - val_accuracy: 0.8019\n",
            "Epoch 499/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0682 - accuracy: 0.9764 - val_loss: 0.8402 - val_accuracy: 0.7729\n",
            "Epoch 500/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0633 - accuracy: 0.9794 - val_loss: 0.8025 - val_accuracy: 0.7681\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(cnnhistory.history['loss'])\n",
        "plt.plot(cnnhistory.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train','test'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "oQYnuaCrDH_A",
        "outputId": "fb00ec4b-8e45-4f77-9f70-3ce718d2360a"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(cnnhistory.history['accuracy'])\n",
        "plt.plot(cnnhistory.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train','test'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "IFkTuO8nDNdq",
        "outputId": "b7c7a617-f86d-4f5c-875a-fc1fb494a39f"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#predictions = model.predict_classes(x_testcnn)\n",
        "predictions = model.predict(x_testcnn)"
      ],
      "metadata": {
        "id": "A2xtrN5wDQgY"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_f_ohjXKDUpY",
        "outputId": "9fd723fa-fb5e-499a-b226-ac64fcd7c6f2"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.1712772e-10, 9.1284945e-11, 1.0581963e-04, 6.9381159e-08,\n",
              "        1.9570415e-04, 9.9969840e-01],\n",
              "       [4.8592649e-03, 9.6385926e-01, 3.5265241e-08, 3.1273995e-02,\n",
              "        6.7402302e-06, 6.8374510e-07],\n",
              "       [3.5299671e-08, 1.1701117e-05, 8.1510681e-01, 1.5927767e-06,\n",
              "        1.8486601e-01, 1.3872395e-05],\n",
              "       ...,\n",
              "       [2.8303136e-08, 1.9021097e-10, 1.7154431e-06, 3.6072269e-08,\n",
              "        9.9989474e-01, 1.0346043e-04],\n",
              "       [4.9691563e-03, 3.9792224e-04, 6.8161609e-03, 6.0817921e-01,\n",
              "        3.3101827e-04, 3.7930655e-01],\n",
              "       [6.4166333e-04, 5.6584318e-05, 6.7968917e-04, 8.5807516e-04,\n",
              "        9.9776399e-01, 1.1722786e-08]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cmA2bFgsDW3D",
        "outputId": "1fe9fb9c-3aab-40e5-8432-b2abe32068cb"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5, 1, 2, 5, 3, 4, 2, 0, 3, 1, 3, 2, 1, 4, 3, 0, 5, 0, 2, 5, 0, 0,\n",
              "       1, 3, 2, 3, 2, 5, 4, 2, 2, 3, 1, 2, 5, 5, 3, 5, 3, 3, 4, 1, 3, 2,\n",
              "       3, 1, 5, 3, 1, 2, 4, 4, 5, 5, 5, 1, 2, 3, 2, 5, 0, 2, 4, 2, 5, 4,\n",
              "       3, 0, 1, 2, 5, 2, 1, 2, 4, 5, 4, 1, 5, 5, 3, 1, 5, 3, 2, 4, 2, 5,\n",
              "       0, 5, 0, 5, 4, 0, 2, 4, 0, 2, 2, 0, 2, 3, 5, 3, 5, 5, 3, 1, 2, 2,\n",
              "       2, 1, 3, 2, 1, 3, 4, 4, 1, 1, 2, 4, 4, 1, 4, 2, 0, 4, 5, 5, 3, 1,\n",
              "       2, 1, 5, 5, 1, 2, 3, 3, 0, 3, 3, 0, 1, 0, 1, 2, 1, 5, 1, 2, 2, 0,\n",
              "       1, 1, 1, 1, 1, 4, 0, 1, 5, 1, 4, 5, 5, 4, 1, 0, 3, 5, 2, 3, 0, 4,\n",
              "       1, 3, 1, 0, 5, 5, 3, 5, 4, 5, 4, 0, 4, 1, 2, 1, 5, 0, 4, 3, 2, 1,\n",
              "       0, 3, 5, 0, 4, 5, 4, 5, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_Ytest = y_test.astype(int)"
      ],
      "metadata": {
        "id": "0PHDKWJWDY3g"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_Ytest"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k68v2i-pDbZE",
        "outputId": "9163ccf3-8049-456a-d75a-3569883cd591"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5, 1, 2, 5, 3, 4, 2, 0, 3, 1, 3, 2, 1, 4, 3, 0, 5, 0, 2, 5, 0, 0,\n",
              "       1, 3, 2, 3, 2, 5, 4, 2, 2, 3, 1, 2, 5, 5, 3, 5, 3, 3, 4, 1, 3, 2,\n",
              "       3, 1, 5, 3, 1, 2, 4, 4, 5, 5, 5, 1, 2, 3, 2, 5, 0, 2, 4, 2, 5, 4,\n",
              "       3, 0, 1, 2, 5, 2, 1, 2, 4, 5, 4, 1, 5, 5, 3, 1, 5, 3, 2, 4, 2, 5,\n",
              "       0, 5, 0, 5, 4, 0, 2, 4, 0, 2, 2, 0, 2, 3, 5, 3, 5, 5, 3, 1, 2, 2,\n",
              "       2, 1, 3, 2, 1, 3, 4, 4, 1, 1, 2, 4, 4, 1, 4, 2, 0, 4, 5, 5, 3, 1,\n",
              "       2, 1, 5, 5, 1, 2, 3, 3, 0, 3, 3, 0, 1, 0, 1, 2, 1, 5, 1, 2, 2, 0,\n",
              "       1, 1, 1, 1, 1, 4, 0, 1, 5, 1, 4, 5, 5, 4, 1, 0, 3, 5, 2, 3, 0, 4,\n",
              "       1, 3, 1, 0, 5, 5, 3, 5, 4, 5, 4, 0, 4, 1, 2, 1, 5, 0, 4, 3, 2, 1,\n",
              "       0, 3, 5, 0, 4, 5, 4, 5, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds1=predictions.argmax(axis=1)\n",
        "preds1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4_cAI39VFhtp",
        "outputId": "90948cd0-99ff-45d6-c3ab-1a1291e20dbc"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5, 1, 2, 5, 3, 4, 2, 0, 3, 1, 3, 3, 1, 4, 3, 0, 5, 3, 2, 5, 1, 1,\n",
              "       1, 3, 2, 3, 2, 5, 4, 2, 2, 3, 0, 2, 5, 5, 1, 5, 3, 3, 5, 1, 3, 2,\n",
              "       3, 1, 5, 5, 1, 4, 4, 4, 5, 5, 5, 1, 2, 3, 2, 5, 0, 2, 4, 2, 5, 4,\n",
              "       3, 4, 1, 2, 5, 2, 1, 2, 4, 3, 4, 1, 5, 5, 3, 1, 5, 3, 2, 4, 2, 5,\n",
              "       0, 5, 0, 5, 4, 0, 3, 4, 3, 4, 2, 2, 2, 3, 5, 3, 5, 5, 5, 1, 2, 2,\n",
              "       2, 1, 3, 2, 1, 3, 4, 4, 1, 1, 2, 4, 4, 1, 4, 2, 1, 4, 5, 5, 5, 1,\n",
              "       4, 1, 5, 5, 1, 2, 3, 3, 0, 3, 5, 0, 1, 0, 1, 2, 1, 5, 1, 2, 2, 0,\n",
              "       1, 1, 1, 1, 1, 4, 0, 1, 5, 1, 4, 5, 5, 2, 1, 0, 2, 5, 2, 3, 3, 4,\n",
              "       1, 3, 1, 0, 5, 5, 3, 5, 4, 3, 4, 0, 0, 3, 2, 1, 5, 0, 4, 1, 2, 0,\n",
              "       1, 4, 5, 0, 2, 5, 4, 3, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "abc = preds1.astype(int).flatten()"
      ],
      "metadata": {
        "id": "H4WEmM60NfQn"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "c = confusion_matrix(new_Ytest, abc) \n",
        "c"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bKEBeEBlFjB8",
        "outputId": "35120365-9773-4e4f-ea0a-4b6932543997"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[16,  4,  1,  3,  1,  0],\n",
              "       [ 2, 36,  0,  1,  0,  0],\n",
              "       [ 0,  0, 33,  2,  3,  0],\n",
              "       [ 0,  2,  1, 25,  1,  4],\n",
              "       [ 1,  0,  2,  0, 26,  1],\n",
              "       [ 0,  0,  0,  3,  0, 39]])"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m4RjG7LWLSQx",
        "outputId": "03e6896d-80c3-4455-91ac-0c1d025cef28"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5, 1, 2, 5, 3, 4, 2, 0, 3, 1, 3, 2, 1, 4, 3, 0, 5, 0, 2, 5, 0, 0,\n",
              "       1, 3, 2, 3, 2, 5, 4, 2, 2, 3, 1, 2, 5, 5, 3, 5, 3, 3, 4, 1, 3, 2,\n",
              "       3, 1, 5, 3, 1, 2, 4, 4, 5, 5, 5, 1, 2, 3, 2, 5, 0, 2, 4, 2, 5, 4,\n",
              "       3, 0, 1, 2, 5, 2, 1, 2, 4, 5, 4, 1, 5, 5, 3, 1, 5, 3, 2, 4, 2, 5,\n",
              "       0, 5, 0, 5, 4, 0, 2, 4, 0, 2, 2, 0, 2, 3, 5, 3, 5, 5, 3, 1, 2, 2,\n",
              "       2, 1, 3, 2, 1, 3, 4, 4, 1, 1, 2, 4, 4, 1, 4, 2, 0, 4, 5, 5, 3, 1,\n",
              "       2, 1, 5, 5, 1, 2, 3, 3, 0, 3, 3, 0, 1, 0, 1, 2, 1, 5, 1, 2, 2, 0,\n",
              "       1, 1, 1, 1, 1, 4, 0, 1, 5, 1, 4, 5, 5, 4, 1, 0, 3, 5, 2, 3, 0, 4,\n",
              "       1, 3, 1, 0, 5, 5, 3, 5, 4, 5, 4, 0, 4, 1, 2, 1, 5, 0, 4, 3, 2, 1,\n",
              "       0, 3, 5, 0, 4, 5, 4, 5, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('/content/drive/My Drive/graduation project/audio/paper_code/mariam/original_500 epoch_with_valid_Adam2_3')\n",
        "print(\"MODEL SAVED\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lsJBNeMWDl6Z",
        "outputId": "c6e893cb-e933-484f-b624-1caa24cfdfa8"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/graduation project/audio/paper_code/mariam/original_500 epoch_with_valid_Adam2_3/assets\n",
            "MODEL SAVED\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_model=keras.models.load_model('/content/drive/My Drive/graduation project/audio/paper_code/mariam/original_500 epoch_with_valid_Adam2_3')\n",
        "new_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q3KjaO9GDoNl",
        "outputId": "0cf48171-a2e6-4224-bc44-de2f7ea4dbd8"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d (Conv1D)             (None, 40, 128)           1152      \n",
            "                                                                 \n",
            " activation (Activation)     (None, 40, 128)           0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 40, 128)           0         \n",
            "                                                                 \n",
            " max_pooling1d (MaxPooling1D  (None, 8, 128)           0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv1d_1 (Conv1D)           (None, 8, 256)            262400    \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 8, 256)            0         \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 8, 256)            0         \n",
            "                                                                 \n",
            " max_pooling1d_1 (MaxPooling  (None, 1, 256)           0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 256)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 256)               65792     \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 256)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 256)               65792     \n",
            "                                                                 \n",
            " activation_3 (Activation)   (None, 256)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 6)                 1542      \n",
            "                                                                 \n",
            " activation_4 (Activation)   (None, 6)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 396,678\n",
            "Trainable params: 396,678\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss, acc =model.evaluate(x_testcnn, y_test)\n",
        "print(\"Restored model, accuracy: {:5.2f}%\".format(100*acc))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n3kzoqPkDqqS",
        "outputId": "66407ae3-3907-4e0e-c074-f58439495c29"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7/7 [==============================] - 0s 3ms/step - loss: 0.6149 - accuracy: 0.8454\n",
            "Restored model, accuracy: 84.54%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss, acc =model.evaluate(X_train, y_train)\n",
        "print(\"Restored model train, accuracy: {:5.2f}%\".format(100*acc))"
      ],
      "metadata": {
        "id": "fJDTGH_OUX0z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "567f4479-07b6-4ee3-ff8c-b49dc20a892e"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "52/52 [==============================] - 0s 4ms/step - loss: 0.0187 - accuracy: 0.9940\n",
            "Restored model train, accuracy: 99.40%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix,accuracy_score\n",
        "import seaborn as sn\n",
        "\n",
        "print(classification_report(new_Ytest,abc))\n",
        "\n",
        "acc = float(accuracy_score(new_Ytest,abc))*100\n",
        "print(\"----accuracy score %s ----\" % acc)\n",
        "\n",
        "cm = confusion_matrix(new_Ytest,abc)\n",
        "#df_cm = pd.DataFrame(cm)\n",
        "class_names = ['neutral','calm', 'happy','sad','angry', 'fearful' ]\n",
        "df_cm = pd.DataFrame(cm, index=class_names, columns=class_names,)\n",
        "sn.heatmap(df_cm, annot=True, fmt='')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 508
        },
        "id": "SfSC3El94LZg",
        "outputId": "395a1ab0-bc50-4be0-a9e0-47c6764861ac"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.64      0.73        25\n",
            "           1       0.86      0.92      0.89        39\n",
            "           2       0.89      0.87      0.88        38\n",
            "           3       0.74      0.76      0.75        33\n",
            "           4       0.84      0.87      0.85        30\n",
            "           5       0.89      0.93      0.91        42\n",
            "\n",
            "    accuracy                           0.85       207\n",
            "   macro avg       0.84      0.83      0.83       207\n",
            "weighted avg       0.85      0.85      0.84       207\n",
            "\n",
            "----accuracy score 84.54106280193237 ----\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "LGpgwFQqkpyU"
      },
      "execution_count": 37,
      "outputs": []
    }
  ]
}