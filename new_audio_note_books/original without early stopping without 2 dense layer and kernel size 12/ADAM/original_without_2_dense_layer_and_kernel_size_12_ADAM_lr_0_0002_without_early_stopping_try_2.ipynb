{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "original without 2 dense layer and kernel size 12 ADAM lr 0.0002 without early stopping try 2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9SRCO-a_AlH5",
        "outputId": "6874ae63-36a6-4b0a-ba4a-8c95075b9c70"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install librosa"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Lo4mUwG9RMd",
        "outputId": "e843f023-3248-456d-a2a4-51c4153c68ce"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.7/dist-packages (0.8.1)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.4.1)\n",
            "Requirement already satisfied: soundfile>=0.10.2 in /usr/local/lib/python3.7/dist-packages (from librosa) (0.10.3.post1)\n",
            "Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.6.0)\n",
            "Requirement already satisfied: decorator>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (21.3)\n",
            "Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.0.2)\n",
            "Requirement already satisfied: resampy>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from librosa) (0.2.2)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.1.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.21.6)\n",
            "Requirement already satisfied: audioread>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (2.1.9)\n",
            "Requirement already satisfied: numba>=0.43.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (0.51.2)\n",
            "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba>=0.43.0->librosa) (0.34.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba>=0.43.0->librosa) (57.4.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->librosa) (3.0.9)\n",
            "Requirement already satisfied: appdirs>=1.3.0 in /usr/local/lib/python3.7/dist-packages (from pooch>=1.0->librosa) (1.4.4)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from pooch>=1.0->librosa) (2.23.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2022.5.18.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (3.0.4)\n",
            "Requirement already satisfied: six>=1.3 in /usr/local/lib/python3.7/dist-packages (from resampy>=0.2.2->librosa) (1.15.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn!=0.19.0,>=0.14.0->librosa) (3.1.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.7/dist-packages (from soundfile>=0.10.2->librosa) (1.15.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.0->soundfile>=0.10.2->librosa) (2.21)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HJjcbxwy46bG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "515012af-994d-4feb-c504-f8412ee298db"
      },
      "source": [
        "# Orignial Notebook: https://github.com/MITESHPUTHRANNEU/Speech-Emotion-Analyzer/blob/master/final_results_gender_test.ipynb\n",
        "# This notebook author: Reza Chu\n",
        "# Last Editing Date: 31st May 2019\n",
        "\n",
        "## Python\n",
        "import os\n",
        "import random\n",
        "import sys\n",
        "\n",
        "import IPython\n",
        "from IPython.display import Audio\n",
        "from IPython.display import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "## Package\n",
        "import glob \n",
        "import keras\n",
        "import IPython.display as ipd\n",
        "import librosa\n",
        "import librosa.display\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import plotly.graph_objs as go\n",
        "import plotly.offline as py\n",
        "import plotly.tools as tls\n",
        "import seaborn as sns\n",
        "import scipy.io.wavfile\n",
        "import tensorflow as tf\n",
        "py.init_notebook_mode(connected=True)\n",
        "\n",
        "## Keras\n",
        "from keras import regularizers\n",
        "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping\n",
        "from keras.callbacks import  History, ReduceLROnPlateau, CSVLogger\n",
        "from keras.models import Model, Sequential\n",
        "from keras.layers import Dense, Embedding, LSTM\n",
        "from keras.layers import Input, Flatten, Dropout, Activation, BatchNormalization\n",
        "from keras.layers import Conv1D, MaxPooling1D, AveragePooling1D\n",
        "from keras.preprocessing import sequence\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.utils import np_utils\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "## Sklearn\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "## Rest\n",
        "from scipy.fftpack import fft\n",
        "from scipy import signal\n",
        "from scipy.io import wavfile\n",
        "from tqdm import tqdm\n",
        "\n",
        "input_duration=3\n",
        "# % pylab inline"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "        <script type=\"text/javascript\">\n",
              "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
              "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
              "        if (typeof require !== 'undefined') {\n",
              "        require.undef(\"plotly\");\n",
              "        requirejs.config({\n",
              "            paths: {\n",
              "                'plotly': ['https://cdn.plot.ly/plotly-2.8.3.min']\n",
              "            }\n",
              "        });\n",
              "        require(['plotly'], function(Plotly) {\n",
              "            window._Plotly = Plotly;\n",
              "        });\n",
              "        }\n",
              "        </script>\n",
              "        "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Saving joblib files to not load them again with the loop above\n",
        "\n",
        "# import joblib\n",
        "\n",
        "# X_name = 'x.joblib'\n",
        "# y_name = 'y.joblib'\n",
        "# save_dir = '/content/drive/My Drive/graduation project/audio/paper_code/features'\n",
        "\n",
        "# savedX = joblib.dump(X, os.path.join(save_dir, X_name))\n",
        "# savedy = joblib.dump(y, os.path.join(save_dir, y_name))"
      ],
      "metadata": {
        "id": "UCzic8rlDcuk"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Loading saved models\n",
        "import joblib\n",
        "X = joblib.load('/content/drive/My Drive/graduation project/audio/paper_code/features/x.joblib')\n",
        "y = joblib.load('/content/drive/My Drive/graduation project/audio/paper_code/features/y.joblib')"
      ],
      "metadata": {
        "id": "Q35CN6zDrzg1"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "id": "7PSTurzjCo5K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a49a676-597d-4478-8e3d-2683d7fdd46e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2068, 40)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.1 ,shuffle = True\n",
        "                                                    , random_state=42)\n",
        "X_train , X_valid, y_train, y_valid = train_test_split(X_train,y_train, test_size=0.1112305212 , shuffle = True \n",
        "                                                       , random_state=42)"
      ],
      "metadata": {
        "id": "Ai4Fy5cPCiq1"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "x_traincnn = np.expand_dims(X_train, axis=2)\n",
        "x_testcnn = np.expand_dims(X_test, axis=2)\n",
        "X_valid= np.expand_dims(X_valid, axis=2)"
      ],
      "metadata": {
        "id": "tp1Fm5K3CEXu"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_traincnn.shape, x_testcnn.shape , X_valid.shape\n",
        "#1861"
      ],
      "metadata": {
        "id": "RI0MxoIPBws5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "094220a4-c6e1-412b-e827-0956343b4f24"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1654, 40, 1), (207, 40, 1), (207, 40, 1))"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow"
      ],
      "metadata": {
        "id": "oALhiMUd9G2Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9291ec7a-f431-4912-9218-d556d86e97d8"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (2.8.2+zzzcolab20220527125636)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.17.3)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.21.6)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.46.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow) (57.4.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.5.3)\n",
            "Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.0)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (14.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (4.2.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.26.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.0.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow) (1.5.2)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.35.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.8.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.23.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.6.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (3.3.7)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.4.6)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (4.11.4)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (3.8.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2022.5.18.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (3.2.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from keras.preprocessing import sequence\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from keras.layers import Input, Flatten, Dropout, Activation\n",
        "from keras.layers import Conv1D, MaxPooling1D\n",
        "from keras.models import Model\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras import optimizers\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv1D(128, 12,padding='same', #classifier.add(Convolution2D(64, (3, 3), padding = 'same', input_shape = (128, 128, 3), activation = 'relu'))\n",
        "                 input_shape=(40,1)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(MaxPooling1D(pool_size=(5)))\n",
        "\n",
        "\n",
        "model.add(Conv1D(256,12,padding='same',))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(MaxPooling1D(pool_size=(5)))\n",
        "\n",
        "#model.add(MaxPooling1D(pool_size=(5)))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "\n",
        "\n",
        "model.add(Dense(6))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "\n",
        "#opt = tf.keras.optimizers.RMSprop(lr=0.0002 , decay=0.0)\n",
        "opt = tf.keras.optimizers.Adam(lr=0.0002 , decay=0.0)\n",
        "#opt = tf.keras.optimizers.RMSprop(lr=0.0001, rho=0.9, epsilon=1e-07, decay=0.0)\n",
        "#opt = tf.keras.optimizers.SGD(lr=0.001, momentum=0.0, decay=0.0, nesterov=False)"
      ],
      "metadata": {
        "id": "g74fXWVAC4Cr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c9247bdb-d967-4607-d703-f8357bb0c38e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning:\n",
            "\n",
            "The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "H6ukOxAGC_I4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c98fa27f-5b95-4b59-d732-4c1bbb2aa2ee"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d (Conv1D)             (None, 40, 128)           1664      \n",
            "                                                                 \n",
            " activation (Activation)     (None, 40, 128)           0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 40, 128)           0         \n",
            "                                                                 \n",
            " max_pooling1d (MaxPooling1D  (None, 8, 128)           0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv1d_1 (Conv1D)           (None, 8, 256)            393472    \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 8, 256)            0         \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 8, 256)            0         \n",
            "                                                                 \n",
            " max_pooling1d_1 (MaxPooling  (None, 1, 256)           0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 256)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 6)                 1542      \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 6)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 396,678\n",
            "Trainable params: 396,678\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='sparse_categorical_crossentropy',\n",
        "              optimizer=opt,\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "AbMlLNk4DCBM"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an Instance of Early Stopping Callback.\n",
        "#early_stopping_callback = EarlyStopping(monitor = 'val_loss', patience = 150, mode = 'min', restore_best_weights = True)\n",
        "\n",
        "cnnhistory=model.fit(x_traincnn, y_train, batch_size=16, epochs=500 , shuffle = True, \n",
        "                     validation_data=(X_valid, y_valid))"
      ],
      "metadata": {
        "id": "RI1v2AuADFhy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b84413b-9286-439c-879c-590a81946d45"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "104/104 [==============================] - 2s 5ms/step - loss: 10.6969 - accuracy: 0.1838 - val_loss: 3.2958 - val_accuracy: 0.1884\n",
            "Epoch 2/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 7.3883 - accuracy: 0.2164 - val_loss: 2.7325 - val_accuracy: 0.2174\n",
            "Epoch 3/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 5.9279 - accuracy: 0.2249 - val_loss: 1.8772 - val_accuracy: 0.3478\n",
            "Epoch 4/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 5.3573 - accuracy: 0.2527 - val_loss: 1.8685 - val_accuracy: 0.2222\n",
            "Epoch 5/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 3.9925 - accuracy: 0.2630 - val_loss: 2.0261 - val_accuracy: 0.3043\n",
            "Epoch 6/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 3.6057 - accuracy: 0.2539 - val_loss: 1.6511 - val_accuracy: 0.3768\n",
            "Epoch 7/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 3.1980 - accuracy: 0.2854 - val_loss: 1.5663 - val_accuracy: 0.3382\n",
            "Epoch 8/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.9264 - accuracy: 0.2872 - val_loss: 1.6437 - val_accuracy: 0.3430\n",
            "Epoch 9/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.4853 - accuracy: 0.2866 - val_loss: 1.5009 - val_accuracy: 0.4541\n",
            "Epoch 10/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.3783 - accuracy: 0.3065 - val_loss: 1.6215 - val_accuracy: 0.2609\n",
            "Epoch 11/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.2644 - accuracy: 0.3229 - val_loss: 1.6109 - val_accuracy: 0.2947\n",
            "Epoch 12/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 2.1142 - accuracy: 0.3114 - val_loss: 1.5383 - val_accuracy: 0.4058\n",
            "Epoch 13/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.9310 - accuracy: 0.3458 - val_loss: 1.5386 - val_accuracy: 0.4300\n",
            "Epoch 14/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.8209 - accuracy: 0.3730 - val_loss: 1.3907 - val_accuracy: 0.4783\n",
            "Epoch 15/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.7753 - accuracy: 0.3700 - val_loss: 1.5416 - val_accuracy: 0.3575\n",
            "Epoch 16/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.6962 - accuracy: 0.3652 - val_loss: 1.3487 - val_accuracy: 0.4493\n",
            "Epoch 17/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.6294 - accuracy: 0.3881 - val_loss: 1.4408 - val_accuracy: 0.4155\n",
            "Epoch 18/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.5649 - accuracy: 0.4002 - val_loss: 1.3380 - val_accuracy: 0.4976\n",
            "Epoch 19/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.6030 - accuracy: 0.3857 - val_loss: 1.3278 - val_accuracy: 0.4879\n",
            "Epoch 20/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.4899 - accuracy: 0.4262 - val_loss: 1.3187 - val_accuracy: 0.4879\n",
            "Epoch 21/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.4686 - accuracy: 0.4293 - val_loss: 1.2720 - val_accuracy: 0.5072\n",
            "Epoch 22/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.4658 - accuracy: 0.4281 - val_loss: 1.3184 - val_accuracy: 0.5169\n",
            "Epoch 23/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.3951 - accuracy: 0.4371 - val_loss: 1.2640 - val_accuracy: 0.4831\n",
            "Epoch 24/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.3320 - accuracy: 0.4734 - val_loss: 1.2274 - val_accuracy: 0.5362\n",
            "Epoch 25/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.3521 - accuracy: 0.4686 - val_loss: 1.2764 - val_accuracy: 0.4348\n",
            "Epoch 26/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.3110 - accuracy: 0.4734 - val_loss: 1.1997 - val_accuracy: 0.5556\n",
            "Epoch 27/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.2719 - accuracy: 0.5024 - val_loss: 1.1479 - val_accuracy: 0.5749\n",
            "Epoch 28/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.2787 - accuracy: 0.4946 - val_loss: 1.2409 - val_accuracy: 0.4879\n",
            "Epoch 29/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.2815 - accuracy: 0.4879 - val_loss: 1.1335 - val_accuracy: 0.6087\n",
            "Epoch 30/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.2210 - accuracy: 0.5187 - val_loss: 1.1178 - val_accuracy: 0.5604\n",
            "Epoch 31/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.1955 - accuracy: 0.5236 - val_loss: 1.1082 - val_accuracy: 0.5894\n",
            "Epoch 32/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.2202 - accuracy: 0.5302 - val_loss: 1.1373 - val_accuracy: 0.5266\n",
            "Epoch 33/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.2044 - accuracy: 0.5175 - val_loss: 1.0799 - val_accuracy: 0.6135\n",
            "Epoch 34/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.1607 - accuracy: 0.5242 - val_loss: 1.1010 - val_accuracy: 0.5990\n",
            "Epoch 35/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.1691 - accuracy: 0.5405 - val_loss: 1.1089 - val_accuracy: 0.5845\n",
            "Epoch 36/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.1639 - accuracy: 0.5339 - val_loss: 1.0860 - val_accuracy: 0.5845\n",
            "Epoch 37/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.1397 - accuracy: 0.5538 - val_loss: 1.1080 - val_accuracy: 0.5990\n",
            "Epoch 38/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.1365 - accuracy: 0.5496 - val_loss: 1.0331 - val_accuracy: 0.5990\n",
            "Epoch 39/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.1028 - accuracy: 0.5707 - val_loss: 1.0236 - val_accuracy: 0.6570\n",
            "Epoch 40/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.1141 - accuracy: 0.5580 - val_loss: 1.0363 - val_accuracy: 0.5990\n",
            "Epoch 41/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.0958 - accuracy: 0.5568 - val_loss: 1.0303 - val_accuracy: 0.6184\n",
            "Epoch 42/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.0692 - accuracy: 0.5738 - val_loss: 1.0579 - val_accuracy: 0.5894\n",
            "Epoch 43/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.0406 - accuracy: 0.5816 - val_loss: 1.0248 - val_accuracy: 0.6232\n",
            "Epoch 44/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.0649 - accuracy: 0.5695 - val_loss: 1.0146 - val_accuracy: 0.5845\n",
            "Epoch 45/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.0318 - accuracy: 0.5931 - val_loss: 1.0156 - val_accuracy: 0.6280\n",
            "Epoch 46/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.0312 - accuracy: 0.5798 - val_loss: 0.9874 - val_accuracy: 0.6473\n",
            "Epoch 47/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 1.0134 - accuracy: 0.5907 - val_loss: 0.9847 - val_accuracy: 0.6425\n",
            "Epoch 48/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.9992 - accuracy: 0.5871 - val_loss: 0.9313 - val_accuracy: 0.7198\n",
            "Epoch 49/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.9890 - accuracy: 0.6125 - val_loss: 1.0167 - val_accuracy: 0.6425\n",
            "Epoch 50/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.9494 - accuracy: 0.6348 - val_loss: 0.9250 - val_accuracy: 0.6957\n",
            "Epoch 51/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.9473 - accuracy: 0.6288 - val_loss: 0.9633 - val_accuracy: 0.6618\n",
            "Epoch 52/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.9628 - accuracy: 0.6233 - val_loss: 0.9467 - val_accuracy: 0.6522\n",
            "Epoch 53/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.9610 - accuracy: 0.6318 - val_loss: 0.9055 - val_accuracy: 0.7053\n",
            "Epoch 54/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.9353 - accuracy: 0.6342 - val_loss: 0.8868 - val_accuracy: 0.6570\n",
            "Epoch 55/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.9071 - accuracy: 0.6397 - val_loss: 0.9160 - val_accuracy: 0.6425\n",
            "Epoch 56/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.9302 - accuracy: 0.6294 - val_loss: 0.9179 - val_accuracy: 0.6618\n",
            "Epoch 57/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.9203 - accuracy: 0.6366 - val_loss: 0.9219 - val_accuracy: 0.6473\n",
            "Epoch 58/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.8907 - accuracy: 0.6463 - val_loss: 0.8675 - val_accuracy: 0.6908\n",
            "Epoch 59/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.8776 - accuracy: 0.6518 - val_loss: 0.8808 - val_accuracy: 0.7053\n",
            "Epoch 60/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.8973 - accuracy: 0.6475 - val_loss: 0.8735 - val_accuracy: 0.7246\n",
            "Epoch 61/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.8816 - accuracy: 0.6415 - val_loss: 0.8974 - val_accuracy: 0.6908\n",
            "Epoch 62/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.8706 - accuracy: 0.6542 - val_loss: 0.8751 - val_accuracy: 0.6667\n",
            "Epoch 63/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.8676 - accuracy: 0.6651 - val_loss: 0.8902 - val_accuracy: 0.6667\n",
            "Epoch 64/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.8664 - accuracy: 0.6560 - val_loss: 0.8868 - val_accuracy: 0.6715\n",
            "Epoch 65/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.8428 - accuracy: 0.6644 - val_loss: 0.8340 - val_accuracy: 0.7488\n",
            "Epoch 66/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.8316 - accuracy: 0.6765 - val_loss: 0.8455 - val_accuracy: 0.7246\n",
            "Epoch 67/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.8206 - accuracy: 0.6790 - val_loss: 0.8570 - val_accuracy: 0.6860\n",
            "Epoch 68/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.8526 - accuracy: 0.6729 - val_loss: 0.8615 - val_accuracy: 0.6957\n",
            "Epoch 69/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.8076 - accuracy: 0.6917 - val_loss: 0.8193 - val_accuracy: 0.7101\n",
            "Epoch 70/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.8306 - accuracy: 0.6693 - val_loss: 0.8248 - val_accuracy: 0.6957\n",
            "Epoch 71/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.7852 - accuracy: 0.6904 - val_loss: 0.8586 - val_accuracy: 0.6763\n",
            "Epoch 72/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.8043 - accuracy: 0.6808 - val_loss: 0.8146 - val_accuracy: 0.7246\n",
            "Epoch 73/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.8046 - accuracy: 0.6699 - val_loss: 0.8065 - val_accuracy: 0.6860\n",
            "Epoch 74/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.7972 - accuracy: 0.6826 - val_loss: 0.8198 - val_accuracy: 0.7005\n",
            "Epoch 75/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.7741 - accuracy: 0.7056 - val_loss: 0.7988 - val_accuracy: 0.7198\n",
            "Epoch 76/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.7907 - accuracy: 0.6880 - val_loss: 0.8142 - val_accuracy: 0.6860\n",
            "Epoch 77/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.7627 - accuracy: 0.7019 - val_loss: 0.8071 - val_accuracy: 0.7246\n",
            "Epoch 78/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.7657 - accuracy: 0.6941 - val_loss: 0.7880 - val_accuracy: 0.7198\n",
            "Epoch 79/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.7485 - accuracy: 0.7031 - val_loss: 0.7914 - val_accuracy: 0.6812\n",
            "Epoch 80/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.7510 - accuracy: 0.7007 - val_loss: 0.7775 - val_accuracy: 0.7343\n",
            "Epoch 81/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.7408 - accuracy: 0.7062 - val_loss: 0.8081 - val_accuracy: 0.7246\n",
            "Epoch 82/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.7244 - accuracy: 0.7086 - val_loss: 0.7542 - val_accuracy: 0.7391\n",
            "Epoch 83/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.7613 - accuracy: 0.7013 - val_loss: 0.7904 - val_accuracy: 0.7150\n",
            "Epoch 84/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.7417 - accuracy: 0.7080 - val_loss: 0.8075 - val_accuracy: 0.7053\n",
            "Epoch 85/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.6936 - accuracy: 0.7376 - val_loss: 0.7548 - val_accuracy: 0.7488\n",
            "Epoch 86/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.6876 - accuracy: 0.7328 - val_loss: 0.7466 - val_accuracy: 0.7005\n",
            "Epoch 87/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.7093 - accuracy: 0.7152 - val_loss: 0.7515 - val_accuracy: 0.7391\n",
            "Epoch 88/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.7051 - accuracy: 0.7183 - val_loss: 0.7592 - val_accuracy: 0.7343\n",
            "Epoch 89/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.6754 - accuracy: 0.7412 - val_loss: 0.7685 - val_accuracy: 0.7246\n",
            "Epoch 90/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.7005 - accuracy: 0.7158 - val_loss: 0.7858 - val_accuracy: 0.7150\n",
            "Epoch 91/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.6942 - accuracy: 0.7346 - val_loss: 0.7380 - val_accuracy: 0.7246\n",
            "Epoch 92/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.6778 - accuracy: 0.7406 - val_loss: 0.7361 - val_accuracy: 0.7343\n",
            "Epoch 93/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.6583 - accuracy: 0.7418 - val_loss: 0.7330 - val_accuracy: 0.7488\n",
            "Epoch 94/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.6670 - accuracy: 0.7316 - val_loss: 0.7479 - val_accuracy: 0.7343\n",
            "Epoch 95/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.6881 - accuracy: 0.7201 - val_loss: 0.7235 - val_accuracy: 0.7440\n",
            "Epoch 96/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.6245 - accuracy: 0.7588 - val_loss: 0.7144 - val_accuracy: 0.7343\n",
            "Epoch 97/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.6451 - accuracy: 0.7418 - val_loss: 0.7117 - val_accuracy: 0.7440\n",
            "Epoch 98/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.6330 - accuracy: 0.7479 - val_loss: 0.7108 - val_accuracy: 0.7585\n",
            "Epoch 99/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.6470 - accuracy: 0.7509 - val_loss: 0.7414 - val_accuracy: 0.7295\n",
            "Epoch 100/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.6447 - accuracy: 0.7394 - val_loss: 0.6894 - val_accuracy: 0.7536\n",
            "Epoch 101/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.6068 - accuracy: 0.7733 - val_loss: 0.7165 - val_accuracy: 0.7343\n",
            "Epoch 102/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.6259 - accuracy: 0.7563 - val_loss: 0.7331 - val_accuracy: 0.7488\n",
            "Epoch 103/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.5972 - accuracy: 0.7703 - val_loss: 0.6976 - val_accuracy: 0.7391\n",
            "Epoch 104/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.5991 - accuracy: 0.7690 - val_loss: 0.6865 - val_accuracy: 0.7295\n",
            "Epoch 105/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.6181 - accuracy: 0.7709 - val_loss: 0.6785 - val_accuracy: 0.7729\n",
            "Epoch 106/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.5897 - accuracy: 0.7642 - val_loss: 0.6994 - val_accuracy: 0.7295\n",
            "Epoch 107/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.5968 - accuracy: 0.7563 - val_loss: 0.7026 - val_accuracy: 0.7488\n",
            "Epoch 108/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.5751 - accuracy: 0.7769 - val_loss: 0.6443 - val_accuracy: 0.7923\n",
            "Epoch 109/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.5773 - accuracy: 0.7823 - val_loss: 0.6526 - val_accuracy: 0.7633\n",
            "Epoch 110/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.5762 - accuracy: 0.7769 - val_loss: 0.6658 - val_accuracy: 0.7488\n",
            "Epoch 111/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.5981 - accuracy: 0.7545 - val_loss: 0.7113 - val_accuracy: 0.7343\n",
            "Epoch 112/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.5360 - accuracy: 0.7981 - val_loss: 0.6669 - val_accuracy: 0.7729\n",
            "Epoch 113/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5776 - accuracy: 0.7660 - val_loss: 0.6520 - val_accuracy: 0.7729\n",
            "Epoch 114/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.5520 - accuracy: 0.7932 - val_loss: 0.6461 - val_accuracy: 0.7729\n",
            "Epoch 115/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5355 - accuracy: 0.7969 - val_loss: 0.6461 - val_accuracy: 0.7633\n",
            "Epoch 116/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.5708 - accuracy: 0.7715 - val_loss: 0.6689 - val_accuracy: 0.7585\n",
            "Epoch 117/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.5528 - accuracy: 0.7854 - val_loss: 0.6716 - val_accuracy: 0.7488\n",
            "Epoch 118/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.5272 - accuracy: 0.7963 - val_loss: 0.6476 - val_accuracy: 0.7633\n",
            "Epoch 119/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.5472 - accuracy: 0.7920 - val_loss: 0.6646 - val_accuracy: 0.7101\n",
            "Epoch 120/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.5205 - accuracy: 0.8065 - val_loss: 0.6166 - val_accuracy: 0.7729\n",
            "Epoch 121/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.5085 - accuracy: 0.8132 - val_loss: 0.6317 - val_accuracy: 0.7826\n",
            "Epoch 122/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.5532 - accuracy: 0.7896 - val_loss: 0.6254 - val_accuracy: 0.7729\n",
            "Epoch 123/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.5225 - accuracy: 0.8017 - val_loss: 0.6428 - val_accuracy: 0.7585\n",
            "Epoch 124/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.4940 - accuracy: 0.8035 - val_loss: 0.6161 - val_accuracy: 0.7874\n",
            "Epoch 125/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.5278 - accuracy: 0.7920 - val_loss: 0.6504 - val_accuracy: 0.7826\n",
            "Epoch 126/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.4837 - accuracy: 0.8174 - val_loss: 0.6137 - val_accuracy: 0.7826\n",
            "Epoch 127/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.5116 - accuracy: 0.7920 - val_loss: 0.6084 - val_accuracy: 0.7826\n",
            "Epoch 128/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.4930 - accuracy: 0.8180 - val_loss: 0.6186 - val_accuracy: 0.7681\n",
            "Epoch 129/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.4954 - accuracy: 0.8083 - val_loss: 0.6156 - val_accuracy: 0.7778\n",
            "Epoch 130/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.4952 - accuracy: 0.8077 - val_loss: 0.6543 - val_accuracy: 0.7488\n",
            "Epoch 131/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.4829 - accuracy: 0.8114 - val_loss: 0.6178 - val_accuracy: 0.7585\n",
            "Epoch 132/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.4736 - accuracy: 0.8156 - val_loss: 0.5897 - val_accuracy: 0.7874\n",
            "Epoch 133/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.4608 - accuracy: 0.8210 - val_loss: 0.5958 - val_accuracy: 0.7633\n",
            "Epoch 134/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.4683 - accuracy: 0.8150 - val_loss: 0.6040 - val_accuracy: 0.7971\n",
            "Epoch 135/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.4634 - accuracy: 0.8283 - val_loss: 0.5963 - val_accuracy: 0.7874\n",
            "Epoch 136/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.4600 - accuracy: 0.8241 - val_loss: 0.6060 - val_accuracy: 0.7681\n",
            "Epoch 137/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4635 - accuracy: 0.8247 - val_loss: 0.6175 - val_accuracy: 0.7633\n",
            "Epoch 138/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4404 - accuracy: 0.8319 - val_loss: 0.6268 - val_accuracy: 0.7633\n",
            "Epoch 139/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.4467 - accuracy: 0.8313 - val_loss: 0.5908 - val_accuracy: 0.8116\n",
            "Epoch 140/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.4435 - accuracy: 0.8362 - val_loss: 0.6086 - val_accuracy: 0.8019\n",
            "Epoch 141/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4489 - accuracy: 0.8349 - val_loss: 0.6026 - val_accuracy: 0.7874\n",
            "Epoch 142/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.4425 - accuracy: 0.8283 - val_loss: 0.5940 - val_accuracy: 0.7874\n",
            "Epoch 143/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4353 - accuracy: 0.8289 - val_loss: 0.5929 - val_accuracy: 0.7874\n",
            "Epoch 144/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4302 - accuracy: 0.8247 - val_loss: 0.5859 - val_accuracy: 0.7971\n",
            "Epoch 145/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4452 - accuracy: 0.8416 - val_loss: 0.5740 - val_accuracy: 0.8068\n",
            "Epoch 146/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.4213 - accuracy: 0.8337 - val_loss: 0.5859 - val_accuracy: 0.7971\n",
            "Epoch 147/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.4358 - accuracy: 0.8380 - val_loss: 0.5951 - val_accuracy: 0.8068\n",
            "Epoch 148/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.4360 - accuracy: 0.8241 - val_loss: 0.5797 - val_accuracy: 0.7681\n",
            "Epoch 149/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.3991 - accuracy: 0.8476 - val_loss: 0.5625 - val_accuracy: 0.7778\n",
            "Epoch 150/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.4273 - accuracy: 0.8271 - val_loss: 0.5754 - val_accuracy: 0.7874\n",
            "Epoch 151/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.4046 - accuracy: 0.8489 - val_loss: 0.6000 - val_accuracy: 0.7440\n",
            "Epoch 152/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.3958 - accuracy: 0.8549 - val_loss: 0.5764 - val_accuracy: 0.7874\n",
            "Epoch 153/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.3833 - accuracy: 0.8591 - val_loss: 0.5561 - val_accuracy: 0.8068\n",
            "Epoch 154/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.3803 - accuracy: 0.8676 - val_loss: 0.5735 - val_accuracy: 0.7778\n",
            "Epoch 155/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.3723 - accuracy: 0.8543 - val_loss: 0.5705 - val_accuracy: 0.7971\n",
            "Epoch 156/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.3970 - accuracy: 0.8525 - val_loss: 0.5866 - val_accuracy: 0.8068\n",
            "Epoch 157/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.3834 - accuracy: 0.8573 - val_loss: 0.5672 - val_accuracy: 0.8019\n",
            "Epoch 158/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.3678 - accuracy: 0.8579 - val_loss: 0.5877 - val_accuracy: 0.7826\n",
            "Epoch 159/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.3618 - accuracy: 0.8555 - val_loss: 0.5645 - val_accuracy: 0.7874\n",
            "Epoch 160/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.3986 - accuracy: 0.8531 - val_loss: 0.5609 - val_accuracy: 0.7923\n",
            "Epoch 161/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.3963 - accuracy: 0.8392 - val_loss: 0.5669 - val_accuracy: 0.8068\n",
            "Epoch 162/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.3561 - accuracy: 0.8634 - val_loss: 0.5513 - val_accuracy: 0.7971\n",
            "Epoch 163/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.3737 - accuracy: 0.8615 - val_loss: 0.5655 - val_accuracy: 0.7971\n",
            "Epoch 164/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.3717 - accuracy: 0.8543 - val_loss: 0.5516 - val_accuracy: 0.7874\n",
            "Epoch 165/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.3564 - accuracy: 0.8664 - val_loss: 0.5677 - val_accuracy: 0.7826\n",
            "Epoch 166/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.3663 - accuracy: 0.8688 - val_loss: 0.5757 - val_accuracy: 0.7778\n",
            "Epoch 167/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.3713 - accuracy: 0.8549 - val_loss: 0.5467 - val_accuracy: 0.8164\n",
            "Epoch 168/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.3632 - accuracy: 0.8658 - val_loss: 0.5731 - val_accuracy: 0.8068\n",
            "Epoch 169/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.3545 - accuracy: 0.8664 - val_loss: 0.5465 - val_accuracy: 0.8019\n",
            "Epoch 170/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.3364 - accuracy: 0.8682 - val_loss: 0.5406 - val_accuracy: 0.8068\n",
            "Epoch 171/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.3436 - accuracy: 0.8670 - val_loss: 0.5624 - val_accuracy: 0.8019\n",
            "Epoch 172/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.3397 - accuracy: 0.8670 - val_loss: 0.5322 - val_accuracy: 0.7874\n",
            "Epoch 173/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.3326 - accuracy: 0.8809 - val_loss: 0.5409 - val_accuracy: 0.8164\n",
            "Epoch 174/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.3271 - accuracy: 0.8797 - val_loss: 0.5553 - val_accuracy: 0.7971\n",
            "Epoch 175/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.3301 - accuracy: 0.8730 - val_loss: 0.5329 - val_accuracy: 0.8309\n",
            "Epoch 176/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.3473 - accuracy: 0.8706 - val_loss: 0.5587 - val_accuracy: 0.7971\n",
            "Epoch 177/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.3289 - accuracy: 0.8821 - val_loss: 0.5639 - val_accuracy: 0.7874\n",
            "Epoch 178/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.3072 - accuracy: 0.8797 - val_loss: 0.5204 - val_accuracy: 0.8309\n",
            "Epoch 179/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.3269 - accuracy: 0.8809 - val_loss: 0.5942 - val_accuracy: 0.7778\n",
            "Epoch 180/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.3223 - accuracy: 0.8742 - val_loss: 0.5517 - val_accuracy: 0.8309\n",
            "Epoch 181/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.3194 - accuracy: 0.8888 - val_loss: 0.5614 - val_accuracy: 0.8357\n",
            "Epoch 182/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.2936 - accuracy: 0.8948 - val_loss: 0.5892 - val_accuracy: 0.7971\n",
            "Epoch 183/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.3281 - accuracy: 0.8730 - val_loss: 0.5820 - val_accuracy: 0.7971\n",
            "Epoch 184/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.3261 - accuracy: 0.8779 - val_loss: 0.5522 - val_accuracy: 0.8164\n",
            "Epoch 185/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.3166 - accuracy: 0.8833 - val_loss: 0.5574 - val_accuracy: 0.8116\n",
            "Epoch 186/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.3011 - accuracy: 0.8960 - val_loss: 0.5297 - val_accuracy: 0.8261\n",
            "Epoch 187/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.3172 - accuracy: 0.8755 - val_loss: 0.5154 - val_accuracy: 0.8164\n",
            "Epoch 188/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.3078 - accuracy: 0.8833 - val_loss: 0.5307 - val_accuracy: 0.8406\n",
            "Epoch 189/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.2900 - accuracy: 0.8924 - val_loss: 0.5249 - val_accuracy: 0.8357\n",
            "Epoch 190/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.3107 - accuracy: 0.8821 - val_loss: 0.5050 - val_accuracy: 0.8309\n",
            "Epoch 191/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.3025 - accuracy: 0.8954 - val_loss: 0.5512 - val_accuracy: 0.8068\n",
            "Epoch 192/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.2897 - accuracy: 0.8984 - val_loss: 0.5464 - val_accuracy: 0.7923\n",
            "Epoch 193/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.3036 - accuracy: 0.8827 - val_loss: 0.5266 - val_accuracy: 0.8213\n",
            "Epoch 194/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.2833 - accuracy: 0.8942 - val_loss: 0.5521 - val_accuracy: 0.8164\n",
            "Epoch 195/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.3022 - accuracy: 0.8942 - val_loss: 0.5129 - val_accuracy: 0.8309\n",
            "Epoch 196/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.2768 - accuracy: 0.9008 - val_loss: 0.6135 - val_accuracy: 0.7923\n",
            "Epoch 197/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.2691 - accuracy: 0.9099 - val_loss: 0.5430 - val_accuracy: 0.8261\n",
            "Epoch 198/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.2842 - accuracy: 0.8918 - val_loss: 0.5808 - val_accuracy: 0.8019\n",
            "Epoch 199/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.2966 - accuracy: 0.8857 - val_loss: 0.4955 - val_accuracy: 0.8116\n",
            "Epoch 200/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.2496 - accuracy: 0.9123 - val_loss: 0.5118 - val_accuracy: 0.8164\n",
            "Epoch 201/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.2955 - accuracy: 0.8857 - val_loss: 0.5348 - val_accuracy: 0.7971\n",
            "Epoch 202/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.2991 - accuracy: 0.8839 - val_loss: 0.5479 - val_accuracy: 0.8261\n",
            "Epoch 203/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.2817 - accuracy: 0.8948 - val_loss: 0.5660 - val_accuracy: 0.8019\n",
            "Epoch 204/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.2954 - accuracy: 0.8851 - val_loss: 0.5157 - val_accuracy: 0.8357\n",
            "Epoch 205/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.2676 - accuracy: 0.8966 - val_loss: 0.5365 - val_accuracy: 0.7971\n",
            "Epoch 206/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.2718 - accuracy: 0.9015 - val_loss: 0.5381 - val_accuracy: 0.8116\n",
            "Epoch 207/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.2478 - accuracy: 0.9117 - val_loss: 0.4628 - val_accuracy: 0.8357\n",
            "Epoch 208/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.2543 - accuracy: 0.9015 - val_loss: 0.4977 - val_accuracy: 0.8454\n",
            "Epoch 209/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.2643 - accuracy: 0.9039 - val_loss: 0.5182 - val_accuracy: 0.8261\n",
            "Epoch 210/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.2516 - accuracy: 0.9154 - val_loss: 0.5442 - val_accuracy: 0.8164\n",
            "Epoch 211/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.2604 - accuracy: 0.9033 - val_loss: 0.4879 - val_accuracy: 0.8068\n",
            "Epoch 212/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.2532 - accuracy: 0.9033 - val_loss: 0.5339 - val_accuracy: 0.8309\n",
            "Epoch 213/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.2496 - accuracy: 0.9087 - val_loss: 0.5320 - val_accuracy: 0.8164\n",
            "Epoch 214/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.2427 - accuracy: 0.9123 - val_loss: 0.4945 - val_accuracy: 0.8502\n",
            "Epoch 215/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.2520 - accuracy: 0.9148 - val_loss: 0.5107 - val_accuracy: 0.8309\n",
            "Epoch 216/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.2553 - accuracy: 0.9093 - val_loss: 0.5104 - val_accuracy: 0.8164\n",
            "Epoch 217/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.2602 - accuracy: 0.8984 - val_loss: 0.5482 - val_accuracy: 0.7971\n",
            "Epoch 218/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.2556 - accuracy: 0.9008 - val_loss: 0.5700 - val_accuracy: 0.7585\n",
            "Epoch 219/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.2502 - accuracy: 0.9111 - val_loss: 0.5047 - val_accuracy: 0.8116\n",
            "Epoch 220/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.2451 - accuracy: 0.9063 - val_loss: 0.5337 - val_accuracy: 0.8261\n",
            "Epoch 221/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.2612 - accuracy: 0.9069 - val_loss: 0.5506 - val_accuracy: 0.8116\n",
            "Epoch 222/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.2479 - accuracy: 0.8996 - val_loss: 0.5260 - val_accuracy: 0.8213\n",
            "Epoch 223/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.2159 - accuracy: 0.9281 - val_loss: 0.4743 - val_accuracy: 0.8454\n",
            "Epoch 224/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.2328 - accuracy: 0.9148 - val_loss: 0.5133 - val_accuracy: 0.8261\n",
            "Epoch 225/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.2624 - accuracy: 0.9015 - val_loss: 0.5245 - val_accuracy: 0.8164\n",
            "Epoch 226/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.2542 - accuracy: 0.9057 - val_loss: 0.5744 - val_accuracy: 0.7923\n",
            "Epoch 227/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.2475 - accuracy: 0.9051 - val_loss: 0.5500 - val_accuracy: 0.7874\n",
            "Epoch 228/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.2285 - accuracy: 0.9154 - val_loss: 0.4830 - val_accuracy: 0.8357\n",
            "Epoch 229/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.2168 - accuracy: 0.9196 - val_loss: 0.5137 - val_accuracy: 0.8357\n",
            "Epoch 230/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.2437 - accuracy: 0.9117 - val_loss: 0.5007 - val_accuracy: 0.8357\n",
            "Epoch 231/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.2338 - accuracy: 0.9099 - val_loss: 0.5196 - val_accuracy: 0.8406\n",
            "Epoch 232/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.2401 - accuracy: 0.9148 - val_loss: 0.5442 - val_accuracy: 0.8019\n",
            "Epoch 233/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.2221 - accuracy: 0.9208 - val_loss: 0.5089 - val_accuracy: 0.8164\n",
            "Epoch 234/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.2314 - accuracy: 0.9099 - val_loss: 0.5435 - val_accuracy: 0.8164\n",
            "Epoch 235/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.2373 - accuracy: 0.9129 - val_loss: 0.5055 - val_accuracy: 0.8164\n",
            "Epoch 236/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.2153 - accuracy: 0.9238 - val_loss: 0.5094 - val_accuracy: 0.8309\n",
            "Epoch 237/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.2021 - accuracy: 0.9244 - val_loss: 0.5109 - val_accuracy: 0.8309\n",
            "Epoch 238/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.1996 - accuracy: 0.9244 - val_loss: 0.5203 - val_accuracy: 0.7923\n",
            "Epoch 239/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.2173 - accuracy: 0.9178 - val_loss: 0.5253 - val_accuracy: 0.8116\n",
            "Epoch 240/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.2396 - accuracy: 0.9166 - val_loss: 0.5300 - val_accuracy: 0.8164\n",
            "Epoch 241/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.2349 - accuracy: 0.9099 - val_loss: 0.6001 - val_accuracy: 0.7826\n",
            "Epoch 242/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.2211 - accuracy: 0.9256 - val_loss: 0.4879 - val_accuracy: 0.8309\n",
            "Epoch 243/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.1969 - accuracy: 0.9305 - val_loss: 0.5098 - val_accuracy: 0.8261\n",
            "Epoch 244/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.2131 - accuracy: 0.9172 - val_loss: 0.4971 - val_accuracy: 0.8261\n",
            "Epoch 245/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.1995 - accuracy: 0.9287 - val_loss: 0.5219 - val_accuracy: 0.8213\n",
            "Epoch 246/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.2003 - accuracy: 0.9214 - val_loss: 0.5386 - val_accuracy: 0.8454\n",
            "Epoch 247/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.2173 - accuracy: 0.9087 - val_loss: 0.5748 - val_accuracy: 0.8213\n",
            "Epoch 248/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.2443 - accuracy: 0.9063 - val_loss: 0.5557 - val_accuracy: 0.8164\n",
            "Epoch 249/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.2085 - accuracy: 0.9238 - val_loss: 0.4928 - val_accuracy: 0.8309\n",
            "Epoch 250/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.2349 - accuracy: 0.9184 - val_loss: 0.5450 - val_accuracy: 0.8164\n",
            "Epoch 251/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.2013 - accuracy: 0.9281 - val_loss: 0.4804 - val_accuracy: 0.8309\n",
            "Epoch 252/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.1959 - accuracy: 0.9262 - val_loss: 0.5227 - val_accuracy: 0.8309\n",
            "Epoch 253/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.2154 - accuracy: 0.9226 - val_loss: 0.4908 - val_accuracy: 0.8502\n",
            "Epoch 254/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.1830 - accuracy: 0.9281 - val_loss: 0.4774 - val_accuracy: 0.8406\n",
            "Epoch 255/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.2037 - accuracy: 0.9305 - val_loss: 0.5436 - val_accuracy: 0.8019\n",
            "Epoch 256/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.1929 - accuracy: 0.9281 - val_loss: 0.4658 - val_accuracy: 0.8502\n",
            "Epoch 257/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.2147 - accuracy: 0.9256 - val_loss: 0.5006 - val_accuracy: 0.8454\n",
            "Epoch 258/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.1928 - accuracy: 0.9250 - val_loss: 0.5028 - val_accuracy: 0.8357\n",
            "Epoch 259/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.2139 - accuracy: 0.9226 - val_loss: 0.5161 - val_accuracy: 0.7971\n",
            "Epoch 260/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.2047 - accuracy: 0.9287 - val_loss: 0.5464 - val_accuracy: 0.8116\n",
            "Epoch 261/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.1935 - accuracy: 0.9274 - val_loss: 0.4689 - val_accuracy: 0.8454\n",
            "Epoch 262/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.1976 - accuracy: 0.9305 - val_loss: 0.5481 - val_accuracy: 0.8406\n",
            "Epoch 263/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.1958 - accuracy: 0.9335 - val_loss: 0.5507 - val_accuracy: 0.8019\n",
            "Epoch 264/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.1915 - accuracy: 0.9281 - val_loss: 0.5365 - val_accuracy: 0.8261\n",
            "Epoch 265/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.1807 - accuracy: 0.9371 - val_loss: 0.5602 - val_accuracy: 0.8068\n",
            "Epoch 266/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.2005 - accuracy: 0.9250 - val_loss: 0.5410 - val_accuracy: 0.8357\n",
            "Epoch 267/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.2090 - accuracy: 0.9244 - val_loss: 0.5279 - val_accuracy: 0.8213\n",
            "Epoch 268/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.1709 - accuracy: 0.9401 - val_loss: 0.5227 - val_accuracy: 0.8309\n",
            "Epoch 269/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.1748 - accuracy: 0.9371 - val_loss: 0.6303 - val_accuracy: 0.7778\n",
            "Epoch 270/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.2072 - accuracy: 0.9232 - val_loss: 0.5125 - val_accuracy: 0.8599\n",
            "Epoch 271/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.1821 - accuracy: 0.9317 - val_loss: 0.5459 - val_accuracy: 0.8502\n",
            "Epoch 272/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.2237 - accuracy: 0.9220 - val_loss: 0.5023 - val_accuracy: 0.8164\n",
            "Epoch 273/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.1863 - accuracy: 0.9377 - val_loss: 0.5683 - val_accuracy: 0.8068\n",
            "Epoch 274/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.1823 - accuracy: 0.9323 - val_loss: 0.4448 - val_accuracy: 0.8406\n",
            "Epoch 275/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.1942 - accuracy: 0.9365 - val_loss: 0.4856 - val_accuracy: 0.8116\n",
            "Epoch 276/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.1777 - accuracy: 0.9323 - val_loss: 0.4868 - val_accuracy: 0.8309\n",
            "Epoch 277/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.1732 - accuracy: 0.9389 - val_loss: 0.4562 - val_accuracy: 0.8502\n",
            "Epoch 278/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.1650 - accuracy: 0.9462 - val_loss: 0.4629 - val_accuracy: 0.8357\n",
            "Epoch 279/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.1596 - accuracy: 0.9414 - val_loss: 0.5007 - val_accuracy: 0.8454\n",
            "Epoch 280/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.1584 - accuracy: 0.9450 - val_loss: 0.5258 - val_accuracy: 0.8309\n",
            "Epoch 281/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.2080 - accuracy: 0.9244 - val_loss: 0.5598 - val_accuracy: 0.8164\n",
            "Epoch 282/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.1833 - accuracy: 0.9299 - val_loss: 0.5776 - val_accuracy: 0.7923\n",
            "Epoch 283/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.1935 - accuracy: 0.9244 - val_loss: 0.4674 - val_accuracy: 0.8696\n",
            "Epoch 284/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.1703 - accuracy: 0.9414 - val_loss: 0.5271 - val_accuracy: 0.8309\n",
            "Epoch 285/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.1760 - accuracy: 0.9335 - val_loss: 0.5120 - val_accuracy: 0.8357\n",
            "Epoch 286/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.1678 - accuracy: 0.9450 - val_loss: 0.5235 - val_accuracy: 0.8116\n",
            "Epoch 287/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.1648 - accuracy: 0.9347 - val_loss: 0.5415 - val_accuracy: 0.8213\n",
            "Epoch 288/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.1763 - accuracy: 0.9359 - val_loss: 0.5480 - val_accuracy: 0.8164\n",
            "Epoch 289/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.1785 - accuracy: 0.9377 - val_loss: 0.4844 - val_accuracy: 0.8502\n",
            "Epoch 290/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.1702 - accuracy: 0.9365 - val_loss: 0.4993 - val_accuracy: 0.8357\n",
            "Epoch 291/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.1757 - accuracy: 0.9365 - val_loss: 0.5102 - val_accuracy: 0.8551\n",
            "Epoch 292/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.1652 - accuracy: 0.9401 - val_loss: 0.4964 - val_accuracy: 0.8309\n",
            "Epoch 293/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.1792 - accuracy: 0.9353 - val_loss: 0.5484 - val_accuracy: 0.8213\n",
            "Epoch 294/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.1954 - accuracy: 0.9238 - val_loss: 0.5155 - val_accuracy: 0.8357\n",
            "Epoch 295/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.1848 - accuracy: 0.9323 - val_loss: 0.5220 - val_accuracy: 0.8261\n",
            "Epoch 296/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.1547 - accuracy: 0.9486 - val_loss: 0.4882 - val_accuracy: 0.8261\n",
            "Epoch 297/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.1607 - accuracy: 0.9420 - val_loss: 0.4995 - val_accuracy: 0.8357\n",
            "Epoch 298/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.1777 - accuracy: 0.9347 - val_loss: 0.4529 - val_accuracy: 0.8309\n",
            "Epoch 299/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.1374 - accuracy: 0.9492 - val_loss: 0.4573 - val_accuracy: 0.8551\n",
            "Epoch 300/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.1689 - accuracy: 0.9389 - val_loss: 0.5161 - val_accuracy: 0.8309\n",
            "Epoch 301/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.1530 - accuracy: 0.9474 - val_loss: 0.4943 - val_accuracy: 0.8213\n",
            "Epoch 302/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.1441 - accuracy: 0.9486 - val_loss: 0.5107 - val_accuracy: 0.8357\n",
            "Epoch 303/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.1349 - accuracy: 0.9522 - val_loss: 0.4750 - val_accuracy: 0.8599\n",
            "Epoch 304/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.1394 - accuracy: 0.9462 - val_loss: 0.5650 - val_accuracy: 0.8019\n",
            "Epoch 305/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.1529 - accuracy: 0.9456 - val_loss: 0.5218 - val_accuracy: 0.8261\n",
            "Epoch 306/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.1688 - accuracy: 0.9317 - val_loss: 0.5024 - val_accuracy: 0.8454\n",
            "Epoch 307/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.1700 - accuracy: 0.9401 - val_loss: 0.5096 - val_accuracy: 0.8213\n",
            "Epoch 308/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.1927 - accuracy: 0.9299 - val_loss: 0.5341 - val_accuracy: 0.8068\n",
            "Epoch 309/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.1425 - accuracy: 0.9456 - val_loss: 0.5540 - val_accuracy: 0.8213\n",
            "Epoch 310/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.1806 - accuracy: 0.9383 - val_loss: 0.4784 - val_accuracy: 0.8309\n",
            "Epoch 311/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.1604 - accuracy: 0.9420 - val_loss: 0.5212 - val_accuracy: 0.8357\n",
            "Epoch 312/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.1699 - accuracy: 0.9335 - val_loss: 0.5256 - val_accuracy: 0.8502\n",
            "Epoch 313/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.1865 - accuracy: 0.9317 - val_loss: 0.5311 - val_accuracy: 0.8309\n",
            "Epoch 314/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.1764 - accuracy: 0.9377 - val_loss: 0.5158 - val_accuracy: 0.8454\n",
            "Epoch 315/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.1516 - accuracy: 0.9450 - val_loss: 0.4600 - val_accuracy: 0.8357\n",
            "Epoch 316/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.1374 - accuracy: 0.9486 - val_loss: 0.4811 - val_accuracy: 0.8744\n",
            "Epoch 317/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.1499 - accuracy: 0.9407 - val_loss: 0.5333 - val_accuracy: 0.8019\n",
            "Epoch 318/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.1400 - accuracy: 0.9480 - val_loss: 0.5383 - val_accuracy: 0.8116\n",
            "Epoch 319/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.1426 - accuracy: 0.9462 - val_loss: 0.5017 - val_accuracy: 0.8261\n",
            "Epoch 320/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.1532 - accuracy: 0.9432 - val_loss: 0.4564 - val_accuracy: 0.8551\n",
            "Epoch 321/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.1583 - accuracy: 0.9498 - val_loss: 0.5434 - val_accuracy: 0.8357\n",
            "Epoch 322/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.1464 - accuracy: 0.9426 - val_loss: 0.5560 - val_accuracy: 0.8213\n",
            "Epoch 323/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.1361 - accuracy: 0.9522 - val_loss: 0.4822 - val_accuracy: 0.8502\n",
            "Epoch 324/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.1559 - accuracy: 0.9407 - val_loss: 0.5405 - val_accuracy: 0.8213\n",
            "Epoch 325/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.1379 - accuracy: 0.9516 - val_loss: 0.5068 - val_accuracy: 0.8599\n",
            "Epoch 326/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.1454 - accuracy: 0.9480 - val_loss: 0.4940 - val_accuracy: 0.8454\n",
            "Epoch 327/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.1508 - accuracy: 0.9474 - val_loss: 0.4897 - val_accuracy: 0.8696\n",
            "Epoch 328/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.1548 - accuracy: 0.9444 - val_loss: 0.5638 - val_accuracy: 0.8454\n",
            "Epoch 329/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.1643 - accuracy: 0.9407 - val_loss: 0.5652 - val_accuracy: 0.8357\n",
            "Epoch 330/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.1444 - accuracy: 0.9486 - val_loss: 0.5170 - val_accuracy: 0.8213\n",
            "Epoch 331/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.1616 - accuracy: 0.9371 - val_loss: 0.4992 - val_accuracy: 0.8357\n",
            "Epoch 332/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.1432 - accuracy: 0.9547 - val_loss: 0.5341 - val_accuracy: 0.8261\n",
            "Epoch 333/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.1529 - accuracy: 0.9401 - val_loss: 0.4950 - val_accuracy: 0.8551\n",
            "Epoch 334/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.1382 - accuracy: 0.9504 - val_loss: 0.5003 - val_accuracy: 0.8502\n",
            "Epoch 335/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.1589 - accuracy: 0.9377 - val_loss: 0.5005 - val_accuracy: 0.8551\n",
            "Epoch 336/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.1652 - accuracy: 0.9347 - val_loss: 0.5419 - val_accuracy: 0.7971\n",
            "Epoch 337/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.1325 - accuracy: 0.9522 - val_loss: 0.5135 - val_accuracy: 0.8357\n",
            "Epoch 338/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.1470 - accuracy: 0.9498 - val_loss: 0.5474 - val_accuracy: 0.8406\n",
            "Epoch 339/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.1510 - accuracy: 0.9450 - val_loss: 0.5232 - val_accuracy: 0.8309\n",
            "Epoch 340/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.1643 - accuracy: 0.9389 - val_loss: 0.5742 - val_accuracy: 0.8116\n",
            "Epoch 341/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.1493 - accuracy: 0.9456 - val_loss: 0.4970 - val_accuracy: 0.8357\n",
            "Epoch 342/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.1458 - accuracy: 0.9486 - val_loss: 0.5245 - val_accuracy: 0.8164\n",
            "Epoch 343/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.1434 - accuracy: 0.9456 - val_loss: 0.5516 - val_accuracy: 0.8309\n",
            "Epoch 344/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.1468 - accuracy: 0.9462 - val_loss: 0.4834 - val_accuracy: 0.8502\n",
            "Epoch 345/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.1368 - accuracy: 0.9522 - val_loss: 0.4584 - val_accuracy: 0.8406\n",
            "Epoch 346/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.1318 - accuracy: 0.9522 - val_loss: 0.4954 - val_accuracy: 0.8309\n",
            "Epoch 347/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.1597 - accuracy: 0.9492 - val_loss: 0.4803 - val_accuracy: 0.8261\n",
            "Epoch 348/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.1268 - accuracy: 0.9522 - val_loss: 0.5296 - val_accuracy: 0.8309\n",
            "Epoch 349/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.1554 - accuracy: 0.9426 - val_loss: 0.5694 - val_accuracy: 0.8357\n",
            "Epoch 350/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.1682 - accuracy: 0.9407 - val_loss: 0.5136 - val_accuracy: 0.8406\n",
            "Epoch 351/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.1163 - accuracy: 0.9595 - val_loss: 0.4933 - val_accuracy: 0.8406\n",
            "Epoch 352/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.1315 - accuracy: 0.9528 - val_loss: 0.5109 - val_accuracy: 0.8019\n",
            "Epoch 353/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.1384 - accuracy: 0.9516 - val_loss: 0.5241 - val_accuracy: 0.8116\n",
            "Epoch 354/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.1185 - accuracy: 0.9583 - val_loss: 0.4262 - val_accuracy: 0.8647\n",
            "Epoch 355/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.1156 - accuracy: 0.9589 - val_loss: 0.4958 - val_accuracy: 0.8357\n",
            "Epoch 356/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.0973 - accuracy: 0.9643 - val_loss: 0.5173 - val_accuracy: 0.8406\n",
            "Epoch 357/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.1552 - accuracy: 0.9426 - val_loss: 0.5456 - val_accuracy: 0.8213\n",
            "Epoch 358/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.1639 - accuracy: 0.9407 - val_loss: 0.5685 - val_accuracy: 0.8406\n",
            "Epoch 359/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.1274 - accuracy: 0.9516 - val_loss: 0.5160 - val_accuracy: 0.8406\n",
            "Epoch 360/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.1135 - accuracy: 0.9547 - val_loss: 0.5102 - val_accuracy: 0.8454\n",
            "Epoch 361/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.1484 - accuracy: 0.9480 - val_loss: 0.5158 - val_accuracy: 0.8454\n",
            "Epoch 362/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.1143 - accuracy: 0.9631 - val_loss: 0.5205 - val_accuracy: 0.8502\n",
            "Epoch 363/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.1339 - accuracy: 0.9522 - val_loss: 0.5655 - val_accuracy: 0.8551\n",
            "Epoch 364/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.1730 - accuracy: 0.9432 - val_loss: 0.4936 - val_accuracy: 0.8406\n",
            "Epoch 365/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.1348 - accuracy: 0.9528 - val_loss: 0.5237 - val_accuracy: 0.8406\n",
            "Epoch 366/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.1294 - accuracy: 0.9510 - val_loss: 0.5819 - val_accuracy: 0.8068\n",
            "Epoch 367/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.1220 - accuracy: 0.9541 - val_loss: 0.4636 - val_accuracy: 0.8599\n",
            "Epoch 368/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.1528 - accuracy: 0.9480 - val_loss: 0.5306 - val_accuracy: 0.8261\n",
            "Epoch 369/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.1555 - accuracy: 0.9474 - val_loss: 0.5422 - val_accuracy: 0.8164\n",
            "Epoch 370/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.1281 - accuracy: 0.9541 - val_loss: 0.5053 - val_accuracy: 0.8599\n",
            "Epoch 371/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.1440 - accuracy: 0.9444 - val_loss: 0.5464 - val_accuracy: 0.8116\n",
            "Epoch 372/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.1347 - accuracy: 0.9541 - val_loss: 0.5150 - val_accuracy: 0.8502\n",
            "Epoch 373/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.1288 - accuracy: 0.9498 - val_loss: 0.4589 - val_accuracy: 0.8551\n",
            "Epoch 374/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.1230 - accuracy: 0.9565 - val_loss: 0.5801 - val_accuracy: 0.8502\n",
            "Epoch 375/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.1364 - accuracy: 0.9504 - val_loss: 0.5574 - val_accuracy: 0.8261\n",
            "Epoch 376/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.1345 - accuracy: 0.9528 - val_loss: 0.6088 - val_accuracy: 0.8116\n",
            "Epoch 377/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.1433 - accuracy: 0.9462 - val_loss: 0.5566 - val_accuracy: 0.8164\n",
            "Epoch 378/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.1232 - accuracy: 0.9534 - val_loss: 0.4630 - val_accuracy: 0.8599\n",
            "Epoch 379/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.1265 - accuracy: 0.9601 - val_loss: 0.5240 - val_accuracy: 0.8357\n",
            "Epoch 380/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.1285 - accuracy: 0.9510 - val_loss: 0.5002 - val_accuracy: 0.8309\n",
            "Epoch 381/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.1509 - accuracy: 0.9432 - val_loss: 0.5092 - val_accuracy: 0.8261\n",
            "Epoch 382/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.1485 - accuracy: 0.9444 - val_loss: 0.5120 - val_accuracy: 0.8309\n",
            "Epoch 383/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.1232 - accuracy: 0.9528 - val_loss: 0.5090 - val_accuracy: 0.8213\n",
            "Epoch 384/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.1350 - accuracy: 0.9516 - val_loss: 0.5238 - val_accuracy: 0.8502\n",
            "Epoch 385/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.1147 - accuracy: 0.9595 - val_loss: 0.5086 - val_accuracy: 0.8647\n",
            "Epoch 386/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.1076 - accuracy: 0.9607 - val_loss: 0.5274 - val_accuracy: 0.8454\n",
            "Epoch 387/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.1114 - accuracy: 0.9601 - val_loss: 0.5155 - val_accuracy: 0.8599\n",
            "Epoch 388/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.1405 - accuracy: 0.9468 - val_loss: 0.5606 - val_accuracy: 0.8309\n",
            "Epoch 389/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.1289 - accuracy: 0.9547 - val_loss: 0.5211 - val_accuracy: 0.8406\n",
            "Epoch 390/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.1261 - accuracy: 0.9589 - val_loss: 0.5238 - val_accuracy: 0.8357\n",
            "Epoch 391/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.1254 - accuracy: 0.9595 - val_loss: 0.5453 - val_accuracy: 0.8551\n",
            "Epoch 392/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.1298 - accuracy: 0.9522 - val_loss: 0.4903 - val_accuracy: 0.8502\n",
            "Epoch 393/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.1311 - accuracy: 0.9571 - val_loss: 0.5303 - val_accuracy: 0.8551\n",
            "Epoch 394/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.1189 - accuracy: 0.9619 - val_loss: 0.4784 - val_accuracy: 0.8454\n",
            "Epoch 395/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.1289 - accuracy: 0.9577 - val_loss: 0.5119 - val_accuracy: 0.8696\n",
            "Epoch 396/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.1452 - accuracy: 0.9516 - val_loss: 0.5001 - val_accuracy: 0.8551\n",
            "Epoch 397/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.0979 - accuracy: 0.9661 - val_loss: 0.4665 - val_accuracy: 0.8744\n",
            "Epoch 398/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.1179 - accuracy: 0.9613 - val_loss: 0.4710 - val_accuracy: 0.8502\n",
            "Epoch 399/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.1161 - accuracy: 0.9565 - val_loss: 0.4870 - val_accuracy: 0.8551\n",
            "Epoch 400/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.1280 - accuracy: 0.9498 - val_loss: 0.5554 - val_accuracy: 0.8406\n",
            "Epoch 401/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.1151 - accuracy: 0.9577 - val_loss: 0.4982 - val_accuracy: 0.8696\n",
            "Epoch 402/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.1352 - accuracy: 0.9468 - val_loss: 0.5430 - val_accuracy: 0.8357\n",
            "Epoch 403/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.1135 - accuracy: 0.9559 - val_loss: 0.5420 - val_accuracy: 0.8551\n",
            "Epoch 404/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.1094 - accuracy: 0.9589 - val_loss: 0.5494 - val_accuracy: 0.8261\n",
            "Epoch 405/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.1037 - accuracy: 0.9655 - val_loss: 0.4970 - val_accuracy: 0.8454\n",
            "Epoch 406/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.1205 - accuracy: 0.9577 - val_loss: 0.5209 - val_accuracy: 0.8068\n",
            "Epoch 407/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.1321 - accuracy: 0.9486 - val_loss: 0.5391 - val_accuracy: 0.8357\n",
            "Epoch 408/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.1156 - accuracy: 0.9607 - val_loss: 0.5618 - val_accuracy: 0.8502\n",
            "Epoch 409/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.0952 - accuracy: 0.9686 - val_loss: 0.5427 - val_accuracy: 0.8406\n",
            "Epoch 410/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.1195 - accuracy: 0.9528 - val_loss: 0.6016 - val_accuracy: 0.8019\n",
            "Epoch 411/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.1271 - accuracy: 0.9534 - val_loss: 0.5643 - val_accuracy: 0.8502\n",
            "Epoch 412/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.1292 - accuracy: 0.9528 - val_loss: 0.4838 - val_accuracy: 0.8744\n",
            "Epoch 413/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.1238 - accuracy: 0.9534 - val_loss: 0.5078 - val_accuracy: 0.8309\n",
            "Epoch 414/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.1141 - accuracy: 0.9601 - val_loss: 0.4906 - val_accuracy: 0.8454\n",
            "Epoch 415/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.0925 - accuracy: 0.9649 - val_loss: 0.5105 - val_accuracy: 0.8647\n",
            "Epoch 416/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.1040 - accuracy: 0.9619 - val_loss: 0.5535 - val_accuracy: 0.8502\n",
            "Epoch 417/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.1143 - accuracy: 0.9589 - val_loss: 0.4913 - val_accuracy: 0.8744\n",
            "Epoch 418/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.1423 - accuracy: 0.9522 - val_loss: 0.5450 - val_accuracy: 0.8406\n",
            "Epoch 419/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.1184 - accuracy: 0.9583 - val_loss: 0.5345 - val_accuracy: 0.8406\n",
            "Epoch 420/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.1185 - accuracy: 0.9583 - val_loss: 0.4989 - val_accuracy: 0.8551\n",
            "Epoch 421/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.1339 - accuracy: 0.9498 - val_loss: 0.5210 - val_accuracy: 0.8599\n",
            "Epoch 422/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.1145 - accuracy: 0.9565 - val_loss: 0.4566 - val_accuracy: 0.8599\n",
            "Epoch 423/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.1115 - accuracy: 0.9613 - val_loss: 0.4436 - val_accuracy: 0.8647\n",
            "Epoch 424/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.0861 - accuracy: 0.9734 - val_loss: 0.4890 - val_accuracy: 0.8647\n",
            "Epoch 425/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.1067 - accuracy: 0.9583 - val_loss: 0.4752 - val_accuracy: 0.8454\n",
            "Epoch 426/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.1186 - accuracy: 0.9547 - val_loss: 0.4911 - val_accuracy: 0.8261\n",
            "Epoch 427/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.0997 - accuracy: 0.9625 - val_loss: 0.4870 - val_accuracy: 0.8357\n",
            "Epoch 428/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.1003 - accuracy: 0.9607 - val_loss: 0.4896 - val_accuracy: 0.8406\n",
            "Epoch 429/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.1302 - accuracy: 0.9534 - val_loss: 0.5339 - val_accuracy: 0.8309\n",
            "Epoch 430/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.1320 - accuracy: 0.9547 - val_loss: 0.5382 - val_accuracy: 0.8309\n",
            "Epoch 431/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.1107 - accuracy: 0.9571 - val_loss: 0.5247 - val_accuracy: 0.8357\n",
            "Epoch 432/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.1142 - accuracy: 0.9595 - val_loss: 0.5149 - val_accuracy: 0.8454\n",
            "Epoch 433/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.1388 - accuracy: 0.9553 - val_loss: 0.6147 - val_accuracy: 0.8164\n",
            "Epoch 434/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.1216 - accuracy: 0.9541 - val_loss: 0.5100 - val_accuracy: 0.8647\n",
            "Epoch 435/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.1275 - accuracy: 0.9534 - val_loss: 0.4990 - val_accuracy: 0.8502\n",
            "Epoch 436/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.0841 - accuracy: 0.9698 - val_loss: 0.4898 - val_accuracy: 0.8502\n",
            "Epoch 437/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.1173 - accuracy: 0.9559 - val_loss: 0.5630 - val_accuracy: 0.8261\n",
            "Epoch 438/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.1237 - accuracy: 0.9553 - val_loss: 0.4945 - val_accuracy: 0.8454\n",
            "Epoch 439/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.1058 - accuracy: 0.9595 - val_loss: 0.5156 - val_accuracy: 0.8406\n",
            "Epoch 440/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.1100 - accuracy: 0.9559 - val_loss: 0.4998 - val_accuracy: 0.8406\n",
            "Epoch 441/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.0922 - accuracy: 0.9680 - val_loss: 0.4616 - val_accuracy: 0.8599\n",
            "Epoch 442/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.1195 - accuracy: 0.9607 - val_loss: 0.5368 - val_accuracy: 0.8406\n",
            "Epoch 443/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.1102 - accuracy: 0.9571 - val_loss: 0.5241 - val_accuracy: 0.8357\n",
            "Epoch 444/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.1189 - accuracy: 0.9577 - val_loss: 0.5652 - val_accuracy: 0.8357\n",
            "Epoch 445/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.1109 - accuracy: 0.9625 - val_loss: 0.5280 - val_accuracy: 0.8454\n",
            "Epoch 446/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.1037 - accuracy: 0.9643 - val_loss: 0.5742 - val_accuracy: 0.8502\n",
            "Epoch 447/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.1120 - accuracy: 0.9547 - val_loss: 0.5727 - val_accuracy: 0.8261\n",
            "Epoch 448/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.1118 - accuracy: 0.9589 - val_loss: 0.5792 - val_accuracy: 0.8357\n",
            "Epoch 449/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.1061 - accuracy: 0.9595 - val_loss: 0.5894 - val_accuracy: 0.8261\n",
            "Epoch 450/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.1116 - accuracy: 0.9631 - val_loss: 0.5086 - val_accuracy: 0.8261\n",
            "Epoch 451/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.0924 - accuracy: 0.9595 - val_loss: 0.4904 - val_accuracy: 0.8599\n",
            "Epoch 452/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.1027 - accuracy: 0.9680 - val_loss: 0.5002 - val_accuracy: 0.8647\n",
            "Epoch 453/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.1009 - accuracy: 0.9607 - val_loss: 0.5762 - val_accuracy: 0.8261\n",
            "Epoch 454/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.1123 - accuracy: 0.9643 - val_loss: 0.4921 - val_accuracy: 0.8647\n",
            "Epoch 455/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.0947 - accuracy: 0.9649 - val_loss: 0.5267 - val_accuracy: 0.8551\n",
            "Epoch 456/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.1161 - accuracy: 0.9559 - val_loss: 0.5206 - val_accuracy: 0.8406\n",
            "Epoch 457/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.1160 - accuracy: 0.9637 - val_loss: 0.5091 - val_accuracy: 0.8309\n",
            "Epoch 458/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.1004 - accuracy: 0.9637 - val_loss: 0.5577 - val_accuracy: 0.8406\n",
            "Epoch 459/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.1163 - accuracy: 0.9571 - val_loss: 0.5482 - val_accuracy: 0.8261\n",
            "Epoch 460/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.1157 - accuracy: 0.9595 - val_loss: 0.5633 - val_accuracy: 0.8213\n",
            "Epoch 461/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.1070 - accuracy: 0.9667 - val_loss: 0.6009 - val_accuracy: 0.8068\n",
            "Epoch 462/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.1227 - accuracy: 0.9583 - val_loss: 0.6102 - val_accuracy: 0.8116\n",
            "Epoch 463/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.1223 - accuracy: 0.9534 - val_loss: 0.5607 - val_accuracy: 0.8357\n",
            "Epoch 464/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.1022 - accuracy: 0.9643 - val_loss: 0.5060 - val_accuracy: 0.8357\n",
            "Epoch 465/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.1123 - accuracy: 0.9601 - val_loss: 0.5823 - val_accuracy: 0.8213\n",
            "Epoch 466/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.1223 - accuracy: 0.9541 - val_loss: 0.6071 - val_accuracy: 0.8164\n",
            "Epoch 467/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.0895 - accuracy: 0.9686 - val_loss: 0.5611 - val_accuracy: 0.8309\n",
            "Epoch 468/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.1186 - accuracy: 0.9619 - val_loss: 0.5701 - val_accuracy: 0.8309\n",
            "Epoch 469/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.1107 - accuracy: 0.9649 - val_loss: 0.5543 - val_accuracy: 0.8454\n",
            "Epoch 470/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.1146 - accuracy: 0.9625 - val_loss: 0.4883 - val_accuracy: 0.8406\n",
            "Epoch 471/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.1192 - accuracy: 0.9571 - val_loss: 0.5313 - val_accuracy: 0.8357\n",
            "Epoch 472/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.1092 - accuracy: 0.9613 - val_loss: 0.5260 - val_accuracy: 0.8164\n",
            "Epoch 473/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.0906 - accuracy: 0.9698 - val_loss: 0.5164 - val_accuracy: 0.8357\n",
            "Epoch 474/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.0872 - accuracy: 0.9674 - val_loss: 0.5060 - val_accuracy: 0.8696\n",
            "Epoch 475/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.0861 - accuracy: 0.9680 - val_loss: 0.4988 - val_accuracy: 0.8599\n",
            "Epoch 476/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.0988 - accuracy: 0.9655 - val_loss: 0.5108 - val_accuracy: 0.8502\n",
            "Epoch 477/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.0828 - accuracy: 0.9722 - val_loss: 0.5728 - val_accuracy: 0.8164\n",
            "Epoch 478/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.1180 - accuracy: 0.9637 - val_loss: 0.5325 - val_accuracy: 0.8454\n",
            "Epoch 479/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.1106 - accuracy: 0.9613 - val_loss: 0.4658 - val_accuracy: 0.8309\n",
            "Epoch 480/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.1034 - accuracy: 0.9607 - val_loss: 0.5527 - val_accuracy: 0.8309\n",
            "Epoch 481/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.1041 - accuracy: 0.9571 - val_loss: 0.5544 - val_accuracy: 0.8213\n",
            "Epoch 482/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.0966 - accuracy: 0.9643 - val_loss: 0.5155 - val_accuracy: 0.8406\n",
            "Epoch 483/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.1000 - accuracy: 0.9637 - val_loss: 0.4878 - val_accuracy: 0.8647\n",
            "Epoch 484/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.0940 - accuracy: 0.9661 - val_loss: 0.5823 - val_accuracy: 0.8309\n",
            "Epoch 485/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.0870 - accuracy: 0.9728 - val_loss: 0.5731 - val_accuracy: 0.8502\n",
            "Epoch 486/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.1006 - accuracy: 0.9637 - val_loss: 0.5650 - val_accuracy: 0.8357\n",
            "Epoch 487/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.1220 - accuracy: 0.9565 - val_loss: 0.5112 - val_accuracy: 0.8696\n",
            "Epoch 488/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.0833 - accuracy: 0.9734 - val_loss: 0.5399 - val_accuracy: 0.8406\n",
            "Epoch 489/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.1033 - accuracy: 0.9649 - val_loss: 0.5486 - val_accuracy: 0.8551\n",
            "Epoch 490/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.0869 - accuracy: 0.9704 - val_loss: 0.5304 - val_accuracy: 0.8454\n",
            "Epoch 491/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.0887 - accuracy: 0.9704 - val_loss: 0.5572 - val_accuracy: 0.8309\n",
            "Epoch 492/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.1016 - accuracy: 0.9649 - val_loss: 0.5687 - val_accuracy: 0.8406\n",
            "Epoch 493/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.1165 - accuracy: 0.9601 - val_loss: 0.5402 - val_accuracy: 0.8213\n",
            "Epoch 494/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.1208 - accuracy: 0.9534 - val_loss: 0.5616 - val_accuracy: 0.8164\n",
            "Epoch 495/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.1132 - accuracy: 0.9577 - val_loss: 0.5338 - val_accuracy: 0.8357\n",
            "Epoch 496/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.0931 - accuracy: 0.9649 - val_loss: 0.6112 - val_accuracy: 0.8309\n",
            "Epoch 497/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.0971 - accuracy: 0.9631 - val_loss: 0.5734 - val_accuracy: 0.8406\n",
            "Epoch 498/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.1100 - accuracy: 0.9595 - val_loss: 0.7046 - val_accuracy: 0.8213\n",
            "Epoch 499/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.0929 - accuracy: 0.9680 - val_loss: 0.5659 - val_accuracy: 0.8261\n",
            "Epoch 500/500\n",
            "104/104 [==============================] - 0s 3ms/step - loss: 0.1077 - accuracy: 0.9595 - val_loss: 0.5727 - val_accuracy: 0.8357\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(cnnhistory.history['loss'])\n",
        "plt.plot(cnnhistory.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train','test'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "oQYnuaCrDH_A",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "e6d0a4d3-666a-4105-a7bc-9d4b4e422a50"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(cnnhistory.history['accuracy'])\n",
        "plt.plot(cnnhistory.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train','test'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "IFkTuO8nDNdq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "9ede19ec-c131-48b0-aac4-1eb305657a61"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model.predict(x_testcnn)"
      ],
      "metadata": {
        "id": "A2xtrN5wDQgY"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions"
      ],
      "metadata": {
        "id": "_f_ohjXKDUpY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cdf97ba6-9284-47d8-d024-735100ec651c"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[3.11870724e-01, 7.17673544e-03, 8.68550315e-02, 5.76221645e-01,\n",
              "        1.27263629e-04, 1.77485775e-02],\n",
              "       [5.43518064e-10, 2.40682266e-11, 8.30826158e-15, 9.99982834e-01,\n",
              "        9.29428626e-13, 1.71971660e-05],\n",
              "       [6.12676237e-03, 7.25523569e-03, 8.34341685e-04, 9.82945800e-01,\n",
              "        6.34633834e-05, 2.77447514e-03],\n",
              "       ...,\n",
              "       [2.20622853e-10, 5.05583089e-18, 4.49661748e-08, 4.52557870e-12,\n",
              "        9.93846118e-01, 6.15388155e-03],\n",
              "       [1.37144879e-10, 5.91200650e-01, 4.08728093e-01, 7.87200918e-07,\n",
              "        5.55705242e-07, 6.99254888e-05],\n",
              "       [1.18540617e-08, 1.62373989e-10, 5.55739319e-03, 1.12336785e-07,\n",
              "        9.94028687e-01, 4.13839181e-04]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test"
      ],
      "metadata": {
        "id": "cmA2bFgsDW3D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d517f59-5f56-43cb-88c4-f1c348583b25"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([3, 3, 3, 0, 4, 4, 1, 2, 5, 0, 5, 3, 2, 2, 1, 4, 4, 5, 2, 4, 1, 2,\n",
              "       3, 5, 4, 2, 1, 2, 2, 2, 2, 5, 2, 5, 3, 1, 2, 0, 4, 5, 2, 3, 2, 2,\n",
              "       5, 2, 0, 1, 3, 4, 4, 5, 1, 1, 4, 4, 5, 1, 1, 1, 0, 1, 5, 0, 4, 1,\n",
              "       1, 0, 1, 4, 1, 0, 4, 1, 3, 1, 2, 2, 1, 2, 3, 0, 5, 3, 5, 5, 2, 4,\n",
              "       5, 1, 5, 1, 5, 3, 4, 1, 4, 1, 5, 4, 5, 1, 2, 1, 1, 5, 1, 3, 2, 5,\n",
              "       2, 1, 3, 5, 4, 4, 0, 0, 3, 1, 2, 2, 3, 5, 1, 5, 3, 4, 2, 2, 0, 2,\n",
              "       2, 5, 5, 0, 3, 3, 2, 2, 0, 3, 4, 0, 4, 2, 4, 5, 4, 1, 5, 3, 2, 2,\n",
              "       5, 4, 3, 3, 4, 3, 3, 4, 1, 5, 2, 3, 2, 2, 0, 2, 1, 3, 1, 2, 2, 5,\n",
              "       5, 1, 4, 2, 2, 1, 1, 3, 3, 5, 5, 2, 5, 1, 5, 0, 3, 3, 0, 5, 1, 4,\n",
              "       1, 4, 2, 5, 5, 1, 4, 2, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_Ytest = y_test.astype(int)"
      ],
      "metadata": {
        "id": "0PHDKWJWDY3g"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_Ytest"
      ],
      "metadata": {
        "id": "k68v2i-pDbZE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "698dc038-1f44-49d0-9860-52ebea9831b1"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([3, 3, 3, 0, 4, 4, 1, 2, 5, 0, 5, 3, 2, 2, 1, 4, 4, 5, 2, 4, 1, 2,\n",
              "       3, 5, 4, 2, 1, 2, 2, 2, 2, 5, 2, 5, 3, 1, 2, 0, 4, 5, 2, 3, 2, 2,\n",
              "       5, 2, 0, 1, 3, 4, 4, 5, 1, 1, 4, 4, 5, 1, 1, 1, 0, 1, 5, 0, 4, 1,\n",
              "       1, 0, 1, 4, 1, 0, 4, 1, 3, 1, 2, 2, 1, 2, 3, 0, 5, 3, 5, 5, 2, 4,\n",
              "       5, 1, 5, 1, 5, 3, 4, 1, 4, 1, 5, 4, 5, 1, 2, 1, 1, 5, 1, 3, 2, 5,\n",
              "       2, 1, 3, 5, 4, 4, 0, 0, 3, 1, 2, 2, 3, 5, 1, 5, 3, 4, 2, 2, 0, 2,\n",
              "       2, 5, 5, 0, 3, 3, 2, 2, 0, 3, 4, 0, 4, 2, 4, 5, 4, 1, 5, 3, 2, 2,\n",
              "       5, 4, 3, 3, 4, 3, 3, 4, 1, 5, 2, 3, 2, 2, 0, 2, 1, 3, 1, 2, 2, 5,\n",
              "       5, 1, 4, 2, 2, 1, 1, 3, 3, 5, 5, 2, 5, 1, 5, 0, 3, 3, 0, 5, 1, 4,\n",
              "       1, 4, 2, 5, 5, 1, 4, 2, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds1=predictions.argmax(axis=1)\n",
        "preds1"
      ],
      "metadata": {
        "id": "4_cAI39VFhtp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "91823a2d-3402-44ba-b98f-0d694a8a694d"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([3, 3, 3, 0, 4, 4, 1, 2, 5, 1, 5, 3, 2, 2, 1, 4, 4, 3, 3, 4, 1, 2,\n",
              "       3, 5, 4, 2, 1, 2, 2, 2, 2, 5, 2, 5, 3, 1, 2, 0, 4, 5, 2, 3, 1, 2,\n",
              "       5, 2, 1, 1, 3, 5, 4, 5, 1, 1, 4, 4, 5, 1, 3, 1, 0, 1, 0, 3, 4, 1,\n",
              "       1, 3, 1, 4, 0, 0, 5, 1, 5, 1, 2, 2, 1, 2, 3, 0, 5, 3, 5, 5, 2, 5,\n",
              "       3, 1, 0, 1, 5, 3, 4, 1, 4, 0, 5, 4, 5, 1, 2, 1, 1, 5, 1, 5, 2, 5,\n",
              "       2, 1, 3, 5, 4, 4, 3, 0, 3, 1, 1, 2, 1, 3, 1, 3, 3, 2, 2, 2, 0, 2,\n",
              "       2, 3, 5, 0, 5, 3, 2, 2, 0, 3, 4, 1, 4, 4, 4, 2, 4, 1, 5, 3, 2, 2,\n",
              "       5, 4, 3, 5, 4, 5, 3, 4, 1, 5, 2, 3, 2, 2, 0, 2, 1, 3, 1, 2, 2, 5,\n",
              "       5, 1, 4, 2, 2, 1, 3, 3, 3, 5, 5, 2, 3, 1, 2, 0, 3, 3, 1, 5, 1, 4,\n",
              "       1, 3, 3, 2, 5, 1, 4, 1, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "abc = preds1.astype(int).flatten()"
      ],
      "metadata": {
        "id": "H4WEmM60NfQn"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "c = confusion_matrix(new_Ytest, abc) \n",
        "c"
      ],
      "metadata": {
        "id": "bKEBeEBlFjB8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bff983d2-e91b-472d-bee3-b3a65a4eefa4"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[11,  4,  0,  3,  0,  0],\n",
              "       [ 2, 37,  0,  2,  0,  0],\n",
              "       [ 0,  3, 39,  2,  1,  0],\n",
              "       [ 0,  1,  0, 25,  0,  5],\n",
              "       [ 0,  0,  1,  1, 28,  3],\n",
              "       [ 2,  0,  3,  6,  0, 28]])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test"
      ],
      "metadata": {
        "id": "m4RjG7LWLSQx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b882719-2a14-44cc-ed97-f63fe57d68eb"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([3, 3, 3, 0, 4, 4, 1, 2, 5, 0, 5, 3, 2, 2, 1, 4, 4, 5, 2, 4, 1, 2,\n",
              "       3, 5, 4, 2, 1, 2, 2, 2, 2, 5, 2, 5, 3, 1, 2, 0, 4, 5, 2, 3, 2, 2,\n",
              "       5, 2, 0, 1, 3, 4, 4, 5, 1, 1, 4, 4, 5, 1, 1, 1, 0, 1, 5, 0, 4, 1,\n",
              "       1, 0, 1, 4, 1, 0, 4, 1, 3, 1, 2, 2, 1, 2, 3, 0, 5, 3, 5, 5, 2, 4,\n",
              "       5, 1, 5, 1, 5, 3, 4, 1, 4, 1, 5, 4, 5, 1, 2, 1, 1, 5, 1, 3, 2, 5,\n",
              "       2, 1, 3, 5, 4, 4, 0, 0, 3, 1, 2, 2, 3, 5, 1, 5, 3, 4, 2, 2, 0, 2,\n",
              "       2, 5, 5, 0, 3, 3, 2, 2, 0, 3, 4, 0, 4, 2, 4, 5, 4, 1, 5, 3, 2, 2,\n",
              "       5, 4, 3, 3, 4, 3, 3, 4, 1, 5, 2, 3, 2, 2, 0, 2, 1, 3, 1, 2, 2, 5,\n",
              "       5, 1, 4, 2, 2, 1, 1, 3, 3, 5, 5, 2, 5, 1, 5, 0, 3, 3, 0, 5, 1, 4,\n",
              "       1, 4, 2, 5, 5, 1, 4, 2, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss, acc =model.evaluate(x_testcnn, y_test)\n",
        "print(\"Restored model, accuracy: {:5.2f}%\".format(100*acc))"
      ],
      "metadata": {
        "id": "n3kzoqPkDqqS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c431abd-c115-40d6-8803-da6ef85963aa"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7/7 [==============================] - 0s 2ms/step - loss: 0.4751 - accuracy: 0.8116\n",
            "Restored model, accuracy: 81.16%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss, acc =model.evaluate(X_train, y_train)\n",
        "print(\"Restored model train, accuracy: {:5.2f}%\".format(100*acc))"
      ],
      "metadata": {
        "id": "fJDTGH_OUX0z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c9cd5d0-be17-44b0-f913-5185cc7df487"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "52/52 [==============================] - 0s 3ms/step - loss: 0.0240 - accuracy: 0.9982\n",
            "Restored model train, accuracy: 99.82%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix,accuracy_score\n",
        "import seaborn as sn\n",
        "\n",
        "print(classification_report(new_Ytest,abc))\n",
        "\n",
        "acc = float(accuracy_score(new_Ytest,abc))*100\n",
        "print(\"----accuracy score %s ----\" % acc)\n",
        "\n",
        "cm = confusion_matrix(new_Ytest,abc)\n",
        "#df_cm = pd.DataFrame(cm)\n",
        "class_names = ['neutral','calm', 'happy','sad','angry', 'fearful' ]\n",
        "df_cm = pd.DataFrame(cm, index=class_names, columns=class_names,)\n",
        "sn.heatmap(df_cm, annot=True, fmt='')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "SfSC3El94LZg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 521
        },
        "outputId": "c553d1da-4c58-41cd-e120-f6a5606b11eb"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.73      0.61      0.67        18\n",
            "           1       0.82      0.90      0.86        41\n",
            "           2       0.91      0.87      0.89        45\n",
            "           3       0.64      0.81      0.71        31\n",
            "           4       0.97      0.85      0.90        33\n",
            "           5       0.78      0.72      0.75        39\n",
            "\n",
            "    accuracy                           0.81       207\n",
            "   macro avg       0.81      0.79      0.80       207\n",
            "weighted avg       0.82      0.81      0.81       207\n",
            "\n",
            "----accuracy score 81.15942028985508 ----\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}