{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "`original model with validation and 500 epoch_RMS.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9SRCO-a_AlH5",
        "outputId": "b4518744-88da-458b-ba98-6e6f3631e038"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install librosa"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oi8pWV3yBVjO",
        "outputId": "86305ba1-4117-4de9-d94b-65668c9643ce"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: librosa in /usr/local/lib/python3.7/dist-packages (0.8.1)\n",
            "Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.6.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.21.5)\n",
            "Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.0.2)\n",
            "Requirement already satisfied: resampy>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from librosa) (0.2.2)\n",
            "Requirement already satisfied: audioread>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (2.1.9)\n",
            "Requirement already satisfied: soundfile>=0.10.2 in /usr/local/lib/python3.7/dist-packages (from librosa) (0.10.3.post1)\n",
            "Requirement already satisfied: numba>=0.43.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (0.51.2)\n",
            "Requirement already satisfied: decorator>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.1.0)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.4.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (21.3)\n",
            "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba>=0.43.0->librosa) (0.34.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba>=0.43.0->librosa) (57.4.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->librosa) (3.0.7)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from pooch>=1.0->librosa) (2.23.0)\n",
            "Requirement already satisfied: appdirs>=1.3.0 in /usr/local/lib/python3.7/dist-packages (from pooch>=1.0->librosa) (1.4.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (3.0.4)\n",
            "Requirement already satisfied: six>=1.3 in /usr/local/lib/python3.7/dist-packages (from resampy>=0.2.2->librosa) (1.15.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn!=0.19.0,>=0.14.0->librosa) (3.1.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.7/dist-packages (from soundfile>=0.10.2->librosa) (1.15.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.0->soundfile>=0.10.2->librosa) (2.21)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "wsaoikiQGfqd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HJjcbxwy46bG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "d95c7085-4505-45b7-cf16-912e2590c340"
      },
      "source": [
        "# Orignial Notebook: https://github.com/MITESHPUTHRANNEU/Speech-Emotion-Analyzer/blob/master/final_results_gender_test.ipynb\n",
        "# This notebook author: Reza Chu\n",
        "# Last Editing Date: 31st May 2019\n",
        "\n",
        "## Python\n",
        "import os\n",
        "import random\n",
        "import sys\n",
        "\n",
        "import IPython\n",
        "from IPython.display import Audio\n",
        "from IPython.display import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "## Package\n",
        "import glob \n",
        "import keras\n",
        "import IPython.display as ipd\n",
        "import librosa\n",
        "import librosa.display\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import plotly.graph_objs as go\n",
        "import plotly.offline as py\n",
        "import plotly.tools as tls\n",
        "import seaborn as sns\n",
        "import scipy.io.wavfile\n",
        "import tensorflow as tf\n",
        "py.init_notebook_mode(connected=True)\n",
        "\n",
        "## Keras\n",
        "from keras import regularizers\n",
        "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping\n",
        "from keras.callbacks import  History, ReduceLROnPlateau, CSVLogger\n",
        "from keras.models import Model, Sequential\n",
        "from keras.layers import Dense, Embedding, LSTM\n",
        "from keras.layers import Input, Flatten, Dropout, Activation, BatchNormalization\n",
        "from keras.layers import Conv1D, MaxPooling1D, AveragePooling1D\n",
        "from keras.preprocessing import sequence\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.utils import np_utils\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "## Sklearn\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "## Rest\n",
        "from scipy.fftpack import fft\n",
        "from scipy import signal\n",
        "from scipy.io import wavfile\n",
        "from tqdm import tqdm\n",
        "\n",
        "input_duration=3\n",
        "# % pylab inline"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "        <script type=\"text/javascript\">\n",
              "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
              "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
              "        if (typeof require !== 'undefined') {\n",
              "        require.undef(\"plotly\");\n",
              "        requirejs.config({\n",
              "            paths: {\n",
              "                'plotly': ['https://cdn.plot.ly/plotly-2.8.3.min']\n",
              "            }\n",
              "        });\n",
              "        require(['plotly'], function(Plotly) {\n",
              "            window._Plotly = Plotly;\n",
              "        });\n",
              "        }\n",
              "        </script>\n",
              "        "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#radvass speech and song\n",
        "import time\n",
        "import os\n",
        "import librosa\n",
        "from librosa import display\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "count=0\n",
        "path1 = '/content/drive/My Drive/data_set/RAVDESS_speech'\n",
        "path2 = '/content/drive/My Drive/data_set/RAVDESS_song'\n",
        "\n",
        "lst = []\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "for subdir, dirs, files in os.walk(path2):\n",
        "  print(dirs)\n",
        "  print(subdir)\n",
        "  #print(files)\n",
        "  for file in files:\n",
        "      try:\n",
        "        count +=1\n",
        "        #Load librosa array, obtain mfcss, store the file and the mcss information in a new array\n",
        "        X, sample_rate = librosa.load(os.path.join(subdir,file), res_type='kaiser_fast')\n",
        "        mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T,axis=0) \n",
        "        # The instruction below converts the labels (from 1 to 8) to a series from 0 to 7\n",
        "        # This is because our predictor needs to start from 0 otherwise it will try to predict also 0.\n",
        "        file = int(file[7:8]) - 1 \n",
        "        arr = mfccs, file\n",
        "        lst.append(arr)\n",
        "      # If the file is not valid, skip it\n",
        "      except ValueError:\n",
        "        continue\n",
        "\n",
        "for subdir, dirs, files in os.walk(path1):\n",
        "  print(dirs)\n",
        "  print(subdir)\n",
        " # print(files)\n",
        "  for file in files:\n",
        "      try:\n",
        "        #Load librosa array, obtain mfcss, store the file and the mcss information in a new array\n",
        "        X, sample_rate = librosa.load(os.path.join(subdir,file), res_type='kaiser_fast')\n",
        "        mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T,axis=0) \n",
        "        # The instruction below converts the labels (from 1 to 8) to a series from 0 to 7\n",
        "        # This is because our predictor needs to start from 0 otherwise it will try to predict also 0.\n",
        "        file = int(file[7:8]) - 1 \n",
        "        if(file ==6 or file==7):\n",
        "          continue\n",
        "        count +=1\n",
        "        arr = mfccs, file\n",
        "        lst.append(arr)\n",
        "      # If the file is not valid, skip it\n",
        "      except ValueError:\n",
        "        continue\n",
        "\n",
        "\n",
        "\n",
        "print(\"--- Data loaded. Loading time: %s seconds ---\" % (time.time() - start_time))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IfuyRZl42ccZ",
        "outputId": "52c8fe51-3b42-462c-ae0b-ff8c00639086"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Actor_10', 'Actor_11', 'Actor_13', 'Actor_12', 'Actor_14', 'Actor_15', 'Actor_16', 'Actor_17', 'Actor_18', 'Actor_19', 'Actor_21', 'Actor_22', 'Actor_23', 'Actor_09', 'Actor_24', 'Actor_04', 'Actor_08', 'Actor_03', 'Actor_02', 'Actor_06', 'Actor_05', 'Actor_01', 'Actor_07', 'Actor_20']\n",
            "/content/drive/My Drive/data_set/RAVDESS_song\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_song/Actor_10\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_song/Actor_11\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_song/Actor_13\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_song/Actor_12\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_song/Actor_14\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_song/Actor_15\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_song/Actor_16\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_song/Actor_17\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_song/Actor_18\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_song/Actor_19\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_song/Actor_21\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_song/Actor_22\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_song/Actor_23\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_song/Actor_09\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_song/Actor_24\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_song/Actor_04\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_song/Actor_08\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_song/Actor_03\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_song/Actor_02\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_song/Actor_06\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_song/Actor_05\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_song/Actor_01\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_song/Actor_07\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_song/Actor_20\n",
            "['Actor_05', 'Actor_08', 'Actor_10', 'Actor_04', 'Actor_09', 'Actor_14', 'Actor_12', 'Actor_13', 'Actor_11', 'Actor_06', 'Actor_24', 'Actor_07', 'Actor_23', 'Actor_22', 'Actor_21', 'Actor_20', 'Actor_02', 'Actor_19', 'Actor_18', 'Actor_17', 'Actor_16', 'Actor_15', 'Actor_03', 'Actor_01']\n",
            "/content/drive/My Drive/data_set/RAVDESS_speech\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_speech/Actor_05\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_speech/Actor_08\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_speech/Actor_10\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_speech/Actor_04\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_speech/Actor_09\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_speech/Actor_14\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_speech/Actor_12\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_speech/Actor_13\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_speech/Actor_11\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_speech/Actor_06\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_speech/Actor_24\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_speech/Actor_07\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_speech/Actor_23\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_speech/Actor_22\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_speech/Actor_21\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_speech/Actor_20\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_speech/Actor_02\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_speech/Actor_19\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_speech/Actor_18\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_speech/Actor_17\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_speech/Actor_16\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_speech/Actor_15\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_speech/Actor_03\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_speech/Actor_01\n",
            "--- Data loaded. Loading time: 689.3357880115509 seconds ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "count"
      ],
      "metadata": {
        "id": "Ltlhi25L2AI5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21556a7f-c201-4f90-b3ea-6f15169d12b3"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2068"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy.core.fromnumeric import size\n",
        "size(lst)"
      ],
      "metadata": {
        "id": "HMOH7d7mzHB7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f3e7bed-62a6-4f2a-a7ec-87fcb82a6aa5"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/core/fromnumeric.py:3208: VisibleDeprecationWarning:\n",
            "\n",
            "Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4136"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating X and y: zip makes a list of all the first elements, and a list of all the second elements.\n",
        "X, y = zip(*lst)"
      ],
      "metadata": {
        "id": "ocdL7tSTBoMt"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "X = np.asarray(X)\n",
        "y = np.asarray(y)\n",
        "X.shape, y.shape"
      ],
      "metadata": {
        "id": "vHKwUGTbBtnF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ecac8ff-fb0e-4531-ea3d-05ec6d0a285c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((2068, 40), (2068,))"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "id": "2sUCtbfMztE5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fbdba9b8-da82-4e63-90b8-9f2cf8283cc6"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2068, 40)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Saving joblib files to not load them again with the loop above\n",
        "\n",
        "import joblib\n",
        "\n",
        "X_name = 'saveex5.joblib'\n",
        "y_name = 'saveey5.joblib'\n",
        "save_dir = '/content/drive/My Drive/graduation project/audio/improvement1/features'\n",
        "\n",
        "savedX = joblib.dump(X, os.path.join(save_dir, X_name))\n",
        "savedy = joblib.dump(y, os.path.join(save_dir, y_name))"
      ],
      "metadata": {
        "id": "UCzic8rlDcuk"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading saved models\n",
        "import joblib\n",
        "X = joblib.load('/content/drive/My Drive/models/CNN_2/last/features/speech&songx6.joblib')\n",
        "y = joblib.load('/content/drive/My Drive/models/CNN_2/last/features/speech&songy6.joblib')"
      ],
      "metadata": {
        "id": "Q35CN6zDrzg1"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2,train_size=0.8, random_state=42)\n",
        "X_valid, X_test, y_valid, y_test = train_test_split(X_test,y_test, test_size=0.5,train_size=0.5, random_state=42)"
      ],
      "metadata": {
        "id": "Ai4Fy5cPCiq1"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7PSTurzjCo5K",
        "outputId": "44f4ba7f-bc88-40f8-9e1d-ed27bb97bdea"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2068, 40)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "x_traincnn = np.expand_dims(X_train, axis=2)\n",
        "x_testcnn = np.expand_dims(X_test, axis=2)\n",
        "X_valid= np.expand_dims(X_valid, axis=2)"
      ],
      "metadata": {
        "id": "tp1Fm5K3CEXu"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_traincnn.shape, x_testcnn.shape , X_valid.shape"
      ],
      "metadata": {
        "id": "RI0MxoIPBws5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d2b7f232-1238-4f9d-f88a-a73d7ee7a63b"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1654, 40, 1), (207, 40, 1), (207, 40, 1))"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow"
      ],
      "metadata": {
        "id": "goxL4Y3jKICC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "abf15d1f-6a69-40a6-b6c2-46adbae4ca3c"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (2.8.0)\n",
            "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow) (57.4.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.13.3)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.10.0.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.21.5)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (13.0.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.24.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.44.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.5.3)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.0.0)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.17.3)\n",
            "Collecting tf-estimator-nightly==2.8.0.dev2021122109\n",
            "  Downloading tf_estimator_nightly-2.8.0.dev2021122109-py2.py3-none-any.whl (462 kB)\n",
            "\u001b[K     |████████████████████████████████| 462 kB 4.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow) (1.5.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.6.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.35.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (3.3.6)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.23.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.8.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.4.6)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.8)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (4.11.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (3.7.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2021.10.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (3.2.0)\n",
            "Installing collected packages: tf-estimator-nightly\n",
            "Successfully installed tf-estimator-nightly-2.8.0.dev2021122109\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keras"
      ],
      "metadata": {
        "id": "EkcmN9UrKSxj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46afd6f0-310f-485a-d4ca-63c902d61e0f"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: keras in /usr/local/lib/python3.7/dist-packages (2.8.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from keras.preprocessing import sequence\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from keras.layers import Input, Flatten, Dropout, Activation\n",
        "from keras.layers import Conv1D, MaxPooling1D\n",
        "from keras.models import Model\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras import optimizers\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv1D(128, 8,padding='same', #classifier.add(Convolution2D(64, (3, 3), padding = 'same', input_shape = (128, 128, 3), activation = 'relu'))\n",
        "                 input_shape=(40,1)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(MaxPooling1D(pool_size=(5)))\n",
        "\n",
        "\n",
        "model.add(Conv1D(256,8,padding='same',))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(MaxPooling1D(pool_size=(5)))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(256))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(256))\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "model.add(Dense(6))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "#opt = tf.keras.optimizers.Adam(lr=0.00002)\n",
        "opt = tf.keras.optimizers.RMSprop(lr=0.0001, rho=0.9, epsilon=1e-07, decay=0.0)\n",
        "#opt = tf.keras.optimizers.SGD(lr=0.001, momentum=0.0, decay=0.0, nesterov=False)"
      ],
      "metadata": {
        "id": "g74fXWVAC4Cr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0251fea9-36c4-4e22-adbd-08e4c28e76a5"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/rmsprop.py:130: UserWarning:\n",
            "\n",
            "The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H6ukOxAGC_I4",
        "outputId": "756bf50a-67e7-4378-ac9b-e67327091b26"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d (Conv1D)             (None, 40, 128)           1152      \n",
            "                                                                 \n",
            " activation (Activation)     (None, 40, 128)           0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 40, 128)           0         \n",
            "                                                                 \n",
            " max_pooling1d (MaxPooling1D  (None, 8, 128)           0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv1d_1 (Conv1D)           (None, 8, 256)            262400    \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 8, 256)            0         \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 8, 256)            0         \n",
            "                                                                 \n",
            " max_pooling1d_1 (MaxPooling  (None, 1, 256)           0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 256)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 256)               65792     \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 256)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 256)               65792     \n",
            "                                                                 \n",
            " activation_3 (Activation)   (None, 256)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 6)                 1542      \n",
            "                                                                 \n",
            " activation_4 (Activation)   (None, 6)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 396,678\n",
            "Trainable params: 396,678\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='sparse_categorical_crossentropy',\n",
        "              optimizer=opt,\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "AbMlLNk4DCBM"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#cnnhistory=model.fit(x_traincnn, y_train, batch_size=16, epochs=700, validation_data=(x_testcnn, y_test))\n",
        "cnnhistory=model.fit(x_traincnn, y_train, batch_size=16, epochs=500 , validation_data=(X_valid, y_valid))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RI1v2AuADFhy",
        "outputId": "04e1ac5d-e4c2-4d96-f41a-66579b24709f"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "104/104 [==============================] - 3s 23ms/step - loss: 4.8421 - accuracy: 0.1753 - val_loss: 3.0273 - val_accuracy: 0.1643\n",
            "Epoch 2/500\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 2.9902 - accuracy: 0.2031 - val_loss: 2.0631 - val_accuracy: 0.1981\n",
            "Epoch 3/500\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 2.5229 - accuracy: 0.2044 - val_loss: 1.8020 - val_accuracy: 0.2367\n",
            "Epoch 4/500\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 2.2289 - accuracy: 0.2249 - val_loss: 1.7155 - val_accuracy: 0.2899\n",
            "Epoch 5/500\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 2.0977 - accuracy: 0.2249 - val_loss: 1.8176 - val_accuracy: 0.2126\n",
            "Epoch 6/500\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 1.9945 - accuracy: 0.2231 - val_loss: 1.7127 - val_accuracy: 0.3430\n",
            "Epoch 7/500\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 1.8978 - accuracy: 0.2364 - val_loss: 1.6690 - val_accuracy: 0.2705\n",
            "Epoch 8/500\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 1.8989 - accuracy: 0.2304 - val_loss: 1.6782 - val_accuracy: 0.2995\n",
            "Epoch 9/500\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 1.8604 - accuracy: 0.2400 - val_loss: 1.6461 - val_accuracy: 0.2947\n",
            "Epoch 10/500\n",
            "104/104 [==============================] - 3s 30ms/step - loss: 1.8055 - accuracy: 0.2618 - val_loss: 1.6274 - val_accuracy: 0.3333\n",
            "Epoch 11/500\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 1.7856 - accuracy: 0.2733 - val_loss: 1.6949 - val_accuracy: 0.2850\n",
            "Epoch 12/500\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 1.7365 - accuracy: 0.2733 - val_loss: 1.6131 - val_accuracy: 0.3478\n",
            "Epoch 13/500\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 1.7344 - accuracy: 0.2799 - val_loss: 1.7374 - val_accuracy: 0.2657\n",
            "Epoch 14/500\n",
            "104/104 [==============================] - 3s 26ms/step - loss: 1.7143 - accuracy: 0.2823 - val_loss: 1.7788 - val_accuracy: 0.2319\n",
            "Epoch 15/500\n",
            "104/104 [==============================] - 3s 31ms/step - loss: 1.6995 - accuracy: 0.2944 - val_loss: 1.5707 - val_accuracy: 0.4251\n",
            "Epoch 16/500\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 1.6771 - accuracy: 0.2938 - val_loss: 1.5814 - val_accuracy: 0.3382\n",
            "Epoch 17/500\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 1.6686 - accuracy: 0.2938 - val_loss: 1.5998 - val_accuracy: 0.3043\n",
            "Epoch 18/500\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 1.6313 - accuracy: 0.3313 - val_loss: 1.6158 - val_accuracy: 0.2754\n",
            "Epoch 19/500\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 1.5991 - accuracy: 0.3349 - val_loss: 1.5357 - val_accuracy: 0.3720\n",
            "Epoch 20/500\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 1.5974 - accuracy: 0.3501 - val_loss: 1.5457 - val_accuracy: 0.3478\n",
            "Epoch 21/500\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 1.5748 - accuracy: 0.3440 - val_loss: 1.5184 - val_accuracy: 0.3092\n",
            "Epoch 22/500\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 1.5518 - accuracy: 0.3585 - val_loss: 1.5703 - val_accuracy: 0.3527\n",
            "Epoch 23/500\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 1.5625 - accuracy: 0.3513 - val_loss: 1.4774 - val_accuracy: 0.4203\n",
            "Epoch 24/500\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 1.5348 - accuracy: 0.3857 - val_loss: 1.5186 - val_accuracy: 0.3671\n",
            "Epoch 25/500\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 1.5097 - accuracy: 0.3924 - val_loss: 1.4262 - val_accuracy: 0.4396\n",
            "Epoch 26/500\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 1.5003 - accuracy: 0.3736 - val_loss: 1.4245 - val_accuracy: 0.4589\n",
            "Epoch 27/500\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 1.4906 - accuracy: 0.3881 - val_loss: 1.4104 - val_accuracy: 0.4493\n",
            "Epoch 28/500\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 1.4709 - accuracy: 0.3972 - val_loss: 1.4378 - val_accuracy: 0.4203\n",
            "Epoch 29/500\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 1.4612 - accuracy: 0.3972 - val_loss: 1.4751 - val_accuracy: 0.4541\n",
            "Epoch 30/500\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 1.4110 - accuracy: 0.4202 - val_loss: 1.4360 - val_accuracy: 0.3913\n",
            "Epoch 31/500\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 1.4059 - accuracy: 0.4232 - val_loss: 1.4089 - val_accuracy: 0.4589\n",
            "Epoch 32/500\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 1.3833 - accuracy: 0.4347 - val_loss: 1.4817 - val_accuracy: 0.4155\n",
            "Epoch 33/500\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 1.3962 - accuracy: 0.4141 - val_loss: 1.2991 - val_accuracy: 0.5266\n",
            "Epoch 34/500\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 1.3712 - accuracy: 0.4389 - val_loss: 1.4470 - val_accuracy: 0.4444\n",
            "Epoch 35/500\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 1.3644 - accuracy: 0.4268 - val_loss: 1.2881 - val_accuracy: 0.5459\n",
            "Epoch 36/500\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 1.3472 - accuracy: 0.4565 - val_loss: 1.2892 - val_accuracy: 0.4879\n",
            "Epoch 37/500\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 1.3274 - accuracy: 0.4643 - val_loss: 1.3049 - val_accuracy: 0.4734\n",
            "Epoch 38/500\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 1.3150 - accuracy: 0.4837 - val_loss: 1.3042 - val_accuracy: 0.4783\n",
            "Epoch 39/500\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 1.3005 - accuracy: 0.4885 - val_loss: 1.2554 - val_accuracy: 0.4976\n",
            "Epoch 40/500\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 1.2885 - accuracy: 0.4619 - val_loss: 1.2610 - val_accuracy: 0.5266\n",
            "Epoch 41/500\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 1.2637 - accuracy: 0.4976 - val_loss: 1.2016 - val_accuracy: 0.5411\n",
            "Epoch 42/500\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 1.2605 - accuracy: 0.4813 - val_loss: 1.2018 - val_accuracy: 0.5652\n",
            "Epoch 43/500\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 1.2555 - accuracy: 0.4970 - val_loss: 1.2439 - val_accuracy: 0.5411\n",
            "Epoch 44/500\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 1.2305 - accuracy: 0.5048 - val_loss: 1.1697 - val_accuracy: 0.5459\n",
            "Epoch 45/500\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 1.2072 - accuracy: 0.5024 - val_loss: 1.1729 - val_accuracy: 0.5459\n",
            "Epoch 46/500\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 1.2158 - accuracy: 0.5193 - val_loss: 1.2223 - val_accuracy: 0.5024\n",
            "Epoch 47/500\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 1.2199 - accuracy: 0.5103 - val_loss: 1.1753 - val_accuracy: 0.5217\n",
            "Epoch 48/500\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 1.1919 - accuracy: 0.5218 - val_loss: 1.1154 - val_accuracy: 0.5700\n",
            "Epoch 49/500\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 1.1739 - accuracy: 0.5145 - val_loss: 1.1127 - val_accuracy: 0.5652\n",
            "Epoch 50/500\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 1.1556 - accuracy: 0.5363 - val_loss: 1.2268 - val_accuracy: 0.5024\n",
            "Epoch 51/500\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 1.1481 - accuracy: 0.5363 - val_loss: 1.0869 - val_accuracy: 0.5797\n",
            "Epoch 52/500\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 1.1350 - accuracy: 0.5459 - val_loss: 1.0926 - val_accuracy: 0.5604\n",
            "Epoch 53/500\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 1.1312 - accuracy: 0.5351 - val_loss: 1.2137 - val_accuracy: 0.4686\n",
            "Epoch 54/500\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 1.1409 - accuracy: 0.5369 - val_loss: 1.0620 - val_accuracy: 0.5652\n",
            "Epoch 55/500\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 1.1023 - accuracy: 0.5605 - val_loss: 1.1492 - val_accuracy: 0.5411\n",
            "Epoch 56/500\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 1.1005 - accuracy: 0.5580 - val_loss: 1.0916 - val_accuracy: 0.5700\n",
            "Epoch 57/500\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 1.0936 - accuracy: 0.5580 - val_loss: 1.0751 - val_accuracy: 0.5990\n",
            "Epoch 58/500\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 1.0798 - accuracy: 0.5671 - val_loss: 1.0657 - val_accuracy: 0.5797\n",
            "Epoch 59/500\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 1.0839 - accuracy: 0.5605 - val_loss: 1.1627 - val_accuracy: 0.4928\n",
            "Epoch 60/500\n",
            "104/104 [==============================] - 3s 24ms/step - loss: 1.0773 - accuracy: 0.5701 - val_loss: 1.0483 - val_accuracy: 0.5749\n",
            "Epoch 61/500\n",
            "104/104 [==============================] - 3s 25ms/step - loss: 1.0523 - accuracy: 0.5834 - val_loss: 1.0596 - val_accuracy: 0.5652\n",
            "Epoch 62/500\n",
            "104/104 [==============================] - 3s 25ms/step - loss: 1.0327 - accuracy: 0.5840 - val_loss: 1.0418 - val_accuracy: 0.6232\n",
            "Epoch 63/500\n",
            "104/104 [==============================] - 2s 23ms/step - loss: 1.0518 - accuracy: 0.5816 - val_loss: 1.0479 - val_accuracy: 0.5797\n",
            "Epoch 64/500\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 1.0227 - accuracy: 0.5889 - val_loss: 1.0161 - val_accuracy: 0.5700\n",
            "Epoch 65/500\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 1.0311 - accuracy: 0.5973 - val_loss: 1.1660 - val_accuracy: 0.5072\n",
            "Epoch 66/500\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 1.0444 - accuracy: 0.5901 - val_loss: 0.9738 - val_accuracy: 0.6039\n",
            "Epoch 67/500\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 1.0213 - accuracy: 0.6022 - val_loss: 1.0212 - val_accuracy: 0.5749\n",
            "Epoch 68/500\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.9936 - accuracy: 0.6028 - val_loss: 0.9940 - val_accuracy: 0.6280\n",
            "Epoch 69/500\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.9886 - accuracy: 0.6016 - val_loss: 0.9687 - val_accuracy: 0.6232\n",
            "Epoch 70/500\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.9931 - accuracy: 0.5955 - val_loss: 0.9850 - val_accuracy: 0.5942\n",
            "Epoch 71/500\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.9836 - accuracy: 0.6112 - val_loss: 0.9531 - val_accuracy: 0.6425\n",
            "Epoch 72/500\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.9625 - accuracy: 0.6245 - val_loss: 0.9600 - val_accuracy: 0.5894\n",
            "Epoch 73/500\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.9315 - accuracy: 0.6378 - val_loss: 0.9391 - val_accuracy: 0.6329\n",
            "Epoch 74/500\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.9525 - accuracy: 0.6282 - val_loss: 0.9379 - val_accuracy: 0.6618\n",
            "Epoch 75/500\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.9424 - accuracy: 0.6258 - val_loss: 0.9445 - val_accuracy: 0.6329\n",
            "Epoch 76/500\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.9419 - accuracy: 0.6203 - val_loss: 0.9466 - val_accuracy: 0.6135\n",
            "Epoch 77/500\n",
            "104/104 [==============================] - 2s 23ms/step - loss: 0.9299 - accuracy: 0.6342 - val_loss: 0.9382 - val_accuracy: 0.6280\n",
            "Epoch 78/500\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.9329 - accuracy: 0.6264 - val_loss: 0.9556 - val_accuracy: 0.6232\n",
            "Epoch 79/500\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.9255 - accuracy: 0.6354 - val_loss: 1.0340 - val_accuracy: 0.5700\n",
            "Epoch 80/500\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.8967 - accuracy: 0.6566 - val_loss: 0.9493 - val_accuracy: 0.6232\n",
            "Epoch 81/500\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.9306 - accuracy: 0.6276 - val_loss: 0.9150 - val_accuracy: 0.6377\n",
            "Epoch 82/500\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.9113 - accuracy: 0.6427 - val_loss: 0.9104 - val_accuracy: 0.6039\n",
            "Epoch 83/500\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.9026 - accuracy: 0.6342 - val_loss: 0.9513 - val_accuracy: 0.5845\n",
            "Epoch 84/500\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.9097 - accuracy: 0.6360 - val_loss: 0.9132 - val_accuracy: 0.6618\n",
            "Epoch 85/500\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.8974 - accuracy: 0.6463 - val_loss: 0.8907 - val_accuracy: 0.6570\n",
            "Epoch 86/500\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.8626 - accuracy: 0.6421 - val_loss: 0.8638 - val_accuracy: 0.6522\n",
            "Epoch 87/500\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.8876 - accuracy: 0.6608 - val_loss: 0.8963 - val_accuracy: 0.6087\n",
            "Epoch 88/500\n",
            "104/104 [==============================] - 2s 23ms/step - loss: 0.8414 - accuracy: 0.6632 - val_loss: 0.8817 - val_accuracy: 0.6329\n",
            "Epoch 89/500\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.8390 - accuracy: 0.6681 - val_loss: 0.8851 - val_accuracy: 0.6280\n",
            "Epoch 90/500\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.8578 - accuracy: 0.6596 - val_loss: 0.9238 - val_accuracy: 0.6618\n",
            "Epoch 91/500\n",
            "104/104 [==============================] - 2s 23ms/step - loss: 0.8543 - accuracy: 0.6651 - val_loss: 0.8830 - val_accuracy: 0.6329\n",
            "Epoch 92/500\n",
            "104/104 [==============================] - 2s 23ms/step - loss: 0.8530 - accuracy: 0.6608 - val_loss: 0.8564 - val_accuracy: 0.6618\n",
            "Epoch 93/500\n",
            "104/104 [==============================] - 2s 23ms/step - loss: 0.8294 - accuracy: 0.6614 - val_loss: 0.8778 - val_accuracy: 0.6618\n",
            "Epoch 94/500\n",
            "104/104 [==============================] - 2s 23ms/step - loss: 0.8250 - accuracy: 0.6693 - val_loss: 0.8612 - val_accuracy: 0.6473\n",
            "Epoch 95/500\n",
            "104/104 [==============================] - 2s 24ms/step - loss: 0.8218 - accuracy: 0.6669 - val_loss: 0.8790 - val_accuracy: 0.6232\n",
            "Epoch 96/500\n",
            "104/104 [==============================] - 2s 24ms/step - loss: 0.8140 - accuracy: 0.6765 - val_loss: 0.8905 - val_accuracy: 0.6280\n",
            "Epoch 97/500\n",
            "104/104 [==============================] - 2s 24ms/step - loss: 0.7831 - accuracy: 0.6904 - val_loss: 0.8272 - val_accuracy: 0.6425\n",
            "Epoch 98/500\n",
            "104/104 [==============================] - 3s 25ms/step - loss: 0.8303 - accuracy: 0.6693 - val_loss: 0.9076 - val_accuracy: 0.6280\n",
            "Epoch 99/500\n",
            "104/104 [==============================] - 2s 23ms/step - loss: 0.8067 - accuracy: 0.6832 - val_loss: 0.8763 - val_accuracy: 0.6232\n",
            "Epoch 100/500\n",
            "104/104 [==============================] - 2s 24ms/step - loss: 0.7785 - accuracy: 0.6844 - val_loss: 0.8869 - val_accuracy: 0.6473\n",
            "Epoch 101/500\n",
            "104/104 [==============================] - 2s 23ms/step - loss: 0.7968 - accuracy: 0.6892 - val_loss: 0.8697 - val_accuracy: 0.6377\n",
            "Epoch 102/500\n",
            "104/104 [==============================] - 3s 24ms/step - loss: 0.7677 - accuracy: 0.6953 - val_loss: 0.8345 - val_accuracy: 0.6812\n",
            "Epoch 103/500\n",
            "104/104 [==============================] - 3s 25ms/step - loss: 0.7777 - accuracy: 0.6904 - val_loss: 0.8449 - val_accuracy: 0.6329\n",
            "Epoch 104/500\n",
            "104/104 [==============================] - 3s 25ms/step - loss: 0.7675 - accuracy: 0.6989 - val_loss: 0.8069 - val_accuracy: 0.6715\n",
            "Epoch 105/500\n",
            "104/104 [==============================] - 3s 25ms/step - loss: 0.7701 - accuracy: 0.6898 - val_loss: 0.8476 - val_accuracy: 0.6184\n",
            "Epoch 106/500\n",
            "104/104 [==============================] - 2s 24ms/step - loss: 0.7793 - accuracy: 0.6917 - val_loss: 0.8472 - val_accuracy: 0.6377\n",
            "Epoch 107/500\n",
            "104/104 [==============================] - 2s 24ms/step - loss: 0.7716 - accuracy: 0.7007 - val_loss: 0.8266 - val_accuracy: 0.6232\n",
            "Epoch 108/500\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.7640 - accuracy: 0.7001 - val_loss: 0.8308 - val_accuracy: 0.6618\n",
            "Epoch 109/500\n",
            "104/104 [==============================] - 2s 23ms/step - loss: 0.7516 - accuracy: 0.6959 - val_loss: 0.7945 - val_accuracy: 0.6667\n",
            "Epoch 110/500\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.7580 - accuracy: 0.6886 - val_loss: 0.8151 - val_accuracy: 0.6618\n",
            "Epoch 111/500\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.7496 - accuracy: 0.7062 - val_loss: 0.8066 - val_accuracy: 0.6715\n",
            "Epoch 112/500\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.7449 - accuracy: 0.7092 - val_loss: 0.7768 - val_accuracy: 0.6763\n",
            "Epoch 113/500\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.7479 - accuracy: 0.7007 - val_loss: 0.8479 - val_accuracy: 0.6425\n",
            "Epoch 114/500\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.7479 - accuracy: 0.7044 - val_loss: 0.8500 - val_accuracy: 0.6522\n",
            "Epoch 115/500\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.7358 - accuracy: 0.7201 - val_loss: 0.8158 - val_accuracy: 0.6570\n",
            "Epoch 116/500\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.7525 - accuracy: 0.7037 - val_loss: 0.8791 - val_accuracy: 0.6425\n",
            "Epoch 117/500\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.7109 - accuracy: 0.7152 - val_loss: 0.7944 - val_accuracy: 0.6618\n",
            "Epoch 118/500\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.7292 - accuracy: 0.7104 - val_loss: 0.7998 - val_accuracy: 0.6618\n",
            "Epoch 119/500\n",
            "104/104 [==============================] - 2s 23ms/step - loss: 0.7133 - accuracy: 0.7140 - val_loss: 0.7770 - val_accuracy: 0.6715\n",
            "Epoch 120/500\n",
            "104/104 [==============================] - 2s 23ms/step - loss: 0.6959 - accuracy: 0.7219 - val_loss: 0.8454 - val_accuracy: 0.6715\n",
            "Epoch 121/500\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.7040 - accuracy: 0.7370 - val_loss: 0.8525 - val_accuracy: 0.6618\n",
            "Epoch 122/500\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.7100 - accuracy: 0.7219 - val_loss: 0.7763 - val_accuracy: 0.6667\n",
            "Epoch 123/500\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.7007 - accuracy: 0.7189 - val_loss: 0.7896 - val_accuracy: 0.6908\n",
            "Epoch 124/500\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.7096 - accuracy: 0.7158 - val_loss: 0.7790 - val_accuracy: 0.6618\n",
            "Epoch 125/500\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.6966 - accuracy: 0.7364 - val_loss: 0.7600 - val_accuracy: 0.6763\n",
            "Epoch 126/500\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.6896 - accuracy: 0.7304 - val_loss: 0.7672 - val_accuracy: 0.6908\n",
            "Epoch 127/500\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.6884 - accuracy: 0.7316 - val_loss: 0.8169 - val_accuracy: 0.6522\n",
            "Epoch 128/500\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.6783 - accuracy: 0.7316 - val_loss: 0.7585 - val_accuracy: 0.6667\n",
            "Epoch 129/500\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.6836 - accuracy: 0.7231 - val_loss: 0.7690 - val_accuracy: 0.6908\n",
            "Epoch 130/500\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.6830 - accuracy: 0.7285 - val_loss: 0.7588 - val_accuracy: 0.7053\n",
            "Epoch 131/500\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 0.6518 - accuracy: 0.7418 - val_loss: 0.7827 - val_accuracy: 0.6908\n",
            "Epoch 132/500\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 0.6670 - accuracy: 0.7352 - val_loss: 0.7489 - val_accuracy: 0.7005\n",
            "Epoch 133/500\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.6593 - accuracy: 0.7328 - val_loss: 0.7670 - val_accuracy: 0.6860\n",
            "Epoch 134/500\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.6475 - accuracy: 0.7467 - val_loss: 0.7746 - val_accuracy: 0.6570\n",
            "Epoch 135/500\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 0.6550 - accuracy: 0.7485 - val_loss: 0.7287 - val_accuracy: 0.7150\n",
            "Epoch 136/500\n",
            "104/104 [==============================] - 2s 23ms/step - loss: 0.6631 - accuracy: 0.7418 - val_loss: 0.7795 - val_accuracy: 0.6812\n",
            "Epoch 137/500\n",
            "104/104 [==============================] - 3s 25ms/step - loss: 0.6396 - accuracy: 0.7594 - val_loss: 0.7522 - val_accuracy: 0.6957\n",
            "Epoch 138/500\n",
            "104/104 [==============================] - 3s 25ms/step - loss: 0.6622 - accuracy: 0.7418 - val_loss: 0.7794 - val_accuracy: 0.6618\n",
            "Epoch 139/500\n",
            "104/104 [==============================] - 2s 23ms/step - loss: 0.6633 - accuracy: 0.7273 - val_loss: 0.7458 - val_accuracy: 0.7053\n",
            "Epoch 140/500\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.6624 - accuracy: 0.7310 - val_loss: 0.7230 - val_accuracy: 0.7053\n",
            "Epoch 141/500\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.6199 - accuracy: 0.7473 - val_loss: 0.7641 - val_accuracy: 0.7053\n",
            "Epoch 142/500\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.6458 - accuracy: 0.7503 - val_loss: 0.7355 - val_accuracy: 0.7005\n",
            "Epoch 143/500\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.6115 - accuracy: 0.7666 - val_loss: 0.7274 - val_accuracy: 0.7246\n",
            "Epoch 144/500\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.6274 - accuracy: 0.7600 - val_loss: 0.7584 - val_accuracy: 0.7150\n",
            "Epoch 145/500\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.6446 - accuracy: 0.7485 - val_loss: 0.7563 - val_accuracy: 0.6667\n",
            "Epoch 146/500\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.6019 - accuracy: 0.7684 - val_loss: 0.7652 - val_accuracy: 0.6570\n",
            "Epoch 147/500\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.6374 - accuracy: 0.7412 - val_loss: 0.7468 - val_accuracy: 0.6860\n",
            "Epoch 148/500\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.6113 - accuracy: 0.7594 - val_loss: 0.8336 - val_accuracy: 0.6425\n",
            "Epoch 149/500\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 0.6276 - accuracy: 0.7594 - val_loss: 0.6802 - val_accuracy: 0.7101\n",
            "Epoch 150/500\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 0.5997 - accuracy: 0.7684 - val_loss: 0.6922 - val_accuracy: 0.7198\n",
            "Epoch 151/500\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 0.5941 - accuracy: 0.7763 - val_loss: 0.7553 - val_accuracy: 0.6763\n",
            "Epoch 152/500\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 0.6006 - accuracy: 0.7696 - val_loss: 0.7774 - val_accuracy: 0.6957\n",
            "Epoch 153/500\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 0.5996 - accuracy: 0.7612 - val_loss: 0.7115 - val_accuracy: 0.7295\n",
            "Epoch 154/500\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 0.5979 - accuracy: 0.7648 - val_loss: 0.7730 - val_accuracy: 0.6812\n",
            "Epoch 155/500\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.5960 - accuracy: 0.7672 - val_loss: 0.7472 - val_accuracy: 0.6763\n",
            "Epoch 156/500\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.6174 - accuracy: 0.7551 - val_loss: 0.7595 - val_accuracy: 0.7391\n",
            "Epoch 157/500\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.5596 - accuracy: 0.7769 - val_loss: 0.6746 - val_accuracy: 0.7150\n",
            "Epoch 158/500\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 0.6024 - accuracy: 0.7660 - val_loss: 0.7019 - val_accuracy: 0.6763\n",
            "Epoch 159/500\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 0.5935 - accuracy: 0.7739 - val_loss: 0.7160 - val_accuracy: 0.6908\n",
            "Epoch 160/500\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.5802 - accuracy: 0.7751 - val_loss: 0.6743 - val_accuracy: 0.7391\n",
            "Epoch 161/500\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.5628 - accuracy: 0.7763 - val_loss: 0.7314 - val_accuracy: 0.6957\n",
            "Epoch 162/500\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.5568 - accuracy: 0.7811 - val_loss: 0.6914 - val_accuracy: 0.7536\n",
            "Epoch 163/500\n",
            "104/104 [==============================] - 2s 23ms/step - loss: 0.5619 - accuracy: 0.7866 - val_loss: 0.6910 - val_accuracy: 0.7440\n",
            "Epoch 164/500\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.5610 - accuracy: 0.7751 - val_loss: 0.6904 - val_accuracy: 0.7053\n",
            "Epoch 165/500\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.5849 - accuracy: 0.7805 - val_loss: 0.6848 - val_accuracy: 0.7246\n",
            "Epoch 166/500\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.5721 - accuracy: 0.7769 - val_loss: 0.6952 - val_accuracy: 0.6860\n",
            "Epoch 167/500\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.5420 - accuracy: 0.7854 - val_loss: 0.7044 - val_accuracy: 0.6957\n",
            "Epoch 168/500\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.5490 - accuracy: 0.7842 - val_loss: 0.7282 - val_accuracy: 0.6908\n",
            "Epoch 169/500\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.5568 - accuracy: 0.7908 - val_loss: 0.7324 - val_accuracy: 0.6908\n",
            "Epoch 170/500\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 0.5271 - accuracy: 0.7908 - val_loss: 0.6580 - val_accuracy: 0.7391\n",
            "Epoch 171/500\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 0.5598 - accuracy: 0.7956 - val_loss: 0.7291 - val_accuracy: 0.7101\n",
            "Epoch 172/500\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.5706 - accuracy: 0.7793 - val_loss: 0.7230 - val_accuracy: 0.7005\n",
            "Epoch 173/500\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.5352 - accuracy: 0.7830 - val_loss: 0.7181 - val_accuracy: 0.7053\n",
            "Epoch 174/500\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.5507 - accuracy: 0.7878 - val_loss: 0.6785 - val_accuracy: 0.7295\n",
            "Epoch 175/500\n",
            "104/104 [==============================] - 2s 23ms/step - loss: 0.5287 - accuracy: 0.7866 - val_loss: 0.6569 - val_accuracy: 0.7101\n",
            "Epoch 176/500\n",
            "104/104 [==============================] - 2s 24ms/step - loss: 0.5434 - accuracy: 0.7926 - val_loss: 0.6666 - val_accuracy: 0.7198\n",
            "Epoch 177/500\n",
            "104/104 [==============================] - 2s 23ms/step - loss: 0.5551 - accuracy: 0.7811 - val_loss: 0.7146 - val_accuracy: 0.7198\n",
            "Epoch 178/500\n",
            "104/104 [==============================] - 2s 23ms/step - loss: 0.5232 - accuracy: 0.7896 - val_loss: 0.6914 - val_accuracy: 0.7005\n",
            "Epoch 179/500\n",
            "104/104 [==============================] - 2s 23ms/step - loss: 0.5194 - accuracy: 0.8023 - val_loss: 0.6533 - val_accuracy: 0.7295\n",
            "Epoch 180/500\n",
            "104/104 [==============================] - 2s 23ms/step - loss: 0.5179 - accuracy: 0.7956 - val_loss: 0.6864 - val_accuracy: 0.7295\n",
            "Epoch 181/500\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.5118 - accuracy: 0.8138 - val_loss: 0.7079 - val_accuracy: 0.7198\n",
            "Epoch 182/500\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.5179 - accuracy: 0.8011 - val_loss: 0.7201 - val_accuracy: 0.6860\n",
            "Epoch 183/500\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.5217 - accuracy: 0.8059 - val_loss: 0.6768 - val_accuracy: 0.7198\n",
            "Epoch 184/500\n",
            "104/104 [==============================] - 2s 23ms/step - loss: 0.5080 - accuracy: 0.8017 - val_loss: 0.6513 - val_accuracy: 0.7488\n",
            "Epoch 185/500\n",
            "104/104 [==============================] - 2s 23ms/step - loss: 0.5330 - accuracy: 0.7920 - val_loss: 0.6802 - val_accuracy: 0.7488\n",
            "Epoch 186/500\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.5445 - accuracy: 0.7848 - val_loss: 0.6859 - val_accuracy: 0.7150\n",
            "Epoch 187/500\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.5197 - accuracy: 0.7969 - val_loss: 0.6513 - val_accuracy: 0.7343\n",
            "Epoch 188/500\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.5068 - accuracy: 0.8035 - val_loss: 0.6833 - val_accuracy: 0.7391\n",
            "Epoch 189/500\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 0.5236 - accuracy: 0.8083 - val_loss: 0.6490 - val_accuracy: 0.7343\n",
            "Epoch 190/500\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.4946 - accuracy: 0.8156 - val_loss: 0.6563 - val_accuracy: 0.7343\n",
            "Epoch 191/500\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.4903 - accuracy: 0.7993 - val_loss: 0.6787 - val_accuracy: 0.7246\n",
            "Epoch 192/500\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 0.4829 - accuracy: 0.8114 - val_loss: 0.6723 - val_accuracy: 0.6860\n",
            "Epoch 193/500\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.4957 - accuracy: 0.8126 - val_loss: 0.7372 - val_accuracy: 0.6812\n",
            "Epoch 194/500\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.4960 - accuracy: 0.8096 - val_loss: 0.6871 - val_accuracy: 0.7343\n",
            "Epoch 195/500\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.4836 - accuracy: 0.8017 - val_loss: 0.6399 - val_accuracy: 0.7488\n",
            "Epoch 196/500\n",
            "104/104 [==============================] - 3s 24ms/step - loss: 0.4622 - accuracy: 0.8253 - val_loss: 0.7700 - val_accuracy: 0.6812\n",
            "Epoch 197/500\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.4751 - accuracy: 0.8186 - val_loss: 0.6817 - val_accuracy: 0.7150\n",
            "Epoch 198/500\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.4826 - accuracy: 0.8077 - val_loss: 0.6729 - val_accuracy: 0.7343\n",
            "Epoch 199/500\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 0.4805 - accuracy: 0.8204 - val_loss: 0.6885 - val_accuracy: 0.7150\n",
            "Epoch 200/500\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.4945 - accuracy: 0.8120 - val_loss: 0.6482 - val_accuracy: 0.7488\n",
            "Epoch 201/500\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 0.4809 - accuracy: 0.8156 - val_loss: 0.6624 - val_accuracy: 0.7488\n",
            "Epoch 202/500\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 0.4549 - accuracy: 0.8216 - val_loss: 0.6782 - val_accuracy: 0.7295\n",
            "Epoch 203/500\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.4659 - accuracy: 0.8253 - val_loss: 0.6501 - val_accuracy: 0.7488\n",
            "Epoch 204/500\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.4849 - accuracy: 0.8126 - val_loss: 0.6203 - val_accuracy: 0.7681\n",
            "Epoch 205/500\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.4781 - accuracy: 0.8174 - val_loss: 0.6108 - val_accuracy: 0.7343\n",
            "Epoch 206/500\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 0.4657 - accuracy: 0.8180 - val_loss: 0.6415 - val_accuracy: 0.7391\n",
            "Epoch 207/500\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 0.4699 - accuracy: 0.8138 - val_loss: 0.6924 - val_accuracy: 0.7053\n",
            "Epoch 208/500\n",
            "104/104 [==============================] - 2s 23ms/step - loss: 0.4877 - accuracy: 0.8235 - val_loss: 0.6529 - val_accuracy: 0.7101\n",
            "Epoch 209/500\n",
            "104/104 [==============================] - 3s 25ms/step - loss: 0.4469 - accuracy: 0.8277 - val_loss: 0.6367 - val_accuracy: 0.7391\n",
            "Epoch 210/500\n",
            "104/104 [==============================] - 3s 25ms/step - loss: 0.4644 - accuracy: 0.8156 - val_loss: 0.6620 - val_accuracy: 0.7343\n",
            "Epoch 211/500\n",
            "104/104 [==============================] - 3s 25ms/step - loss: 0.4484 - accuracy: 0.8241 - val_loss: 0.6266 - val_accuracy: 0.7681\n",
            "Epoch 212/500\n",
            "104/104 [==============================] - 3s 25ms/step - loss: 0.4471 - accuracy: 0.8313 - val_loss: 0.6591 - val_accuracy: 0.7488\n",
            "Epoch 213/500\n",
            "104/104 [==============================] - 3s 25ms/step - loss: 0.4777 - accuracy: 0.8186 - val_loss: 0.6335 - val_accuracy: 0.7633\n",
            "Epoch 214/500\n",
            "104/104 [==============================] - 2s 23ms/step - loss: 0.4380 - accuracy: 0.8229 - val_loss: 0.6516 - val_accuracy: 0.7633\n",
            "Epoch 215/500\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.4257 - accuracy: 0.8349 - val_loss: 0.6311 - val_accuracy: 0.7585\n",
            "Epoch 216/500\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.4423 - accuracy: 0.8235 - val_loss: 0.6283 - val_accuracy: 0.7391\n",
            "Epoch 217/500\n",
            "104/104 [==============================] - 2s 24ms/step - loss: 0.3969 - accuracy: 0.8507 - val_loss: 0.7011 - val_accuracy: 0.7101\n",
            "Epoch 218/500\n",
            "104/104 [==============================] - 3s 26ms/step - loss: 0.4317 - accuracy: 0.8434 - val_loss: 0.7338 - val_accuracy: 0.7198\n",
            "Epoch 219/500\n",
            "104/104 [==============================] - 4s 42ms/step - loss: 0.4135 - accuracy: 0.8458 - val_loss: 0.6622 - val_accuracy: 0.7440\n",
            "Epoch 220/500\n",
            "104/104 [==============================] - 4s 40ms/step - loss: 0.4373 - accuracy: 0.8307 - val_loss: 0.6885 - val_accuracy: 0.7681\n",
            "Epoch 221/500\n",
            "104/104 [==============================] - 5s 45ms/step - loss: 0.4309 - accuracy: 0.8283 - val_loss: 0.7232 - val_accuracy: 0.7585\n",
            "Epoch 222/500\n",
            "104/104 [==============================] - 3s 30ms/step - loss: 0.4190 - accuracy: 0.8452 - val_loss: 0.6451 - val_accuracy: 0.7729\n",
            "Epoch 223/500\n",
            "104/104 [==============================] - 3s 25ms/step - loss: 0.4188 - accuracy: 0.8380 - val_loss: 0.6595 - val_accuracy: 0.7343\n",
            "Epoch 224/500\n",
            "104/104 [==============================] - 3s 25ms/step - loss: 0.4235 - accuracy: 0.8362 - val_loss: 0.6330 - val_accuracy: 0.7585\n",
            "Epoch 225/500\n",
            "104/104 [==============================] - 3s 25ms/step - loss: 0.4203 - accuracy: 0.8404 - val_loss: 0.7015 - val_accuracy: 0.7295\n",
            "Epoch 226/500\n",
            "104/104 [==============================] - 3s 25ms/step - loss: 0.4323 - accuracy: 0.8362 - val_loss: 0.6385 - val_accuracy: 0.7536\n",
            "Epoch 227/500\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.3803 - accuracy: 0.8561 - val_loss: 0.6430 - val_accuracy: 0.7295\n",
            "Epoch 228/500\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.3980 - accuracy: 0.8398 - val_loss: 0.6247 - val_accuracy: 0.7440\n",
            "Epoch 229/500\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.4168 - accuracy: 0.8458 - val_loss: 0.5964 - val_accuracy: 0.7778\n",
            "Epoch 230/500\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.4214 - accuracy: 0.8476 - val_loss: 0.7708 - val_accuracy: 0.6908\n",
            "Epoch 231/500\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.3829 - accuracy: 0.8579 - val_loss: 0.6606 - val_accuracy: 0.7585\n",
            "Epoch 232/500\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.4187 - accuracy: 0.8440 - val_loss: 0.6216 - val_accuracy: 0.7681\n",
            "Epoch 233/500\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.4088 - accuracy: 0.8482 - val_loss: 0.6526 - val_accuracy: 0.7101\n",
            "Epoch 234/500\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.4003 - accuracy: 0.8416 - val_loss: 0.6591 - val_accuracy: 0.7585\n",
            "Epoch 235/500\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.4014 - accuracy: 0.8446 - val_loss: 0.6471 - val_accuracy: 0.7246\n",
            "Epoch 236/500\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 0.3950 - accuracy: 0.8476 - val_loss: 0.6240 - val_accuracy: 0.7488\n",
            "Epoch 237/500\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 0.4052 - accuracy: 0.8531 - val_loss: 0.5839 - val_accuracy: 0.7585\n",
            "Epoch 238/500\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 0.3762 - accuracy: 0.8573 - val_loss: 0.6380 - val_accuracy: 0.7343\n",
            "Epoch 239/500\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 0.4049 - accuracy: 0.8501 - val_loss: 0.6365 - val_accuracy: 0.7440\n",
            "Epoch 240/500\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 0.4209 - accuracy: 0.8374 - val_loss: 0.6303 - val_accuracy: 0.7536\n",
            "Epoch 241/500\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 0.3996 - accuracy: 0.8404 - val_loss: 0.6043 - val_accuracy: 0.7488\n",
            "Epoch 242/500\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.4017 - accuracy: 0.8464 - val_loss: 0.6247 - val_accuracy: 0.7343\n",
            "Epoch 243/500\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 0.3944 - accuracy: 0.8428 - val_loss: 0.6968 - val_accuracy: 0.7150\n",
            "Epoch 244/500\n",
            "104/104 [==============================] - 2s 19ms/step - loss: 0.3739 - accuracy: 0.8531 - val_loss: 0.6266 - val_accuracy: 0.7440\n",
            "Epoch 245/500\n",
            "104/104 [==============================] - 2s 19ms/step - loss: 0.3964 - accuracy: 0.8464 - val_loss: 0.6128 - val_accuracy: 0.7633\n",
            "Epoch 246/500\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 0.3876 - accuracy: 0.8531 - val_loss: 0.6163 - val_accuracy: 0.7778\n",
            "Epoch 247/500\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.3776 - accuracy: 0.8579 - val_loss: 0.6309 - val_accuracy: 0.7440\n",
            "Epoch 248/500\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 0.3836 - accuracy: 0.8585 - val_loss: 0.6262 - val_accuracy: 0.7633\n",
            "Epoch 249/500\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 0.3841 - accuracy: 0.8579 - val_loss: 0.6278 - val_accuracy: 0.7633\n",
            "Epoch 250/500\n",
            "104/104 [==============================] - 2s 23ms/step - loss: 0.3652 - accuracy: 0.8585 - val_loss: 0.7147 - val_accuracy: 0.6957\n",
            "Epoch 251/500\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.3996 - accuracy: 0.8464 - val_loss: 0.6862 - val_accuracy: 0.7295\n",
            "Epoch 252/500\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 0.3830 - accuracy: 0.8519 - val_loss: 0.6111 - val_accuracy: 0.7343\n",
            "Epoch 253/500\n",
            "104/104 [==============================] - 2s 19ms/step - loss: 0.3739 - accuracy: 0.8622 - val_loss: 0.6600 - val_accuracy: 0.7440\n",
            "Epoch 254/500\n",
            "104/104 [==============================] - 2s 19ms/step - loss: 0.3491 - accuracy: 0.8785 - val_loss: 0.6175 - val_accuracy: 0.7391\n",
            "Epoch 255/500\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 0.3768 - accuracy: 0.8507 - val_loss: 0.6301 - val_accuracy: 0.7391\n",
            "Epoch 256/500\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 0.3877 - accuracy: 0.8531 - val_loss: 0.6741 - val_accuracy: 0.7440\n",
            "Epoch 257/500\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 0.3713 - accuracy: 0.8615 - val_loss: 0.6324 - val_accuracy: 0.7874\n",
            "Epoch 258/500\n",
            "104/104 [==============================] - 2s 23ms/step - loss: 0.3588 - accuracy: 0.8682 - val_loss: 0.6480 - val_accuracy: 0.7536\n",
            "Epoch 259/500\n",
            "104/104 [==============================] - 3s 26ms/step - loss: 0.3577 - accuracy: 0.8597 - val_loss: 0.6156 - val_accuracy: 0.7585\n",
            "Epoch 260/500\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 0.3387 - accuracy: 0.8694 - val_loss: 0.6530 - val_accuracy: 0.7150\n",
            "Epoch 261/500\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 0.3578 - accuracy: 0.8646 - val_loss: 0.6489 - val_accuracy: 0.7101\n",
            "Epoch 262/500\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.3315 - accuracy: 0.8736 - val_loss: 0.6597 - val_accuracy: 0.7246\n",
            "Epoch 263/500\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.3868 - accuracy: 0.8573 - val_loss: 0.7741 - val_accuracy: 0.7150\n",
            "Epoch 264/500\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.3448 - accuracy: 0.8742 - val_loss: 0.5809 - val_accuracy: 0.7729\n",
            "Epoch 265/500\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.3387 - accuracy: 0.8736 - val_loss: 0.6603 - val_accuracy: 0.7440\n",
            "Epoch 266/500\n",
            "104/104 [==============================] - 2s 23ms/step - loss: 0.3712 - accuracy: 0.8634 - val_loss: 0.6105 - val_accuracy: 0.7874\n",
            "Epoch 267/500\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.3476 - accuracy: 0.8779 - val_loss: 0.5997 - val_accuracy: 0.7874\n",
            "Epoch 268/500\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.3518 - accuracy: 0.8640 - val_loss: 0.6343 - val_accuracy: 0.7585\n",
            "Epoch 269/500\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.3379 - accuracy: 0.8761 - val_loss: 0.6506 - val_accuracy: 0.7343\n",
            "Epoch 270/500\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.3464 - accuracy: 0.8742 - val_loss: 0.6541 - val_accuracy: 0.7440\n",
            "Epoch 271/500\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.3515 - accuracy: 0.8718 - val_loss: 0.6445 - val_accuracy: 0.7488\n",
            "Epoch 272/500\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.3481 - accuracy: 0.8700 - val_loss: 0.6102 - val_accuracy: 0.7729\n",
            "Epoch 273/500\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.3435 - accuracy: 0.8652 - val_loss: 0.6386 - val_accuracy: 0.7585\n",
            "Epoch 274/500\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.3465 - accuracy: 0.8670 - val_loss: 0.6309 - val_accuracy: 0.7440\n",
            "Epoch 275/500\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.3305 - accuracy: 0.8742 - val_loss: 0.6023 - val_accuracy: 0.8068\n",
            "Epoch 276/500\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.3416 - accuracy: 0.8706 - val_loss: 0.6636 - val_accuracy: 0.7440\n",
            "Epoch 277/500\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.3484 - accuracy: 0.8712 - val_loss: 0.6178 - val_accuracy: 0.7826\n",
            "Epoch 278/500\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.3291 - accuracy: 0.8809 - val_loss: 0.6245 - val_accuracy: 0.7826\n",
            "Epoch 279/500\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.3412 - accuracy: 0.8767 - val_loss: 0.6510 - val_accuracy: 0.7295\n",
            "Epoch 280/500\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.3321 - accuracy: 0.8785 - val_loss: 0.5742 - val_accuracy: 0.7874\n",
            "Epoch 281/500\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.3317 - accuracy: 0.8785 - val_loss: 0.7025 - val_accuracy: 0.7391\n",
            "Epoch 282/500\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.3337 - accuracy: 0.8712 - val_loss: 0.6281 - val_accuracy: 0.7778\n",
            "Epoch 283/500\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.3073 - accuracy: 0.8845 - val_loss: 0.6145 - val_accuracy: 0.7778\n",
            "Epoch 284/500\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 0.3128 - accuracy: 0.8748 - val_loss: 0.6207 - val_accuracy: 0.7681\n",
            "Epoch 285/500\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.3148 - accuracy: 0.8857 - val_loss: 0.6120 - val_accuracy: 0.7633\n",
            "Epoch 286/500\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.3269 - accuracy: 0.8857 - val_loss: 0.6461 - val_accuracy: 0.7488\n",
            "Epoch 287/500\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 0.3350 - accuracy: 0.8736 - val_loss: 0.6275 - val_accuracy: 0.7488\n",
            "Epoch 288/500\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.3030 - accuracy: 0.8900 - val_loss: 0.5912 - val_accuracy: 0.8019\n",
            "Epoch 289/500\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.3179 - accuracy: 0.8833 - val_loss: 0.6899 - val_accuracy: 0.7198\n",
            "Epoch 290/500\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.2996 - accuracy: 0.8845 - val_loss: 0.6730 - val_accuracy: 0.7391\n",
            "Epoch 291/500\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 0.3290 - accuracy: 0.8773 - val_loss: 0.6365 - val_accuracy: 0.7391\n",
            "Epoch 292/500\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.3055 - accuracy: 0.8875 - val_loss: 0.6199 - val_accuracy: 0.7536\n",
            "Epoch 293/500\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.2920 - accuracy: 0.8894 - val_loss: 0.6455 - val_accuracy: 0.7585\n",
            "Epoch 294/500\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.2833 - accuracy: 0.8918 - val_loss: 0.6278 - val_accuracy: 0.7826\n",
            "Epoch 295/500\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.3120 - accuracy: 0.8821 - val_loss: 0.7017 - val_accuracy: 0.7633\n",
            "Epoch 296/500\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 0.3054 - accuracy: 0.8827 - val_loss: 0.6444 - val_accuracy: 0.7585\n",
            "Epoch 297/500\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.3291 - accuracy: 0.8755 - val_loss: 0.5731 - val_accuracy: 0.8261\n",
            "Epoch 298/500\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.3025 - accuracy: 0.8833 - val_loss: 0.6467 - val_accuracy: 0.7971\n",
            "Epoch 299/500\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.2871 - accuracy: 0.8930 - val_loss: 0.6081 - val_accuracy: 0.7778\n",
            "Epoch 300/500\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.2796 - accuracy: 0.8906 - val_loss: 0.6204 - val_accuracy: 0.7826\n",
            "Epoch 301/500\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.2859 - accuracy: 0.8918 - val_loss: 0.7229 - val_accuracy: 0.7440\n",
            "Epoch 302/500\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.3336 - accuracy: 0.8755 - val_loss: 0.5953 - val_accuracy: 0.7633\n",
            "Epoch 303/500\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 0.2971 - accuracy: 0.8900 - val_loss: 0.5830 - val_accuracy: 0.7923\n",
            "Epoch 304/500\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.3158 - accuracy: 0.8839 - val_loss: 0.5778 - val_accuracy: 0.8019\n",
            "Epoch 305/500\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 0.3165 - accuracy: 0.8833 - val_loss: 0.5938 - val_accuracy: 0.7874\n",
            "Epoch 306/500\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 0.2900 - accuracy: 0.8966 - val_loss: 0.6062 - val_accuracy: 0.8068\n",
            "Epoch 307/500\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.3032 - accuracy: 0.8930 - val_loss: 0.6326 - val_accuracy: 0.7923\n",
            "Epoch 308/500\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 0.3094 - accuracy: 0.8894 - val_loss: 0.5619 - val_accuracy: 0.8213\n",
            "Epoch 309/500\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.2626 - accuracy: 0.8960 - val_loss: 0.5720 - val_accuracy: 0.8164\n",
            "Epoch 310/500\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.2756 - accuracy: 0.9008 - val_loss: 0.6159 - val_accuracy: 0.7729\n",
            "Epoch 311/500\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.2813 - accuracy: 0.8960 - val_loss: 0.6052 - val_accuracy: 0.7923\n",
            "Epoch 312/500\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.2797 - accuracy: 0.8972 - val_loss: 0.6063 - val_accuracy: 0.7778\n",
            "Epoch 313/500\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.2765 - accuracy: 0.8960 - val_loss: 0.6407 - val_accuracy: 0.7633\n",
            "Epoch 314/500\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.2810 - accuracy: 0.8954 - val_loss: 0.5778 - val_accuracy: 0.7971\n",
            "Epoch 315/500\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.2798 - accuracy: 0.9002 - val_loss: 0.5861 - val_accuracy: 0.8068\n",
            "Epoch 316/500\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.2960 - accuracy: 0.8857 - val_loss: 0.6130 - val_accuracy: 0.7826\n",
            "Epoch 317/500\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.2836 - accuracy: 0.8954 - val_loss: 0.6546 - val_accuracy: 0.7826\n",
            "Epoch 318/500\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.2963 - accuracy: 0.8900 - val_loss: 0.6125 - val_accuracy: 0.7729\n",
            "Epoch 319/500\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.2711 - accuracy: 0.8996 - val_loss: 0.6298 - val_accuracy: 0.8164\n",
            "Epoch 320/500\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.2591 - accuracy: 0.9069 - val_loss: 0.6886 - val_accuracy: 0.7488\n",
            "Epoch 321/500\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 0.2877 - accuracy: 0.8912 - val_loss: 0.5834 - val_accuracy: 0.8019\n",
            "Epoch 322/500\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.2674 - accuracy: 0.9069 - val_loss: 0.5374 - val_accuracy: 0.8068\n",
            "Epoch 323/500\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 0.2881 - accuracy: 0.8924 - val_loss: 0.6915 - val_accuracy: 0.7343\n",
            "Epoch 324/500\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 0.2881 - accuracy: 0.9021 - val_loss: 0.6129 - val_accuracy: 0.7585\n",
            "Epoch 325/500\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.2570 - accuracy: 0.9051 - val_loss: 0.5753 - val_accuracy: 0.7923\n",
            "Epoch 326/500\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.2769 - accuracy: 0.8954 - val_loss: 0.6244 - val_accuracy: 0.7826\n",
            "Epoch 327/500\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.2544 - accuracy: 0.9087 - val_loss: 0.7067 - val_accuracy: 0.7295\n",
            "Epoch 328/500\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.2922 - accuracy: 0.8966 - val_loss: 0.6413 - val_accuracy: 0.7633\n",
            "Epoch 329/500\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.2617 - accuracy: 0.9075 - val_loss: 0.6745 - val_accuracy: 0.7343\n",
            "Epoch 330/500\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.2635 - accuracy: 0.9051 - val_loss: 0.6045 - val_accuracy: 0.7874\n",
            "Epoch 331/500\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.2772 - accuracy: 0.9027 - val_loss: 0.6164 - val_accuracy: 0.7729\n",
            "Epoch 332/500\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.2793 - accuracy: 0.8930 - val_loss: 0.6274 - val_accuracy: 0.7729\n",
            "Epoch 333/500\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.2625 - accuracy: 0.9087 - val_loss: 0.6474 - val_accuracy: 0.7585\n",
            "Epoch 334/500\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.2606 - accuracy: 0.9015 - val_loss: 0.6220 - val_accuracy: 0.7729\n",
            "Epoch 335/500\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.2692 - accuracy: 0.9015 - val_loss: 0.6604 - val_accuracy: 0.7681\n",
            "Epoch 336/500\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.2352 - accuracy: 0.9135 - val_loss: 0.6253 - val_accuracy: 0.7923\n",
            "Epoch 337/500\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.2648 - accuracy: 0.9039 - val_loss: 0.6005 - val_accuracy: 0.7923\n",
            "Epoch 338/500\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.2689 - accuracy: 0.8942 - val_loss: 0.6399 - val_accuracy: 0.7826\n",
            "Epoch 339/500\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.2647 - accuracy: 0.9063 - val_loss: 0.6476 - val_accuracy: 0.7440\n",
            "Epoch 340/500\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.2470 - accuracy: 0.9117 - val_loss: 0.6260 - val_accuracy: 0.7681\n",
            "Epoch 341/500\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.2474 - accuracy: 0.9081 - val_loss: 0.6111 - val_accuracy: 0.7874\n",
            "Epoch 342/500\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.2664 - accuracy: 0.9015 - val_loss: 0.6405 - val_accuracy: 0.8164\n",
            "Epoch 343/500\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.2827 - accuracy: 0.9033 - val_loss: 0.6058 - val_accuracy: 0.7874\n",
            "Epoch 344/500\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.2594 - accuracy: 0.9099 - val_loss: 0.6551 - val_accuracy: 0.7826\n",
            "Epoch 345/500\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.2821 - accuracy: 0.8984 - val_loss: 0.6046 - val_accuracy: 0.7923\n",
            "Epoch 346/500\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.2584 - accuracy: 0.8978 - val_loss: 0.6037 - val_accuracy: 0.7923\n",
            "Epoch 347/500\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.2402 - accuracy: 0.9166 - val_loss: 0.5866 - val_accuracy: 0.8164\n",
            "Epoch 348/500\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.2329 - accuracy: 0.9250 - val_loss: 0.6268 - val_accuracy: 0.7826\n",
            "Epoch 349/500\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.2552 - accuracy: 0.9039 - val_loss: 0.6139 - val_accuracy: 0.7729\n",
            "Epoch 350/500\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.2489 - accuracy: 0.9123 - val_loss: 0.6955 - val_accuracy: 0.7778\n",
            "Epoch 351/500\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.2737 - accuracy: 0.9033 - val_loss: 0.6125 - val_accuracy: 0.7778\n",
            "Epoch 352/500\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.2556 - accuracy: 0.9045 - val_loss: 0.5729 - val_accuracy: 0.8213\n",
            "Epoch 353/500\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.2580 - accuracy: 0.9069 - val_loss: 0.5652 - val_accuracy: 0.7971\n",
            "Epoch 354/500\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.2493 - accuracy: 0.9051 - val_loss: 0.6192 - val_accuracy: 0.7923\n",
            "Epoch 355/500\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.2557 - accuracy: 0.9093 - val_loss: 0.6445 - val_accuracy: 0.7971\n",
            "Epoch 356/500\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.2482 - accuracy: 0.9069 - val_loss: 0.6475 - val_accuracy: 0.7778\n",
            "Epoch 357/500\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.2691 - accuracy: 0.9117 - val_loss: 0.6953 - val_accuracy: 0.7971\n",
            "Epoch 358/500\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.2388 - accuracy: 0.9232 - val_loss: 0.6149 - val_accuracy: 0.7874\n",
            "Epoch 359/500\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.2481 - accuracy: 0.9154 - val_loss: 0.5805 - val_accuracy: 0.7826\n",
            "Epoch 360/500\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 0.2550 - accuracy: 0.9087 - val_loss: 0.6225 - val_accuracy: 0.7681\n",
            "Epoch 361/500\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.2387 - accuracy: 0.9129 - val_loss: 0.6161 - val_accuracy: 0.7826\n",
            "Epoch 362/500\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.2249 - accuracy: 0.9178 - val_loss: 0.6174 - val_accuracy: 0.8068\n",
            "Epoch 363/500\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.2392 - accuracy: 0.9123 - val_loss: 0.6631 - val_accuracy: 0.7681\n",
            "Epoch 364/500\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.2070 - accuracy: 0.9202 - val_loss: 0.6740 - val_accuracy: 0.7826\n",
            "Epoch 365/500\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.2325 - accuracy: 0.9172 - val_loss: 0.7328 - val_accuracy: 0.7536\n",
            "Epoch 366/500\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.2204 - accuracy: 0.9178 - val_loss: 0.6680 - val_accuracy: 0.7971\n",
            "Epoch 367/500\n",
            "104/104 [==============================] - 2s 23ms/step - loss: 0.2448 - accuracy: 0.9160 - val_loss: 0.5982 - val_accuracy: 0.8213\n",
            "Epoch 368/500\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.2401 - accuracy: 0.9039 - val_loss: 0.6420 - val_accuracy: 0.8068\n",
            "Epoch 369/500\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.2417 - accuracy: 0.9105 - val_loss: 0.5596 - val_accuracy: 0.7971\n",
            "Epoch 370/500\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.2270 - accuracy: 0.9202 - val_loss: 0.6402 - val_accuracy: 0.7923\n",
            "Epoch 371/500\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.2136 - accuracy: 0.9220 - val_loss: 0.7027 - val_accuracy: 0.7585\n",
            "Epoch 372/500\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.2291 - accuracy: 0.9214 - val_loss: 0.6106 - val_accuracy: 0.7874\n",
            "Epoch 373/500\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.2165 - accuracy: 0.9135 - val_loss: 0.7211 - val_accuracy: 0.7295\n",
            "Epoch 374/500\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.2390 - accuracy: 0.9117 - val_loss: 0.6246 - val_accuracy: 0.7778\n",
            "Epoch 375/500\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.2413 - accuracy: 0.9129 - val_loss: 0.6651 - val_accuracy: 0.7633\n",
            "Epoch 376/500\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.2064 - accuracy: 0.9268 - val_loss: 0.6650 - val_accuracy: 0.7633\n",
            "Epoch 377/500\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.2091 - accuracy: 0.9220 - val_loss: 0.6587 - val_accuracy: 0.7874\n",
            "Epoch 378/500\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.2416 - accuracy: 0.9196 - val_loss: 0.6495 - val_accuracy: 0.7826\n",
            "Epoch 379/500\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.2292 - accuracy: 0.9184 - val_loss: 0.6574 - val_accuracy: 0.7681\n",
            "Epoch 380/500\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.2167 - accuracy: 0.9262 - val_loss: 0.6793 - val_accuracy: 0.7585\n",
            "Epoch 381/500\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.2251 - accuracy: 0.9232 - val_loss: 0.5762 - val_accuracy: 0.8116\n",
            "Epoch 382/500\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.2177 - accuracy: 0.9262 - val_loss: 0.6460 - val_accuracy: 0.7923\n",
            "Epoch 383/500\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.2342 - accuracy: 0.9160 - val_loss: 0.6428 - val_accuracy: 0.7585\n",
            "Epoch 384/500\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.2252 - accuracy: 0.9117 - val_loss: 0.7204 - val_accuracy: 0.7585\n",
            "Epoch 385/500\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.2148 - accuracy: 0.9123 - val_loss: 0.6543 - val_accuracy: 0.7536\n",
            "Epoch 386/500\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.2343 - accuracy: 0.9172 - val_loss: 0.6265 - val_accuracy: 0.7729\n",
            "Epoch 387/500\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.2380 - accuracy: 0.9178 - val_loss: 0.6439 - val_accuracy: 0.7729\n",
            "Epoch 388/500\n",
            "104/104 [==============================] - 2s 23ms/step - loss: 0.2191 - accuracy: 0.9190 - val_loss: 0.6311 - val_accuracy: 0.7971\n",
            "Epoch 389/500\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.2122 - accuracy: 0.9256 - val_loss: 0.6341 - val_accuracy: 0.7971\n",
            "Epoch 390/500\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.1943 - accuracy: 0.9371 - val_loss: 0.6374 - val_accuracy: 0.7923\n",
            "Epoch 391/500\n",
            "104/104 [==============================] - 2s 23ms/step - loss: 0.1932 - accuracy: 0.9305 - val_loss: 0.7724 - val_accuracy: 0.7681\n",
            "Epoch 392/500\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.2327 - accuracy: 0.9238 - val_loss: 0.6445 - val_accuracy: 0.7633\n",
            "Epoch 393/500\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.2030 - accuracy: 0.9287 - val_loss: 0.6368 - val_accuracy: 0.7488\n",
            "Epoch 394/500\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.2156 - accuracy: 0.9256 - val_loss: 0.6076 - val_accuracy: 0.7681\n",
            "Epoch 395/500\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.2114 - accuracy: 0.9238 - val_loss: 0.5971 - val_accuracy: 0.8019\n",
            "Epoch 396/500\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.2066 - accuracy: 0.9238 - val_loss: 0.6923 - val_accuracy: 0.7971\n",
            "Epoch 397/500\n",
            "104/104 [==============================] - 2s 23ms/step - loss: 0.2104 - accuracy: 0.9262 - val_loss: 0.6179 - val_accuracy: 0.7874\n",
            "Epoch 398/500\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.2014 - accuracy: 0.9281 - val_loss: 0.6510 - val_accuracy: 0.7633\n",
            "Epoch 399/500\n",
            "104/104 [==============================] - 2s 23ms/step - loss: 0.2194 - accuracy: 0.9226 - val_loss: 0.6477 - val_accuracy: 0.7971\n",
            "Epoch 400/500\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.2285 - accuracy: 0.9208 - val_loss: 0.6438 - val_accuracy: 0.8068\n",
            "Epoch 401/500\n",
            "104/104 [==============================] - 2s 23ms/step - loss: 0.2171 - accuracy: 0.9208 - val_loss: 0.6548 - val_accuracy: 0.7778\n",
            "Epoch 402/500\n",
            "104/104 [==============================] - 2s 24ms/step - loss: 0.2036 - accuracy: 0.9293 - val_loss: 0.6387 - val_accuracy: 0.7826\n",
            "Epoch 403/500\n",
            "104/104 [==============================] - 3s 26ms/step - loss: 0.1926 - accuracy: 0.9262 - val_loss: 0.6848 - val_accuracy: 0.7826\n",
            "Epoch 404/500\n",
            "104/104 [==============================] - 3s 26ms/step - loss: 0.2061 - accuracy: 0.9281 - val_loss: 0.6380 - val_accuracy: 0.7826\n",
            "Epoch 405/500\n",
            "104/104 [==============================] - 2s 24ms/step - loss: 0.2253 - accuracy: 0.9190 - val_loss: 0.5931 - val_accuracy: 0.8213\n",
            "Epoch 406/500\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.1945 - accuracy: 0.9311 - val_loss: 0.6217 - val_accuracy: 0.8116\n",
            "Epoch 407/500\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.2241 - accuracy: 0.9208 - val_loss: 0.6063 - val_accuracy: 0.8068\n",
            "Epoch 408/500\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.1914 - accuracy: 0.9311 - val_loss: 0.6311 - val_accuracy: 0.7923\n",
            "Epoch 409/500\n",
            "104/104 [==============================] - 3s 25ms/step - loss: 0.2027 - accuracy: 0.9196 - val_loss: 0.6463 - val_accuracy: 0.7585\n",
            "Epoch 410/500\n",
            "104/104 [==============================] - 3s 25ms/step - loss: 0.2097 - accuracy: 0.9262 - val_loss: 0.6985 - val_accuracy: 0.7923\n",
            "Epoch 411/500\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.2040 - accuracy: 0.9353 - val_loss: 0.6780 - val_accuracy: 0.7923\n",
            "Epoch 412/500\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.2026 - accuracy: 0.9281 - val_loss: 0.6700 - val_accuracy: 0.7826\n",
            "Epoch 413/500\n",
            "104/104 [==============================] - 3s 24ms/step - loss: 0.2174 - accuracy: 0.9323 - val_loss: 0.6273 - val_accuracy: 0.8213\n",
            "Epoch 414/500\n",
            "104/104 [==============================] - 3s 26ms/step - loss: 0.1958 - accuracy: 0.9281 - val_loss: 0.6426 - val_accuracy: 0.8019\n",
            "Epoch 415/500\n",
            "104/104 [==============================] - 2s 24ms/step - loss: 0.2095 - accuracy: 0.9226 - val_loss: 0.5986 - val_accuracy: 0.7923\n",
            "Epoch 416/500\n",
            "104/104 [==============================] - 2s 24ms/step - loss: 0.2166 - accuracy: 0.9244 - val_loss: 0.5812 - val_accuracy: 0.8019\n",
            "Epoch 417/500\n",
            "104/104 [==============================] - 3s 25ms/step - loss: 0.2004 - accuracy: 0.9323 - val_loss: 0.6421 - val_accuracy: 0.7729\n",
            "Epoch 418/500\n",
            "104/104 [==============================] - 3s 25ms/step - loss: 0.2038 - accuracy: 0.9305 - val_loss: 0.7226 - val_accuracy: 0.7681\n",
            "Epoch 419/500\n",
            "104/104 [==============================] - 2s 24ms/step - loss: 0.1664 - accuracy: 0.9395 - val_loss: 0.6776 - val_accuracy: 0.7633\n",
            "Epoch 420/500\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.1811 - accuracy: 0.9323 - val_loss: 0.7476 - val_accuracy: 0.7778\n",
            "Epoch 421/500\n",
            "104/104 [==============================] - 2s 23ms/step - loss: 0.1995 - accuracy: 0.9250 - val_loss: 0.6657 - val_accuracy: 0.8164\n",
            "Epoch 422/500\n",
            "104/104 [==============================] - 2s 23ms/step - loss: 0.1878 - accuracy: 0.9395 - val_loss: 0.6513 - val_accuracy: 0.7826\n",
            "Epoch 423/500\n",
            "104/104 [==============================] - 2s 24ms/step - loss: 0.1884 - accuracy: 0.9377 - val_loss: 0.6381 - val_accuracy: 0.7729\n",
            "Epoch 424/500\n",
            "104/104 [==============================] - 2s 23ms/step - loss: 0.1683 - accuracy: 0.9389 - val_loss: 0.6261 - val_accuracy: 0.8116\n",
            "Epoch 425/500\n",
            "104/104 [==============================] - 2s 23ms/step - loss: 0.1788 - accuracy: 0.9371 - val_loss: 0.6739 - val_accuracy: 0.7923\n",
            "Epoch 426/500\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.1843 - accuracy: 0.9371 - val_loss: 0.5926 - val_accuracy: 0.8406\n",
            "Epoch 427/500\n",
            "104/104 [==============================] - 2s 24ms/step - loss: 0.1824 - accuracy: 0.9335 - val_loss: 0.6764 - val_accuracy: 0.7536\n",
            "Epoch 428/500\n",
            "104/104 [==============================] - 2s 24ms/step - loss: 0.2016 - accuracy: 0.9268 - val_loss: 0.6614 - val_accuracy: 0.7923\n",
            "Epoch 429/500\n",
            "104/104 [==============================] - 2s 24ms/step - loss: 0.1782 - accuracy: 0.9353 - val_loss: 0.6183 - val_accuracy: 0.8164\n",
            "Epoch 430/500\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.1750 - accuracy: 0.9377 - val_loss: 0.6048 - val_accuracy: 0.7826\n",
            "Epoch 431/500\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.1987 - accuracy: 0.9274 - val_loss: 0.7482 - val_accuracy: 0.7585\n",
            "Epoch 432/500\n",
            "104/104 [==============================] - 2s 23ms/step - loss: 0.1895 - accuracy: 0.9347 - val_loss: 0.6505 - val_accuracy: 0.7971\n",
            "Epoch 433/500\n",
            "104/104 [==============================] - 2s 23ms/step - loss: 0.1933 - accuracy: 0.9305 - val_loss: 0.6525 - val_accuracy: 0.8116\n",
            "Epoch 434/500\n",
            "104/104 [==============================] - 2s 23ms/step - loss: 0.1893 - accuracy: 0.9383 - val_loss: 0.6080 - val_accuracy: 0.8019\n",
            "Epoch 435/500\n",
            "104/104 [==============================] - 2s 24ms/step - loss: 0.1933 - accuracy: 0.9359 - val_loss: 0.6380 - val_accuracy: 0.8116\n",
            "Epoch 436/500\n",
            "104/104 [==============================] - 3s 24ms/step - loss: 0.2157 - accuracy: 0.9299 - val_loss: 0.7723 - val_accuracy: 0.7633\n",
            "Epoch 437/500\n",
            "104/104 [==============================] - 2s 23ms/step - loss: 0.1608 - accuracy: 0.9389 - val_loss: 0.6867 - val_accuracy: 0.8068\n",
            "Epoch 438/500\n",
            "104/104 [==============================] - 3s 25ms/step - loss: 0.1877 - accuracy: 0.9438 - val_loss: 0.6328 - val_accuracy: 0.8116\n",
            "Epoch 439/500\n",
            "104/104 [==============================] - 3s 25ms/step - loss: 0.2141 - accuracy: 0.9281 - val_loss: 0.6410 - val_accuracy: 0.7729\n",
            "Epoch 440/500\n",
            "104/104 [==============================] - 3s 24ms/step - loss: 0.1680 - accuracy: 0.9395 - val_loss: 0.6616 - val_accuracy: 0.7826\n",
            "Epoch 441/500\n",
            "104/104 [==============================] - 2s 23ms/step - loss: 0.1857 - accuracy: 0.9329 - val_loss: 0.6259 - val_accuracy: 0.7923\n",
            "Epoch 442/500\n",
            "104/104 [==============================] - 2s 23ms/step - loss: 0.2093 - accuracy: 0.9335 - val_loss: 0.6643 - val_accuracy: 0.7923\n",
            "Epoch 443/500\n",
            "104/104 [==============================] - 3s 24ms/step - loss: 0.1730 - accuracy: 0.9401 - val_loss: 0.6154 - val_accuracy: 0.8116\n",
            "Epoch 444/500\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.1862 - accuracy: 0.9407 - val_loss: 0.5975 - val_accuracy: 0.8357\n",
            "Epoch 445/500\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.1766 - accuracy: 0.9426 - val_loss: 0.6623 - val_accuracy: 0.7874\n",
            "Epoch 446/500\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.1920 - accuracy: 0.9311 - val_loss: 0.6363 - val_accuracy: 0.7826\n",
            "Epoch 447/500\n",
            "104/104 [==============================] - 2s 23ms/step - loss: 0.1809 - accuracy: 0.9347 - val_loss: 0.6312 - val_accuracy: 0.7874\n",
            "Epoch 448/500\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.1714 - accuracy: 0.9407 - val_loss: 0.6575 - val_accuracy: 0.7923\n",
            "Epoch 449/500\n",
            "104/104 [==============================] - 2s 24ms/step - loss: 0.1786 - accuracy: 0.9389 - val_loss: 0.5640 - val_accuracy: 0.8309\n",
            "Epoch 450/500\n",
            "104/104 [==============================] - 2s 23ms/step - loss: 0.1670 - accuracy: 0.9395 - val_loss: 0.6882 - val_accuracy: 0.7826\n",
            "Epoch 451/500\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.1894 - accuracy: 0.9359 - val_loss: 0.5746 - val_accuracy: 0.8309\n",
            "Epoch 452/500\n",
            "104/104 [==============================] - 2s 23ms/step - loss: 0.1677 - accuracy: 0.9414 - val_loss: 0.7066 - val_accuracy: 0.8019\n",
            "Epoch 453/500\n",
            "104/104 [==============================] - 3s 24ms/step - loss: 0.1647 - accuracy: 0.9371 - val_loss: 0.6322 - val_accuracy: 0.7874\n",
            "Epoch 454/500\n",
            "104/104 [==============================] - 2s 23ms/step - loss: 0.1596 - accuracy: 0.9426 - val_loss: 0.6311 - val_accuracy: 0.7729\n",
            "Epoch 455/500\n",
            "104/104 [==============================] - 2s 23ms/step - loss: 0.1691 - accuracy: 0.9395 - val_loss: 0.8028 - val_accuracy: 0.7778\n",
            "Epoch 456/500\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.1799 - accuracy: 0.9426 - val_loss: 0.5832 - val_accuracy: 0.7923\n",
            "Epoch 457/500\n",
            "104/104 [==============================] - 2s 23ms/step - loss: 0.1823 - accuracy: 0.9377 - val_loss: 0.6071 - val_accuracy: 0.8019\n",
            "Epoch 458/500\n",
            "104/104 [==============================] - 2s 24ms/step - loss: 0.1718 - accuracy: 0.9347 - val_loss: 0.6555 - val_accuracy: 0.7681\n",
            "Epoch 459/500\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.1901 - accuracy: 0.9317 - val_loss: 0.5929 - val_accuracy: 0.8068\n",
            "Epoch 460/500\n",
            "104/104 [==============================] - 2s 23ms/step - loss: 0.1546 - accuracy: 0.9474 - val_loss: 0.7163 - val_accuracy: 0.8019\n",
            "Epoch 461/500\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.1681 - accuracy: 0.9414 - val_loss: 0.7307 - val_accuracy: 0.8019\n",
            "Epoch 462/500\n",
            "104/104 [==============================] - 2s 23ms/step - loss: 0.1757 - accuracy: 0.9407 - val_loss: 0.6728 - val_accuracy: 0.7971\n",
            "Epoch 463/500\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.1644 - accuracy: 0.9407 - val_loss: 0.6061 - val_accuracy: 0.8406\n",
            "Epoch 464/500\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.1701 - accuracy: 0.9353 - val_loss: 0.6656 - val_accuracy: 0.7971\n",
            "Epoch 465/500\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.1542 - accuracy: 0.9468 - val_loss: 0.8339 - val_accuracy: 0.7585\n",
            "Epoch 466/500\n",
            "104/104 [==============================] - 2s 23ms/step - loss: 0.1606 - accuracy: 0.9371 - val_loss: 0.6412 - val_accuracy: 0.7826\n",
            "Epoch 467/500\n",
            "104/104 [==============================] - 2s 23ms/step - loss: 0.1682 - accuracy: 0.9438 - val_loss: 0.5961 - val_accuracy: 0.7778\n",
            "Epoch 468/500\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.1854 - accuracy: 0.9432 - val_loss: 0.6284 - val_accuracy: 0.7778\n",
            "Epoch 469/500\n",
            "104/104 [==============================] - 2s 23ms/step - loss: 0.1810 - accuracy: 0.9317 - val_loss: 0.6702 - val_accuracy: 0.7971\n",
            "Epoch 470/500\n",
            "104/104 [==============================] - 2s 23ms/step - loss: 0.1636 - accuracy: 0.9462 - val_loss: 0.5946 - val_accuracy: 0.7826\n",
            "Epoch 471/500\n",
            "104/104 [==============================] - 2s 23ms/step - loss: 0.1762 - accuracy: 0.9480 - val_loss: 0.6247 - val_accuracy: 0.8116\n",
            "Epoch 472/500\n",
            "104/104 [==============================] - 3s 25ms/step - loss: 0.1750 - accuracy: 0.9383 - val_loss: 0.6466 - val_accuracy: 0.8164\n",
            "Epoch 473/500\n",
            "104/104 [==============================] - 2s 23ms/step - loss: 0.1696 - accuracy: 0.9432 - val_loss: 0.5860 - val_accuracy: 0.8019\n",
            "Epoch 474/500\n",
            "104/104 [==============================] - 2s 23ms/step - loss: 0.1618 - accuracy: 0.9522 - val_loss: 0.7347 - val_accuracy: 0.7729\n",
            "Epoch 475/500\n",
            "104/104 [==============================] - 3s 24ms/step - loss: 0.1575 - accuracy: 0.9426 - val_loss: 0.6627 - val_accuracy: 0.8019\n",
            "Epoch 476/500\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.1862 - accuracy: 0.9359 - val_loss: 0.5137 - val_accuracy: 0.8164\n",
            "Epoch 477/500\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.1817 - accuracy: 0.9377 - val_loss: 0.6704 - val_accuracy: 0.8068\n",
            "Epoch 478/500\n",
            "104/104 [==============================] - 2s 23ms/step - loss: 0.1594 - accuracy: 0.9432 - val_loss: 0.6294 - val_accuracy: 0.8068\n",
            "Epoch 479/500\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.1532 - accuracy: 0.9504 - val_loss: 0.5831 - val_accuracy: 0.8261\n",
            "Epoch 480/500\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.1804 - accuracy: 0.9365 - val_loss: 0.6256 - val_accuracy: 0.7729\n",
            "Epoch 481/500\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.1605 - accuracy: 0.9414 - val_loss: 0.5911 - val_accuracy: 0.8261\n",
            "Epoch 482/500\n",
            "104/104 [==============================] - 2s 24ms/step - loss: 0.1685 - accuracy: 0.9420 - val_loss: 0.5466 - val_accuracy: 0.8019\n",
            "Epoch 483/500\n",
            "104/104 [==============================] - 3s 26ms/step - loss: 0.1691 - accuracy: 0.9456 - val_loss: 0.6733 - val_accuracy: 0.7585\n",
            "Epoch 484/500\n",
            "104/104 [==============================] - 3s 26ms/step - loss: 0.1517 - accuracy: 0.9474 - val_loss: 0.7516 - val_accuracy: 0.7633\n",
            "Epoch 485/500\n",
            "104/104 [==============================] - 3s 27ms/step - loss: 0.1899 - accuracy: 0.9365 - val_loss: 0.6649 - val_accuracy: 0.8213\n",
            "Epoch 486/500\n",
            "104/104 [==============================] - 3s 26ms/step - loss: 0.1522 - accuracy: 0.9462 - val_loss: 0.6298 - val_accuracy: 0.8551\n",
            "Epoch 487/500\n",
            "104/104 [==============================] - 3s 24ms/step - loss: 0.1533 - accuracy: 0.9480 - val_loss: 0.6725 - val_accuracy: 0.7826\n",
            "Epoch 488/500\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.1800 - accuracy: 0.9317 - val_loss: 0.6952 - val_accuracy: 0.8019\n",
            "Epoch 489/500\n",
            "104/104 [==============================] - 2s 23ms/step - loss: 0.1658 - accuracy: 0.9426 - val_loss: 0.6627 - val_accuracy: 0.7826\n",
            "Epoch 490/500\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.1755 - accuracy: 0.9414 - val_loss: 0.6382 - val_accuracy: 0.7923\n",
            "Epoch 491/500\n",
            "104/104 [==============================] - 2s 24ms/step - loss: 0.1826 - accuracy: 0.9371 - val_loss: 0.6640 - val_accuracy: 0.7681\n",
            "Epoch 492/500\n",
            "104/104 [==============================] - 2s 23ms/step - loss: 0.1353 - accuracy: 0.9492 - val_loss: 0.6368 - val_accuracy: 0.8068\n",
            "Epoch 493/500\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.1468 - accuracy: 0.9486 - val_loss: 0.6377 - val_accuracy: 0.7971\n",
            "Epoch 494/500\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.1450 - accuracy: 0.9474 - val_loss: 0.6298 - val_accuracy: 0.7874\n",
            "Epoch 495/500\n",
            "104/104 [==============================] - 2s 24ms/step - loss: 0.1456 - accuracy: 0.9414 - val_loss: 0.6986 - val_accuracy: 0.7778\n",
            "Epoch 496/500\n",
            "104/104 [==============================] - 3s 25ms/step - loss: 0.1863 - accuracy: 0.9317 - val_loss: 0.6973 - val_accuracy: 0.7874\n",
            "Epoch 497/500\n",
            "104/104 [==============================] - 3s 24ms/step - loss: 0.1495 - accuracy: 0.9456 - val_loss: 0.6477 - val_accuracy: 0.8019\n",
            "Epoch 498/500\n",
            "104/104 [==============================] - 3s 26ms/step - loss: 0.1602 - accuracy: 0.9450 - val_loss: 0.6210 - val_accuracy: 0.8309\n",
            "Epoch 499/500\n",
            "104/104 [==============================] - 3s 29ms/step - loss: 0.1731 - accuracy: 0.9432 - val_loss: 0.5814 - val_accuracy: 0.8164\n",
            "Epoch 500/500\n",
            "104/104 [==============================] - 3s 27ms/step - loss: 0.1475 - accuracy: 0.9541 - val_loss: 0.6911 - val_accuracy: 0.7681\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(cnnhistory.history['loss'])\n",
        "plt.plot(cnnhistory.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train','test'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "oQYnuaCrDH_A",
        "outputId": "4bff5ac2-6880-4164-c7f4-4a4d7f7bd7f4"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "01otXNBSCLs9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(cnnhistory.history['accuracy'])\n",
        "plt.plot(cnnhistory.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train','test'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "IFkTuO8nDNdq",
        "outputId": "426c7b7d-712d-4754-cbf6-996d03deda83"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#predictions = model.predict_classes(x_testcnn)\n",
        "predictions = model.predict(x_testcnn)"
      ],
      "metadata": {
        "id": "A2xtrN5wDQgY"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_f_ohjXKDUpY",
        "outputId": "50022809-4f72-4ea6-9667-f81bbde74b9a"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[3.6945089e-03, 2.1693850e-02, 9.0481110e-02, 1.2446282e-02,\n",
              "        6.5397274e-01, 2.1771148e-01],\n",
              "       [3.6402718e-05, 9.9693573e-01, 8.7570970e-06, 1.9298944e-03,\n",
              "        1.0868990e-03, 2.2258976e-06],\n",
              "       [1.3379362e-05, 2.2191041e-04, 9.9629968e-01, 2.0174008e-05,\n",
              "        3.1681214e-03, 2.7675516e-04],\n",
              "       ...,\n",
              "       [4.3569977e-05, 5.7348927e-07, 9.3112438e-04, 1.6334870e-04,\n",
              "        9.8051810e-01, 1.8343279e-02],\n",
              "       [9.2729839e-04, 3.2178323e-05, 9.5006028e-05, 8.1418735e-01,\n",
              "        1.2861990e-04, 1.8462956e-01],\n",
              "       [1.5327862e-05, 1.0354538e-07, 2.7578392e-03, 3.1100568e-01,\n",
              "        1.4993172e-10, 6.8622100e-01]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cmA2bFgsDW3D",
        "outputId": "78d821db-19f8-4593-9e78-7393deea88d3"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5, 1, 2, 5, 4, 3, 2, 0, 3, 0, 3, 2, 0, 3, 3, 0, 5, 0, 2, 4, 0, 0,\n",
              "       1, 3, 2, 3, 2, 5, 3, 1, 2, 4, 2, 2, 5, 5, 3, 5, 3, 3, 4, 1, 2, 2,\n",
              "       3, 1, 5, 3, 1, 0, 4, 5, 5, 5, 5, 1, 2, 3, 2, 5, 0, 2, 4, 2, 5, 4,\n",
              "       2, 0, 2, 3, 5, 2, 0, 3, 4, 4, 4, 0, 5, 5, 3, 4, 5, 3, 2, 4, 1, 5,\n",
              "       0, 5, 0, 5, 4, 0, 1, 4, 0, 2, 2, 0, 2, 4, 5, 3, 4, 5, 3, 1, 2, 2,\n",
              "       2, 1, 3, 2, 1, 2, 4, 4, 2, 1, 2, 4, 5, 1, 4, 2, 0, 4, 5, 5, 3, 1,\n",
              "       2, 1, 5, 5, 1, 2, 3, 3, 0, 3, 3, 0, 1, 0, 1, 2, 2, 5, 2, 2, 2, 1,\n",
              "       1, 0, 1, 1, 1, 4, 0, 1, 5, 1, 5, 5, 5, 4, 1, 0, 3, 5, 2, 4, 1, 4,\n",
              "       1, 3, 2, 0, 5, 5, 3, 5, 4, 5, 4, 0, 4, 1, 2, 1, 4, 0, 4, 3, 2, 1,\n",
              "       0, 3, 5, 0, 4, 5, 4, 5, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_Ytest = y_test.astype(int)"
      ],
      "metadata": {
        "id": "0PHDKWJWDY3g"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_Ytest"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k68v2i-pDbZE",
        "outputId": "409c0a05-0469-483a-e0c9-2e67f17b20bc"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5, 1, 2, 5, 4, 3, 2, 0, 3, 0, 3, 2, 0, 3, 3, 0, 5, 0, 2, 4, 0, 0,\n",
              "       1, 3, 2, 3, 2, 5, 3, 1, 2, 4, 2, 2, 5, 5, 3, 5, 3, 3, 4, 1, 2, 2,\n",
              "       3, 1, 5, 3, 1, 0, 4, 5, 5, 5, 5, 1, 2, 3, 2, 5, 0, 2, 4, 2, 5, 4,\n",
              "       2, 0, 2, 3, 5, 2, 0, 3, 4, 4, 4, 0, 5, 5, 3, 4, 5, 3, 2, 4, 1, 5,\n",
              "       0, 5, 0, 5, 4, 0, 1, 4, 0, 2, 2, 0, 2, 4, 5, 3, 4, 5, 3, 1, 2, 2,\n",
              "       2, 1, 3, 2, 1, 2, 4, 4, 2, 1, 2, 4, 5, 1, 4, 2, 0, 4, 5, 5, 3, 1,\n",
              "       2, 1, 5, 5, 1, 2, 3, 3, 0, 3, 3, 0, 1, 0, 1, 2, 2, 5, 2, 2, 2, 1,\n",
              "       1, 0, 1, 1, 1, 4, 0, 1, 5, 1, 5, 5, 5, 4, 1, 0, 3, 5, 2, 4, 1, 4,\n",
              "       1, 3, 2, 0, 5, 5, 3, 5, 4, 5, 4, 0, 4, 1, 2, 1, 4, 0, 4, 3, 2, 1,\n",
              "       0, 3, 5, 0, 4, 5, 4, 5, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds1=predictions.argmax(axis=1)\n",
        "preds1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4_cAI39VFhtp",
        "outputId": "5d0aada8-ea1d-4a1e-ca59-7fe63aa517b4"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([4, 1, 2, 5, 4, 1, 2, 0, 3, 0, 3, 2, 0, 3, 3, 0, 5, 3, 2, 4, 2, 1,\n",
              "       1, 3, 2, 5, 2, 2, 3, 3, 2, 4, 2, 2, 5, 4, 1, 5, 3, 2, 5, 1, 4, 5,\n",
              "       3, 1, 5, 3, 1, 1, 4, 2, 2, 2, 4, 1, 2, 3, 2, 5, 0, 2, 3, 4, 5, 4,\n",
              "       2, 0, 2, 3, 3, 2, 0, 3, 4, 4, 4, 1, 5, 5, 3, 4, 5, 3, 2, 4, 1, 5,\n",
              "       1, 5, 0, 5, 4, 0, 1, 4, 3, 4, 2, 4, 2, 4, 5, 3, 4, 5, 5, 1, 2, 2,\n",
              "       2, 1, 3, 2, 1, 5, 4, 4, 2, 1, 5, 4, 0, 1, 4, 4, 2, 4, 4, 5, 5, 1,\n",
              "       4, 1, 5, 5, 1, 3, 3, 3, 0, 3, 3, 0, 1, 0, 1, 2, 4, 5, 2, 2, 4, 1,\n",
              "       1, 0, 1, 1, 1, 4, 0, 1, 5, 1, 5, 5, 5, 4, 1, 0, 3, 1, 2, 4, 3, 4,\n",
              "       1, 3, 1, 5, 5, 5, 3, 5, 4, 5, 4, 0, 4, 0, 2, 1, 4, 0, 4, 1, 2, 0,\n",
              "       0, 5, 5, 0, 4, 2, 4, 3, 5])"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "abc = preds1.astype(int).flatten()"
      ],
      "metadata": {
        "id": "H4WEmM60NfQn"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "c = confusion_matrix(new_Ytest, abc) \n",
        "c"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bKEBeEBlFjB8",
        "outputId": "37f281fb-1d9f-4154-c9ee-df23aad73865"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[19,  4,  2,  2,  1,  1],\n",
              "       [ 2, 28,  0,  2,  0,  0],\n",
              "       [ 0,  1, 29,  1,  7,  3],\n",
              "       [ 0,  3,  1, 23,  0,  5],\n",
              "       [ 0,  0,  0,  1, 30,  1],\n",
              "       [ 1,  1,  5,  2,  4, 28]])"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m4RjG7LWLSQx",
        "outputId": "c7c6efbc-ca43-4f15-87a0-cf4b30db1e05"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5, 1, 2, 5, 4, 3, 2, 0, 3, 0, 3, 2, 0, 3, 3, 0, 5, 0, 2, 4, 0, 0,\n",
              "       1, 3, 2, 3, 2, 5, 3, 1, 2, 4, 2, 2, 5, 5, 3, 5, 3, 3, 4, 1, 2, 2,\n",
              "       3, 1, 5, 3, 1, 0, 4, 5, 5, 5, 5, 1, 2, 3, 2, 5, 0, 2, 4, 2, 5, 4,\n",
              "       2, 0, 2, 3, 5, 2, 0, 3, 4, 4, 4, 0, 5, 5, 3, 4, 5, 3, 2, 4, 1, 5,\n",
              "       0, 5, 0, 5, 4, 0, 1, 4, 0, 2, 2, 0, 2, 4, 5, 3, 4, 5, 3, 1, 2, 2,\n",
              "       2, 1, 3, 2, 1, 2, 4, 4, 2, 1, 2, 4, 5, 1, 4, 2, 0, 4, 5, 5, 3, 1,\n",
              "       2, 1, 5, 5, 1, 2, 3, 3, 0, 3, 3, 0, 1, 0, 1, 2, 2, 5, 2, 2, 2, 1,\n",
              "       1, 0, 1, 1, 1, 4, 0, 1, 5, 1, 5, 5, 5, 4, 1, 0, 3, 5, 2, 4, 1, 4,\n",
              "       1, 3, 2, 0, 5, 5, 3, 5, 4, 5, 4, 0, 4, 1, 2, 1, 4, 0, 4, 3, 2, 1,\n",
              "       0, 3, 5, 0, 4, 5, 4, 5, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('/content/drive/My Drive/graduation project/audio/paper_code/mariam/original_500 epoch_with_valid_RMS3')\n",
        "print(\"MODEL SAVED\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lsJBNeMWDl6Z",
        "outputId": "db5a4cb9-d888-4458-c0fc-8fef5ca9c1e8"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/graduation project/audio/paper_code/mariam/original_500 epoch_with_valid_RMS3/assets\n",
            "MODEL SAVED\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_model=keras.models.load_model('/content/drive/My Drive/graduation project/audio/paper_code/mariam/original_500 epoch_with_valid_RMS3')\n",
        "new_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q3KjaO9GDoNl",
        "outputId": "b73c3eec-369f-49c2-8c49-24c275476d04"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d (Conv1D)             (None, 40, 128)           1152      \n",
            "                                                                 \n",
            " activation (Activation)     (None, 40, 128)           0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 40, 128)           0         \n",
            "                                                                 \n",
            " max_pooling1d (MaxPooling1D  (None, 8, 128)           0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv1d_1 (Conv1D)           (None, 8, 256)            262400    \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 8, 256)            0         \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 8, 256)            0         \n",
            "                                                                 \n",
            " max_pooling1d_1 (MaxPooling  (None, 1, 256)           0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 256)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 256)               65792     \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 256)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 256)               65792     \n",
            "                                                                 \n",
            " activation_3 (Activation)   (None, 256)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 6)                 1542      \n",
            "                                                                 \n",
            " activation_4 (Activation)   (None, 6)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 396,678\n",
            "Trainable params: 396,678\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = new_model.predict(x_testcnn)"
      ],
      "metadata": {
        "id": "WOKeSzc7T-MZ"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3RjQxa2RUBKQ",
        "outputId": "b2ae6485-cd63-483d-a238-80911f01d464"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[3.6945089e-03, 2.1693850e-02, 9.0481110e-02, 1.2446282e-02,\n",
              "        6.5397274e-01, 2.1771148e-01],\n",
              "       [3.6402718e-05, 9.9693573e-01, 8.7570970e-06, 1.9298944e-03,\n",
              "        1.0868990e-03, 2.2258976e-06],\n",
              "       [1.3379362e-05, 2.2191041e-04, 9.9629968e-01, 2.0174008e-05,\n",
              "        3.1681214e-03, 2.7675516e-04],\n",
              "       ...,\n",
              "       [4.3569977e-05, 5.7348927e-07, 9.3112438e-04, 1.6334870e-04,\n",
              "        9.8051810e-01, 1.8343279e-02],\n",
              "       [9.2729839e-04, 3.2178323e-05, 9.5006028e-05, 8.1418735e-01,\n",
              "        1.2861990e-04, 1.8462956e-01],\n",
              "       [1.5327862e-05, 1.0354538e-07, 2.7578392e-03, 3.1100568e-01,\n",
              "        1.4993172e-10, 6.8622100e-01]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss, acc =new_model.evaluate(x_testcnn, y_test)\n",
        "print(\"Restored model, accuracy: {:5.2f}%\".format(100*acc))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n3kzoqPkDqqS",
        "outputId": "2fc9b9c7-9b43-4ae9-db22-91660d3af229"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7/7 [==============================] - 0s 6ms/step - loss: 0.8628 - accuracy: 0.7585\n",
            "Restored model, accuracy: 75.85%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss, acc =new_model.evaluate(X_train, y_train)\n",
        "print(\"Restored model train, accuracy: {:5.2f}%\".format(100*acc))"
      ],
      "metadata": {
        "id": "fJDTGH_OUX0z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d2e60551-92c5-45a7-d56f-e6b98e26253b"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "52/52 [==============================] - 0s 5ms/step - loss: 0.0660 - accuracy: 0.9873\n",
            "Restored model train, accuracy: 98.73%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix,accuracy_score\n",
        "import seaborn as sn\n",
        "\n",
        "print(classification_report(new_Ytest,abc))\n",
        "\n",
        "acc = float(accuracy_score(new_Ytest,abc))*100\n",
        "print(\"----accuracy score %s ----\" % acc)\n",
        "\n",
        "cm = confusion_matrix(new_Ytest,abc)\n",
        "#df_cm = pd.DataFrame(cm)\n",
        "class_names = ['neutral','calm', 'happy','sad','angry', 'fearful' ]\n",
        "df_cm = pd.DataFrame(cm, index=class_names, columns=class_names,)\n",
        "sn.heatmap(df_cm, annot=True, fmt='')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 512
        },
        "id": "SfSC3El94LZg",
        "outputId": "2cd26228-9374-4880-f6e0-c210a3255dc3"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.66      0.75        29\n",
            "           1       0.76      0.88      0.81        32\n",
            "           2       0.78      0.71      0.74        41\n",
            "           3       0.74      0.72      0.73        32\n",
            "           4       0.71      0.94      0.81        32\n",
            "           5       0.74      0.68      0.71        41\n",
            "\n",
            "    accuracy                           0.76       207\n",
            "   macro avg       0.77      0.76      0.76       207\n",
            "weighted avg       0.76      0.76      0.76       207\n",
            "\n",
            "----accuracy score 75.84541062801932 ----\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "y5OoGgupF7kU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}