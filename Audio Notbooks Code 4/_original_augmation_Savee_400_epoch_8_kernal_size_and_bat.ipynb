{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uzZTLwtNdxKi",
        "outputId": "6a6f5a12-a0d2-4825-e5f7-f9e8cd2dd5ae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: keras in /opt/conda/envs/rapids/lib/python3.7/site-packages (2.8.0)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install keras"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cB9NV-RLdSLZ",
        "outputId": "65e45188-024c-4db1-955c-69fcb00b1b08"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EbHyBIe_dOYb",
        "outputId": "65c42ecd-cb15-422c-9f7c-006f2a33e71f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow in /opt/conda/envs/rapids/lib/python3.7/site-packages (2.8.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: tf-estimator-nightly==2.8.0.dev2021122109 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from tensorflow) (2.8.0.dev2021122109)\n",
            "Requirement already satisfied: numpy>=1.20 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from tensorflow) (1.21.1)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from tensorflow) (13.0.0)\n",
            "Requirement already satisfied: gast>=0.2.1 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from tensorflow) (0.5.3)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from tensorflow) (0.24.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from tensorflow) (3.6.0)\n",
            "Requirement already satisfied: setuptools in /opt/conda/envs/rapids/lib/python3.7/site-packages (from tensorflow) (49.6.0.post20210108)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from tensorflow) (1.44.0)\n",
            "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from tensorflow) (2.8.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from tensorflow) (1.12.1)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from tensorflow) (1.0.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: six>=1.12.0 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: tensorboard<2.9,>=2.8 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from tensorflow) (2.8.0)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from tensorflow) (2.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from tensorflow) (3.10.0.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from tensorflow) (3.16.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from astunparse>=1.6.0->tensorflow) (0.37.0)\n",
            "Requirement already satisfied: cached-property in /opt/conda/envs/rapids/lib/python3.7/site-packages (from h5py>=2.9.0->tensorflow) (1.5.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from tensorboard<2.9,>=2.8->tensorflow) (3.3.4)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.8.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.6.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.6.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.26.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.0.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.4.6)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.2.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata in /opt/conda/envs/rapids/lib/python3.7/site-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (4.6.4)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (1.26.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2021.10.8)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (3.1)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2.0.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (3.2.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from importlib-metadata->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (3.5.0)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-2iPI3-RdOYc",
        "outputId": "2509154d-3389-4ed5-bb2b-ee9ecd547258"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting package metadata (current_repodata.json): done\n",
            "Solving environment: done\n",
            "\n",
            "# All requested packages already installed.\n",
            "\n",
            "\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "conda install librosa "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bcVbQcYAdOYd",
        "outputId": "1390c775-5026-4e4a-9499-dda6f863afb1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: plotly in /opt/conda/envs/rapids/lib/python3.7/site-packages (5.6.0)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from plotly) (8.0.1)\n",
            "Requirement already satisfied: six in /opt/conda/envs/rapids/lib/python3.7/site-packages (from plotly) (1.16.0)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install plotly"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QeizPlDkdOYe",
        "outputId": "0307d276-8ddb-469d-d681-866e0cd6afab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: librosa in /opt/conda/envs/rapids/lib/python3.7/site-packages (0.9.1)\n",
            "Requirement already satisfied: resampy>=0.2.2 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from librosa) (0.2.2)\n",
            "Requirement already satisfied: scikit-learn>=0.19.1 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from librosa) (0.23.1)\n",
            "Requirement already satisfied: pooch>=1.0 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from librosa) (1.5.1)\n",
            "Requirement already satisfied: audioread>=2.1.5 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from librosa) (2.1.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from librosa) (21.0)\n",
            "Requirement already satisfied: numpy>=1.17.0 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from librosa) (1.21.1)\n",
            "Requirement already satisfied: decorator>=4.0.10 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied: joblib>=0.14 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from librosa) (1.0.1)\n",
            "Requirement already satisfied: numba>=0.45.1 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from librosa) (0.53.1)\n",
            "Requirement already satisfied: scipy>=1.2.0 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from librosa) (1.6.0)\n",
            "Requirement already satisfied: soundfile>=0.10.2 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from librosa) (0.10.3.post1)\n",
            "Requirement already satisfied: llvmlite<0.37,>=0.36.0rc1 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from numba>=0.45.1->librosa) (0.36.0)\n",
            "Requirement already satisfied: setuptools in /opt/conda/envs/rapids/lib/python3.7/site-packages (from numba>=0.45.1->librosa) (49.6.0.post20210108)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from packaging>=20.0->librosa) (2.4.7)\n",
            "Requirement already satisfied: requests in /opt/conda/envs/rapids/lib/python3.7/site-packages (from pooch>=1.0->librosa) (2.26.0)\n",
            "Requirement already satisfied: appdirs in /opt/conda/envs/rapids/lib/python3.7/site-packages (from pooch>=1.0->librosa) (1.4.4)\n",
            "Requirement already satisfied: six>=1.3 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from resampy>=0.2.2->librosa) (1.16.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from scikit-learn>=0.19.1->librosa) (2.2.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from soundfile>=0.10.2->librosa) (1.14.6)\n",
            "Requirement already satisfied: pycparser in /opt/conda/envs/rapids/lib/python3.7/site-packages (from cffi>=1.0->soundfile>=0.10.2->librosa) (2.20)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from requests->pooch>=1.0->librosa) (2021.10.8)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from requests->pooch>=1.0->librosa) (1.26.6)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from requests->pooch>=1.0->librosa) (2.0.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from requests->pooch>=1.0->librosa) (3.1)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install librosa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "NgJohC6sdr-S",
        "outputId": "102b3584-1466-4cf8-a0e3-c8010b318138"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "        <script type=\"text/javascript\">\n",
              "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
              "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
              "        if (typeof require !== 'undefined') {\n",
              "        require.undef(\"plotly\");\n",
              "        requirejs.config({\n",
              "            paths: {\n",
              "                'plotly': ['https://cdn.plot.ly/plotly-2.8.3.min']\n",
              "            }\n",
              "        });\n",
              "        require(['plotly'], function(Plotly) {\n",
              "            window._Plotly = Plotly;\n",
              "        });\n",
              "        }\n",
              "        </script>\n",
              "        "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Orignial Notebook: https://github.com/MITESHPUTHRANNEU/Speech-Emotion-Analyzer/blob/master/final_results_gender_test.ipynb\n",
        "# This notebook author: Reza Chu\n",
        "# Last Editing Date: 31st May 2019\n",
        "\n",
        "## Python\n",
        "import os\n",
        "import random\n",
        "import sys\n",
        "\n",
        "import IPython\n",
        "from IPython.display import Audio\n",
        "from IPython.display import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "## Package\n",
        "import glob \n",
        "import keras\n",
        "import IPython.display as ipd\n",
        "import librosa\n",
        "import librosa.display\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import plotly.graph_objs as go\n",
        "import plotly.offline as py\n",
        "import plotly.tools as tls\n",
        "import seaborn as sns\n",
        "import scipy.io.wavfile\n",
        "import tensorflow as tf\n",
        "py.init_notebook_mode(connected=True)\n",
        "\n",
        "## Keras\n",
        "from keras import regularizers\n",
        "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping\n",
        "from keras.callbacks import  History, ReduceLROnPlateau, CSVLogger\n",
        "from keras.models import Model, Sequential\n",
        "from keras.layers import Dense, Embedding, LSTM\n",
        "from keras.layers import Input, Flatten, Dropout, Activation, BatchNormalization\n",
        "from keras.layers import Conv1D, MaxPooling1D, AveragePooling1D\n",
        "from keras.preprocessing import sequence\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.utils import np_utils\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "## Sklearn\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "## Rest\n",
        "from scipy.fftpack import fft\n",
        "from scipy import signal\n",
        "from scipy.io import wavfile\n",
        "from tqdm import tqdm\n",
        "\n",
        "input_duration=3\n",
        "# % pylab inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a9_TpDKveU1d",
        "outputId": "e84f401c-a0c5-45c5-9a69-52db9954fa9f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Data loaded. Loading time: 14.231287956237793 seconds ---\n"
          ]
        }
      ],
      "source": [
        "#only SAVEE data set\n",
        "import time\n",
        "import os\n",
        "import librosa\n",
        "from librosa import display\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "lst = []\n",
        "count=0\n",
        "start_time = time.time()\n",
        "\n",
        "path3 = '/content/drive/My Drive/data_set/SAVEE'\n",
        "for subdir, dirs, files in os.walk(path3):\n",
        "  for file in files:\n",
        "      try:\n",
        "        #0 = neutral,  1 = fearful, 2 = happy, 3 = sad, 4 = angry\n",
        "        if file.startswith('a'):\n",
        "            emotion=4\n",
        "        elif file.startswith('d'):\n",
        "            continue\n",
        "        elif file.startswith('f'):\n",
        "            emotion=1\n",
        "        elif file.startswith('h'):\n",
        "            emotion=2\n",
        "        elif file.startswith('n'):\n",
        "            emotion=0\n",
        "        elif file.startswith('sa'):\n",
        "            emotion=3\n",
        "        elif file.startswith('su'):\n",
        "            continue\n",
        "        else:\n",
        "            continue\n",
        "        #Load librosa array, obtain mfcss, store the file and the mcss information in a new array\n",
        "        X, sample_rate = librosa.load(os.path.join(subdir,file), res_type='kaiser_fast')\n",
        "        #print(sample_rate)\n",
        "       # mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T,axis=0) \n",
        "        count +=1\n",
        "        # The instruction below converts the labels (from 1 to 8) to a series from 0 to 7\n",
        "        # This is because our predictor needs to start from 0 otherwise it will try to predict also 0.\n",
        "        #file = int(file[7:8]) - 1 \n",
        "        #0 = neutral, 1 = calm, 2 = happy, 3 = sad, 4 = angry, 5 = fearful, 6 = disgust, 7 = surprised\n",
        "        arr = X, emotion\n",
        "        lst.append(arr)\n",
        "      # If the file is not valid, skip it\n",
        "      except ValueError:\n",
        "        continue\n",
        "\n",
        "print(\"--- Data loaded. Loading time: %s seconds ---\" % (time.time() - start_time))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XVaArAIkdOYj",
        "outputId": "7cda59b7-7fa0-4b5d-a194-c35890c842bc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/core/fromnumeric.py:3208: VisibleDeprecationWarning:\n",
            "\n",
            "Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "720"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "from numpy.core.fromnumeric import size\n",
        "size(lst)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uo6fLwandOYl",
        "outputId": "2c8b338e-c485-4748-fc13-c55f511f42c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/core/fromnumeric.py:3208: VisibleDeprecationWarning:\n",
            "\n",
            "Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "720"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "from numpy.core.fromnumeric import size\n",
        "size(lst)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2vTLVo3SdOYm",
        "outputId": "7e271b4b-8017-4840-d2d6-c35e3e100efb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: VisibleDeprecationWarning:\n",
            "\n",
            "Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "audio_file, emotion = zip(*lst)\n",
        "audio_file=np.asarray(audio_file)\n",
        "emotion=np.asarray(emotion)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M-pbYcFDd5a2",
        "outputId": "60fc1cd2-6de0-40b7-e7d7-be0527d3aa16"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((288,), (36,), (36,))"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "\n",
        "emotion.shape,audio_file.shape\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "signal_train, signal_test, emo_train, emo_test = train_test_split(audio_file,emotion, test_size=0.2, random_state=42)\n",
        "signal_valid, signal_test, emo_valid, emo_test = train_test_split(signal_test,emo_test, test_size=0.5,train_size=0.5, random_state=42)\n",
        "signal_train.shape,signal_valid.shape,signal_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "OflClL3QfDoj"
      },
      "outputs": [],
      "source": [
        "x_valid=[]\n",
        "x_test=[]\n",
        "for i in range(signal_valid.size):\n",
        "  x_valid.append(np.mean(librosa.feature.mfcc(y=signal_valid[i], sr=sample_rate, n_mfcc=40).T,axis=0))\n",
        "  #x_valid.append(np.mean(librosa.feature.chroma_stft(S=np.abs(librosa.stft(signal_valid[i])), sr=sample_rate ,n_chroma=12).T,axis=0))\n",
        "\n",
        "for i in range(signal_test.size):\n",
        "  x_test.append(np.mean(librosa.feature.mfcc(y=signal_test[i], sr=sample_rate, n_mfcc=40).T,axis=0))\n",
        "  #x_test.append(np.mean(librosa.feature.chroma_stft(S=np.abs(librosa.stft(signal_test[i])), sr=sample_rate,n_chroma=12).T,axis=0))\n",
        "#resv = np.hstack((resv, mfccsv))  \n",
        "#resv = np.hstack((resv, cromav))  \n",
        "#resv = np.hstack((resv, melv))  \n",
        "\n",
        "#rest = np.hstack((rest, mfccst))  \n",
        "#rest = np.hstack((rest, cromat))  \n",
        "#rest = np.hstack((rest, melt))\n",
        "\n",
        "#x_valid.append(resv)\n",
        "#x_test.append(rest)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kJkN-K17gSvD",
        "outputId": "0f534e07-3b3e-46ca-9167-e1fc3d66dc83"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((36, 40), (36, 40))"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "x_valid=np.asarray(x_valid)\n",
        "x_test=np.asarray(x_test)\n",
        "x_valid.shape,x_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "k43cyWMKgXo9"
      },
      "outputs": [],
      "source": [
        "train_lst=[]\n",
        "for i in range(signal_train.size):\n",
        "  emo=emo_train[i]\n",
        "  x=signal_train[i]\n",
        "  arr=x,emo\n",
        "  train_lst.append(arr)\n",
        "  x=librosa.effects.time_stretch(signal_train[i],0.5)\n",
        "  arr=x,emo\n",
        "  train_lst.append(arr)\n",
        "  x=librosa.effects.time_stretch(signal_train[i],1.5)\n",
        "  arr=x,emo\n",
        "  train_lst.append(arr)\n",
        "  x=librosa.effects.pitch_shift(signal_train[i],sample_rate,2)\n",
        "  arr=x,emo\n",
        "  train_lst.append(arr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "gFL9v0A9kYvD"
      },
      "outputs": [],
      "source": [
        "signal, y_train = zip(*train_lst)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ulnUCfZikY7Y",
        "outputId": "99b5b744-3b85-4483-f055-8e3097d5b691"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: VisibleDeprecationWarning:\n",
            "\n",
            "Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "signal=np.asarray(signal)\n",
        "y_train=np.asarray(y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bt0pm0g4kY9q",
        "outputId": "c88a4084-aaa4-424d-8177-e0219f8e6dbe"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1152,)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "y_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "yGPv5UDikY_f"
      },
      "outputs": [],
      "source": [
        "x_train=[]\n",
        "for i in range(signal.size):\n",
        "  x_train.append(np.mean(librosa.feature.mfcc(y=signal[i], sr=sample_rate, n_mfcc=40).T,axis=0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7qnveahvkj3U",
        "outputId": "57175a63-8a19-4ec0-94e7-b3889c7ee0af"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1152, 40)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "x_train=np.asarray(x_train)\n",
        "x_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LFnBsKPXkmDV",
        "outputId": "1c04405b-319e-447a-c4f1-4ce415a8bcd4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1152,)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "y_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zlvfnkyLkxWx",
        "outputId": "91e6df55-0065-4c66-ae90-c84cb35a4f2d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning:\n",
            "\n",
            "The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import keras\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from keras.preprocessing import sequence\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from keras.layers import Input, Flatten, Dropout, Activation\n",
        "from keras.layers import Conv1D, MaxPooling1D\n",
        "from keras.models import Model\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras import optimizers\n",
        "from keras.models import InputLayer\n",
        "\n",
        "model = Sequential(InputLayer((40,1)))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Conv1D(128, 8,padding='same', ))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.1))\n",
        "model.add(MaxPooling1D(pool_size=(5)))\n",
        "\n",
        "\n",
        "model.add(Conv1D(256,8,padding='same',))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(MaxPooling1D(pool_size=(5)))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(6))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "opt = tf.keras.optimizers.Adam(lr=0.0002)\n",
        "#opt = tf.keras.optimizers.RMSprop(lr=0.0001, rho=0.9, epsilon=1e-07, decay=0.0)\n",
        "#opt = tf.keras.optimizers.SGD(lr=0.001, momentum=0.0, decay=0.0, nesterov=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1-Xsvw44kzg1",
        "outputId": "db5ee11c-8b2d-44b2-882b-821d6321b272"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " batch_normalization_3 (Batc  (None, 40, 1)            4         \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " conv1d_2 (Conv1D)           (None, 40, 128)           1152      \n",
            "                                                                 \n",
            " batch_normalization_4 (Batc  (None, 40, 128)          512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_3 (Activation)   (None, 40, 128)           0         \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 40, 128)           0         \n",
            "                                                                 \n",
            " max_pooling1d_2 (MaxPooling  (None, 8, 128)           0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " conv1d_3 (Conv1D)           (None, 8, 256)            262400    \n",
            "                                                                 \n",
            " batch_normalization_5 (Batc  (None, 8, 256)           1024      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_4 (Activation)   (None, 8, 256)            0         \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 8, 256)            0         \n",
            "                                                                 \n",
            " max_pooling1d_3 (MaxPooling  (None, 1, 256)           0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 256)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 6)                 1542      \n",
            "                                                                 \n",
            " activation_5 (Activation)   (None, 6)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 266,634\n",
            "Trainable params: 265,864\n",
            "Non-trainable params: 770\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "m0w5VpjNk1d7"
      },
      "outputs": [],
      "source": [
        "model.compile(loss='sparse_categorical_crossentropy',\n",
        "              optimizer=opt,\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tz-HMdw4k3Vt",
        "outputId": "d29acbe6-dd21-45a4-e18e-545b301dc153"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/400\n",
            "72/72 [==============================] - 2s 21ms/step - loss: 1.9694 - accuracy: 0.3681 - val_loss: 1.7260 - val_accuracy: 0.2222\n",
            "Epoch 2/400\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 1.2349 - accuracy: 0.5286 - val_loss: 1.9967 - val_accuracy: 0.3889\n",
            "Epoch 3/400\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 1.0523 - accuracy: 0.5964 - val_loss: 1.9519 - val_accuracy: 0.4167\n",
            "Epoch 4/400\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.9794 - accuracy: 0.6189 - val_loss: 2.0222 - val_accuracy: 0.2778\n",
            "Epoch 5/400\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.9062 - accuracy: 0.6545 - val_loss: 2.2565 - val_accuracy: 0.1389\n",
            "Epoch 6/400\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.8751 - accuracy: 0.6484 - val_loss: 1.9621 - val_accuracy: 0.1111\n",
            "Epoch 7/400\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.8540 - accuracy: 0.6684 - val_loss: 1.0632 - val_accuracy: 0.5833\n",
            "Epoch 8/400\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.7873 - accuracy: 0.6962 - val_loss: 0.8748 - val_accuracy: 0.6389\n",
            "Epoch 9/400\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.7024 - accuracy: 0.7387 - val_loss: 0.7761 - val_accuracy: 0.6667\n",
            "Epoch 10/400\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.7350 - accuracy: 0.6901 - val_loss: 0.8244 - val_accuracy: 0.6389\n",
            "Epoch 11/400\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.7125 - accuracy: 0.7231 - val_loss: 0.8601 - val_accuracy: 0.6389\n",
            "Epoch 12/400\n",
            "72/72 [==============================] - 2s 23ms/step - loss: 0.6509 - accuracy: 0.7396 - val_loss: 0.8107 - val_accuracy: 0.6389\n",
            "Epoch 13/400\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.6418 - accuracy: 0.7378 - val_loss: 0.8194 - val_accuracy: 0.6389\n",
            "Epoch 14/400\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.6364 - accuracy: 0.7370 - val_loss: 0.5777 - val_accuracy: 0.7500\n",
            "Epoch 15/400\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.5873 - accuracy: 0.7656 - val_loss: 0.6043 - val_accuracy: 0.6944\n",
            "Epoch 16/400\n",
            "72/72 [==============================] - 1s 16ms/step - loss: 0.5894 - accuracy: 0.7561 - val_loss: 0.6440 - val_accuracy: 0.6944\n",
            "Epoch 17/400\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.5698 - accuracy: 0.7804 - val_loss: 0.7487 - val_accuracy: 0.6944\n",
            "Epoch 18/400\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.5500 - accuracy: 0.7717 - val_loss: 0.7637 - val_accuracy: 0.6667\n",
            "Epoch 19/400\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.5445 - accuracy: 0.7812 - val_loss: 0.5739 - val_accuracy: 0.6944\n",
            "Epoch 20/400\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.5013 - accuracy: 0.7986 - val_loss: 0.6484 - val_accuracy: 0.7500\n",
            "Epoch 21/400\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.4974 - accuracy: 0.8064 - val_loss: 0.7392 - val_accuracy: 0.6667\n",
            "Epoch 22/400\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.4698 - accuracy: 0.7977 - val_loss: 0.7061 - val_accuracy: 0.7778\n",
            "Epoch 23/400\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.4671 - accuracy: 0.8003 - val_loss: 0.7334 - val_accuracy: 0.6944\n",
            "Epoch 24/400\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.4306 - accuracy: 0.8264 - val_loss: 0.5133 - val_accuracy: 0.7222\n",
            "Epoch 25/400\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.4302 - accuracy: 0.8212 - val_loss: 0.6827 - val_accuracy: 0.7222\n",
            "Epoch 26/400\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.4612 - accuracy: 0.8099 - val_loss: 0.8095 - val_accuracy: 0.6944\n",
            "Epoch 27/400\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.4355 - accuracy: 0.8307 - val_loss: 0.6057 - val_accuracy: 0.8056\n",
            "Epoch 28/400\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.3891 - accuracy: 0.8325 - val_loss: 0.6264 - val_accuracy: 0.7222\n",
            "Epoch 29/400\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.3728 - accuracy: 0.8481 - val_loss: 0.5862 - val_accuracy: 0.7222\n",
            "Epoch 30/400\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.3950 - accuracy: 0.8472 - val_loss: 0.7302 - val_accuracy: 0.7500\n",
            "Epoch 31/400\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.3720 - accuracy: 0.8533 - val_loss: 0.5679 - val_accuracy: 0.7778\n",
            "Epoch 32/400\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.3399 - accuracy: 0.8672 - val_loss: 0.6816 - val_accuracy: 0.7778\n",
            "Epoch 33/400\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.3770 - accuracy: 0.8498 - val_loss: 0.6576 - val_accuracy: 0.7500\n",
            "Epoch 34/400\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.3396 - accuracy: 0.8698 - val_loss: 0.3832 - val_accuracy: 0.8333\n",
            "Epoch 35/400\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.3164 - accuracy: 0.8698 - val_loss: 0.5729 - val_accuracy: 0.7778\n",
            "Epoch 36/400\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.3309 - accuracy: 0.8741 - val_loss: 0.5317 - val_accuracy: 0.7778\n",
            "Epoch 37/400\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.2999 - accuracy: 0.8845 - val_loss: 0.4330 - val_accuracy: 0.8333\n",
            "Epoch 38/400\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.2921 - accuracy: 0.8698 - val_loss: 0.7465 - val_accuracy: 0.7500\n",
            "Epoch 39/400\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.3109 - accuracy: 0.8733 - val_loss: 0.4855 - val_accuracy: 0.7778\n",
            "Epoch 40/400\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.2967 - accuracy: 0.8845 - val_loss: 0.8160 - val_accuracy: 0.7222\n",
            "Epoch 41/400\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.2734 - accuracy: 0.8941 - val_loss: 0.5838 - val_accuracy: 0.7222\n",
            "Epoch 42/400\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.2725 - accuracy: 0.8976 - val_loss: 0.4129 - val_accuracy: 0.8056\n",
            "Epoch 43/400\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.2611 - accuracy: 0.8967 - val_loss: 0.4988 - val_accuracy: 0.8056\n",
            "Epoch 44/400\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.2707 - accuracy: 0.8993 - val_loss: 0.4275 - val_accuracy: 0.7500\n",
            "Epoch 45/400\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.2737 - accuracy: 0.8976 - val_loss: 0.5312 - val_accuracy: 0.8056\n",
            "Epoch 46/400\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.2428 - accuracy: 0.9080 - val_loss: 0.6876 - val_accuracy: 0.6667\n",
            "Epoch 47/400\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.2576 - accuracy: 0.9036 - val_loss: 0.6762 - val_accuracy: 0.7500\n",
            "Epoch 48/400\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.2454 - accuracy: 0.9071 - val_loss: 0.4593 - val_accuracy: 0.7778\n",
            "Epoch 49/400\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.2440 - accuracy: 0.9089 - val_loss: 0.4880 - val_accuracy: 0.7500\n",
            "Epoch 50/400\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.2186 - accuracy: 0.9210 - val_loss: 0.3720 - val_accuracy: 0.8611\n",
            "Epoch 51/400\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.2188 - accuracy: 0.9141 - val_loss: 0.4801 - val_accuracy: 0.7778\n",
            "Epoch 52/400\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.1972 - accuracy: 0.9314 - val_loss: 0.4111 - val_accuracy: 0.8333\n",
            "Epoch 53/400\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.2020 - accuracy: 0.9219 - val_loss: 0.3292 - val_accuracy: 0.8889\n",
            "Epoch 54/400\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.2206 - accuracy: 0.9149 - val_loss: 0.8122 - val_accuracy: 0.7222\n",
            "Epoch 55/400\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.2033 - accuracy: 0.9175 - val_loss: 0.5065 - val_accuracy: 0.7778\n",
            "Epoch 56/400\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.2038 - accuracy: 0.9253 - val_loss: 0.6436 - val_accuracy: 0.7222\n",
            "Epoch 57/400\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.2039 - accuracy: 0.9253 - val_loss: 0.3703 - val_accuracy: 0.8333\n",
            "Epoch 58/400\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.1795 - accuracy: 0.9340 - val_loss: 0.3845 - val_accuracy: 0.8333\n",
            "Epoch 59/400\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.1911 - accuracy: 0.9280 - val_loss: 0.3597 - val_accuracy: 0.8611\n",
            "Epoch 60/400\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.1787 - accuracy: 0.9323 - val_loss: 0.5893 - val_accuracy: 0.7500\n",
            "Epoch 61/400\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.1736 - accuracy: 0.9462 - val_loss: 0.4144 - val_accuracy: 0.8056\n",
            "Epoch 62/400\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.1783 - accuracy: 0.9418 - val_loss: 0.3761 - val_accuracy: 0.8333\n",
            "Epoch 63/400\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.1763 - accuracy: 0.9340 - val_loss: 0.4586 - val_accuracy: 0.7500\n",
            "Epoch 64/400\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.1529 - accuracy: 0.9488 - val_loss: 0.3551 - val_accuracy: 0.8333\n",
            "Epoch 65/400\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.1502 - accuracy: 0.9392 - val_loss: 0.4086 - val_accuracy: 0.8056\n",
            "Epoch 66/400\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.1418 - accuracy: 0.9436 - val_loss: 0.4845 - val_accuracy: 0.7778\n",
            "Epoch 67/400\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.1712 - accuracy: 0.9323 - val_loss: 0.6081 - val_accuracy: 0.7500\n",
            "Epoch 68/400\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.1733 - accuracy: 0.9384 - val_loss: 0.7847 - val_accuracy: 0.7778\n",
            "Epoch 69/400\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.1509 - accuracy: 0.9505 - val_loss: 0.4835 - val_accuracy: 0.7222\n",
            "Epoch 70/400\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.1788 - accuracy: 0.9349 - val_loss: 0.5804 - val_accuracy: 0.8056\n",
            "Epoch 71/400\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.1451 - accuracy: 0.9436 - val_loss: 0.3592 - val_accuracy: 0.8056\n",
            "Epoch 72/400\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.1528 - accuracy: 0.9436 - val_loss: 0.5724 - val_accuracy: 0.7500\n",
            "Epoch 73/400\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.1451 - accuracy: 0.9470 - val_loss: 0.5802 - val_accuracy: 0.7500\n",
            "Epoch 74/400\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.1493 - accuracy: 0.9462 - val_loss: 0.4528 - val_accuracy: 0.7500\n",
            "Epoch 75/400\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.1317 - accuracy: 0.9566 - val_loss: 0.5099 - val_accuracy: 0.7500\n",
            "Epoch 76/400\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.1200 - accuracy: 0.9575 - val_loss: 0.6235 - val_accuracy: 0.7222\n",
            "Epoch 77/400\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.1577 - accuracy: 0.9410 - val_loss: 0.4297 - val_accuracy: 0.8056\n",
            "Epoch 78/400\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.1361 - accuracy: 0.9497 - val_loss: 0.4498 - val_accuracy: 0.8056\n",
            "Epoch 79/400\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.1138 - accuracy: 0.9644 - val_loss: 0.3018 - val_accuracy: 0.8611\n",
            "Epoch 80/400\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.1268 - accuracy: 0.9523 - val_loss: 0.4709 - val_accuracy: 0.7500\n",
            "Epoch 81/400\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.1300 - accuracy: 0.9575 - val_loss: 0.5335 - val_accuracy: 0.7500\n",
            "Epoch 82/400\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.1208 - accuracy: 0.9566 - val_loss: 0.5297 - val_accuracy: 0.7500\n",
            "Epoch 83/400\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.1018 - accuracy: 0.9679 - val_loss: 0.4698 - val_accuracy: 0.7500\n",
            "Epoch 84/400\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.1090 - accuracy: 0.9635 - val_loss: 0.7220 - val_accuracy: 0.7778\n",
            "Epoch 85/400\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.1139 - accuracy: 0.9540 - val_loss: 0.3344 - val_accuracy: 0.8611\n",
            "Epoch 86/400\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.1241 - accuracy: 0.9505 - val_loss: 0.5227 - val_accuracy: 0.7222\n",
            "Epoch 87/400\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.1240 - accuracy: 0.9549 - val_loss: 0.3278 - val_accuracy: 0.8611\n",
            "Epoch 88/400\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.1012 - accuracy: 0.9661 - val_loss: 0.5305 - val_accuracy: 0.7500\n",
            "Epoch 89/400\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.1033 - accuracy: 0.9635 - val_loss: 0.3536 - val_accuracy: 0.8056\n",
            "Epoch 90/400\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0968 - accuracy: 0.9635 - val_loss: 0.2679 - val_accuracy: 0.8333\n",
            "Epoch 91/400\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0935 - accuracy: 0.9705 - val_loss: 0.2800 - val_accuracy: 0.8611\n",
            "Epoch 92/400\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.1017 - accuracy: 0.9661 - val_loss: 0.3167 - val_accuracy: 0.8611\n",
            "Epoch 93/400\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.1190 - accuracy: 0.9583 - val_loss: 0.6916 - val_accuracy: 0.6944\n",
            "Epoch 94/400\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0952 - accuracy: 0.9661 - val_loss: 0.5171 - val_accuracy: 0.7500\n",
            "Epoch 95/400\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.1014 - accuracy: 0.9705 - val_loss: 0.4852 - val_accuracy: 0.7222\n",
            "Epoch 96/400\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0977 - accuracy: 0.9705 - val_loss: 0.6731 - val_accuracy: 0.7222\n",
            "Epoch 97/400\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.0803 - accuracy: 0.9748 - val_loss: 0.3245 - val_accuracy: 0.8611\n",
            "Epoch 98/400\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0980 - accuracy: 0.9635 - val_loss: 0.5749 - val_accuracy: 0.7778\n",
            "Epoch 99/400\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0796 - accuracy: 0.9748 - val_loss: 0.6134 - val_accuracy: 0.7778\n",
            "Epoch 100/400\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.1001 - accuracy: 0.9627 - val_loss: 0.4626 - val_accuracy: 0.7500\n",
            "Epoch 101/400\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.0748 - accuracy: 0.9722 - val_loss: 0.4608 - val_accuracy: 0.7778\n",
            "Epoch 102/400\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0692 - accuracy: 0.9748 - val_loss: 0.4633 - val_accuracy: 0.7778\n",
            "Epoch 103/400\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.0845 - accuracy: 0.9714 - val_loss: 0.6479 - val_accuracy: 0.7222\n",
            "Epoch 104/400\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.0778 - accuracy: 0.9748 - val_loss: 0.7109 - val_accuracy: 0.7222\n",
            "Epoch 105/400\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.0956 - accuracy: 0.9653 - val_loss: 0.6279 - val_accuracy: 0.7500\n",
            "Epoch 106/400\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.0673 - accuracy: 0.9774 - val_loss: 0.4461 - val_accuracy: 0.7778\n",
            "Epoch 107/400\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0629 - accuracy: 0.9783 - val_loss: 0.4973 - val_accuracy: 0.7778\n",
            "Epoch 108/400\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0754 - accuracy: 0.9774 - val_loss: 0.5577 - val_accuracy: 0.7500\n",
            "Epoch 109/400\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.0754 - accuracy: 0.9705 - val_loss: 0.4139 - val_accuracy: 0.8056\n",
            "Epoch 110/400\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.0608 - accuracy: 0.9800 - val_loss: 0.5208 - val_accuracy: 0.7500\n",
            "Epoch 111/400\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.0733 - accuracy: 0.9748 - val_loss: 0.7801 - val_accuracy: 0.7500\n",
            "Epoch 112/400\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0722 - accuracy: 0.9774 - val_loss: 0.6131 - val_accuracy: 0.7778\n",
            "Epoch 113/400\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0775 - accuracy: 0.9766 - val_loss: 0.5413 - val_accuracy: 0.7500\n",
            "Epoch 114/400\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0697 - accuracy: 0.9774 - val_loss: 0.4177 - val_accuracy: 0.8056\n",
            "Epoch 115/400\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0784 - accuracy: 0.9714 - val_loss: 0.4200 - val_accuracy: 0.8056\n",
            "Epoch 116/400\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0742 - accuracy: 0.9783 - val_loss: 0.3489 - val_accuracy: 0.8611\n",
            "Epoch 117/400\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0599 - accuracy: 0.9835 - val_loss: 0.3944 - val_accuracy: 0.7778\n",
            "Epoch 118/400\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.0751 - accuracy: 0.9714 - val_loss: 0.5266 - val_accuracy: 0.7500\n",
            "Epoch 119/400\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0735 - accuracy: 0.9731 - val_loss: 0.4449 - val_accuracy: 0.7778\n",
            "Epoch 120/400\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.0494 - accuracy: 0.9887 - val_loss: 0.3113 - val_accuracy: 0.8611\n",
            "Epoch 121/400\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.0544 - accuracy: 0.9844 - val_loss: 0.3827 - val_accuracy: 0.8333\n",
            "Epoch 122/400\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.0680 - accuracy: 0.9783 - val_loss: 0.4626 - val_accuracy: 0.7500\n",
            "Epoch 123/400\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0659 - accuracy: 0.9766 - val_loss: 0.5725 - val_accuracy: 0.7500\n",
            "Epoch 124/400\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0756 - accuracy: 0.9740 - val_loss: 0.4066 - val_accuracy: 0.7778\n",
            "Epoch 125/400\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0551 - accuracy: 0.9818 - val_loss: 0.5648 - val_accuracy: 0.8056\n",
            "Epoch 126/400\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0614 - accuracy: 0.9835 - val_loss: 0.9594 - val_accuracy: 0.7222\n",
            "Epoch 127/400\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.0595 - accuracy: 0.9835 - val_loss: 0.6023 - val_accuracy: 0.7500\n",
            "Epoch 128/400\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.0568 - accuracy: 0.9835 - val_loss: 0.4956 - val_accuracy: 0.7778\n",
            "Epoch 129/400\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0469 - accuracy: 0.9878 - val_loss: 0.4124 - val_accuracy: 0.8056\n",
            "Epoch 130/400\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0662 - accuracy: 0.9766 - val_loss: 0.6368 - val_accuracy: 0.7500\n",
            "Epoch 131/400\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0729 - accuracy: 0.9696 - val_loss: 0.5896 - val_accuracy: 0.7500\n",
            "Epoch 132/400\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0441 - accuracy: 0.9887 - val_loss: 0.5577 - val_accuracy: 0.7222\n",
            "Epoch 133/400\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0432 - accuracy: 0.9887 - val_loss: 0.5275 - val_accuracy: 0.7222\n",
            "Epoch 134/400\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0327 - accuracy: 0.9913 - val_loss: 0.4596 - val_accuracy: 0.8056\n",
            "Epoch 135/400\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0444 - accuracy: 0.9870 - val_loss: 0.4245 - val_accuracy: 0.8056\n",
            "Epoch 136/400\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0418 - accuracy: 0.9878 - val_loss: 0.4922 - val_accuracy: 0.7500\n",
            "Epoch 137/400\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0433 - accuracy: 0.9896 - val_loss: 0.5934 - val_accuracy: 0.8333\n",
            "Epoch 138/400\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0405 - accuracy: 0.9878 - val_loss: 0.5916 - val_accuracy: 0.7500\n",
            "Epoch 139/400\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.0401 - accuracy: 0.9861 - val_loss: 0.3515 - val_accuracy: 0.8056\n",
            "Epoch 140/400\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0477 - accuracy: 0.9861 - val_loss: 0.4388 - val_accuracy: 0.8333\n",
            "Epoch 141/400\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0408 - accuracy: 0.9861 - val_loss: 0.3265 - val_accuracy: 0.8333\n",
            "Epoch 142/400\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0570 - accuracy: 0.9809 - val_loss: 0.4386 - val_accuracy: 0.8333\n",
            "Epoch 143/400\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0519 - accuracy: 0.9852 - val_loss: 0.4760 - val_accuracy: 0.8056\n",
            "Epoch 144/400\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0515 - accuracy: 0.9818 - val_loss: 0.5775 - val_accuracy: 0.7778\n",
            "Epoch 145/400\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0400 - accuracy: 0.9922 - val_loss: 0.5905 - val_accuracy: 0.7222\n",
            "Epoch 146/400\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0531 - accuracy: 0.9826 - val_loss: 0.8065 - val_accuracy: 0.7500\n",
            "Epoch 147/400\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0316 - accuracy: 0.9939 - val_loss: 0.4546 - val_accuracy: 0.7778\n",
            "Epoch 148/400\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0393 - accuracy: 0.9905 - val_loss: 0.4348 - val_accuracy: 0.7500\n",
            "Epoch 149/400\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0455 - accuracy: 0.9826 - val_loss: 0.4537 - val_accuracy: 0.8056\n",
            "Epoch 150/400\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0381 - accuracy: 0.9905 - val_loss: 0.3797 - val_accuracy: 0.7778\n",
            "Epoch 151/400\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.0403 - accuracy: 0.9870 - val_loss: 0.2994 - val_accuracy: 0.8889\n",
            "Epoch 152/400\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0566 - accuracy: 0.9792 - val_loss: 0.5749 - val_accuracy: 0.8056\n",
            "Epoch 153/400\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0496 - accuracy: 0.9809 - val_loss: 0.5496 - val_accuracy: 0.7500\n",
            "Epoch 154/400\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0464 - accuracy: 0.9852 - val_loss: 0.6934 - val_accuracy: 0.7500\n",
            "Epoch 155/400\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0393 - accuracy: 0.9887 - val_loss: 0.5759 - val_accuracy: 0.7500\n",
            "Epoch 156/400\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0369 - accuracy: 0.9887 - val_loss: 0.6466 - val_accuracy: 0.7778\n",
            "Epoch 157/400\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0445 - accuracy: 0.9861 - val_loss: 0.4901 - val_accuracy: 0.7778\n",
            "Epoch 158/400\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0254 - accuracy: 0.9922 - val_loss: 0.4946 - val_accuracy: 0.7778\n",
            "Epoch 159/400\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0243 - accuracy: 0.9957 - val_loss: 0.4387 - val_accuracy: 0.8056\n",
            "Epoch 160/400\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0299 - accuracy: 0.9913 - val_loss: 0.5067 - val_accuracy: 0.7500\n",
            "Epoch 161/400\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0382 - accuracy: 0.9887 - val_loss: 0.4136 - val_accuracy: 0.8333\n",
            "Epoch 162/400\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0324 - accuracy: 0.9922 - val_loss: 0.4968 - val_accuracy: 0.7778\n",
            "Epoch 163/400\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0394 - accuracy: 0.9826 - val_loss: 0.4354 - val_accuracy: 0.7500\n",
            "Epoch 164/400\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0496 - accuracy: 0.9870 - val_loss: 0.6442 - val_accuracy: 0.6944\n",
            "Epoch 165/400\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0442 - accuracy: 0.9844 - val_loss: 0.4076 - val_accuracy: 0.8611\n",
            "Epoch 166/400\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0293 - accuracy: 0.9957 - val_loss: 0.4485 - val_accuracy: 0.7778\n",
            "Epoch 167/400\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0206 - accuracy: 0.9983 - val_loss: 0.3879 - val_accuracy: 0.8056\n",
            "Epoch 168/400\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0312 - accuracy: 0.9896 - val_loss: 0.6423 - val_accuracy: 0.7778\n",
            "Epoch 169/400\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0320 - accuracy: 0.9939 - val_loss: 0.3412 - val_accuracy: 0.8333\n",
            "Epoch 170/400\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0427 - accuracy: 0.9826 - val_loss: 0.4073 - val_accuracy: 0.8333\n",
            "Epoch 171/400\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0434 - accuracy: 0.9835 - val_loss: 0.6762 - val_accuracy: 0.7222\n",
            "Epoch 172/400\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0401 - accuracy: 0.9896 - val_loss: 0.4663 - val_accuracy: 0.8056\n",
            "Epoch 173/400\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0299 - accuracy: 0.9913 - val_loss: 0.6013 - val_accuracy: 0.7222\n",
            "Epoch 174/400\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0314 - accuracy: 0.9922 - val_loss: 0.4174 - val_accuracy: 0.7778\n",
            "Epoch 175/400\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0389 - accuracy: 0.9878 - val_loss: 0.5830 - val_accuracy: 0.7500\n",
            "Epoch 176/400\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0371 - accuracy: 0.9896 - val_loss: 0.4169 - val_accuracy: 0.8056\n",
            "Epoch 177/400\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0354 - accuracy: 0.9905 - val_loss: 0.2685 - val_accuracy: 0.8611\n",
            "Epoch 178/400\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0307 - accuracy: 0.9905 - val_loss: 0.5240 - val_accuracy: 0.7222\n",
            "Epoch 179/400\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0381 - accuracy: 0.9878 - val_loss: 0.4302 - val_accuracy: 0.7500\n",
            "Epoch 180/400\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0361 - accuracy: 0.9896 - val_loss: 0.3912 - val_accuracy: 0.8611\n",
            "Epoch 181/400\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0254 - accuracy: 0.9948 - val_loss: 0.2658 - val_accuracy: 0.8611\n",
            "Epoch 182/400\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.0472 - accuracy: 0.9870 - val_loss: 0.7994 - val_accuracy: 0.7500\n",
            "Epoch 183/400\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0320 - accuracy: 0.9913 - val_loss: 0.3994 - val_accuracy: 0.7778\n",
            "Epoch 184/400\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0448 - accuracy: 0.9870 - val_loss: 0.6737 - val_accuracy: 0.7500\n",
            "Epoch 185/400\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.0423 - accuracy: 0.9878 - val_loss: 0.5081 - val_accuracy: 0.8056\n",
            "Epoch 186/400\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0634 - accuracy: 0.9766 - val_loss: 0.3915 - val_accuracy: 0.8333\n",
            "Epoch 187/400\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0295 - accuracy: 0.9939 - val_loss: 0.3960 - val_accuracy: 0.8333\n",
            "Epoch 188/400\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0314 - accuracy: 0.9922 - val_loss: 0.6835 - val_accuracy: 0.7778\n",
            "Epoch 189/400\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0321 - accuracy: 0.9922 - val_loss: 0.3669 - val_accuracy: 0.7778\n",
            "Epoch 190/400\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0321 - accuracy: 0.9905 - val_loss: 0.3751 - val_accuracy: 0.8333\n",
            "Epoch 191/400\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0238 - accuracy: 0.9896 - val_loss: 0.3315 - val_accuracy: 0.9167\n",
            "Epoch 192/400\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0338 - accuracy: 0.9844 - val_loss: 0.5376 - val_accuracy: 0.7222\n",
            "Epoch 193/400\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0359 - accuracy: 0.9878 - val_loss: 0.4217 - val_accuracy: 0.8333\n",
            "Epoch 194/400\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0200 - accuracy: 0.9965 - val_loss: 0.6005 - val_accuracy: 0.7500\n",
            "Epoch 195/400\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0171 - accuracy: 0.9983 - val_loss: 0.4034 - val_accuracy: 0.8333\n",
            "Epoch 196/400\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0148 - accuracy: 0.9974 - val_loss: 0.6326 - val_accuracy: 0.7222\n",
            "Epoch 197/400\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0248 - accuracy: 0.9896 - val_loss: 0.4690 - val_accuracy: 0.7778\n",
            "Epoch 198/400\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0292 - accuracy: 0.9922 - val_loss: 0.5714 - val_accuracy: 0.7500\n",
            "Epoch 199/400\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0237 - accuracy: 0.9922 - val_loss: 0.4673 - val_accuracy: 0.7500\n",
            "Epoch 200/400\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0219 - accuracy: 0.9948 - val_loss: 0.5054 - val_accuracy: 0.7778\n",
            "Epoch 201/400\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0258 - accuracy: 0.9931 - val_loss: 0.4476 - val_accuracy: 0.8056\n",
            "Epoch 202/400\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0217 - accuracy: 0.9948 - val_loss: 0.5844 - val_accuracy: 0.7500\n",
            "Epoch 203/400\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0339 - accuracy: 0.9896 - val_loss: 0.7663 - val_accuracy: 0.6944\n",
            "Epoch 204/400\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0220 - accuracy: 0.9948 - val_loss: 0.6355 - val_accuracy: 0.7500\n",
            "Epoch 205/400\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0251 - accuracy: 0.9931 - val_loss: 0.5101 - val_accuracy: 0.8056\n",
            "Epoch 206/400\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0245 - accuracy: 0.9939 - val_loss: 0.4820 - val_accuracy: 0.8056\n",
            "Epoch 207/400\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0187 - accuracy: 0.9974 - val_loss: 0.7578 - val_accuracy: 0.7500\n",
            "Epoch 208/400\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0212 - accuracy: 0.9939 - val_loss: 0.4226 - val_accuracy: 0.8056\n",
            "Epoch 209/400\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0204 - accuracy: 0.9939 - val_loss: 0.7044 - val_accuracy: 0.7778\n",
            "Epoch 210/400\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0208 - accuracy: 0.9957 - val_loss: 0.5650 - val_accuracy: 0.7778\n",
            "Epoch 211/400\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0310 - accuracy: 0.9896 - val_loss: 0.4711 - val_accuracy: 0.7778\n",
            "Epoch 212/400\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0269 - accuracy: 0.9905 - val_loss: 0.5477 - val_accuracy: 0.8056\n",
            "Epoch 213/400\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0188 - accuracy: 0.9939 - val_loss: 0.3774 - val_accuracy: 0.8056\n",
            "Epoch 214/400\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0331 - accuracy: 0.9913 - val_loss: 0.4253 - val_accuracy: 0.7778\n",
            "Epoch 215/400\n",
            "72/72 [==============================] - 1s 20ms/step - loss: 0.0190 - accuracy: 0.9957 - val_loss: 0.6111 - val_accuracy: 0.7500\n",
            "Epoch 216/400\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0248 - accuracy: 0.9931 - val_loss: 1.2948 - val_accuracy: 0.6944\n",
            "Epoch 217/400\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0318 - accuracy: 0.9905 - val_loss: 0.5754 - val_accuracy: 0.7500\n",
            "Epoch 218/400\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0420 - accuracy: 0.9852 - val_loss: 0.6295 - val_accuracy: 0.7778\n",
            "Epoch 219/400\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0403 - accuracy: 0.9870 - val_loss: 0.4370 - val_accuracy: 0.8056\n",
            "Epoch 220/400\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0328 - accuracy: 0.9870 - val_loss: 0.5403 - val_accuracy: 0.7500\n",
            "Epoch 221/400\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0261 - accuracy: 0.9948 - val_loss: 0.5861 - val_accuracy: 0.7500\n",
            "Epoch 222/400\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0166 - accuracy: 0.9965 - val_loss: 0.5738 - val_accuracy: 0.7500\n",
            "Epoch 223/400\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0292 - accuracy: 0.9905 - val_loss: 0.4602 - val_accuracy: 0.7778\n",
            "Epoch 224/400\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0156 - accuracy: 0.9991 - val_loss: 0.4596 - val_accuracy: 0.7778\n",
            "Epoch 225/400\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0171 - accuracy: 0.9948 - val_loss: 0.3475 - val_accuracy: 0.8611\n",
            "Epoch 226/400\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0214 - accuracy: 0.9957 - val_loss: 0.4071 - val_accuracy: 0.8056\n",
            "Epoch 227/400\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0283 - accuracy: 0.9931 - val_loss: 0.5617 - val_accuracy: 0.7500\n",
            "Epoch 228/400\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0291 - accuracy: 0.9896 - val_loss: 0.6106 - val_accuracy: 0.7222\n",
            "Epoch 229/400\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0397 - accuracy: 0.9887 - val_loss: 0.6498 - val_accuracy: 0.7778\n",
            "Epoch 230/400\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0252 - accuracy: 0.9939 - val_loss: 0.5752 - val_accuracy: 0.7778\n",
            "Epoch 231/400\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0309 - accuracy: 0.9922 - val_loss: 0.5469 - val_accuracy: 0.7778\n",
            "Epoch 232/400\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.0196 - accuracy: 0.9939 - val_loss: 0.3902 - val_accuracy: 0.7500\n",
            "Epoch 233/400\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0230 - accuracy: 0.9913 - val_loss: 0.5100 - val_accuracy: 0.8333\n",
            "Epoch 234/400\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0201 - accuracy: 0.9939 - val_loss: 0.8343 - val_accuracy: 0.7500\n",
            "Epoch 235/400\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0319 - accuracy: 0.9913 - val_loss: 0.5907 - val_accuracy: 0.7500\n",
            "Epoch 236/400\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0199 - accuracy: 0.9939 - val_loss: 0.6032 - val_accuracy: 0.7500\n",
            "Epoch 237/400\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0153 - accuracy: 0.9974 - val_loss: 0.4067 - val_accuracy: 0.8056\n",
            "Epoch 238/400\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0215 - accuracy: 0.9939 - val_loss: 0.6720 - val_accuracy: 0.7500\n",
            "Epoch 239/400\n",
            "72/72 [==============================] - 1s 20ms/step - loss: 0.0156 - accuracy: 0.9965 - val_loss: 0.8112 - val_accuracy: 0.7778\n",
            "Epoch 240/400\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0167 - accuracy: 0.9939 - val_loss: 0.7592 - val_accuracy: 0.7778\n",
            "Epoch 241/400\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0143 - accuracy: 0.9983 - val_loss: 0.3938 - val_accuracy: 0.8333\n",
            "Epoch 242/400\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0110 - accuracy: 0.9965 - val_loss: 0.4925 - val_accuracy: 0.7500\n",
            "Epoch 243/400\n",
            "72/72 [==============================] - 2s 21ms/step - loss: 0.0248 - accuracy: 0.9887 - val_loss: 0.6232 - val_accuracy: 0.7778\n",
            "Epoch 244/400\n",
            "72/72 [==============================] - 2s 23ms/step - loss: 0.0379 - accuracy: 0.9870 - val_loss: 0.9713 - val_accuracy: 0.7778\n",
            "Epoch 245/400\n",
            "72/72 [==============================] - 2s 23ms/step - loss: 0.0266 - accuracy: 0.9931 - val_loss: 0.4267 - val_accuracy: 0.8333\n",
            "Epoch 246/400\n",
            "72/72 [==============================] - 2s 24ms/step - loss: 0.0155 - accuracy: 0.9948 - val_loss: 0.5942 - val_accuracy: 0.7500\n",
            "Epoch 247/400\n",
            "72/72 [==============================] - 1s 20ms/step - loss: 0.0145 - accuracy: 0.9965 - val_loss: 0.5188 - val_accuracy: 0.7500\n",
            "Epoch 248/400\n",
            "72/72 [==============================] - 1s 20ms/step - loss: 0.0380 - accuracy: 0.9844 - val_loss: 0.7067 - val_accuracy: 0.7500\n",
            "Epoch 249/400\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0259 - accuracy: 0.9939 - val_loss: 0.5015 - val_accuracy: 0.7778\n",
            "Epoch 250/400\n",
            "72/72 [==============================] - 1s 20ms/step - loss: 0.0192 - accuracy: 0.9939 - val_loss: 0.4990 - val_accuracy: 0.8056\n",
            "Epoch 251/400\n",
            "72/72 [==============================] - 1s 20ms/step - loss: 0.0177 - accuracy: 0.9957 - val_loss: 0.5520 - val_accuracy: 0.7778\n",
            "Epoch 252/400\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0266 - accuracy: 0.9913 - val_loss: 0.5727 - val_accuracy: 0.7500\n",
            "Epoch 253/400\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0144 - accuracy: 0.9965 - val_loss: 0.5644 - val_accuracy: 0.8056\n",
            "Epoch 254/400\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0174 - accuracy: 0.9965 - val_loss: 0.3778 - val_accuracy: 0.8056\n",
            "Epoch 255/400\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0133 - accuracy: 0.9965 - val_loss: 0.4533 - val_accuracy: 0.8056\n",
            "Epoch 256/400\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0152 - accuracy: 0.9983 - val_loss: 0.4019 - val_accuracy: 0.8333\n",
            "Epoch 257/400\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0144 - accuracy: 0.9965 - val_loss: 0.4228 - val_accuracy: 0.8056\n",
            "Epoch 258/400\n",
            "72/72 [==============================] - 1s 20ms/step - loss: 0.0190 - accuracy: 0.9957 - val_loss: 0.4550 - val_accuracy: 0.8056\n",
            "Epoch 259/400\n",
            "72/72 [==============================] - 1s 20ms/step - loss: 0.0156 - accuracy: 0.9965 - val_loss: 0.4806 - val_accuracy: 0.8333\n",
            "Epoch 260/400\n",
            "72/72 [==============================] - 2s 21ms/step - loss: 0.0179 - accuracy: 0.9957 - val_loss: 0.3238 - val_accuracy: 0.8333\n",
            "Epoch 261/400\n",
            "72/72 [==============================] - 1s 20ms/step - loss: 0.0131 - accuracy: 0.9957 - val_loss: 0.3497 - val_accuracy: 0.8333\n",
            "Epoch 262/400\n",
            "72/72 [==============================] - 1s 21ms/step - loss: 0.0189 - accuracy: 0.9913 - val_loss: 0.6505 - val_accuracy: 0.7222\n",
            "Epoch 263/400\n",
            "72/72 [==============================] - 1s 21ms/step - loss: 0.0202 - accuracy: 0.9948 - val_loss: 0.6139 - val_accuracy: 0.7500\n",
            "Epoch 264/400\n",
            "72/72 [==============================] - 2s 21ms/step - loss: 0.0162 - accuracy: 0.9974 - val_loss: 0.5465 - val_accuracy: 0.8056\n",
            "Epoch 265/400\n",
            "72/72 [==============================] - 2s 21ms/step - loss: 0.0189 - accuracy: 0.9948 - val_loss: 0.4961 - val_accuracy: 0.8333\n",
            "Epoch 266/400\n",
            "72/72 [==============================] - 2s 22ms/step - loss: 0.0193 - accuracy: 0.9948 - val_loss: 0.7114 - val_accuracy: 0.7778\n",
            "Epoch 267/400\n",
            "72/72 [==============================] - 1s 20ms/step - loss: 0.0107 - accuracy: 0.9965 - val_loss: 0.5502 - val_accuracy: 0.7500\n",
            "Epoch 268/400\n",
            "72/72 [==============================] - 1s 21ms/step - loss: 0.0087 - accuracy: 0.9983 - val_loss: 0.3778 - val_accuracy: 0.8333\n",
            "Epoch 269/400\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0093 - accuracy: 0.9974 - val_loss: 0.8374 - val_accuracy: 0.7500\n",
            "Epoch 270/400\n",
            "72/72 [==============================] - 2s 21ms/step - loss: 0.0212 - accuracy: 0.9913 - val_loss: 0.5610 - val_accuracy: 0.7778\n",
            "Epoch 271/400\n",
            "72/72 [==============================] - 1s 20ms/step - loss: 0.0313 - accuracy: 0.9905 - val_loss: 0.7955 - val_accuracy: 0.6944\n",
            "Epoch 272/400\n",
            "72/72 [==============================] - 2s 21ms/step - loss: 0.0317 - accuracy: 0.9878 - val_loss: 1.0464 - val_accuracy: 0.6944\n",
            "Epoch 273/400\n",
            "72/72 [==============================] - 1s 20ms/step - loss: 0.0256 - accuracy: 0.9922 - val_loss: 0.5213 - val_accuracy: 0.7778\n",
            "Epoch 274/400\n",
            "72/72 [==============================] - 1s 20ms/step - loss: 0.0291 - accuracy: 0.9931 - val_loss: 1.5413 - val_accuracy: 0.6667\n",
            "Epoch 275/400\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0353 - accuracy: 0.9896 - val_loss: 0.4311 - val_accuracy: 0.8333\n",
            "Epoch 276/400\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0183 - accuracy: 0.9948 - val_loss: 0.6246 - val_accuracy: 0.7778\n",
            "Epoch 277/400\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0094 - accuracy: 0.9991 - val_loss: 0.5287 - val_accuracy: 0.8056\n",
            "Epoch 278/400\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0116 - accuracy: 0.9974 - val_loss: 0.5772 - val_accuracy: 0.8056\n",
            "Epoch 279/400\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0126 - accuracy: 0.9974 - val_loss: 0.4202 - val_accuracy: 0.8056\n",
            "Epoch 280/400\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0085 - accuracy: 0.9974 - val_loss: 0.4816 - val_accuracy: 0.7778\n",
            "Epoch 281/400\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0103 - accuracy: 0.9991 - val_loss: 0.5058 - val_accuracy: 0.8056\n",
            "Epoch 282/400\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0092 - accuracy: 0.9991 - val_loss: 0.5594 - val_accuracy: 0.7778\n",
            "Epoch 283/400\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0235 - accuracy: 0.9931 - val_loss: 0.6524 - val_accuracy: 0.7500\n",
            "Epoch 284/400\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0223 - accuracy: 0.9922 - val_loss: 0.7488 - val_accuracy: 0.7222\n",
            "Epoch 285/400\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0136 - accuracy: 0.9948 - val_loss: 0.6146 - val_accuracy: 0.7778\n",
            "Epoch 286/400\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0296 - accuracy: 0.9887 - val_loss: 0.8689 - val_accuracy: 0.7500\n",
            "Epoch 287/400\n",
            "72/72 [==============================] - 1s 20ms/step - loss: 0.0150 - accuracy: 0.9974 - val_loss: 1.2399 - val_accuracy: 0.7222\n",
            "Epoch 288/400\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0140 - accuracy: 0.9974 - val_loss: 0.4636 - val_accuracy: 0.7778\n",
            "Epoch 289/400\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0110 - accuracy: 0.9983 - val_loss: 0.5912 - val_accuracy: 0.7778\n",
            "Epoch 290/400\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0207 - accuracy: 0.9948 - val_loss: 0.5988 - val_accuracy: 0.8333\n",
            "Epoch 291/400\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0152 - accuracy: 0.9965 - val_loss: 0.5218 - val_accuracy: 0.8056\n",
            "Epoch 292/400\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0143 - accuracy: 0.9974 - val_loss: 0.6090 - val_accuracy: 0.7778\n",
            "Epoch 293/400\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0078 - accuracy: 0.9991 - val_loss: 0.5545 - val_accuracy: 0.8056\n",
            "Epoch 294/400\n",
            "72/72 [==============================] - 1s 20ms/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 0.6804 - val_accuracy: 0.7500\n",
            "Epoch 295/400\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0093 - accuracy: 0.9983 - val_loss: 0.6043 - val_accuracy: 0.7778\n",
            "Epoch 296/400\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0194 - accuracy: 0.9931 - val_loss: 0.4060 - val_accuracy: 0.8889\n",
            "Epoch 297/400\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0118 - accuracy: 0.9965 - val_loss: 0.4692 - val_accuracy: 0.8056\n",
            "Epoch 298/400\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0099 - accuracy: 0.9983 - val_loss: 0.7789 - val_accuracy: 0.7500\n",
            "Epoch 299/400\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0146 - accuracy: 0.9957 - val_loss: 0.5872 - val_accuracy: 0.7500\n",
            "Epoch 300/400\n",
            "72/72 [==============================] - 1s 20ms/step - loss: 0.0095 - accuracy: 0.9991 - val_loss: 0.8530 - val_accuracy: 0.7222\n",
            "Epoch 301/400\n",
            "72/72 [==============================] - 1s 20ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.6448 - val_accuracy: 0.7778\n",
            "Epoch 302/400\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0103 - accuracy: 0.9983 - val_loss: 0.6941 - val_accuracy: 0.6944\n",
            "Epoch 303/400\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0177 - accuracy: 0.9957 - val_loss: 0.4852 - val_accuracy: 0.7500\n",
            "Epoch 304/400\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0354 - accuracy: 0.9887 - val_loss: 0.4985 - val_accuracy: 0.8056\n",
            "Epoch 305/400\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0147 - accuracy: 0.9983 - val_loss: 0.7123 - val_accuracy: 0.8056\n",
            "Epoch 306/400\n",
            "72/72 [==============================] - 1s 20ms/step - loss: 0.0192 - accuracy: 0.9939 - val_loss: 0.6040 - val_accuracy: 0.7778\n",
            "Epoch 307/400\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0183 - accuracy: 0.9948 - val_loss: 0.5301 - val_accuracy: 0.7778\n",
            "Epoch 308/400\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0108 - accuracy: 0.9974 - val_loss: 0.3925 - val_accuracy: 0.8056\n",
            "Epoch 309/400\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0163 - accuracy: 0.9948 - val_loss: 0.6920 - val_accuracy: 0.7778\n",
            "Epoch 310/400\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0304 - accuracy: 0.9861 - val_loss: 0.5368 - val_accuracy: 0.7778\n",
            "Epoch 311/400\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0215 - accuracy: 0.9948 - val_loss: 0.3761 - val_accuracy: 0.8056\n",
            "Epoch 312/400\n",
            "72/72 [==============================] - 1s 20ms/step - loss: 0.0248 - accuracy: 0.9922 - val_loss: 0.6744 - val_accuracy: 0.8056\n",
            "Epoch 313/400\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0151 - accuracy: 0.9965 - val_loss: 0.4138 - val_accuracy: 0.8056\n",
            "Epoch 314/400\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0177 - accuracy: 0.9957 - val_loss: 0.8579 - val_accuracy: 0.7222\n",
            "Epoch 315/400\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0177 - accuracy: 0.9948 - val_loss: 0.5028 - val_accuracy: 0.8056\n",
            "Epoch 316/400\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0153 - accuracy: 0.9974 - val_loss: 0.6378 - val_accuracy: 0.7778\n",
            "Epoch 317/400\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0246 - accuracy: 0.9922 - val_loss: 0.6653 - val_accuracy: 0.7778\n",
            "Epoch 318/400\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0170 - accuracy: 0.9974 - val_loss: 0.5244 - val_accuracy: 0.8056\n",
            "Epoch 319/400\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0133 - accuracy: 0.9965 - val_loss: 0.6157 - val_accuracy: 0.7778\n",
            "Epoch 320/400\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0136 - accuracy: 0.9965 - val_loss: 0.5415 - val_accuracy: 0.8056\n",
            "Epoch 321/400\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0108 - accuracy: 0.9974 - val_loss: 0.4306 - val_accuracy: 0.7778\n",
            "Epoch 322/400\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0090 - accuracy: 0.9983 - val_loss: 0.6031 - val_accuracy: 0.8056\n",
            "Epoch 323/400\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0141 - accuracy: 0.9931 - val_loss: 0.3632 - val_accuracy: 0.8889\n",
            "Epoch 324/400\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0201 - accuracy: 0.9922 - val_loss: 0.5100 - val_accuracy: 0.7500\n",
            "Epoch 325/400\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0106 - accuracy: 0.9983 - val_loss: 0.5746 - val_accuracy: 0.7778\n",
            "Epoch 326/400\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0066 - accuracy: 0.9983 - val_loss: 1.0517 - val_accuracy: 0.7222\n",
            "Epoch 327/400\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0110 - accuracy: 0.9965 - val_loss: 0.5688 - val_accuracy: 0.7778\n",
            "Epoch 328/400\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0086 - accuracy: 0.9991 - val_loss: 0.3795 - val_accuracy: 0.8611\n",
            "Epoch 329/400\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0191 - accuracy: 0.9939 - val_loss: 0.8972 - val_accuracy: 0.7500\n",
            "Epoch 330/400\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0295 - accuracy: 0.9905 - val_loss: 0.6343 - val_accuracy: 0.6944\n",
            "Epoch 331/400\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0195 - accuracy: 0.9922 - val_loss: 0.7712 - val_accuracy: 0.7500\n",
            "Epoch 332/400\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0151 - accuracy: 0.9965 - val_loss: 0.4821 - val_accuracy: 0.8333\n",
            "Epoch 333/400\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0169 - accuracy: 0.9939 - val_loss: 0.4839 - val_accuracy: 0.7778\n",
            "Epoch 334/400\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0148 - accuracy: 0.9931 - val_loss: 0.9418 - val_accuracy: 0.6667\n",
            "Epoch 335/400\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0119 - accuracy: 0.9965 - val_loss: 0.7966 - val_accuracy: 0.7222\n",
            "Epoch 336/400\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0092 - accuracy: 0.9983 - val_loss: 0.5477 - val_accuracy: 0.8056\n",
            "Epoch 337/400\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0077 - accuracy: 0.9974 - val_loss: 0.7059 - val_accuracy: 0.7500\n",
            "Epoch 338/400\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0098 - accuracy: 0.9974 - val_loss: 0.7266 - val_accuracy: 0.7500\n",
            "Epoch 339/400\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.5006 - val_accuracy: 0.8056\n",
            "Epoch 340/400\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0070 - accuracy: 0.9991 - val_loss: 0.6839 - val_accuracy: 0.7500\n",
            "Epoch 341/400\n",
            "72/72 [==============================] - 1s 20ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.6529 - val_accuracy: 0.7778\n",
            "Epoch 342/400\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0097 - accuracy: 0.9965 - val_loss: 0.7568 - val_accuracy: 0.7778\n",
            "Epoch 343/400\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0152 - accuracy: 0.9965 - val_loss: 0.6366 - val_accuracy: 0.8056\n",
            "Epoch 344/400\n",
            "72/72 [==============================] - 1s 20ms/step - loss: 0.0103 - accuracy: 0.9974 - val_loss: 0.6828 - val_accuracy: 0.7500\n",
            "Epoch 345/400\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0134 - accuracy: 0.9957 - val_loss: 0.9699 - val_accuracy: 0.7222\n",
            "Epoch 346/400\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0204 - accuracy: 0.9939 - val_loss: 0.5238 - val_accuracy: 0.8056\n",
            "Epoch 347/400\n",
            "72/72 [==============================] - 1s 20ms/step - loss: 0.0180 - accuracy: 0.9931 - val_loss: 0.5394 - val_accuracy: 0.7500\n",
            "Epoch 348/400\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0157 - accuracy: 0.9965 - val_loss: 0.6393 - val_accuracy: 0.7222\n",
            "Epoch 349/400\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0139 - accuracy: 0.9948 - val_loss: 0.7703 - val_accuracy: 0.7222\n",
            "Epoch 350/400\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0278 - accuracy: 0.9931 - val_loss: 0.4946 - val_accuracy: 0.7778\n",
            "Epoch 351/400\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0127 - accuracy: 0.9965 - val_loss: 0.6990 - val_accuracy: 0.6944\n",
            "Epoch 352/400\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0108 - accuracy: 0.9974 - val_loss: 0.7018 - val_accuracy: 0.6944\n",
            "Epoch 353/400\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0089 - accuracy: 0.9974 - val_loss: 0.8016 - val_accuracy: 0.7500\n",
            "Epoch 354/400\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0148 - accuracy: 0.9957 - val_loss: 1.1316 - val_accuracy: 0.6944\n",
            "Epoch 355/400\n",
            "72/72 [==============================] - 1s 20ms/step - loss: 0.0235 - accuracy: 0.9922 - val_loss: 0.6723 - val_accuracy: 0.7500\n",
            "Epoch 356/400\n",
            "72/72 [==============================] - 1s 20ms/step - loss: 0.0169 - accuracy: 0.9948 - val_loss: 0.4859 - val_accuracy: 0.8333\n",
            "Epoch 357/400\n",
            "72/72 [==============================] - 1s 20ms/step - loss: 0.0178 - accuracy: 0.9957 - val_loss: 0.5627 - val_accuracy: 0.7778\n",
            "Epoch 358/400\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0069 - accuracy: 0.9991 - val_loss: 0.5473 - val_accuracy: 0.7500\n",
            "Epoch 359/400\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0222 - accuracy: 0.9922 - val_loss: 0.8003 - val_accuracy: 0.8056\n",
            "Epoch 360/400\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0124 - accuracy: 0.9974 - val_loss: 0.7699 - val_accuracy: 0.7222\n",
            "Epoch 361/400\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0140 - accuracy: 0.9965 - val_loss: 0.4971 - val_accuracy: 0.7500\n",
            "Epoch 362/400\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0069 - accuracy: 0.9991 - val_loss: 0.6101 - val_accuracy: 0.7500\n",
            "Epoch 363/400\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0054 - accuracy: 0.9983 - val_loss: 0.9984 - val_accuracy: 0.7500\n",
            "Epoch 364/400\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0163 - accuracy: 0.9965 - val_loss: 0.4434 - val_accuracy: 0.8611\n",
            "Epoch 365/400\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0124 - accuracy: 0.9965 - val_loss: 0.4792 - val_accuracy: 0.8611\n",
            "Epoch 366/400\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0173 - accuracy: 0.9939 - val_loss: 0.4521 - val_accuracy: 0.8333\n",
            "Epoch 367/400\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0104 - accuracy: 0.9965 - val_loss: 0.5988 - val_accuracy: 0.8333\n",
            "Epoch 368/400\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0083 - accuracy: 0.9983 - val_loss: 0.4529 - val_accuracy: 0.8056\n",
            "Epoch 369/400\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.5928 - val_accuracy: 0.7778\n",
            "Epoch 370/400\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0044 - accuracy: 0.9983 - val_loss: 0.5725 - val_accuracy: 0.7778\n",
            "Epoch 371/400\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0160 - accuracy: 0.9957 - val_loss: 0.6235 - val_accuracy: 0.7222\n",
            "Epoch 372/400\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0138 - accuracy: 0.9965 - val_loss: 0.6590 - val_accuracy: 0.8056\n",
            "Epoch 373/400\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0168 - accuracy: 0.9948 - val_loss: 1.2064 - val_accuracy: 0.6944\n",
            "Epoch 374/400\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0044 - accuracy: 0.9991 - val_loss: 0.4475 - val_accuracy: 0.8056\n",
            "Epoch 375/400\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0046 - accuracy: 0.9991 - val_loss: 0.5325 - val_accuracy: 0.8333\n",
            "Epoch 376/400\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0143 - accuracy: 0.9957 - val_loss: 0.6702 - val_accuracy: 0.8333\n",
            "Epoch 377/400\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0063 - accuracy: 0.9991 - val_loss: 0.5523 - val_accuracy: 0.7778\n",
            "Epoch 378/400\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0054 - accuracy: 0.9991 - val_loss: 0.3301 - val_accuracy: 0.8611\n",
            "Epoch 379/400\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0068 - accuracy: 0.9974 - val_loss: 0.5226 - val_accuracy: 0.7778\n",
            "Epoch 380/400\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.5485 - val_accuracy: 0.7500\n",
            "Epoch 381/400\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0121 - accuracy: 0.9957 - val_loss: 0.9601 - val_accuracy: 0.6944\n",
            "Epoch 382/400\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0293 - accuracy: 0.9913 - val_loss: 0.8945 - val_accuracy: 0.7500\n",
            "Epoch 383/400\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0274 - accuracy: 0.9896 - val_loss: 0.8436 - val_accuracy: 0.7500\n",
            "Epoch 384/400\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0251 - accuracy: 0.9905 - val_loss: 0.5981 - val_accuracy: 0.7222\n",
            "Epoch 385/400\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0114 - accuracy: 0.9974 - val_loss: 0.6096 - val_accuracy: 0.7778\n",
            "Epoch 386/400\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0212 - accuracy: 0.9939 - val_loss: 0.5944 - val_accuracy: 0.7778\n",
            "Epoch 387/400\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0152 - accuracy: 0.9957 - val_loss: 0.7362 - val_accuracy: 0.7500\n",
            "Epoch 388/400\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0129 - accuracy: 0.9948 - val_loss: 1.1222 - val_accuracy: 0.6944\n",
            "Epoch 389/400\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0127 - accuracy: 0.9957 - val_loss: 0.5988 - val_accuracy: 0.7778\n",
            "Epoch 390/400\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0099 - accuracy: 0.9974 - val_loss: 0.8294 - val_accuracy: 0.8056\n",
            "Epoch 391/400\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0085 - accuracy: 0.9983 - val_loss: 0.5282 - val_accuracy: 0.7500\n",
            "Epoch 392/400\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0086 - accuracy: 0.9983 - val_loss: 0.7130 - val_accuracy: 0.7500\n",
            "Epoch 393/400\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.5051 - val_accuracy: 0.8056\n",
            "Epoch 394/400\n",
            "72/72 [==============================] - 1s 20ms/step - loss: 0.0077 - accuracy: 0.9983 - val_loss: 0.4996 - val_accuracy: 0.8056\n",
            "Epoch 395/400\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.6047 - val_accuracy: 0.7778\n",
            "Epoch 396/400\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0057 - accuracy: 0.9991 - val_loss: 0.6276 - val_accuracy: 0.7500\n",
            "Epoch 397/400\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0060 - accuracy: 0.9983 - val_loss: 0.7038 - val_accuracy: 0.7778\n",
            "Epoch 398/400\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0040 - accuracy: 0.9991 - val_loss: 0.6237 - val_accuracy: 0.8056\n",
            "Epoch 399/400\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0116 - accuracy: 0.9957 - val_loss: 0.8931 - val_accuracy: 0.7500\n",
            "Epoch 400/400\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0090 - accuracy: 0.9983 - val_loss: 0.6482 - val_accuracy: 0.8056\n"
          ]
        }
      ],
      "source": [
        "cnnhistory=model.fit(x_train, y_train, batch_size=16, epochs=400,validation_data=(x_valid, emo_valid))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EWT6F8K425LT",
        "outputId": "0051be10-903a-438a-ea5d-561284c801ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9618923608213663\n"
          ]
        }
      ],
      "source": [
        "ava_acc=np.mean(cnnhistory.history['accuracy']) # numpy assumed imported as np\n",
        "print(ava_acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "3_HGLS8F29Qr",
        "outputId": "ffdf6fc8-7e92-47ca-c884-edc599207cfb"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOydd3wcxfn/P3NFd+pdsi0XuXfjhjFgwPTeew2QYCAkQL6QBJJvQr4JJPxIoQQIPZgeejUhEAymGFeMce9FbmpWL9fm98fs3M7u7TXpTifpnvfrpZeu7O3O7e3OZ54yzzDOOQiCIIj0xZbqBhAEQRCphYSAIAgizSEhIAiCSHNICAiCINIcEgKCIIg0h4SAIAgizSEhIIgYYYw9yxi7O8ZtdzDGTujufgiiJyAhIAiCSHNICAiCINIcEgKiX6G5ZH7OGFvNGGtljD3NGCtnjH3IGGtmjH3CGCtUtj+LMbaWMdbAGPuMMTZeeW8aY2yl9rl/AXCbjnUGY2yV9tmvGWNTutjm6xhjWxhj9Yyxdxljg7TXGWPsfsZYNWOsiTH2PWNskvbeaYyxdVrb9jDGbu/SCSMIkBAQ/ZPzAZwIYAyAMwF8COBXAEohrvmbAYAxNgbAywBu1d5bAOA9xlgGYywDwNsAngdQBOA1bb/QPjsNwDMArgdQDOBxAO8yxlzxNJQxdhyAPwG4CMBAADsBvKK9fRKAo7Xvka9tU6e99zSA6znnuQAmAfg0nuMShAoJAdEf+Tvn/ADnfA+ALwAs4Zx/yznvAPAWgGnadhcD+IBz/jHn3AvgLwAyARwBYDYAJ4AHOOdezvnrAJYpx5gH4HHO+RLOuZ9zPh9Ap/a5eLgcwDOc85Wc804AdwI4nDFWCcALIBfAOACMc76ec75P+5wXwATGWB7n/CDnfGWcxyWIICQERH/kgPK43eJ5jvZ4EMQIHADAOQ8A2A2gQntvDzdWZdypPB4G4DbNLdTAGGsAMET7XDyY29ACMeqv4Jx/CuBhAI8AqGaMPcEYy9M2PR/AaQB2MsY+Z4wdHudxCSIICQGRzuyF6NABCJ88RGe+B8A+ABXaa5KhyuPdAO7hnBcof1mc85e72YZsCFfTHgDgnD/EOZ8BYAKEi+jn2uvLOOdnAyiDcGG9GudxCSIICQGRzrwK4HTG2PGMMSeA2yDcO18DWAzAB+BmxpiTMXYegFnKZ58EcANj7DAtqJvNGDudMZYbZxteBnANY2yqFl/4I4Qrawdj7FBt/04ArQA6AAS0GMbljLF8zaXVBCDQjfNApDkkBETawjnfCOAKAH8HUAsRWD6Tc+7hnHsAnAfgagD1EPGEN5XPLgdwHYTr5iCALdq28bbhEwC/AfAGhBUyEsAl2tt5EIJzEMJ9VAfgz9p7VwLYwRhrAnADRKyBILoEo4VpCIIg0huyCAiCINIcEgKCIIg0h4SAIAgizSEhIAiCSHMcqW5AvJSUlPDKyspUN4MgCKJPsWLFilrOeanVe31OCCorK7F8+fJUN4MgCKJPwRjbGe49cg0RBEGkOSQEBEEQaQ4JAUEQRJrT52IEVni9XlRVVaGjoyPVTUk6brcbgwcPhtPpTHVTCILoJ/QLIaiqqkJubi4qKythLBbZv+Cco66uDlVVVRg+fHiqm0MQRD+hX7iGOjo6UFxc3K9FAAAYYyguLk4Ly4cgiJ6jXwgBgH4vApJ0+Z4EQfQc/UYI4oIHgNY6gCqvEgRBpKkQtFQDjbuA9oMJ2V1DQwMeffTRuD932mmnoaGhISFtIAiC6CrpKQR+r/gf8Cdkd+GEwOfzRfzcggULUFBQkJA2EARBdJV+kTXUZRLkbr/jjjuwdetWTJ06FU6nE263G4WFhdiwYQM2bdqEc845B7t370ZHRwduueUWzJs3D4BeLqOlpQWnnnoq5syZg6+//hoVFRV45513kJmZmZgGEgRBRKDfCcH/vbcW6/Y2Rd7I1wkEvICjGbBtibrPCYPycNeZE8O+f++992LNmjVYtWoVPvvsM5x++ulYs2ZNMMXzmWeeQVFREdrb23HooYfi/PPPR3FxsWEfmzdvxssvv4wnn3wSF110Ed544w1cccUV0b8wQRBEN+l3QtAbmDVrliHP/6GHHsJbb70FANi9ezc2b94cIgTDhw/H1KlTAQAzZszAjh07eqy9BEGkN/1OCCKN3IM07ALa6oD8IUB2ScLbkJ2dHXz82Wef4ZNPPsHixYuRlZWFuXPnWs4DcLlcwcd2ux3t7e0JbxdBEIQV6RksDqaNJiZ9NDc3F83NzZbvNTY2orCwEFlZWdiwYQO++eabhByTIAgiUfQ7iyAuEjSPoLi4GEceeSQmTZqEzMxMlJeXB9875ZRT8Nhjj2H8+PEYO3YsZs+enZBjEgRBJArG+9ikqpkzZ3LzwjTr16/H+PHjY9/JwZ1Aez2QOwjILY++fS8j7u9LEETawxhbwTmfafVeerqGgi6hQEpbQRAE0RtITyGQVlAfs4YIgiCSQZoKgWYJkBAQBEGkuxCQa4ggCCK9hSBB6aMEQRB9mTQVAhkjIIuAIAgiTYUgtTGCnJwcAMDevXtxwQUXWG4zd+5cmNNkCYIgkkGaC0FqLYJBgwbh9ddfT2kbCIIg0lwIEmMR3HHHHXjkkUeCz3/3u9/h7rvvxvHHH4/p06dj8uTJeOedd0I+t2PHDkyaNAkA0N7ejksuuQTjx4/HueeeS7WGCILoMfpfiYkP7wD2fx95G08LAA4wO+DMir7PAZOBU+8N+/bFF1+MW2+9FTfddBMA4NVXX8VHH32Em2++GXl5eaitrcXs2bNx1llnhV1z+B//+AeysrKwfv16rF69GtOnT4/eLoIgiATQ/4QgKhyJzhaaNm0aqqursXfvXtTU1KCwsBADBgzAz372MyxatAg2mw179uzBgQMHMGDAAMt9LFq0CDfffDMAYMqUKZgyZUpC20gQBBGOpAkBY2wIgOcAlEP0vE9wzh80bcMAPAjgNABtAK7mnK/s1oEjjNwBiOUp968Wjx2ZQNm4bh1OcuGFF+L111/H/v37cfHFF+PFF19ETU0NVqxYAafTicrKSsvy0wRBEKkmmTECH4DbOOcTAMwGcBNjbIJpm1MBjNb+5gH4RxLbIwh49ccJDBZffPHFeOWVV/D666/jwgsvRGNjI8rKyuB0OrFw4ULs3Lkz4uePPvpovPTSSwCANWvWYPXq1QlrG0EQRCSSZhFwzvcB2Kc9bmaMrQdQAWCdstnZAJ7jogTqN4yxAsbYQO2ziaezBWjWdm3PQCJdRBMnTkRzczMqKiowcOBAXH755TjzzDMxefJkzJw5E+PGRbY8brzxRlxzzTUYP348xo8fjxkzZiSsbQRBEJHokRgBY6wSwDQAS0xvVQDYrTyv0l4zCAFjbB6ExYChQ4d2vSF1m/XHDhfgTWxmzvff60HqkpISLF682HK7lpYWAGLx+jVr1gAAMjMz8corryS0PQRBELGQ9PRRxlgOgDcA3Mo5j7KqvDWc8yc45zM55zNLS0u71A6PL4AAs+sv2F1UdI4gCAJJFgLGmBNCBF7knL9psckeAEOU54O11xJOm8eHtoBTaZwt5RPKCIIgegNJEwItI+hpAOs5538Ls9m7AK5igtkAGrsaH4i20hoD4Fe/LmPoi0Xn+tqKcgRB9H6SGSM4EsCVAL5njK3SXvsVgKEAwDl/DMACiNTRLRDpo9d05UButxt1dXUoLi4OO2ELjMEmO/7C4QmPD/QEnHPU1dXB7XanuikEQfQjkpk19CXEQDzSNhzATd091uDBg1FVVYWampqw23R4/WCt1XDabbA17gM6GsVf4/ruHr5HcbvdGDx4cKqbQRBEP6JfzCx2Op0YPnx4xG0WbqxGwes/wJAhA5F33fvA5/cBC+8BflsP2OwRP0sQBNGfSZuic3bG4IIXfptLvCBdSAF/6hpFEATRC0gfIbAxuOBBwK7512UqKWUOEQSR5qSNENgYg4t54bdliBeY9tU5WQQEQaQ3aSME0iIIuoZsZBEQBEEAaSUEEDECu4wRaF+dYgQEQaQ5aSMEtpBgMVkEBEEQQBoJgZ1xuJgPvpAYAQkBQRDpTfoIQcADAHqw2EZCQBAEAaSREDgCnQAAH6MYAUEQhEr6CAEXFoHuGqIYAUEQBJBGQmD3SyEwWQQ0j4AgiDQnbYQgxCKgeQQEQRAA0kgI7P4OAICXmbKGKEZAEESakz5CEAwWm2MEtNALQRDpTRoJgXANeYPBYq36KMUICIJIc9JHCPzCIvAyqjVEEAShkjZCYAtIIaAYAUEQhEraCAEvGoVHfGeh1VkkXqASEwRBEADSSAhQPhF/9l2CVkeheB4MFpNFQBBEepM2QmC3ieBwQGYJkUVAEAQBIJ2EQMsS8st+XwaLAyQEBEGkN2kjBLLYqG4RyPRREgKCINKbtBEC3SKQQkDpowRBEEA6CYHNLARUdI4gCAJIIyFgjIExxTVEE8oIgiAApJEQAMI9FGIR0IQygiDSnLQSApuNwc8pRkAQBKGSVkJgZwyBkBgBCQFBEOlNegmBjSnzCEgICIIggDQTAhuzmFlMMQKCINKctBICYRFQjIAgCEIl/YQgpNYQWQQEQaQ3aSUENjVYTPMICCJ2An7g7ZuA6vWpbgmRBJImBIyxZxhj1YyxNWHen8sYa2SMrdL+fpustkiMriGKERBEzNRuAla9ALx2dapbQiQBRxL3/SyAhwE8F2GbLzjnZySxDQZszGoeAS1eTxBEepM0i4BzvghAfbL23xXsNnUeAS1eTxAEAaQ+RnA4Y+w7xtiHjLGJyT6YCBZrTyhGQBAEASC5rqForAQwjHPewhg7DcDbAEZbbcgYmwdgHgAMHTq0ywe0MYTOLKYYAUFEh1yo/ZqUWQSc8ybOeYv2eAEAJ2OsJMy2T3DOZ3LOZ5aWlnb5mHYbg0+uSEbzCAiCIACkUAgYYwMYE456xtgsrS11yTymjSklJmgeAUF0AZbqBhBJIGmuIcbYywDmAihhjFUBuAuAEwA4548BuADAjYwxH4B2AJdwnlz7025jtB4BQRCEiaQJAef80ijvPwyRXtpjWM8jICEgCCK9SXXWUI9isAioDDVBEASAdBMCqxXKKEZAEDFAWUP9mbQSApvqGqIYAUHEjrxPGAWL+yNpJQR2ZuEaonkEBBEdGjD1a9JLCGg9AoLoGnSf9GvSSghsaokJihEQROyQEPRr0koI7GqJCRtVHyWImKE0635NegkBrUdAEF0jaBFQsLg/klZCYDMEixkARiYvQcQC3Sf9mrQSAoNFAAirgGIEBBEdEoJ+TVoJgU1dvB4QcQK6wAkiOnSf9GvSSgjs6uL1gLAIKEZApApPa6pbEDtkOfdr0ksIzBYBs9FIh0gNq18F/jgIqN6Q6pbEBs0s7teklRDYGDNmwTFyDREpYuMC8b96bWrbESt0n/Rr0koI7DZYBIvpAieIqNB8m35NmgmBOVhMMQIiRfS1jpUGTP2atBICm1WwmC5wIqX0EZ97PAOmPStoJnIfI62EIDRYTDECgoiJWO+TXUuAJ48Dvro/ue0hEkpaCYHbaUeHVxnZ0IQygoiNWEtMNOwU/w+sS2pziMSSVkKQlWFHhzdgXJyGLAIiJfTTGIF0IcmijulKay2w77tUtyJm0koIsjMcAIA2j0+8wGzkyySIWIhVCKSFzdJcCB47Cnj86FS3ImZiEgLG2C2MsTwmeJoxtpIxdlKyG5dosl1SCOTFSsFiIlX0kSCxJG6LIK3GmKE07011C+Ii1l/rWs55E4CTABQCuBLAvUlrVZLIdolRSkunYhFQjIAgokMWQb8mViGQw5fTADzPOV+LPjekAbKka6hT8WOSRUCkhD4aI4h21wctAkdSm0MklliFYAVj7D8QQvARYywXQJ/rQbMzxCil1RAjIIuASCF9pXYPBYv7NbHK9g8BTAWwjXPexhgrAnBN8pqVHPQYgRQCsggIIibINdSvidUiOBzARs55A2PsCgD/C6Axec1KDjJG0NpJwWKil9BXrr90tAj8PuC5s4GdX3d9H30kKzFWIfgHgDbG2CEAbgOwFcBzSWtVkpAxglYZLLaREBApQs5w7yMdRcwuVK4Msvo6TXuAbZ8Bb17f9X3EkozSWgv8Lh9Y+3bXj9NNYv21fJxzDuBsAA9zzh8BkJu8ZiUHOY+gVU0fpRgBkUr6StZarDOL+5NFEGuAPBKx9C/V68X/pU9240DdI9YYQTNj7E6ItNGjGGM2AM7kNSs5ZGmuobZOihEQvYS+MhCJOUYgO8/+JATdsG5iEfpesOhPrN/wYgCdEPMJ9gMYDODPSWtVknDabchw2IwWQV8ZkRH9C3nTB3ypbUesxFo2uz9ZBIEEuLliEfq+IgRa5/8igHzG2BkAOjjnfS5GAIgUUj1GQBYBkSJkx9pXBiJxZw31gxiBv1P87451E9PvK0W2lwsBY+wiAEsBXAjgIgBLGGMXJLNhySIrw0HzCIjeQ1+5/mIVLGnh9LWFd6zwecT/7ozUY0kGkOcqheIZ65F/DeBQzvkPOOdXAZgF4DfJa1byyHYpFoHDBfg6U9sgIr3pCxZpS40e0IzWKfq94n9PWzr7VgOvXS1SPhOFXwpBsmMEfUcIbJzzauV5XRyf7VWU5LhQ06x1/hk5gKc1tQ0i0pu+YBF8fi/w7fOxbSuFoKe/186vgLVvAW11idtn0DXUHSGIxSLoIzECAP9mjH3EGLuaMXY1gA8ALIj0AcbYM4yxasbYmjDvM8bYQ4yxLYyx1Yyx6fE1vWsMKsjE3oYO8SQjG/CSEBCpoA/FCNoPxr6tHEX39PeSLqlEBt99CbAIYgoWy216uRBwzn8O4AkAU7S/Jzjnv4zysWcBnBLh/VMBjNb+5kFMWks6FQWZONDcAY8vADizyCIgUktfsAi87bFvmyqLIHhcbwL3KS2CbnTQsQiibHsKXUMxlwjknL8B4I04tl/EGKuMsMnZAJ7TJqp9wxgrYIwN5Jzvi/UYXaGiIBOcAweaOjAkI5uEgEgtfcEiiEsIpEXQw7GPoEWQwPMZLUbQ2QK4cqK0KxYhSIDl0U0iHpkx1swYa7L4a2aMNXXz2BUAdivPq7TXrNoxjzG2nDG2vKampnsHLcwUBzvYLmIE3ra+MSoj+id9ocSEr0N5Ei1YrHVqPX1PSSHwJ9AiiOQa2vcd8KeK6GUhYhHEXmARRDwy5zyXc55n8ZfLOc/rqUZyzp/gnM/knM8sLS3t1r4GFQgh2NvQLmIEgBADguhJgrWG+sCEMoNFECUtNFVZQ8l0DVmJ395vxf8tn0TeR1wWQS+PESSJPQCGKM8Ha68llYH5bnFwVQjIPUT0NMmaUPbvO4HtXyR2n6pFEG1+QMpcQ1IIuiCsy/8J7FkZ+nokiyDW8hOx/L6JFK8ukkoheBfAVVr20GwAjcmODwCA22lHSY7LaBGQECSfT+8BqpanuhW9B9lBJNqF8s2jwPwzErtP1SKIVQh63DWkHa8r8wjevxV48tjQ1yP57mPN/Tefhz0rgLd/bHQJ9nbXUHdgjL0MYDGAsYyxKsbYDxljNzDGbtA2WQBgG4AtAJ4E8ONktcVMRWEmWQQ9CefAovuAp45PdUt6D7KDSKRFkKzO1yAEUUb6vdE11FrbxX1GmEfQVYvgjR8Bq14EDm5XjpP6YHHSFhblnF8a5X0O4KZkHT8SFQVubNjfTELQU1AwPpRkWASyQ0k0BtdQNCGQFkEvcQ2tfhV48zrguoVAhcVUpUgWTkTXkLQIYizLLckpB+q3ibUOikeK19I8RpAyKgoysbehHdxJQtAjJKuD6ssEa/IksMNM1nmOyyJI8YQyc9aQXF1sr0UMAIh8zqRFYBV3iNkiMJ2vvEHif8Mu5TipTxhISyEYVJCJDm8AjX5tSQVPS2ob1N/pBcGwXoccMSfSIvAlQQgCfuPvF6trqMcnlIWZR+DMEv89YTIDDamx5n1GykTqYowgp1z8P7hDOU6K4ioKaSkEgwvFxbG7VSsvSxZBcklkbnd/gSchRpAMi8A8mazXWgRKp127We9UMzQhCDcpLlLRSfme1Yi9qzEC6VIiIUg9U4cUAACW7dF+aJpHkFzINRRKIBkxgiRU0jWPmHurRSDdN9XrgYdnAp/dK55LiyBcTbGIFoF0DVkMZCIt3anGHcznQe6rfptynBjmQLx3S/fWTo5CWgpBaa4Lkyry8Ol27eIg11ByIYsglGQUSQue5wQGHc2DpJgtgh4OFstRe5M2FWnHl+K/U0wgDW8RRBikyPesrt9IwWL1u5vPg9xXzSZlUmEMcyBWPAusfiX8+90kLYUAAOaOKcPiXW3gzA50dLdaBhEREoJQgq6hJASLE5mG6DVbBL18QlnwuexUtY46nNUf0SKQLps4XUPq9mbXkLwXPM1AY1X04/QQaSsEF84cDH8AaHMUAG21wKtXAfPPTHWz+ifkGgolmcHiRAqBL84YgfSrR/tenAObP45tJbM1b0R3i5hXRgtaXLLjDScEEdxpiRACcxqtKlhysZ9UudMU0lYIhhVnY1ZlEaoDeUBLNbDuHWD7ov6xxF5vg7KGQklmsDipFkEEIeBcF45o32vVi8CLFwDfvhC9Da9fG90tEpzIJgXWlE4a1jUUwSIIBostrt/gwvYWrqGIFoEHyBkgHlev018Ld5weIm2FAABGlmWjOpCr5xoDQOPu8B8guga5hkLpatnkzZ8An99n/Z4Mbtq6sdi6yt3lwJs/Mr4WSQgCPqUjjvK9pFukYWfX22c+NhBqkcjXw7mGIgXYIwWLIw1u1O9uPg9+H5BdArjz9XiGvD9aa4C6reH3m0TSWggGF2Zhry8X6FRiBJ/8X3gzsiv4ffHVc++PkGsolK6WmHjxfGDhPdbvJbpmja/DOPEJiCwEholnUb6XbGM8sYRI1npQCNqNz4M++TAJIRFdQ9pnrdJHI6V8RrIIAl7A7hTZTPJ8yeMc3A78vUcWagwhrYVgSFEWanm+eCIvzDWvRy8t6+0Avnwgtgk8r1wK3DMgtga9dwvw3b9i27Yv0V2LoPkA0LQ3MW3pLSSqxMSK+aKMAqC4hhJkEVgRqeNW3SzRSkx0RQginaugC0hrgzkrK1xCSCyuIavRfyS/vnq9h1gEHsDmBBxu/djxDJSSFEdIayEYWpSFOrmswoApwPBjxONo8woW/x345C5g5fzoB9n8n9gbtOJZ4K15sW/fV+iuEPx1DPC38YlpSzQ6m4EFP0/+JEPZUXY1u0aOjt+7WdTSAfSOK5k1axJtEcTTsUXqMEMsAlNufmc4IYgjWNxWL5JKmg9EDiRHjBH4AHuGtUUQC5GEqxuktRAMKcxEHTQhyCkHzn1cPI4mBLKaYaSLyEwig9CcA5s+6hurWwF9K1j81UPA0ifEXzLp7tKK5k4x4O+ZcsYRLYLO2LYDumYRRPLnh4sRSLdOZ7P153wRKoy2N+j75hzY8l+RVLLgNsUiiCIE5nvU7wHsDsDp1oXAfH+Y+wrVNWUO3ieItBaCouwM5Nq1HyGnTPw4QPSTLW9Chyv2gyXST77mDeCli4BlTyVun/Hy3SvA7/LFuq3R6EsxgmRM9LKiu1lD5sHKwR36eU5UsNiKiNU6FYsgksC98xNhUUfbn5lII2dzdlBnixjBB5TXrY4VFALtnHk7RMfLuQjeSgI+fX3iHV9GEQLlu1vGCDIAR2Z415B5n6oVYE7nTRBpLQSMMazIORbrs2YCc+/Qp6PLk91SDXz999ALSMYGbHFU8U5kwFjWKWlK+oJu4fnib+J/LFlWfSlrKDhS7eLn2+qBf10BtNZF3s6c1RIv3g5jh1O9PvLSivESriOP6BrSOixmiyxw3z6v7C9RriGzEDQC9w1Xrj1u/XnZyUrxvKcceO4s4UrydwLZ2tK4fq++7/aDigsqSrA4JEbgFTEC1SIw3x9m949qaZFFkBxc+WW4K/9uIH+wUGow/WQ/fCjwn/8F6rYYPyRvuHhGuokUAnmh2TMSt894sWuVW2Pp5PuUEGidaFd993u/Bda/B+xZDtRuEVbT1oWh23U3WOxrN/q967Yk1jUU7jcLd158HqB2k3ickRP794rnHoooBNrxzO5atVNW78GDO8RvU7VMPFcD7Du/0t2/uVqiR8Br3Ld0NcUdI/AK11CkYLE5CYUsguRTnufGgaYOcM5FJ+DMFGZ3YxXQofkIPS0ik0i6QeQPFymg2FonLjRJtLhDPP5+eXzZGacCOYKKJXjVl1xDXfFdq8hrov0gsFOrd7PmjdDtgumjXTyOtwPoaFSet+sdVSJcQ+HiOuHau3I+8O5PxOOM7Ni/Vzyp2pGy9KRwmTtKVdDUa3XDB+L/+ne1F7hRvKRbKK9C24/PuO9YhcCq6Jw9Q+tnwlgE5liI2m6yCJJDea4LO+vaMPrXH6K5w6srdZOyfPLBHcAL5wN/qgBevkz/Mbzt4uL89J5QX7m6FB0QvcOMx0UgL5x4XFOJxqaJULggnIoqBL1+5rZ0q3SxnUEhaIhcmKy71Ud97UYh8HtSaxHUK9d7Rnbs3ytcVVDLNsXhGjK/Lt/b+634XaxcNur5bKkW/3MHavvxGTvhiEIQIUYgXUMRLQKza4gsgqRTnicCxL4Ax3vf7dOUukPUH5KorqGNH+iWgrcN+O4lsR7voj8bd2y++aO5huLJrAm6hmK0CAIB4KFp1iPTrmKPQwgijZCi0dOrN3XXNSQnLnU0QBcTqwqV3Q0Wd1gIQQItr3hjBC0H9MfOrNi/Vzwu00guxqBrKIJ/feE9wBNzgV2LrYO48r4GFItgkP6+wSLQ3HJRXUPmDCA5oUyxCMz3UGeL8XMGi4CEICkUZet+9ndW7RE/kK/duOB1vWl0Ly8ST6tu2ob8QPEKQRcsglhH154WUf/83ZtjP4bK2zcBH9xufE1aI7GU8FY7qHhr5idpBBSWoGuoqxaBdj7aD+qdZku1iBeodNci8FpZBKbUyXXv6IXNYqW1DnhoOnDge/01mzLgCCcErdX643hiBPL+WfqkloUWYWARsRxEmCwedX/fv6Yds9V47iRt9frj5v3iv4wR+L0mi0D7neMOFnuEEEiLIOAPnePw+FHAl/eLx7qllu4AACAASURBVJwDu5bo75EQJAdpEQDA5uoWkdblbTdZBKb6H9Jt5G2DvmSdqeM33zDRfsB4Rr7Seoh1HkO0GacHd0bu+Fa9ACx70vha0CKIVwjiHLUaJimZ2ti0F9j/PRJLElxDmz4EHp5h3C5YLTMJriG571evAh6dHd9+67cB9VuFC0XiytUfh7UIVCGIwyLYsxzYuwpY8ph43rRX3Au1m0O3jcU1ZMYqjufrMKaGStTXFt0HZBXrmYQBn3FkHrNFYLY8fHqMwKdYdXZTKrrMrFrzBvDRnca2J4G0F4I5o0vw/k/n4M5Tx6G+1QOf3SU6H4NFoK0mdPIfxX85SvW06jdG017jxWvupINVGTnw3DnA8n8a34/HNRSsihijEMjO1MpXfWAd8OAUkSZrRThzXIpKTDEC5caIN4NIvZHNn31wKvDYnPj2F42ga0gRgn3fAdu/iO3zsr2qm8EM5wgKTVcnBaquIVeeODfByVS+rls0MqlBHR3L/HkAALfet0EILILFLdVGcZT4PcATx+gLyHQ2AxveAx45DGgxddZh4xY8vEVtZbFu/g/wvYWb1CwOp96nW75+r6mERoT5JhGLznnFPh3aAFSeN7mkpkRapvtXG18niyB5TKrIR2VJNgCggzu1EUOtnkPcWg24C4DMQuMHvW36xbH+XbFEXjhfpfwBvW3AtoXA+7ca1y2NxzUkO99YRweRsklkFchtC4E1bwK7lxnfV4uOWc0c9cQZLO6ORWAWPvk8nk5v0Z+B164O/74Ugg3vA2vfFo8fPxqYf0Zs+7dyDZmJFEyMlaBFwICsImOMIODverwgmCuvCFlGrnEbK793uyIczqxQgfvLaOCBKeGvc6e4/9BWJ+497gda9otyH8HjhPlOkdxQnS2h7V/5nLXL0SwEI+bqlm/Aa90JR80a8olBhDxn0jUkha9Fc0E5TUIAiwEJQBZBsqksFhdia8Cpu4byKnRlzikP/bE8baHFrLZ/Lv6bL1o50lK3Vy2IeEbKctQZS9E7QL/orbKM5Oxonwd4/Rrg6ROM76vxkWYlk0pekLG4hlRrJ56yHIBJCMKco3jWnP70bmDtW+Hfl7937SbgtR/Evl+JPB/tDaHtlT5mtfPvzoSyzhbhj3e4Q11DXa2V5FXSXyUGiwChAmfuQG0Oa4HrbAz/+8uOsa1O32bXN8ZSH7uXAg9MFrV+VCJZ054Wo2srEqoXQLbJrtwfVp1wtBjB8n+KQcT6d4U4cr82s1izCOR3kd9fIgckqsACZBEkm6FFopNv8DqMFkGGdhPkWgiBtzU00LP5Y/HffMHLTkB1pagdWDxBQznqjNk1JGd8WlgEclJauH2pabBNVkIQi0XgtX4cC2p6YbgR4c7FiZu01t30VnUegfmcWvmVo/3uzfuBxY+KdqkuNl+7+HO6xQjT74Whfn48QuBtF+XXO5uNs2cl5o40xO1j6phtdpPVo2bAhBMC7d5qrQ1/bX31gLBQq5YaX48kprEIwcCp2rFNgubIFG4uQFyH3naEJIFYHVuNLzZqFnX9dl2wbA79+7aEEwKta240VQ8giyC5ZGbYceSoYqyr9aKlpUn8QNml+oWQM8D4YzmzNIvAlH0gL95wFoFBCNTaLEpH9rv8yCUKghZBjEIQtAgshECO3MJ1stJ1BADNSiloKS5xZw15RMcda1lp9RyF+74vng98+gfja5yL8/if/xXPHz8GWBJDIbnulvlVYwTmyT/yWonHNfSvK0WwsG6rUVjkBDKHW4xau2MRbPgA+PJvwMd3WQtBRhSLwOzLZ3bj91J/w3BVQG1aV9RWq18v4QYZVq6pcPBAqEVjZpCFEDizRJvk/e9pFZ2wO9/4WSsh2PWNCDQb2qEUBbRn6HXNgkKQbdqJJjjq/QeQRdATPHr5DOTl5CKnfa9wg5RP1E24/MFGiyCnTGRXbPzQuBPZWYUEi+UoR7kRVIvAfDHLALUV0v1g1THWbQ3tzIIWgUWwOHjThenQPS26JSFT6oDuWQT/PEUEemMh0jlS2bPS+FyeGxkE37cK+FDxN4cL0sbjqnn7JuPscUCx1jyhAWMpBGoneXBH5OUa9ywX/5v3mWrOtIs/h0t0LH6P/j4PxPa7SFxaBd6dXxktmuD7phG1OVMrmkWg7kuNi9mcwJhTADA9jVR1DYULuJsHX9F+MyuLYPaPgVO1uT8Dpoj/qstJ3vcGIegEMguiH3vHV8CwI2GwHgIBY0UAhzaolPeUlWuIc2M9sds2Asf9xvIrdhcSAoX8TCcmVZbrLww+VL+x8wcbfywZOA43C9DsFghOHlGEQJ1eb76gHBHqCMkArVkIareIFY7Mk9sixQhk56r6IltqREofIG6AvArxWdWH2mUhkOuzxmjNqOdItSzMHbn5BjW43Sw6/XAmtvl3iJZWa0YdiasxFUDv2MzteeemMG0J6KPvxirj9/d1aBZBpu4aMqQ3WuTJh0Put2aDYhEo14PZIjDHkdQ5BIBmESjfUe3Q1QFORhYw5DAAXBeLVkUIrFI8ATE/Yttn+nPzb2Zz6iXlAWshyMgBDpsH3NWg38uqxSvvlaAQtIhz4zYLgWnQ1bRPuIOGHWG0wD0txomg0iKQQuBwG/fDbKIOknodZ5dF7he6AQmBicJ8MTryMwcwcIp+geYPMQqB2WSTBC0Cs2vIYhahwTVkupgjzSuQnY25M5WjrV3fWLfJKkYgOwF11Pb3GSKlD9B8rDnihlAvStn2SGmS5mMAJp9/DH59g0WgfF9ztpLZZA/3Ocnub6zPsfl3COdiUUe26vfwtOhtMQc1g66hGOMZsogbIK43VfhXzAeaqowWgTpStpowFQ71/MgsFvU3c5o6KcBoQbZUi8yc8WcBg6brFoGvUxTc+8cR+raqEAT8ekcr/eptdXp7wrlHt3wMPHe2GJhs/DD0OnK4hDUfbL9iyUvrRx6XMT0zSD1nshM3u4bCWQRSEKrXiv8DJhvvt/aDSmkYxSKQ9ahCMswYsOpF0fZfbAd+vlV3nyUBEgITGW4x+tnIRqDR59B/6PwK/aIAgFP/H5A/NHQHUS2CcMFiixrknIfOSPW26zdpOPeTeXThjRAjsIoNyNEk5+IGyMgWIyj15pfHbtobPRde7fjU/HQ1a6pqOfDvO4F9EfKm1Rs+xD1gGpl5LERL5flzrdf+jTQzVQrHwZ3Ag4dYb+NpBfIGi8ctiitNbXOsWU4H1uiPm8wWQbuY3+DMVIRAEeX3fhbbMQDjoKV6Q+j7jszQ11R3UEs1kFMKXPw8MG+h6Fy9rcDd5cDz5xg/p5YtD/j1wZXs9Fv2R7cIJC9eALx8Sei1YLMbJ2ipM6PNHXzI+9pj2YlLEfG0hrEIfKLtfxos3JD/1WJVpeON91t7vdE1ZI5blIw2Pvd1iFTuyqNEenB2Sej3TyAkBGY0U+2jzsm4/bXv9NfNrqFRJwI3fmn8rLsgfIzAHCx2ZkdOjfR1iNS5h2cAVSv019WR+95vxcXSvB9Y/Zo+ejUvmOOLkDUUaVTuaVWEIFt3k3EuOqLMQnFxm33EVseQN5DaEexRvteyp4FvHjW6tTgHtv5X2Y/SYZnTds0uqqDlwcK7gb56MHQiXYigKOInxb15v/U2nIvH+RXW28kOy8rK+PZFETdRR8EH1goXRfmkUNeQxOHSXUPtSoeouoaipRmr56fGoiSFlUVQvV4XxpZqkV4tCV5nFm419fodNFXvaOXv1bRPv1eiCcE+7f40JyzYHMZ7wK64ROXIW3V3qe/nayIuR982u5YY0iLOU4YpqBvwCVeQt00kJuzTXKrZxcb7re2gsXx86Tjg/KdFnOLYXwPH3wVc9a6+vbdNWEm5ynlNIiQEZgorAQBbyk7CJ+uVDs6dbxwZZeSI1y5VFpvPHSCCey9dHDpKCQpBk7iwXLlGN4nZXeDr1Gul1yslLtQbydMi/LV/HQu8+SOgep14PaxFYPFzR5p41NmkCUGO+JMdWMAnbqhibRQTbnGalmrglcvFDS2rODYo2279VH+s1m+S7F4qfMETzxPPpbi2HwQeO9J4rJDzLWdT28JnWnA/8MVfja+ZfwdVYILiburgPrgNqNmkzzQvGCZeN5/bcEKQVQIsf1qk6n78W/316nVAyRigaLhwqcjjX/yC3sk43KJj8baLzj+zKPR7eluBj34tFhOyinkYBNbCpWRlEfzrcn2VsdZqffIlELkMtrx+T/w9cOkrxo6V2cT5l9dINLej7NSDv5EWnJXVPYPtUUb80noNZxEUDNHbIsnI1i0Cdb8ZuWLgYB6UBPer7EO1CGwOYTVNvkDEKY75hfD9jzhG397TItxkWcm1BIJN7ZGj9CVm/xi4dQ3uuvYcOG02PDJuPnChtki9OnKQP/LYU4SaA2I0EfABm/6t1zuXSLdKR5MQAbX6IBA6EvV16De7VQaG2UQF9CqpdlNQOKJFEEEIOprEBRm0CFpFEFlOmisZI/6rs49VvrxfzNDds0L4Vh1uXTSc2UII5HeTQqCOTpu0OMzoE7W2ap20KiZnPSxGzGaLQLqGGIucZtvZbOwcQ1xDyk0eziW3+T8igCk7UW0wEYKcrStHsBc+C1TMEN9ZuszUkgIH1gFlE4ChhwshkK40OZAAdCGQgXwrF0LVcmDxw8B//y/0ugSUcx5mZTMriwAQa3QAwiK0tAhMZBbp52D40eKaUK1seT2pAx8zaqctkXEH2YnbHMagqlqlV2ZsqUKgvi/dvep3yMgGlj8jOnO1vTll4noxp8Re9mroPtrqjemj0ehoFPtOsktIQkJgxu4ACoagLNeNMw8ZhIfXurE06+jIn5nzM+C3B42jsYadxm1kcLOzWROCrCiuoU59ZKWmG8oOQ1ZFVJFCYM5flze6Vc56JNdQ0CLQYgSeZhFEfuF88X7JKPE/nEWgdpgZOWJ0Izvx8WeIEZ8sbiY7MvWcyNdkKeBgCQWlsx46GygdG8U1FCH32lxMzCwEakxDfh8r105brT6Cza+w7gyr1wGf/1kfFBSPBkYeL4RBTtxTLb6W/WJwMfZU8VzOiHa49I7MoU0ok9/XagS5RMmgsRJt6ToqHRv63phTgVEnhL4OAAVDRcfe0ai7w4DwFkFGtn4+pQ9fzZ+XQqCeAzNWmW/SEi6fpB/fYBFEcQ2p4hJ0DalCoGyr3tc55eJ6US2C8WcCY04Wj5nJIoi3fDxAFkFv4ObjR6EkNwM3vrBCrGAWDsaEhRBuMXt3gX7zSyHIyIoSLG7XLyT1PXmTqKa4RI6Mgi4cv5jpLEfbstOXi3MDMVgErUaLQCW7VHy3cBlU6r5ducJvKkVj7GkAmBhVqguFq51ya604B3K0aR6Rl44DikaIfYcIgVJoL9qqTupnzZaZmjLr9wCb/iMqU5pprdEtAndBaBYTAOxeAiy8G9j5tXiekW0sNlYyRrgD5Hf0e8R3KxohUnjljFq7S/etO93GEWa2aSITII5XMVM8thIxfycAFhqwBIDT/6ILsRl3gZ7ZVDpOf12KoLRaB0wBfrZWG/yY4lhWFkEkrOI91evFvqUlZncag8V2JzDreuDoXyhCoFoEFjECVcjVrKOpV+iPc0pDLQL1d1fFxO8Rrk5AZCDGitXvmQSSKgSMsVMYYxsZY1sYY3dYvH81Y6yGMbZK+/tRMtsTL8OKs3HjMaNQ1+rB7voYZvSZffMSd57uDuhsEilszszI8whUi0AdWUshsDIvZUcpb7aNC0RmhZyw1Lwf2PEl8Idi4L1bjJ+xoqNBiFVGjshyMKdDOtxCDGTn5feJSVYH1oXu250nRjdS/PIHAxXTgS3/FR2xDMSq4thaI2ZoyvMaFAKtMzjzQXGOXHmh5rns8Jgt+poGLQdEPfxAwMIiUOdOdAIvXWgs0Rxsa60iBPmhBQpV5O8jYy+SQdPE9/e266NM2bFkFurn2ZERahFIrAYI3laRzmjPsJ4J7usQ+ykdH/qelStG4mkFajaKx2onLj1MRcPFf2eW+L0Nna92/apCmFMOuCwE1AAPbVf1eiEC8lwymxiYyW1sDuC0+4Djfq0LgZq1o1oM8nuonbi83k65V7iCJdlloTECtf1yMCIHMt+9JASzTBHNaFj9nkkgaULAGLMDeATAqQAmALiUMTbBYtN/cc6nan9PJas9XWVyhfhhv98TQ152OF+qM0sfdbbW6nXOI82aVWME6s3bflBc4BHrq2gdjZqHDoiO/dnTxeOV862PqyKzXqRryLysoDNTdFBSnOq3iUlW/9JGTaqAuXKN/k5npvCPV6/XrQGH2zh6b60RN4IcPZqFQL7uytMmWKnzFWSMwBa9FMfHvwUW3A6sfTP0vKqZK5EmwbXV6UKQWRCaby5TSgGl9HC2cbQpO6G2el3YZCxAnRRlV4XAZbREw7kSSsdZW3WAOG+ODKDc4va0csXklItrsLNJTEKzu4xxEXmMQdPF/8kXiP+qEEhxV11DGVkiVTIS5zwmRK1ASd32tACFw/X9m5dyNQSLZYxAEYL8weL3ufgFPbagunWkyy9PcX8B4hoO+IwBdtUikL9hoSaI+78HRp8U+ftd9ipwqDIe7geuoVkAtnDOt3HOPQBeAXB2Eo+XFMYMyEGG3Ya3V+1BIMCBGdcAR95qvXE4iyAjW3RUu74RI8zsUotgsYVFIH36nSYhyCwMX7MF0C2NSGUqJJEsAjkzVrqGzGQWGYVAdtBSuFQBc+UZL2pnpsiu8TTrQdD8IcbRe2utEI9gYTy5II9pvoTsJFtrRMmHZU8ZO/Bo9Vlkx9y0N1QY1f1ESsM8sAZ463rx2F1gDJ4CeiAT0M4rE+dAPa/FI8X/tjoLIcjTt1M7f0emyTWknWN7BnCesphQ6Vhj5peKX6tZVGYhBNJtcmeVXpJh9InAyGNFG6vXCZeSOoKWI+TSccCde/SOTRU92eEa6ndlWrvUVKZeCtzwZWgtn4IhihDIhZhsxu8AIGhRqOc9sxD4n7XCvy+zigxzALSOPt8kBDZtnlFnGCGQFI3QH5vbbWbMySKQLukHweIKAGoUsUp7zcz5jLHVjLHXGWOWzjPG2DzG2HLG2PKamii5xQnG5bDjpInl+HjdATy3eAdw5gPAif9nvXG4GIG8AZ45WYweskvESKhus0g7BPS0xZPuFv99HdaF3aQQRJo5Km/2+h3RRxR+b6ibyZkNgOmF4TJyrYUgu8QoBMG1nLWOt03JiZcxguAxsoBCLc1S1tMpGGIKFmsWgXR9mOdoBC0CrbO8X+vIPrhNzBEAtBo80So2ar6MzubQGIHqDou1LIYrDxhxrPE1dQTbUi06ZcaM5zW7TPxvr9ctSCkAqkWQWaikj7qMriHZ0ZSMER12Rq74fQdMNs4FUfF1ilG92mFJ5Gjalau7VWTWUsMuUWt/xFzjZ6SIufOEC0bWuFLdQNKHr37/rJLwQlAxAzjj/tDvKcks1PdlXn9DtQjk/RVu0CYFSh39y45eteoAXQg6wsQIJMXKebW6j8yMOFb8FiVjwvcpCSbVweL3AFRyzqcA+BjAfKuNOOdPcM5ncs5nlpb2jM9M5e+XTsP4gXl4f/W+yBuGu7iKRxmfZ5foI6FHDhWLb8gO55BLNVdHpzL3wEIIZF6+mdyBugunflvoTWrG7wktr21ziDYYLAKLCo5ZxZoQaAIQTI/Ujm8Wghwl00laBICoRgoIE9rvUVJKNevJHs41pJ3vCtMykCoBXwxrJmijxM6mUMvMsAZDjEJgd+iZPhK1Y2k5oHcIho5Qc4u01SlCYHINMZvwQ8vRrsMULJbbSbfdHTuB2zeJa85cJmTHV6LiqK9TdIB2J3Ddp8DVC5TvonSi0lpzuMX10X5QDGCmXGT8rmYRk1jFCNSRd+VRekdqdkkd80tg5rX6c7MLyZUXKgTBc6R0pkf8FPhdo3UBRkAI5tmPiD/JyOPEf+mvv30z8D8btDZysdaAJJpFEIsQuPOAm78FbloafdsEkUwh2ANAHeEP1l4Lwjmv45zLu+spABHu6NTBGMPJE8uxfOdBvLhkZ/gNZcek+hfnfQYMP8q4XVaJcbLM0ieAz+8Vj2Xqm7c91NUCiFF63kAxt0FOtFIZeIg2+aVDFNGKlonh94ib8vYt+o1ms4kORQZ9wwmBXLWts0lYFvI7SZeWYbnDXGPKqzNLHyXv/NL43NchRKWzUXxGdkZB15C0CLTzXTZO+HfDEW1ikhQwmbstsbuM5bLjWVSnYIhY6lBijhnIDkEVYTnKbatXgsUmiyCzUAuEah2lmjXkytM7VnlubHY9cG2OETx7mqjxr06Uqphh9PerHbK01tR5DJlFevVOSYfJrSWR8QCb0zjZat5nwC93iNfkeTKP+M3CYB68uPMV15D2O532F+Co263vk0hMu8L4e138AnDzKr3NOWXiHrRKk7UqeS0tPSA2IZCEE6skkEwhWAZgNGNsOGMsA8AlAN5VN2CMqcPaswBYzG/vHVx22FAMynfjN2+vweKtdai84wOsMQeQ5chDHfkOmha6VF52aWj5AYmcFenrNFYsfetGUU6iaY8YXeaUAlMuDv18+SRtgpKW7ZJTJgJspWEyFaRrKKdUL9TFbMKNI03irCLdZFazImw2vZPpaDQubygno0lcucY0RLtT3GxyBFUwVCk30K6n2lXMEDccs4sOfceXocFiILLgRcpLB/TqmR0miyBvoHHuhVU8ZeAhwDF3ALkWKZaHXa9bgyOOBU74nf5e0CJQOg55Lhfcrk8sC7qG8ozb21SLQBNKd75e9sFc1lh+trFKZPqoawy315usCnkMh7EzCgqBW29PwZDQDmuYVmTOPLFOuobMo/lB0/TvLq+HaC5Ns8vEnacLjfydplwIHP+b7qdgZmTrGVAqVgMDZtGlqqIVjxD0IEkTAs65D8BPAHwE0cG/yjlfyxj7PWPsLG2zmxljaxlj3wG4GcDVyWpPdynLdeO+Cw5BgAN3vClu0ucXm6wDOaoy1wcxjxKyS4AzHrBOlZN1Unwduhlft1Wknj19onhd5iGrN7vM0JAjmfu1Tt2VKwJsk863/mJ+r96RSBcMswPnPgGcdA9wxZtCXOTofsAk4+flDdx+0Bi3MKdYuvKs3VlyNFkwTM+68raL6qDMrrt9cspELaJnT9dXSlNzxQstblTJkseMz3/0qZjIJZEdR2uNMUZg7tytbvyjfw4ceydwW5gxjJyv4XCLiYdOkwDIztHm1PPdASF4gD6qlpaB/K1kh2Nz6J24u0C/ZqyEwJkl5nE8Msu4jkZrjal0giIEKlYWgTralcy9E7j1e2OAHNC/e6Q8enlPhCwAY4rdmONaqmuop9i7MvQ1NRYkMQTEe6cQWOSGJQ7O+QIAC0yv/VZ5fCeAO5PZhkQyfVgBHDaGnXXiZvticw0452ByRBScJGP6sc0msgyyHv8bMfpTsVtYBMGZu1qnIrMX1JHGNR+KDm35M8b9hbupJdI1BBj9tmWmfOdJ54m6P8f80ljnxyAEikVgvklcudb+08o5wI4vtBIU2g3zwCQhGjLACQBTL9PrAtVt1jpA5TvFU6fd6bZeWN5cMyfPJFxWQWdVjC56zvgc0I8j3QguLQ3X7BqSo+c5PwOWPi4qnNpdoQFx+TvKYDEPKEKQr1hLVhaBcl2qi+G01ho7MJtdXMPm0a0aI5DJDVZ57naHdYcoRc+cUaUiO03z7FvzrHgri6CnhWDaFWJC5I+XiBRUv8do7VzwT33OkCTdLIL+SFaGAzMrRcdXUZCJvY0d2NeodA5Bv6wNGHoEMPdX4rnZv+4O4wcF02IE0iIIk/YoA4+GkYZb3AzmWaDSGglX30TNGrLKoZZkFooywzLFUX0dAFY+Z3QNHVhrakeetc9z0DTxXy1JDIggrepamH2TXgembot1YP76L4DR2vT+sgnhfcMONywrYzbtNZ5zswVjmbKr7GfC2cYJR+b3gVBLILNAWIdXvS2ey46ks9E4gDALgRSWgF9/rPrJZUaW1bEBMUtZduKdTaEC5soJrVk19jTxf+hsUU0TiC+9UYpXjoUVIZEdvFkIzEH84ccYn7vyrONYyWTiuSLwXDZOnC+zy2vSecDoE9LbNdRf+efVs/DJ/xyN+y8WSy2u26t0DvJCtzmAaz8E5v5SPA+WA8gGrv1I7xDDTZ5xuCMLgZVrSDLpAuDwn+jPMyIIgd+rWQRO4zbhiobJtqnIAPC3z4vicnIkKgPNknALiI88DjjiZuE/N0/IU4Uyuxi4TitJ3bDLOq1u4BRhRQAid33CWaHbAOKzQ2aLx2oH6PcY1wAwTyCyijVEW+z+nMdEXrgcIcvfTB0xz7xGL23gcOkxJbeSdRPWIvDr80bc+WJxmHMfFy4rM+ZOSI0xmc+nKzd0VvG400VNrdKxeibNpDgCsXJORiQhkOfHfGyzRTvscDFHQeLON6an9ibIIuh/ZGbYMaosFxMG5YExYN2+JuzSXEVB89V80eaUAXP+B7j+czGaCu7MLATSn6xaBKZRtCNTH4WZMycAYY2UKaUCZAdiVejK02LtGoqUrcAYcPajwI1aymd+BXD638Tjg9v1UXztRuE/HneGeC5vgAuf1beX7TrpD8KfbHZnmC2mLG1yGQ+ET9Wd8zORKTLtCj091YwzS5T+/fE3YjlSIDTVEQh1DUmL56yHgRlXa98rSucz7HDgB+/p51+u3VA+Kfxn5ABBdaUFrU3t2qrU3HPFo40zmhkDDrnE+vc2u1ciCUFGjvU+ZJB68AwxGpYWXSzIa2PIrPDbyO8prZHBhwLH/q/1jFw19ubKs74fegMGy713tjGpMYL+TI7LgcribDz1xTb87eNNeOyK6TjFoZmvZiFgDDjhrtCdRLIIqjcIX/KIY4FtC/X3SkbrHbWVRQAYOzU1/9xMZ4spWGyR223FtMuNz8ecDMjqxoWVYnGTgE+IxPlPi6wU2eaJ54bfbySLABCdUN4gsUxkuIk29+Lu0gAAG/VJREFUrhwRewFELaM7dgH3mvzVmYWiPWXj9fNTNFz4ypv26EFqNfsL0C2CjCzg5D+KAH2lKTU4GnJUrC6laCarWFS5tAqAy85v2pXCPVI4TF82U1pD4ZBCNvAQEetRrz8riyBatlW8TLtCLEYTqZ0yfpA7SHSa2WXAMRbWjZkkreWbEFRBJYug/3H06BI0dYjO/+Wlu/Hudq2zk6PMaFgtIgIIn62cFGbel+qjDze6UF0K0jVklfroaQ3jGorzslB96YOm6WZ9XoXo3MNVrzRj/j5W0/Glu8YqGGqFO19YY2qnqlo88lw53PrEn0nnAT/6WJz7E38P3Pg1AKZPHHJqJTdm/KDrud4lFiWfJVKc1N968KHC5Xf2o/p3kHGAyRcAP3hfTEaMhEznnf1j4eYx1C+ycg0leJzIWHSxqpwDnPeUcBW6cnt3B98Vog2yUgRZBN3gpmNHYf7inXDaGT7fVIPPNwErRj6J/zvygth2IN0KZRP0muqAMVXO3wlMuQRY/54QBzW/OtxNoloE0mqwKi4X1jUUpxCoF/fAKcJF0VoTX7ldINTdk2VRwTMoBHFMvT/hLrH603Nnhy7ooy7wIkVBdoB2B3CkVqVVDfp2xxd94XxRUiNSByc7bHVGus0OnGyxxjIgOljzpEUrjvuNiGmM12InanDVfD6nXGRcAKinYEzk/wNidnYkF5oV5z0VmtBARIUsgm5QlufG0l8fjxd/pPv9391XAB7PKPHW74Effmx87dzHxEgUECO18x4XU+MB63Q9c3aL6luWbTEvwQhoQqC6hkwLd3eFAVP0ztZcpCsa5s7IyiKQ+wwXIwiHFLmQrCqlJINst9VI+Cglzbc7ueATz9Hr3YRDumSKEtyhFQwBzn9Smbtg1wPT5nM/8VzgyJsTe/x4OfNBYNZ1kbcZNscYC5pyoXAJEnFBFkE3Kct1ozhbv4kOtnmxtaYVo8piTGWzyrcuHCZGokMP10dEs64T+fOHXW/c9rqFesaJxCrwaeUaaqs3WgSSrpivpeNFbCBvkC5E5nZFwzzPIKJrKM5iXLL+jXllN9UikKmwVkJw/G+AL/4iHoeLzSSKkjGiTpRVEbhEE1y6sYdTLxPFNRZLbxJxQxZBArDbGOaMKkGGQ5zOez9cj9eWJ8CsHjJLH71llwAXPBNas6Ziemg6nttCCKx86i0HjPMIZKfQFb/3tR8Ct3wnPivbaK7WGI2MbJGJMlULRltaBDLNMk6LQM5gnvM/xtddSoxACoGV9QTos2hjWXO2O5z7GHDVOz2zOpWciSzTQYm0hCyCBDH/2lngnOOEv32OT9ZX45P11TjzkEFwO2McXY85VSzykQisRsuz5omOftFftdmnXEzaUoPFclQYKZAZjsxCpV6MdA3FKQSSgqH64j1mpGsnXosgb6AQGTNB15AiBOZlLyWXvQJ8fp+1FZdIMgujV41NNPGkgRLxM+GcVLcgIiQECcJuYwAY5h09Er9663sAwLNf78CSbXW49/wpKM+LMoK97JXkNtCRIdxNh90gnj88UxQg62jU/cQlo8UKScOODL+fWMgsEO6VSBOHInHEzaKkhJVlktdFiyAcQYsgU7dkwpWtrpgBXPavxBy3t/DDjwGwHq10mZZcZFlhv9dArqEEc+msIVh853HIcNhw74cbsHBjDX7//rroH+wp5OpWuQPFwva+djE5SDLmZOtSuvEw81p9PeGukJEVftSdVSQ67UQt2BGPRdAfGTILGBJjujPRbyEhSDCMMQzMz8RNc/XUvwXf78PehijLJSaaeZ8DP7WojijJHaDXzhl6RGKPXT5RTB5KBowBp/wJmH5VYvZnFSy2WsWLIPox5BpKErecMBqnTBoAl8OGuX/5DD95aSXuPX8KFm6oxriBeThmTJJXWhs0NfL7Mg21cHhoKYXezsxrErcvwzwCLWspnSwCggAJQVIZO0B0MmdMGYj3V+/DSfcvAiAql35461HIc1vUcukpZED3mF+mrg29gawiMW8is1CPF/TSejAEkSwYj1Y9sZcxc+ZMvnz58lQ3I24+WXcAv377e0walI//bhCrQ91z7iRcNmuovp5BT9LeAFQtEwucpztVy4U7y5kJLHsKGHVC6OpaBNHHYYyt4JzPtHyPhKDn4JxjV30bjvnzZ8HXLpgxGH+58JDUNYogiLQgkhBQsLgHYYxhWHE2fn3aeLx2w+GYPaIIb66sQk1zHIuiEwRBJBgSghRw3dEjcGhlEX5/9iQEOHD8Xz/D9tpWXPXMUjz++dZUN48giDSDgsUpZEx5Lq6cPQzPf7MTlz35DfY1dmDRJlGvfuyAXMwd28UJWQRBEHFAQpBi/nDOJDR3ePH2qr0AxAzlP324AW6nDU//4FDMGFYYe5kKgiCILkBC0Au47aSxGFyYhStmD0NepgPf7mrA5U8tweVPLcFJE8rxx/Mmo9MXQEWBsXBcQ5sHHn8AZbkJKrdAEERaQllDvRBZvG5rjViljDGxnshfLzwE588YjKe+2IZFm2uDbqQd956eyuYSBNEHiJQ1RBZBL4Qxhvd+Ogcuhx2vLt+NbTUteOvbvXj6y+2YNbwId3+w3rB9dXNH0Cro8Prx5eZaHD++LDXzEwiC6HOQRdBHmP/1Dtz17tqw788ZVYLjxpXBaWf4zTtr8cIPD8Oc0SVhtycIIr2geQT9gIsPHYLrjxErVrkcNnx069G44ZiRKMsVVTi/3FKL37+/Di8tFQvivLxsV8raShBE34Isgj7Gqt0NcNoZJg4SBdKaO7zIdNqx6UALLnzsa7R69IXvjxhZjI37m/HQpdNw5KgS7Gtsx7ur9mJmZSFmDCtK1VcgCCIFkEXQj5g6pCAoAgCQ63bCYbdhwqA83HaSWFns/Oli8Zavt9ahod2LG15Yge92N+CyJ5fgTx9uwI9fXAl/QAwAtte2YvofPsZXW2p7/ssQBNErIIugH8E5x6LNtZhVWYRfvrEaA/LdOHPKIJz58JcAgFyXA+dNr8D8xTsxqSIP9180FQ/8dzM+WL0POS4H/njeZJw0oRzNHT40tnuQmeEISVklCKJvQkXn0pxbXvkWje1e/PmCQ5Cf6cQJf/scu+rbLLcdXJiJqoNiEZ2sDDvW/f4UtHv8uOCxr/HDOcNx3vQurkNMEERKISEgDHDOUdPSiae+2A63w4YrD6/EW99WYXd9O57/Zqdh22uPHI5nvtoOAMjOsGPFb07EluoWTBiYB8aAZTsOIttlx9o9TTh50gB0ev3IdjmQ7RKZyf4AR2O7F0XZGT3+PQmC0CEhIGKisc2L655fjiGFWfh210Fsq20N2SbH5UBLpy/ifvLcDrz30zlYuKEajy/ahroWD7751fFBMfhg9T7c++/1eOiSaZg2tDAp3yVRNHV4U7uAEEEkCBICoku8s2oP/rVsN+67YApaO/04+QGxwtqQokzsrm9HUXYGzplaga01LRg/MA+PKZVTB+S5sb+pw7C/iYPyMG1oAV74RqS2Xn7YUNxz7mTLY3+87gAa2jw4YXw5GBOWRXGOSJX1+gN4ackuHD++DIMLk7ea2Ndba3HZk0vw3LWzcHSylxYliCRDQkAkhKqDbdhR24aZlYV44ZudOHdaRbBzBoBXlu5CRWEmHl24FYu31WHGsELMv3YWfvavVdhS3YLSXBeWbq8HAIwbkIsN+5vxzk1HYsP+JuS4nHA5RBLbwwu3YNXuBsOxB+S58ey1h2LhhhrYbcAfF2wAAPzk2FG46vBh+HJLLc6eWgG7TcymrmnuxI/mL8OEQXm468yJcDvt6PD68d/11chxO3DkyGI47KFJc9XNHbh3wQbMHVeGm1/+FgBwxeyhuPsca8HqLgdbPahu7sSY8pywM8H9AR78XgTRVUgIiB5l/b4mfLWlFpfMGooclwP+AIeNidIZTyzaik5vAKPKcnDjiysj7ucP50zCw59uxoEmsXCP087g9YvrtSTHhUMrC/Hhmv3B7R+8ZCpcDhv+8P56VDd3BLf96XGjcNrkgfjdu2uxRBOi6UMLMCDfjcVb6zB+YB4CnKO6qRO7D7YFPycZU56DG+eOhD8AlOW68Ory3Th54gCcecggAEC7xw+30wbGGJo7vHh1eRUunDk4xKW0ancDRpfl4LuqBpTlumC32XD+P75GfasHZ0wZiL9edAj8AY5Mpx2MMXT6/Hhk4Va88M1O/PXCQzB9aCHys5zYuL8ZuW4HBpkyuto9fsx7fjlOmlCOK2YPwzXPLsOs4UX48dxR8f6EQTy+AD7dUI3SXBdsDHhn1V7cfvJY5Lisq9M0d3iRneGALQ7haurw4r5/b8DNx41GWZ4oldLm8aG5w4fyvK4VVGxo86Agq2txKc55UsuzdHj96PD6u9y+rpIyIWCMnQLgQQB2AE9xzu81ve8C8ByAGQDqAFzMOd8RaZ8kBP2H3fVt+OH8ZRhdlot5R49Aa6cP+xo7MGNYITp9AYwdkIuGNg9W7W7AL15fjWHFWfjBEZXYWdeGC2cORlmuG/9Zux+fbarBS0uMM6kLspx45LLpeHX5bryjlfgGgNtPGoMMhw1/XLABjAGnTR6IDfuasLWmFSU5LtS2CNEpzs7AY1fOwBeba/HQfzeHtD3P7cC7P5mD+Yt3YP7XOzB5cAGKspxYuFEUArQxYGZlEWYPL0JBVgZ21bfh2a93BD9fmutCp1dM/jtp4gC8vqIKsyqLsPFAM86dVoGjRpfgl2+sRm2LJ/iZrAw7jh1bhg++34eKgkz87aJDcKC5E6dMHIAMhw1/WrAejy/aBhsTFW3//NFGAMCvThuHLzbXYvrQQlx/zAhkZQhx3lrTgrJcF1wOO9bsbUS7x4+SHBfaPD5MG1oIGwNueWUV3v1OP38A8LMTxuCWE0YHnze2e/HnjzagIDMDT36xDcePL8Ojl8/Ayl0HUZDpxIjSHABAIMCxYX8zxg/MNXS09/17Ax79bCtOnFCOG44ZgYmD8nHV00uxdEc9Dq0sxK0njMHgwkw0tnvxzJfb8ZPjRmNUWU7w8yt3HURlcXYwBvX//r0Bj3++FQ9eMg0nTSxHht0WsWP3Bzi+2FyDAfluuBx2XPHUEtx52jicMWUQdte34Z9f7cDZUwdhZFkO3v52D86eOgi5ish3eP3IsNsM4sc5R4DD0pK74qkl+HJLLcYNyMVPjxuNvEwHjhqdfNdjSoSAMWYHsAnAiQCqACwDcCnnfJ2yzY8BTOGc38AYuwTAuZzziyPtl4SgfxEI8JhGj+qo24rlO+rx4H83Y8LAPNxywmg47TY47TY0tHlw1TNL0e7x44mrZmJ4STYAYOP+ZmRl2DGkKAuBAMfug20YmJ+J+z/ZhHOmVmB4STYyHDa0e/xYtqMegwoysWZPI95ZtQfXHDkcP5q/HB5/AABw+Ihi7GtsR4c3AF9ACNjmAy0ozMrAxgPNwTaOKstBY7sXrZ0+tHv9mFKRj79fOh1Di7Pwxooq/OKN1cGJfgAwsjQbNx07Cg67DY9/vhVr9zaBMaAwKwPNHV6D5TKiNBs7altx9tQKfL+nEVuqWwCIuMzavU2GczUw342WDh+aIwT9T5pQjpJcF15asgvXHjkcxTkZ4Jzjqy11WLW7AZcfNhT1rR6MGZCLt7/dgw37mw2fH5jvxr5GESOaMjgfVx9RiS+31OLNlXtw7NhSdHgDmDw4H6NKc3DXu2vR7vVbNcMSt9OG8QPzMKYsF82dXiz4fj9Glmbj+mNG4pN1B/CfdQeQ63aguUN8v4qCTBwxshiHjShGgHPMGFYIjy+AN1ZU4bNNNXA7bVizR5wju43BH+DIsNtww9yReG357uD3kLgcNlw0cwjyM53451fb4fEHMGVwAX5y3CgMK8rCZU8ugS8QgMthx93nTsITn2/DTceOwpCiTGzc34x5z6/AaZMH4ItNtcHfYMrgfAwpzMJhI4pQkuPC5Ip8ePwBDC7MREuHD0u312NrTQtOmjgAY8pzYz5XKqkSgsMB/I5zfrL2/E4A4Jz/SdnmI22bxYwxB4D9AEp5hEaREBDxEghw+DmH0yIm0FV21bXho7X7wRjwwznDLQWKc451+5pQnueGnTEUZDnR5vGjpdMHjy+AAfluQ5tW7W6AxxfAsh31qCjIxKmTB8Dl0Bcl2tfYjvxMJ/wBjqqD7fho7X4MLszCjtpWrNx1EI3tXrx03Ww0tXvx1BfbMLEiH+dNq8CS7fXIczvxzqo9aPP6Ud/iQV6mA0OLsuD1c2yubsasyiKU5bnR5vFja00Lnli0Df4Ax+mTB+Lvl04LinV1cweufGoptta0IMftQEObFwBw3VHDUVmSjaZ2H5o6vPh6ax3aPT4cPqIYn6yvxp6G9uD3yMqwIz/TGexgJ1fk464zJ+DTDdUYWJCJxz7bijMPGYRfnDwWB5o78NzinRheko2q+jbMqCzCR2v3Y1tNC9btbUKHN4BLZw3BGyv3BLPZjhhZjMeunIHXllehoc2DzQdasHhbHRrbvSG/0YiSbHR4/Zh39AjkuJ1Ytr0eAwvcWPD9Pmw60IJhxVn41WnjsXxHPZ78QqRRTxiYh3X7hHAwBkwZXIBN+5sNYjZ1SEFInCt4zNJsLLj5KHy1pRYPfLIZ04YWYNOBZuyqa8Nek+iYuXHuSPzylHERtwlHqoTgAgCncM5/pD2/EsBhnPOfKNus0bap0p5v1bapNe1rHoB5ADB06NAZO3cac90JgkgsrZ0+HGzzoKIgM0TkOOfw+jkYA+paPMjMsCPXFT4u0ObxYVtNK4pzMjAwPzNoBe6ub8PehnbMrCzqUjDcH+Do9PmRleHAwVYPttS0oLI4G/mZTmQ4bCHbbq5u/v/t3X2MFPUdx/H3x5M7QYiIUiRwEbAkLTVCaTW2PsRotEKbYhOMpNaSpk2TVpOapqkQrbUm/aNN+piYYh+oqFipVCIxNq0CofUPeVCPJxW5Aq1Q6lmqV88WUPj2j/ktbJe7k6XMzNL5vJLNzfx2bvdz39u9385v5n7D3r4DdPf0May9jamdIwf9dF2bx6t2UkF3z5t0jhpGx6ltbNrVy/a/93HNlHMY2p6diPBY1266XullzoWdTO0cyR+3vcb6na9z9ZQxbPlrLwcOBn/Z+xZfuGxSv8c+IoI9vfv4895/sWbHXs4c1k7vv99mWHsbQ9pOYcb55yCJ0SM6jvreY3HSdwT1vEdgZta8siad2w101q2PT239bpOGhs4gO2hsZmYFybMjWAdMljRRUjswB1jesM1yYG5ang2sHOz4gJmZnXi5XaoyIt6RdAvwO7LTRxdGxBZJdwPrI2I58AvgAUndwD/IOgszMytQrtcsjogngCca2u6sW94HXJ9nBjMzG5wvTGNmVnHuCMzMKs4dgZlZxbkjMDOruJNu9lFJrwHH+6/FZwOtepX2Vs3mXM1xruY4V/OON9u5EdHv7HYnXUfwv5C0fqD/rCtbq2ZzruY4V3Ocq3l5ZPPQkJlZxbkjMDOruKp1BD8tO8AgWjWbczXHuZrjXM074dkqdYzAzMyOVrU9AjMza+COwMys4irTEUi6VtJWSd2S5pWcZaekTZK6JK1PbaMkPSlpW/p6ZgE5FkrqSRcIqrX1m0OZH6f6bZQ0veBcd0nanWrWJWlm3X3zU66tkj6WY65OSaskvSBpi6SvpPZSazZIrlao2WmS1krakLJ9K7VPlLQmZViSpqpHUkda7073Tyg4132SdtTVbFpqL+z1n56vTdLzkh5P6/nWKyL+729k02D/CZgEtAMbgCkl5tkJnN3Q9l1gXlqeB3yngByXA9OBze+WA5gJ/BYQcDGwpuBcdwFf62fbKen32QFMTL/ntpxyjQWmp+URwMvp+Uut2SC5WqFmAoan5SHAmlSLXwNzUvsC4Etp+cvAgrQ8B1hScK77gNn9bF/Y6z8931eBh4DH03qu9arKHsFFQHdEbI+IA8DDwKySMzWaBSxKy4uA6/J+woj4A9l1II4lxyzg/sg8A4yUNLbAXAOZBTwcEfsjYgfQTfb7ziPXnoh4Li2/CbwIjKPkmg2SayBF1iwioi+tDkm3AK4Elqb2xprVarkUuEpS8xc0Pv5cAyns9S9pPPBx4OdpXeRcr6p0BOOAV+rWdzH4GyVvAfxe0rOSvpjaxkTEnrT8N2BMOdEGzNEKNbwl7ZYvrBs6KyVX2gX/INknyZapWUMuaIGapWGOLqAHeJJsD+SNiHinn+c/nC3d3wucVUSuiKjV7NupZj+QVLtSfJE1+yHwdeBQWj+LnOtVlY6g1VwaEdOBGcDNki6vvzOy/bzSz+ttlRzJT4DzgGnAHuB7ZQWRNBz4DXBrRPyz/r4ya9ZPrpaoWUQcjIhpZNctvwh4Xxk5GjXmknQ+MJ8s34XAKOC2IjNJ+gTQExHPFvm8VekIdgOddevjU1spImJ3+toDLCN7c7xa29VMX3tKijdQjlJrGBGvpjfuIeBnHBnKKDSXpCFkf2wXR8Sjqbn0mvWXq1VqVhMRbwCrgI+QDa3UrpBY//yHs6X7zwD2FpTr2jTMFhGxH/glxdfsEuCTknaSDWFfCfyInOtVlY5gHTA5HXlvJzuosryMIJJOlzSitgxcA2xOeeamzeYCj5WRb5Acy4HPprMnLgZ664ZDctcwHvspsprVcs1JZ09MBCYDa3PKILLrbL8YEd+vu6vUmg2Uq0VqNlrSyLQ8FLia7BjGKmB22qyxZrVazgZWpr2sInK9VNehi2wcvr5muf8uI2J+RIyPiAlkf6dWRsSN5F2vE3mku5VvZEf9XyYbn7y9xByTyM7Y2ABsqWUhG9dbAWwDngJGFZDlV2RDBm+TjTt+fqAcZGdL3JPqtwn4cMG5HkjPuzG9+MfWbX97yrUVmJFjrkvJhn02Al3pNrPsmg2SqxVqdgHwfMqwGbiz7n2wluxA9SNAR2o/La13p/snFZxrZarZZuBBjpxZVNjrvy7jFRw5ayjXenmKCTOziqvK0JCZmQ3AHYGZWcW5IzAzqzh3BGZmFeeOwMys4twRmBVI0hW1GSXNWoU7AjOzinNHYNYPSZ9J89V3Sbo3TVDWlyYi2yJphaTRadtpkp5JE5Ut05HrEbxX0lPK5rx/TtJ56eGHS1oq6SVJi/OYXdOsGe4IzBpIej9wA3BJZJOSHQRuBE4H1kfEB4DVwDfTt9wP3BYRF5D912mtfTFwT0RMBT5K9t/SkM0OeivZdQEmkc0vY1aaU999E7PKuQr4ELAufVgfSjaR3CFgSdrmQeBRSWcAIyNidWpfBDyS5pMaFxHLACJiH0B6vLURsSutdwETgKfz/7HM+ueOwOxoAhZFxPz/apS+0bDd8c7Psr9u+SB+H1rJPDRkdrQVwGxJ74HD1yQ+l+z9UpsB8tPA0xHRC7wu6bLUfhOwOrIrhe2SdF16jA5Jwwr9KcyOkT+JmDWIiBck3UF2FblTyGZBvRl4i+wCJneQDRXdkL5lLrAg/aHfDnwutd8E3Cvp7vQY1xf4Y5gdM88+anaMJPVFxPCyc5idaB4aMjOrOO8RmJlVnPcIzMwqzh2BmVnFuSMwM6s4dwRmZhXnjsDMrOL+A//KE32DGxh8AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.plot(cnnhistory.history['loss'])\n",
        "plt.plot(cnnhistory.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'valid'], loc='upper left')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "YlkBpKyX3El2",
        "outputId": "c0432658-5c5b-4eee-d55e-f615add47657"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOydeXhU1d34P2cmk0z2hIQQloQdZBFBEPd9RcWt7rWt9m1tXVqXtm+Xt4tt7War7c/axWqrthaXWrdad8UdF1QEBAREIAECgZA9k9nO749zz9w7d2aSScyQwJzP88wzM3c9995zv9/zXc45QkqJwWAwGLIXz2AXwGAwGAyDi1EEBoPBkOUYRWAwGAxZjlEEBoPBkOUYRWAwGAxZjlEEBoPBkOUYRWDIKoQQdwshbkxz241CiBMyXSaDYbAxisBgMBiyHKMIDIa9ECFEzmCXwbDvYBSBYchhuWS+JYRYLoToEEL8VQgxQgjxlBCiTQjxvBCi3LH9GUKID4UQzUKIl4QQ0xzr5ggh3rP2ewDwu851uhBimbXvG0KIWWmW8TQhxPtCiFYhRJ0Q4gbX+iOs4zVb6y+1lucLIW4WQmwSQrQIIV6zlh0jhKhPch9OsH7fIIR4SAhxrxCiFbhUCDFfCLHEOsc2IcRtQohcx/4zhBDPCSGahBDbhRDfE0JUCyE6hRAVju0OFEI0CiF86Vy7Yd/DKALDUOUzwInAFGAh8BTwPWA4qt5+HUAIMQW4D7jWWvck8B8hRK4lFB8F/gEMA/5lHRdr3znA34CvABXA7cDjQoi8NMrXAXweKANOA64QQpxlHXesVd7fW2WaDSyz9vsNMBc4zCrT/wLRNO/JmcBD1jn/CUSA64BK4FDgeOBKqwzFwPPA08AoYBLwgpSyAXgJON9x3M8B90spQ2mWw7CPYRSBYajyeynldinlFuBV4C0p5ftSygDwCDDH2u4C4L9SyucsQfYbIB8laA8BfMDvpJQhKeVDwDuOc1wO3C6lfEtKGZFS3gN0W/v1iJTyJSnlCillVEq5HKWMjrZWXww8L6W8zzrvLinlMiGEB/gicI2Ucot1zjeklN1p3pMlUspHrXN2SSnflVK+KaUMSyk3ohSZLsPpQIOU8mYpZUBK2SalfMtadw9wCYAQwgtchFKWhizFKALDUGW743dXkv9F1u9RwCa9QkoZBeqA0da6LTJ+ZMVNjt9jgW9YrpVmIUQzUGPt1yNCiIOFEIstl0oL8FVUyxzrGB8n2a0S5ZpKti4d6lxlmCKEeEII0WC5i36eRhkAHgOmCyHGo6yuFinl2/0sk2EfwCgCw97OVpRAB0AIIVBCcAuwDRhtLdPUOn7XAT+TUpY5PgVSyvvSOO8i4HGgRkpZCvwZ0OepAyYm2WcnEEixrgMocFyHF+VWcuIeKvhPwBpgspSyBOU6c5ZhQrKCW1bVgyir4HMYayDrMYrAsLfzIHCaEOJ4K9j5DZR75w1gCRAGvi6E8AkhzgHmO/a9A/iq1boXQohCKwhcnMZ5i4EmKWVACDEf5Q7S/BM4QQhxvhAiRwhRIYSYbVkrfwNuEUKMEkJ4hRCHWjGJtYDfOr8P+D7QW6yiGGgF2oUQ+wFXONY9AYwUQlwrhMgTQhQLIQ52rP87cClwBkYRZD1GERj2aqSUH6Fatr9HtbgXAgullEEpZRA4ByXwmlDxhIcd+y4FvgzcBuwG1lvbpsOVwE+EEG3AD1EKSR93M3AqSik1oQLFB1irvwmsQMUqmoBfAR4pZYt1zDtR1kwHEJdFlIRvohRQG0qpPeAoQxvK7bMQaADWAcc61r+OClK/J6V0ussMWYgwE9MYDNmJEOJFYJGU8s7BLothcDGKwGDIQoQQBwHPoWIcbYNdHsPgYlxDBkOWIYS4B9XH4FqjBAxgLAKDwWDIeoxFYDAYDFnOXjdwVWVlpRw3btxgF8NgMBj2Kt59992dUkp33xRgL1QE48aNY+nSpYNdDIPBYNirEEKkTBM2riGDwWDIcowiMBgMhizHKAKDwWDIcva6GEEyQqEQ9fX1BAKBwS5KxvH7/YwZMwafz8whYjAYBoZ9QhHU19dTXFzMuHHjiB9oct9CSsmuXbuor69n/Pjxg10cg8Gwj5Ax15AQ4m9CiB1CiJUp1gshxK1CiPVCTUl4YH/PFQgEqKio2KeVAIAQgoqKiqywfAwGw54jkzGCu4FTeli/AJhsfS5Hja3eb/Z1JaDJlus0GAx7joy5hqSUrwghxvWwyZnA363Zo94UQpQJIUZKKbdlqkyG7CQcUVMC53gHrt0TjUo6gmGK/QMbq5FSsnZ7O1NGFPVJ6Xd0hynMS+91Doaj5HgEHk/q43eHI0gJfp83Yd36HW2U+H1UlfhZtbWVxvZujphUiddxvEAoQl6OByEEn+zs4KWPdjBjVCnzxw+jMxhGIHhq5TaiEhYeMJJcr4dQRJKbk/4zCoajhKNRCnJz2NXeTW6Oh81NnUwcXpRQ7q5gBK9H8OHWFlZsaUFKWDCzmqoSf1rnklKyalsr+1WX4PUIltc3M6wwlzHlai6haFTy7KrtgOTE6dV4PYL1O9rZ0tzFtOpiltU1M7w4j9Xb2jhv3hh8KepiS2eIdTvaWLu9nRyPwOsRTBheSGVRHh3BMJOriuPu80AxmDGC0cRPvVdvLUtQBEKIy1FWA7W1te7Vg05zczOLFi3iyiuv7NN+p556KosWLaKsrCxDJdt36AyGKchNXV2llDz83hZmjC5hv+qS2PLl9c1cdtc7HD11OD88fTplBbk9HmPlllZmjCqJCclwJEp3OBonZHe1d/P5v73Nh1tbOX/eGG469wDqd3fS2NZNZzDC+MpCtrcG2NYS4NYX1nHVsZPY3hrg5BnVDC/OoysY4d/v1XPGAaNigmhbSxe/f3E9HzW08e6m3Rw9ZTiXHzWBwydV0hWMIIQt7KNS8u/3tnDnqxsYU57PhsYOGloDfOmI8fzfadOp393Jna9+wpzaMg6sLeftT5qQwOI1O2jqCPJ+3W6qS/zMqS0nEpWMrSjghGkj+OVTaxhWmMukqiLuWbKRzu4Ivz5vFmfOHh279jUNrZxx2+sEw1FK8320dKn57r9y1ATOmzeGuqYuvvPwcna1BynI9TJheBHL65uJWkOaHVBTxrrtbXQGI7Fj3vHKBg6oKeWJ5dv43KFjeW7Vdq4/cQoThxexaVcHj76/lUlVRTy3ajvjKwtZt6ONYYW5rNzSSmm+j2tPmMz/PbqSiHWSBTOrufWiOfzsv6uZMaqElq4QNz+7loiUBMPR2HlveW4tVcV5VJf6ufrYSbz9SRMtXSFmji7l9lc20NDSxWETK/nSkeP593v13PvmZnK9HvJzvbHrnlNbxvxxw1j80Q7Wbm8HYMLwQorzcvigvgWAHI8gHLXHdFu/o50fLpzOg0vruOeNjRw+qZIRJX6eW9XAmxuaUtZPgO+fNo0vHZl04rlPRUYHnbMsgieklDOTrHsC+KWU8jXr/wvAt63JQlIyb9486e5ZvHr1aqZNmzZQxe4zGzdu5PTTT2flyvhwSDgcJidn4HXtYF/vQNEdjvD3NzZxzNThjCrLJyplQgv7yRXbeHHNDv7zwVZOmDaC606cQl6Oh5phBXHb/WHxen79zEfk5nj4wqFjKfH7+Nrxk/nC397m5bWNse2euuZIvB7B3W9spLM7zNXHTWbFlmZK833sag/yrYeWc+zU4Zw5ezRnzRnNzc9+xO9fXM/cseUcP62Ks2aP5t/v1nPzc2uZU1vG+5ubGV2Wz872brotIePzCkIR9V55BDEhOLw4j6K8HD7Z2QFAZVEet108h0MmVHDB7Ut465NEIXDdCVN4YvlWNjd10h2OUuJX9ak1EEYIcL++Nyyczs+eXB07v5t5Y8sZW1FIXVMnG3Z24PMKtrWomFNhrpdAOEokKjl6ynA2N3Wys62bX35mFs+uamDJx7vY0dYNwAXzavD71HN4dd3OuHsMcMYBo3jmwwZGlvpZeMAozjlwDNc+sIwP6pqZMqKIzmCEq46dREVhLlcvep9gxBbQxf4cOoORmGD3+zwEQvb6glwvM0eVMrGqiH8trSMclVQV53Hs1Cr+9W4dUQkl/hxaA+HYPkdNGc7UEUUU5Oaw8IBRMWUJSrntbA/GlX9SVRGza8p4/IOtccpDn//zh47D5xU8t2o7axraGF2Wz3cW7EdnMMytL6ynqSNIRVEup+0/kudXb+eaE6bwSWMHSzc18eq6nVx17ET+sDh+SunqEj8Xza9lbEUBYysKkIA/x8uKLc3c93Ydo8vy+fnZ+1Na0D8rVAjxrpRyXtJ1g6gIbgde0vPDCiE+Ao7pzTU0FBXBhRdeyGOPPcbUqVPx+Xz4/X7Ky8tZs2YNa9eu5ayzzqKuro5AIMA111zD5ZdfDtjDZbS3t7NgwQKOOOII3njjDUaPHs1jjz1Gfn5+0vMN9vX2xi+eXM27m3Zz75cOjjPRpZT89InVTBheiNcj+O7DK2LrCnO9RKTk4vljGVdZwIG15VQU5XLoL15Meo6nrjkSv8/LpXe9zaZdnQBMGVHElt1ddFitzTNnj+KxZVs5fr8qXlizA4Bz5ozmyZXb4gRLKiYMVwIzFJHsP7qUFVtaYusOm1jBbRcfyNwbn0NKOG3/kUwZUczjH2zh48YOjtuviuP2q+LY/ap4f/Nulm7czd1vbASgrMDHhQfV8uyqBjY0dnDQuHLe2bib8+aO4V/v1nPTubM4avJwbvzvKp5Yrl6HSVVFVBXn0dIVIscjmFNbzhcPH09nKExLZ4hxlYUcddNiusNRxlYUsHDWKG5bvB6AWy+aw71LNnHu3DGcf1BNwnU+t2o7v31uLTedO4vqUj/BcJRRZfms2trKJX99i6YOJSRzvR6CkSj3fHE+R0+xh6xp7gzy2+fW8vzqHWxp7uKEaVXc+YWDaOkKUZSXE3NlbG8N8Oyq7Vx0UE2cm+76B5bx8Ptb+NbJUzlkwjDKC3I57uaXATiwtozfXjCbsvxc6nZ38sA7dXzv1Gnk56p69fTKbTz+wVa+evREZo0pIxKVXP/gMp5a0cBVx05iwvBC2gJhLjioJqVLpTMY5skVDYBSlM982MCFB9VSWuDjrQ27eHBpPdeeMJlwVPLX1zbw7VP2i2uwLN3YxOSq4jgBHQhFiEqZYMWGIlG+ePc7vLpuJz6v4FefmcXM0aXK1Vac16O77tMyVBXBacDVqCn9DgZulVLOd2/npjdF8OP/fMiqra2fuuxOpo8q4UcLZ6Rc77QIXnrpJU477TRWrlwZS/Fsampi2LBhdHV1cdBBB/Hyyy9TUVERpwgmTZrE0qVLmT17Nueffz5nnHEGl1xySdLzDQVFEInKuBerOxzh2vuXcfac0Vz+j3cB+OLh4/nhwuksXrOD//fCOpo6gmxuUkL75BkjeObD7Xz7lP14bNkWpo1U7pzHlm0hmqJKjir1s9Vqvc4dW86OtgBtgTDTqkv4aHsbT379SEKRKPe+uYnbX9kQ2+/+yw9heHEe33jwA5bVNeP3eXj++qN5dd1O6po6OWP2KF5bt5PtrQHmj6/gzlc3UJDrZfFHqpV76WHjuOGMGSyra+asP7weO+YhEyr4ZGcHwwpyY0IgEpV83NjOlBHx0x5LKXnrkyamjiimvFC5pzbt6uCU371KIBxh+sgS7rv8EHI8IiY8wpEoT3/YQCQq49wzqXhqxTb++NLHfOvkqYyrKOSoXy9m3thyHrrisF73TUU4EuWu1zfi93k4b14Nm3Z1MrU6+ZTO0nJZHTW5Mm3fO0B7d5jHl22NE9ZfuucdpIS/XnpQn8sspaQrFOnRlTiYSCl5b3Mz1aV+Rpclb+xlgp4UQcbulBDiPuAYoFIIUQ/8CPABSCn/DDyJUgLrgU7gskyVZU8zf/78uDz/W2+9lUceeQSAuro61q1bR0VFRdw+48ePZ/bs2QDMnTuXjRs37rHypkNXMMKtL65jd0eQKSOK+eXTa7jymIlUl/gJRqJsbQ7w1MoGXnG4CP6+ZCNTq4v40eMfMqo0n/3HlOL1qODhMx9u59T9q7nimIlccczE2D4/PWsmDS1dnHbra3SHo1QU5nLwhGEcOrGS4rwcnl+t/MS/f1G1dh++8jAOrC0nHInGWpnfPXUaXaEIJX4f00eVcPD4YQghuPyoCdzx6ga+ePh4xpQXcNF8O97kjCucOH0EACf99mXWbm9n5uhSAGbXlPHoVYfHfgOMryyMu09ej0hQAqCyvQ6ZEP/Mx1YU8ux1R1GUlxNTDk5yvB5OnzWqlydjs2D/kSzYf2Ts/58vmcv88cPS3j8ZOV4PXz7K9kmnUgKgrvHcuWP6fI6ivBwuPjg+9veXzyWVV2khhBiySgBU+eaOLR/sYsSRyayhi3pZL4GrBvq8PbXc9xSFhbZweOmll3j++edZsmQJBQUFHHPMMUn7AeTl5cV+e71eurq69khZnayob+FbD33AjFGlFPtzGFnq578rtjGsMJePG9upa4ov0++eX5dwDO2W+fMlc/nNsx/x7X8r988fLzmQ/apL2Nnezbwbnwdg6oiShP2L8nKYVFXMa98+jpL8HHK9nrjsmbPmjKalM0QwEmXhrFExIe3OCPrJmQlGKKfuP5JTHYKyNz53yFh+8NiHHDCmNLZMK4CBwh3rGEhOmVmdsWNnmky6SAyJDF21uRdRXFxMW1vyGf9aWlooLy+noKCANWvW8Oabb+7h0sHKLS1UleRRVRxvrn/jwQ8oyPVywxkz+Oa/PuCR97cAsKYh+bVMHVHMdSdO4av3vsvIUj9fPHw8R08dztfve581DW385MwZ/PCxDynOy+GYqcM5YVoVt7+ygY7ucKzFXVmUF/O3T6oqSlnm4cV5KdeVFvj47oLMu8YuOWQsJ82oZkQf3BwGw96IUQQDQEVFBYcffjgzZ84kPz+fESNGxNadcsop/PnPf2batGlMnTqVQw45ZI+U6YF3NjO7ppyxFQWc/vvXAFj545OJSsl5f1pCab6PtzeqLJXV21pZumk3J88YwdKNu9nVYWdQvPiNo3lgaR23v7yBsRUFnDR9BDcsnM4pM0dSXaoE5ANfOZT1O9o5sLaMScOLmFVTFgsSX3XspISy/emSA/n1Mx9x5JTKTN+GT4UQwigBQ1aw181ZPBSzhvY0PV2vlJLWrjAH/ORZ8nI8/PmSuVx29zsAfHfBflSX+rnm/mWASlcryc9h7fZ2DptYwT+/dDCL3t7Mz/+7mo5ghANry3j4ysMJhCL89IlVXH7UBMZWFCY9r8FgGNoMSrDYsGeJRCWX3vU2b33SxPUnTgGgOxzlsrvfiQUwH122lYnDC6ksyuWZa4+iIDeH51Zv5+v3vc+Xj5qAEIKL59dy3twatjZ3UWm5Z/w+Lz87e//BvDyDwZBBjCLYS5BSIqUdRNvQ2M6mpk6OnVoFwNufqI4qAP/PFcT9xTn70x2O8oNHV7J6WyufP3QsFUVKyC+cNZLpI4uZVKWyQYQQ5OYIxlWalr/BkC0YRTDE6egOE4lKwlFJ/e7OWND1xN++QiQqWXvjAl5e28iX/76UXK8Hv89DayDM9JElnDCtis8fNo7KojzCkSjLNjezvrGd/z1lv9jxhRAxJWAwGLITowiGOBt3dhBxxHHWNLTSFQjFut9P+f5TsXUXH1zLc6u20xoIc+H8Gj5/6LjYuhyvh5vPP2CPldtgMOw9GEUwhIlEZZwS0LR2heP+nzd3DDecMYPCvByqS/388qk1afVENRgMBjCKYEgQtVw/egheKSWbmzpj3e2L8nJo7w5T4vchBGx37X/TubNina6+ctQELj1sXNLhgw0GgyEZZvL6QaCoSHWk2rp1K+eeey51uztZ09Aac/e0d4c59/STefWNtxBCUDusgMqiPEaX5zOqLB+PUML/31ccyjPXHhXX81YIYZSAwWDoE8YiGERGjRrFQw89xPL6ZgBaAyEExAZm83oEY4cVkOP1MMoxONWosnyOn5Y4iqTBYDD0B6MIBoDvfOc71NTUcNVVauikG264gZycHBYvXszu3bsJhULceOONnHnmmXH7fbzhExacehoPPf8Gga4uPvfZL7F65QrGTZyMDAcZX1lISf7AzoBlMBgMbvY9RfDUd6BhRe/b9YXq/WHBL1OuvuCCC7j22mtjiuDBBx/kmWee4etf/zolJSXs3LmTQw45hDPOOCPOjdMZDBO1gsGPLLqbnFw/jyx+i9YtH3PM4Qeb+YmHGm/8Hl7+NXx382CXxGAYUPY9RTAIzJkzhx07drB161YaGxspLy+nurqa6667jldeeQWPx8OWLVvYvn071dX2iJAd3Xb2z8p33+SCSy+nqsTP/qMPZNasWYNxKYaeePb7g10CgyEj7HuKoIeWeyY577zzeOihh2hoaOCCCy7gn//8J42Njbz77rv4fD7GjRtHIBAgFIkipRrorbkzhNcjmDlajdM/qiyfajPI2dAnGgWPybMw7DuY2jxAXHDBBdx///089NBDnHfeebS0tFBVVYXP52Px4sVs2rQJKSW7O4NI1JR1xfk+fF4PHiE46qijWLRoEQArV65k+fLlg3tBhtREw71vYzDsRex7FsEgMWPGDNra2hg9ejQjR47ks5/9LAsXLmT//ffnwAPnMmnyVDY0tjPcpyalGVdRyK6Q3fq/4ooruOyyy5g2bRrTpk1j7ty5g3Upht6IhoDEGcUMhr0VowgGkBUr7CB1ZWUlS5YsQUrJuh3tBEIRcr0ecnM8bGtsoiTfR8n48axcuRKA/Px87r///sEquqEvGIvAsI9hXEMZpiMYIRCKUFNewH4jS5gwvIjSgiStyfYd0LlrzxdwbyMahUeugLp3Bq8MEaMI+sW25fDQ/wzs/Xv51/CBaUB9WowiyABSSjbv6qQtEKK5M4hHCEp76w/QuQu6du+ZAu7NBJrhg0Xwz88MXhmMRdA//nUprHwIdn8ycMdcfCM88pWBO16Wss+4hqSUQybvvjMYobkrSGsghEcISvy+3ifjjkbA0/vj2NtmlBtwohHrOzqIZQgN3rn3ZoTV7tTP0DBk2CcsAr/fz65du4aMkGzpUoIiKiXhaJSS/DT0rYwAPZdfSsmuXbvw+7M4xTSsgu3qfg0SxiLoHx5rDCyjSIcc+4RFMGbMGOrr62lsbBzUckSt+YI7usNxIt3b6mdbT9aKlNDSAN48aOxZwPn9fsaMGTMwBd4bCXerbzmIFoGJEfQPbRGEAoNbDkMC+4Qi8Pl8jB8/flDL8JV/LOWDuhYaWgOMLsvn9s/N5X8fWs71J05hxvQRPe/c2QQ3HQrVs+Crr+6ZAu+taItgMN0LxiLoH8KyCEIdA3O8iLEsBop9wjU02HQFIzzz4XYaWgPkeASLv3kMM0eX8uQ1R3JCT0pASnj9VtixWv13CphwEF76JXS3969Q795jHxegvRFevQVWPgx1b6tlKx6Cx78Guz6OP2ews+/nW/8CrH1W/d74Gqx6vH/l7o2+WASdTfDKr3uOJ0RC8NKv1H1+50544jqVweXGqXgy7drYugyW3ZfZcwwGujd2qGtgjhdMolDe+otdnzPN1mXw2FWw7rnet13xENS/m/ky9ZN9wiIYbN7bbGf7VBXnxSaY6ZWmDfDcD+wgsbOF886d8NIvlF/1qG/1rUBSwn++ro77Qysl9dErYL2jwt7QAs/9CFrroXw8HHk9vHePOmc0DMf1cVyde8+xj3v3afbvgSaiFUEaFsGT31JZKqMOhEnHJ99my3vw0s/VwIL//YZaVnMwHHBh/HYhh3LMdEt06d/gw0dh9kWZPc+eRlsEyQR4f3ArlGAnPPUtKBkN168amHP0xAf3wfv3KsUz+cSet332BzDuCBhzR+bL1Q+MRTAAvLLOjk0km1oyJXpbbQlEgva65k3qO6cfgWH9ojktDHcfhWgU2ra6zm8JuEBr38+ZjEy4b8J98C9rQRHqwcIJWMrKee+TncMpdDLtlgp2QHfr4GZGZYJYjKAfFmcy3MfRz6ireWCO3+v5rfM11/W+bbBj4K47AxhF8CkIRaJcc//73P7yBuaNLQdg3thh6R/A7d5wCm7tnsjvw/E0gSQtcbdfu327fX6tALRlMlA+8LZtA3McJ9o1lA7eJJaWm6SKIJi4nbMVm2nXUKgLkEoZ7EvorKGBcg0lKILO+PNkGl1n2rb2biWGOoe0IjCuoU/B8voWHlumWtW/Oe8AGtu7mTayJP0DRFxCzVmZtCLoT5qkFm7OfgnuVmyzY0x9XaFj6X0DpAiaN0PpAGc49cUi8Fid+Hq6noDVenQK+l4tggwHi3UwNdAC+WWZPdeeRFsEA+UacseytKAVe6h9G0tljkLrFigfl3y7SEg1HvoTe9tDGIvgU/C+FRt4+3vHM66ykIPGDaMorw+61d26dbY027cn3yYddEvS6VZyCy+nItDrvFpw9lH5pEqnbM7ABC59sgisoTwiSVr4Gn2vnK3vZOfYkzECrXT2NYsAK4U60xbBHlMEjnrSU13X5RrCFoFRBJ+C9+uaGV2WT5WeQyAaUdkyUsInr0DHzp4P4G55agHTsAJ2rbO32fwm7FxnZ+X0hrYIcvLsZW53RotVcb259nlFPzv8OAWWlJBXqn6n4zvV7FwHDStVps9bf4Elf4TdGxO3680i6G63szicrqFQQAVh1z0fv72+V91tiecIdqig/ccvxrdiN7wEO9er70ygW45uF19nE2x4Ofn2a59Rv8NBWPPfno+/6Q1o3abu+ZI/wNt32Ne/7nkVI2pYqdY76WpW2WHpsuEl6HDEprQFnKkYQdDlGtr4evIMsL7S9AlsfT9xeTgABZXq98s3JTaIpIRli1RAOVl5hxDGNdRPHnhnM0+t2MbZcxyujzf/BM/+H5xzBzz8ZZWJ8tXXUh8klSJwzoQVCsDfTrb/X7sSynqZuD6mCHqxCAoqQQhb8Gs3VF9dH05FEAnasYe+xAie+T811tL0M9U9BNi+Es76Y/x2vVkE/7lGZQpd/W68a+jjF1VqKMRnM/WkCFY/YWcSXehI53zjVvUB+N42yC1I7xrTJZRCEbx7Fyz+uTpnjmPgwie/BcvuhSuWwPL74fX/B194AsYfmUcdMBQAACAASURBVHjsaBTuPRdmX6ysztVWmm9uEYw9VI3hNOMcaKmH/HL47IP2vg9/GdY9C99YC8W99I2JhODez8Dh18LxP1DLwgOtCLqS/9cWwd2nQmktXPcpp669dbb6dmfBhbuhYiJ07oSNr8LmN2D8Ufb67StVtl6q8g4hjEXQR65e9B53vrqBxz/YyvjKQn64cLq9Ugu+HVbq2vZeUthSuYaCHTBmvqrQOrNHk6yV7CapReCOEdQpheLx2a4T/d1XReAUWMEO28fdlxc+0KyOs3ujsijGzIfdmxK3cyrPZEHdXevt42lXVzgAXU32Ns7MLl32QBLXkPNeB1JkovTkduovqRRBV7N6Nu4OWTs+tPbrslvxyRIGADoa1f67N6pPtTUlaqgDWq261rzJfh5OmjZYx04jKyfQqsrqvIcxS2uAFEFcAD9q3xfhtRtVLRmcXzocUAr0aqt/gLu+ut/VgYqNZACjCPpAMBzlieXbuPG/q3l9/S7m1JbHjyqqg7PaJeTtZcRRt0Ugo0pghwNQWKla9G7zPB2/u36BvU5FkMQiKKtV7hNt0mrB2tcYgVNgBJpti6AvFT/UqQRZ82Yor4Vh45Nfq1N5JlM0+p5HgvbzCHXFl9Hp449ZBE5FYD0X5/lb6pOXuz8xnN5IpQhi6bCulqXTJaGvLVXd09fUvFl9hu+n/oe7oWWL+u0vVedw31+fZfmk81y1snDew0xaBNFQvEWQCTeMOzU83K3e0fKx6pzu+ur+byyCfYOtzfEPcnJVUfwG+uXTOfue3hRBEiESCVkVLE99dq6NX98XReAc8citCFrqlCLw+GxLZCAsAqdPuC8VP9ipWnTNm6FsLJTWqEwMt9+1N0Wg77nT1RPsiC+jUwEndQ1Z52h2tPBS3fe+ZDGlSyxG4AoW6+t1t6j18wt1Otx8Kfog6Bbyzo+UsK6crP6HA/b15pUkz3uPKYI0ervr+xqnCALx1/FpcVpGkaCtoDyezGTouOtzOKDeUa8Pikf1rggi3UN25FWjCPpA3e74yjVlRHH8BloI9dciAPUihwOqpZHjt7OHNC1pBGD1S+gUmm7hHg4o/6k31+EaCiXfNt3zgfKXavrywoe61MvbUqeUQFmtilm4XWPOe5ZM0eh7Hmixr8ttETjvSyBZ1pB1jpY626pKdd8H2iLQqYaQxCJIkX2in1uoy1acqe69WzhVTFTf4W77GiNW69p9f335VrnSyGbSZW9vsO9R2PE8BgKnsA8HHRaBNzMWgft5hIN2HK6sNrGONG9O7BA6RAPGGVUEQohThBAfCSHWCyG+k2R9rRBisRDifSHEciHEqZksT3+JRCWPvr+FddtVS+j0WSMppIupRa6HqoOtHVamglMRbH0ftn8IbQ32+EHJfNzaIvDm2umPTpwvcutW+OTV+OOEArDeyoxxCqlkKZ5u15DO6uhNuO3eaAsfKe3zQXymlK70bdtt4dHeGN/zc+c6NfZRsAPCXaq1WVarPu7rDXaoDA7nfyetW20lFmixy9i8Kf44u9bZ15jMIogEVcutpV4F/N3lcOJUTK3b7OO01KsxlwIttssl1KWyftpcyn3Xx7bbwSko3IIn6FAEkZDtg45ZBB2OOJPetkvFg6SE+qXq46RsrFJ24YB9jYFm61m47m9uofre9gF8vFhlt7U1JFcMzrI3rFT1wpmN5SQaUZlxeoygnVacZ+c6dZ4da9Sz1ZZd23a1bdBlETjTR90Ct3Wbeu+62+z7H7TiIlKmNz5RoDl+O20RgKqv+v6Fgype0FwHI2bGH6MnS6WzSVnU4aCqO7redLepY61/3o7jDDAZyxoSQniBPwAnAvXAO0KIx6WUzgjq94EHpZR/EkJMB54ExmWqTP3lwaV1fPdhlXmQ6/XwuwtmIxu+gO/OzfGZBLryaX+ythB2fQx/Ocbermo6XLkkXohoF03EZRG4cborFl0ADcvh9N/CvC+qZe/cqVwqEH/8ZK380jHJXUM9tdgCrXDbfHXOOZ9VQvzDR+z12iLw+OxKf89ClU1x2m/gvgugYjKcc7sK8N02L3m5kimC+y5UabkapyCQEm6Z5ihni31da5+OP/5dC+CUX8EhX3UoAks5e3PVfWvfoe7ZiOmwZakqR/6w+KAzxCvNuxbA1FPhlJ/DP85R7hfNj5phyW3w4o3qXnzhP2p50wb4/Vz47L/UeDXOe+8OyjotguUPqIymb623FV6wM/EZvnEbvPF7+PwjcKc13lLxSDuxYdgEVc+cMYK2hvhjaLRF8MpN1gIBRVXqmhf+Ln5bpyK487j4dW5FsP4FWHSeqjNfeFzdxy+/CPecoRoG2modNUcJ1vXPq+eT57DInYpARhLLfst+MGJ/lRm18TX1/t11KmxbBmf/BR65HD73KEw8lpQ8+3117q+9pywpHSMAlXixYot6Fk9cp7K4vHkw63xVfzQ9WQQ3WSMon/47eOJaGD4NrnpTjQn24SOq7p12Cxz0P6mP0U8yaRHMB9ZLKTdIKYPA/cCZrm0koLvilgKZUXefkkVv2cKotqKAHK8HX2uSFqIWfLEOWq7gsUZnFTmFSKGVjxwNWSZnXnzWj6Z1q92C11NbOluYWhAfcHHPriFQ6YFeny1IIg5fcyo6dyrLQSubdktoHPM99a2vtbDSclWEVAu8vUEJ6x1r7H1TnSe/3O6R7OyL4FQCEN+KdwvNQEvP8wa0NyjrSVtB2jXkL1X3TR9P9xaNhqGgIvE4Mb93QE3B2FpvH99JZ5Md+NctXoDGtYC0Gw9OIZnKNRTsVNuHAyoe5XxuMdeQdZzG1dDdYufBL7xVpTRfsQSuXgoFw1Q9c16zVhJun7azYTLmIFXu9u3QuCbxvvTUGc753MC+V9EQbF6ifm94SSmBism2ctv6vjpX2zYl7J3PPBK0379wd2IjAWD7CnXftMLbtsw+Lqh0z57Qlm+ss6fLIpBR9X5+ZPXjiHSruuwkHdeQPn6TZSk2rrEbIP7S3vfvB5lUBKMBp9Os3lrm5AbgEiFEPcoa+FqyAwkhLhdCLBVCLN3Tk8/s7giyYksLc2rLGF9ZyE/PnJl6Y3crJJa1kuLhO1vsumNKbxZBNGy/qG73hi6DvxRKRsUfP9lQFf7S+A5lsdZkGoO0ub9rD1bfWhEUVNopiTKqytW1Wy3TL3Aqy8Nfql6w4pE9B8ed1+3uvOaMEWicQ2644wb6mv2l6r5pd0fZWHubpIrAegZakOtjuidfadlsl7Ftm+3O037l2H6Oe+IWps5B9Jz33xksdqdo6nM2WEJu7OFKSY+YbgeKtUUQK4Pj+Tt/O7NmJp9k/07WcTDQolw0upOiRngTFZzz/8bX479Hzorf1n0u3WfAaRGEA/H30a1c3QP6udOnnSQbRNKTo5ZHuuNjBKDqqzNQ736HU7mGnOVxjn/VuSv+mv2ZGXJksIPFFwF3SynHAKcC/xAisX+4lPIvUsp5Usp5w4cP36MFXLlVPZRvnjSVxd88hkMnuoSB8wG687u1MEipCJJYBKFOQCa3CLSrSQvHZGmGwQ7wFaoKKCOqhZhqSITcQlWptSDR5enJjxkTQM3x/4tHqm9tkRRW2Omg+pjarRUTOCnSEHWrp7Qm3hWW6wrOO1uEboXhFJAaX6H9251J5Dy3Uyg6x0rSz8hJLNXUcW1OS8NZvlgZpW05JNwT697nD0sSI3D0z3AqAmewWLe29XH0OXVrN1mLMidPCcdwIHF4BmddcN7PsYfZv9u2Jsa7Ai0q+6jE1fYrGqHiD3EBe6cieC3+W6e3atyWVsUk9R3udiiC7vh3zplwEWhBDeiXpBGQzIJM1lgJB+zy63e01Ork2bw5Xia43+FUsiChjBZNG2wLGsDfh7HM+kAmFcEWwNkFdoy1zMn/AA8CSCmXAH4gyds2eKzYoh7KzFEpTLKeslhSpfsl21cLGf0iJ7MIdKVvsYJ/WjC4W7a+fLvnaTiQuvIJkcI11FOMIIlFIDxQaCnoOIvAIfxDnXbLRu+b6r5oYeXOxHC/BHEWgUsRdLcmvthO4RzqSu6+yCuxLALr2AUVtgIqSDISrLvPQaAluYLZ9bESmLWWANX3wrkf2M+qeGTqfgRBhyLo3OWoZx3xxwl324Jzu9XpLJkgyfHbQzHolm3snM4xlhzCvnIKFFap33rQNSeBFvUc3b3gi6x64gwwx/Xx6I7/rpySWF4n+p3QmU6gnonTCnD2cNfnSpZ0kMwiSPYuBB2WV0wRjAGE9W72YBGkehed9dypFDa/GW/N74WuoXeAyUKI8UKIXOBCwD1t1WbgeAAhxDSUIhjciYct2gIhfvKfVby+fie1wwooLUiRChrqVEK5vTFxNjG9LtnDlzK5a0gfIyfPzhrSKYzalG/ebO1rma1u11BugV0Bw909C3aPL3E+hGCberG62+JfqK7dtsAItKhr0C2/XKtPhe5DoRWb7gcR6nQIPcs0T1WuPEtYldUol0s0os7ldDPk+G1BHmiND8zq8rktgjil3enIXnLMJ+0vUS16bW34S+2gZCrXkJTxLp5kimDja0pAjDtc/Y917HIpR61Ii6vte9yxU2WTOIPFentnFkvHTtXaBnVvnZ3gQp2Qk5887pSTZwufUpfgTjXYXuHweKWhGyf607RB3Uu3YimyhqbodimCstp4iw2gqDrRx+5Gp79GHHEBGY0/fmsSRaBn6XMuSzbGVjKrVStZsO+ndmVuXRYvuHuyCPSzjUbiGzLNdVA1Q/3e9Hr8/hlSBBnLGpJShoUQVwPPAF7gb1LKD4UQPwGWSikfB74B3CGEuA4l1S6Vsi8zu2SOp1c28LfXVavhovk1akrJ534A390CeY6OZKFOeOUuWHxj4kHCAfhxGZz40/jlwqOmhFz2T3tZcbX6/udn1HeO3xbMxdWqZV0wTL1Ir98Ki39m75vgGiqwK2A40HOnJ2+SISYAbj9KBbU9Pvj2Rqh7U40dEztnKzxwCax5QvnRc3LVth2WHteKoNES0KEuR6tHqkBgKteQntKwtEYpqV3r4a8nxbuC/KXquneuhz/MT4yBdO220x01I2baLpKPnlQfUAJeu7T8parl/uQ31f+8EjUUdNvW5IrgsSuh7i2Hm641uSL42Bqsbexh8b1Q9Xd3qwoo/9vKCCmrUQLtlV/HP2uIVwQvOurWB4vs38EO+9jCq+5PKiESZxGMBRzzZv/pMLj8ZfjL0fH7CKEyjravtFNPF12getkOmwj178CEY9Q2ToosKyLQDPd/VtWfKaco33deiTqer0BdY/m4xGcISmEIoeqQdh3dszDef64TKSDeItAW99PftpdpJdjdrqaTvPM4uOxplWGUrLHijMU4W/zDxsPap+K3dVsEzsbim3+CZ74Lsy6AKkfGW0sdjD9aKfJNS+L339sUAYCU8klUENi57IeO36uAwzNZhv6yq8MWimfNHg2PW1PMdTTGK4Jgp519AMr0n3WeytfWgr7N5dfMybdTyoZNhAU3JU6mkeO3K1vxSKUIfAWq5VT/Tvy2CRZBoV0BnRk+TnTgNM41FFQvX6DFzmyKhtSLsu2DxHPqF0i7G4pHqqCor0C15sCeN9kpmPT+vXUs0sqkfqmtBKadASf+BP55njrG9hVKyB39bdi23H4RW7cqpVkxGT5zh3oB/aVwe5KB2AqHK0UgPLZlo++Rzw9n/Uk94+lnxg8IqHnvHjW9Zex+Wc+7tFbdj8knw5ST1LHHH616obbUqXuiFVCgxR4nafZnYeRs+9pzi+2OhpAY6B6+n7q+1nqlPHP88fGZ0QeqOpPKv5yTa1sSToGkcbaeCyrt1NcTfgQHfxX+eoI6147V6v3QmUan/Eo1YkJd8NotVlmn2de75gnrd6t6Nif/TE0dOu4INYhbzSHE9Y6f/VmVqlo6Rm3f9HG8cnY2FDodab5xKb+O442ep95DbTEEWuzpXNc/rxRBsuE0Ql12o8kp6E+7Gf54SPy2OXlw3YfqXbnj+HilpK3lrcviY1GhTtua2u4YMM+b278ZC9NgsIPFQ5KPG9t5Za1q2V40v4aDxg2zg2jurvtOPziohzfviyrnWdO2Te2vtbnPH995Z/IJib2QdUofQIkViPUVJJruBRVJYgROi6A7eeZNjpUT7nYNFY2AQ66K37a7NfEYHY12pdbDTmt/cFmtPSJnLEZgCSZ9HwMtvY9Zo11EzrS+moNVy0tbBLpch16lBIgmHFDlKx2jnsX4I5MHe8Fe7o7L6PsyajbMvbRnN0VznX1tukzaLTLuCDjoS2oeZI/X7nykXTfCE38th33NnpCmpU61onUwHhID3YdfY9fLw76unmHI6qUtvLaS6ski0FQnyYpzujcqJ6uMI1D3dsxcq6FSpwKwzZtVfRk2Aar2U9cxdUHi8ePGp7LiCSMPgHmXqXPM+6I6jx7WAmDOJTDtdPU8ho2HSSck73QJ8RaB87cTPSqqDhw7A+/6uLqx4rx3wY7EGAEoJerMMtPrS8fA6LmWZe94j7T7qnlzYrzMGV/R9cpfqiyhDGAUQRKOv/ll3vh4FwfWlvGLc2bh8QjbP50sIByX0ma1OJwmbVuDMme16ZqTb++TalyiHL8dMCsepb59+Yk+1+JR8elwoU5XjED3GBXxSkRXYG+OXfnDQfUCuM8RaElM24sbb8a6Zr1fgr9XqBbn7k12cC8di0C/fA0rEpfFFEGd+q1TTsEWmrs3xivYVK0pfUxnXKavtG2zry2mCGrij68pq1Hl1ttVTLKuxVKapTW2EmzerPZ3KrFQZ7wPvKzWtiy0EtYxmZLRSmgmK4fGKcwqJieud+b9e5I4Ecpq1b0OtKpytG6zy+8+r/P5a7p2py6bUxE4f2vcz0vHIJzC32kdOBmxf/x/Z1zJ60r9dmYvhRxZT+465ba6nOudvY/1+UC9G+7hKfyl9vuk71mG3EJgFEGPBEKO1n9s4m2X8GprUK36kQeo/zrYp3thgvIv+/LtB9ndapviGq/rBXNaBDp+kFuYRBFUo3zu1ssa1FlDTougTvUrcConXUHjxhoKKsGZVBFstq/Rja7Qer/Smvjr152ygm32kA3drb13rulVEbTao6jqa4H41rNTUCQLlDqX5/gTO6aljUwcjkKXK0ER1Cp3nR7WuXp/61rqlIWXV2Q3GoLtSrgUOBRB+454y7Ss1n6GZda9D1qKoKxGuaiSlUPjFFbJtnGOH5Vs/KzSGsuVqDturYw/Ttxv67qcWUPt21OXLbc3ReAqj85k6mqyGyOpLILCCtsyhniLQDfMtNU6fKq9XSiFRQCJef7O9aU1yRUBKLea+zno+jNihr0sQxhF4KIzaKccHubsMxCbeNvlztB+vrFWqEO/NM486VZr8hKnInDjbtk4YwS6laNjBE6028iZNugrTLQISmtcQtH67XYNefPslqxuiXQ1qxZL7aGJ5Qb7pS51uoYcSsfZmhrhcA305hqKCQ2HcNYKRlsELXW2oNNCQStOiG/BelMoAn1fnNkz/UFfW3Oduq/6uSVTBNIaX8fjg8qpql41fWzfQ7cgLXTURfeEP9piBEsJF9qWqnPcprxUMQLrvghv8uCss2d8shF1y2rjn1GgOb78zvPmFiZ2KuspkO0U/skmAHI/Ux2M7mq2XXmpFAHEnzfQYr8LOvlAN/yc1nQwRbDYfTz3et0A0DGUQIuKEYJ69s4GjL/UPmf5OHUPUz2/AcAoAhdtb/yNx3K/z3cX7Mf/nmIJsL8ca3ejD3bG9zbUwdCa+eo7FqR1pKJFulWF7kmjJ7iG8mxBqN0CSS0CSwjcfhT8ZqpSMr58uxwPfF512y9zKQLd0cebo/a5/WjbIigeqcqjBVvTx6ri60rrRpvDMddQTfwL7GxN6Z6ij3xFDckAtiBPdVwn+t77S9XgfjtW24orzxG01vfa2WJ0W12x5Y40XXdP2L6gLYIWy52j/fzu565f8E1vKP+xFlgbX0vuTvKXxk+M7p6jwnld/hIlMFvq7eBxKheVRtcVf0lyH3SnY2jxZBaBu066z+W0DoVQQfNXf5N6eycery3sk1kE7iQLrXw7m+z7mso15D5voCW+U+W/LrMTPpz3f+lf4V/W2F4JFoFbETjWl1lZcPddCL+ZohqRzpiM0/3ntAhKa2z3Z4YwU1W6GPHStxjhgVBtKbk5HtUpaet79gahzvg0S50eOfYINSDUFGtayVkXKEH36s3qv68AjrhOZd9of+BpN9vZIQnBYj9cuEgNmDbhWJWCOvkkldN+0s/s6RynnGylYnbCe39Xy3ILlBA/4jqr5SVUoO0Za5+TfqbKB7YQ3LZMKZ4RM9XLdeYflGBb/bjtmimrUVM2enPV1I8VE5TgnGgNKjb2MDj+RyodMMcPR35TXVelw+88cjZMPwtWPapS43Ly4dInYMNi9XvUbHtbr89OJTzgImVZTLIGTpv9WcuikDD3MrVs6qkqo2juZWpcokBLzz7/8vHqGXxkZRoVDocFv1KBvdIx8Zkcbk64AZ6/Qf2ecbbK+9aKQLf0Jp8EJ/w40aWmW63tDSqQO+10pWwjQTVGFKhUYU+OEhz+UhUEFl7lJlj7tLovE46xW7CXv2yPRjr3UqUwPV41JWVuIZxxW3xvYCfu2MpVb6vxd0JdavCzjl5cQ8mmTnUKLSHg7NvtBIpjvg3PfC/19m5yC6CrO7kiKKqCBb9W6aAyqlygoCysgnJA2BbBwV9VyqFqOpRaDaHiEXYflLCzJ3yHqqPaBTf1VDjpRpW63bFDXfPk/1HHcuJutTstAu22WueYe1xb6pGgur7Tblad3cYfrY514k9g5jlKwZWMJFNkvSIIhqO8/UkTh0+q4G+vb0SP6zc633rBEsZ76YzPy9/5kRJghZXxowLm5MJxP4DXfqsqky8fxsxTKYhLblPbzDzXbjW6g3A5uaqy6mMe/nV73WFX24qgeKRKuwM18bhO38zJVcLKfUyEyrDRLT+nJRJotoXCAZaiyCt2KIJa2185+QQS8PrgyOvt/zor4yNr9E9fgfKBL7hJvWQ7P1JDKZSPVcIrGf5Sdc9HzFDZNJrhU9Ropk48HpVBo/eD5MFNzcTjlGLRE7KX1arneOiVqffRHHGdrQhOu0UJbmf8yF+i7t0R1ya/JufvklFKAcVdi1cJjratdiBc31vd2HAyaratRKv3h9NviV9/4OdSX4sWVtpSGT7VtuKe+2F8jCCpa2hs4jK3YD/gQvv3IVcmKoKe3B6+AuXqSRXjOfhyNZ/zjlXxSslfZrlYredy8s8TLQjd6tauWJ2h1tFoKwGPTynTw74GS+9SimDW+XZdc+Iuo/N/MmWXX2ZZt43qOg/6Uvx6fY5ppye/9gEi611Dv35mDZf89S0eXbaFnz5hj5BdlesalVLjzBjQlNUkN6mFsCu49r06W1TOFk6yGEE6OP2m2o+crOWkz+HNjS+r213ibvHpSgqJqavpostYat2nwuG2uZ/MJ+0+f3/Ord1KPU0OpNfp+5HMxZEO+hnn+O3n2FML1yn0ehKAscB4ZgYaixGzCJJMSO8rcFkESSws53hCqQLkToRIVNA9be8rsGILPaROOoclcS6LZcflJSoBsN2S5VZmla7rzjiMM23TmZ2VjGSWfew4SZ617kgHyWMge4isVwSrt6lsm5c+UhUgIlQF9Qb18AVJBv5y99TtSYDE+g5YflKvIzCX43ipeqpAPeEU+jqzpDdF4MTdwnOvdwqj/g54pcuj75PHY7fcnP7jZCR7wdMhZhH0oAi0MIr1qu2notPKVIj4rKZU5BbF54anIp1jDQS6YVOUTBHkxzeGksVZfH67A2G1FQPqrczu9T0qgvw+1JOx8cv0e5Rqf12v3A0StyLQuDPk3CRLA092HOcyt4wYBLJeEUSt4OO7m3ZTkOvFE5uOzzW4miaZRdBTazX2kF0WgVvwJ7iGUpjBbpzH0cEm98iXsW1z45WPXtbTf90a7a+QBIcicBxD37NUSit2/k+pCHq0CKxr1T2BndlG/SUd4e3x2K3AdBRBhnqTxtCZUtqH7cQtIFMpVv1sdYJBb4rAbQn1qDgL068nRVV2Y8tfZr9HqSzPWJ2U8edwjgaQrAGUKsHBXd+c71PSkV/9iTJiEMh6RRCJKkVQv7uLmaNLEbripFIEr9ykZk5y0heLQB/fLfjdZmuqVMee0COApkqXS2YR9FRxIXlLq6/oa3feJ/07nRdcxxb6Ql8Ugb5fRXtIEaS7nR7tdKDm+E2FHnyvKIkicLdSU93Pslpl6fTWeU3jHsm1V4sgjXqihwhx3tveLAL9zLvbXCmijg6TycqWqpd6Ty5ep/LTQl/PH9JTGfcAWR8sjjpSQSdUFkJnLxYB2BOqjzpQtTSSBe80sy5QecO6m72uKG7Bn1sE87+iMmx2b0yd6qi55OHEMYeOuE6ZtAd+Pvk+M89RQVYnToVUe5jqtu/ep3OXnWXUH0prYPYlsJ8j4DXzHJUGOeu8nvfd/zw1FHFfu9brl849JMjpv1U9qLcshUOuUMvOvl1N8ZlsnB03C2+1n905dyTWj4FUBCf8WGUF7Xda7+X6NJz4YyVop5ySuM4tgFMpgtkXq34nE49Tz6x6/+Tbac65A576tjW2j+g5VjL7sz2ngIJKwtBxBH+JCuj6SxwWQVHy/YZNgHn/o5IVNr2hsuS2Lbc7aEL8M7r4XyrDLlV9nPsFlRn40ZNKyDvfY49XXWd3q6qH659Tz1bPvNdbvCyDZL0iCEVsRTCixG9XHN1JKtnE3JoTboAJR6deDypbw5mxoV8kt0UgBJx6E2kz6Xg7lVJTMAw+c2fqfaacnKi0dDlmXQDn/CVxn5mfUZ9PgzcHzvpD/LIJx6hPbyQrczpoAeYew0XP7exkxAz1YqbD3C/Yv2edn7heC7S8dBVBDwKweETPz3OgKB8HZ/8p+bp0XUOTTrAbEemUuWIinHc3/GK0yq7y9OCc2P/ccd/v5QAAGBdJREFU3o837gh7rKk4iyAvfpkbj8fOsBo5S81j/eDnYdVj9jbOfaecpD6pyCtWgxzeNj9+GPDYeksRVE62M/O0sjAxgsGjudPuEzCixJH10ZNFoOmP79abwjU0WOh4wiBWwoygryedOWIHkoG0CIYC6bqG+nVsS1kP9D1I5hrqyzncvvr+9OhNNed4sueulWtPiQ0ZJusVgXO46erSPLuDTlqKoB9+/JhraIgoAu1/7s0Hu7ehW7JDXhFkODX005JQLwZw9EuPJz5YOlD0xSJIhlv59ecZpZpzPNlz18o12cQ4e4isVgShSJS2gD22UFWxY3yfnhSBFuL9sgi09v8UQxkMJNp1sq8pAn09mQ60utnnLAJXvXDHXAbi+EPNInDn8/enfL1aBA4rQ8uEVHOL7wGyWhHsdlgDANWlfjs1dPMSePFniZNlgz3uSH9eiljW0OCZgXHoQfQGsTNLRtDX09vAdgPNvqYI3PXCPRPcpz5+YWYVgQ7q9qVV73YN9UsR9GAR+ArjXWxaFkTDidvvIbJaEWxtie8YNqwg17YI2rapVNGPF8fvNOkENRxAfnn/eqKmChYPFgdcpMoy45zBLsnAMupAe3ynPcmYeWpsod7qRs18NZpr/rCetxtsRs2JH6o5OsCKYOJxMP6ogT1m7aHqmLlFKkMM+ibMR81Wwnr6WapfhHOSqXQZd3jyRJJxRyQGmw+4SCmDQXwHxRCZIjht5s2bJ5cuXTogx3pi+VauXvQ+Fx9cS/3uLv7+xflw4wg4+CtqPJSbp8bvcOjV9rg+/eWTV9T8qlUz4Mo3Pt2xDIY9xau3wAs/VmPfnPiTwS5N+vz9TNjwkkoRdo53lIUIId6VUs5Ltm6INEsHhy27lf/4Owv2o8TvUyM2hgPKpCusskcFzCtV09kNhH80ljU0RGIEBkM6pJqqdaijXb1D3QU3yGS1a6h+dxcl/hylBMAxIXWeymjQPQ2HjVPfA2EW6xdqqLiGDIZ00A2X6N6mCCxXr1EEPZLVimBLcxdjyh3BMF1pdKtdj0MSCw4PgCLQASGjCAx7E3rCnoEOFmeakPVO5xUPbjmGOFmtCOp3dzK2zKdmhgLHhNRaEeghasep74GwCLQiGMiOOQZDptGW7EAHizNNbErJfazD5ACTtYogHImycVcnp4glcPdpsHN94jykow5UQ/POOFv9TzYWS18ZNkF9f5qxewyGPU3tIep7cg/DKwxF9PAuyQbUM8TIWv/EpqZOguEok3OsseibNthCWiuCuZeqAa9ycuEHOwemFV86euCOZTDsKUbN3jvr7RHXq2k+97Zy72Gy0iLYtKuDS+96G4CR0lIEzZscFoGePEbY4/cPZEUyldKwN7I31lsh9s5y72GyUhHc++Ym6ppU6mhJtzUTUUudI0aQ4YlADAaDYQiRlYpA96GrKs7D21qn/jRvTrQIDAaDIQtISxEIIR4WQpwmhNgnFMeOtm6qS/y8eP0R0LJFLdy5DnZYk9cbi8BgMGQR6Qr2PwIXA+uEEL8UQkztbYehTGNbN2PK8ykK7lJ50blFsH0lPPlNtUH+EB8a2GAwGAaQtLKGpJTPA88LIUqBi6zfdcAdwL1SysEbP7Uf7GgLMGVEsT1X7Sm/UGmiUqoeiJVTej6AwWAw7EOknT4qhKgALgE+B7wP/BM4AvgCcEwmCpcpdrR1c8SkSnuugbLa9KZNNBgMhn2QtBSBEOIRYCrwD2ChlNJKteEBIcTADAW6hwiEIrQFwgwvzlNzh4IZh8RgMGQ16VoEt0opFydbkWpY06FKY5tKEa0q9tsWgVEEBoMhi0k3WDxdCBGLoAohyoUQV2aoTBmlrklNzTiqLN9WBHlGERgMhuwlXUXwZSlls/4jpdwNfLm3nYQQpwghPhJCrBdCfCfFNucLIVYJIT4UQixKszz95uOdaurCCcMLHRZBSQ97GAwGw75Nuq4hrxBCSGs6MyGEF8jtaQdrmz8AJwL1wDtCiMellKsc20wGvgscLqXcLYTI+MhQGxrbyfd5qS6xXEPu+UMNBoMhy0jXIngaFRg+XghxPHCftawn5gPrpZQbpJRB4H7gTNc2Xwb+YFkYSKkH/skcGxo7GF9ZiMcjlCIw8QGDwZDlpKsIvg0sBq6wPi8A/9vLPqOBOsf/emuZkynAFCHE60KIN4UQScd5FkJcLoRYKoRY2tjYmGaRk/PJzg7lFgJLERi3kMFgyG7S7VAWBf5kfQb6/JNR/RDGAK8IIfZ3xiOs8/8F+Auoyes/zQl3tAUYWTpC/TEWgcFgMKQ91tBkIcRDVlB3g/70stsWoMbxf4y1zEk98LiUMiSl/ARYi1IMGSEciRIIRSnMs/SfUQQGg8GQtmvoLpQ1EAaOBf4O3NvLPu8Ak4UQ44UQucCFwOOubR7F6pUshKhEuYp6UzD9piOoptkrciqCPOMaMhgM2U26iiBfSvkCIKSUm6SUNwCn9bSDlDIMXA08A6wGHpRSfiiE+IkQ4gxrs2eAXUKIVagYxLeklLv6cyHp0NGt5guOWQSRoBlp1GAwZD3ppo92W0NQrxNCXI1y8RT1tpOU8kngSdeyHzp+S+B665NxEhSBjKoZjAwGgyGLSdciuAYoAL4OzEUNPveFTBUqU7RbiqAoz6sWSAn7xhQLBoPB0G96tQisjmEXSCm/CbQDl2W8VBmio1vFCApznRaBUQQGgyG76VUKSikjqOGm93rak7qGjCIwGAzZTboxgveFEI8D/wI69EIp5cMZKVWG6Ii5howiMBgMBk26isAP7AKOcyyTwN6lCILGIjAYDAY36fYs3mvjAk7aEywCEyw2GAyGdGcouwtlAcQhpfzigJcog3R0h/EI8Pss4W/SRw0GgyFt19ATjt9+4Gxg68AXJ7N0dEcozMtBaOFvXEMGg8GQtmvo387/Qoj7gNcyUqIM0t4dtt1CAEhjERgMhqynv83hyUDGJ5EZaDq6w3agGIxFYDAYDKQfI2gjPkbQgJqjYK8iEIqQ7/PaC4wiMBgMhrRdQ8WZLsieIBSR+LwOV5BRBAaDwZD2fARnCyFKHf/LhBBnZa5YmSEUiZLjdVyyUQQGg8GQdozgR1LKFv3HmkHsR5kpUuYIRaLkGkVgMBgMcaQrBZNtl27q6ZAhHJXkaNeQ1CEPkzVkMBiym3QVwVIhxC1CiInW5xbg3UwWLBMEw1F82iLQisBYBAaDIctJVwp+DQgCDwD3AwHgqkwVKlOEo45gsYyqb6MIDAZDlpNu1lAH8J0MlyXjhCNOi0ArAuMaMhgM2U26WUPPCSHKHP/LhRDPZK5YmSEUkeR43IrAWAQGgyG7SVcKVlqZQgBIKXezF/YsDkWi5OYY15DBYDA4SVcKRoUQtfqPEGIcSUYjHeqEIlFjERgMBoOLdFNA/w94TQjxMirf8kjg8oyVKkOEI9LECAwGg8FFusHip4UQ81DC/33gUaArkwXLBMFI1GQNGQwGg4t0B537EnANMAZYBhwCLCF+6sohT1yHMkw/AoPBYID0YwTXAAcBm6SUxwJzgOaedxlaRKOSSFSaDmUGg8HgIl0pGJBSBgCEEHlSyjXA1MwVa+AJRZUrKDFGYBSBwWDIbtINFtdb/QgeBZ4TQuwGNmWuWANPKKIsgMQYgQkWGwyG7CbdYPHZ1s8bhBCLgVLg6YyVKgOEI0rwm/RRg8FgiKfPI4hKKV/OREEyTcwiyDGKwGAwGJxkjRQMWRaBz+NyDZlhqA0GQ5aTNYogHIsRmKwhg8FgcJI1UjCoYwSmQ5nBYDDEkTVSMGylj+aa9FGDwWCII2ukYCisXEE5RhEYDAZDHFkjBXWHsikrfg3rXzAxAoPBYLDIGikYCkfJIczY1XfAveeYDmUGg8FgkVFFIIQ4RQjxkRBivRAi5VSXQojPCCGkNcJpRghHJdWiyTqhxygCg8FgsMiYIhBCeIE/AAuA6cBFQojpSbYrRg1q91amygIqa6hGNKo/RdUmRmAwGAwWmZSC84H1UsoNUsogcD9wZpLtfgr8CghksCyEI5LRYqf6UzwCMwy1wWAwKDIpBUcDdY7/9dayGEKIA4EaKeV/ezqQEOJyIcRSIcTSxsbGfhUmFIkyRlsEhVXGIjAYDAaLQZOCQggPcAvwjd62lVL+RUo5T0o5b/jw4f06XygSZTQ79RGNIjAYDAaLTErBLUCN4/8Ya5mmGJgJvCSE2Iia9ezxTAWMwxHJMNGm/kSCRhEYDAaDRSal4DvAZCHEeCFELnAh8LheKaVskVJWSinHSSnHAW8CZ0gpl2aiMKFIFB9h9ScSMorAYDAYLDImBaWUYeBq4BlgNfCglPJDIcRPhBBnZOq8qQhFJT4i6k+423QoMxgMBos+z0fQF6SUTwJPupb9MMW2x2SyLKFwFJ/QFkHQDENtMBgMFlnTHA5HVc9iwHINaYvAKAKDwZDdZI0iOGBMGSOLLAMo0m1iBAaDwWCRUdfQUOLgCRVQ6IVOTLDYYDAYHGSXFIwE7W+jCAwGgwHINkUQDanvsHENGQwGgya7pGDE9CMwGAwGN9klBbVFEOcaMllDBoMhu8kuRaBjBFFjERgMBoMmu6Sgdg2BihOAUQQGgyHryS4pGA2Bx8qYDVvTHxjXkMFgyHKyRxFIqVxDvkL131gEBoPBAGSTIohaA87lakXQpb6NIjAYDFlO9khBnTGUaywCg8FgcJI9UjCiFUGB+o7FCLLnFhgMBkMyskcKxhRBkfrWFoEZhtpgMGQ52aMIElxDxiIwGAwGyCZFoC0Cn3YNmRiBwWAwQDYpArdFEDJZQwaDwQDZpAgiqbKGTIzAYDBkN1msCEyMwGAwGCCbFIF2DfmMIjAYDAYn2SMF9YBzCRaBcQ0ZDIbsJosUgTUEdUwRWP+NRWAwGLKc7JGCCf0ITNaQwWAwQDYpggTXkOlHYDAYDJBNiiDq7lBmgsUGg8EA2aQIYjECa6yhkFEEBoPBAFmlCMzoowaDwZCM7JGCUStG4M1V01WansUGg8EAZJMi0BaBN1d9tEVghqE2GAxZThYpAitG4PWpj7SmrjSuIYPBkOVkjxTUriGPT1kEGqMIDAZDlpM9UjDmGsoBb5693CgCg8GQ5WSPFBQCcvIti8DnWJ49t8BgMBiSkT1S8NCr4PsNKn3UuIYMBoMhRkaloBDiFCHER0KI9UKI7yRZf70QYpUQYrkQ4gUhxNhMlidGjlEEBoPBoMmYFBRCeIE/AAuA6f+/vfuPtbqu4zj+fAWCJk5Eb85xScHYihohkbM0cmql1MA2mpQaa25upVuutYRpZm79ka6fmwusTEwKlWSR05U/GM0/FFEuCiJ6U5ow89IPKWthwrs/vp9z7+FwDnDlfr/fo5/XY7u73+/n+73n+zqf8+N9vp9z7ucAn5c0rWW3DcCsiJgOrARuLCvPPvY5I/DHR80sb2W+HD4d6I+IFyLidWAFMK95h4hYExH/SauPAr0l5hnioSEzs0FlPgtOBF5qWt+e2jq5DLi/3QZJl0taL2n9zp07Dz+ZzwjMzAZ1xcthSZcAs4Cb2m2PiFsiYlZEzOrp6Tn8AzYKgc8GzMwYXeJl7wAmNa33prZ9SDoPuAb4eETsLjHPEBcCM7NBZT4TPg5MlTRZ0hhgAbC6eQdJpwFLgbkRMVBiln2NdiEwM2so7ZkwIt4ArgR+D2wB7oqIzZJukDQ37XYTMA64W1KfpNUdLm5k+YzAzGxQmUNDRMR9wH0tbdc1LZ9X5vE7avxnsQuBmVl3vFlcucG5hvyJITOzTAuBh4bMzBryfCb00JCZ2aA8nwkHzwg8NGRmlmchGJ3eI4ioN4eZWRfIsxA0hoYa31pmZpaxTAtBGhpyITAzy7wQ7KlmRgszs26WZyEYd2LdCczMukaehWD8u+tOYGbWNVwIzMwyl2chOOq4uhOYmXWNPAuB/5HMzGxQnoXAzMwGlToNdVdb+DvYtb3uFGZmtcu3EEyeXXcCM7Ou4KEhM7PMuRCYmWXOhcDMLHMuBGZmmXMhMDPLnAuBmVnmXAjMzDLnQmBmljnFW+x7eyXtBP78Jv/8BOCvIxhnpHRrLujebM41PM41PG/HXCdHRE+7DW+5QnA4JK2PiFl152jVrbmge7M51/A41/DklstDQ2ZmmXMhMDPLXG6F4Ja6A3TQrbmge7M51/A41/BklSur9wjMzGx/uZ0RmJlZCxcCM7PMZVMIJJ0vaaukfkmLas6yTdLTkvokrU9tEyQ9IOn59Pu4CnLcKmlA0qamtrY5VPhx6r+nJM2sONf1knakPuuTNKdp2+KUa6ukT5WYa5KkNZKekbRZ0ldTe619doBctfaZpCMlrZO0MeX6dmqfLOmxdPw7JY1J7WPTen/afkoZuQ6S7TZJLzb12YzUXuX9f5SkDZLuTevl91dEvO1/gFHAn4ApwBhgIzCtxjzbgBNa2m4EFqXlRcB3K8gxG5gJbDpYDmAOcD8g4AzgsYpzXQ98vc2+09LtORaYnG7nUSXlOgmYmZaPAZ5Lx6+1zw6Qq9Y+S9d7XFo+Angs9cNdwILUvgT4clr+CrAkLS8A7izxPtYp223A/Db7V3n//xrwK+DetF56f+VyRnA60B8RL0TE68AKYF7NmVrNA5al5WXAhWUfMCL+CPz9EHPMA26PwqPAeEknVZirk3nAiojYHREvAv0Ut3cZuV6OiCfT8r+ALcBEau6zA+TqpJI+S9f7tbR6RPoJ4BxgZWpv7a9GP64EzpWkkc51kGydVHJbSuoFPg38LK2LCvorl0IwEXipaX07B36glC2AP0h6QtLlqe3EiHg5Lf8FOLGeaB1zdEMfXplOy29tGjqrJVc6DT+N4pVk1/RZSy6ouc/SMEcfMAA8QHH28WpEvNHm2IO50vZdwPFl5GqXLSIaffad1Gc/kDS2NVub3CPph8A3gL1p/Xgq6K9cCkG3OSsiZgIXAFdImt28MYpzvdo/19stOZKfAKcCM4CXge/VFUTSOOA3wFUR8c/mbXX2WZtctfdZROyJiBlAL8VZx3urztBJazZJHwAWU2T8MDABuLqqPJI+AwxExBNVHbMhl0KwA5jUtN6b2moRETvS7wFgFcUD5JXGqWb6PVBTvE45au3DiHglPXD3Aj9laCij0lySjqB4sl0eEfek5tr7rF2ubumzlOVVYA3wEYphldFtjj2YK20/Fvhbmblasp2fhtkiInYDv6DaPjsTmCtpG8Xw9TnAj6igv3IpBI8DU9O772Mo3lhZXUcQSUdLOqaxDHwS2JTyLEy7LQR+W0e+A+RYDXwxfXriDGBX03BI6VrGYz9L0WeNXAvSJygmA1OBdSVlEPBzYEtEfL9pU6191ilX3X0mqUfS+LR8FPAJivcv1gDz026t/dXox/nAw+kMa8R1yPZsU0EXxVh8c5+VeltGxOKI6I2IUyieox6OiIupor9G6p3ubv+heNf/OYoxymtqzDGF4hMbG4HNjSwUY3sPAc8DDwITKsjya4ohg/9RjD1e1ikHxaclbk799zQwq+Jcv0zHfSo9AE5q2v+alGsrcEGJuc6iGPZ5CuhLP3Pq7rMD5Kq1z4DpwIZ0/E3AdU2PgXUUb1LfDYxN7Uem9f60fUqJt2WnbA+nPtsE3MHQJ4squ/+n453N0KeGSu8vTzFhZpa5XIaGzMysAxcCM7PMuRCYmWXOhcDMLHMuBGZmmXMhMKuQpLMbs0qadQsXAjOzzLkQmLUh6ZI0X32fpKVpgrLX0kRkmyU9JKkn7TtD0qNporJVGvo+gvdIelDFnPdPSjo1Xfw4SSslPStpeVkzbJodKhcCsxaS3gdcBJwZxaRke4CLgaOB9RHxfmAt8K30J7cDV0fEdIr/Om20LwdujogPAh+l+G9pKGYHvYriewGmUMwxY1ab0QffxSw75wIfAh5PL9aPophIbi9wZ9rnDuAeSccC4yNibWpfBtyd5pOaGBGrACLivwDp8tZFxPa03gecAjxS/tUya8+FwGx/ApZFxOJ9GqVvtuz3Zudn2d20vAc/Dq1mHhoy299DwHxJ74LB7yQ+meLx0pgF8gvAIxGxC/iHpI+l9kuBtVF8U9h2SRemyxgr6Z2VXguzQ+RXImYtIuIZSddSfIvcOyhmQb0C+DfFF5hcSzFUdFH6k4XAkvRE/wLwpdR+KbBU0g3pMj5X4dUwO2SefdTsEEl6LSLG1Z3DbKR5aMjMLHM+IzAzy5zPCMzMMudCYGaWORcCM7PMuRCYmWXOhcDMLHP/B48YrSfrI/MYAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.plot(cnnhistory.history['accuracy'])\n",
        "plt.plot(cnnhistory.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'valid'], loc='upper left')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jVaxLrTj3Hxc",
        "outputId": "7a4a4ef8-1df1-4a48-eb38-7769a1090287"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[9.99999881e-01, 2.00630311e-13, 2.17538678e-11, 1.63909249e-07,\n",
              "        3.88517024e-10, 2.98765374e-18],\n",
              "       [1.38221534e-09, 8.03246558e-01, 1.96722984e-01, 1.08544257e-10,\n",
              "        3.04507776e-05, 2.19572919e-11],\n",
              "       [9.99977708e-01, 4.72540833e-08, 2.81673521e-11, 2.21768514e-05,\n",
              "        1.13727417e-07, 1.74254234e-13],\n",
              "       [2.98034817e-01, 2.48121709e-01, 2.86819577e-01, 1.56470854e-03,\n",
              "        1.65459111e-01, 9.60818696e-08],\n",
              "       [6.09215795e-16, 9.94650781e-01, 1.01266629e-07, 5.34892874e-03,\n",
              "        2.77942917e-07, 2.10044398e-16],\n",
              "       [3.63994772e-08, 2.07778320e-01, 5.40511250e-01, 6.89218432e-05,\n",
              "        2.51641333e-01, 1.40268071e-07],\n",
              "       [6.14996378e-12, 9.44551721e-05, 1.97880979e-07, 9.99897242e-01,\n",
              "        8.05536365e-06, 2.07576994e-14],\n",
              "       [6.98747584e-08, 9.93163764e-01, 4.40834789e-03, 2.42740242e-03,\n",
              "        3.14560708e-07, 1.02560002e-10],\n",
              "       [5.18401578e-07, 3.72346654e-03, 9.96165395e-01, 7.21615515e-06,\n",
              "        1.03375984e-04, 7.28562266e-10],\n",
              "       [9.99818265e-01, 8.53151837e-12, 1.24983552e-12, 1.81729731e-04,\n",
              "        2.21863829e-11, 1.36818492e-16],\n",
              "       [1.06253952e-04, 3.69768216e-10, 3.08237302e-09, 7.84123981e-12,\n",
              "        9.99893785e-01, 2.19918959e-14],\n",
              "       [3.63318316e-12, 8.04370046e-02, 3.24363232e-01, 8.96272104e-06,\n",
              "        5.95190763e-01, 8.03875966e-10],\n",
              "       [3.52054030e-06, 4.09633976e-05, 9.99238491e-01, 5.29214449e-04,\n",
              "        1.87812126e-04, 4.82325957e-10],\n",
              "       [8.02832562e-03, 4.21419382e-01, 2.67893367e-04, 5.66144645e-01,\n",
              "        4.13970230e-03, 2.82918418e-08],\n",
              "       [3.87881952e-03, 9.05515277e-04, 7.38694012e-01, 6.99848752e-04,\n",
              "        2.55821705e-01, 4.78682054e-08],\n",
              "       [9.99995828e-01, 3.03590242e-09, 2.40495783e-08, 4.13636917e-06,\n",
              "        1.81202492e-13, 3.59974788e-16],\n",
              "       [7.93081212e-10, 3.45056122e-07, 5.56298937e-06, 1.19315424e-09,\n",
              "        9.99994040e-01, 1.09093177e-11],\n",
              "       [3.70863378e-01, 1.34942115e-06, 9.08179118e-07, 6.29134357e-01,\n",
              "        1.71370349e-08, 1.41369078e-11],\n",
              "       [9.99999046e-01, 1.89410404e-10, 1.72487599e-12, 7.05501350e-07,\n",
              "        1.79300187e-07, 5.34503472e-14],\n",
              "       [2.32676939e-06, 1.79495051e-04, 8.92155111e-01, 6.18849072e-06,\n",
              "        1.07656844e-01, 3.58183705e-09],\n",
              "       [3.13582518e-07, 6.77987373e-08, 9.90356624e-01, 1.26837980e-08,\n",
              "        9.64303501e-03, 4.18275657e-11],\n",
              "       [2.70541318e-06, 7.57968724e-02, 1.98935959e-02, 5.06923001e-08,\n",
              "        9.04306769e-01, 5.07127069e-08],\n",
              "       [3.32424301e-13, 9.34032023e-01, 6.38222247e-02, 3.12347547e-05,\n",
              "        2.11443100e-03, 3.31120710e-13],\n",
              "       [9.98719573e-01, 1.25031690e-07, 1.81031988e-13, 1.28030754e-03,\n",
              "        1.47926241e-10, 8.66129339e-14],\n",
              "       [1.54017897e-07, 8.13820861e-06, 1.90826063e-03, 2.48374050e-07,\n",
              "        9.98083234e-01, 4.92979879e-09],\n",
              "       [9.99999166e-01, 1.34023972e-10, 9.19755869e-11, 6.22864150e-07,\n",
              "        2.18761826e-07, 1.68670552e-14],\n",
              "       [2.61179682e-08, 1.22685946e-04, 6.51417434e-01, 1.50609030e-05,\n",
              "        3.48444790e-01, 6.67638722e-10],\n",
              "       [1.35877505e-02, 3.68634530e-04, 8.65224600e-01, 3.80519684e-03,\n",
              "        1.17013626e-01, 5.90963509e-08],\n",
              "       [9.19334888e-02, 2.62769870e-03, 7.15706721e-02, 1.08433887e-02,\n",
              "        8.23024631e-01, 5.14644007e-08],\n",
              "       [9.99999642e-01, 1.77404601e-11, 1.38583631e-10, 3.11716434e-07,\n",
              "        5.71540610e-08, 4.01706540e-16],\n",
              "       [4.08902675e-01, 1.96028128e-01, 3.16187531e-01, 1.40845841e-02,\n",
              "        6.47969767e-02, 4.95551120e-08],\n",
              "       [6.15413519e-05, 9.49829815e-09, 3.67923914e-10, 9.99938488e-01,\n",
              "        4.49843246e-10, 1.41228260e-14],\n",
              "       [1.16942263e-13, 2.88902633e-02, 1.30455058e-09, 9.71109390e-01,\n",
              "        3.25401857e-07, 1.21529111e-16],\n",
              "       [1.99958208e-06, 8.91163573e-02, 9.10754859e-01, 4.22906169e-07,\n",
              "        1.26350540e-04, 5.10653020e-10],\n",
              "       [1.52637713e-05, 2.19610974e-05, 1.00510333e-05, 1.23349167e-07,\n",
              "        9.99952555e-01, 5.73801111e-11],\n",
              "       [7.46850908e-01, 7.75807257e-06, 6.45049226e-07, 2.53140569e-01,\n",
              "        1.10239839e-07, 8.69378805e-11]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "#predictions = model.predict_classes(x_testcnn)\n",
        "predictions = model.predict(x_test)\n",
        "predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y01xRIqN3Kv7",
        "outputId": "b9a73ec9-0fdb-4020-9505-5a2a619635b0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 2, 0, 2, 1, 1, 3, 1, 2, 0, 4, 4, 2, 3, 4, 0, 4, 0, 0, 4, 4, 1,\n",
              "       2, 0, 4, 0, 4, 2, 0, 0, 1, 3, 3, 2, 4, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "emo_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DLhoAcuI3N3Z",
        "outputId": "6077f01b-79df-4c32-937c-bb4d7a148769"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 2, 0, 2, 1, 1, 3, 1, 2, 0, 4, 4, 2, 3, 4, 0, 4, 0, 0, 4, 4, 1,\n",
              "       2, 0, 4, 0, 4, 2, 0, 0, 1, 3, 3, 2, 4, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "new_Ytest = emo_test.astype(int)\n",
        "new_Ytest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "msg0xsZw3ROh",
        "outputId": "5afdb673-03cd-477d-df8e-6bd4f5a38278"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 0, 0, 1, 2, 3, 1, 2, 0, 4, 4, 2, 3, 2, 0, 4, 3, 0, 2, 2, 4,\n",
              "       1, 0, 4, 0, 2, 2, 4, 0, 0, 3, 3, 2, 4, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "preds1=predictions.argmax(axis=1)\n",
        "preds1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-nADWckp3UHg",
        "outputId": "db3d2c84-3f22-4c77-9bf4-4990b0ca6003"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[9, 0, 0, 1, 1],\n",
              "       [1, 2, 1, 0, 1],\n",
              "       [1, 2, 4, 0, 0],\n",
              "       [0, 0, 0, 4, 0],\n",
              "       [0, 0, 4, 0, 5]])"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "abc = preds1.astype(int).flatten()\n",
        "from sklearn.metrics import confusion_matrix\n",
        "c = confusion_matrix(new_Ytest, abc) \n",
        "c"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2fbTq6qW3UOm",
        "outputId": "05f43572-9ed0-4af8-93dd-6267cdb6e9fa"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 2, 0, 2, 1, 1, 3, 1, 2, 0, 4, 4, 2, 3, 4, 0, 4, 0, 0, 4, 4, 1,\n",
              "       2, 0, 4, 0, 4, 2, 0, 0, 1, 3, 3, 2, 4, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "emo_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vcuBTzA93UQk",
        "outputId": "f503d063-6c90-4ef6-9dd0-c047538c18d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/graduation project/audio/model/original_augmation_Savee_400_epoch_8_kernal_size_and_bat/assets\n",
            "MODEL SAVED\n"
          ]
        }
      ],
      "source": [
        "#model.save('/content/drive/My Drive/augmanted_radvass')\n",
        "model.save('/content/drive/My Drive/graduation project/audio/model/original_augmation_Savee_400_epoch_8_kernal_size_and_bat')\n",
        "print(\"MODEL SAVED\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gleoIwgk3aRm",
        "outputId": "f9cdef80-08ad-435c-901f-e8030b668b64"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " batch_normalization_3 (Batc  (None, 40, 1)            4         \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " conv1d_2 (Conv1D)           (None, 40, 128)           1152      \n",
            "                                                                 \n",
            " batch_normalization_4 (Batc  (None, 40, 128)          512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_3 (Activation)   (None, 40, 128)           0         \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 40, 128)           0         \n",
            "                                                                 \n",
            " max_pooling1d_2 (MaxPooling  (None, 8, 128)           0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " conv1d_3 (Conv1D)           (None, 8, 256)            262400    \n",
            "                                                                 \n",
            " batch_normalization_5 (Batc  (None, 8, 256)           1024      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_4 (Activation)   (None, 8, 256)            0         \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 8, 256)            0         \n",
            "                                                                 \n",
            " max_pooling1d_3 (MaxPooling  (None, 1, 256)           0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 256)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 6)                 1542      \n",
            "                                                                 \n",
            " activation_5 (Activation)   (None, 6)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 266,634\n",
            "Trainable params: 265,864\n",
            "Non-trainable params: 770\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "#new_model=keras.models.load_model('/content/drive/My Drive/augmanted_radvass')\n",
        "new_model=keras.models.load_model('/content/drive/My Drive/graduation project/audio/model/original_augmation_Savee_400_epoch_8_kernal_size_and_bat')\n",
        "new_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pufwy7Ia3b12",
        "outputId": "f889e35b-6714-4cd4-87ed-cf5836dd6933"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 4ms/step - loss: 0.7150 - accuracy: 0.6667\n",
            "Restored model, accuracy: 66.67%\n"
          ]
        }
      ],
      "source": [
        "loss, acc = model.evaluate(x_test, emo_test)\n",
        "print(\"Restored model, accuracy: {:5.2f}%\".format(100*acc))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gqYIsrpY3drM",
        "outputId": "c1d84170-09b8-45e9-d28d-aa8efc776a45"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "36/36 [==============================] - 0s 5ms/step - loss: 0.0012 - accuracy: 1.0000\n",
            "Restored model, accuracy: 100.00%\n"
          ]
        }
      ],
      "source": [
        "loss, acc = model.evaluate(x_train, y_train)\n",
        "print(\"Restored model, accuracy: {:5.2f}%\".format(100*acc))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 606
        },
        "id": "biI56TZV3fPV",
        "outputId": "fd8850aa-f232-40cf-a053-a16fbce830fb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.82      0.82        11\n",
            "           1       0.50      0.40      0.44         5\n",
            "           2       0.44      0.57      0.50         7\n",
            "           3       0.80      1.00      0.89         4\n",
            "           4       0.71      0.56      0.63         9\n",
            "\n",
            "    accuracy                           0.67        36\n",
            "   macro avg       0.66      0.67      0.66        36\n",
            "weighted avg       0.67      0.67      0.66        36\n",
            "\n",
            "----accuracy score 66.66666666666666 ----\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-35-ced4651393a1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m#df_cm = pd.DataFrame(cm)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mclass_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'neutral'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'calm'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'happy'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'sad'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'angry'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'fearful'\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mdf_cm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0msn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheatmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_cm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mannot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfmt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    676\u001b[0m                     \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m                     \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 678\u001b[0;31m                     \u001b[0mtyp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmanager\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    679\u001b[0m                 )\n\u001b[1;32m    680\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36mndarray_to_mgr\u001b[0;34m(values, index, columns, dtype, copy, typ)\u001b[0m\n\u001b[1;32m    322\u001b[0m     )\n\u001b[1;32m    323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m     \u001b[0m_check_values_indices_shape_match\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtyp\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"array\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36m_check_values_indices_shape_match\u001b[0;34m(values, index, columns)\u001b[0m\n\u001b[1;32m    391\u001b[0m         \u001b[0mpassed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m         \u001b[0mimplied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 393\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Shape of passed values is {passed}, indices imply {implied}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Shape of passed values is (5, 5), indices imply (6, 6)"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix,accuracy_score\n",
        "import seaborn as sn\n",
        "\n",
        "print(classification_report(emo_test,abc))\n",
        "\n",
        "acc = float(accuracy_score(emo_test,abc))*100\n",
        "print(\"----accuracy score %s ----\" % acc)\n",
        "\n",
        "cm = confusion_matrix(emo_test,abc)\n",
        "#df_cm = pd.DataFrame(cm)\n",
        "class_names = ['neutral','calm', 'happy','sad','angry', 'fearful' ]\n",
        "df_cm = pd.DataFrame(cm, index=class_names, columns=class_names,)\n",
        "sn.heatmap(df_cm, annot=True, fmt='')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "59mA6uxedOYx"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "_original_augmation_Savee_400_epoch_8_kernal_size_and_bat.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}