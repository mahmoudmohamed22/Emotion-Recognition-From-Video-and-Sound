{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ramadan adam 0.0002 1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9SRCO-a_AlH5",
        "outputId": "c6091392-b67a-4fe6-9882-36bc042908e5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install librosa"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oi8pWV3yBVjO",
        "outputId": "5661addc-edcf-414a-9ebe-091a9f15d901"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.7/dist-packages (0.8.1)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.4.1)\n",
            "Requirement already satisfied: resampy>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from librosa) (0.2.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (21.3)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.1.0)\n",
            "Requirement already satisfied: audioread>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (2.1.9)\n",
            "Requirement already satisfied: decorator>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied: soundfile>=0.10.2 in /usr/local/lib/python3.7/dist-packages (from librosa) (0.10.3.post1)\n",
            "Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.0.2)\n",
            "Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.6.0)\n",
            "Requirement already satisfied: numba>=0.43.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (0.51.2)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.21.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba>=0.43.0->librosa) (57.4.0)\n",
            "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba>=0.43.0->librosa) (0.34.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->librosa) (3.0.9)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from pooch>=1.0->librosa) (2.23.0)\n",
            "Requirement already satisfied: appdirs>=1.3.0 in /usr/local/lib/python3.7/dist-packages (from pooch>=1.0->librosa) (1.4.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2022.5.18.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2.10)\n",
            "Requirement already satisfied: six>=1.3 in /usr/local/lib/python3.7/dist-packages (from resampy>=0.2.2->librosa) (1.15.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn!=0.19.0,>=0.14.0->librosa) (3.1.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.7/dist-packages (from soundfile>=0.10.2->librosa) (1.15.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.0->soundfile>=0.10.2->librosa) (2.21)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HJjcbxwy46bG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "c9a2bc5a-23d0-4141-a27e-455af717f6b7"
      },
      "source": [
        "# Orignial Notebook: https://github.com/MITESHPUTHRANNEU/Speech-Emotion-Analyzer/blob/master/final_results_gender_test.ipynb\n",
        "# This notebook author: Reza Chu\n",
        "# Last Editing Date: 31st May 2019\n",
        "\n",
        "## Python\n",
        "import os\n",
        "import random\n",
        "import sys\n",
        "\n",
        "import IPython\n",
        "from IPython.display import Audio\n",
        "from IPython.display import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "## Package\n",
        "import glob \n",
        "import keras\n",
        "import IPython.display as ipd\n",
        "import librosa\n",
        "import librosa.display\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import plotly.graph_objs as go\n",
        "import plotly.offline as py\n",
        "import plotly.tools as tls\n",
        "import seaborn as sns\n",
        "import scipy.io.wavfile\n",
        "import tensorflow as tf\n",
        "py.init_notebook_mode(connected=True)\n",
        "\n",
        "## Keras\n",
        "from keras import regularizers\n",
        "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping\n",
        "from keras.callbacks import  History, ReduceLROnPlateau, CSVLogger\n",
        "from keras.models import Model, Sequential\n",
        "from keras.layers import Dense, Embedding, LSTM\n",
        "from keras.layers import Input, Flatten, Dropout, Activation, BatchNormalization\n",
        "from keras.layers import Conv1D, MaxPooling1D, AveragePooling1D\n",
        "from keras.preprocessing import sequence\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.utils import np_utils\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "## Sklearn\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "## Rest\n",
        "from scipy.fftpack import fft\n",
        "from scipy import signal\n",
        "from scipy.io import wavfile\n",
        "from tqdm import tqdm\n",
        "\n",
        "input_duration=3\n",
        "# % pylab inline"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "        <script type=\"text/javascript\">\n",
              "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
              "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
              "        if (typeof require !== 'undefined') {\n",
              "        require.undef(\"plotly\");\n",
              "        requirejs.config({\n",
              "            paths: {\n",
              "                'plotly': ['https://cdn.plot.ly/plotly-2.8.3.min']\n",
              "            }\n",
              "        });\n",
              "        require(['plotly'], function(Plotly) {\n",
              "            window._Plotly = Plotly;\n",
              "        });\n",
              "        }\n",
              "        </script>\n",
              "        "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#radvass speech and song\n",
        "import time\n",
        "import os\n",
        "import librosa\n",
        "from librosa import display\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "count=0\n",
        "path1 = '/content/drive/MyDrive/RAVDESS_speech'\n",
        "path2 = '/content/drive/MyDrive/RAVDESS_song'\n",
        "\n",
        "lst = []\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "for subdir, dirs, files in os.walk(path2):\n",
        "  print(dirs)\n",
        "  print(subdir)\n",
        "  #print(files)\n",
        "  for file in files:\n",
        "      try:\n",
        "        count +=1\n",
        "        #Load librosa array, obtain mfcss, store the file and the mcss information in a new array\n",
        "        X, sample_rate = librosa.load(os.path.join(subdir,file), res_type='kaiser_fast')\n",
        "        mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T,axis=0) \n",
        "        # The instruction below converts the labels (from 1 to 8) to a series from 0 to 7\n",
        "        # This is because our predictor needs to start from 0 otherwise it will try to predict also 0.\n",
        "        file = int(file[7:8]) - 1 \n",
        "        arr = mfccs, file\n",
        "        lst.append(arr)\n",
        "      # If the file is not valid, skip it\n",
        "      except ValueError:\n",
        "        continue\n",
        "\n",
        "for subdir, dirs, files in os.walk(path1):\n",
        "  print(dirs)\n",
        "  print(subdir)\n",
        " # print(files)\n",
        "  for file in files:\n",
        "      try:\n",
        "        #Load librosa array, obtain mfcss, store the file and the mcss information in a new array\n",
        "        X, sample_rate = librosa.load(os.path.join(subdir,file), res_type='kaiser_fast')\n",
        "        mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T,axis=0) \n",
        "        # The instruction below converts the labels (from 1 to 8) to a series from 0 to 7\n",
        "        # This is because our predictor needs to start from 0 otherwise it will try to predict also 0.\n",
        "        file = int(file[7:8]) - 1 \n",
        "        if(file ==6 or file==7):\n",
        "          continue\n",
        "        count +=1\n",
        "        arr = mfccs, file\n",
        "        lst.append(arr)\n",
        "      # If the file is not valid, skip it\n",
        "      except ValueError:\n",
        "        continue\n",
        "\n",
        "\n",
        "\n",
        "print(\"--- Data loaded. Loading time: %s seconds ---\" % (time.time() - start_time))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IfuyRZl42ccZ",
        "outputId": "ce249970-9930-450a-db19-8e2b3f9edde8"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Actor_10', 'Actor_11', 'Actor_13', 'Actor_12', 'Actor_14', 'Actor_15', 'Actor_16', 'Actor_17', 'Actor_18', 'Actor_19', 'Actor_21', 'Actor_22', 'Actor_23', 'Actor_09', 'Actor_24', 'Actor_04', 'Actor_08', 'Actor_03', 'Actor_02', 'Actor_06', 'Actor_05', 'Actor_01', 'Actor_07', 'Actor_20']\n",
            "/content/drive/MyDrive/RAVDESS_song\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_10\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_11\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_13\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_12\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_14\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_15\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_16\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_17\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_18\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_19\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_21\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_22\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_23\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_09\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_24\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_04\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_08\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_03\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_02\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_06\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_05\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_01\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_07\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_20\n",
            "['Actor_05', 'Actor_08', 'Actor_10', 'Actor_04', 'Actor_09', 'Actor_14', 'Actor_12', 'Actor_13', 'Actor_11', 'Actor_06', 'Actor_24', 'Actor_07', 'Actor_23', 'Actor_22', 'Actor_21', 'Actor_20', 'Actor_02', 'Actor_19', 'Actor_18', 'Actor_17', 'Actor_16', 'Actor_15', 'Actor_03', 'Actor_01']\n",
            "/content/drive/MyDrive/RAVDESS_speech\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_05\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_08\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_10\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_04\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_09\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_14\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_12\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_13\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_11\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_06\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_24\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_07\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_23\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_22\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_21\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_20\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_02\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_19\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_18\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_17\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_16\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_15\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_03\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_01\n",
            "--- Data loaded. Loading time: 204.12607288360596 seconds ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "count"
      ],
      "metadata": {
        "id": "Ltlhi25L2AI5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92f64156-e27a-4381-e558-85094fc41c56"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2068"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy.core.fromnumeric import size\n",
        "size(lst)"
      ],
      "metadata": {
        "id": "HMOH7d7mzHB7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "454c6795-9625-4c4a-aae1-8816c01db98f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/core/fromnumeric.py:3208: VisibleDeprecationWarning:\n",
            "\n",
            "Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4136"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating X and y: zip makes a list of all the first elements, and a list of all the second elements.\n",
        "X, y = zip(*lst)"
      ],
      "metadata": {
        "id": "ocdL7tSTBoMt"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "X = np.asarray(X)\n",
        "y = np.asarray(y)\n",
        "X.shape, y.shape"
      ],
      "metadata": {
        "id": "vHKwUGTbBtnF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52b5b212-692b-49e9-b357-6d6f08d864df"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((2068, 40), (2068,))"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "id": "2sUCtbfMztE5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e14844a2-b3c4-439c-e82f-783c1f91504a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2068, 40)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Saving joblib files to not load them again with the loop above\n",
        "\n",
        "# import joblib\n",
        "\n",
        "# X_name = 'x.joblib'\n",
        "# y_name = 'y.joblib'\n",
        "# save_dir = '/content/drive/My Drive/graduation project/audio/paper_code/features'\n",
        "\n",
        "# savedX = joblib.dump(X, os.path.join(save_dir, X_name))\n",
        "# savedy = joblib.dump(y, os.path.join(save_dir, y_name))"
      ],
      "metadata": {
        "id": "UCzic8rlDcuk"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Loading saved models\n",
        "# import joblib\n",
        "# X = joblib.load('/content/drive/My Drive/graduation project/audio/paper_code/features/x.joblib')\n",
        "# y = joblib.load('/content/drive/My Drive/graduation project/audio/paper_code/features/y.joblib')"
      ],
      "metadata": {
        "id": "Q35CN6zDrzg1"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7PSTurzjCo5K",
        "outputId": "d213d88d-ce24-4cb7-8fe3-c1f3c15c8ce2"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2068, 40)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2,train_size=0.8, random_state=42)\n",
        "X_valid, X_test, y_valid, y_test = train_test_split(X_test,y_test, test_size=0.5,train_size=0.5, random_state=42)"
      ],
      "metadata": {
        "id": "Ai4Fy5cPCiq1"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "x_traincnn = np.expand_dims(X_train, axis=2)\n",
        "x_testcnn = np.expand_dims(X_test, axis=2)\n",
        "X_valid= np.expand_dims(X_valid, axis=2)"
      ],
      "metadata": {
        "id": "tp1Fm5K3CEXu"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_traincnn.shape, x_testcnn.shape , X_valid.shape"
      ],
      "metadata": {
        "id": "RI0MxoIPBws5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2aa0962f-a4d1-4f08-ae28-139e10fec529"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1654, 40, 1), (207, 40, 1), (207, 40, 1))"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow"
      ],
      "metadata": {
        "id": "goxL4Y3jKICC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8cdd7ae3-35ee-446e-ab94-1a6e2f958331"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (2.8.2+zzzcolab20220527125636)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.46.3)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.0.0)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.21.6)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (14.0.1)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.5.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow) (57.4.0)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.17.3)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (4.2.0)\n",
            "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.26.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow) (1.5.2)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.35.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (3.3.7)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.23.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.8.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.6.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.4.6)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.2.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (4.11.4)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (3.8.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2022.5.18.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (3.2.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keras"
      ],
      "metadata": {
        "id": "EkcmN9UrKSxj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fad24552-53e3-4816-90d3-f919cc87e96c"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.7/dist-packages (2.8.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from keras.preprocessing import sequence\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from keras.layers import Input, Flatten, Dropout, Activation\n",
        "from keras.layers import Conv1D, MaxPooling1D\n",
        "from keras.models import Model\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras import optimizers\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv1D(128, 8,padding='same', #classifier.add(Convolution2D(64, (3, 3), padding = 'same', input_shape = (128, 128, 3), activation = 'relu'))\n",
        "                 input_shape=(40,1)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(MaxPooling1D(pool_size=(5)))\n",
        "\n",
        "\n",
        "model.add(Conv1D(256,8,padding='same',))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(MaxPooling1D(pool_size=(5)))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(256))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(256))\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "model.add(Dense(6))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "opt = tf.keras.optimizers.Adam(lr=0.0002)\n",
        "#opt = tf.keras.optimizers.RMSprop(lr=0.0001, rho=0.9, epsilon=1e-07, decay=0.0)\n",
        "#opt = tf.keras.optimizers.SGD(lr=0.001, momentum=0.0, decay=0.0, nesterov=False)"
      ],
      "metadata": {
        "id": "g74fXWVAC4Cr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "929560db-3c5f-4cba-e83e-548f5f3e150f"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning:\n",
            "\n",
            "The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H6ukOxAGC_I4",
        "outputId": "96adaa3d-8ddd-4f48-8c19-11b80098fc08"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d (Conv1D)             (None, 40, 128)           1152      \n",
            "                                                                 \n",
            " activation (Activation)     (None, 40, 128)           0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 40, 128)           0         \n",
            "                                                                 \n",
            " max_pooling1d (MaxPooling1D  (None, 8, 128)           0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv1d_1 (Conv1D)           (None, 8, 256)            262400    \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 8, 256)            0         \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 8, 256)            0         \n",
            "                                                                 \n",
            " max_pooling1d_1 (MaxPooling  (None, 1, 256)           0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 256)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 256)               65792     \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 256)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 256)               65792     \n",
            "                                                                 \n",
            " activation_3 (Activation)   (None, 256)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 6)                 1542      \n",
            "                                                                 \n",
            " activation_4 (Activation)   (None, 6)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 396,678\n",
            "Trainable params: 396,678\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='sparse_categorical_crossentropy',\n",
        "              optimizer=opt,\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "AbMlLNk4DCBM"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#cnnhistory=model.fit(x_traincnn, y_train, batch_size=16, epochs=700, validation_data=(x_testcnn, y_test))\n",
        "cnnhistory=model.fit(x_traincnn, y_train, batch_size=16, epochs=500 , validation_data=(X_valid, y_valid))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RI1v2AuADFhy",
        "outputId": "bd3f9a9f-86ba-4e50-d76c-92cfa2c3bfc7"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "104/104 [==============================] - 4s 11ms/step - loss: 4.3540 - accuracy: 0.1898 - val_loss: 1.8713 - val_accuracy: 0.1739\n",
            "Epoch 2/500\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 2.4024 - accuracy: 0.1886 - val_loss: 1.6948 - val_accuracy: 0.2464\n",
            "Epoch 3/500\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 2.0660 - accuracy: 0.2128 - val_loss: 1.6869 - val_accuracy: 0.2947\n",
            "Epoch 4/500\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 1.9340 - accuracy: 0.2152 - val_loss: 1.7273 - val_accuracy: 0.2850\n",
            "Epoch 5/500\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 1.8280 - accuracy: 0.2352 - val_loss: 1.6643 - val_accuracy: 0.2995\n",
            "Epoch 6/500\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 1.8305 - accuracy: 0.2467 - val_loss: 1.7072 - val_accuracy: 0.2947\n",
            "Epoch 7/500\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 1.8298 - accuracy: 0.2461 - val_loss: 1.7416 - val_accuracy: 0.2077\n",
            "Epoch 8/500\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 1.7795 - accuracy: 0.2485 - val_loss: 1.6512 - val_accuracy: 0.3237\n",
            "Epoch 9/500\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 1.7223 - accuracy: 0.2799 - val_loss: 1.6182 - val_accuracy: 0.3285\n",
            "Epoch 10/500\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 1.7168 - accuracy: 0.2811 - val_loss: 1.6678 - val_accuracy: 0.2754\n",
            "Epoch 11/500\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 1.6809 - accuracy: 0.2817 - val_loss: 1.6396 - val_accuracy: 0.3188\n",
            "Epoch 12/500\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 1.6736 - accuracy: 0.2799 - val_loss: 1.5677 - val_accuracy: 0.3527\n",
            "Epoch 13/500\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 1.6441 - accuracy: 0.3023 - val_loss: 1.5973 - val_accuracy: 0.3333\n",
            "Epoch 14/500\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 1.6252 - accuracy: 0.3204 - val_loss: 1.5741 - val_accuracy: 0.3575\n",
            "Epoch 15/500\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 1.6061 - accuracy: 0.3295 - val_loss: 1.5590 - val_accuracy: 0.3768\n",
            "Epoch 16/500\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 1.5851 - accuracy: 0.3362 - val_loss: 1.5107 - val_accuracy: 0.4106\n",
            "Epoch 17/500\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 1.5730 - accuracy: 0.3422 - val_loss: 1.4811 - val_accuracy: 0.3865\n",
            "Epoch 18/500\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 1.5255 - accuracy: 0.3682 - val_loss: 1.5152 - val_accuracy: 0.3720\n",
            "Epoch 19/500\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 1.5163 - accuracy: 0.3549 - val_loss: 1.4318 - val_accuracy: 0.4589\n",
            "Epoch 20/500\n",
            "104/104 [==============================] - 1s 9ms/step - loss: 1.4470 - accuracy: 0.4021 - val_loss: 1.4498 - val_accuracy: 0.4493\n",
            "Epoch 21/500\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 1.4352 - accuracy: 0.4081 - val_loss: 1.3812 - val_accuracy: 0.4493\n",
            "Epoch 22/500\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 1.4171 - accuracy: 0.4148 - val_loss: 1.3486 - val_accuracy: 0.4251\n",
            "Epoch 23/500\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 1.3910 - accuracy: 0.4238 - val_loss: 1.2940 - val_accuracy: 0.5459\n",
            "Epoch 24/500\n",
            "104/104 [==============================] - 1s 9ms/step - loss: 1.3827 - accuracy: 0.4256 - val_loss: 1.3172 - val_accuracy: 0.5169\n",
            "Epoch 25/500\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 1.3327 - accuracy: 0.4395 - val_loss: 1.2270 - val_accuracy: 0.5459\n",
            "Epoch 26/500\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 1.3078 - accuracy: 0.4559 - val_loss: 1.2136 - val_accuracy: 0.5700\n",
            "Epoch 27/500\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 1.2970 - accuracy: 0.4553 - val_loss: 1.2474 - val_accuracy: 0.5362\n",
            "Epoch 28/500\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 1.2699 - accuracy: 0.4867 - val_loss: 1.1729 - val_accuracy: 0.5797\n",
            "Epoch 29/500\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 1.2396 - accuracy: 0.5139 - val_loss: 1.1937 - val_accuracy: 0.5362\n",
            "Epoch 30/500\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 1.2146 - accuracy: 0.5000 - val_loss: 1.2052 - val_accuracy: 0.5556\n",
            "Epoch 31/500\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 1.2326 - accuracy: 0.4873 - val_loss: 1.1487 - val_accuracy: 0.5556\n",
            "Epoch 32/500\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 1.2305 - accuracy: 0.4825 - val_loss: 1.2277 - val_accuracy: 0.5459\n",
            "Epoch 33/500\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 1.1891 - accuracy: 0.5206 - val_loss: 1.1144 - val_accuracy: 0.6087\n",
            "Epoch 34/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 1.1777 - accuracy: 0.5218 - val_loss: 1.1118 - val_accuracy: 0.6087\n",
            "Epoch 35/500\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 1.1468 - accuracy: 0.5308 - val_loss: 1.1049 - val_accuracy: 0.5845\n",
            "Epoch 36/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.1400 - accuracy: 0.5260 - val_loss: 1.0688 - val_accuracy: 0.6280\n",
            "Epoch 37/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.1171 - accuracy: 0.5496 - val_loss: 1.1006 - val_accuracy: 0.5556\n",
            "Epoch 38/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.1093 - accuracy: 0.5357 - val_loss: 1.0889 - val_accuracy: 0.5121\n",
            "Epoch 39/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0941 - accuracy: 0.5538 - val_loss: 1.0655 - val_accuracy: 0.5845\n",
            "Epoch 40/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.0687 - accuracy: 0.5641 - val_loss: 1.0144 - val_accuracy: 0.6425\n",
            "Epoch 41/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.0671 - accuracy: 0.5580 - val_loss: 1.0365 - val_accuracy: 0.5700\n",
            "Epoch 42/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.0305 - accuracy: 0.5828 - val_loss: 1.0168 - val_accuracy: 0.6087\n",
            "Epoch 43/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.0364 - accuracy: 0.5683 - val_loss: 1.0004 - val_accuracy: 0.6184\n",
            "Epoch 44/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0174 - accuracy: 0.5871 - val_loss: 1.0203 - val_accuracy: 0.5797\n",
            "Epoch 45/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9894 - accuracy: 0.5852 - val_loss: 1.0030 - val_accuracy: 0.5749\n",
            "Epoch 46/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.0016 - accuracy: 0.5834 - val_loss: 0.9901 - val_accuracy: 0.6135\n",
            "Epoch 47/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.9780 - accuracy: 0.6167 - val_loss: 0.9692 - val_accuracy: 0.6087\n",
            "Epoch 48/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.9522 - accuracy: 0.6082 - val_loss: 0.9715 - val_accuracy: 0.5894\n",
            "Epoch 49/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9593 - accuracy: 0.5943 - val_loss: 0.9652 - val_accuracy: 0.6377\n",
            "Epoch 50/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9555 - accuracy: 0.6112 - val_loss: 0.9486 - val_accuracy: 0.6087\n",
            "Epoch 51/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.9354 - accuracy: 0.6191 - val_loss: 0.9589 - val_accuracy: 0.6184\n",
            "Epoch 52/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9049 - accuracy: 0.6403 - val_loss: 0.9419 - val_accuracy: 0.6473\n",
            "Epoch 53/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.8933 - accuracy: 0.6451 - val_loss: 0.9422 - val_accuracy: 0.6135\n",
            "Epoch 54/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.9219 - accuracy: 0.6185 - val_loss: 1.0039 - val_accuracy: 0.5797\n",
            "Epoch 55/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.8912 - accuracy: 0.6378 - val_loss: 0.9804 - val_accuracy: 0.5990\n",
            "Epoch 56/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.8666 - accuracy: 0.6475 - val_loss: 0.8832 - val_accuracy: 0.6329\n",
            "Epoch 57/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.8594 - accuracy: 0.6475 - val_loss: 0.9024 - val_accuracy: 0.6329\n",
            "Epoch 58/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8748 - accuracy: 0.6487 - val_loss: 0.9323 - val_accuracy: 0.6425\n",
            "Epoch 59/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.8570 - accuracy: 0.6608 - val_loss: 0.9016 - val_accuracy: 0.6473\n",
            "Epoch 60/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.8346 - accuracy: 0.6596 - val_loss: 0.8949 - val_accuracy: 0.6232\n",
            "Epoch 61/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.8647 - accuracy: 0.6566 - val_loss: 0.8976 - val_accuracy: 0.6329\n",
            "Epoch 62/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.8202 - accuracy: 0.6687 - val_loss: 0.9578 - val_accuracy: 0.6280\n",
            "Epoch 63/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.8487 - accuracy: 0.6602 - val_loss: 0.9102 - val_accuracy: 0.6473\n",
            "Epoch 64/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.7972 - accuracy: 0.6790 - val_loss: 0.8472 - val_accuracy: 0.6715\n",
            "Epoch 65/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7893 - accuracy: 0.6747 - val_loss: 0.8691 - val_accuracy: 0.6570\n",
            "Epoch 66/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7841 - accuracy: 0.7001 - val_loss: 0.8629 - val_accuracy: 0.6522\n",
            "Epoch 67/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7916 - accuracy: 0.6771 - val_loss: 0.8908 - val_accuracy: 0.6522\n",
            "Epoch 68/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7971 - accuracy: 0.6826 - val_loss: 0.8669 - val_accuracy: 0.6667\n",
            "Epoch 69/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.7847 - accuracy: 0.6771 - val_loss: 0.8760 - val_accuracy: 0.6618\n",
            "Epoch 70/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7749 - accuracy: 0.6832 - val_loss: 0.8555 - val_accuracy: 0.6570\n",
            "Epoch 71/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.7413 - accuracy: 0.7068 - val_loss: 0.8500 - val_accuracy: 0.6522\n",
            "Epoch 72/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.7579 - accuracy: 0.6935 - val_loss: 0.8270 - val_accuracy: 0.6763\n",
            "Epoch 73/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.7202 - accuracy: 0.7044 - val_loss: 0.8730 - val_accuracy: 0.6425\n",
            "Epoch 74/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7287 - accuracy: 0.7110 - val_loss: 0.8340 - val_accuracy: 0.6667\n",
            "Epoch 75/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7225 - accuracy: 0.7116 - val_loss: 0.8367 - val_accuracy: 0.6522\n",
            "Epoch 76/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.7371 - accuracy: 0.7062 - val_loss: 0.8381 - val_accuracy: 0.6667\n",
            "Epoch 77/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.7264 - accuracy: 0.7092 - val_loss: 0.7963 - val_accuracy: 0.6667\n",
            "Epoch 78/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7365 - accuracy: 0.7031 - val_loss: 0.8214 - val_accuracy: 0.6908\n",
            "Epoch 79/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7188 - accuracy: 0.7170 - val_loss: 0.8070 - val_accuracy: 0.6763\n",
            "Epoch 80/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6908 - accuracy: 0.7285 - val_loss: 0.7863 - val_accuracy: 0.6570\n",
            "Epoch 81/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.6778 - accuracy: 0.7237 - val_loss: 0.7906 - val_accuracy: 0.6715\n",
            "Epoch 82/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.7032 - accuracy: 0.7243 - val_loss: 0.8036 - val_accuracy: 0.6812\n",
            "Epoch 83/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6882 - accuracy: 0.7297 - val_loss: 0.8138 - val_accuracy: 0.6570\n",
            "Epoch 84/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6691 - accuracy: 0.7249 - val_loss: 0.8054 - val_accuracy: 0.6667\n",
            "Epoch 85/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6746 - accuracy: 0.7346 - val_loss: 0.8437 - val_accuracy: 0.6425\n",
            "Epoch 86/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6757 - accuracy: 0.7364 - val_loss: 0.8162 - val_accuracy: 0.6667\n",
            "Epoch 87/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6355 - accuracy: 0.7449 - val_loss: 0.7662 - val_accuracy: 0.7005\n",
            "Epoch 88/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.6362 - accuracy: 0.7437 - val_loss: 0.7949 - val_accuracy: 0.6812\n",
            "Epoch 89/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.6327 - accuracy: 0.7479 - val_loss: 0.7769 - val_accuracy: 0.7101\n",
            "Epoch 90/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6458 - accuracy: 0.7437 - val_loss: 0.7772 - val_accuracy: 0.6522\n",
            "Epoch 91/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6314 - accuracy: 0.7563 - val_loss: 0.7571 - val_accuracy: 0.6860\n",
            "Epoch 92/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.6131 - accuracy: 0.7618 - val_loss: 0.7506 - val_accuracy: 0.6812\n",
            "Epoch 93/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.5979 - accuracy: 0.7648 - val_loss: 0.7381 - val_accuracy: 0.6908\n",
            "Epoch 94/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.5944 - accuracy: 0.7588 - val_loss: 0.7481 - val_accuracy: 0.7101\n",
            "Epoch 95/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.5894 - accuracy: 0.7672 - val_loss: 0.7784 - val_accuracy: 0.6715\n",
            "Epoch 96/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.5782 - accuracy: 0.7636 - val_loss: 0.7907 - val_accuracy: 0.6618\n",
            "Epoch 97/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6005 - accuracy: 0.7648 - val_loss: 0.7181 - val_accuracy: 0.7150\n",
            "Epoch 98/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6030 - accuracy: 0.7551 - val_loss: 0.7937 - val_accuracy: 0.6908\n",
            "Epoch 99/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.5781 - accuracy: 0.7769 - val_loss: 0.7394 - val_accuracy: 0.7053\n",
            "Epoch 100/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.5363 - accuracy: 0.7878 - val_loss: 0.7391 - val_accuracy: 0.7101\n",
            "Epoch 101/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.5654 - accuracy: 0.7787 - val_loss: 0.7516 - val_accuracy: 0.7053\n",
            "Epoch 102/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.5759 - accuracy: 0.7570 - val_loss: 0.7699 - val_accuracy: 0.6715\n",
            "Epoch 103/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.5620 - accuracy: 0.7811 - val_loss: 0.7327 - val_accuracy: 0.6667\n",
            "Epoch 104/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.5559 - accuracy: 0.7672 - val_loss: 0.7424 - val_accuracy: 0.7005\n",
            "Epoch 105/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.5425 - accuracy: 0.7805 - val_loss: 0.7339 - val_accuracy: 0.6812\n",
            "Epoch 106/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.5341 - accuracy: 0.7932 - val_loss: 0.7221 - val_accuracy: 0.7246\n",
            "Epoch 107/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.5348 - accuracy: 0.7956 - val_loss: 0.7338 - val_accuracy: 0.7005\n",
            "Epoch 108/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.5088 - accuracy: 0.7914 - val_loss: 0.7063 - val_accuracy: 0.6957\n",
            "Epoch 109/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.5309 - accuracy: 0.7908 - val_loss: 0.7016 - val_accuracy: 0.7488\n",
            "Epoch 110/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.5224 - accuracy: 0.7938 - val_loss: 0.7001 - val_accuracy: 0.7488\n",
            "Epoch 111/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.5061 - accuracy: 0.8029 - val_loss: 0.7465 - val_accuracy: 0.7343\n",
            "Epoch 112/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.5123 - accuracy: 0.8126 - val_loss: 0.6882 - val_accuracy: 0.7295\n",
            "Epoch 113/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.4908 - accuracy: 0.8011 - val_loss: 0.7589 - val_accuracy: 0.7295\n",
            "Epoch 114/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.5209 - accuracy: 0.7908 - val_loss: 0.6802 - val_accuracy: 0.7488\n",
            "Epoch 115/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.4687 - accuracy: 0.8174 - val_loss: 0.7143 - val_accuracy: 0.7101\n",
            "Epoch 116/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.5032 - accuracy: 0.8065 - val_loss: 0.6812 - val_accuracy: 0.7343\n",
            "Epoch 117/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.4446 - accuracy: 0.8222 - val_loss: 0.7127 - val_accuracy: 0.7150\n",
            "Epoch 118/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.4616 - accuracy: 0.8216 - val_loss: 0.6936 - val_accuracy: 0.7440\n",
            "Epoch 119/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.4436 - accuracy: 0.8337 - val_loss: 0.6901 - val_accuracy: 0.7150\n",
            "Epoch 120/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.4565 - accuracy: 0.8186 - val_loss: 0.7166 - val_accuracy: 0.7101\n",
            "Epoch 121/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.4341 - accuracy: 0.8277 - val_loss: 0.6788 - val_accuracy: 0.7391\n",
            "Epoch 122/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.4415 - accuracy: 0.8349 - val_loss: 0.6612 - val_accuracy: 0.7101\n",
            "Epoch 123/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.4518 - accuracy: 0.8186 - val_loss: 0.6684 - val_accuracy: 0.7101\n",
            "Epoch 124/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.4530 - accuracy: 0.8180 - val_loss: 0.7045 - val_accuracy: 0.7101\n",
            "Epoch 125/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.4489 - accuracy: 0.8271 - val_loss: 0.7241 - val_accuracy: 0.6957\n",
            "Epoch 126/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.4278 - accuracy: 0.8216 - val_loss: 0.6920 - val_accuracy: 0.7295\n",
            "Epoch 127/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.4107 - accuracy: 0.8470 - val_loss: 0.6879 - val_accuracy: 0.7295\n",
            "Epoch 128/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.4130 - accuracy: 0.8380 - val_loss: 0.7005 - val_accuracy: 0.7101\n",
            "Epoch 129/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.3986 - accuracy: 0.8489 - val_loss: 0.7691 - val_accuracy: 0.6860\n",
            "Epoch 130/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.4118 - accuracy: 0.8489 - val_loss: 0.6682 - val_accuracy: 0.7391\n",
            "Epoch 131/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.3882 - accuracy: 0.8573 - val_loss: 0.6668 - val_accuracy: 0.7246\n",
            "Epoch 132/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.4021 - accuracy: 0.8356 - val_loss: 0.6627 - val_accuracy: 0.7536\n",
            "Epoch 133/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.3887 - accuracy: 0.8446 - val_loss: 0.6544 - val_accuracy: 0.7391\n",
            "Epoch 134/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3864 - accuracy: 0.8507 - val_loss: 0.6679 - val_accuracy: 0.6957\n",
            "Epoch 135/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3695 - accuracy: 0.8579 - val_loss: 0.6627 - val_accuracy: 0.7295\n",
            "Epoch 136/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.3878 - accuracy: 0.8495 - val_loss: 0.6745 - val_accuracy: 0.7198\n",
            "Epoch 137/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.3608 - accuracy: 0.8688 - val_loss: 0.6661 - val_accuracy: 0.7198\n",
            "Epoch 138/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3574 - accuracy: 0.8615 - val_loss: 0.6894 - val_accuracy: 0.7246\n",
            "Epoch 139/500\n",
            "104/104 [==============================] - 1s 9ms/step - loss: 0.3718 - accuracy: 0.8519 - val_loss: 0.7207 - val_accuracy: 0.7440\n",
            "Epoch 140/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.3468 - accuracy: 0.8664 - val_loss: 0.6165 - val_accuracy: 0.7633\n",
            "Epoch 141/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.3927 - accuracy: 0.8555 - val_loss: 0.6788 - val_accuracy: 0.7101\n",
            "Epoch 142/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.3623 - accuracy: 0.8615 - val_loss: 0.6786 - val_accuracy: 0.7488\n",
            "Epoch 143/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.3515 - accuracy: 0.8646 - val_loss: 0.6639 - val_accuracy: 0.7343\n",
            "Epoch 144/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.3364 - accuracy: 0.8755 - val_loss: 0.6905 - val_accuracy: 0.7053\n",
            "Epoch 145/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.3311 - accuracy: 0.8700 - val_loss: 0.6861 - val_accuracy: 0.7295\n",
            "Epoch 146/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.3351 - accuracy: 0.8767 - val_loss: 0.6953 - val_accuracy: 0.7246\n",
            "Epoch 147/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3444 - accuracy: 0.8700 - val_loss: 0.6561 - val_accuracy: 0.7343\n",
            "Epoch 148/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.3337 - accuracy: 0.8652 - val_loss: 0.6230 - val_accuracy: 0.7633\n",
            "Epoch 149/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.3244 - accuracy: 0.8785 - val_loss: 0.6136 - val_accuracy: 0.7874\n",
            "Epoch 150/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.3181 - accuracy: 0.8761 - val_loss: 0.6381 - val_accuracy: 0.7681\n",
            "Epoch 151/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.3304 - accuracy: 0.8730 - val_loss: 0.6509 - val_accuracy: 0.7633\n",
            "Epoch 152/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.3145 - accuracy: 0.8839 - val_loss: 0.6331 - val_accuracy: 0.7681\n",
            "Epoch 153/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.3510 - accuracy: 0.8628 - val_loss: 0.6407 - val_accuracy: 0.7681\n",
            "Epoch 154/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.3243 - accuracy: 0.8742 - val_loss: 0.6350 - val_accuracy: 0.7633\n",
            "Epoch 155/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.3197 - accuracy: 0.8742 - val_loss: 0.6435 - val_accuracy: 0.7391\n",
            "Epoch 156/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.2991 - accuracy: 0.8942 - val_loss: 0.6023 - val_accuracy: 0.7729\n",
            "Epoch 157/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.3153 - accuracy: 0.8779 - val_loss: 0.6204 - val_accuracy: 0.7778\n",
            "Epoch 158/500\n",
            "104/104 [==============================] - 1s 9ms/step - loss: 0.2942 - accuracy: 0.8839 - val_loss: 0.6295 - val_accuracy: 0.7536\n",
            "Epoch 159/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.3082 - accuracy: 0.8791 - val_loss: 0.6203 - val_accuracy: 0.7585\n",
            "Epoch 160/500\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 0.3053 - accuracy: 0.8815 - val_loss: 0.6673 - val_accuracy: 0.7778\n",
            "Epoch 161/500\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.2635 - accuracy: 0.9008 - val_loss: 0.6043 - val_accuracy: 0.7729\n",
            "Epoch 162/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.2878 - accuracy: 0.8863 - val_loss: 0.6240 - val_accuracy: 0.7585\n",
            "Epoch 163/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.2714 - accuracy: 0.8960 - val_loss: 0.5996 - val_accuracy: 0.7729\n",
            "Epoch 164/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.2780 - accuracy: 0.8990 - val_loss: 0.6922 - val_accuracy: 0.7488\n",
            "Epoch 165/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.3351 - accuracy: 0.8748 - val_loss: 0.6088 - val_accuracy: 0.7778\n",
            "Epoch 166/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.2932 - accuracy: 0.8881 - val_loss: 0.5420 - val_accuracy: 0.7971\n",
            "Epoch 167/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.2722 - accuracy: 0.8972 - val_loss: 0.6083 - val_accuracy: 0.7536\n",
            "Epoch 168/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.2574 - accuracy: 0.9027 - val_loss: 0.6466 - val_accuracy: 0.7198\n",
            "Epoch 169/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.2960 - accuracy: 0.8815 - val_loss: 0.6620 - val_accuracy: 0.7536\n",
            "Epoch 170/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.2615 - accuracy: 0.9033 - val_loss: 0.6248 - val_accuracy: 0.7874\n",
            "Epoch 171/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.2561 - accuracy: 0.8936 - val_loss: 0.6386 - val_accuracy: 0.7923\n",
            "Epoch 172/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2423 - accuracy: 0.9105 - val_loss: 0.6921 - val_accuracy: 0.7585\n",
            "Epoch 173/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.2599 - accuracy: 0.8966 - val_loss: 0.6513 - val_accuracy: 0.7440\n",
            "Epoch 174/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2495 - accuracy: 0.9039 - val_loss: 0.6026 - val_accuracy: 0.7923\n",
            "Epoch 175/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.2710 - accuracy: 0.8966 - val_loss: 0.6346 - val_accuracy: 0.7729\n",
            "Epoch 176/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2481 - accuracy: 0.9154 - val_loss: 0.5444 - val_accuracy: 0.8116\n",
            "Epoch 177/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.2369 - accuracy: 0.9154 - val_loss: 0.6296 - val_accuracy: 0.7729\n",
            "Epoch 178/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.2715 - accuracy: 0.8996 - val_loss: 0.6327 - val_accuracy: 0.8116\n",
            "Epoch 179/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.2522 - accuracy: 0.9075 - val_loss: 0.6281 - val_accuracy: 0.7729\n",
            "Epoch 180/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.2510 - accuracy: 0.9021 - val_loss: 0.6020 - val_accuracy: 0.7729\n",
            "Epoch 181/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.2452 - accuracy: 0.9015 - val_loss: 0.6031 - val_accuracy: 0.7826\n",
            "Epoch 182/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.2327 - accuracy: 0.9141 - val_loss: 0.6122 - val_accuracy: 0.7633\n",
            "Epoch 183/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.2229 - accuracy: 0.9141 - val_loss: 0.6356 - val_accuracy: 0.7536\n",
            "Epoch 184/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.2283 - accuracy: 0.9178 - val_loss: 0.5896 - val_accuracy: 0.7826\n",
            "Epoch 185/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.2145 - accuracy: 0.9287 - val_loss: 0.6394 - val_accuracy: 0.7681\n",
            "Epoch 186/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.2358 - accuracy: 0.9123 - val_loss: 0.6286 - val_accuracy: 0.7633\n",
            "Epoch 187/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.2345 - accuracy: 0.9117 - val_loss: 0.7161 - val_accuracy: 0.7633\n",
            "Epoch 188/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.2417 - accuracy: 0.9051 - val_loss: 0.5787 - val_accuracy: 0.7923\n",
            "Epoch 189/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.2311 - accuracy: 0.9154 - val_loss: 0.7127 - val_accuracy: 0.7343\n",
            "Epoch 190/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.2068 - accuracy: 0.9160 - val_loss: 0.6259 - val_accuracy: 0.7681\n",
            "Epoch 191/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2316 - accuracy: 0.9105 - val_loss: 0.6003 - val_accuracy: 0.8019\n",
            "Epoch 192/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.2154 - accuracy: 0.9166 - val_loss: 0.5894 - val_accuracy: 0.7874\n",
            "Epoch 193/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.2114 - accuracy: 0.9226 - val_loss: 0.5882 - val_accuracy: 0.7971\n",
            "Epoch 194/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1961 - accuracy: 0.9293 - val_loss: 0.6346 - val_accuracy: 0.7391\n",
            "Epoch 195/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.2059 - accuracy: 0.9178 - val_loss: 0.6631 - val_accuracy: 0.7536\n",
            "Epoch 196/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.1980 - accuracy: 0.9226 - val_loss: 0.6389 - val_accuracy: 0.7729\n",
            "Epoch 197/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.2197 - accuracy: 0.9141 - val_loss: 0.6586 - val_accuracy: 0.7729\n",
            "Epoch 198/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.2128 - accuracy: 0.9196 - val_loss: 0.6146 - val_accuracy: 0.7874\n",
            "Epoch 199/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.2253 - accuracy: 0.9105 - val_loss: 0.6090 - val_accuracy: 0.7778\n",
            "Epoch 200/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.2205 - accuracy: 0.9250 - val_loss: 0.5923 - val_accuracy: 0.7971\n",
            "Epoch 201/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.1787 - accuracy: 0.9299 - val_loss: 0.6907 - val_accuracy: 0.7440\n",
            "Epoch 202/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.2008 - accuracy: 0.9238 - val_loss: 0.6863 - val_accuracy: 0.7440\n",
            "Epoch 203/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.1895 - accuracy: 0.9293 - val_loss: 0.6348 - val_accuracy: 0.8019\n",
            "Epoch 204/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.2034 - accuracy: 0.9293 - val_loss: 0.6197 - val_accuracy: 0.8116\n",
            "Epoch 205/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.1989 - accuracy: 0.9256 - val_loss: 0.6626 - val_accuracy: 0.7681\n",
            "Epoch 206/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.2156 - accuracy: 0.9238 - val_loss: 0.6417 - val_accuracy: 0.7874\n",
            "Epoch 207/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.2184 - accuracy: 0.9268 - val_loss: 0.6095 - val_accuracy: 0.8019\n",
            "Epoch 208/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.2041 - accuracy: 0.9232 - val_loss: 0.6588 - val_accuracy: 0.7874\n",
            "Epoch 209/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.1723 - accuracy: 0.9432 - val_loss: 0.6216 - val_accuracy: 0.7488\n",
            "Epoch 210/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.1648 - accuracy: 0.9438 - val_loss: 0.6530 - val_accuracy: 0.7778\n",
            "Epoch 211/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.1710 - accuracy: 0.9371 - val_loss: 0.6635 - val_accuracy: 0.8019\n",
            "Epoch 212/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.1956 - accuracy: 0.9274 - val_loss: 0.6087 - val_accuracy: 0.7778\n",
            "Epoch 213/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.1706 - accuracy: 0.9456 - val_loss: 0.6359 - val_accuracy: 0.7874\n",
            "Epoch 214/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.1760 - accuracy: 0.9407 - val_loss: 0.6528 - val_accuracy: 0.7874\n",
            "Epoch 215/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.1800 - accuracy: 0.9341 - val_loss: 0.7037 - val_accuracy: 0.7488\n",
            "Epoch 216/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.1612 - accuracy: 0.9426 - val_loss: 0.7708 - val_accuracy: 0.7295\n",
            "Epoch 217/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.2114 - accuracy: 0.9184 - val_loss: 0.6108 - val_accuracy: 0.7874\n",
            "Epoch 218/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.1761 - accuracy: 0.9383 - val_loss: 0.6464 - val_accuracy: 0.8164\n",
            "Epoch 219/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.1706 - accuracy: 0.9359 - val_loss: 0.6198 - val_accuracy: 0.7681\n",
            "Epoch 220/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.1676 - accuracy: 0.9365 - val_loss: 0.6245 - val_accuracy: 0.7826\n",
            "Epoch 221/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.1621 - accuracy: 0.9462 - val_loss: 0.6637 - val_accuracy: 0.7633\n",
            "Epoch 222/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.1753 - accuracy: 0.9353 - val_loss: 0.6738 - val_accuracy: 0.7874\n",
            "Epoch 223/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1556 - accuracy: 0.9468 - val_loss: 0.6006 - val_accuracy: 0.8116\n",
            "Epoch 224/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.1643 - accuracy: 0.9438 - val_loss: 0.6085 - val_accuracy: 0.8068\n",
            "Epoch 225/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.1778 - accuracy: 0.9311 - val_loss: 0.5708 - val_accuracy: 0.8116\n",
            "Epoch 226/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.1578 - accuracy: 0.9480 - val_loss: 0.6355 - val_accuracy: 0.7826\n",
            "Epoch 227/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.1558 - accuracy: 0.9444 - val_loss: 0.6064 - val_accuracy: 0.7874\n",
            "Epoch 228/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.1581 - accuracy: 0.9438 - val_loss: 0.6670 - val_accuracy: 0.7923\n",
            "Epoch 229/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1381 - accuracy: 0.9553 - val_loss: 0.6621 - val_accuracy: 0.8019\n",
            "Epoch 230/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.1372 - accuracy: 0.9474 - val_loss: 0.6959 - val_accuracy: 0.7778\n",
            "Epoch 231/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.1498 - accuracy: 0.9474 - val_loss: 0.5990 - val_accuracy: 0.7826\n",
            "Epoch 232/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.1555 - accuracy: 0.9432 - val_loss: 0.6135 - val_accuracy: 0.7826\n",
            "Epoch 233/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.1747 - accuracy: 0.9365 - val_loss: 0.7228 - val_accuracy: 0.7488\n",
            "Epoch 234/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.1700 - accuracy: 0.9371 - val_loss: 0.7170 - val_accuracy: 0.7585\n",
            "Epoch 235/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.1750 - accuracy: 0.9341 - val_loss: 0.6648 - val_accuracy: 0.7633\n",
            "Epoch 236/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1591 - accuracy: 0.9438 - val_loss: 0.6536 - val_accuracy: 0.7488\n",
            "Epoch 237/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.1488 - accuracy: 0.9426 - val_loss: 0.6610 - val_accuracy: 0.7729\n",
            "Epoch 238/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.1423 - accuracy: 0.9504 - val_loss: 0.7134 - val_accuracy: 0.7729\n",
            "Epoch 239/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.1619 - accuracy: 0.9383 - val_loss: 0.6430 - val_accuracy: 0.7826\n",
            "Epoch 240/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.1544 - accuracy: 0.9504 - val_loss: 0.6120 - val_accuracy: 0.7778\n",
            "Epoch 241/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.1312 - accuracy: 0.9522 - val_loss: 0.6559 - val_accuracy: 0.7874\n",
            "Epoch 242/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1453 - accuracy: 0.9480 - val_loss: 0.6536 - val_accuracy: 0.7826\n",
            "Epoch 243/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.1518 - accuracy: 0.9456 - val_loss: 0.6146 - val_accuracy: 0.7729\n",
            "Epoch 244/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.1434 - accuracy: 0.9474 - val_loss: 0.6717 - val_accuracy: 0.7681\n",
            "Epoch 245/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.1627 - accuracy: 0.9365 - val_loss: 0.6819 - val_accuracy: 0.7391\n",
            "Epoch 246/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1352 - accuracy: 0.9456 - val_loss: 0.6546 - val_accuracy: 0.7923\n",
            "Epoch 247/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.1373 - accuracy: 0.9450 - val_loss: 0.5444 - val_accuracy: 0.8019\n",
            "Epoch 248/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.1543 - accuracy: 0.9456 - val_loss: 0.5673 - val_accuracy: 0.7971\n",
            "Epoch 249/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.1354 - accuracy: 0.9516 - val_loss: 0.6328 - val_accuracy: 0.7488\n",
            "Epoch 250/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.1267 - accuracy: 0.9541 - val_loss: 0.6958 - val_accuracy: 0.7440\n",
            "Epoch 251/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.1785 - accuracy: 0.9347 - val_loss: 0.6141 - val_accuracy: 0.7633\n",
            "Epoch 252/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.1739 - accuracy: 0.9371 - val_loss: 0.7122 - val_accuracy: 0.7440\n",
            "Epoch 253/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.1563 - accuracy: 0.9389 - val_loss: 0.6577 - val_accuracy: 0.7633\n",
            "Epoch 254/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.1510 - accuracy: 0.9414 - val_loss: 0.6838 - val_accuracy: 0.7585\n",
            "Epoch 255/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.1301 - accuracy: 0.9547 - val_loss: 0.6220 - val_accuracy: 0.7923\n",
            "Epoch 256/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.1392 - accuracy: 0.9480 - val_loss: 0.7268 - val_accuracy: 0.7729\n",
            "Epoch 257/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.1289 - accuracy: 0.9486 - val_loss: 0.5966 - val_accuracy: 0.8068\n",
            "Epoch 258/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.1226 - accuracy: 0.9541 - val_loss: 0.6567 - val_accuracy: 0.7923\n",
            "Epoch 259/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.1092 - accuracy: 0.9571 - val_loss: 0.6114 - val_accuracy: 0.8261\n",
            "Epoch 260/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.1249 - accuracy: 0.9571 - val_loss: 0.6324 - val_accuracy: 0.7778\n",
            "Epoch 261/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1548 - accuracy: 0.9438 - val_loss: 0.6724 - val_accuracy: 0.7778\n",
            "Epoch 262/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1269 - accuracy: 0.9474 - val_loss: 0.6115 - val_accuracy: 0.7971\n",
            "Epoch 263/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1126 - accuracy: 0.9559 - val_loss: 0.7214 - val_accuracy: 0.7633\n",
            "Epoch 264/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1137 - accuracy: 0.9589 - val_loss: 0.6583 - val_accuracy: 0.7874\n",
            "Epoch 265/500\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.1274 - accuracy: 0.9522 - val_loss: 0.6441 - val_accuracy: 0.8019\n",
            "Epoch 266/500\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.1274 - accuracy: 0.9522 - val_loss: 0.6213 - val_accuracy: 0.7971\n",
            "Epoch 267/500\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.1291 - accuracy: 0.9534 - val_loss: 0.6511 - val_accuracy: 0.7826\n",
            "Epoch 268/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1374 - accuracy: 0.9498 - val_loss: 0.6795 - val_accuracy: 0.7874\n",
            "Epoch 269/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1393 - accuracy: 0.9510 - val_loss: 0.6794 - val_accuracy: 0.8019\n",
            "Epoch 270/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.1351 - accuracy: 0.9516 - val_loss: 0.6324 - val_accuracy: 0.7826\n",
            "Epoch 271/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.1120 - accuracy: 0.9625 - val_loss: 0.5976 - val_accuracy: 0.8019\n",
            "Epoch 272/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.1175 - accuracy: 0.9583 - val_loss: 0.5996 - val_accuracy: 0.8068\n",
            "Epoch 273/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1117 - accuracy: 0.9577 - val_loss: 0.6212 - val_accuracy: 0.8019\n",
            "Epoch 274/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.1234 - accuracy: 0.9541 - val_loss: 0.6848 - val_accuracy: 0.7633\n",
            "Epoch 275/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1114 - accuracy: 0.9595 - val_loss: 0.6538 - val_accuracy: 0.7778\n",
            "Epoch 276/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1180 - accuracy: 0.9559 - val_loss: 0.7127 - val_accuracy: 0.7681\n",
            "Epoch 277/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1063 - accuracy: 0.9559 - val_loss: 0.7184 - val_accuracy: 0.7778\n",
            "Epoch 278/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0838 - accuracy: 0.9710 - val_loss: 0.5867 - val_accuracy: 0.8116\n",
            "Epoch 279/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1100 - accuracy: 0.9631 - val_loss: 0.7037 - val_accuracy: 0.7826\n",
            "Epoch 280/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.1526 - accuracy: 0.9414 - val_loss: 0.6625 - val_accuracy: 0.7778\n",
            "Epoch 281/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1296 - accuracy: 0.9498 - val_loss: 0.7039 - val_accuracy: 0.7681\n",
            "Epoch 282/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.1366 - accuracy: 0.9492 - val_loss: 0.6409 - val_accuracy: 0.7923\n",
            "Epoch 283/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.1154 - accuracy: 0.9577 - val_loss: 0.7105 - val_accuracy: 0.7729\n",
            "Epoch 284/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.1070 - accuracy: 0.9661 - val_loss: 0.6664 - val_accuracy: 0.7971\n",
            "Epoch 285/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1167 - accuracy: 0.9589 - val_loss: 0.6984 - val_accuracy: 0.7923\n",
            "Epoch 286/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1200 - accuracy: 0.9553 - val_loss: 0.7012 - val_accuracy: 0.7778\n",
            "Epoch 287/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0971 - accuracy: 0.9625 - val_loss: 0.6827 - val_accuracy: 0.7778\n",
            "Epoch 288/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1348 - accuracy: 0.9480 - val_loss: 0.6714 - val_accuracy: 0.7826\n",
            "Epoch 289/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1353 - accuracy: 0.9510 - val_loss: 0.6095 - val_accuracy: 0.7971\n",
            "Epoch 290/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1413 - accuracy: 0.9504 - val_loss: 0.6345 - val_accuracy: 0.7971\n",
            "Epoch 291/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0881 - accuracy: 0.9692 - val_loss: 0.7799 - val_accuracy: 0.7681\n",
            "Epoch 292/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1249 - accuracy: 0.9553 - val_loss: 0.6961 - val_accuracy: 0.7971\n",
            "Epoch 293/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.0967 - accuracy: 0.9619 - val_loss: 0.7021 - val_accuracy: 0.7536\n",
            "Epoch 294/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1093 - accuracy: 0.9571 - val_loss: 0.6673 - val_accuracy: 0.8068\n",
            "Epoch 295/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1347 - accuracy: 0.9480 - val_loss: 0.7003 - val_accuracy: 0.8068\n",
            "Epoch 296/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.0887 - accuracy: 0.9655 - val_loss: 0.7065 - val_accuracy: 0.7923\n",
            "Epoch 297/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0949 - accuracy: 0.9674 - val_loss: 0.6570 - val_accuracy: 0.8068\n",
            "Epoch 298/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.1395 - accuracy: 0.9504 - val_loss: 0.6938 - val_accuracy: 0.7729\n",
            "Epoch 299/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1170 - accuracy: 0.9583 - val_loss: 0.6806 - val_accuracy: 0.7874\n",
            "Epoch 300/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1286 - accuracy: 0.9595 - val_loss: 0.6845 - val_accuracy: 0.7633\n",
            "Epoch 301/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1029 - accuracy: 0.9583 - val_loss: 0.6498 - val_accuracy: 0.8116\n",
            "Epoch 302/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1146 - accuracy: 0.9547 - val_loss: 0.6816 - val_accuracy: 0.7923\n",
            "Epoch 303/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0983 - accuracy: 0.9661 - val_loss: 0.6899 - val_accuracy: 0.7874\n",
            "Epoch 304/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1095 - accuracy: 0.9619 - val_loss: 0.7513 - val_accuracy: 0.7440\n",
            "Epoch 305/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0971 - accuracy: 0.9637 - val_loss: 0.6903 - val_accuracy: 0.7729\n",
            "Epoch 306/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1024 - accuracy: 0.9631 - val_loss: 0.6636 - val_accuracy: 0.8068\n",
            "Epoch 307/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.1170 - accuracy: 0.9577 - val_loss: 0.6233 - val_accuracy: 0.7778\n",
            "Epoch 308/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.1214 - accuracy: 0.9528 - val_loss: 0.6842 - val_accuracy: 0.7778\n",
            "Epoch 309/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1160 - accuracy: 0.9559 - val_loss: 0.7457 - val_accuracy: 0.7874\n",
            "Epoch 310/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0918 - accuracy: 0.9667 - val_loss: 0.7639 - val_accuracy: 0.7874\n",
            "Epoch 311/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1149 - accuracy: 0.9631 - val_loss: 0.6818 - val_accuracy: 0.7681\n",
            "Epoch 312/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1037 - accuracy: 0.9619 - val_loss: 0.6462 - val_accuracy: 0.7874\n",
            "Epoch 313/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.0968 - accuracy: 0.9619 - val_loss: 0.7137 - val_accuracy: 0.7681\n",
            "Epoch 314/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0902 - accuracy: 0.9643 - val_loss: 0.7051 - val_accuracy: 0.7971\n",
            "Epoch 315/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0920 - accuracy: 0.9686 - val_loss: 0.6971 - val_accuracy: 0.7874\n",
            "Epoch 316/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0819 - accuracy: 0.9698 - val_loss: 0.7012 - val_accuracy: 0.7971\n",
            "Epoch 317/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1034 - accuracy: 0.9637 - val_loss: 0.6245 - val_accuracy: 0.7778\n",
            "Epoch 318/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0794 - accuracy: 0.9764 - val_loss: 0.6927 - val_accuracy: 0.7874\n",
            "Epoch 319/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.1103 - accuracy: 0.9619 - val_loss: 0.7086 - val_accuracy: 0.8019\n",
            "Epoch 320/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.0899 - accuracy: 0.9667 - val_loss: 0.7402 - val_accuracy: 0.7681\n",
            "Epoch 321/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0878 - accuracy: 0.9631 - val_loss: 0.6417 - val_accuracy: 0.7826\n",
            "Epoch 322/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1010 - accuracy: 0.9643 - val_loss: 0.6647 - val_accuracy: 0.8019\n",
            "Epoch 323/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1201 - accuracy: 0.9559 - val_loss: 0.7229 - val_accuracy: 0.7923\n",
            "Epoch 324/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.0805 - accuracy: 0.9692 - val_loss: 0.6897 - val_accuracy: 0.7778\n",
            "Epoch 325/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1122 - accuracy: 0.9625 - val_loss: 0.8907 - val_accuracy: 0.7633\n",
            "Epoch 326/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1017 - accuracy: 0.9680 - val_loss: 0.6645 - val_accuracy: 0.8116\n",
            "Epoch 327/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1030 - accuracy: 0.9643 - val_loss: 0.7083 - val_accuracy: 0.7971\n",
            "Epoch 328/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0939 - accuracy: 0.9643 - val_loss: 0.7013 - val_accuracy: 0.7826\n",
            "Epoch 329/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1009 - accuracy: 0.9631 - val_loss: 0.6509 - val_accuracy: 0.7971\n",
            "Epoch 330/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.0812 - accuracy: 0.9667 - val_loss: 0.6915 - val_accuracy: 0.7923\n",
            "Epoch 331/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1007 - accuracy: 0.9667 - val_loss: 0.6431 - val_accuracy: 0.7874\n",
            "Epoch 332/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.0994 - accuracy: 0.9667 - val_loss: 0.7429 - val_accuracy: 0.8019\n",
            "Epoch 333/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.0972 - accuracy: 0.9589 - val_loss: 0.7188 - val_accuracy: 0.8019\n",
            "Epoch 334/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1208 - accuracy: 0.9571 - val_loss: 0.6798 - val_accuracy: 0.7971\n",
            "Epoch 335/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.0958 - accuracy: 0.9613 - val_loss: 0.7007 - val_accuracy: 0.7826\n",
            "Epoch 336/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0948 - accuracy: 0.9674 - val_loss: 0.6861 - val_accuracy: 0.8019\n",
            "Epoch 337/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.0973 - accuracy: 0.9631 - val_loss: 0.6827 - val_accuracy: 0.8116\n",
            "Epoch 338/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.0830 - accuracy: 0.9704 - val_loss: 0.7504 - val_accuracy: 0.7874\n",
            "Epoch 339/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.0877 - accuracy: 0.9649 - val_loss: 0.6113 - val_accuracy: 0.8116\n",
            "Epoch 340/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1132 - accuracy: 0.9583 - val_loss: 0.6803 - val_accuracy: 0.8019\n",
            "Epoch 341/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0969 - accuracy: 0.9661 - val_loss: 0.6010 - val_accuracy: 0.8164\n",
            "Epoch 342/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0857 - accuracy: 0.9710 - val_loss: 0.6785 - val_accuracy: 0.7923\n",
            "Epoch 343/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.0955 - accuracy: 0.9649 - val_loss: 0.6572 - val_accuracy: 0.8164\n",
            "Epoch 344/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1188 - accuracy: 0.9613 - val_loss: 0.7124 - val_accuracy: 0.7874\n",
            "Epoch 345/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.0859 - accuracy: 0.9692 - val_loss: 0.7123 - val_accuracy: 0.7874\n",
            "Epoch 346/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0978 - accuracy: 0.9674 - val_loss: 0.6368 - val_accuracy: 0.7826\n",
            "Epoch 347/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0700 - accuracy: 0.9686 - val_loss: 0.6113 - val_accuracy: 0.7971\n",
            "Epoch 348/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0938 - accuracy: 0.9674 - val_loss: 0.6462 - val_accuracy: 0.7826\n",
            "Epoch 349/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0871 - accuracy: 0.9649 - val_loss: 0.6902 - val_accuracy: 0.7681\n",
            "Epoch 350/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.1171 - accuracy: 0.9583 - val_loss: 0.7371 - val_accuracy: 0.7585\n",
            "Epoch 351/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.1019 - accuracy: 0.9649 - val_loss: 0.7890 - val_accuracy: 0.7440\n",
            "Epoch 352/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0871 - accuracy: 0.9710 - val_loss: 0.6694 - val_accuracy: 0.7778\n",
            "Epoch 353/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0897 - accuracy: 0.9680 - val_loss: 0.6262 - val_accuracy: 0.8116\n",
            "Epoch 354/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0734 - accuracy: 0.9764 - val_loss: 0.6514 - val_accuracy: 0.8357\n",
            "Epoch 355/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.0760 - accuracy: 0.9758 - val_loss: 0.7415 - val_accuracy: 0.7923\n",
            "Epoch 356/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0741 - accuracy: 0.9758 - val_loss: 0.7438 - val_accuracy: 0.7681\n",
            "Epoch 357/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0950 - accuracy: 0.9643 - val_loss: 0.6581 - val_accuracy: 0.7778\n",
            "Epoch 358/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0755 - accuracy: 0.9752 - val_loss: 0.6900 - val_accuracy: 0.8164\n",
            "Epoch 359/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0957 - accuracy: 0.9625 - val_loss: 0.6656 - val_accuracy: 0.7778\n",
            "Epoch 360/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0915 - accuracy: 0.9686 - val_loss: 0.6780 - val_accuracy: 0.7874\n",
            "Epoch 361/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.0879 - accuracy: 0.9704 - val_loss: 0.6251 - val_accuracy: 0.7826\n",
            "Epoch 362/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.0862 - accuracy: 0.9704 - val_loss: 0.6570 - val_accuracy: 0.8116\n",
            "Epoch 363/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0835 - accuracy: 0.9686 - val_loss: 0.7412 - val_accuracy: 0.7923\n",
            "Epoch 364/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.0780 - accuracy: 0.9728 - val_loss: 0.6806 - val_accuracy: 0.8019\n",
            "Epoch 365/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0977 - accuracy: 0.9655 - val_loss: 0.7042 - val_accuracy: 0.7633\n",
            "Epoch 366/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.0883 - accuracy: 0.9722 - val_loss: 0.7140 - val_accuracy: 0.7826\n",
            "Epoch 367/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0902 - accuracy: 0.9680 - val_loss: 0.7487 - val_accuracy: 0.8068\n",
            "Epoch 368/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.0884 - accuracy: 0.9680 - val_loss: 0.6645 - val_accuracy: 0.7826\n",
            "Epoch 369/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1041 - accuracy: 0.9607 - val_loss: 0.7896 - val_accuracy: 0.7440\n",
            "Epoch 370/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0794 - accuracy: 0.9728 - val_loss: 0.7840 - val_accuracy: 0.7633\n",
            "Epoch 371/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1051 - accuracy: 0.9619 - val_loss: 0.7292 - val_accuracy: 0.7874\n",
            "Epoch 372/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1022 - accuracy: 0.9667 - val_loss: 0.7048 - val_accuracy: 0.7681\n",
            "Epoch 373/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0801 - accuracy: 0.9716 - val_loss: 0.7797 - val_accuracy: 0.7681\n",
            "Epoch 374/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.0682 - accuracy: 0.9764 - val_loss: 0.6861 - val_accuracy: 0.7681\n",
            "Epoch 375/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0767 - accuracy: 0.9746 - val_loss: 0.8661 - val_accuracy: 0.7295\n",
            "Epoch 376/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1071 - accuracy: 0.9613 - val_loss: 0.8075 - val_accuracy: 0.7778\n",
            "Epoch 377/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0869 - accuracy: 0.9704 - val_loss: 0.7176 - val_accuracy: 0.7874\n",
            "Epoch 378/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.0953 - accuracy: 0.9710 - val_loss: 0.7135 - val_accuracy: 0.7874\n",
            "Epoch 379/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.0932 - accuracy: 0.9667 - val_loss: 0.6652 - val_accuracy: 0.7923\n",
            "Epoch 380/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0706 - accuracy: 0.9734 - val_loss: 0.6601 - val_accuracy: 0.7971\n",
            "Epoch 381/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0680 - accuracy: 0.9770 - val_loss: 0.7757 - val_accuracy: 0.7343\n",
            "Epoch 382/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0764 - accuracy: 0.9692 - val_loss: 0.7659 - val_accuracy: 0.7681\n",
            "Epoch 383/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0801 - accuracy: 0.9746 - val_loss: 0.7302 - val_accuracy: 0.7826\n",
            "Epoch 384/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.0656 - accuracy: 0.9782 - val_loss: 0.7148 - val_accuracy: 0.8116\n",
            "Epoch 385/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0810 - accuracy: 0.9686 - val_loss: 0.6967 - val_accuracy: 0.8116\n",
            "Epoch 386/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0835 - accuracy: 0.9667 - val_loss: 0.8374 - val_accuracy: 0.7536\n",
            "Epoch 387/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0688 - accuracy: 0.9740 - val_loss: 0.7752 - val_accuracy: 0.7681\n",
            "Epoch 388/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.0709 - accuracy: 0.9764 - val_loss: 0.8117 - val_accuracy: 0.7536\n",
            "Epoch 389/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0650 - accuracy: 0.9788 - val_loss: 0.6649 - val_accuracy: 0.7923\n",
            "Epoch 390/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0676 - accuracy: 0.9758 - val_loss: 0.7710 - val_accuracy: 0.7971\n",
            "Epoch 391/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0696 - accuracy: 0.9740 - val_loss: 0.6118 - val_accuracy: 0.8116\n",
            "Epoch 392/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.0667 - accuracy: 0.9746 - val_loss: 0.7561 - val_accuracy: 0.7826\n",
            "Epoch 393/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.0886 - accuracy: 0.9728 - val_loss: 0.6987 - val_accuracy: 0.7536\n",
            "Epoch 394/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0633 - accuracy: 0.9770 - val_loss: 0.7283 - val_accuracy: 0.7778\n",
            "Epoch 395/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1026 - accuracy: 0.9686 - val_loss: 0.7063 - val_accuracy: 0.7971\n",
            "Epoch 396/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.0852 - accuracy: 0.9649 - val_loss: 0.7501 - val_accuracy: 0.7971\n",
            "Epoch 397/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0989 - accuracy: 0.9649 - val_loss: 0.7932 - val_accuracy: 0.7729\n",
            "Epoch 398/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0868 - accuracy: 0.9698 - val_loss: 0.6912 - val_accuracy: 0.7778\n",
            "Epoch 399/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0907 - accuracy: 0.9667 - val_loss: 0.7378 - val_accuracy: 0.7440\n",
            "Epoch 400/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0628 - accuracy: 0.9788 - val_loss: 0.6401 - val_accuracy: 0.7826\n",
            "Epoch 401/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0469 - accuracy: 0.9825 - val_loss: 0.6204 - val_accuracy: 0.8116\n",
            "Epoch 402/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0573 - accuracy: 0.9819 - val_loss: 0.6098 - val_accuracy: 0.8261\n",
            "Epoch 403/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0924 - accuracy: 0.9680 - val_loss: 0.6809 - val_accuracy: 0.7923\n",
            "Epoch 404/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0924 - accuracy: 0.9637 - val_loss: 0.7574 - val_accuracy: 0.7971\n",
            "Epoch 405/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0735 - accuracy: 0.9686 - val_loss: 0.7967 - val_accuracy: 0.7536\n",
            "Epoch 406/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0973 - accuracy: 0.9643 - val_loss: 0.7498 - val_accuracy: 0.7874\n",
            "Epoch 407/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0707 - accuracy: 0.9758 - val_loss: 0.6737 - val_accuracy: 0.7729\n",
            "Epoch 408/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.1143 - accuracy: 0.9631 - val_loss: 0.7151 - val_accuracy: 0.8116\n",
            "Epoch 409/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0807 - accuracy: 0.9692 - val_loss: 0.6497 - val_accuracy: 0.7971\n",
            "Epoch 410/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0845 - accuracy: 0.9686 - val_loss: 0.6057 - val_accuracy: 0.8213\n",
            "Epoch 411/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.0776 - accuracy: 0.9752 - val_loss: 0.7586 - val_accuracy: 0.7633\n",
            "Epoch 412/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0544 - accuracy: 0.9813 - val_loss: 0.7742 - val_accuracy: 0.7923\n",
            "Epoch 413/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0652 - accuracy: 0.9788 - val_loss: 0.6851 - val_accuracy: 0.8019\n",
            "Epoch 414/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0676 - accuracy: 0.9758 - val_loss: 0.7749 - val_accuracy: 0.7585\n",
            "Epoch 415/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.0966 - accuracy: 0.9680 - val_loss: 0.7080 - val_accuracy: 0.8164\n",
            "Epoch 416/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0715 - accuracy: 0.9716 - val_loss: 0.7314 - val_accuracy: 0.8019\n",
            "Epoch 417/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.0657 - accuracy: 0.9807 - val_loss: 0.7254 - val_accuracy: 0.7585\n",
            "Epoch 418/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0507 - accuracy: 0.9819 - val_loss: 0.6549 - val_accuracy: 0.7681\n",
            "Epoch 419/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.0850 - accuracy: 0.9661 - val_loss: 0.7373 - val_accuracy: 0.8019\n",
            "Epoch 420/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.0993 - accuracy: 0.9637 - val_loss: 0.7230 - val_accuracy: 0.7874\n",
            "Epoch 421/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.0638 - accuracy: 0.9782 - val_loss: 0.7088 - val_accuracy: 0.7826\n",
            "Epoch 422/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0678 - accuracy: 0.9734 - val_loss: 0.8041 - val_accuracy: 0.7633\n",
            "Epoch 423/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0991 - accuracy: 0.9613 - val_loss: 0.6975 - val_accuracy: 0.7681\n",
            "Epoch 424/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0851 - accuracy: 0.9746 - val_loss: 0.7284 - val_accuracy: 0.8068\n",
            "Epoch 425/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0801 - accuracy: 0.9710 - val_loss: 0.6790 - val_accuracy: 0.7826\n",
            "Epoch 426/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.0781 - accuracy: 0.9740 - val_loss: 0.6179 - val_accuracy: 0.8068\n",
            "Epoch 427/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0686 - accuracy: 0.9734 - val_loss: 0.7551 - val_accuracy: 0.7923\n",
            "Epoch 428/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.0632 - accuracy: 0.9794 - val_loss: 0.7762 - val_accuracy: 0.7585\n",
            "Epoch 429/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0832 - accuracy: 0.9716 - val_loss: 0.7026 - val_accuracy: 0.7826\n",
            "Epoch 430/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.0705 - accuracy: 0.9740 - val_loss: 0.7787 - val_accuracy: 0.7391\n",
            "Epoch 431/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0684 - accuracy: 0.9746 - val_loss: 0.7579 - val_accuracy: 0.7729\n",
            "Epoch 432/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.0611 - accuracy: 0.9764 - val_loss: 0.8308 - val_accuracy: 0.7729\n",
            "Epoch 433/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.0677 - accuracy: 0.9764 - val_loss: 0.7818 - val_accuracy: 0.8068\n",
            "Epoch 434/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0692 - accuracy: 0.9716 - val_loss: 0.6782 - val_accuracy: 0.7826\n",
            "Epoch 435/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.0657 - accuracy: 0.9758 - val_loss: 0.7538 - val_accuracy: 0.7681\n",
            "Epoch 436/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0685 - accuracy: 0.9764 - val_loss: 0.7643 - val_accuracy: 0.8068\n",
            "Epoch 437/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0773 - accuracy: 0.9752 - val_loss: 0.7855 - val_accuracy: 0.7826\n",
            "Epoch 438/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0451 - accuracy: 0.9855 - val_loss: 0.7247 - val_accuracy: 0.8019\n",
            "Epoch 439/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0834 - accuracy: 0.9698 - val_loss: 0.7559 - val_accuracy: 0.7778\n",
            "Epoch 440/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0992 - accuracy: 0.9655 - val_loss: 0.8510 - val_accuracy: 0.8068\n",
            "Epoch 441/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0800 - accuracy: 0.9698 - val_loss: 0.7620 - val_accuracy: 0.7971\n",
            "Epoch 442/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0507 - accuracy: 0.9825 - val_loss: 0.7279 - val_accuracy: 0.8019\n",
            "Epoch 443/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0719 - accuracy: 0.9776 - val_loss: 0.7897 - val_accuracy: 0.7826\n",
            "Epoch 444/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0884 - accuracy: 0.9710 - val_loss: 0.8071 - val_accuracy: 0.7488\n",
            "Epoch 445/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0645 - accuracy: 0.9716 - val_loss: 0.7708 - val_accuracy: 0.7826\n",
            "Epoch 446/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0827 - accuracy: 0.9692 - val_loss: 0.6928 - val_accuracy: 0.8068\n",
            "Epoch 447/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0717 - accuracy: 0.9734 - val_loss: 0.7683 - val_accuracy: 0.8068\n",
            "Epoch 448/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0857 - accuracy: 0.9655 - val_loss: 0.6177 - val_accuracy: 0.8309\n",
            "Epoch 449/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0895 - accuracy: 0.9680 - val_loss: 0.6637 - val_accuracy: 0.8164\n",
            "Epoch 450/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0696 - accuracy: 0.9770 - val_loss: 0.6933 - val_accuracy: 0.7874\n",
            "Epoch 451/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.0906 - accuracy: 0.9680 - val_loss: 0.7262 - val_accuracy: 0.7826\n",
            "Epoch 452/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0905 - accuracy: 0.9680 - val_loss: 0.6417 - val_accuracy: 0.8261\n",
            "Epoch 453/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0566 - accuracy: 0.9776 - val_loss: 0.7063 - val_accuracy: 0.7778\n",
            "Epoch 454/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.0827 - accuracy: 0.9740 - val_loss: 0.7126 - val_accuracy: 0.8019\n",
            "Epoch 455/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0548 - accuracy: 0.9800 - val_loss: 0.7674 - val_accuracy: 0.7633\n",
            "Epoch 456/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0775 - accuracy: 0.9728 - val_loss: 0.8018 - val_accuracy: 0.7681\n",
            "Epoch 457/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0746 - accuracy: 0.9752 - val_loss: 0.8289 - val_accuracy: 0.7633\n",
            "Epoch 458/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0718 - accuracy: 0.9758 - val_loss: 0.7244 - val_accuracy: 0.8019\n",
            "Epoch 459/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0488 - accuracy: 0.9794 - val_loss: 0.8017 - val_accuracy: 0.7971\n",
            "Epoch 460/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0482 - accuracy: 0.9837 - val_loss: 0.6895 - val_accuracy: 0.7874\n",
            "Epoch 461/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0533 - accuracy: 0.9819 - val_loss: 0.6930 - val_accuracy: 0.8116\n",
            "Epoch 462/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.0523 - accuracy: 0.9819 - val_loss: 0.7913 - val_accuracy: 0.7778\n",
            "Epoch 463/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0533 - accuracy: 0.9807 - val_loss: 0.7580 - val_accuracy: 0.8068\n",
            "Epoch 464/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0478 - accuracy: 0.9849 - val_loss: 0.7303 - val_accuracy: 0.8068\n",
            "Epoch 465/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0600 - accuracy: 0.9776 - val_loss: 0.7493 - val_accuracy: 0.7923\n",
            "Epoch 466/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0704 - accuracy: 0.9770 - val_loss: 0.7982 - val_accuracy: 0.7729\n",
            "Epoch 467/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.0766 - accuracy: 0.9728 - val_loss: 0.6712 - val_accuracy: 0.7778\n",
            "Epoch 468/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0728 - accuracy: 0.9740 - val_loss: 0.7584 - val_accuracy: 0.7826\n",
            "Epoch 469/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0681 - accuracy: 0.9770 - val_loss: 0.7808 - val_accuracy: 0.7874\n",
            "Epoch 470/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0749 - accuracy: 0.9752 - val_loss: 0.8047 - val_accuracy: 0.8164\n",
            "Epoch 471/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0802 - accuracy: 0.9734 - val_loss: 0.6749 - val_accuracy: 0.7923\n",
            "Epoch 472/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.0824 - accuracy: 0.9710 - val_loss: 0.7412 - val_accuracy: 0.7681\n",
            "Epoch 473/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0981 - accuracy: 0.9680 - val_loss: 0.6818 - val_accuracy: 0.7923\n",
            "Epoch 474/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.0710 - accuracy: 0.9740 - val_loss: 0.5902 - val_accuracy: 0.8068\n",
            "Epoch 475/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0577 - accuracy: 0.9788 - val_loss: 0.6193 - val_accuracy: 0.8068\n",
            "Epoch 476/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0747 - accuracy: 0.9740 - val_loss: 0.7102 - val_accuracy: 0.8068\n",
            "Epoch 477/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.0616 - accuracy: 0.9794 - val_loss: 0.6951 - val_accuracy: 0.8116\n",
            "Epoch 478/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.0551 - accuracy: 0.9831 - val_loss: 0.7756 - val_accuracy: 0.7536\n",
            "Epoch 479/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0655 - accuracy: 0.9776 - val_loss: 0.7584 - val_accuracy: 0.7874\n",
            "Epoch 480/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0749 - accuracy: 0.9740 - val_loss: 0.7075 - val_accuracy: 0.7778\n",
            "Epoch 481/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0470 - accuracy: 0.9825 - val_loss: 0.7013 - val_accuracy: 0.7874\n",
            "Epoch 482/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.0391 - accuracy: 0.9909 - val_loss: 0.5740 - val_accuracy: 0.8213\n",
            "Epoch 483/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0714 - accuracy: 0.9758 - val_loss: 0.6728 - val_accuracy: 0.7923\n",
            "Epoch 484/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0446 - accuracy: 0.9813 - val_loss: 0.7092 - val_accuracy: 0.7874\n",
            "Epoch 485/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0460 - accuracy: 0.9825 - val_loss: 0.7181 - val_accuracy: 0.7778\n",
            "Epoch 486/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0720 - accuracy: 0.9752 - val_loss: 0.7494 - val_accuracy: 0.7488\n",
            "Epoch 487/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.0919 - accuracy: 0.9655 - val_loss: 0.6605 - val_accuracy: 0.8068\n",
            "Epoch 488/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.0688 - accuracy: 0.9704 - val_loss: 0.7419 - val_accuracy: 0.8019\n",
            "Epoch 489/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.0614 - accuracy: 0.9752 - val_loss: 0.7600 - val_accuracy: 0.7874\n",
            "Epoch 490/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0603 - accuracy: 0.9794 - val_loss: 0.6970 - val_accuracy: 0.7874\n",
            "Epoch 491/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0879 - accuracy: 0.9667 - val_loss: 0.7286 - val_accuracy: 0.8068\n",
            "Epoch 492/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0739 - accuracy: 0.9728 - val_loss: 0.9499 - val_accuracy: 0.7343\n",
            "Epoch 493/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.0602 - accuracy: 0.9734 - val_loss: 0.8136 - val_accuracy: 0.7923\n",
            "Epoch 494/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0480 - accuracy: 0.9807 - val_loss: 0.7073 - val_accuracy: 0.7874\n",
            "Epoch 495/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0638 - accuracy: 0.9788 - val_loss: 0.7565 - val_accuracy: 0.7729\n",
            "Epoch 496/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0616 - accuracy: 0.9794 - val_loss: 0.8075 - val_accuracy: 0.7681\n",
            "Epoch 497/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0703 - accuracy: 0.9746 - val_loss: 0.7297 - val_accuracy: 0.7923\n",
            "Epoch 498/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0594 - accuracy: 0.9813 - val_loss: 0.8257 - val_accuracy: 0.7826\n",
            "Epoch 499/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.0505 - accuracy: 0.9807 - val_loss: 0.8345 - val_accuracy: 0.7874\n",
            "Epoch 500/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0785 - accuracy: 0.9764 - val_loss: 0.7358 - val_accuracy: 0.7826\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(cnnhistory.history['loss'])\n",
        "plt.plot(cnnhistory.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train','test'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "oQYnuaCrDH_A",
        "outputId": "73589b1a-d927-4807-a8bc-2e487dba1066"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(cnnhistory.history['accuracy'])\n",
        "plt.plot(cnnhistory.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train','test'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "IFkTuO8nDNdq",
        "outputId": "1f9b6695-70a8-495d-ba9b-43950f1feab1"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#predictions = model.predict_classes(x_testcnn)\n",
        "predictions = model.predict(x_testcnn)"
      ],
      "metadata": {
        "id": "A2xtrN5wDQgY"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_f_ohjXKDUpY",
        "outputId": "c834bac9-0d7b-4ee0-bc4b-117c1d7f7b7a"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[4.3227934e-12, 2.7963868e-12, 1.0624469e-05, 2.0625208e-08,\n",
              "        1.5040411e-01, 8.4958518e-01],\n",
              "       [2.6158199e-02, 9.7366184e-01, 5.2510933e-07, 1.7046482e-04,\n",
              "        7.7932718e-06, 1.1681690e-06],\n",
              "       [1.4714373e-13, 1.4370138e-10, 9.9997771e-01, 4.3743004e-08,\n",
              "        1.0854111e-05, 1.1453767e-05],\n",
              "       ...,\n",
              "       [1.8661425e-10, 6.4984814e-12, 3.5426444e-06, 2.6200933e-10,\n",
              "        9.9993145e-01, 6.4999731e-05],\n",
              "       [4.3480632e-06, 5.3695174e-05, 2.3368474e-04, 7.2460127e-01,\n",
              "        1.8598945e-03, 2.7324718e-01],\n",
              "       [1.0693762e-03, 1.9441180e-04, 1.4089547e-03, 1.1030245e-04,\n",
              "        9.9721658e-01, 4.0566508e-07]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cmA2bFgsDW3D",
        "outputId": "6c6d9ac1-efdf-42c9-f59f-2341ae808302"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5, 1, 2, 5, 3, 4, 2, 0, 3, 1, 3, 2, 1, 4, 3, 0, 5, 0, 2, 5, 0, 0,\n",
              "       1, 3, 2, 3, 2, 5, 4, 2, 2, 3, 1, 2, 5, 5, 3, 5, 3, 3, 4, 1, 3, 2,\n",
              "       3, 1, 5, 3, 1, 2, 4, 4, 5, 5, 5, 1, 2, 3, 2, 5, 0, 2, 4, 2, 5, 4,\n",
              "       3, 0, 1, 2, 5, 2, 1, 2, 4, 5, 4, 1, 5, 5, 3, 1, 5, 3, 2, 4, 2, 5,\n",
              "       0, 5, 0, 5, 4, 0, 2, 4, 0, 2, 2, 0, 2, 3, 5, 3, 5, 5, 3, 1, 2, 2,\n",
              "       2, 1, 3, 2, 1, 3, 4, 4, 1, 1, 2, 4, 4, 1, 4, 2, 0, 4, 5, 5, 3, 1,\n",
              "       2, 1, 5, 5, 1, 2, 3, 3, 0, 3, 3, 0, 1, 0, 1, 2, 1, 5, 1, 2, 2, 0,\n",
              "       1, 1, 1, 1, 1, 4, 0, 1, 5, 1, 4, 5, 5, 4, 1, 0, 3, 5, 2, 3, 0, 4,\n",
              "       1, 3, 1, 0, 5, 5, 3, 5, 4, 5, 4, 0, 4, 1, 2, 1, 5, 0, 4, 3, 2, 1,\n",
              "       0, 3, 5, 0, 4, 5, 4, 5, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_Ytest = y_test.astype(int)"
      ],
      "metadata": {
        "id": "0PHDKWJWDY3g"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_Ytest"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k68v2i-pDbZE",
        "outputId": "5d43d863-01f4-4a00-94e0-c26e132c8c65"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5, 1, 2, 5, 3, 4, 2, 0, 3, 1, 3, 2, 1, 4, 3, 0, 5, 0, 2, 5, 0, 0,\n",
              "       1, 3, 2, 3, 2, 5, 4, 2, 2, 3, 1, 2, 5, 5, 3, 5, 3, 3, 4, 1, 3, 2,\n",
              "       3, 1, 5, 3, 1, 2, 4, 4, 5, 5, 5, 1, 2, 3, 2, 5, 0, 2, 4, 2, 5, 4,\n",
              "       3, 0, 1, 2, 5, 2, 1, 2, 4, 5, 4, 1, 5, 5, 3, 1, 5, 3, 2, 4, 2, 5,\n",
              "       0, 5, 0, 5, 4, 0, 2, 4, 0, 2, 2, 0, 2, 3, 5, 3, 5, 5, 3, 1, 2, 2,\n",
              "       2, 1, 3, 2, 1, 3, 4, 4, 1, 1, 2, 4, 4, 1, 4, 2, 0, 4, 5, 5, 3, 1,\n",
              "       2, 1, 5, 5, 1, 2, 3, 3, 0, 3, 3, 0, 1, 0, 1, 2, 1, 5, 1, 2, 2, 0,\n",
              "       1, 1, 1, 1, 1, 4, 0, 1, 5, 1, 4, 5, 5, 4, 1, 0, 3, 5, 2, 3, 0, 4,\n",
              "       1, 3, 1, 0, 5, 5, 3, 5, 4, 5, 4, 0, 4, 1, 2, 1, 5, 0, 4, 3, 2, 1,\n",
              "       0, 3, 5, 0, 4, 5, 4, 5, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds1=predictions.argmax(axis=1)\n",
        "preds1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4_cAI39VFhtp",
        "outputId": "3483f82f-fd51-4bb2-8e40-49428cc3831c"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5, 1, 2, 5, 1, 4, 2, 0, 3, 1, 5, 2, 1, 4, 3, 0, 5, 1, 2, 5, 0, 0,\n",
              "       1, 3, 2, 5, 2, 5, 4, 4, 2, 3, 0, 2, 5, 5, 1, 5, 3, 2, 4, 1, 2, 2,\n",
              "       3, 1, 3, 3, 1, 4, 4, 4, 5, 5, 5, 1, 2, 3, 2, 5, 0, 2, 4, 2, 5, 4,\n",
              "       0, 4, 1, 2, 5, 2, 1, 2, 4, 2, 4, 3, 5, 2, 3, 1, 5, 3, 2, 4, 2, 5,\n",
              "       0, 5, 0, 5, 4, 0, 3, 4, 3, 4, 2, 2, 4, 3, 5, 3, 5, 5, 5, 1, 2, 2,\n",
              "       2, 1, 3, 2, 1, 4, 4, 4, 1, 1, 2, 4, 4, 1, 4, 2, 0, 4, 5, 5, 5, 1,\n",
              "       2, 1, 5, 5, 1, 2, 3, 3, 0, 3, 5, 0, 1, 0, 1, 2, 1, 5, 0, 2, 2, 0,\n",
              "       1, 1, 1, 1, 1, 4, 0, 1, 5, 1, 4, 5, 5, 2, 1, 0, 2, 5, 2, 2, 3, 4,\n",
              "       1, 5, 0, 0, 5, 5, 3, 5, 4, 5, 0, 0, 4, 3, 2, 1, 5, 0, 4, 3, 2, 4,\n",
              "       1, 3, 5, 3, 4, 4, 4, 3, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "abc = preds1.astype(int).flatten()"
      ],
      "metadata": {
        "id": "H4WEmM60NfQn"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "c = confusion_matrix(new_Ytest, abc) \n",
        "c"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bKEBeEBlFjB8",
        "outputId": "cddc304a-914b-4d4c-c180-2e6bbb557225"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[18,  2,  1,  3,  1,  0],\n",
              "       [ 3, 33,  0,  2,  1,  0],\n",
              "       [ 0,  0, 33,  1,  4,  0],\n",
              "       [ 1,  2,  4, 19,  1,  6],\n",
              "       [ 1,  0,  1,  0, 28,  0],\n",
              "       [ 0,  0,  2,  2,  1, 37]])"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m4RjG7LWLSQx",
        "outputId": "768f6fc7-1356-489f-db1b-2e433e23c12a"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5, 1, 2, 5, 3, 4, 2, 0, 3, 1, 3, 2, 1, 4, 3, 0, 5, 0, 2, 5, 0, 0,\n",
              "       1, 3, 2, 3, 2, 5, 4, 2, 2, 3, 1, 2, 5, 5, 3, 5, 3, 3, 4, 1, 3, 2,\n",
              "       3, 1, 5, 3, 1, 2, 4, 4, 5, 5, 5, 1, 2, 3, 2, 5, 0, 2, 4, 2, 5, 4,\n",
              "       3, 0, 1, 2, 5, 2, 1, 2, 4, 5, 4, 1, 5, 5, 3, 1, 5, 3, 2, 4, 2, 5,\n",
              "       0, 5, 0, 5, 4, 0, 2, 4, 0, 2, 2, 0, 2, 3, 5, 3, 5, 5, 3, 1, 2, 2,\n",
              "       2, 1, 3, 2, 1, 3, 4, 4, 1, 1, 2, 4, 4, 1, 4, 2, 0, 4, 5, 5, 3, 1,\n",
              "       2, 1, 5, 5, 1, 2, 3, 3, 0, 3, 3, 0, 1, 0, 1, 2, 1, 5, 1, 2, 2, 0,\n",
              "       1, 1, 1, 1, 1, 4, 0, 1, 5, 1, 4, 5, 5, 4, 1, 0, 3, 5, 2, 3, 0, 4,\n",
              "       1, 3, 1, 0, 5, 5, 3, 5, 4, 5, 4, 0, 4, 1, 2, 1, 5, 0, 4, 3, 2, 1,\n",
              "       0, 3, 5, 0, 4, 5, 4, 5, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('/content/drive/My Drive/graduation project/audio/paper_code/mariam/original_500 epoch_with_valid_Adam2_3')\n",
        "print(\"MODEL SAVED\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lsJBNeMWDl6Z",
        "outputId": "ed96267e-046d-45db-d259-833819b1e6f2"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/graduation project/audio/paper_code/mariam/original_500 epoch_with_valid_Adam2_3/assets\n",
            "MODEL SAVED\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_model=keras.models.load_model('/content/drive/My Drive/graduation project/audio/paper_code/mariam/original_500 epoch_with_valid_Adam2_3')\n",
        "new_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q3KjaO9GDoNl",
        "outputId": "b509c41b-32e6-434b-f23d-4c04a29eb7c5"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d (Conv1D)             (None, 40, 128)           1152      \n",
            "                                                                 \n",
            " activation (Activation)     (None, 40, 128)           0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 40, 128)           0         \n",
            "                                                                 \n",
            " max_pooling1d (MaxPooling1D  (None, 8, 128)           0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv1d_1 (Conv1D)           (None, 8, 256)            262400    \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 8, 256)            0         \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 8, 256)            0         \n",
            "                                                                 \n",
            " max_pooling1d_1 (MaxPooling  (None, 1, 256)           0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 256)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 256)               65792     \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 256)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 256)               65792     \n",
            "                                                                 \n",
            " activation_3 (Activation)   (None, 256)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 6)                 1542      \n",
            "                                                                 \n",
            " activation_4 (Activation)   (None, 6)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 396,678\n",
            "Trainable params: 396,678\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss, acc =model.evaluate(x_testcnn, y_test)\n",
        "print(\"Restored model, accuracy: {:5.2f}%\".format(100*acc))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n3kzoqPkDqqS",
        "outputId": "f27ceefa-a3ca-44e4-c9b2-7086475b2d1c"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7/7 [==============================] - 0s 4ms/step - loss: 0.6315 - accuracy: 0.8116\n",
            "Restored model, accuracy: 81.16%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss, acc =model.evaluate(X_train, y_train)\n",
        "print(\"Restored model train, accuracy: {:5.2f}%\".format(100*acc))"
      ],
      "metadata": {
        "id": "fJDTGH_OUX0z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03fb1352-b49c-4129-f787-ef432e84d80b"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "52/52 [==============================] - 0s 5ms/step - loss: 0.0179 - accuracy: 0.9976\n",
            "Restored model train, accuracy: 99.76%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix,accuracy_score\n",
        "import seaborn as sn\n",
        "\n",
        "print(classification_report(new_Ytest,abc))\n",
        "\n",
        "acc = float(accuracy_score(new_Ytest,abc))*100\n",
        "print(\"----accuracy score %s ----\" % acc)\n",
        "\n",
        "cm = confusion_matrix(new_Ytest,abc)\n",
        "#df_cm = pd.DataFrame(cm)\n",
        "class_names = ['neutral','calm', 'happy','sad','angry', 'fearful' ]\n",
        "df_cm = pd.DataFrame(cm, index=class_names, columns=class_names,)\n",
        "sn.heatmap(df_cm, annot=True, fmt='')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 508
        },
        "id": "SfSC3El94LZg",
        "outputId": "ac7c51ef-c33a-41d7-f277-a331c03098ad"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      0.72      0.75        25\n",
            "           1       0.89      0.85      0.87        39\n",
            "           2       0.80      0.87      0.84        38\n",
            "           3       0.70      0.58      0.63        33\n",
            "           4       0.78      0.93      0.85        30\n",
            "           5       0.86      0.88      0.87        42\n",
            "\n",
            "    accuracy                           0.81       207\n",
            "   macro avg       0.80      0.80      0.80       207\n",
            "weighted avg       0.81      0.81      0.81       207\n",
            "\n",
            "----accuracy score 81.15942028985508 ----\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVoAAAD4CAYAAACt8i4nAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXwV1f3/8dfnJhA2UTbZMSi4FoSyiOICKoK2Cq0VxIpbW9pq6/J16SJWq+BPUbHiRrFCANeIdQGtiogLKEqwrEFAFhUIiAICQSC59/P7Yyb0Aknu3OTOnTvx8+QxD+7MvXfmncnNycmZM+eIqmKMMcY/kaADGGNMTWcFrTHG+MwKWmOM8ZkVtMYY4zMraI0xxmfZfh/gw5YXhqpbw8BdS4KOkLRdJXuCjpC0pnUbBh0hKd98vz3oCEnbU1oSdISkle5dL9XdR8k3qz2XObWaHlnt43lhNVpjjPGZ7zVaY4xJq1g06AQHsYLWGFOzREuDTnCQSgtaEdkBlNfeIYCqarga2owxNZ5qLOgIB6m0oFXVQ9IVxBhjUiIWsoL2QCJyOFCnbF1Vv0x5ImOMqY6w1WjLiMgFwANAK+Br4AhgGXCCf9GMMaYKMvBimNfuXXcBvYAVqtoeOAuY61sqY4ypKo15X9LEa0FboqrfAhERiajqLKC7j7mMMaZKNFrqeamMiNQRkU9EZKGILBWRv7vb80RkjYgscJcuiTJ5baPdJiINgPeBp0Xka6DY43uNMSZ9UncxbA9wpqruFJFawGwR+Y/73M2qOtXrjrzWaAcCu4AbgDeAVcD5SQQ2xpj0SFHTgTp2uqu13KVKQwokLGhFJAuYrqoxVS1V1UmqOtZtSjDGmMwSi3peRGS4iBTELcPjdyUiWSKyAKcTwAxV/dh9apSILBKRB0UkJ1GkhE0HqhoVkZiIHKqq31XpCzfGmHRJ4iKXqo4HxlfyfBToIiKHAS+JyI+AvwAbgdrue/8E3FnZcbw2HewEFovIkyIytmzx+N5qO2rM1fRYPIEusx7ct63eCbl0mv7/OHHG/XR+414adOmQrjhJa9W6BS9Nm8zsj1/jg7nTGf67y4KOlNDj40azdm0B8+a9GXQUT3JyavPKjKf5z3svMGPOv7nhT1cHHSmhsJ1jgP7n9GHpkvf5rHA2t9x8TdBxyhct9b54pKrbgFnAAFUtcpsV9gATgZ6J3u+1oP03cBvOxbD57lLgOWU1bc5/l8JL7tpvW+5tw/hqTD4L+93El6Of54jbhqUrTtKipVFuH3EPp570EwacPYSrfnMJRx9zVNCxKvXUlKkMGnR50DE827NnL0MH/Zpzz7iIc88YzBln9aZr985Bx6pU2M5xJBJh7EOj+On5l9LpxL4MGTKI447rGHSsg8Vi3pdKiEgztyaLiNQF+gGfiUhLd5sAg4CEY6t67XVwmKo+dECI6zy+t9q2zy0kp02z/bapQlaDugBkN6zH3o1b0xUnaZs2bWbTps0AFO8sZsXy1bRs1ZwVy1cFnKxic+Z8Qrt2bYKOkZRdxd8DkF0rm1rZ2WT6DM9hO8c9e3Rl1aq1rFnj3BCan/8KF5zfn2XLVgacbH/OX/sp0RKY5F6nigD5qjpdRN4RkWY4Y74sAH6XaEdeC9rLgYcO2HZFOdvSZu3fJnD8s7eR+7fLISIsueDWoKIkpW271nTqfBzzCxYGHaXGiUQiTH/nOXLbt2PyhOdYMH9x0JFqlFatW/DVug371tetL6Jnj64BJqpAim5EUNVFwEFfoKqemey+Km06EJGhIjINaC8ir8Yts4Atlbxv35W8V3atSTaTJy0u68+a2/OY3/23rL09j6MeyPw2ufr16zFxylhG/OVudu6wbsipFovFOK/PYHp16keXrj/i6GMzt93e+ChFTQeplKhG+yFQBDTFGeugzA5gUUVvir+S59dUNs0G92HNbRMA+Hbahxz1wO/9OEzKZGdnM3HKWKbmT+O1aTOCjlOjbd++gw9nz6PPWb1Z8dnnQcepMTas30jbNq32rbdp3ZINGzYGmKgCGTioTKU1WlX9QlXfVdWTVfW9uOVTVQ10dN29m7bS8GRnTJtDT+3E7jVFQcZJ6B+PjGLF8tWMezQv6Cg1UuMmjWjY0BnVM6dODqf1OZnPV/rz19QP1byCBXTo0J7c3LbUqlWLwYMHMm36W0HHOli0xPuSJl5H74ofALw2zh0Sxeka+LvjYzdw6CknkN34ELrNH89X9z/Pqpsep/1dVyFZWcT27GXVzePSEaVKTurVjSFDB7F0yXJmffAyAKPuHMPbM94POFnF8vLGctrpvWjSpBErVn7EyJEPMnlSftCxKnR486aMeXQkkawsp6325Td5563MPb8QvnMcjUa57voRvP7aM2RFIuRNep7CwhVBxzpYBo5HK8lemXW7NAwEeqnqnxO93mbB9Z/Ngus/mwU3PVIxC+7uj571XObUOXloZs6C63bUfRno70MeY4ypnhBeDANARH4etxrBGSJxty+JjDGmOjKw6cBrP9r4kbpKgbU4zQfGGJNRNI0XubzyVNCq6pV+BzHGmJQIW/euMiJytIjMFJEl7npnERnhbzRjjKmCDGyj9Xox7AmcocFKYN+taRf7FcoYY6osA+cM89pGW09VP3F6du0T6A0LxhhTrhBfDPtGRI7CvWlBRH6Bc2uuMcZklgxso/Va0F6DM3bBsSKyHlgD/NK3VMYYU1WlmffHtteCdj3OSOKzgMbAdpyhEyudvsEYY9IuxDXaV4BtwKfAhgSvNcaY4IS4jbaNqg7wNYkxxqRCBtZovXbv+lBEOvmaxBhjUiED+9F6rdGeClwhImuAPThz5aiqJpz9bujezJpPKJGvpofvPowGZyUcRC3j7CoN34hjJiQysEbrtaA919cUxhiTKmHtdaCqX/gdxBhjUiJFsx+LSB3gfSAHp6ycqqq3i0h74DmgCTAfGKaqeyvbV9Lj0RpjTEZLXRvtHuBMVT0R6AIMEJFewL3Ag6raAdgK/CrRjqygNcbULCkqaN1JDna6q7XcRYEzganu9knAoESRrKA1xtQsSQwqIyLDRaQgbhkevysRyRKRBcDXwAxgFbAtbnLadUDrRJG8XgwzxphwiEY9v1RVx+MML1DR81Ggi4gcBrwEHFuVSFbQGmNqFh/6x6rqNhGZBZwMHCYi2W6ttg3OEAWVsqYDY0zNkqI2WhFp5tZkEZG6QD9gGc6YL79wX3Y5zhAFlbIarTGmZkndDQstgUkikoVTKc1X1ekiUgg8JyIjgf8CTybakeeCVkQ6A7nx71HVfycZ3BhjfKWx1PSjdWeS6VrO9tVAz2T25XW68QlAZ2ApUPbrQgEraI0xmSXEo3f1UtXjfU1ijDGpkESvg3TxejHsIxGxgtYYk/lCPHrXZJzCdiNJjt5ljDFpFeKmgyeBYcBi/tdGG4icnNrkT59I7dq1yc7O4vVX3+bBex8LMlK59pSUcuW9kykpLaU0FqNft+O4euAZ3J43jcK1RajCES0ac9eVF1CvTu2g4x6k/zl9GDPmTrIiESZMfJbR9z0adKRKtWrdgkfHjabZ4U1QVabk5TN+3OSgY1Xq8XGjOXfAmWze/C09evQPOo4nofhcpGhQmVQS9RBKRD5S1ZOrcoAjmnRO+Vddr35ddhV/T3Z2NlNfn8Tf/3ov/y1YlJJ9L3/55pTsR1X5fk8J9erUpqQ0yhX3TuJPF5/Dka2a0aBuDgD3PT+DxofU41fn9a7WsVI9Hm0kEmHZ0g8YcN5Q1q0rYu5Hr3PpsKtZtix1Yws3qtsgZfsCaN68Gc1bNGPRwkLqN6jPzPde5LJLrmHF8lUp2f+uktSPn9u7d0+Ki4t54okxvhS0e0pLUrq/dHwuSveul+ruY9eY33guc+r93xPVPp4XXtto/ysiz4jIUBH5ednia7JK7Cr+HoDsWtnUys7Gyy+LdBORfTXV0miM0mgMRPYVsqrKnr0liKTl+5yUnj26smrVWtas+ZKSkhLy81/hgvMzu8a1adNmFi0sBKB4ZzErlq+mZavmAaeq3Jw5n7Bly3dBx/AsNJ+LmHpf0sRr00FdnLbZc+K2Bda9KxKJMP2d58ht347JE55jwfzFQcRIKBqLMfSuJ/ny6y0M6dudzkc6Y0/cNuFVZi9exZGtmnLj4H4BpzxYq9Yt+Grd/+bgXLe+iJ49DupOmLHatmtNp87HMb9gYdBRapTQfC4ysNeB14G/r0xmp+4IOMMBGtdrTYM6jasQrWKxWIzz+gymYcNDGD/5QY4+tgMrPvs8pcdIhaxIhPzbf8P2Xbu54dEXWLn+azq2Ppy7rrqAaCzGPc+8yZvzljLo1C5BR60x6tevx8QpYxnxl7vZuaM46DgmABq2i2Ei8jBOzbVcqnptBdv3jYjjRxttme3bd/Dh7Hn0Oat3Rha0ZRrWq0OPY4/gwyWr6Nj6cMAphAf0PJ6Jb3yUcQXthvUbadum1b71Nq1bsmHDxgATeZOdnc3EKWOZmj+N16bNCDpOjROaz0UamwS8StRGW4AzVUNFS9o1btKIhg0PASCnTg6n9TmZz1euCSJKpbbsKGb7rt0A7N5bwtzCNRzRvAlfbtoCOG207y5YSfsWTYOMWa55BQvo0KE9ubltqVWrFoMHD2Ta9LeCjpXQPx4ZxYrlqxn3aF7QUWqk0HwukhiPNl0qrdGq6qR0BfHq8OZNGfPoSCJZWU5b7ctv8s5b7wcd6yDfbNvJiAmvEospMVXO6XEcp3fuyJX3TmLn7j2owjFtD+fWS88LOupBotEo110/gtdfe4asSIS8Sc9TWLgi6FiVOqlXN4YMHcTSJcuZ9cHLAIy6cwxvz8i8z0aZvLyxnHZ6L5o0acSKlR8xcuSDTJ6UH3SsCoXmc5GBNVqv3buaAX8CjgfqlG1X1TMTvdfPpgM/pKp7VzqFcbrxVHfv8psf3bv8luruXemQiu5dxX+72HOZU//O5zKqe9fTOOMwtgf+DqwF5vmUyRhjqi4Dmw68FrRNVPVJoERV31PVq3AmKDPGmMwS4n60ZX+DFInIT4ANQGr7bBljTAqErntXnJEicihwI/Aw0BC43rdUxhhTVRl4Mcxr08FFOBfOlqhqX5y5c37mXyxjjKmiEDcddFbVbWUrqrpFRDLw3jtjzA9eWG/BBSIi0khVtwKISOMk3muMMWmTqjnDUslrYfkAzsDfL7jrFwGj/IlkjDHVkIEFrac2WlWdDPwc2OQuP1fVKX4GM8aYKknRVDYi0lZEZolIoYgsFZHr3O13iMh6EVngLglv7/T857+qFgKFXl9vjDGBSF2NthS4UVU/FZFDgPkiUjZa0YOqer/XHVk7qzGmZklRQauqRUCR+3iHiCwDWldlX167dxljTChoNOZ5EZHhIlIQtwwvb58ikgt0BT52N/1BRBaJyAQRaZQok6dBZaoju3brzGuZrmF2zrwn6AhJa9L/tqAjJKVdg8ODjpC0ldvWBx0haakYVGb7r/p5LnMaPjkj4fFEpAHwHjBKVf8tIs2Bb3DG6r4LaOkOS1AhazowxtQoqezeJSK1gBeBp1X13wCquinu+SeA6Yn2YwWtMaZmSVFBK87MqU8Cy1R1TNz2lm77LTh3yC5JtC8raI0xNUvqxpTpDQwDFovIAnfbX4GhItIFp+lgLfDbRDuygtYYU6NoaWpKWlWdDZTXhvt6svuygtYYU7Nk3iiJ3rp3icgfvXRhMMaYoGlMPS/p4rUfbXNgnojki8gAt5HYGGMyTyyJJU28jnUwAuiIcwXuCmCliNwtIkf5mM0YY5IW5hot6tzZsNFdSoFGwFQRGe1TNmOMSV4G1mg9XQxzR625DOduiH8BN6tqiYhEgJXALf5FNMYY77Q06AQH89rroDHO0IhfxG9U1ZiI/DT1sYwxpmrSOIu4Z54KWlW9XUR+LCIDcTrpzlHVT93nlvkZ0BhjkpKBBa3X7l23AZOAJkBTYKKIjPAzmDHGVIXGvC/p4rXp4FLgRFXdDSAi9wALgJF+BTPGmKrIxKYDr70ONgB14tZzgMDGYOt/Th+WLnmfzwpnc8vN1wQVIymZnnlPSSmXjJzARXeM52d/G8djr7wHwO1507jojvH84vbx3Pj4VHbt3htw0vI9Pm40a9cWMG/em0FHSUokEuHFmVN4/KkxiV+cATL9cwygUfG8pIvXGu13wFJ3GgcF+gGfiMhYAFW91qd8B4lEIox9aBQDzhvKunVFzP3odaZNf4tly1amK0LSwpC5dnYW/7rpUurVqU1JaZQr7p3EqT86ipuHnEODujkA3Pf8DJ59Zx6/Oq93wGkP9tSUqfxz3CSeeCIcBVaZYcMvZvWKtTQ4pH7QURIKw+cYwl2jfQln1JpZwLvArcArwHx3SZuePbqyatVa1qz5kpKSEvLzX+GC8/unM0LSwpBZRKhXpzYApdEYpdEYiOwrZFWVPXtLyNSbAufM+YQtW74LOkZSmrc8nDPO7s3Up18JOoonYfgcA2hMPC/p4rXXwSQRqQ0ci1OjXa6qgfwN2ap1C75at2Hf+rr1RfTs0TWIKJ6FJXM0FmPoXU/y5ddbGNK3O52PdKZHum3Cq8xevIojWzXlxsH9Ak5Zc/xl5A3cf+fD1G9QL+gonoTlcxzaGq07ne4qYCzwCPC5iJxbyev3zcMTixWnJqnxXVYkQv7tv+Gt+65jyZoNrFz/NQB3XXUBbz9wHUe2bMqb85YGnLJm6NPvVLZ8s5XCRZ8FHaXGURXPS7p4bToYA/RV1T6qegbQF3iwoher6nhV7a6q3SOR1LY9bVi/kbZtWu1bb9O6JRs2bEzpMVItbJkb1qtDj2OP4MMlq/Zty4pEGNDzeN7+1AqGVOjaszN9+5/G2wUv88D4UZx0anfufezvQceqVFg+x5nYvctrQbtDVT+PW18N7PAhT0LzChbQoUN7cnPbUqtWLQYPHsi06W8FEcWzMGTesqOY7bt2A7B7bwlzC9dwRPMmfLlpC+C00b67YCXtWzQNMmaN8eCox+jb5XzO7j6IG4ffysezC/jT1bcHHatSYfgcA8Si4nlJF6+9DgpE5HUgH6eN9iKcYRN/DlA2aVk6RKNRrrt+BK+/9gxZkQh5k56nsHBFug5fJWHI/M22nYyY8CqxmBJT5Zwex3F6545cee8kdu7egyoc0/Zwbr30vKCjlisvbyynnd6LJk0asWLlR4wc+SCTJ+UHHatGCcPnGEjrRS6vPE03LiITK3laK5tq16Yb959NN+4/m248PVIx3fjaLt6nG89dkHi68VTw2uvgSr+DGGNMKnioO6ad12ES6wC/Ak4g7g6xymqyxhgThFQ1HYhIW2AyzgwzCoxX1YdEpDHwPJCLMwvuYFXdWtm+vF4MmwK0APoD7wFtCOhimDHGVCaF3btKgRtV9XigF3CNiBwP/BmYqaodgZnueqW8FrQdVPU2oFhVJwE/AU7y+F5jjEmbaFQ8L5VR1aK44WB3AMuA1sBAnNEMcf8flCiT14K2xP1/m4j8CDgUCN/VAWNMjZdMjTb+5ip3GV7ePkUkF+gKfAw0V9Ui96mNOE0LlfLavWu8O934COBVoAEQrsvGxpgfhGTaaFV1PDC+steISAPgReB6Vd0eP96HqqqIJLz85rWgnQJciNP4W1ZlTliKG2NMuqWy14GI1MIpZJ+Ou19gk4i0VNUiEWkJfJ1oP16bDl7BaZcoBXa6iw1iYIzJOKkavUucquuTwDJVjR9/81Xgcvfx5TjlY6W81mjbqOoAj681xpjARGNe648J9QaGAYtFZIG77a/APUC+iPwK+AIYnGhHXgvaD0Wkk6ourkpaY4xJl1Q1HajqbKCiau9Zyeyr0oJWRBbjdNTNBq4UkdXAHvfgqqqdkzmYMcb4LZbG4Q+9SlSj/WlaUhhjTIqkc5xZryotaFX1i3QFMcaYVAjtWAfVkZNdy+9DpFS9WjlBR0ha1wsfDjpC0uY0C1erU+/Ni4KOkLRTmh0bdIRAhLHpwBhjQiWFvQ5SxgpaY0yNkoEtB1bQGmNqFms6MMYYn4Wu14ExxoRNGie39cwKWmNMjaIV3swVHCtojTE1Sqk1HRhjjL+sRmuMMT6zNlpjjPGZ1WiNMcZnVqM1xhifRcNWo40bj7ZcNh6tMSbTJDE3Y9p4HY/2Gvf/Ke7/v/QnTmKPjxvNuQPOZPPmb+nRo39QMZLSqnULHh03mmaHN0FVmZKXz/hxk4OOlVAkEuGFGZP4umgzv7/0/4KOc5C2911LwzO7U/rtdyw/548A1Dkul7Z3X02kXh32rvuaL657gNjO7wNOWr4wfpYbNKzPLfffRPtjckGVe268n6XzC4OOtZ9YBtZoKx3mRlW/cMek7aeqt6jqYnf5M3BOeiLu76kpUxk06PLEL8wg0dIot4+4h1NP+gkDzh7CVb+5hKOPOSroWAkNG34xq1esDTpGhba8MJPVl9+x37Z29/6RDfdMYnn/a/nuzbkc/tufBxPOgzB+lq+98w98PGsew864kiv7DeeLlZk3ZLUmsaSL1/HERER6x62cksR7U2rOnE/YsuW7IA5dZZs2bWbRQue3fvHOYlYsX03LVpk9W3vzlodzxtm9mfp0wgk+A1P8yVKi23buty2nfSuKP14KwI4PFnDYuScHEc2TsH2W6x9SnxNP6sRrz74OQGlJKTu3Z95k2LEklnTxWlj+CnhMRNaKyBfAY8BV/sWqudq2a02nzscxv2Bh0FEq9ZeRN3D/nQ8Ti2XiNdyK7V75JYeecxIAh/2kN7VaNg04Uc3Rsl0Ltn37HX958Bb+9eY4brnvRurUrRN0rIPERDwviYjIBBH5WkSWxG27Q0TWi8gCdzkv0X48FbSqOl9VTwROBDqrahdV/bSScMNFpEBECkpLd3g5xA9C/fr1mDhlLCP+cjc7d2ReTaBMn36nsuWbrRQu+izoKEn78uaxNBl2HkdPH0Okfl20pDToSDVGVlYWHTt15OXJr/Lr/r9j967d/PIPFwcd6yDRJBYP8oAB5Wx/0C0Hu6jq64l24rl7l4j8BDgBqCPubwJVvbO816rqeGA8QP16uZk4Dm/aZWdnM3HKWKbmT+O1aTOCjlOprj0707f/aZx+1inUrpNDgwb1ufexv/Onq28POlpCe1atZ/UwJ2dO+1Y0PLN7wIlqjs1Fm9lctJll/3V+Ab/72vsZWdCmsteBqr4vIrnV3Y+nGq2IjAOGAH/EmWr8IuCI6h78h+Qfj4xixfLVjHs0L+goCT046jH6djmfs7sP4sbht/Lx7IJQFLIA2U0OdR6I0PyPg/n26TeCDVSDbNm8la83bKbtUW0A6HZqV9auyLyLYTHE81INfxCRRW7TQqNEL/baRnuKql4GbFXVvwMnA0dXJ2VV5eWNZda7/6bj0UeyYuVHXHb54CBiJOWkXt0YMnQQp57ei1kfvMysD17m7H6nBx0r9I4YexMdXxpNnSNbc/zcCTQe0o/DLjidY2c9zrHvPEbJpi1syX876JgVCuNn+aHbHua2h//KxBlP0OGEDkx5+JmgIx0kmV4H8c2c7jLcwyEeB44CugBFwAOJ3iDqYW5eEflEVXuKyFzg58AWYImqdkj03rA1HYRxFtymOYcGHSFpz9ZtEXSEpIRxFtxujTK/C+GB3l8/s9p/+E9ufannMuey9U8lPJ7bdDBdVX+UzHPxvLbRThORw4D7gE9xfhk84fG9xhiTNn73kxGRlqpa5K7+DFhS2evBe0H7GRBV1RdF5Hjgx8DLVYtpjDH+iabwYpiIPAv0AZqKyDrgdqCPiHTBqXCuBX6baD9eC9rbVPUFETkVOBO4H6ed4qTkoxtjjH9SWaNV1aHlbH4y2f14vRhW1uXsJ8ATqvoaUDvZgxljjN/CfGfYehH5J04Xr9dFJCeJ9xpjTNqoeF/SxWthORh4E+ivqtuAxsDNvqUyxpgqysQarac2WlXdBfw7br0Ip/+YMcZkFI+31qaVzbBgjKlRwjjwtzHGhEomjjdnBa0xpkaxgtYYY3yWiff8W0FrjKlRrI3WGGN8Zr0OQmDr9zsTvyjD7CrZE3SEpHXftj7oCEnZPiocs9TGa3jrm0FHCEQsAxsPrKA1xtQodjHMGGN8lnn1WStojTE1jNVojTHGZ6WSeXVaK2iNMTVK5hWzVtAaY2qYTGw68Drd+B+9TKlrjDFBi6Gel3TxOh5tc2CeiOSLyAARycB7L4wxJrnpxtPFU0GrqiOAjjhz5VwBrBSRu0UkfPMZG2NqtEwc+NvzdDSqqsBGdykFGgFTRWS0T9mMMSZpUdTzki5e22ivE5H5wGhgDtBJVX8PdAMu9DGfMcYkJZU1WhGZICJfi8iSuG2NRWSGiKx0/094/cprjbYR8HNV7a+qL6hqCYCqxoCfetyHMcb4TpP450EeMOCAbX8GZqpqR2Cmu16phAWtiGQBF6vqF+U9r6rLEkY1xpg0SWWNVlXfB7YcsHkgMMl9PAkYlGg/CQtaVY0Cy0WknYdcvnt83GjWri1g3rxwjUzU/5w+LF3yPp8VzuaWm68JOk5CYTzPYTjHckgjcobcTJ0rR1LnyrvI/vHZzvbD25Lzy1upc/kd5Az7G5EW7QNOWr4wnONkuneJyHARKYhbhns4RHN3glpwrlk1T/SGZJoOlorITBF5tWzx+N6UemrKVAYNujyIQ1dZJBJh7EOj+On5l9LpxL4MGTKI447rGHSsSoXtPIflHGssxt5Zz7N74gh2PzWK7K5nIk1aUfuMiyj58FV2T7qDktkvUeuMi4KOepDQnONkFtXxqto9bhmf1LGcTgIJ2yC83hl2WzIH99OcOZ/Qrl2boGMkpWePrqxatZY1a74EID//FS44vz/Llq0MOFnFwnaeQ3OOi79Di79zHpfsJvZtEdLgMFCQ2nUAkJx66M5tAYYsX1jOcan/vQk2iUhLVS0SkZbA14ne4KmgVdX3qh3tB6xV6xZ8tW7DvvV164vo2aNrgIlqnjCeY2nYhEjzdsSKVrP3nWfJuej/qNVnCIiw55m7g453kLCcY48XuarjVeBy4B73/1cSvcFr964dIrL9gOUrEXlJRI4s5/X72j1KS3ck+0UYU/PVyiFn4DWUvPMs7N1Ndpe+lMx6jt3/vAidubUAABCcSURBVImSWc9Re8CVQScMrRR373oW+Ag4RkTWicivcArYfiKyEjjbXa+U16aDfwDrgGcAAS4GjgI+BSYAfeJf7LZzjAeoXy83EwfTSasN6zfStk2rfettWrdkw4aNASaqeUJ1jiNZ5Ay8htJlc4mu/BSA7B+dwvfvPANAdPk8ave/IsCA5QvLOU5ljVZVh1bw1FnJ7MfrxbALVPWfqrpDVbe7BWl/VX0e50KZqcS8ggV06NCe3Ny21KpVi8GDBzJt+ltBx6pRwnSOaw+4kti3RZQW/C+f7txGpO0xAETaHYdu3RRUvAqF5Rxn4i24Xmu0u0RkMDDVXf8FsNt9nNYaa17eWE47vRdNmjRixcqPGDnyQSZPyk9nhKRFo1Guu34Er7/2DFmRCHmTnqewcEXQsSoVtvMclnMcad2R7BNOIbb5K7IuvwOAve+/yN43J1H7zKEQyUJLS9jz1qTKdxSAsJzjqGbeH9GiHkK57bAPASfjFKxzgRuA9UA3VZ1d0XvD1nSwp7Qk6AhJy8muFXSEpIXtPNssuOlRund9tUcGvOSIn3kuc5754qW0jETotdfBauD8Cp6usJA1xph0S0Ovg6R5KmhFpBnwGyA3/j2qepU/sYwxpmoycYYFr220rwAfAG8DUf/iGGNM9aRz5gSvvBa09VT1T74mMcaYFMjEpgOv3bumi8h5viYxxpgUiKp6XtLFa432OuCvIrIHKMG5aUFVtaFvyYwxpgpC23SgqoeISGOcecPq+BvJGGOqLrQXw0Tk1zi12jbAAqAX8CFJ3oZmjDF+C3Mb7XVAD+ALVe0LdAW+8y2VMcZUUTIDf6eL1zba3aq6W0QQkRxV/UxEjvE1mTHGVIGXu13TzWtBu05EDgNeBmaIyFag3DnEjDEmSOmcRtwrrxfDfuY+vENEZgGHAm/4lsoYY6ootL0O4tlsC8aYTBbmpoMqC9soTWFUr1ZO0BGSFrbMzW5/J+gISft+wwdBRwhEjajRGmNMJsvE7l1W0BpjapRMHPjbClpjTI1iTQfGGOOzVBa0IrIW2IEzPGypqnavyn6soDXG1Cg+9Droq6rfVGcHFRa0IrKD8idetJG7jDEZK1RNB6p6SDqDGGNMKiTT60BEhgPD4zaNV9Xx++0O3hIRBf55wHOeJWw6EJF25W1X1S+rckBjjPFTVL0PlOgWnJUVnqeq6noRORxn+IHPVPX9ZDN5aaN9Le5xHaA9sBw4IdmDGWOM31LZRquq693/vxaRl4CeQOoLWlXtFL8uIj8Grk72QMYYkw6paqMVkfpARFV3uI/PAe6syr6qMtbBpyJyUlUOZowxfkvhnWHNgZdEBJyy8hlVrdJgWl7aaP8vbjUC/BjYUJWDGWOM32IpajpQ1dXAianYl5cabXzvg1KcNtsXU3FwY4xJtVCNdSAiU1R1GLBNVR9KYyZjjKmyZHodpEtlNdpuItIKuEpEJuPcqLCPqm7xNVkl+p/ThzFj7iQrEmHCxGcZfd+jQUXxLEyZW7VuwaPjRtPs8CaoKlPy8hk/bnLQsSoVxsyPjxvNuQPOZPPmb+nRo3/Qccq1Z89eLr/mZvaWlBAtjdKv76n84dfDuOz3N1G863sAtmzdRqfjj2HsPX8LOK0jVU0HqSQVdYUQkWuB3wNHAuvZv6BVVT3SywGya7dO6VcdiURYtvQDBpw3lHXripj70etcOuxqli1bmcrDpJTfmRvVbZCS/ZRp3rwZzVs0Y9HCQuo3qM/M917kskuuYcXyVSk9Tir5nXlXyZ6U7Cde7949KS4u5oknxvhS0G77svpj6Koq33+/m3r16lJSWsplv7+JP1/3W0780XH7XnP9X0fS97ReDDz37Gofr1bTIyXxqyrXsVk3z2XOys3zq308LyqcBVdVx6rqccAEVT1SVdvHLZ4KWT/07NGVVavWsmbNl5SUlJCf/woXnJ+ZtYEyYcu8adNmFi0sBKB4ZzErlq+mZavmAaeqXBgzz5nzCVu2ZPZk0iJCvXp1ASgtLaW0tBT3KjwAO4uL+eTThZx1+slBRTxITNXzki6VTjcuIllA3zRl8aRV6xZ8te5/nR7WrS+iVasWASZKLIyZy7Rt15pOnY9jfsHCoKN4FsbMmSwajXLh5ddw+k+HcnKPrnQ+4dh9z818/yNO6nYiDerXDzDh/jSJf+lSaUGrqlFgeUW34VZERIaLSIGIFMRixdUKaIJTv349Jk4Zy4i/3M3OHeH4PoYxc6bLysrixUmPMvOlKSwuXMHK1Wv3Pfeft9/jvLP7BJatPFGNel7SpdKC1tUIWCoiM0Xk1bKlsjeo6nhV7a6q3SOR1P6m27B+I23btNq33qZ1SzZs2JjSY6RaGDNnZ2czccpYpuZP47VpM4KO40kYM4dJw0Ma0PPHnZk9twCArdu+Y3Hhck4/pWfAyfanqp6XdPHSj/Y231MkYV7BAjp0aE9ublvWr9/I4MEDGXbZNUHHqlQYM//jkVGsWL6acY/mBR3FszBmznRbtm4jOzubhoc0YPeePXw0779cdelFALw1azZnnNKTnJzaAafcX6iGSSyTadOLR6NRrrt+BK+/9gxZkQh5k56nsHBF0LEqFbbMJ/XqxpChg1i6ZDmzPngZgFF3juHtGUmPpZE2YcyclzeW007vRZMmjVix8iNGjnyQyZPyg461n83fbuXWkfcTjcXQmNL/zNPo09u5A/8/M9/j15cODjjhwTJxuvEKu3fte4FIL+Bh4DigNpAFFHsd+DvV3bvMwVLdvcsczI/uXX5LRfeudEtF966Whx3vucwp2laYlu5dXpoOHgEuBl4AugOXAUf7GcoYY6oqE2/B9XIxDFX9HMhS1aiqTgQG+BvLGGOqJqoxz0u6eKnR7hKR2sACERkNFOGxgDbGmHTLxDZaLwXmMPd1fwCKgbbAhX6GMsaYqsrEO8O89Dr4QkTqAi1V9e9pyGSMMVUWyhqtiJwPLADecNe7JLphwRhjghJDPS/p4qXp4A6cCcm2AajqApwJGo0xJuOE9c6wElX9Ln7EHsjA/hPGGEP4Bv4us1RELgGyRKQjcC3wob+xjDGmajJx4O8Kmw5EZIr7cBVwArAHeBbYDlzvfzRjjEle2JoOyqayGYIzJu0Dcc/VA3b7GcwYY6oilXeGicgA4CGcoQf+par3VGU/lRW044CZOFPZFMQfG6eNNrBZFowxpiKpqqm6Ex88CvQD1gHzRORVVS1Mdl8VFrSqOhYYKyKPq+rvq5zWGGPSKIVttD2Bz1V1NYCIPAcMBFJX0JapbiFbune9b6PjiMhwVR3v1/5TLWx5IXyZw5YXLHOqJVPmiMhwYHjcpvFxX1dr4Ku459YBJ1UlU9jHLBie+CUZJWx5IXyZw5YXLHNg4meDcRdffnmEvaA1xhi/rMcZ26VMG3db0qygNcaY8s0DOopIe3cEw4uBKg0/4OWGhUyWkW1ElQhbXghf5rDlBcuckVS1VET+ALyJ071rgqourcq+Ek5lY4wxpnqs6cAYY3xmBa0xxvgs1AWtiOS6A95U5b07U53HwzGvEJFHAjhurogsSfdxM4mdg4OJyLUiskxEnk7XvoL4ucsEYb8YlgtcAjxz4BMikq2qpWlPZEwK+fw5vho4W1XXVXUHcfmqva+aLJAarVu7WCYiT4jIUhF5S0TqishRIvKGiMwXkQ9E5Fj39Xki8ou495f9VrwHOE1EFojIDW6N8VUReQeYKSINRGSmiHwqIotFZKBPX89lIrJIRBaKyBQROV9EPhaR/4rI2yLSvJz35InI4yIyV0RWi0gfEZngnpc8H2JmlXO+fyMi89zcL4pIvbhs40SkQERWiMhP3e1XiMgrIvKuiKwUkdvd7XeKyL4R3URklIhc58PXgIjUF5HX3MxLRGSIiPzN/TqWiMh4cQdPFpFu7usWAtf4kaecfC+7n9+l7l1HiMhO95wsdL/fzd3tR7nri0VkZNnn2v0sfCDOTCaFfpxfERmHM17Jf0TkVvez94n7mR3ovibXzfGpu5xSQb74fd0gIneIyE1xx1oiIrnVyRt6yQwplqoFpyZaCnRx1/OBS3EGsenobjsJeMd9nAf8Iu79O93/+wDT47ZfgXObXGN3PRto6D5uCnzO/3pa7EzR13ICsAJo6q43BhrFHefXwANx+R6J+5qewxmkZyDO8JOdcH75zS87Nz6f7yZxrxkJ/DEu2xtulo7uOa3j5i8CmgB1gSVAd3f/n7rvjeAMrdkkVfkP+FouBJ6IWz+07Pvtrk8BzncfLwJOdx/fByxJw2e77LNXdn6a4AzCVJZpNDDCfTwdGOo+/t0Bn+tioH3c9y/l5xdY6/5c3A1c6m47zP0818cZpa+Ou70jUFBevvh9uY/vAG6Ke24JkJvKn7uwLUE2HaxRZ1occAqWXOAU4AX532wOOVXY7wxV3eI+FuBuETkdiOHcu9wc2FjV0OU4E3hBVb8BUNUtItIJeF5EWgK1gTUVvHeaqqqILAY2qepiABFZinM+FlTwvqoo73z/SERG4vxwNcDpL1gmX1VjwEoRWQ0c626foarfujn/DZyqqv8QkW9FpCvO+f1v2Wt8sBh4QETuxfkl+4GIXCgit+AUDI1xBqv/ADhMVd933zcFONenTPGuFZGfuY/b4hRQe3EKVXDOfT/38cnAIPfxM8D9cfv5RFXXAKjqWp/P7znABXG10DpAO2AD8IiIdAGiwNHl5TOJBVnQ7ol7HMX5AG1T1S7lvLYUt5lDRCI4hVdFiuMe/xJoBnRT1RIRWYvzIfLbw8AYVX1VRPrg/IYvT9k5iLH/+YiR+u/Ngee7Lk7NdZCqLhSRK3BqKmUO7GCtCbb/C6fG2wKYUO20FVDVFSLyY+A8YKSIzMRpFuiuql+JyB2k53t8EPd7fTZwsqruEpF33Swl6lbncM69l+9t8QHrfp5fAS5U1eX7bXTO5SbgRJyfv/gxqA/MF2/fz6srkO9HJsmkXgfbgTUichGAOE50n1sLdHMfXwDUch/vAA6pZJ+HAl+7hWxf4IiUp4Z3gItEpAmAiDR2j1t2T/TlPhwzVQ4BikSkFs4vpXgXiUhERI7CaX8r+yHsJyKNxZmCfhAwx93+EjAA6MH+NeOUEmcw+l2q+hROc8CP3ae+EZEGwC8AVHUbsE1ETnWfP/Dr88OhwFa3kD0W6JXg9XNxmkLAub2zMn6e3zeBP8a1bXd1tx8KFLl/2QzDuTvKi7W43xf3l+IPfjLXTOt18EvgcREZgVOYPgcsBJ4AXnEvarzB/36bLgKi7vY8YOsB+3samOb+aV4AfJbqwKq6VERGAe+JSBT4L04N9gUR2YpTEGfqB+024GNgs/t//C+tL4FPgIbA71R1t/tz+AnwIs4AG0+pagGAqu4VkVk4f5VEfczcCbhPRGJACfB7nAJ/CU6T0Ly4114JTBARBd7yMVOZN4DficgynF9McxO8/nrgKRG51X3vdxW90OfzexfwD2CR+xfjGuCnwGPAiyJyGfv/3CXyInCZ2wT2MU6b7w+a3YJrDiJOr4fpqjr1gO1X4PyJ/ody3hMBPgUuUtWV6cgZduL08vjebae/GOfCWLk9Y+z8hlsmNR2YkBKR43F6dMy0QiAp3YAFIrIIpx/qjeW9yM5v+FmN1hhjfGY1WmOM8ZkVtMYY4zMraI0xxmdW0BpjjM+soDXGGJ/9f3ubBPr4lweuAAAAAElFTkSuQmCC\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "LGpgwFQqkpyU"
      },
      "execution_count": 37,
      "outputs": []
    }
  ]
}