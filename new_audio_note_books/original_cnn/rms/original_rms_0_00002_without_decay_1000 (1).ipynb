{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "original_rms_0.00002_without decay_1000.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9SRCO-a_AlH5",
        "outputId": "8a6ed626-39d4-44d9-c7b6-562f0bfcbbbb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install librosa"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Lo4mUwG9RMd",
        "outputId": "9eba17b5-e0a8-4d1b-979a-06932b1aeb06"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.7/dist-packages (0.8.1)\n",
            "Requirement already satisfied: resampy>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from librosa) (0.2.2)\n",
            "Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.6.0)\n",
            "Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.0.2)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.4.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (21.3)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.1.0)\n",
            "Requirement already satisfied: decorator>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied: numba>=0.43.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (0.51.2)\n",
            "Requirement already satisfied: audioread>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (2.1.9)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.21.6)\n",
            "Requirement already satisfied: soundfile>=0.10.2 in /usr/local/lib/python3.7/dist-packages (from librosa) (0.10.3.post1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba>=0.43.0->librosa) (57.4.0)\n",
            "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba>=0.43.0->librosa) (0.34.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->librosa) (3.0.9)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from pooch>=1.0->librosa) (2.23.0)\n",
            "Requirement already satisfied: appdirs>=1.3.0 in /usr/local/lib/python3.7/dist-packages (from pooch>=1.0->librosa) (1.4.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2022.5.18.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (3.0.4)\n",
            "Requirement already satisfied: six>=1.3 in /usr/local/lib/python3.7/dist-packages (from resampy>=0.2.2->librosa) (1.15.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn!=0.19.0,>=0.14.0->librosa) (3.1.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.7/dist-packages (from soundfile>=0.10.2->librosa) (1.15.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.0->soundfile>=0.10.2->librosa) (2.21)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HJjcbxwy46bG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "28d6919b-e64c-42d2-f126-0330465e6ae8"
      },
      "source": [
        "# Orignial Notebook: https://github.com/MITESHPUTHRANNEU/Speech-Emotion-Analyzer/blob/master/final_results_gender_test.ipynb\n",
        "# This notebook author: Reza Chu\n",
        "# Last Editing Date: 31st May 2019\n",
        "\n",
        "## Python\n",
        "import os\n",
        "import random\n",
        "import sys\n",
        "\n",
        "import IPython\n",
        "from IPython.display import Audio\n",
        "from IPython.display import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "## Package\n",
        "import glob \n",
        "import keras\n",
        "import IPython.display as ipd\n",
        "import librosa\n",
        "import librosa.display\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import plotly.graph_objs as go\n",
        "import plotly.offline as py\n",
        "import plotly.tools as tls\n",
        "import seaborn as sns\n",
        "import scipy.io.wavfile\n",
        "import tensorflow as tf\n",
        "py.init_notebook_mode(connected=True)\n",
        "\n",
        "## Keras\n",
        "from keras import regularizers\n",
        "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping\n",
        "from keras.callbacks import  History, ReduceLROnPlateau, CSVLogger\n",
        "from keras.models import Model, Sequential\n",
        "from keras.layers import Dense, Embedding, LSTM\n",
        "from keras.layers import Input, Flatten, Dropout, Activation, BatchNormalization\n",
        "from keras.layers import Conv1D, MaxPooling1D, AveragePooling1D\n",
        "from keras.preprocessing import sequence\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.utils import np_utils\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "## Sklearn\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "## Rest\n",
        "from scipy.fftpack import fft\n",
        "from scipy import signal\n",
        "from scipy.io import wavfile\n",
        "from tqdm import tqdm\n",
        "\n",
        "input_duration=3\n",
        "# % pylab inline"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "        <script type=\"text/javascript\">\n",
              "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
              "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
              "        if (typeof require !== 'undefined') {\n",
              "        require.undef(\"plotly\");\n",
              "        requirejs.config({\n",
              "            paths: {\n",
              "                'plotly': ['https://cdn.plot.ly/plotly-2.8.3.min']\n",
              "            }\n",
              "        });\n",
              "        require(['plotly'], function(Plotly) {\n",
              "            window._Plotly = Plotly;\n",
              "        });\n",
              "        }\n",
              "        </script>\n",
              "        "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Saving joblib files to not load them again with the loop above\n",
        "\n",
        "# import joblib\n",
        "\n",
        "# X_name = 'x.joblib'\n",
        "# y_name = 'y.joblib'\n",
        "# save_dir = '/content/drive/My Drive/graduation project/audio/paper_code/features'\n",
        "\n",
        "# savedX = joblib.dump(X, os.path.join(save_dir, X_name))\n",
        "# savedy = joblib.dump(y, os.path.join(save_dir, y_name))"
      ],
      "metadata": {
        "id": "UCzic8rlDcuk"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Loading saved models\n",
        "import joblib\n",
        "X = joblib.load('/content/drive/My Drive/graduation project/audio/paper_code/features/x.joblib')\n",
        "y = joblib.load('/content/drive/My Drive/graduation project/audio/paper_code/features/y.joblib')"
      ],
      "metadata": {
        "id": "Q35CN6zDrzg1"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7PSTurzjCo5K",
        "outputId": "e4f343d6-756f-4b68-a96a-5d061356074c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2068, 40)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.1 ,shuffle = True\n",
        "                                                    , random_state=42)\n",
        "X_train , X_valid, y_train, y_valid = train_test_split(X_train,y_train, test_size=0.1112305212 , shuffle = True \n",
        "                                                       , random_state=42)"
      ],
      "metadata": {
        "id": "Ai4Fy5cPCiq1"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "x_traincnn = np.expand_dims(X_train, axis=2)\n",
        "x_testcnn = np.expand_dims(X_test, axis=2)\n",
        "X_valid= np.expand_dims(X_valid, axis=2)"
      ],
      "metadata": {
        "id": "tp1Fm5K3CEXu"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_traincnn.shape, x_testcnn.shape , X_valid.shape\n",
        "#1861"
      ],
      "metadata": {
        "id": "RI0MxoIPBws5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb0636a1-c5a1-4ed7-d2a5-94669bea6bdf"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1654, 40, 1), (207, 40, 1), (207, 40, 1))"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oALhiMUd9G2Y",
        "outputId": "b482c39b-be6d-40f5-82fc-d3355dd50041"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (2.8.2+zzzcolab20220527125636)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (4.2.0)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow) (57.4.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (14.0.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.26.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.0.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.46.3)\n",
            "Requirement already satisfied: tensorflow-estimator<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n",
            "Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.5.3)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.21.6)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.17.3)\n",
            "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow) (1.5.2)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.4.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.23.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.35.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.8.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (3.3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.6.1)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (4.11.4)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (3.8.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2022.5.18.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (3.2.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from keras.preprocessing import sequence\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from keras.layers import Input, Flatten, Dropout, Activation\n",
        "from keras.layers import Conv1D, MaxPooling1D\n",
        "from keras.models import Model\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras import optimizers\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv1D(128, 8,padding='same', #classifier.add(Convolution2D(64, (3, 3), padding = 'same', input_shape = (128, 128, 3), activation = 'relu'))\n",
        "                 input_shape=(40,1)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(MaxPooling1D(pool_size=(5)))\n",
        "\n",
        "\n",
        "model.add(Conv1D(256,8,padding='same',))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(MaxPooling1D(pool_size=(5)))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(256))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(256))\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "model.add(Dense(6))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "opt = tf.keras.optimizers.RMSprop(lr=0.00002 , decay=0.0)\n",
        "#opt = tf.keras.optimizers.RMSprop(lr=0.0001, rho=0.9, epsilon=1e-07, decay=0.0)\n",
        "#opt = tf.keras.optimizers.SGD(lr=0.001, momentum=0.0, decay=0.0, nesterov=False)"
      ],
      "metadata": {
        "id": "g74fXWVAC4Cr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b8e907d-ac53-47ec-d1ca-40fda4554ab7"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/rmsprop.py:130: UserWarning:\n",
            "\n",
            "The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H6ukOxAGC_I4",
        "outputId": "8ab4ca16-e850-495b-8f2d-7964667fe7c2"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d (Conv1D)             (None, 40, 128)           1152      \n",
            "                                                                 \n",
            " activation (Activation)     (None, 40, 128)           0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 40, 128)           0         \n",
            "                                                                 \n",
            " max_pooling1d (MaxPooling1D  (None, 8, 128)           0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv1d_1 (Conv1D)           (None, 8, 256)            262400    \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 8, 256)            0         \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 8, 256)            0         \n",
            "                                                                 \n",
            " max_pooling1d_1 (MaxPooling  (None, 1, 256)           0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 256)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 256)               65792     \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 256)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 256)               65792     \n",
            "                                                                 \n",
            " activation_3 (Activation)   (None, 256)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 6)                 1542      \n",
            "                                                                 \n",
            " activation_4 (Activation)   (None, 6)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 396,678\n",
            "Trainable params: 396,678\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='sparse_categorical_crossentropy',\n",
        "              optimizer=opt,\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "AbMlLNk4DCBM"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an Instance of Early Stopping Callback.\n",
        "#early_stopping_callback = EarlyStopping(monitor = 'val_loss', patience = 35, mode = 'min', restore_best_weights = True)\n",
        "\n",
        "cnnhistory=model.fit(x_traincnn, y_train, batch_size=16, epochs=1000 , shuffle = True, \n",
        "                     validation_data=(X_valid, y_valid) \n",
        "                     #, callbacks = [early_stopping_callback]\n",
        "                     )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RI1v2AuADFhy",
        "outputId": "d531b25d-4c88-4625-8d01-99f2bde8da7d"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "104/104 [==============================] - 4s 7ms/step - loss: 5.7085 - accuracy: 0.1826 - val_loss: 3.6433 - val_accuracy: 0.1739\n",
            "Epoch 2/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 4.2569 - accuracy: 0.1759 - val_loss: 2.1338 - val_accuracy: 0.1739\n",
            "Epoch 3/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 3.7312 - accuracy: 0.1796 - val_loss: 2.0207 - val_accuracy: 0.1739\n",
            "Epoch 4/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 3.3057 - accuracy: 0.1735 - val_loss: 1.9198 - val_accuracy: 0.1739\n",
            "Epoch 5/1000\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 2.9359 - accuracy: 0.1989 - val_loss: 1.8617 - val_accuracy: 0.1739\n",
            "Epoch 6/1000\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 2.7065 - accuracy: 0.2001 - val_loss: 1.8623 - val_accuracy: 0.1884\n",
            "Epoch 7/1000\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 2.5889 - accuracy: 0.1765 - val_loss: 1.7752 - val_accuracy: 0.2657\n",
            "Epoch 8/1000\n",
            "104/104 [==============================] - 1s 9ms/step - loss: 2.4686 - accuracy: 0.1892 - val_loss: 1.8761 - val_accuracy: 0.1884\n",
            "Epoch 9/1000\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 2.3793 - accuracy: 0.1995 - val_loss: 1.8429 - val_accuracy: 0.2222\n",
            "Epoch 10/1000\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 2.2743 - accuracy: 0.2037 - val_loss: 1.7576 - val_accuracy: 0.1932\n",
            "Epoch 11/1000\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 2.1929 - accuracy: 0.2080 - val_loss: 1.7729 - val_accuracy: 0.2560\n",
            "Epoch 12/1000\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 2.1303 - accuracy: 0.2031 - val_loss: 1.7390 - val_accuracy: 0.2077\n",
            "Epoch 13/1000\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 2.1353 - accuracy: 0.2110 - val_loss: 1.7364 - val_accuracy: 0.2850\n",
            "Epoch 14/1000\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 2.0674 - accuracy: 0.2086 - val_loss: 1.7321 - val_accuracy: 0.2464\n",
            "Epoch 15/1000\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 2.0356 - accuracy: 0.2273 - val_loss: 1.7295 - val_accuracy: 0.1981\n",
            "Epoch 16/1000\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 1.9778 - accuracy: 0.2545 - val_loss: 1.7362 - val_accuracy: 0.2512\n",
            "Epoch 17/1000\n",
            "104/104 [==============================] - 1s 10ms/step - loss: 2.0069 - accuracy: 0.2207 - val_loss: 1.6979 - val_accuracy: 0.3382\n",
            "Epoch 18/1000\n",
            "104/104 [==============================] - 1s 9ms/step - loss: 1.9534 - accuracy: 0.2243 - val_loss: 1.6963 - val_accuracy: 0.3285\n",
            "Epoch 19/1000\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 1.9459 - accuracy: 0.2291 - val_loss: 1.7118 - val_accuracy: 0.2850\n",
            "Epoch 20/1000\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 1.8954 - accuracy: 0.2388 - val_loss: 1.6965 - val_accuracy: 0.2802\n",
            "Epoch 21/1000\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 1.8895 - accuracy: 0.2225 - val_loss: 1.6857 - val_accuracy: 0.3816\n",
            "Epoch 22/1000\n",
            "104/104 [==============================] - 1s 9ms/step - loss: 1.8912 - accuracy: 0.2406 - val_loss: 1.7104 - val_accuracy: 0.2947\n",
            "Epoch 23/1000\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 1.8734 - accuracy: 0.2437 - val_loss: 1.6855 - val_accuracy: 0.2609\n",
            "Epoch 24/1000\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 1.8531 - accuracy: 0.2424 - val_loss: 1.6913 - val_accuracy: 0.3043\n",
            "Epoch 25/1000\n",
            "104/104 [==============================] - 1s 9ms/step - loss: 1.8588 - accuracy: 0.2255 - val_loss: 1.6840 - val_accuracy: 0.3333\n",
            "Epoch 26/1000\n",
            "104/104 [==============================] - 1s 9ms/step - loss: 1.8289 - accuracy: 0.2461 - val_loss: 1.6985 - val_accuracy: 0.2609\n",
            "Epoch 27/1000\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 1.7990 - accuracy: 0.2491 - val_loss: 1.6771 - val_accuracy: 0.3382\n",
            "Epoch 28/1000\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 1.7978 - accuracy: 0.2570 - val_loss: 1.6834 - val_accuracy: 0.2850\n",
            "Epoch 29/1000\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 1.8047 - accuracy: 0.2533 - val_loss: 1.6647 - val_accuracy: 0.3671\n",
            "Epoch 30/1000\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 1.7929 - accuracy: 0.2533 - val_loss: 1.6649 - val_accuracy: 0.3623\n",
            "Epoch 31/1000\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 1.7520 - accuracy: 0.2666 - val_loss: 1.6745 - val_accuracy: 0.2705\n",
            "Epoch 32/1000\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 1.7708 - accuracy: 0.2763 - val_loss: 1.6675 - val_accuracy: 0.3140\n",
            "Epoch 33/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.7742 - accuracy: 0.2594 - val_loss: 1.6617 - val_accuracy: 0.2802\n",
            "Epoch 34/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.7616 - accuracy: 0.2696 - val_loss: 1.6557 - val_accuracy: 0.3575\n",
            "Epoch 35/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.7541 - accuracy: 0.2509 - val_loss: 1.6461 - val_accuracy: 0.3478\n",
            "Epoch 36/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.7417 - accuracy: 0.2563 - val_loss: 1.6504 - val_accuracy: 0.3333\n",
            "Epoch 37/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.7317 - accuracy: 0.2636 - val_loss: 1.6348 - val_accuracy: 0.3430\n",
            "Epoch 38/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.7310 - accuracy: 0.2642 - val_loss: 1.6413 - val_accuracy: 0.3671\n",
            "Epoch 39/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.7447 - accuracy: 0.2497 - val_loss: 1.6354 - val_accuracy: 0.3092\n",
            "Epoch 40/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.7185 - accuracy: 0.2836 - val_loss: 1.6348 - val_accuracy: 0.3671\n",
            "Epoch 41/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.6942 - accuracy: 0.2860 - val_loss: 1.6244 - val_accuracy: 0.3478\n",
            "Epoch 42/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.6766 - accuracy: 0.3041 - val_loss: 1.6283 - val_accuracy: 0.3671\n",
            "Epoch 43/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.6980 - accuracy: 0.2872 - val_loss: 1.6128 - val_accuracy: 0.3961\n",
            "Epoch 44/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.6520 - accuracy: 0.3053 - val_loss: 1.6132 - val_accuracy: 0.3575\n",
            "Epoch 45/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.6836 - accuracy: 0.2963 - val_loss: 1.6178 - val_accuracy: 0.3430\n",
            "Epoch 46/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.6702 - accuracy: 0.3108 - val_loss: 1.6123 - val_accuracy: 0.3720\n",
            "Epoch 47/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.6815 - accuracy: 0.2926 - val_loss: 1.5996 - val_accuracy: 0.3816\n",
            "Epoch 48/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.6874 - accuracy: 0.2926 - val_loss: 1.6030 - val_accuracy: 0.3285\n",
            "Epoch 49/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.6600 - accuracy: 0.2975 - val_loss: 1.5854 - val_accuracy: 0.3913\n",
            "Epoch 50/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.6680 - accuracy: 0.3077 - val_loss: 1.5917 - val_accuracy: 0.3575\n",
            "Epoch 51/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.6473 - accuracy: 0.3047 - val_loss: 1.5796 - val_accuracy: 0.3865\n",
            "Epoch 52/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.6610 - accuracy: 0.3047 - val_loss: 1.5898 - val_accuracy: 0.3478\n",
            "Epoch 53/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.6498 - accuracy: 0.3071 - val_loss: 1.5892 - val_accuracy: 0.3913\n",
            "Epoch 54/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.6325 - accuracy: 0.3102 - val_loss: 1.5726 - val_accuracy: 0.3913\n",
            "Epoch 55/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.6513 - accuracy: 0.2975 - val_loss: 1.5825 - val_accuracy: 0.3527\n",
            "Epoch 56/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.6141 - accuracy: 0.3216 - val_loss: 1.5734 - val_accuracy: 0.3623\n",
            "Epoch 57/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.6240 - accuracy: 0.3192 - val_loss: 1.5827 - val_accuracy: 0.3575\n",
            "Epoch 58/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.6206 - accuracy: 0.3241 - val_loss: 1.5860 - val_accuracy: 0.3623\n",
            "Epoch 59/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.6265 - accuracy: 0.3186 - val_loss: 1.5758 - val_accuracy: 0.3382\n",
            "Epoch 60/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.6119 - accuracy: 0.3368 - val_loss: 1.5666 - val_accuracy: 0.3768\n",
            "Epoch 61/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.5962 - accuracy: 0.3319 - val_loss: 1.5831 - val_accuracy: 0.3527\n",
            "Epoch 62/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.6098 - accuracy: 0.3168 - val_loss: 1.5646 - val_accuracy: 0.3720\n",
            "Epoch 63/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.5717 - accuracy: 0.3325 - val_loss: 1.5554 - val_accuracy: 0.3768\n",
            "Epoch 64/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.6303 - accuracy: 0.3089 - val_loss: 1.5448 - val_accuracy: 0.3816\n",
            "Epoch 65/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.5894 - accuracy: 0.3555 - val_loss: 1.5385 - val_accuracy: 0.3913\n",
            "Epoch 66/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.5793 - accuracy: 0.3495 - val_loss: 1.5322 - val_accuracy: 0.3720\n",
            "Epoch 67/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.5781 - accuracy: 0.3573 - val_loss: 1.5252 - val_accuracy: 0.4203\n",
            "Epoch 68/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.5734 - accuracy: 0.3398 - val_loss: 1.5335 - val_accuracy: 0.3816\n",
            "Epoch 69/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.5684 - accuracy: 0.3519 - val_loss: 1.5361 - val_accuracy: 0.4010\n",
            "Epoch 70/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.5536 - accuracy: 0.3476 - val_loss: 1.5189 - val_accuracy: 0.3865\n",
            "Epoch 71/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.5689 - accuracy: 0.3446 - val_loss: 1.5170 - val_accuracy: 0.4300\n",
            "Epoch 72/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.5642 - accuracy: 0.3501 - val_loss: 1.5126 - val_accuracy: 0.4300\n",
            "Epoch 73/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.5544 - accuracy: 0.3597 - val_loss: 1.5095 - val_accuracy: 0.4106\n",
            "Epoch 74/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.5550 - accuracy: 0.3543 - val_loss: 1.4997 - val_accuracy: 0.4010\n",
            "Epoch 75/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.5394 - accuracy: 0.3525 - val_loss: 1.5072 - val_accuracy: 0.4106\n",
            "Epoch 76/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.5273 - accuracy: 0.3591 - val_loss: 1.5076 - val_accuracy: 0.3720\n",
            "Epoch 77/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.5408 - accuracy: 0.3513 - val_loss: 1.5046 - val_accuracy: 0.4251\n",
            "Epoch 78/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.5276 - accuracy: 0.3597 - val_loss: 1.4903 - val_accuracy: 0.3865\n",
            "Epoch 79/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.5390 - accuracy: 0.3736 - val_loss: 1.4827 - val_accuracy: 0.4300\n",
            "Epoch 80/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.5308 - accuracy: 0.3706 - val_loss: 1.4815 - val_accuracy: 0.4203\n",
            "Epoch 81/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.5179 - accuracy: 0.3791 - val_loss: 1.4798 - val_accuracy: 0.4058\n",
            "Epoch 82/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.5460 - accuracy: 0.3531 - val_loss: 1.4684 - val_accuracy: 0.4444\n",
            "Epoch 83/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.5133 - accuracy: 0.3670 - val_loss: 1.4700 - val_accuracy: 0.4396\n",
            "Epoch 84/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.5206 - accuracy: 0.3706 - val_loss: 1.4749 - val_accuracy: 0.4300\n",
            "Epoch 85/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.5083 - accuracy: 0.3797 - val_loss: 1.4780 - val_accuracy: 0.4010\n",
            "Epoch 86/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.5087 - accuracy: 0.3767 - val_loss: 1.4723 - val_accuracy: 0.4396\n",
            "Epoch 87/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.4913 - accuracy: 0.3906 - val_loss: 1.4679 - val_accuracy: 0.4203\n",
            "Epoch 88/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.4979 - accuracy: 0.3712 - val_loss: 1.4568 - val_accuracy: 0.4686\n",
            "Epoch 89/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.4915 - accuracy: 0.3966 - val_loss: 1.4579 - val_accuracy: 0.4058\n",
            "Epoch 90/1000\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 1.4907 - accuracy: 0.3924 - val_loss: 1.4502 - val_accuracy: 0.4638\n",
            "Epoch 91/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 1.4829 - accuracy: 0.3894 - val_loss: 1.4314 - val_accuracy: 0.4493\n",
            "Epoch 92/1000\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 1.4781 - accuracy: 0.3966 - val_loss: 1.4403 - val_accuracy: 0.4444\n",
            "Epoch 93/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 1.4794 - accuracy: 0.3839 - val_loss: 1.4429 - val_accuracy: 0.4203\n",
            "Epoch 94/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 1.4578 - accuracy: 0.4015 - val_loss: 1.4271 - val_accuracy: 0.4734\n",
            "Epoch 95/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.4509 - accuracy: 0.4027 - val_loss: 1.4331 - val_accuracy: 0.4203\n",
            "Epoch 96/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.4505 - accuracy: 0.4081 - val_loss: 1.4210 - val_accuracy: 0.4493\n",
            "Epoch 97/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.4536 - accuracy: 0.4141 - val_loss: 1.4152 - val_accuracy: 0.4300\n",
            "Epoch 98/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.4388 - accuracy: 0.4008 - val_loss: 1.4117 - val_accuracy: 0.4348\n",
            "Epoch 99/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.4509 - accuracy: 0.4033 - val_loss: 1.4380 - val_accuracy: 0.4155\n",
            "Epoch 100/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.4451 - accuracy: 0.4105 - val_loss: 1.4083 - val_accuracy: 0.4928\n",
            "Epoch 101/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.4275 - accuracy: 0.4129 - val_loss: 1.4079 - val_accuracy: 0.4686\n",
            "Epoch 102/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.4486 - accuracy: 0.4057 - val_loss: 1.4424 - val_accuracy: 0.4106\n",
            "Epoch 103/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.4361 - accuracy: 0.4021 - val_loss: 1.3979 - val_accuracy: 0.4396\n",
            "Epoch 104/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.4387 - accuracy: 0.4184 - val_loss: 1.3820 - val_accuracy: 0.4928\n",
            "Epoch 105/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.4246 - accuracy: 0.4063 - val_loss: 1.3834 - val_accuracy: 0.4928\n",
            "Epoch 106/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.4325 - accuracy: 0.4184 - val_loss: 1.3990 - val_accuracy: 0.4444\n",
            "Epoch 107/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.4054 - accuracy: 0.4232 - val_loss: 1.3853 - val_accuracy: 0.5266\n",
            "Epoch 108/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.4274 - accuracy: 0.4238 - val_loss: 1.3821 - val_accuracy: 0.5024\n",
            "Epoch 109/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.4154 - accuracy: 0.4148 - val_loss: 1.3718 - val_accuracy: 0.5024\n",
            "Epoch 110/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.4119 - accuracy: 0.4123 - val_loss: 1.3709 - val_accuracy: 0.5169\n",
            "Epoch 111/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.4116 - accuracy: 0.4208 - val_loss: 1.3669 - val_accuracy: 0.4831\n",
            "Epoch 112/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.4090 - accuracy: 0.4214 - val_loss: 1.3824 - val_accuracy: 0.4493\n",
            "Epoch 113/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.3727 - accuracy: 0.4311 - val_loss: 1.3603 - val_accuracy: 0.5169\n",
            "Epoch 114/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.4017 - accuracy: 0.4190 - val_loss: 1.3662 - val_accuracy: 0.4928\n",
            "Epoch 115/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.3943 - accuracy: 0.4208 - val_loss: 1.3600 - val_accuracy: 0.4783\n",
            "Epoch 116/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.3741 - accuracy: 0.4432 - val_loss: 1.3764 - val_accuracy: 0.4444\n",
            "Epoch 117/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.3798 - accuracy: 0.4329 - val_loss: 1.3521 - val_accuracy: 0.4831\n",
            "Epoch 118/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.3800 - accuracy: 0.4389 - val_loss: 1.3482 - val_accuracy: 0.4879\n",
            "Epoch 119/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.3901 - accuracy: 0.4383 - val_loss: 1.3439 - val_accuracy: 0.5024\n",
            "Epoch 120/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.3870 - accuracy: 0.4329 - val_loss: 1.3402 - val_accuracy: 0.5121\n",
            "Epoch 121/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.3658 - accuracy: 0.4395 - val_loss: 1.3332 - val_accuracy: 0.4879\n",
            "Epoch 122/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.3629 - accuracy: 0.4389 - val_loss: 1.3275 - val_accuracy: 0.5314\n",
            "Epoch 123/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.3518 - accuracy: 0.4480 - val_loss: 1.3238 - val_accuracy: 0.5024\n",
            "Epoch 124/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.3650 - accuracy: 0.4462 - val_loss: 1.3132 - val_accuracy: 0.5652\n",
            "Epoch 125/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.3429 - accuracy: 0.4504 - val_loss: 1.3005 - val_accuracy: 0.5314\n",
            "Epoch 126/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.3365 - accuracy: 0.4528 - val_loss: 1.3171 - val_accuracy: 0.4734\n",
            "Epoch 127/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.3255 - accuracy: 0.4601 - val_loss: 1.3141 - val_accuracy: 0.4928\n",
            "Epoch 128/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.3540 - accuracy: 0.4534 - val_loss: 1.3196 - val_accuracy: 0.5169\n",
            "Epoch 129/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.3244 - accuracy: 0.4534 - val_loss: 1.3142 - val_accuracy: 0.5024\n",
            "Epoch 130/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.3341 - accuracy: 0.4516 - val_loss: 1.3000 - val_accuracy: 0.5362\n",
            "Epoch 131/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.3098 - accuracy: 0.4619 - val_loss: 1.2786 - val_accuracy: 0.4976\n",
            "Epoch 132/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.3246 - accuracy: 0.4625 - val_loss: 1.2768 - val_accuracy: 0.5217\n",
            "Epoch 133/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.3224 - accuracy: 0.4522 - val_loss: 1.2717 - val_accuracy: 0.5314\n",
            "Epoch 134/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.3085 - accuracy: 0.4534 - val_loss: 1.2737 - val_accuracy: 0.5604\n",
            "Epoch 135/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.2990 - accuracy: 0.4849 - val_loss: 1.2595 - val_accuracy: 0.5217\n",
            "Epoch 136/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.3166 - accuracy: 0.4619 - val_loss: 1.2624 - val_accuracy: 0.5507\n",
            "Epoch 137/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.3040 - accuracy: 0.4625 - val_loss: 1.2655 - val_accuracy: 0.5411\n",
            "Epoch 138/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.2952 - accuracy: 0.4710 - val_loss: 1.2749 - val_accuracy: 0.5362\n",
            "Epoch 139/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.2975 - accuracy: 0.4819 - val_loss: 1.2554 - val_accuracy: 0.5459\n",
            "Epoch 140/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.2972 - accuracy: 0.4843 - val_loss: 1.2638 - val_accuracy: 0.5507\n",
            "Epoch 141/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.2950 - accuracy: 0.4825 - val_loss: 1.2916 - val_accuracy: 0.5024\n",
            "Epoch 142/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.2809 - accuracy: 0.4788 - val_loss: 1.2645 - val_accuracy: 0.5459\n",
            "Epoch 143/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.2803 - accuracy: 0.4879 - val_loss: 1.2625 - val_accuracy: 0.5024\n",
            "Epoch 144/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.2698 - accuracy: 0.4746 - val_loss: 1.2303 - val_accuracy: 0.5217\n",
            "Epoch 145/1000\n",
            "104/104 [==============================] - 1s 9ms/step - loss: 1.2856 - accuracy: 0.4770 - val_loss: 1.2462 - val_accuracy: 0.5604\n",
            "Epoch 146/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.2815 - accuracy: 0.4933 - val_loss: 1.2379 - val_accuracy: 0.5604\n",
            "Epoch 147/1000\n",
            "104/104 [==============================] - 1s 9ms/step - loss: 1.2612 - accuracy: 0.4843 - val_loss: 1.2409 - val_accuracy: 0.5507\n",
            "Epoch 148/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.2780 - accuracy: 0.4927 - val_loss: 1.2408 - val_accuracy: 0.5459\n",
            "Epoch 149/1000\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 1.2520 - accuracy: 0.4933 - val_loss: 1.2326 - val_accuracy: 0.5556\n",
            "Epoch 150/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.2719 - accuracy: 0.4770 - val_loss: 1.2265 - val_accuracy: 0.5845\n",
            "Epoch 151/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.2713 - accuracy: 0.4873 - val_loss: 1.2415 - val_accuracy: 0.5652\n",
            "Epoch 152/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.2563 - accuracy: 0.4849 - val_loss: 1.2045 - val_accuracy: 0.5459\n",
            "Epoch 153/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.2515 - accuracy: 0.5012 - val_loss: 1.2208 - val_accuracy: 0.5797\n",
            "Epoch 154/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.2541 - accuracy: 0.4885 - val_loss: 1.2032 - val_accuracy: 0.5749\n",
            "Epoch 155/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.2421 - accuracy: 0.4970 - val_loss: 1.1998 - val_accuracy: 0.5314\n",
            "Epoch 156/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.2363 - accuracy: 0.4958 - val_loss: 1.1934 - val_accuracy: 0.5700\n",
            "Epoch 157/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.2329 - accuracy: 0.5042 - val_loss: 1.2202 - val_accuracy: 0.5700\n",
            "Epoch 158/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.2360 - accuracy: 0.5000 - val_loss: 1.1775 - val_accuracy: 0.5990\n",
            "Epoch 159/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.2178 - accuracy: 0.5042 - val_loss: 1.1816 - val_accuracy: 0.5749\n",
            "Epoch 160/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.2225 - accuracy: 0.5073 - val_loss: 1.1764 - val_accuracy: 0.6039\n",
            "Epoch 161/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.2197 - accuracy: 0.5012 - val_loss: 1.1811 - val_accuracy: 0.5700\n",
            "Epoch 162/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.2319 - accuracy: 0.5060 - val_loss: 1.1846 - val_accuracy: 0.5652\n",
            "Epoch 163/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.2249 - accuracy: 0.5103 - val_loss: 1.1773 - val_accuracy: 0.5797\n",
            "Epoch 164/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.2317 - accuracy: 0.5036 - val_loss: 1.1660 - val_accuracy: 0.5894\n",
            "Epoch 165/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.2276 - accuracy: 0.5224 - val_loss: 1.1679 - val_accuracy: 0.5700\n",
            "Epoch 166/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.2240 - accuracy: 0.5085 - val_loss: 1.1750 - val_accuracy: 0.5894\n",
            "Epoch 167/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.2335 - accuracy: 0.5067 - val_loss: 1.1747 - val_accuracy: 0.5604\n",
            "Epoch 168/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.2013 - accuracy: 0.5236 - val_loss: 1.1606 - val_accuracy: 0.6087\n",
            "Epoch 169/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.1765 - accuracy: 0.5157 - val_loss: 1.1613 - val_accuracy: 0.5700\n",
            "Epoch 170/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.1911 - accuracy: 0.5212 - val_loss: 1.1603 - val_accuracy: 0.5797\n",
            "Epoch 171/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.1943 - accuracy: 0.5091 - val_loss: 1.1484 - val_accuracy: 0.5990\n",
            "Epoch 172/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.1892 - accuracy: 0.5212 - val_loss: 1.1421 - val_accuracy: 0.6232\n",
            "Epoch 173/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 1.2009 - accuracy: 0.5145 - val_loss: 1.1542 - val_accuracy: 0.5556\n",
            "Epoch 174/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.1900 - accuracy: 0.5260 - val_loss: 1.1647 - val_accuracy: 0.5749\n",
            "Epoch 175/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.1938 - accuracy: 0.5133 - val_loss: 1.1598 - val_accuracy: 0.5797\n",
            "Epoch 176/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.1922 - accuracy: 0.5157 - val_loss: 1.1338 - val_accuracy: 0.5749\n",
            "Epoch 177/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.1771 - accuracy: 0.5272 - val_loss: 1.1396 - val_accuracy: 0.6039\n",
            "Epoch 178/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.1703 - accuracy: 0.5357 - val_loss: 1.1347 - val_accuracy: 0.6135\n",
            "Epoch 179/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.1719 - accuracy: 0.5326 - val_loss: 1.1583 - val_accuracy: 0.5894\n",
            "Epoch 180/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.1635 - accuracy: 0.5272 - val_loss: 1.1246 - val_accuracy: 0.6039\n",
            "Epoch 181/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.1905 - accuracy: 0.5193 - val_loss: 1.1548 - val_accuracy: 0.5749\n",
            "Epoch 182/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.1670 - accuracy: 0.5411 - val_loss: 1.1282 - val_accuracy: 0.5797\n",
            "Epoch 183/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.1674 - accuracy: 0.5193 - val_loss: 1.1327 - val_accuracy: 0.5797\n",
            "Epoch 184/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.1602 - accuracy: 0.5369 - val_loss: 1.1221 - val_accuracy: 0.6087\n",
            "Epoch 185/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.1551 - accuracy: 0.5333 - val_loss: 1.1496 - val_accuracy: 0.5797\n",
            "Epoch 186/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.1694 - accuracy: 0.5248 - val_loss: 1.1201 - val_accuracy: 0.6039\n",
            "Epoch 187/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.1516 - accuracy: 0.5357 - val_loss: 1.1133 - val_accuracy: 0.5797\n",
            "Epoch 188/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.1202 - accuracy: 0.5532 - val_loss: 1.1032 - val_accuracy: 0.6184\n",
            "Epoch 189/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.1444 - accuracy: 0.5339 - val_loss: 1.1221 - val_accuracy: 0.6425\n",
            "Epoch 190/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.1436 - accuracy: 0.5357 - val_loss: 1.0912 - val_accuracy: 0.6135\n",
            "Epoch 191/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.1427 - accuracy: 0.5381 - val_loss: 1.0909 - val_accuracy: 0.6377\n",
            "Epoch 192/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.1303 - accuracy: 0.5514 - val_loss: 1.1105 - val_accuracy: 0.6087\n",
            "Epoch 193/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.1416 - accuracy: 0.5278 - val_loss: 1.1033 - val_accuracy: 0.6232\n",
            "Epoch 194/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.1550 - accuracy: 0.5369 - val_loss: 1.1193 - val_accuracy: 0.6087\n",
            "Epoch 195/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.1249 - accuracy: 0.5459 - val_loss: 1.1129 - val_accuracy: 0.5942\n",
            "Epoch 196/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.1368 - accuracy: 0.5381 - val_loss: 1.0883 - val_accuracy: 0.5845\n",
            "Epoch 197/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.1300 - accuracy: 0.5441 - val_loss: 1.0982 - val_accuracy: 0.6232\n",
            "Epoch 198/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.1288 - accuracy: 0.5556 - val_loss: 1.0912 - val_accuracy: 0.6329\n",
            "Epoch 199/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.1332 - accuracy: 0.5453 - val_loss: 1.0707 - val_accuracy: 0.6087\n",
            "Epoch 200/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.1144 - accuracy: 0.5447 - val_loss: 1.0902 - val_accuracy: 0.5845\n",
            "Epoch 201/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.1339 - accuracy: 0.5502 - val_loss: 1.0782 - val_accuracy: 0.5990\n",
            "Epoch 202/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0970 - accuracy: 0.5635 - val_loss: 1.0638 - val_accuracy: 0.6377\n",
            "Epoch 203/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.1008 - accuracy: 0.5659 - val_loss: 1.0784 - val_accuracy: 0.6184\n",
            "Epoch 204/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.1100 - accuracy: 0.5562 - val_loss: 1.0805 - val_accuracy: 0.6377\n",
            "Epoch 205/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.1119 - accuracy: 0.5629 - val_loss: 1.0770 - val_accuracy: 0.6280\n",
            "Epoch 206/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.1108 - accuracy: 0.5393 - val_loss: 1.0817 - val_accuracy: 0.6184\n",
            "Epoch 207/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0996 - accuracy: 0.5659 - val_loss: 1.0610 - val_accuracy: 0.6280\n",
            "Epoch 208/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.1050 - accuracy: 0.5641 - val_loss: 1.0725 - val_accuracy: 0.6377\n",
            "Epoch 209/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0875 - accuracy: 0.5683 - val_loss: 1.0735 - val_accuracy: 0.6184\n",
            "Epoch 210/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0799 - accuracy: 0.5701 - val_loss: 1.0571 - val_accuracy: 0.6135\n",
            "Epoch 211/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0975 - accuracy: 0.5623 - val_loss: 1.0674 - val_accuracy: 0.6039\n",
            "Epoch 212/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.1012 - accuracy: 0.5701 - val_loss: 1.0702 - val_accuracy: 0.6135\n",
            "Epoch 213/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0808 - accuracy: 0.5750 - val_loss: 1.0426 - val_accuracy: 0.6329\n",
            "Epoch 214/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0778 - accuracy: 0.5683 - val_loss: 1.0502 - val_accuracy: 0.6087\n",
            "Epoch 215/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0829 - accuracy: 0.5617 - val_loss: 1.0419 - val_accuracy: 0.6280\n",
            "Epoch 216/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0922 - accuracy: 0.5562 - val_loss: 1.0748 - val_accuracy: 0.6280\n",
            "Epoch 217/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0757 - accuracy: 0.5689 - val_loss: 1.0393 - val_accuracy: 0.6377\n",
            "Epoch 218/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0581 - accuracy: 0.5768 - val_loss: 1.0367 - val_accuracy: 0.6184\n",
            "Epoch 219/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0520 - accuracy: 0.5798 - val_loss: 1.0310 - val_accuracy: 0.6425\n",
            "Epoch 220/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0827 - accuracy: 0.5671 - val_loss: 1.0367 - val_accuracy: 0.6087\n",
            "Epoch 221/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0625 - accuracy: 0.5798 - val_loss: 1.0467 - val_accuracy: 0.6473\n",
            "Epoch 222/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0636 - accuracy: 0.5701 - val_loss: 1.0517 - val_accuracy: 0.6618\n",
            "Epoch 223/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0617 - accuracy: 0.5774 - val_loss: 1.0399 - val_accuracy: 0.6232\n",
            "Epoch 224/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0546 - accuracy: 0.5756 - val_loss: 1.0180 - val_accuracy: 0.6522\n",
            "Epoch 225/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0576 - accuracy: 0.5798 - val_loss: 1.0381 - val_accuracy: 0.6329\n",
            "Epoch 226/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0678 - accuracy: 0.5792 - val_loss: 1.0133 - val_accuracy: 0.6522\n",
            "Epoch 227/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0653 - accuracy: 0.5738 - val_loss: 1.0240 - val_accuracy: 0.6522\n",
            "Epoch 228/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0414 - accuracy: 0.5792 - val_loss: 1.0123 - val_accuracy: 0.6329\n",
            "Epoch 229/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0351 - accuracy: 0.5840 - val_loss: 1.0040 - val_accuracy: 0.6522\n",
            "Epoch 230/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0443 - accuracy: 0.5744 - val_loss: 1.0098 - val_accuracy: 0.6667\n",
            "Epoch 231/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0577 - accuracy: 0.5877 - val_loss: 1.0146 - val_accuracy: 0.6570\n",
            "Epoch 232/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0397 - accuracy: 0.5919 - val_loss: 1.0049 - val_accuracy: 0.6570\n",
            "Epoch 233/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0297 - accuracy: 0.5998 - val_loss: 1.0294 - val_accuracy: 0.6135\n",
            "Epoch 234/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0296 - accuracy: 0.6022 - val_loss: 0.9930 - val_accuracy: 0.6667\n",
            "Epoch 235/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0322 - accuracy: 0.5925 - val_loss: 0.9921 - val_accuracy: 0.6618\n",
            "Epoch 236/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0368 - accuracy: 0.5883 - val_loss: 0.9919 - val_accuracy: 0.6618\n",
            "Epoch 237/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0240 - accuracy: 0.5852 - val_loss: 0.9863 - val_accuracy: 0.7005\n",
            "Epoch 238/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0360 - accuracy: 0.5750 - val_loss: 0.9890 - val_accuracy: 0.6715\n",
            "Epoch 239/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0232 - accuracy: 0.5992 - val_loss: 1.0034 - val_accuracy: 0.6812\n",
            "Epoch 240/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0199 - accuracy: 0.5955 - val_loss: 0.9962 - val_accuracy: 0.6908\n",
            "Epoch 241/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0195 - accuracy: 0.5846 - val_loss: 1.0025 - val_accuracy: 0.6184\n",
            "Epoch 242/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0291 - accuracy: 0.5907 - val_loss: 0.9946 - val_accuracy: 0.6425\n",
            "Epoch 243/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0171 - accuracy: 0.5967 - val_loss: 0.9796 - val_accuracy: 0.6618\n",
            "Epoch 244/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0177 - accuracy: 0.5973 - val_loss: 1.0136 - val_accuracy: 0.6087\n",
            "Epoch 245/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0175 - accuracy: 0.5883 - val_loss: 0.9868 - val_accuracy: 0.6425\n",
            "Epoch 246/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0004 - accuracy: 0.5979 - val_loss: 0.9956 - val_accuracy: 0.6763\n",
            "Epoch 247/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9856 - accuracy: 0.6155 - val_loss: 0.9643 - val_accuracy: 0.6860\n",
            "Epoch 248/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0143 - accuracy: 0.5985 - val_loss: 0.9673 - val_accuracy: 0.6763\n",
            "Epoch 249/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0105 - accuracy: 0.5937 - val_loss: 0.9710 - val_accuracy: 0.6667\n",
            "Epoch 250/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9879 - accuracy: 0.5979 - val_loss: 0.9910 - val_accuracy: 0.6570\n",
            "Epoch 251/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0156 - accuracy: 0.6022 - val_loss: 0.9778 - val_accuracy: 0.6522\n",
            "Epoch 252/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0061 - accuracy: 0.5998 - val_loss: 0.9583 - val_accuracy: 0.6618\n",
            "Epoch 253/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9934 - accuracy: 0.6010 - val_loss: 0.9835 - val_accuracy: 0.5942\n",
            "Epoch 254/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0093 - accuracy: 0.6052 - val_loss: 0.9690 - val_accuracy: 0.6425\n",
            "Epoch 255/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9788 - accuracy: 0.6094 - val_loss: 0.9791 - val_accuracy: 0.6425\n",
            "Epoch 256/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9860 - accuracy: 0.6022 - val_loss: 0.9791 - val_accuracy: 0.6522\n",
            "Epoch 257/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0025 - accuracy: 0.5955 - val_loss: 0.9754 - val_accuracy: 0.6715\n",
            "Epoch 258/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9967 - accuracy: 0.5992 - val_loss: 0.9635 - val_accuracy: 0.6763\n",
            "Epoch 259/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9879 - accuracy: 0.6040 - val_loss: 0.9556 - val_accuracy: 0.6570\n",
            "Epoch 260/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9883 - accuracy: 0.6112 - val_loss: 0.9599 - val_accuracy: 0.6522\n",
            "Epoch 261/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9630 - accuracy: 0.6167 - val_loss: 0.9471 - val_accuracy: 0.7053\n",
            "Epoch 262/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9610 - accuracy: 0.6215 - val_loss: 0.9392 - val_accuracy: 0.6860\n",
            "Epoch 263/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9946 - accuracy: 0.6161 - val_loss: 0.9573 - val_accuracy: 0.6618\n",
            "Epoch 264/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9785 - accuracy: 0.6082 - val_loss: 0.9504 - val_accuracy: 0.6763\n",
            "Epoch 265/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9650 - accuracy: 0.6179 - val_loss: 0.9494 - val_accuracy: 0.6763\n",
            "Epoch 266/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9818 - accuracy: 0.6046 - val_loss: 0.9450 - val_accuracy: 0.6522\n",
            "Epoch 267/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9765 - accuracy: 0.6064 - val_loss: 0.9321 - val_accuracy: 0.6908\n",
            "Epoch 268/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9882 - accuracy: 0.6052 - val_loss: 0.9431 - val_accuracy: 0.6667\n",
            "Epoch 269/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9672 - accuracy: 0.5985 - val_loss: 0.9550 - val_accuracy: 0.6908\n",
            "Epoch 270/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9596 - accuracy: 0.6209 - val_loss: 0.9345 - val_accuracy: 0.6763\n",
            "Epoch 271/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9770 - accuracy: 0.6070 - val_loss: 0.9416 - val_accuracy: 0.6908\n",
            "Epoch 272/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9593 - accuracy: 0.6155 - val_loss: 0.9448 - val_accuracy: 0.6763\n",
            "Epoch 273/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9460 - accuracy: 0.6233 - val_loss: 0.9378 - val_accuracy: 0.7053\n",
            "Epoch 274/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9787 - accuracy: 0.6010 - val_loss: 0.9511 - val_accuracy: 0.6957\n",
            "Epoch 275/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9521 - accuracy: 0.6185 - val_loss: 0.9473 - val_accuracy: 0.6957\n",
            "Epoch 276/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9482 - accuracy: 0.6149 - val_loss: 0.9370 - val_accuracy: 0.6763\n",
            "Epoch 277/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9483 - accuracy: 0.6191 - val_loss: 0.9272 - val_accuracy: 0.6473\n",
            "Epoch 278/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9692 - accuracy: 0.6155 - val_loss: 0.9243 - val_accuracy: 0.6667\n",
            "Epoch 279/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9574 - accuracy: 0.6258 - val_loss: 0.9365 - val_accuracy: 0.6618\n",
            "Epoch 280/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9353 - accuracy: 0.6378 - val_loss: 0.9284 - val_accuracy: 0.7005\n",
            "Epoch 281/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9373 - accuracy: 0.6252 - val_loss: 0.9510 - val_accuracy: 0.6812\n",
            "Epoch 282/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9546 - accuracy: 0.6185 - val_loss: 0.9348 - val_accuracy: 0.6715\n",
            "Epoch 283/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9510 - accuracy: 0.6264 - val_loss: 0.9229 - val_accuracy: 0.6860\n",
            "Epoch 284/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9352 - accuracy: 0.6252 - val_loss: 0.9216 - val_accuracy: 0.6957\n",
            "Epoch 285/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9376 - accuracy: 0.6366 - val_loss: 0.9034 - val_accuracy: 0.7246\n",
            "Epoch 286/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9435 - accuracy: 0.6258 - val_loss: 0.9011 - val_accuracy: 0.6715\n",
            "Epoch 287/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9509 - accuracy: 0.6215 - val_loss: 0.9215 - val_accuracy: 0.6570\n",
            "Epoch 288/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9408 - accuracy: 0.6312 - val_loss: 0.9288 - val_accuracy: 0.6522\n",
            "Epoch 289/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9343 - accuracy: 0.6312 - val_loss: 0.9094 - val_accuracy: 0.7198\n",
            "Epoch 290/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9391 - accuracy: 0.6336 - val_loss: 0.9142 - val_accuracy: 0.6957\n",
            "Epoch 291/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.9050 - accuracy: 0.6421 - val_loss: 0.9172 - val_accuracy: 0.7005\n",
            "Epoch 292/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9278 - accuracy: 0.6342 - val_loss: 0.9166 - val_accuracy: 0.6473\n",
            "Epoch 293/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9104 - accuracy: 0.6457 - val_loss: 0.9056 - val_accuracy: 0.7053\n",
            "Epoch 294/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9271 - accuracy: 0.6306 - val_loss: 0.9161 - val_accuracy: 0.6860\n",
            "Epoch 295/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9205 - accuracy: 0.6548 - val_loss: 0.9044 - val_accuracy: 0.6812\n",
            "Epoch 296/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9309 - accuracy: 0.6131 - val_loss: 0.9035 - val_accuracy: 0.6860\n",
            "Epoch 297/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9130 - accuracy: 0.6312 - val_loss: 0.9069 - val_accuracy: 0.7005\n",
            "Epoch 298/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9047 - accuracy: 0.6439 - val_loss: 0.8915 - val_accuracy: 0.7053\n",
            "Epoch 299/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9175 - accuracy: 0.6312 - val_loss: 0.8863 - val_accuracy: 0.6570\n",
            "Epoch 300/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8955 - accuracy: 0.6566 - val_loss: 0.9047 - val_accuracy: 0.6763\n",
            "Epoch 301/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9118 - accuracy: 0.6330 - val_loss: 0.8910 - val_accuracy: 0.6667\n",
            "Epoch 302/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9138 - accuracy: 0.6415 - val_loss: 0.9049 - val_accuracy: 0.6908\n",
            "Epoch 303/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8772 - accuracy: 0.6499 - val_loss: 0.8829 - val_accuracy: 0.6812\n",
            "Epoch 304/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9257 - accuracy: 0.6294 - val_loss: 0.8842 - val_accuracy: 0.7053\n",
            "Epoch 305/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8923 - accuracy: 0.6542 - val_loss: 0.8859 - val_accuracy: 0.6860\n",
            "Epoch 306/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9249 - accuracy: 0.6372 - val_loss: 0.8756 - val_accuracy: 0.6957\n",
            "Epoch 307/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8980 - accuracy: 0.6620 - val_loss: 0.8766 - val_accuracy: 0.7005\n",
            "Epoch 308/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8989 - accuracy: 0.6505 - val_loss: 0.8708 - val_accuracy: 0.7295\n",
            "Epoch 309/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8926 - accuracy: 0.6451 - val_loss: 0.8824 - val_accuracy: 0.6908\n",
            "Epoch 310/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8892 - accuracy: 0.6469 - val_loss: 0.8797 - val_accuracy: 0.6715\n",
            "Epoch 311/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8985 - accuracy: 0.6524 - val_loss: 0.8652 - val_accuracy: 0.6908\n",
            "Epoch 312/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9115 - accuracy: 0.6433 - val_loss: 0.8699 - val_accuracy: 0.7101\n",
            "Epoch 313/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9004 - accuracy: 0.6409 - val_loss: 0.8695 - val_accuracy: 0.7295\n",
            "Epoch 314/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8985 - accuracy: 0.6445 - val_loss: 0.8974 - val_accuracy: 0.7053\n",
            "Epoch 315/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9058 - accuracy: 0.6481 - val_loss: 0.8854 - val_accuracy: 0.6908\n",
            "Epoch 316/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8968 - accuracy: 0.6378 - val_loss: 0.8983 - val_accuracy: 0.6908\n",
            "Epoch 317/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8735 - accuracy: 0.6493 - val_loss: 0.8707 - val_accuracy: 0.7053\n",
            "Epoch 318/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8902 - accuracy: 0.6505 - val_loss: 0.8731 - val_accuracy: 0.7005\n",
            "Epoch 319/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8946 - accuracy: 0.6385 - val_loss: 0.8772 - val_accuracy: 0.6957\n",
            "Epoch 320/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8672 - accuracy: 0.6499 - val_loss: 0.8593 - val_accuracy: 0.7246\n",
            "Epoch 321/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8841 - accuracy: 0.6524 - val_loss: 0.8778 - val_accuracy: 0.7053\n",
            "Epoch 322/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8596 - accuracy: 0.6505 - val_loss: 0.8649 - val_accuracy: 0.7053\n",
            "Epoch 323/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8930 - accuracy: 0.6372 - val_loss: 0.8590 - val_accuracy: 0.7053\n",
            "Epoch 324/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8918 - accuracy: 0.6451 - val_loss: 0.8625 - val_accuracy: 0.7150\n",
            "Epoch 325/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8874 - accuracy: 0.6475 - val_loss: 0.9049 - val_accuracy: 0.6473\n",
            "Epoch 326/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8625 - accuracy: 0.6560 - val_loss: 0.8619 - val_accuracy: 0.7053\n",
            "Epoch 327/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8604 - accuracy: 0.6596 - val_loss: 0.8591 - val_accuracy: 0.6715\n",
            "Epoch 328/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8707 - accuracy: 0.6475 - val_loss: 0.8550 - val_accuracy: 0.6957\n",
            "Epoch 329/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8857 - accuracy: 0.6439 - val_loss: 0.8645 - val_accuracy: 0.7150\n",
            "Epoch 330/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8806 - accuracy: 0.6644 - val_loss: 0.8705 - val_accuracy: 0.6957\n",
            "Epoch 331/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8853 - accuracy: 0.6409 - val_loss: 0.8807 - val_accuracy: 0.7053\n",
            "Epoch 332/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8632 - accuracy: 0.6554 - val_loss: 0.8563 - val_accuracy: 0.7101\n",
            "Epoch 333/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8762 - accuracy: 0.6578 - val_loss: 0.8436 - val_accuracy: 0.7246\n",
            "Epoch 334/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8781 - accuracy: 0.6469 - val_loss: 0.8544 - val_accuracy: 0.7053\n",
            "Epoch 335/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8594 - accuracy: 0.6602 - val_loss: 0.8603 - val_accuracy: 0.6860\n",
            "Epoch 336/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8895 - accuracy: 0.6451 - val_loss: 0.8606 - val_accuracy: 0.7053\n",
            "Epoch 337/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8639 - accuracy: 0.6651 - val_loss: 0.8555 - val_accuracy: 0.7053\n",
            "Epoch 338/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8441 - accuracy: 0.6584 - val_loss: 0.8558 - val_accuracy: 0.6957\n",
            "Epoch 339/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8709 - accuracy: 0.6499 - val_loss: 0.8916 - val_accuracy: 0.6860\n",
            "Epoch 340/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8424 - accuracy: 0.6687 - val_loss: 0.8404 - val_accuracy: 0.7198\n",
            "Epoch 341/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8382 - accuracy: 0.6620 - val_loss: 0.8355 - val_accuracy: 0.7198\n",
            "Epoch 342/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8606 - accuracy: 0.6632 - val_loss: 0.8469 - val_accuracy: 0.7150\n",
            "Epoch 343/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8456 - accuracy: 0.6765 - val_loss: 0.8301 - val_accuracy: 0.7295\n",
            "Epoch 344/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8527 - accuracy: 0.6651 - val_loss: 0.8389 - val_accuracy: 0.7198\n",
            "Epoch 345/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8585 - accuracy: 0.6584 - val_loss: 0.8341 - val_accuracy: 0.7150\n",
            "Epoch 346/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8429 - accuracy: 0.6620 - val_loss: 0.8407 - val_accuracy: 0.7005\n",
            "Epoch 347/1000\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.8283 - accuracy: 0.6711 - val_loss: 0.8550 - val_accuracy: 0.7150\n",
            "Epoch 348/1000\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.8378 - accuracy: 0.6651 - val_loss: 0.8355 - val_accuracy: 0.7246\n",
            "Epoch 349/1000\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.8356 - accuracy: 0.6651 - val_loss: 0.8541 - val_accuracy: 0.6812\n",
            "Epoch 350/1000\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.8589 - accuracy: 0.6572 - val_loss: 0.8434 - val_accuracy: 0.7101\n",
            "Epoch 351/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.8438 - accuracy: 0.6548 - val_loss: 0.8284 - val_accuracy: 0.7295\n",
            "Epoch 352/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.8202 - accuracy: 0.6699 - val_loss: 0.8419 - val_accuracy: 0.7150\n",
            "Epoch 353/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8293 - accuracy: 0.6759 - val_loss: 0.8511 - val_accuracy: 0.7150\n",
            "Epoch 354/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8034 - accuracy: 0.6868 - val_loss: 0.8470 - val_accuracy: 0.6908\n",
            "Epoch 355/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8386 - accuracy: 0.6711 - val_loss: 0.8254 - val_accuracy: 0.7343\n",
            "Epoch 356/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8300 - accuracy: 0.6675 - val_loss: 0.8381 - val_accuracy: 0.7101\n",
            "Epoch 357/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8363 - accuracy: 0.6663 - val_loss: 0.8416 - val_accuracy: 0.7101\n",
            "Epoch 358/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8505 - accuracy: 0.6614 - val_loss: 0.8343 - val_accuracy: 0.7343\n",
            "Epoch 359/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8173 - accuracy: 0.6850 - val_loss: 0.8113 - val_accuracy: 0.7343\n",
            "Epoch 360/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8450 - accuracy: 0.6644 - val_loss: 0.8398 - val_accuracy: 0.6908\n",
            "Epoch 361/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8237 - accuracy: 0.6638 - val_loss: 0.8272 - val_accuracy: 0.7198\n",
            "Epoch 362/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7909 - accuracy: 0.6790 - val_loss: 0.8271 - val_accuracy: 0.7101\n",
            "Epoch 363/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8335 - accuracy: 0.6711 - val_loss: 0.8277 - val_accuracy: 0.7053\n",
            "Epoch 364/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.8283 - accuracy: 0.6638 - val_loss: 0.8238 - val_accuracy: 0.7101\n",
            "Epoch 365/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8258 - accuracy: 0.6705 - val_loss: 0.8378 - val_accuracy: 0.7053\n",
            "Epoch 366/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8287 - accuracy: 0.6753 - val_loss: 0.8321 - val_accuracy: 0.7150\n",
            "Epoch 367/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8117 - accuracy: 0.6723 - val_loss: 0.8260 - val_accuracy: 0.7101\n",
            "Epoch 368/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8322 - accuracy: 0.6644 - val_loss: 0.8367 - val_accuracy: 0.7005\n",
            "Epoch 369/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8260 - accuracy: 0.6729 - val_loss: 0.8249 - val_accuracy: 0.7343\n",
            "Epoch 370/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8099 - accuracy: 0.6790 - val_loss: 0.8198 - val_accuracy: 0.6908\n",
            "Epoch 371/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8187 - accuracy: 0.6699 - val_loss: 0.8218 - val_accuracy: 0.7101\n",
            "Epoch 372/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8023 - accuracy: 0.6820 - val_loss: 0.8399 - val_accuracy: 0.7101\n",
            "Epoch 373/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8094 - accuracy: 0.6850 - val_loss: 0.8173 - val_accuracy: 0.7488\n",
            "Epoch 374/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8198 - accuracy: 0.6632 - val_loss: 0.8138 - val_accuracy: 0.7198\n",
            "Epoch 375/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8235 - accuracy: 0.6723 - val_loss: 0.8239 - val_accuracy: 0.7101\n",
            "Epoch 376/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8209 - accuracy: 0.6717 - val_loss: 0.8266 - val_accuracy: 0.7198\n",
            "Epoch 377/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8143 - accuracy: 0.6765 - val_loss: 0.8207 - val_accuracy: 0.7150\n",
            "Epoch 378/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7752 - accuracy: 0.6965 - val_loss: 0.8064 - val_accuracy: 0.7295\n",
            "Epoch 379/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8106 - accuracy: 0.6765 - val_loss: 0.8111 - val_accuracy: 0.7053\n",
            "Epoch 380/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8085 - accuracy: 0.6808 - val_loss: 0.8113 - val_accuracy: 0.7101\n",
            "Epoch 381/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8114 - accuracy: 0.6796 - val_loss: 0.8121 - val_accuracy: 0.7246\n",
            "Epoch 382/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7867 - accuracy: 0.6886 - val_loss: 0.8179 - val_accuracy: 0.7198\n",
            "Epoch 383/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8127 - accuracy: 0.6705 - val_loss: 0.8299 - val_accuracy: 0.7198\n",
            "Epoch 384/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7891 - accuracy: 0.6947 - val_loss: 0.8096 - val_accuracy: 0.7295\n",
            "Epoch 385/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8202 - accuracy: 0.6729 - val_loss: 0.8120 - val_accuracy: 0.7005\n",
            "Epoch 386/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7817 - accuracy: 0.6892 - val_loss: 0.8052 - val_accuracy: 0.7246\n",
            "Epoch 387/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8177 - accuracy: 0.6602 - val_loss: 0.7949 - val_accuracy: 0.7246\n",
            "Epoch 388/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7807 - accuracy: 0.6892 - val_loss: 0.8069 - val_accuracy: 0.7150\n",
            "Epoch 389/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7909 - accuracy: 0.6965 - val_loss: 0.8054 - val_accuracy: 0.7391\n",
            "Epoch 390/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8156 - accuracy: 0.6771 - val_loss: 0.8009 - val_accuracy: 0.7198\n",
            "Epoch 391/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8057 - accuracy: 0.6711 - val_loss: 0.7923 - val_accuracy: 0.7343\n",
            "Epoch 392/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7909 - accuracy: 0.6747 - val_loss: 0.7912 - val_accuracy: 0.7295\n",
            "Epoch 393/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7969 - accuracy: 0.6796 - val_loss: 0.7976 - val_accuracy: 0.7391\n",
            "Epoch 394/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7802 - accuracy: 0.6977 - val_loss: 0.8321 - val_accuracy: 0.7053\n",
            "Epoch 395/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.7888 - accuracy: 0.6868 - val_loss: 0.7873 - val_accuracy: 0.7391\n",
            "Epoch 396/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7880 - accuracy: 0.6880 - val_loss: 0.8059 - val_accuracy: 0.7391\n",
            "Epoch 397/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7748 - accuracy: 0.6947 - val_loss: 0.8107 - val_accuracy: 0.6908\n",
            "Epoch 398/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7634 - accuracy: 0.6983 - val_loss: 0.7996 - val_accuracy: 0.7391\n",
            "Epoch 399/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7890 - accuracy: 0.6808 - val_loss: 0.7845 - val_accuracy: 0.7295\n",
            "Epoch 400/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7810 - accuracy: 0.6965 - val_loss: 0.7814 - val_accuracy: 0.7391\n",
            "Epoch 401/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7791 - accuracy: 0.6874 - val_loss: 0.7784 - val_accuracy: 0.7585\n",
            "Epoch 402/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.7700 - accuracy: 0.6850 - val_loss: 0.7875 - val_accuracy: 0.7101\n",
            "Epoch 403/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7911 - accuracy: 0.6868 - val_loss: 0.7815 - val_accuracy: 0.7536\n",
            "Epoch 404/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.7711 - accuracy: 0.6917 - val_loss: 0.7813 - val_accuracy: 0.7198\n",
            "Epoch 405/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7924 - accuracy: 0.6959 - val_loss: 0.7997 - val_accuracy: 0.7150\n",
            "Epoch 406/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7460 - accuracy: 0.7044 - val_loss: 0.8244 - val_accuracy: 0.7005\n",
            "Epoch 407/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7643 - accuracy: 0.6862 - val_loss: 0.7830 - val_accuracy: 0.7391\n",
            "Epoch 408/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7780 - accuracy: 0.6856 - val_loss: 0.7894 - val_accuracy: 0.7343\n",
            "Epoch 409/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7455 - accuracy: 0.7074 - val_loss: 0.7869 - val_accuracy: 0.7246\n",
            "Epoch 410/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7511 - accuracy: 0.7007 - val_loss: 0.7885 - val_accuracy: 0.7343\n",
            "Epoch 411/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.7573 - accuracy: 0.7001 - val_loss: 0.7840 - val_accuracy: 0.7440\n",
            "Epoch 412/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7655 - accuracy: 0.6935 - val_loss: 0.7893 - val_accuracy: 0.7391\n",
            "Epoch 413/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7850 - accuracy: 0.6886 - val_loss: 0.7890 - val_accuracy: 0.7053\n",
            "Epoch 414/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7534 - accuracy: 0.6983 - val_loss: 0.7825 - val_accuracy: 0.7295\n",
            "Epoch 415/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7704 - accuracy: 0.6904 - val_loss: 0.7850 - val_accuracy: 0.7246\n",
            "Epoch 416/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.7773 - accuracy: 0.6959 - val_loss: 0.7966 - val_accuracy: 0.7295\n",
            "Epoch 417/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7647 - accuracy: 0.6935 - val_loss: 0.7797 - val_accuracy: 0.7488\n",
            "Epoch 418/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7516 - accuracy: 0.7074 - val_loss: 0.7800 - val_accuracy: 0.7440\n",
            "Epoch 419/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7622 - accuracy: 0.7007 - val_loss: 0.7805 - val_accuracy: 0.7198\n",
            "Epoch 420/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7610 - accuracy: 0.7031 - val_loss: 0.7667 - val_accuracy: 0.7440\n",
            "Epoch 421/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7692 - accuracy: 0.6923 - val_loss: 0.7858 - val_accuracy: 0.7246\n",
            "Epoch 422/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7569 - accuracy: 0.7019 - val_loss: 0.7757 - val_accuracy: 0.7150\n",
            "Epoch 423/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7445 - accuracy: 0.6983 - val_loss: 0.7807 - val_accuracy: 0.7391\n",
            "Epoch 424/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7472 - accuracy: 0.7080 - val_loss: 0.7932 - val_accuracy: 0.7198\n",
            "Epoch 425/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7660 - accuracy: 0.6947 - val_loss: 0.7713 - val_accuracy: 0.7295\n",
            "Epoch 426/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7637 - accuracy: 0.7128 - val_loss: 0.7790 - val_accuracy: 0.7391\n",
            "Epoch 427/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7685 - accuracy: 0.7001 - val_loss: 0.7991 - val_accuracy: 0.7053\n",
            "Epoch 428/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7567 - accuracy: 0.6989 - val_loss: 0.7915 - val_accuracy: 0.7053\n",
            "Epoch 429/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.7482 - accuracy: 0.6892 - val_loss: 0.7753 - val_accuracy: 0.7488\n",
            "Epoch 430/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7452 - accuracy: 0.7062 - val_loss: 0.7836 - val_accuracy: 0.7440\n",
            "Epoch 431/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7457 - accuracy: 0.7134 - val_loss: 0.7716 - val_accuracy: 0.7295\n",
            "Epoch 432/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7586 - accuracy: 0.7037 - val_loss: 0.7755 - val_accuracy: 0.7343\n",
            "Epoch 433/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7291 - accuracy: 0.7189 - val_loss: 0.7687 - val_accuracy: 0.7343\n",
            "Epoch 434/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7720 - accuracy: 0.6953 - val_loss: 0.7667 - val_accuracy: 0.7440\n",
            "Epoch 435/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7445 - accuracy: 0.7031 - val_loss: 0.7867 - val_accuracy: 0.7391\n",
            "Epoch 436/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7559 - accuracy: 0.7128 - val_loss: 0.7671 - val_accuracy: 0.7246\n",
            "Epoch 437/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7336 - accuracy: 0.7146 - val_loss: 0.7740 - val_accuracy: 0.7391\n",
            "Epoch 438/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7337 - accuracy: 0.7037 - val_loss: 0.7671 - val_accuracy: 0.7343\n",
            "Epoch 439/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7318 - accuracy: 0.6983 - val_loss: 0.7834 - val_accuracy: 0.7440\n",
            "Epoch 440/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.7430 - accuracy: 0.7110 - val_loss: 0.7681 - val_accuracy: 0.7585\n",
            "Epoch 441/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7451 - accuracy: 0.6953 - val_loss: 0.7835 - val_accuracy: 0.7343\n",
            "Epoch 442/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7426 - accuracy: 0.7128 - val_loss: 0.7856 - val_accuracy: 0.7440\n",
            "Epoch 443/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.7457 - accuracy: 0.7050 - val_loss: 0.7827 - val_accuracy: 0.7391\n",
            "Epoch 444/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7373 - accuracy: 0.7050 - val_loss: 0.7715 - val_accuracy: 0.7585\n",
            "Epoch 445/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7179 - accuracy: 0.7134 - val_loss: 0.7770 - val_accuracy: 0.7440\n",
            "Epoch 446/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7494 - accuracy: 0.6977 - val_loss: 0.7727 - val_accuracy: 0.7391\n",
            "Epoch 447/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7125 - accuracy: 0.7195 - val_loss: 0.7972 - val_accuracy: 0.7198\n",
            "Epoch 448/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7330 - accuracy: 0.7074 - val_loss: 0.7913 - val_accuracy: 0.7101\n",
            "Epoch 449/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.7432 - accuracy: 0.7050 - val_loss: 0.7707 - val_accuracy: 0.7536\n",
            "Epoch 450/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7241 - accuracy: 0.7177 - val_loss: 0.7682 - val_accuracy: 0.7440\n",
            "Epoch 451/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7460 - accuracy: 0.7007 - val_loss: 0.7835 - val_accuracy: 0.7246\n",
            "Epoch 452/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7565 - accuracy: 0.7007 - val_loss: 0.7755 - val_accuracy: 0.7246\n",
            "Epoch 453/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7219 - accuracy: 0.7170 - val_loss: 0.7687 - val_accuracy: 0.7343\n",
            "Epoch 454/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7300 - accuracy: 0.7195 - val_loss: 0.7715 - val_accuracy: 0.7295\n",
            "Epoch 455/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7287 - accuracy: 0.7001 - val_loss: 0.7725 - val_accuracy: 0.7536\n",
            "Epoch 456/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7397 - accuracy: 0.7122 - val_loss: 0.7764 - val_accuracy: 0.7150\n",
            "Epoch 457/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7318 - accuracy: 0.7128 - val_loss: 0.7656 - val_accuracy: 0.7246\n",
            "Epoch 458/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7314 - accuracy: 0.7122 - val_loss: 0.7699 - val_accuracy: 0.7053\n",
            "Epoch 459/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7164 - accuracy: 0.7134 - val_loss: 0.7508 - val_accuracy: 0.7585\n",
            "Epoch 460/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6959 - accuracy: 0.7273 - val_loss: 0.7760 - val_accuracy: 0.7391\n",
            "Epoch 461/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.7231 - accuracy: 0.7074 - val_loss: 0.7555 - val_accuracy: 0.7585\n",
            "Epoch 462/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7346 - accuracy: 0.7122 - val_loss: 0.7777 - val_accuracy: 0.7440\n",
            "Epoch 463/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7332 - accuracy: 0.7098 - val_loss: 0.7502 - val_accuracy: 0.7488\n",
            "Epoch 464/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.7114 - accuracy: 0.7255 - val_loss: 0.7497 - val_accuracy: 0.7488\n",
            "Epoch 465/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.7322 - accuracy: 0.7068 - val_loss: 0.7471 - val_accuracy: 0.7440\n",
            "Epoch 466/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.7228 - accuracy: 0.7291 - val_loss: 0.7396 - val_accuracy: 0.7536\n",
            "Epoch 467/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7229 - accuracy: 0.7086 - val_loss: 0.7618 - val_accuracy: 0.7488\n",
            "Epoch 468/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.7025 - accuracy: 0.7237 - val_loss: 0.7539 - val_accuracy: 0.7391\n",
            "Epoch 469/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7179 - accuracy: 0.7249 - val_loss: 0.7658 - val_accuracy: 0.7440\n",
            "Epoch 470/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.7177 - accuracy: 0.7134 - val_loss: 0.7425 - val_accuracy: 0.7391\n",
            "Epoch 471/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6938 - accuracy: 0.7231 - val_loss: 0.7646 - val_accuracy: 0.7295\n",
            "Epoch 472/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7340 - accuracy: 0.7080 - val_loss: 0.7557 - val_accuracy: 0.7585\n",
            "Epoch 473/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.7130 - accuracy: 0.7116 - val_loss: 0.7503 - val_accuracy: 0.7440\n",
            "Epoch 474/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7085 - accuracy: 0.7134 - val_loss: 0.7450 - val_accuracy: 0.7391\n",
            "Epoch 475/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7222 - accuracy: 0.7116 - val_loss: 0.7542 - val_accuracy: 0.7536\n",
            "Epoch 476/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.7099 - accuracy: 0.7152 - val_loss: 0.7465 - val_accuracy: 0.7440\n",
            "Epoch 477/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.7039 - accuracy: 0.7279 - val_loss: 0.7548 - val_accuracy: 0.7440\n",
            "Epoch 478/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7020 - accuracy: 0.7267 - val_loss: 0.7417 - val_accuracy: 0.7488\n",
            "Epoch 479/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7136 - accuracy: 0.7255 - val_loss: 0.7448 - val_accuracy: 0.7440\n",
            "Epoch 480/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6850 - accuracy: 0.7382 - val_loss: 0.7433 - val_accuracy: 0.7681\n",
            "Epoch 481/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6888 - accuracy: 0.7400 - val_loss: 0.7669 - val_accuracy: 0.7536\n",
            "Epoch 482/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6976 - accuracy: 0.7346 - val_loss: 0.7361 - val_accuracy: 0.7729\n",
            "Epoch 483/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.7012 - accuracy: 0.7225 - val_loss: 0.7303 - val_accuracy: 0.7633\n",
            "Epoch 484/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6916 - accuracy: 0.7189 - val_loss: 0.7334 - val_accuracy: 0.7488\n",
            "Epoch 485/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7137 - accuracy: 0.7158 - val_loss: 0.7529 - val_accuracy: 0.7343\n",
            "Epoch 486/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6815 - accuracy: 0.7358 - val_loss: 0.7418 - val_accuracy: 0.7391\n",
            "Epoch 487/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6930 - accuracy: 0.7134 - val_loss: 0.7473 - val_accuracy: 0.7488\n",
            "Epoch 488/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7220 - accuracy: 0.7201 - val_loss: 0.7519 - val_accuracy: 0.7391\n",
            "Epoch 489/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.7011 - accuracy: 0.7195 - val_loss: 0.7567 - val_accuracy: 0.7246\n",
            "Epoch 490/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6740 - accuracy: 0.7430 - val_loss: 0.7403 - val_accuracy: 0.7440\n",
            "Epoch 491/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6942 - accuracy: 0.7249 - val_loss: 0.7296 - val_accuracy: 0.7440\n",
            "Epoch 492/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6932 - accuracy: 0.7092 - val_loss: 0.7397 - val_accuracy: 0.7585\n",
            "Epoch 493/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6886 - accuracy: 0.7267 - val_loss: 0.7486 - val_accuracy: 0.7488\n",
            "Epoch 494/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7033 - accuracy: 0.7110 - val_loss: 0.7347 - val_accuracy: 0.7488\n",
            "Epoch 495/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.7065 - accuracy: 0.7231 - val_loss: 0.7344 - val_accuracy: 0.7488\n",
            "Epoch 496/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6846 - accuracy: 0.7249 - val_loss: 0.7210 - val_accuracy: 0.7536\n",
            "Epoch 497/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6841 - accuracy: 0.7243 - val_loss: 0.7228 - val_accuracy: 0.7585\n",
            "Epoch 498/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6831 - accuracy: 0.7412 - val_loss: 0.7158 - val_accuracy: 0.7585\n",
            "Epoch 499/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6878 - accuracy: 0.7201 - val_loss: 0.7412 - val_accuracy: 0.7488\n",
            "Epoch 500/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6901 - accuracy: 0.7304 - val_loss: 0.7390 - val_accuracy: 0.7150\n",
            "Epoch 501/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6958 - accuracy: 0.7044 - val_loss: 0.7352 - val_accuracy: 0.7488\n",
            "Epoch 502/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.7164 - accuracy: 0.7285 - val_loss: 0.7256 - val_accuracy: 0.7585\n",
            "Epoch 503/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6658 - accuracy: 0.7273 - val_loss: 0.7217 - val_accuracy: 0.7343\n",
            "Epoch 504/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6929 - accuracy: 0.7255 - val_loss: 0.7204 - val_accuracy: 0.7585\n",
            "Epoch 505/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6819 - accuracy: 0.7291 - val_loss: 0.7479 - val_accuracy: 0.7488\n",
            "Epoch 506/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6625 - accuracy: 0.7418 - val_loss: 0.7318 - val_accuracy: 0.7681\n",
            "Epoch 507/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6746 - accuracy: 0.7364 - val_loss: 0.7362 - val_accuracy: 0.7633\n",
            "Epoch 508/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6880 - accuracy: 0.7358 - val_loss: 0.7300 - val_accuracy: 0.7729\n",
            "Epoch 509/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6502 - accuracy: 0.7606 - val_loss: 0.7206 - val_accuracy: 0.7440\n",
            "Epoch 510/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6852 - accuracy: 0.7346 - val_loss: 0.7226 - val_accuracy: 0.7633\n",
            "Epoch 511/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6933 - accuracy: 0.7116 - val_loss: 0.7176 - val_accuracy: 0.7826\n",
            "Epoch 512/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6941 - accuracy: 0.7116 - val_loss: 0.7378 - val_accuracy: 0.7536\n",
            "Epoch 513/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6809 - accuracy: 0.7334 - val_loss: 0.7192 - val_accuracy: 0.7585\n",
            "Epoch 514/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6726 - accuracy: 0.7376 - val_loss: 0.7189 - val_accuracy: 0.7585\n",
            "Epoch 515/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6626 - accuracy: 0.7418 - val_loss: 0.7174 - val_accuracy: 0.7391\n",
            "Epoch 516/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6558 - accuracy: 0.7430 - val_loss: 0.7250 - val_accuracy: 0.7633\n",
            "Epoch 517/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6585 - accuracy: 0.7449 - val_loss: 0.7313 - val_accuracy: 0.7536\n",
            "Epoch 518/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6682 - accuracy: 0.7412 - val_loss: 0.7089 - val_accuracy: 0.7826\n",
            "Epoch 519/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6720 - accuracy: 0.7364 - val_loss: 0.7191 - val_accuracy: 0.7633\n",
            "Epoch 520/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6725 - accuracy: 0.7437 - val_loss: 0.7230 - val_accuracy: 0.7778\n",
            "Epoch 521/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6811 - accuracy: 0.7255 - val_loss: 0.7181 - val_accuracy: 0.7874\n",
            "Epoch 522/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6875 - accuracy: 0.7297 - val_loss: 0.7150 - val_accuracy: 0.7778\n",
            "Epoch 523/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6620 - accuracy: 0.7491 - val_loss: 0.7334 - val_accuracy: 0.7778\n",
            "Epoch 524/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6646 - accuracy: 0.7394 - val_loss: 0.7349 - val_accuracy: 0.7826\n",
            "Epoch 525/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6702 - accuracy: 0.7370 - val_loss: 0.7221 - val_accuracy: 0.7729\n",
            "Epoch 526/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6756 - accuracy: 0.7267 - val_loss: 0.7218 - val_accuracy: 0.7633\n",
            "Epoch 527/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6702 - accuracy: 0.7394 - val_loss: 0.7202 - val_accuracy: 0.7440\n",
            "Epoch 528/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6603 - accuracy: 0.7322 - val_loss: 0.7111 - val_accuracy: 0.7729\n",
            "Epoch 529/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6791 - accuracy: 0.7352 - val_loss: 0.7193 - val_accuracy: 0.7585\n",
            "Epoch 530/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6534 - accuracy: 0.7304 - val_loss: 0.7249 - val_accuracy: 0.7681\n",
            "Epoch 531/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6669 - accuracy: 0.7455 - val_loss: 0.7417 - val_accuracy: 0.7198\n",
            "Epoch 532/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6517 - accuracy: 0.7461 - val_loss: 0.7259 - val_accuracy: 0.7440\n",
            "Epoch 533/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6635 - accuracy: 0.7328 - val_loss: 0.7163 - val_accuracy: 0.7633\n",
            "Epoch 534/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6604 - accuracy: 0.7400 - val_loss: 0.7219 - val_accuracy: 0.7536\n",
            "Epoch 535/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6384 - accuracy: 0.7479 - val_loss: 0.7162 - val_accuracy: 0.7488\n",
            "Epoch 536/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6613 - accuracy: 0.7352 - val_loss: 0.7107 - val_accuracy: 0.7391\n",
            "Epoch 537/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6636 - accuracy: 0.7412 - val_loss: 0.7115 - val_accuracy: 0.7585\n",
            "Epoch 538/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6373 - accuracy: 0.7473 - val_loss: 0.7149 - val_accuracy: 0.7246\n",
            "Epoch 539/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6484 - accuracy: 0.7424 - val_loss: 0.7190 - val_accuracy: 0.7585\n",
            "Epoch 540/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6447 - accuracy: 0.7473 - val_loss: 0.7021 - val_accuracy: 0.7536\n",
            "Epoch 541/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6749 - accuracy: 0.7304 - val_loss: 0.7039 - val_accuracy: 0.7585\n",
            "Epoch 542/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6232 - accuracy: 0.7570 - val_loss: 0.7041 - val_accuracy: 0.7536\n",
            "Epoch 543/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6397 - accuracy: 0.7467 - val_loss: 0.7173 - val_accuracy: 0.7585\n",
            "Epoch 544/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6760 - accuracy: 0.7388 - val_loss: 0.7002 - val_accuracy: 0.7633\n",
            "Epoch 545/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6417 - accuracy: 0.7485 - val_loss: 0.7127 - val_accuracy: 0.7826\n",
            "Epoch 546/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6209 - accuracy: 0.7606 - val_loss: 0.6920 - val_accuracy: 0.7826\n",
            "Epoch 547/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6343 - accuracy: 0.7406 - val_loss: 0.6850 - val_accuracy: 0.7295\n",
            "Epoch 548/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6528 - accuracy: 0.7424 - val_loss: 0.7048 - val_accuracy: 0.7729\n",
            "Epoch 549/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6347 - accuracy: 0.7479 - val_loss: 0.7018 - val_accuracy: 0.7729\n",
            "Epoch 550/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6309 - accuracy: 0.7533 - val_loss: 0.7115 - val_accuracy: 0.7633\n",
            "Epoch 551/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6453 - accuracy: 0.7437 - val_loss: 0.7164 - val_accuracy: 0.7681\n",
            "Epoch 552/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6330 - accuracy: 0.7551 - val_loss: 0.7191 - val_accuracy: 0.7778\n",
            "Epoch 553/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6301 - accuracy: 0.7479 - val_loss: 0.7128 - val_accuracy: 0.7681\n",
            "Epoch 554/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6414 - accuracy: 0.7570 - val_loss: 0.7038 - val_accuracy: 0.7585\n",
            "Epoch 555/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6482 - accuracy: 0.7449 - val_loss: 0.7194 - val_accuracy: 0.7778\n",
            "Epoch 556/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6283 - accuracy: 0.7491 - val_loss: 0.7035 - val_accuracy: 0.7536\n",
            "Epoch 557/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6200 - accuracy: 0.7636 - val_loss: 0.7082 - val_accuracy: 0.7729\n",
            "Epoch 558/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6523 - accuracy: 0.7424 - val_loss: 0.7130 - val_accuracy: 0.7488\n",
            "Epoch 559/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6302 - accuracy: 0.7473 - val_loss: 0.7117 - val_accuracy: 0.7633\n",
            "Epoch 560/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6513 - accuracy: 0.7382 - val_loss: 0.7062 - val_accuracy: 0.7778\n",
            "Epoch 561/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6148 - accuracy: 0.7612 - val_loss: 0.7249 - val_accuracy: 0.7536\n",
            "Epoch 562/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6136 - accuracy: 0.7594 - val_loss: 0.7104 - val_accuracy: 0.7536\n",
            "Epoch 563/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6438 - accuracy: 0.7418 - val_loss: 0.7306 - val_accuracy: 0.7343\n",
            "Epoch 564/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6384 - accuracy: 0.7400 - val_loss: 0.7261 - val_accuracy: 0.7488\n",
            "Epoch 565/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6253 - accuracy: 0.7412 - val_loss: 0.6978 - val_accuracy: 0.7633\n",
            "Epoch 566/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6186 - accuracy: 0.7570 - val_loss: 0.6886 - val_accuracy: 0.7440\n",
            "Epoch 567/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6015 - accuracy: 0.7642 - val_loss: 0.6947 - val_accuracy: 0.7681\n",
            "Epoch 568/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6160 - accuracy: 0.7600 - val_loss: 0.6970 - val_accuracy: 0.7633\n",
            "Epoch 569/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6255 - accuracy: 0.7600 - val_loss: 0.6939 - val_accuracy: 0.7536\n",
            "Epoch 570/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6341 - accuracy: 0.7582 - val_loss: 0.6732 - val_accuracy: 0.7681\n",
            "Epoch 571/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6223 - accuracy: 0.7533 - val_loss: 0.6970 - val_accuracy: 0.7585\n",
            "Epoch 572/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6343 - accuracy: 0.7594 - val_loss: 0.6987 - val_accuracy: 0.7391\n",
            "Epoch 573/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6020 - accuracy: 0.7612 - val_loss: 0.6794 - val_accuracy: 0.7585\n",
            "Epoch 574/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6170 - accuracy: 0.7521 - val_loss: 0.6967 - val_accuracy: 0.7585\n",
            "Epoch 575/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6230 - accuracy: 0.7509 - val_loss: 0.6932 - val_accuracy: 0.7729\n",
            "Epoch 576/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6378 - accuracy: 0.7461 - val_loss: 0.7014 - val_accuracy: 0.7585\n",
            "Epoch 577/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6143 - accuracy: 0.7594 - val_loss: 0.7103 - val_accuracy: 0.7440\n",
            "Epoch 578/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6191 - accuracy: 0.7515 - val_loss: 0.6997 - val_accuracy: 0.7585\n",
            "Epoch 579/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6093 - accuracy: 0.7479 - val_loss: 0.7027 - val_accuracy: 0.7778\n",
            "Epoch 580/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6295 - accuracy: 0.7473 - val_loss: 0.6909 - val_accuracy: 0.7585\n",
            "Epoch 581/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6080 - accuracy: 0.7630 - val_loss: 0.7061 - val_accuracy: 0.7391\n",
            "Epoch 582/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6185 - accuracy: 0.7473 - val_loss: 0.7095 - val_accuracy: 0.7536\n",
            "Epoch 583/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6105 - accuracy: 0.7557 - val_loss: 0.7325 - val_accuracy: 0.7343\n",
            "Epoch 584/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6095 - accuracy: 0.7648 - val_loss: 0.6925 - val_accuracy: 0.7681\n",
            "Epoch 585/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6190 - accuracy: 0.7600 - val_loss: 0.7020 - val_accuracy: 0.7440\n",
            "Epoch 586/1000\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.6201 - accuracy: 0.7582 - val_loss: 0.7006 - val_accuracy: 0.7681\n",
            "Epoch 587/1000\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.6077 - accuracy: 0.7606 - val_loss: 0.7107 - val_accuracy: 0.7391\n",
            "Epoch 588/1000\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.6155 - accuracy: 0.7612 - val_loss: 0.6893 - val_accuracy: 0.7585\n",
            "Epoch 589/1000\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.6076 - accuracy: 0.7690 - val_loss: 0.6907 - val_accuracy: 0.7826\n",
            "Epoch 590/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5802 - accuracy: 0.7684 - val_loss: 0.6979 - val_accuracy: 0.7585\n",
            "Epoch 591/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6096 - accuracy: 0.7497 - val_loss: 0.6863 - val_accuracy: 0.7585\n",
            "Epoch 592/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6149 - accuracy: 0.7648 - val_loss: 0.6872 - val_accuracy: 0.7536\n",
            "Epoch 593/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6017 - accuracy: 0.7642 - val_loss: 0.6785 - val_accuracy: 0.7729\n",
            "Epoch 594/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5904 - accuracy: 0.7709 - val_loss: 0.6845 - val_accuracy: 0.7585\n",
            "Epoch 595/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6295 - accuracy: 0.7497 - val_loss: 0.6787 - val_accuracy: 0.7585\n",
            "Epoch 596/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5926 - accuracy: 0.7836 - val_loss: 0.6839 - val_accuracy: 0.7826\n",
            "Epoch 597/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6032 - accuracy: 0.7660 - val_loss: 0.6719 - val_accuracy: 0.7826\n",
            "Epoch 598/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6104 - accuracy: 0.7696 - val_loss: 0.6753 - val_accuracy: 0.7633\n",
            "Epoch 599/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6050 - accuracy: 0.7684 - val_loss: 0.6797 - val_accuracy: 0.7681\n",
            "Epoch 600/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5968 - accuracy: 0.7678 - val_loss: 0.6912 - val_accuracy: 0.7874\n",
            "Epoch 601/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6056 - accuracy: 0.7539 - val_loss: 0.6673 - val_accuracy: 0.7536\n",
            "Epoch 602/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5919 - accuracy: 0.7745 - val_loss: 0.6903 - val_accuracy: 0.7633\n",
            "Epoch 603/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6021 - accuracy: 0.7618 - val_loss: 0.6876 - val_accuracy: 0.7488\n",
            "Epoch 604/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5772 - accuracy: 0.7763 - val_loss: 0.6942 - val_accuracy: 0.7778\n",
            "Epoch 605/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5929 - accuracy: 0.7703 - val_loss: 0.6802 - val_accuracy: 0.7971\n",
            "Epoch 606/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5914 - accuracy: 0.7624 - val_loss: 0.6666 - val_accuracy: 0.7729\n",
            "Epoch 607/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5942 - accuracy: 0.7769 - val_loss: 0.6767 - val_accuracy: 0.7536\n",
            "Epoch 608/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5850 - accuracy: 0.7672 - val_loss: 0.6650 - val_accuracy: 0.7971\n",
            "Epoch 609/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5997 - accuracy: 0.7696 - val_loss: 0.6760 - val_accuracy: 0.7778\n",
            "Epoch 610/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5903 - accuracy: 0.7612 - val_loss: 0.6729 - val_accuracy: 0.7778\n",
            "Epoch 611/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5838 - accuracy: 0.7769 - val_loss: 0.6888 - val_accuracy: 0.7488\n",
            "Epoch 612/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5718 - accuracy: 0.7830 - val_loss: 0.6744 - val_accuracy: 0.8019\n",
            "Epoch 613/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5738 - accuracy: 0.7775 - val_loss: 0.6730 - val_accuracy: 0.7778\n",
            "Epoch 614/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5961 - accuracy: 0.7739 - val_loss: 0.6802 - val_accuracy: 0.7874\n",
            "Epoch 615/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5792 - accuracy: 0.7715 - val_loss: 0.6968 - val_accuracy: 0.7778\n",
            "Epoch 616/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5914 - accuracy: 0.7703 - val_loss: 0.6873 - val_accuracy: 0.7826\n",
            "Epoch 617/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5861 - accuracy: 0.7642 - val_loss: 0.6857 - val_accuracy: 0.7826\n",
            "Epoch 618/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5824 - accuracy: 0.7787 - val_loss: 0.6742 - val_accuracy: 0.7874\n",
            "Epoch 619/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6061 - accuracy: 0.7690 - val_loss: 0.6760 - val_accuracy: 0.7826\n",
            "Epoch 620/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5855 - accuracy: 0.7672 - val_loss: 0.6720 - val_accuracy: 0.7729\n",
            "Epoch 621/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5719 - accuracy: 0.7751 - val_loss: 0.6791 - val_accuracy: 0.7729\n",
            "Epoch 622/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5767 - accuracy: 0.7733 - val_loss: 0.6845 - val_accuracy: 0.7681\n",
            "Epoch 623/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5764 - accuracy: 0.7739 - val_loss: 0.6935 - val_accuracy: 0.7826\n",
            "Epoch 624/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5803 - accuracy: 0.7763 - val_loss: 0.6771 - val_accuracy: 0.7874\n",
            "Epoch 625/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5842 - accuracy: 0.7703 - val_loss: 0.6697 - val_accuracy: 0.7826\n",
            "Epoch 626/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5946 - accuracy: 0.7842 - val_loss: 0.6727 - val_accuracy: 0.7778\n",
            "Epoch 627/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5637 - accuracy: 0.7811 - val_loss: 0.6749 - val_accuracy: 0.7633\n",
            "Epoch 628/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5573 - accuracy: 0.7848 - val_loss: 0.6811 - val_accuracy: 0.7729\n",
            "Epoch 629/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5935 - accuracy: 0.7648 - val_loss: 0.6731 - val_accuracy: 0.7826\n",
            "Epoch 630/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5808 - accuracy: 0.7703 - val_loss: 0.6736 - val_accuracy: 0.7778\n",
            "Epoch 631/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5798 - accuracy: 0.7715 - val_loss: 0.6679 - val_accuracy: 0.7778\n",
            "Epoch 632/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5796 - accuracy: 0.7787 - val_loss: 0.6606 - val_accuracy: 0.7826\n",
            "Epoch 633/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5805 - accuracy: 0.7836 - val_loss: 0.6873 - val_accuracy: 0.7585\n",
            "Epoch 634/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5778 - accuracy: 0.7696 - val_loss: 0.6821 - val_accuracy: 0.7536\n",
            "Epoch 635/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5669 - accuracy: 0.7684 - val_loss: 0.6637 - val_accuracy: 0.7923\n",
            "Epoch 636/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5606 - accuracy: 0.7830 - val_loss: 0.6680 - val_accuracy: 0.7923\n",
            "Epoch 637/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5712 - accuracy: 0.7811 - val_loss: 0.6716 - val_accuracy: 0.7874\n",
            "Epoch 638/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5629 - accuracy: 0.7733 - val_loss: 0.6584 - val_accuracy: 0.7826\n",
            "Epoch 639/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5649 - accuracy: 0.7823 - val_loss: 0.6630 - val_accuracy: 0.7923\n",
            "Epoch 640/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5748 - accuracy: 0.7733 - val_loss: 0.6808 - val_accuracy: 0.7874\n",
            "Epoch 641/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5594 - accuracy: 0.7902 - val_loss: 0.6646 - val_accuracy: 0.7778\n",
            "Epoch 642/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5701 - accuracy: 0.7805 - val_loss: 0.6607 - val_accuracy: 0.7826\n",
            "Epoch 643/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5768 - accuracy: 0.7739 - val_loss: 0.6797 - val_accuracy: 0.7633\n",
            "Epoch 644/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5678 - accuracy: 0.7709 - val_loss: 0.6595 - val_accuracy: 0.7874\n",
            "Epoch 645/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5896 - accuracy: 0.7684 - val_loss: 0.6626 - val_accuracy: 0.7681\n",
            "Epoch 646/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5584 - accuracy: 0.7775 - val_loss: 0.6657 - val_accuracy: 0.7923\n",
            "Epoch 647/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5800 - accuracy: 0.7757 - val_loss: 0.6601 - val_accuracy: 0.7923\n",
            "Epoch 648/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5533 - accuracy: 0.7805 - val_loss: 0.6579 - val_accuracy: 0.7874\n",
            "Epoch 649/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5651 - accuracy: 0.7854 - val_loss: 0.6523 - val_accuracy: 0.7874\n",
            "Epoch 650/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5750 - accuracy: 0.7817 - val_loss: 0.6503 - val_accuracy: 0.7874\n",
            "Epoch 651/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5596 - accuracy: 0.7830 - val_loss: 0.6605 - val_accuracy: 0.7633\n",
            "Epoch 652/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5403 - accuracy: 0.7926 - val_loss: 0.6679 - val_accuracy: 0.7778\n",
            "Epoch 653/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5653 - accuracy: 0.7811 - val_loss: 0.6654 - val_accuracy: 0.7923\n",
            "Epoch 654/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5526 - accuracy: 0.7878 - val_loss: 0.6790 - val_accuracy: 0.7729\n",
            "Epoch 655/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5608 - accuracy: 0.7836 - val_loss: 0.6832 - val_accuracy: 0.7778\n",
            "Epoch 656/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5216 - accuracy: 0.7878 - val_loss: 0.6555 - val_accuracy: 0.7729\n",
            "Epoch 657/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5558 - accuracy: 0.7805 - val_loss: 0.6824 - val_accuracy: 0.7585\n",
            "Epoch 658/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5470 - accuracy: 0.7866 - val_loss: 0.6618 - val_accuracy: 0.7778\n",
            "Epoch 659/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5473 - accuracy: 0.7890 - val_loss: 0.6598 - val_accuracy: 0.7826\n",
            "Epoch 660/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5474 - accuracy: 0.7817 - val_loss: 0.6647 - val_accuracy: 0.7923\n",
            "Epoch 661/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5578 - accuracy: 0.7793 - val_loss: 0.6685 - val_accuracy: 0.7633\n",
            "Epoch 662/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5611 - accuracy: 0.7793 - val_loss: 0.6852 - val_accuracy: 0.7729\n",
            "Epoch 663/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5623 - accuracy: 0.7848 - val_loss: 0.6697 - val_accuracy: 0.7971\n",
            "Epoch 664/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5540 - accuracy: 0.7908 - val_loss: 0.6622 - val_accuracy: 0.7923\n",
            "Epoch 665/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5338 - accuracy: 0.7842 - val_loss: 0.6918 - val_accuracy: 0.7585\n",
            "Epoch 666/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5254 - accuracy: 0.7908 - val_loss: 0.6529 - val_accuracy: 0.7874\n",
            "Epoch 667/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5391 - accuracy: 0.7872 - val_loss: 0.6798 - val_accuracy: 0.7729\n",
            "Epoch 668/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5529 - accuracy: 0.7787 - val_loss: 0.6593 - val_accuracy: 0.7826\n",
            "Epoch 669/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5671 - accuracy: 0.7793 - val_loss: 0.6669 - val_accuracy: 0.7778\n",
            "Epoch 670/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5407 - accuracy: 0.7866 - val_loss: 0.6671 - val_accuracy: 0.7874\n",
            "Epoch 671/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5513 - accuracy: 0.7878 - val_loss: 0.6622 - val_accuracy: 0.7681\n",
            "Epoch 672/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5430 - accuracy: 0.7805 - val_loss: 0.6659 - val_accuracy: 0.7971\n",
            "Epoch 673/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5307 - accuracy: 0.7872 - val_loss: 0.6717 - val_accuracy: 0.7681\n",
            "Epoch 674/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5337 - accuracy: 0.7944 - val_loss: 0.6653 - val_accuracy: 0.7971\n",
            "Epoch 675/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5682 - accuracy: 0.7787 - val_loss: 0.6568 - val_accuracy: 0.7729\n",
            "Epoch 676/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5264 - accuracy: 0.7932 - val_loss: 0.6662 - val_accuracy: 0.7729\n",
            "Epoch 677/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5350 - accuracy: 0.7950 - val_loss: 0.6589 - val_accuracy: 0.7778\n",
            "Epoch 678/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5286 - accuracy: 0.7963 - val_loss: 0.6771 - val_accuracy: 0.7585\n",
            "Epoch 679/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5617 - accuracy: 0.7823 - val_loss: 0.6644 - val_accuracy: 0.7778\n",
            "Epoch 680/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5333 - accuracy: 0.7872 - val_loss: 0.6716 - val_accuracy: 0.7923\n",
            "Epoch 681/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5279 - accuracy: 0.7993 - val_loss: 0.6714 - val_accuracy: 0.7923\n",
            "Epoch 682/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5208 - accuracy: 0.7969 - val_loss: 0.7090 - val_accuracy: 0.7633\n",
            "Epoch 683/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5372 - accuracy: 0.7878 - val_loss: 0.6713 - val_accuracy: 0.7874\n",
            "Epoch 684/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5482 - accuracy: 0.7890 - val_loss: 0.6785 - val_accuracy: 0.7778\n",
            "Epoch 685/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5285 - accuracy: 0.7956 - val_loss: 0.6516 - val_accuracy: 0.7681\n",
            "Epoch 686/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5456 - accuracy: 0.7999 - val_loss: 0.6461 - val_accuracy: 0.7971\n",
            "Epoch 687/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5329 - accuracy: 0.7890 - val_loss: 0.6416 - val_accuracy: 0.7874\n",
            "Epoch 688/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5163 - accuracy: 0.7914 - val_loss: 0.6530 - val_accuracy: 0.7778\n",
            "Epoch 689/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5388 - accuracy: 0.7981 - val_loss: 0.6544 - val_accuracy: 0.7923\n",
            "Epoch 690/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5609 - accuracy: 0.7830 - val_loss: 0.6653 - val_accuracy: 0.7923\n",
            "Epoch 691/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5293 - accuracy: 0.7896 - val_loss: 0.6623 - val_accuracy: 0.7923\n",
            "Epoch 692/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5393 - accuracy: 0.7920 - val_loss: 0.6605 - val_accuracy: 0.7826\n",
            "Epoch 693/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5013 - accuracy: 0.8053 - val_loss: 0.6541 - val_accuracy: 0.7874\n",
            "Epoch 694/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5311 - accuracy: 0.7981 - val_loss: 0.6566 - val_accuracy: 0.7778\n",
            "Epoch 695/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5402 - accuracy: 0.7848 - val_loss: 0.6510 - val_accuracy: 0.7778\n",
            "Epoch 696/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5202 - accuracy: 0.7975 - val_loss: 0.6561 - val_accuracy: 0.7826\n",
            "Epoch 697/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5045 - accuracy: 0.8120 - val_loss: 0.6677 - val_accuracy: 0.7633\n",
            "Epoch 698/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5165 - accuracy: 0.8029 - val_loss: 0.6443 - val_accuracy: 0.7923\n",
            "Epoch 699/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5149 - accuracy: 0.8017 - val_loss: 0.6501 - val_accuracy: 0.7778\n",
            "Epoch 700/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5297 - accuracy: 0.7956 - val_loss: 0.6450 - val_accuracy: 0.7729\n",
            "Epoch 701/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.4957 - accuracy: 0.8065 - val_loss: 0.6471 - val_accuracy: 0.7778\n",
            "Epoch 702/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5025 - accuracy: 0.8083 - val_loss: 0.6418 - val_accuracy: 0.7874\n",
            "Epoch 703/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5209 - accuracy: 0.8005 - val_loss: 0.6400 - val_accuracy: 0.7923\n",
            "Epoch 704/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5199 - accuracy: 0.7963 - val_loss: 0.6453 - val_accuracy: 0.7874\n",
            "Epoch 705/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5309 - accuracy: 0.7981 - val_loss: 0.6438 - val_accuracy: 0.7971\n",
            "Epoch 706/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5364 - accuracy: 0.7956 - val_loss: 0.6490 - val_accuracy: 0.7826\n",
            "Epoch 707/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5274 - accuracy: 0.7963 - val_loss: 0.6733 - val_accuracy: 0.7681\n",
            "Epoch 708/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5276 - accuracy: 0.8029 - val_loss: 0.6478 - val_accuracy: 0.7874\n",
            "Epoch 709/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5240 - accuracy: 0.8083 - val_loss: 0.6511 - val_accuracy: 0.7971\n",
            "Epoch 710/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5268 - accuracy: 0.7793 - val_loss: 0.6530 - val_accuracy: 0.8019\n",
            "Epoch 711/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5147 - accuracy: 0.7932 - val_loss: 0.6659 - val_accuracy: 0.7778\n",
            "Epoch 712/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4927 - accuracy: 0.8120 - val_loss: 0.6523 - val_accuracy: 0.7826\n",
            "Epoch 713/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5226 - accuracy: 0.7884 - val_loss: 0.6667 - val_accuracy: 0.7729\n",
            "Epoch 714/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5161 - accuracy: 0.7993 - val_loss: 0.6487 - val_accuracy: 0.7971\n",
            "Epoch 715/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5165 - accuracy: 0.8029 - val_loss: 0.6770 - val_accuracy: 0.7778\n",
            "Epoch 716/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5179 - accuracy: 0.8047 - val_loss: 0.6647 - val_accuracy: 0.7874\n",
            "Epoch 717/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5255 - accuracy: 0.8083 - val_loss: 0.6481 - val_accuracy: 0.8019\n",
            "Epoch 718/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5483 - accuracy: 0.8023 - val_loss: 0.6442 - val_accuracy: 0.8019\n",
            "Epoch 719/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5437 - accuracy: 0.7830 - val_loss: 0.6448 - val_accuracy: 0.7826\n",
            "Epoch 720/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5193 - accuracy: 0.7920 - val_loss: 0.6477 - val_accuracy: 0.8019\n",
            "Epoch 721/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5079 - accuracy: 0.7963 - val_loss: 0.6621 - val_accuracy: 0.7681\n",
            "Epoch 722/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5067 - accuracy: 0.8065 - val_loss: 0.6595 - val_accuracy: 0.7729\n",
            "Epoch 723/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5086 - accuracy: 0.7993 - val_loss: 0.6389 - val_accuracy: 0.7971\n",
            "Epoch 724/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5219 - accuracy: 0.7950 - val_loss: 0.6331 - val_accuracy: 0.7971\n",
            "Epoch 725/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5035 - accuracy: 0.8144 - val_loss: 0.6418 - val_accuracy: 0.8019\n",
            "Epoch 726/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5014 - accuracy: 0.8096 - val_loss: 0.6444 - val_accuracy: 0.7874\n",
            "Epoch 727/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5339 - accuracy: 0.7866 - val_loss: 0.6523 - val_accuracy: 0.8019\n",
            "Epoch 728/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5110 - accuracy: 0.8077 - val_loss: 0.6464 - val_accuracy: 0.8068\n",
            "Epoch 729/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5202 - accuracy: 0.7956 - val_loss: 0.6423 - val_accuracy: 0.8164\n",
            "Epoch 730/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5167 - accuracy: 0.8029 - val_loss: 0.6520 - val_accuracy: 0.8116\n",
            "Epoch 731/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5104 - accuracy: 0.7963 - val_loss: 0.6391 - val_accuracy: 0.7971\n",
            "Epoch 732/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5018 - accuracy: 0.8071 - val_loss: 0.6480 - val_accuracy: 0.7874\n",
            "Epoch 733/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5128 - accuracy: 0.7999 - val_loss: 0.6689 - val_accuracy: 0.7874\n",
            "Epoch 734/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.4999 - accuracy: 0.8174 - val_loss: 0.6656 - val_accuracy: 0.7729\n",
            "Epoch 735/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.4912 - accuracy: 0.8077 - val_loss: 0.6624 - val_accuracy: 0.7681\n",
            "Epoch 736/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5060 - accuracy: 0.7969 - val_loss: 0.6400 - val_accuracy: 0.7874\n",
            "Epoch 737/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4856 - accuracy: 0.8192 - val_loss: 0.6458 - val_accuracy: 0.7729\n",
            "Epoch 738/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4980 - accuracy: 0.8047 - val_loss: 0.6327 - val_accuracy: 0.7874\n",
            "Epoch 739/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5222 - accuracy: 0.7993 - val_loss: 0.6473 - val_accuracy: 0.7826\n",
            "Epoch 740/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.4704 - accuracy: 0.8132 - val_loss: 0.6322 - val_accuracy: 0.7874\n",
            "Epoch 741/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.4791 - accuracy: 0.8156 - val_loss: 0.6692 - val_accuracy: 0.7633\n",
            "Epoch 742/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4936 - accuracy: 0.8150 - val_loss: 0.6575 - val_accuracy: 0.7681\n",
            "Epoch 743/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4716 - accuracy: 0.8204 - val_loss: 0.6686 - val_accuracy: 0.7729\n",
            "Epoch 744/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4756 - accuracy: 0.8216 - val_loss: 0.6606 - val_accuracy: 0.7778\n",
            "Epoch 745/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5057 - accuracy: 0.7969 - val_loss: 0.6571 - val_accuracy: 0.7923\n",
            "Epoch 746/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5062 - accuracy: 0.8023 - val_loss: 0.6507 - val_accuracy: 0.7874\n",
            "Epoch 747/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.4922 - accuracy: 0.8029 - val_loss: 0.6491 - val_accuracy: 0.7729\n",
            "Epoch 748/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.4996 - accuracy: 0.8023 - val_loss: 0.6465 - val_accuracy: 0.7729\n",
            "Epoch 749/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5134 - accuracy: 0.8029 - val_loss: 0.6570 - val_accuracy: 0.7826\n",
            "Epoch 750/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4932 - accuracy: 0.8071 - val_loss: 0.6502 - val_accuracy: 0.7971\n",
            "Epoch 751/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5091 - accuracy: 0.7932 - val_loss: 0.6641 - val_accuracy: 0.7729\n",
            "Epoch 752/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5019 - accuracy: 0.7999 - val_loss: 0.6455 - val_accuracy: 0.7923\n",
            "Epoch 753/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4761 - accuracy: 0.8198 - val_loss: 0.6735 - val_accuracy: 0.7536\n",
            "Epoch 754/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4857 - accuracy: 0.8229 - val_loss: 0.6496 - val_accuracy: 0.7778\n",
            "Epoch 755/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.4919 - accuracy: 0.8102 - val_loss: 0.6484 - val_accuracy: 0.7923\n",
            "Epoch 756/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4700 - accuracy: 0.8138 - val_loss: 0.6489 - val_accuracy: 0.7729\n",
            "Epoch 757/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4822 - accuracy: 0.8150 - val_loss: 0.6337 - val_accuracy: 0.7923\n",
            "Epoch 758/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4747 - accuracy: 0.8102 - val_loss: 0.6502 - val_accuracy: 0.7874\n",
            "Epoch 759/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5042 - accuracy: 0.8102 - val_loss: 0.6450 - val_accuracy: 0.7874\n",
            "Epoch 760/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.4673 - accuracy: 0.8265 - val_loss: 0.6332 - val_accuracy: 0.8068\n",
            "Epoch 761/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4786 - accuracy: 0.8077 - val_loss: 0.6395 - val_accuracy: 0.7923\n",
            "Epoch 762/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4918 - accuracy: 0.8077 - val_loss: 0.6461 - val_accuracy: 0.7826\n",
            "Epoch 763/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.4799 - accuracy: 0.8198 - val_loss: 0.6454 - val_accuracy: 0.7874\n",
            "Epoch 764/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.4803 - accuracy: 0.8162 - val_loss: 0.6380 - val_accuracy: 0.7971\n",
            "Epoch 765/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.4841 - accuracy: 0.8174 - val_loss: 0.6491 - val_accuracy: 0.7826\n",
            "Epoch 766/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4892 - accuracy: 0.8089 - val_loss: 0.6411 - val_accuracy: 0.7826\n",
            "Epoch 767/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.4761 - accuracy: 0.8126 - val_loss: 0.6269 - val_accuracy: 0.7778\n",
            "Epoch 768/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.4850 - accuracy: 0.8253 - val_loss: 0.6185 - val_accuracy: 0.7971\n",
            "Epoch 769/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.4960 - accuracy: 0.7981 - val_loss: 0.6315 - val_accuracy: 0.7923\n",
            "Epoch 770/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.4883 - accuracy: 0.8156 - val_loss: 0.6465 - val_accuracy: 0.7874\n",
            "Epoch 771/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.4816 - accuracy: 0.8174 - val_loss: 0.6375 - val_accuracy: 0.7778\n",
            "Epoch 772/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4857 - accuracy: 0.8241 - val_loss: 0.6404 - val_accuracy: 0.7874\n",
            "Epoch 773/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.4783 - accuracy: 0.8301 - val_loss: 0.6374 - val_accuracy: 0.7826\n",
            "Epoch 774/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.4907 - accuracy: 0.8108 - val_loss: 0.6619 - val_accuracy: 0.7729\n",
            "Epoch 775/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.4511 - accuracy: 0.8283 - val_loss: 0.6451 - val_accuracy: 0.8019\n",
            "Epoch 776/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4606 - accuracy: 0.8235 - val_loss: 0.6459 - val_accuracy: 0.7923\n",
            "Epoch 777/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4681 - accuracy: 0.8241 - val_loss: 0.6605 - val_accuracy: 0.7729\n",
            "Epoch 778/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.4823 - accuracy: 0.8198 - val_loss: 0.6272 - val_accuracy: 0.8019\n",
            "Epoch 779/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.4679 - accuracy: 0.8162 - val_loss: 0.6445 - val_accuracy: 0.7778\n",
            "Epoch 780/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.4558 - accuracy: 0.8343 - val_loss: 0.6550 - val_accuracy: 0.7681\n",
            "Epoch 781/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4682 - accuracy: 0.8174 - val_loss: 0.6291 - val_accuracy: 0.7923\n",
            "Epoch 782/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.4757 - accuracy: 0.8174 - val_loss: 0.6435 - val_accuracy: 0.7633\n",
            "Epoch 783/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.4495 - accuracy: 0.8313 - val_loss: 0.6540 - val_accuracy: 0.7585\n",
            "Epoch 784/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.4962 - accuracy: 0.8047 - val_loss: 0.6573 - val_accuracy: 0.7729\n",
            "Epoch 785/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.4727 - accuracy: 0.8144 - val_loss: 0.6430 - val_accuracy: 0.7923\n",
            "Epoch 786/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4794 - accuracy: 0.8210 - val_loss: 0.6246 - val_accuracy: 0.8164\n",
            "Epoch 787/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4611 - accuracy: 0.8271 - val_loss: 0.6316 - val_accuracy: 0.8116\n",
            "Epoch 788/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.4683 - accuracy: 0.8144 - val_loss: 0.6338 - val_accuracy: 0.7971\n",
            "Epoch 789/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4679 - accuracy: 0.8204 - val_loss: 0.6457 - val_accuracy: 0.7681\n",
            "Epoch 790/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4715 - accuracy: 0.8259 - val_loss: 0.6674 - val_accuracy: 0.7729\n",
            "Epoch 791/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4822 - accuracy: 0.8186 - val_loss: 0.6386 - val_accuracy: 0.7874\n",
            "Epoch 792/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.4818 - accuracy: 0.8120 - val_loss: 0.6664 - val_accuracy: 0.7729\n",
            "Epoch 793/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.4480 - accuracy: 0.8325 - val_loss: 0.6521 - val_accuracy: 0.7681\n",
            "Epoch 794/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4832 - accuracy: 0.8083 - val_loss: 0.6435 - val_accuracy: 0.7874\n",
            "Epoch 795/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.4613 - accuracy: 0.8277 - val_loss: 0.6369 - val_accuracy: 0.7923\n",
            "Epoch 796/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.4540 - accuracy: 0.8331 - val_loss: 0.6599 - val_accuracy: 0.7729\n",
            "Epoch 797/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4632 - accuracy: 0.8229 - val_loss: 0.6299 - val_accuracy: 0.7971\n",
            "Epoch 798/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.4786 - accuracy: 0.8265 - val_loss: 0.6535 - val_accuracy: 0.7923\n",
            "Epoch 799/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.4700 - accuracy: 0.8253 - val_loss: 0.6691 - val_accuracy: 0.7585\n",
            "Epoch 800/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.4519 - accuracy: 0.8216 - val_loss: 0.6645 - val_accuracy: 0.7778\n",
            "Epoch 801/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4546 - accuracy: 0.8295 - val_loss: 0.6343 - val_accuracy: 0.7971\n",
            "Epoch 802/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.4607 - accuracy: 0.8265 - val_loss: 0.6159 - val_accuracy: 0.8068\n",
            "Epoch 803/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.4651 - accuracy: 0.8198 - val_loss: 0.6166 - val_accuracy: 0.8019\n",
            "Epoch 804/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.4684 - accuracy: 0.8229 - val_loss: 0.6492 - val_accuracy: 0.7729\n",
            "Epoch 805/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.4461 - accuracy: 0.8301 - val_loss: 0.6160 - val_accuracy: 0.7826\n",
            "Epoch 806/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.4391 - accuracy: 0.8368 - val_loss: 0.6250 - val_accuracy: 0.8019\n",
            "Epoch 807/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.4755 - accuracy: 0.8114 - val_loss: 0.6328 - val_accuracy: 0.7826\n",
            "Epoch 808/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4466 - accuracy: 0.8222 - val_loss: 0.6426 - val_accuracy: 0.7826\n",
            "Epoch 809/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.4588 - accuracy: 0.8144 - val_loss: 0.6289 - val_accuracy: 0.7874\n",
            "Epoch 810/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4563 - accuracy: 0.8313 - val_loss: 0.6264 - val_accuracy: 0.7923\n",
            "Epoch 811/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.4620 - accuracy: 0.8229 - val_loss: 0.6252 - val_accuracy: 0.7874\n",
            "Epoch 812/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.4498 - accuracy: 0.8307 - val_loss: 0.6433 - val_accuracy: 0.7826\n",
            "Epoch 813/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.4544 - accuracy: 0.8289 - val_loss: 0.6028 - val_accuracy: 0.8068\n",
            "Epoch 814/1000\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.4378 - accuracy: 0.8337 - val_loss: 0.6220 - val_accuracy: 0.7874\n",
            "Epoch 815/1000\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 0.4343 - accuracy: 0.8301 - val_loss: 0.6174 - val_accuracy: 0.7923\n",
            "Epoch 816/1000\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 0.4440 - accuracy: 0.8301 - val_loss: 0.6097 - val_accuracy: 0.8019\n",
            "Epoch 817/1000\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.4552 - accuracy: 0.8253 - val_loss: 0.6358 - val_accuracy: 0.8019\n",
            "Epoch 818/1000\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.4605 - accuracy: 0.8253 - val_loss: 0.6173 - val_accuracy: 0.7923\n",
            "Epoch 819/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.4731 - accuracy: 0.8126 - val_loss: 0.6265 - val_accuracy: 0.7874\n",
            "Epoch 820/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.4305 - accuracy: 0.8416 - val_loss: 0.6277 - val_accuracy: 0.7874\n",
            "Epoch 821/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.4614 - accuracy: 0.8174 - val_loss: 0.6153 - val_accuracy: 0.8164\n",
            "Epoch 822/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.4422 - accuracy: 0.8277 - val_loss: 0.6261 - val_accuracy: 0.7729\n",
            "Epoch 823/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.4213 - accuracy: 0.8410 - val_loss: 0.6076 - val_accuracy: 0.7971\n",
            "Epoch 824/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.4517 - accuracy: 0.8277 - val_loss: 0.6170 - val_accuracy: 0.8116\n",
            "Epoch 825/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.4324 - accuracy: 0.8337 - val_loss: 0.6150 - val_accuracy: 0.7923\n",
            "Epoch 826/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4103 - accuracy: 0.8374 - val_loss: 0.6140 - val_accuracy: 0.8068\n",
            "Epoch 827/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.4336 - accuracy: 0.8325 - val_loss: 0.6348 - val_accuracy: 0.7778\n",
            "Epoch 828/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.4541 - accuracy: 0.8229 - val_loss: 0.6201 - val_accuracy: 0.7923\n",
            "Epoch 829/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.4165 - accuracy: 0.8434 - val_loss: 0.6317 - val_accuracy: 0.7729\n",
            "Epoch 830/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.4426 - accuracy: 0.8235 - val_loss: 0.6337 - val_accuracy: 0.7681\n",
            "Epoch 831/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4454 - accuracy: 0.8404 - val_loss: 0.6349 - val_accuracy: 0.7778\n",
            "Epoch 832/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.4411 - accuracy: 0.8283 - val_loss: 0.6199 - val_accuracy: 0.8019\n",
            "Epoch 833/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.4439 - accuracy: 0.8301 - val_loss: 0.6347 - val_accuracy: 0.7971\n",
            "Epoch 834/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4499 - accuracy: 0.8301 - val_loss: 0.6214 - val_accuracy: 0.7923\n",
            "Epoch 835/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.4454 - accuracy: 0.8241 - val_loss: 0.6187 - val_accuracy: 0.7923\n",
            "Epoch 836/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.4536 - accuracy: 0.8247 - val_loss: 0.6234 - val_accuracy: 0.7971\n",
            "Epoch 837/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.4545 - accuracy: 0.8259 - val_loss: 0.6520 - val_accuracy: 0.7633\n",
            "Epoch 838/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.4201 - accuracy: 0.8476 - val_loss: 0.6079 - val_accuracy: 0.7971\n",
            "Epoch 839/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.4357 - accuracy: 0.8440 - val_loss: 0.6040 - val_accuracy: 0.8164\n",
            "Epoch 840/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.4424 - accuracy: 0.8253 - val_loss: 0.6432 - val_accuracy: 0.7778\n",
            "Epoch 841/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.4216 - accuracy: 0.8392 - val_loss: 0.6251 - val_accuracy: 0.7971\n",
            "Epoch 842/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.4231 - accuracy: 0.8374 - val_loss: 0.6187 - val_accuracy: 0.7923\n",
            "Epoch 843/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4168 - accuracy: 0.8416 - val_loss: 0.6006 - val_accuracy: 0.8213\n",
            "Epoch 844/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.4274 - accuracy: 0.8356 - val_loss: 0.6134 - val_accuracy: 0.8019\n",
            "Epoch 845/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.4319 - accuracy: 0.8392 - val_loss: 0.6256 - val_accuracy: 0.7923\n",
            "Epoch 846/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.4161 - accuracy: 0.8392 - val_loss: 0.6368 - val_accuracy: 0.8068\n",
            "Epoch 847/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.4274 - accuracy: 0.8307 - val_loss: 0.6228 - val_accuracy: 0.7923\n",
            "Epoch 848/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.4286 - accuracy: 0.8434 - val_loss: 0.6330 - val_accuracy: 0.8116\n",
            "Epoch 849/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.4226 - accuracy: 0.8380 - val_loss: 0.6282 - val_accuracy: 0.8068\n",
            "Epoch 850/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.4340 - accuracy: 0.8374 - val_loss: 0.6207 - val_accuracy: 0.7971\n",
            "Epoch 851/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.4356 - accuracy: 0.8319 - val_loss: 0.6314 - val_accuracy: 0.7729\n",
            "Epoch 852/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.4455 - accuracy: 0.8368 - val_loss: 0.6424 - val_accuracy: 0.7874\n",
            "Epoch 853/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.4169 - accuracy: 0.8422 - val_loss: 0.6266 - val_accuracy: 0.7971\n",
            "Epoch 854/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4268 - accuracy: 0.8404 - val_loss: 0.6294 - val_accuracy: 0.8213\n",
            "Epoch 855/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.4238 - accuracy: 0.8301 - val_loss: 0.6249 - val_accuracy: 0.8068\n",
            "Epoch 856/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.4274 - accuracy: 0.8295 - val_loss: 0.6646 - val_accuracy: 0.7729\n",
            "Epoch 857/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.4174 - accuracy: 0.8374 - val_loss: 0.6352 - val_accuracy: 0.7778\n",
            "Epoch 858/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4260 - accuracy: 0.8368 - val_loss: 0.6314 - val_accuracy: 0.7923\n",
            "Epoch 859/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4113 - accuracy: 0.8337 - val_loss: 0.6318 - val_accuracy: 0.7778\n",
            "Epoch 860/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.4182 - accuracy: 0.8422 - val_loss: 0.6249 - val_accuracy: 0.7923\n",
            "Epoch 861/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.4168 - accuracy: 0.8374 - val_loss: 0.6289 - val_accuracy: 0.7826\n",
            "Epoch 862/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4644 - accuracy: 0.8156 - val_loss: 0.6300 - val_accuracy: 0.7874\n",
            "Epoch 863/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4322 - accuracy: 0.8374 - val_loss: 0.6184 - val_accuracy: 0.8116\n",
            "Epoch 864/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4103 - accuracy: 0.8434 - val_loss: 0.6091 - val_accuracy: 0.8068\n",
            "Epoch 865/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.4005 - accuracy: 0.8440 - val_loss: 0.6331 - val_accuracy: 0.7826\n",
            "Epoch 866/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.4254 - accuracy: 0.8398 - val_loss: 0.6143 - val_accuracy: 0.8116\n",
            "Epoch 867/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.4106 - accuracy: 0.8513 - val_loss: 0.6107 - val_accuracy: 0.7923\n",
            "Epoch 868/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.4165 - accuracy: 0.8374 - val_loss: 0.6295 - val_accuracy: 0.7923\n",
            "Epoch 869/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.4310 - accuracy: 0.8476 - val_loss: 0.6250 - val_accuracy: 0.7971\n",
            "Epoch 870/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.4146 - accuracy: 0.8380 - val_loss: 0.6157 - val_accuracy: 0.7874\n",
            "Epoch 871/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.4434 - accuracy: 0.8331 - val_loss: 0.6399 - val_accuracy: 0.7923\n",
            "Epoch 872/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.4279 - accuracy: 0.8374 - val_loss: 0.6539 - val_accuracy: 0.7633\n",
            "Epoch 873/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.4201 - accuracy: 0.8398 - val_loss: 0.6313 - val_accuracy: 0.7923\n",
            "Epoch 874/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.4090 - accuracy: 0.8561 - val_loss: 0.6182 - val_accuracy: 0.8019\n",
            "Epoch 875/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.4316 - accuracy: 0.8349 - val_loss: 0.6224 - val_accuracy: 0.7874\n",
            "Epoch 876/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.4312 - accuracy: 0.8277 - val_loss: 0.6194 - val_accuracy: 0.8019\n",
            "Epoch 877/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.4286 - accuracy: 0.8362 - val_loss: 0.6207 - val_accuracy: 0.8019\n",
            "Epoch 878/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.4009 - accuracy: 0.8428 - val_loss: 0.6051 - val_accuracy: 0.8068\n",
            "Epoch 879/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.4100 - accuracy: 0.8337 - val_loss: 0.6068 - val_accuracy: 0.8116\n",
            "Epoch 880/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.4067 - accuracy: 0.8525 - val_loss: 0.6065 - val_accuracy: 0.8019\n",
            "Epoch 881/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.3998 - accuracy: 0.8513 - val_loss: 0.6067 - val_accuracy: 0.8164\n",
            "Epoch 882/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3982 - accuracy: 0.8458 - val_loss: 0.6345 - val_accuracy: 0.7826\n",
            "Epoch 883/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.3957 - accuracy: 0.8470 - val_loss: 0.6005 - val_accuracy: 0.8164\n",
            "Epoch 884/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.4075 - accuracy: 0.8470 - val_loss: 0.5932 - val_accuracy: 0.8068\n",
            "Epoch 885/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.4212 - accuracy: 0.8362 - val_loss: 0.6121 - val_accuracy: 0.8019\n",
            "Epoch 886/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4045 - accuracy: 0.8428 - val_loss: 0.6046 - val_accuracy: 0.8068\n",
            "Epoch 887/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.3827 - accuracy: 0.8555 - val_loss: 0.6006 - val_accuracy: 0.8019\n",
            "Epoch 888/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.3823 - accuracy: 0.8495 - val_loss: 0.6167 - val_accuracy: 0.7874\n",
            "Epoch 889/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3894 - accuracy: 0.8489 - val_loss: 0.6146 - val_accuracy: 0.7729\n",
            "Epoch 890/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.3927 - accuracy: 0.8519 - val_loss: 0.6002 - val_accuracy: 0.7874\n",
            "Epoch 891/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.3786 - accuracy: 0.8531 - val_loss: 0.6324 - val_accuracy: 0.7633\n",
            "Epoch 892/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.4126 - accuracy: 0.8331 - val_loss: 0.6355 - val_accuracy: 0.7729\n",
            "Epoch 893/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.3981 - accuracy: 0.8573 - val_loss: 0.6151 - val_accuracy: 0.7971\n",
            "Epoch 894/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.4002 - accuracy: 0.8482 - val_loss: 0.6352 - val_accuracy: 0.7681\n",
            "Epoch 895/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.3782 - accuracy: 0.8628 - val_loss: 0.6180 - val_accuracy: 0.7874\n",
            "Epoch 896/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.4074 - accuracy: 0.8380 - val_loss: 0.6162 - val_accuracy: 0.7971\n",
            "Epoch 897/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.4070 - accuracy: 0.8495 - val_loss: 0.6283 - val_accuracy: 0.7971\n",
            "Epoch 898/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3949 - accuracy: 0.8416 - val_loss: 0.6177 - val_accuracy: 0.7923\n",
            "Epoch 899/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.4281 - accuracy: 0.8368 - val_loss: 0.6141 - val_accuracy: 0.7971\n",
            "Epoch 900/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.4033 - accuracy: 0.8489 - val_loss: 0.6253 - val_accuracy: 0.7923\n",
            "Epoch 901/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.4067 - accuracy: 0.8434 - val_loss: 0.6017 - val_accuracy: 0.8116\n",
            "Epoch 902/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.4077 - accuracy: 0.8458 - val_loss: 0.6155 - val_accuracy: 0.8019\n",
            "Epoch 903/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3845 - accuracy: 0.8567 - val_loss: 0.6003 - val_accuracy: 0.8019\n",
            "Epoch 904/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.3865 - accuracy: 0.8603 - val_loss: 0.5998 - val_accuracy: 0.8068\n",
            "Epoch 905/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.3995 - accuracy: 0.8452 - val_loss: 0.6231 - val_accuracy: 0.7874\n",
            "Epoch 906/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.4191 - accuracy: 0.8476 - val_loss: 0.6176 - val_accuracy: 0.8019\n",
            "Epoch 907/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.4003 - accuracy: 0.8537 - val_loss: 0.6240 - val_accuracy: 0.7923\n",
            "Epoch 908/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.3809 - accuracy: 0.8615 - val_loss: 0.6127 - val_accuracy: 0.7874\n",
            "Epoch 909/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.3888 - accuracy: 0.8549 - val_loss: 0.6048 - val_accuracy: 0.7971\n",
            "Epoch 910/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.4191 - accuracy: 0.8331 - val_loss: 0.6141 - val_accuracy: 0.8068\n",
            "Epoch 911/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.4097 - accuracy: 0.8422 - val_loss: 0.6128 - val_accuracy: 0.8019\n",
            "Epoch 912/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4149 - accuracy: 0.8410 - val_loss: 0.6008 - val_accuracy: 0.7971\n",
            "Epoch 913/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3941 - accuracy: 0.8482 - val_loss: 0.6022 - val_accuracy: 0.7971\n",
            "Epoch 914/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.3947 - accuracy: 0.8458 - val_loss: 0.6086 - val_accuracy: 0.7923\n",
            "Epoch 915/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.3954 - accuracy: 0.8470 - val_loss: 0.6010 - val_accuracy: 0.7971\n",
            "Epoch 916/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.4083 - accuracy: 0.8404 - val_loss: 0.5996 - val_accuracy: 0.7923\n",
            "Epoch 917/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.3963 - accuracy: 0.8440 - val_loss: 0.5956 - val_accuracy: 0.7971\n",
            "Epoch 918/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.3936 - accuracy: 0.8543 - val_loss: 0.6293 - val_accuracy: 0.7923\n",
            "Epoch 919/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4063 - accuracy: 0.8434 - val_loss: 0.6103 - val_accuracy: 0.7923\n",
            "Epoch 920/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.3959 - accuracy: 0.8446 - val_loss: 0.6044 - val_accuracy: 0.8019\n",
            "Epoch 921/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.4079 - accuracy: 0.8356 - val_loss: 0.6278 - val_accuracy: 0.7923\n",
            "Epoch 922/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.4185 - accuracy: 0.8416 - val_loss: 0.6195 - val_accuracy: 0.8019\n",
            "Epoch 923/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.3932 - accuracy: 0.8609 - val_loss: 0.6218 - val_accuracy: 0.7923\n",
            "Epoch 924/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.3639 - accuracy: 0.8694 - val_loss: 0.6117 - val_accuracy: 0.8019\n",
            "Epoch 925/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.3730 - accuracy: 0.8622 - val_loss: 0.5975 - val_accuracy: 0.7923\n",
            "Epoch 926/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.3915 - accuracy: 0.8531 - val_loss: 0.6293 - val_accuracy: 0.7778\n",
            "Epoch 927/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.3743 - accuracy: 0.8561 - val_loss: 0.6269 - val_accuracy: 0.7874\n",
            "Epoch 928/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3888 - accuracy: 0.8470 - val_loss: 0.6149 - val_accuracy: 0.7874\n",
            "Epoch 929/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.4005 - accuracy: 0.8434 - val_loss: 0.6345 - val_accuracy: 0.7681\n",
            "Epoch 930/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.3894 - accuracy: 0.8519 - val_loss: 0.5883 - val_accuracy: 0.7874\n",
            "Epoch 931/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.4041 - accuracy: 0.8434 - val_loss: 0.6092 - val_accuracy: 0.7874\n",
            "Epoch 932/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.3759 - accuracy: 0.8615 - val_loss: 0.5960 - val_accuracy: 0.8068\n",
            "Epoch 933/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.3476 - accuracy: 0.8718 - val_loss: 0.6295 - val_accuracy: 0.7778\n",
            "Epoch 934/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.3801 - accuracy: 0.8591 - val_loss: 0.6036 - val_accuracy: 0.8164\n",
            "Epoch 935/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3952 - accuracy: 0.8579 - val_loss: 0.6119 - val_accuracy: 0.7971\n",
            "Epoch 936/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.3659 - accuracy: 0.8700 - val_loss: 0.6158 - val_accuracy: 0.7874\n",
            "Epoch 937/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3898 - accuracy: 0.8464 - val_loss: 0.6447 - val_accuracy: 0.7729\n",
            "Epoch 938/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.3721 - accuracy: 0.8585 - val_loss: 0.6005 - val_accuracy: 0.7826\n",
            "Epoch 939/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.3959 - accuracy: 0.8489 - val_loss: 0.6083 - val_accuracy: 0.8019\n",
            "Epoch 940/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.3855 - accuracy: 0.8507 - val_loss: 0.6021 - val_accuracy: 0.7923\n",
            "Epoch 941/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.3852 - accuracy: 0.8537 - val_loss: 0.6206 - val_accuracy: 0.8116\n",
            "Epoch 942/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.3816 - accuracy: 0.8519 - val_loss: 0.6342 - val_accuracy: 0.7729\n",
            "Epoch 943/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.3754 - accuracy: 0.8597 - val_loss: 0.6189 - val_accuracy: 0.8019\n",
            "Epoch 944/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3619 - accuracy: 0.8664 - val_loss: 0.6121 - val_accuracy: 0.8164\n",
            "Epoch 945/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3699 - accuracy: 0.8676 - val_loss: 0.6224 - val_accuracy: 0.7923\n",
            "Epoch 946/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.3604 - accuracy: 0.8712 - val_loss: 0.6405 - val_accuracy: 0.7874\n",
            "Epoch 947/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.3769 - accuracy: 0.8495 - val_loss: 0.6107 - val_accuracy: 0.8019\n",
            "Epoch 948/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.3641 - accuracy: 0.8694 - val_loss: 0.5986 - val_accuracy: 0.8019\n",
            "Epoch 949/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.3786 - accuracy: 0.8634 - val_loss: 0.6233 - val_accuracy: 0.7874\n",
            "Epoch 950/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.3852 - accuracy: 0.8464 - val_loss: 0.6164 - val_accuracy: 0.7971\n",
            "Epoch 951/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.3911 - accuracy: 0.8537 - val_loss: 0.5961 - val_accuracy: 0.8213\n",
            "Epoch 952/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3913 - accuracy: 0.8470 - val_loss: 0.5952 - val_accuracy: 0.7971\n",
            "Epoch 953/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.3361 - accuracy: 0.8736 - val_loss: 0.5863 - val_accuracy: 0.7923\n",
            "Epoch 954/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.3643 - accuracy: 0.8609 - val_loss: 0.6000 - val_accuracy: 0.7923\n",
            "Epoch 955/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.3694 - accuracy: 0.8628 - val_loss: 0.5922 - val_accuracy: 0.8019\n",
            "Epoch 956/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.3740 - accuracy: 0.8549 - val_loss: 0.5911 - val_accuracy: 0.8309\n",
            "Epoch 957/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.3678 - accuracy: 0.8615 - val_loss: 0.6076 - val_accuracy: 0.7971\n",
            "Epoch 958/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3942 - accuracy: 0.8416 - val_loss: 0.6183 - val_accuracy: 0.7826\n",
            "Epoch 959/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.3548 - accuracy: 0.8622 - val_loss: 0.5922 - val_accuracy: 0.8019\n",
            "Epoch 960/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.3470 - accuracy: 0.8628 - val_loss: 0.6285 - val_accuracy: 0.7971\n",
            "Epoch 961/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.3583 - accuracy: 0.8718 - val_loss: 0.6125 - val_accuracy: 0.8068\n",
            "Epoch 962/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3692 - accuracy: 0.8597 - val_loss: 0.6168 - val_accuracy: 0.7971\n",
            "Epoch 963/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.3425 - accuracy: 0.8833 - val_loss: 0.6083 - val_accuracy: 0.7971\n",
            "Epoch 964/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.3646 - accuracy: 0.8597 - val_loss: 0.6074 - val_accuracy: 0.7729\n",
            "Epoch 965/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3455 - accuracy: 0.8712 - val_loss: 0.6033 - val_accuracy: 0.8019\n",
            "Epoch 966/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.3855 - accuracy: 0.8579 - val_loss: 0.6116 - val_accuracy: 0.7874\n",
            "Epoch 967/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.3966 - accuracy: 0.8464 - val_loss: 0.5870 - val_accuracy: 0.7971\n",
            "Epoch 968/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.3820 - accuracy: 0.8501 - val_loss: 0.5926 - val_accuracy: 0.7923\n",
            "Epoch 969/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.3719 - accuracy: 0.8658 - val_loss: 0.6131 - val_accuracy: 0.7729\n",
            "Epoch 970/1000\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.3474 - accuracy: 0.8700 - val_loss: 0.6281 - val_accuracy: 0.7923\n",
            "Epoch 971/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.3650 - accuracy: 0.8712 - val_loss: 0.6150 - val_accuracy: 0.7971\n",
            "Epoch 972/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.3685 - accuracy: 0.8597 - val_loss: 0.6018 - val_accuracy: 0.7923\n",
            "Epoch 973/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.3714 - accuracy: 0.8549 - val_loss: 0.5889 - val_accuracy: 0.8068\n",
            "Epoch 974/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.3801 - accuracy: 0.8585 - val_loss: 0.6119 - val_accuracy: 0.7971\n",
            "Epoch 975/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.3658 - accuracy: 0.8609 - val_loss: 0.6077 - val_accuracy: 0.7923\n",
            "Epoch 976/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.3767 - accuracy: 0.8628 - val_loss: 0.6124 - val_accuracy: 0.7923\n",
            "Epoch 977/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.3532 - accuracy: 0.8676 - val_loss: 0.6106 - val_accuracy: 0.7971\n",
            "Epoch 978/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.3773 - accuracy: 0.8525 - val_loss: 0.6162 - val_accuracy: 0.7923\n",
            "Epoch 979/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.3584 - accuracy: 0.8718 - val_loss: 0.6042 - val_accuracy: 0.7874\n",
            "Epoch 980/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.3356 - accuracy: 0.8694 - val_loss: 0.6225 - val_accuracy: 0.7826\n",
            "Epoch 981/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.3527 - accuracy: 0.8664 - val_loss: 0.5994 - val_accuracy: 0.7923\n",
            "Epoch 982/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.3559 - accuracy: 0.8658 - val_loss: 0.6078 - val_accuracy: 0.7971\n",
            "Epoch 983/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.3711 - accuracy: 0.8579 - val_loss: 0.6046 - val_accuracy: 0.7826\n",
            "Epoch 984/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.3486 - accuracy: 0.8688 - val_loss: 0.5815 - val_accuracy: 0.8019\n",
            "Epoch 985/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3771 - accuracy: 0.8549 - val_loss: 0.6067 - val_accuracy: 0.7874\n",
            "Epoch 986/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.3677 - accuracy: 0.8615 - val_loss: 0.6051 - val_accuracy: 0.8213\n",
            "Epoch 987/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.3728 - accuracy: 0.8622 - val_loss: 0.6035 - val_accuracy: 0.8068\n",
            "Epoch 988/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.3515 - accuracy: 0.8634 - val_loss: 0.6001 - val_accuracy: 0.8116\n",
            "Epoch 989/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.3581 - accuracy: 0.8652 - val_loss: 0.5962 - val_accuracy: 0.8019\n",
            "Epoch 990/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.3450 - accuracy: 0.8664 - val_loss: 0.6062 - val_accuracy: 0.8068\n",
            "Epoch 991/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.3810 - accuracy: 0.8579 - val_loss: 0.6019 - val_accuracy: 0.7923\n",
            "Epoch 992/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.3496 - accuracy: 0.8670 - val_loss: 0.6005 - val_accuracy: 0.8068\n",
            "Epoch 993/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.3532 - accuracy: 0.8664 - val_loss: 0.5844 - val_accuracy: 0.7874\n",
            "Epoch 994/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.3615 - accuracy: 0.8603 - val_loss: 0.5888 - val_accuracy: 0.8019\n",
            "Epoch 995/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.3686 - accuracy: 0.8700 - val_loss: 0.6039 - val_accuracy: 0.7971\n",
            "Epoch 996/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.3668 - accuracy: 0.8609 - val_loss: 0.6237 - val_accuracy: 0.7778\n",
            "Epoch 997/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.3357 - accuracy: 0.8761 - val_loss: 0.6125 - val_accuracy: 0.7826\n",
            "Epoch 998/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.3725 - accuracy: 0.8622 - val_loss: 0.6145 - val_accuracy: 0.7923\n",
            "Epoch 999/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.3377 - accuracy: 0.8785 - val_loss: 0.5889 - val_accuracy: 0.8164\n",
            "Epoch 1000/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.3555 - accuracy: 0.8609 - val_loss: 0.6324 - val_accuracy: 0.7826\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(cnnhistory.history['loss'])\n",
        "plt.plot(cnnhistory.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train','test'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "oQYnuaCrDH_A",
        "outputId": "bb9c1970-73b9-4177-f1b1-75c0df54be19"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(cnnhistory.history['accuracy'])\n",
        "plt.plot(cnnhistory.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train','test'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "IFkTuO8nDNdq",
        "outputId": "ac4c09e7-14db-4547-c9ff-18df37d43b73"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdd3hU1dbA4d+aSSMhBEjoLSC9KEgXCyggNqyfFxS9VmwoNrx67V6vXa8NCyr23lFQRAHBAlKl9xp6gAQC6dnfH+dMpicTkiFl1vs8eXLKPmf2BJ01Z5e1xRiDUkqpyOWo7AoopZSqXBoIlFIqwmkgUEqpCKeBQCmlIpwGAqWUinAaCJRSKsJpIFARRUTeEZFHQyy7SUQGh7tOSlU2DQRKKRXhNBAoVQ2JSFRl10HVHBoIVJVjN8mME5ElInJIRN4SkUYi8oOIHBSRn0Wknkf54SKyXEQyRGSmiHTyONdDRBba130KxPm81tkisti+9g8ROTbEOp4lIotE5ICIbBWRh3zOn2jfL8M+f4V9vJaIPCsim0UkU0R+s48NFJG0AH+Hwfb2QyLyhYh8ICIHgCtEpI+I/Gm/xg4ReVlEYjyu7yIi00Rkn4jsEpF/i0hjETksIske5Y4XkT0iEh3Ke1c1jwYCVVVdCAwB2gPnAD8A/wYaYP13ewuAiLQHPgZutc9NAb4TkRj7Q/Eb4H2gPvC5fV/sa3sAE4HrgGTgdWCSiMSGUL9DwOVAXeAs4AYROc++byu7vi/ZdeoOLLavewboCZxg1+kuoCjEv8m5wBf2a34IFAK3ASlAf+A04Ea7DonAz8CPQFOgLfCLMWYnMBO42OO+lwGfGGPyQ6yHqmE0EKiq6iVjzC5jzDZgNjDXGLPIGJMDfA30sMv9A5hsjJlmf5A9A9TC+qDtB0QDzxtj8o0xXwDzPF5jNPC6MWauMabQGPMukGtfVyJjzExjzFJjTJExZglWMDrFPn0J8LMx5mP7dfcaYxaLiAO4ChhrjNlmv+YfxpjcEP8mfxpjvrFfM9sYs8AYM8cYU2CM2YQVyFx1OBvYaYx51hiTY4w5aIyZa597FxgFICJOYCRWsFQRSgOBqqp2eWxnB9ivbW83BTa7ThhjioCtQDP73DbjnVlxs8d2K+AOu2klQ0QygBb2dSUSkb4iMsNuUskErsf6Zo59j/UBLkvBapoKdC4UW33q0F5EvheRnXZz0WMh1AHgW6CziLTGeurKNMb8dYR1UjWABgJV3W3H+kAHQEQE60NwG7ADaGYfc2npsb0V+K8xpq7HT7wx5uMQXvcjYBLQwhiTBLwGuF5nK3BMgGvSgZwg5w4B8R7vw4nVrOTJN1Xwq8AqoJ0xpg5W05lnHdoEqrj9VPUZ1lPBZejTQMTTQKCqu8+As0TkNLuz8w6s5p0/gD+BAuAWEYkWkQuAPh7XvgFcb3+7FxFJsDuBE0N43URgnzEmR0T6YDUHuXwIDBaRi0UkSkSSRaS7/bQyEXhORJqKiFNE+tt9EmuAOPv1o4H7gNL6KhKBA0CWiHQEbvA49z3QRERuFZFYEUkUkb4e598DrgCGo4Eg4mkgUNWaMWY11jfbl7C+cZ8DnGOMyTPG5AEXYH3g7cPqT/jK49r5wLXAy8B+YJ1dNhQ3Ao+IyEHgAayA5LrvFuBMrKC0D6uj+Dj79J3AUqy+in3Ak4DDGJNp3/NNrKeZQ4DXKKIA7sQKQAexgtqnHnU4iNXscw6wE1gLDPI4/ztWJ/VCY4xnc5mKQKIL0ygVmURkOvCRMebNyq6LqlwaCJSKQCLSG5iG1cdxsLLroyqXNg0pFWFE5F2sOQa3ahBQoE8ESikV8fSJQCmlIly1S1yVkpJiUlNTK7saSilVrSxYsCDdGOM7NwWohoEgNTWV+fPnV3Y1lFKqWhGRoMOEw9o0JCLDRGS1iKwTkbsDnG8lIr+IlWVypog0D2d9lFJK+QtbILCnyI8HzgA6AyNFpLNPsWeA94wxxwKPAI+Hqz5KKaUCC+cTQR9gnTFmgz3D8xOsNLqeOgPT7e0ZAc4rpZQKs3D2ETTDO1tiGtDXp8zfWCkAXgDOBxJFJNkYs7csL5Sfn09aWho5OTnlqW+VFxcXR/PmzYmO1vVDlFIVp7I7i+8EXrZXb5qFlWOl0LeQiIzGyh1Py5YtfU+TlpZGYmIiqampeCearDmMMezdu5e0tDRat25d2dVRStUg4Wwa2oaVDtiluX2smDFmuzHmAmNMD+Be+1iG742MMROMMb2MMb0aNPAf/ZSTk0NycnKNDQIAIkJycnKNf+pRSh194QwE84B2ItLaXjJwBFb+9mIikmKv2gRwD1aK3iNSk4OASyS8R6XU0Re2QGCMKQDGAFOBlcBnxpjlIvKIiAy3iw0EVovIGqAR8N9w1UcppaqSQ7kFfLUwjaqQ5ies8wiMMVOMMe2NMccYY/5rH3vAGDPJ3v7CGNPOLnNNGdZurVIyMjJ45ZVXynzdmWeeSUaGX0uYUioCPDRpObd/9jeLtpb+GWCMISu3IGx10VxDFSBYICgoKPkfbsqUKdStWzdc1VJKVWHbM7MBOJzrNz7Gz8g35tD1wansPhiePkINBBXg7rvvZv369XTv3p3evXtz0kknMXz4cDp3tubPnXfeefTs2ZMuXbowYcKE4utSU1NJT09n06ZNdOrUiWuvvZYuXbowdOhQsrOzK+vtKKXK6XBeARv2ZBXvFxYZcvILWbnjADd+uID8wiI2pR8GIL+oiMN5BRQVGQ7nFbBud5bXvXILCpmzYR8AOzPDEwgqe/hohXv4u+Ws2H6gQu/ZuWkdHjynS9DzTzzxBMuWLWPx4sXMnDmTs846i2XLlhUP85w4cSL169cnOzub3r17c+GFF5KcnOx1j7Vr1/Lxxx/zxhtvcPHFF/Pll18yatSoCn0fSqnwyc4r5OUZa7lpUFuu/2Ahs9bs4bqT23DPmZ24+eOFTFm6s7js6JMPsC3D+rJ35dvzABh7Wjt2ZGbz2fw0nvm/4zipXQqN6sTx8dwtxdflFxaFpe41LhBUBX369PEa6//iiy/y9ddfA7B161bWrl3rFwhat25N9+7dAejZsyebNm06avVVSpXfe39uYvyM9dSOjWbWmj0AvD5rA7ec1s4rCABsSj/kd/07f2wiMzsfgDs//5vE2CgO+vQLHMgJTz9BjQsEJX1zP1oSEhKKt2fOnMnPP//Mn3/+SXx8PAMHDgw4FyA2NrZ42+l0atOQUlVIQWER93y1lGtPbkP7RonkFxYxY9VuTmrXgFoxTsAaBQSQlZvvde3SbZl+97v108V+x1xBwMU3CAAc8ClTUWpcIKgMiYmJHDwYeMW/zMxM6tWrR3x8PKtWrWLOnDlHuXZKqfL6a9M+Pl+QxvLtB7hyQCrjvlgCwMg+LXn8gm4AHMqzOn0PZHt/gP+wdEeF1UOfCKqw5ORkBgwYQNeuXalVqxaNGjUqPjds2DBee+01OnXqRIcOHejXr18l1lQpVZJvFm3j2Wmr+fXOQTgcwl8b9/HT8p28+dtGAKKjHDzz0+ri8qt2Wv2Rs9fuKe7IfX+Od9r/d/8MugxAqRrViSXK4WD8pceTX1hE65SE0i86AhoIKshHH30U8HhsbCw//PBDwHOufoCUlBSWLVtWfPzOO++s8PoppYJbti2TrfsOc+fnf1NQZHhx+loWbN7P3A37yPPooI2LcnDIY7hnXJST7RnZXPbWX0f0uuMvOZ6bPloIQLdmScXNSHef0ZGVOw7wwoge5XhXodNAoJSq0bZnZDN91W4u7dsyaJqWs1/6zWv/+Z/XBiw3d+M+r/0/N+xl4NMzS61Ds7q1ikcJeUquHQNASu0Yvrv5RH5ds4eEGCe9UuuXes+KpPMIlFI10uy1eygsMjzy3Qru+2YZS9Iyyc4rZM6GvRhjilM77M0qX0IDzyeGfm38P8BH9mnBb/8axOBODf3ONa4TB8Alfaysyqe0b3DUgwDoE4FSqga57K25LN9+gGtPasOTP66iR8u6NK1bC4Bzx/9eXK5WtJMhnRuRnpXLH+vLtPwJAAM7NODvrRnsP+w9iqewyFA3PpqMw/k8fdGx9EqtX9yu/8blvdiYfojWKQm0vmcKAKkpCUy/45Swtf2HSgOBUqpaKiwyfDh3Mxf3akFctDWEc/badACe/HEVAIu2ZNCqfrzftdn5hUz6e3tIr9MwMZbdB72fGt65sg89HvmpeN/pEAqLDA4R5t87GANEOcSrKUpEaNOgNgAvjOhOmxRr23WsMmnTkFKqSjqcV8A5L/3G3x5J2f5cv5e3f99IfmERn83fygPfLuet3zby5YI0vl6UFvA+Ofmlz8ZNTfYPFi43DDzGa//Ooe0B97j/hfcP4dubBgAwsENDopwOop2OEtPGn9u9Gd2aJ5Var6NFnwiUUlXKgZx8Hp+yigFtk1m6LZNzx//Olzf0B4SRb1jzcFbvPFg8wubpqatLuBv8uHxniecBWtSP59HzunH9BwuKs3x+cHVfeqXWIzbKwf+mrWHcsI5c1q9V8TX/Oa8rz/20hnrx0dRPiOHHW0+ifcPE0t/g35/C7Gfgpr+giqwxIlUhF3ZZ9OrVy8yfP9/r2MqVK+nUqVMl1cjKPvrRRx9x4403lvna559/ntGjRxMfH/wbiafKfq9KVbSc/EKenrqasYPbcTCngCd/WBWw2SY2ykFuQfly7bx7VR/2HcqlSVIt7vlqKcc0qM3PK3dxUrsU3r/aWlI99e7JAGx64qxyvVZQD9lPAveng/PorT8uIguMMb0CndMnggrgSkN9pIFg1KhRIQcCpaq7RVv206lJHWKcDp7/ZS0HsvN5549NRDmE12dtCHpdeYNA/8aGU1onQnQDyM9hxg3dmJFWyM8rd3mV+2R0Pxomxga5Szll7XZv52cHDwTGwMGdUKdJeOrhQwNBBfBMQz1kyBAaNmzIZ599Rm5uLueffz4PP/wwhw4d4uKLLyYtLY3CwkLuv/9+du3axfbt2xk0aBApKSnMmDGjst+KUmGx71Aer89azzEptbnryyX857yutG9Ymxd/cY/XLykIlKZNSgJdmiXxnf0k8d5Vfbh84l+8e1UfdmRkM7RLY+o/3QDePwGu+gE+uBA2/4aM9J8v0K9Nst+xClGQB8+089gvYdjq3Nfgx7ut5qMGHcJTHw81LxD8cDfsXFqx92zcDc54IuhpzzTUP/30E1988QV//fUXxhiGDx/OrFmz2LNnD02bNmXyZOuxMzMzk6SkJJ577jlmzJhBSkpKxdZZqUq2dd9hkle+T9GuFRz/11Cvc5mH89i873BI92kue3g5+gWuy7udXVhj7BfdP4TxM9YVp364aVBbVuw4wNXOyXR3rOfk9lPdTTs5mfDmidb2lj+s35vtCWRFQRaF2b4YJpwCPS6Dc18O/U27HEqHt4bCyE+gdkOYOAzOesa7TEEJawtssuu3Z5UVCDb/AZPvgGunQ3StstenFDpqqIL99NNP/PTTT/To0YPjjz+eVatWsXbtWrp168a0adP417/+xezZs0lKqjojBpQqqx2Z2bz0y1qv9Xa/+3s7cze4x+Sf9NQM4qfdRe0l7xBLntf1eYWGrBASqA3u1JDzHbPp7tjA1VHuVC31EmK47+zOxfttGiRQt1Y090d/yDnOOdYHp8vG2ZDu0aG88P3izd6NnVzReCPPNZoK6evcZSacYv1e5C4LQGE+/PUGFJZS91WTYd96+OMF+OYG2LMSpj3gXaakQBBtNxWvt1sJptwFu1fAnpI7xo9UWJ8IRGQY8ALgBN40xjzhc74l8C5Q1y5ztzFmSrletIRv7keDMYZ77rmH6667zu/cwoULmTJlCvfddx+nnXYaDzzwQIA7KFX1jft8Cb+tS2fHgRwu6NGMAzn53PzxIgBuPrUtNw5s61U+VXay2rQs3s/OK2DdbnfG3nocYD91vK4Z3Kkhb/6zN+Pu/QyA4a3yeWy9fbKoCLL3k5wQQ+/U+vRoAB0atYLZ9vm3z4AHM6xROYU+TTCTxhRvJhRm8lDGvTAfmP8sPJRpPUF4ys92fwtf8A5MuRMO7oCB/4a8g1Crnv8fqMgOFHvXw5Y/vY+5ZO2CeqnufoJDeyHBbpaKsSeYLXgbBj8Exn5ycYTnIztsTwQi4gTGA2cAnYGRItLZp9h9wGfGmB7ACKDsK8BXAZ5pqE8//XQmTpxIVpa13Ny2bdvYvXs327dvJz4+nlGjRjFu3DgWLlzod61S1cEPS3fw2zpr4tZHc7cw5qNFXPWOeyTfS9PX0emBH3HibnZJEfeHa0yUgzdmbyxerOXTM50sirueC+Lc9/j42n68cmlPAOLsp4nGCQ7+r2dz7jurk/VN++k2LBjbldcuagNPphI/+zHviv7xovW7pLb47P3+x9K8RyXyksdAG9e9Zj8LH10MT6Zabf++Jt9u/T6U7j5W5NPZ/c5Z8K0dlJZ8Bk+3sZqkAGI9Jpk92crdhGWq3wplfYB1xpgNACLyCXAusMKjjIHirwFJQGhT/aoYzzTUZ5xxBpdccgn9+/cHoHbt2nzwwQesW7eOcePG4XA4iI6O5tVXXwVg9OjRDBs2jKZNm2pnsSq/fRvhy6vh0i8gvuJy1uQVFHEwJx8R4YYPF3qd23kgh76ykiuifuSZgov5JXYcAIuL3BOxUsj0upenvvHW//bP9khn5pIY9h3Ko8OOb4l5/zY4+S56NY2FPUBBDk9fcpx10UR7Vu9zHeHyb63t3/7nXekF78C6X6DVCcHfWL5PP8X6GfDBBd7HDnhMVIvxGN23/hf7D7DEChDvnGnt37HGXWavR2f0rgB9l0s+geS2kLHJ2t++EJp2hz9e8i7natoqKaiVQzgDQTNgq8d+GtDXp8xDwE8icjOQAAwOdCMRGQ2MBmjZsmWgIpXONw312LFjvfaPOeYYTj/9dL/rbr75Zm6++eaw1k1FgMP7rG+Vf7wIB7bB8q+h99Vlv0/aAnA4oGkPWPwR5GbxdcyZ3Pbp33STDRQhQGuvSwY5FvF2zNOA1QTk0t2xvni7gXg3tzgp5Hznb3xVeBJEWYnXZMU3nGoasVLqUv/ne62Cs57i3JPvsgJBvt2mvnaa1TTjMjNIc/C+DdbPxl+Dv998n3b6988LXG77Itg4y7+dH+DN07z3570Z/PUCmfEo1LbXMFnwLjTpHrxsSf0K5VDZo4ZGAu8YY54Vkf7A+yLS1Rjv5x9jzARgAlgTyiqhnkpVbZ//0/qgcikMsqThge1W+3NsHast3OFka2YBzeol4BDgzVOtcv/ebnVyAi/lCg2oxXex9wHQL+cldpJMPDkU4igOAgCdHFt9XxFwNw1NvuVE7vlsAefnfM2VOe+RyGE4ZKVsIPcAz/A0+A7hd7XZ52RanbQfXuR93nNsflllbAl8vFE372/wEwaW4aZH8BGVZc9l2LEY3hgUvFw1fCLYBrTw2G9uH/N0NTAMwBjzp4jEASlAOf5llYpA+zZ57xcGaLfeMhcmWsM4l7Qfw7HbPqNAnLTI2sHe+DYkxTqKPxB+XrS2+PH8qegJ9HK4mzvmxN3MlXnjvAJASQ44khh9fG2uv8Aazjmp4AbIsZ4cHox+H6aVcoO/Xrd+F2RbAc/XvvX+x0L1w7jAx6PKMaHs8L7SyxypgvCsZR7O4aPzgHYi0lpEYrA6gyf5lNkCnAYgIp2AOKyHwDKrbqkyjkQkvMcap6gIvrkRth7ZClYh+e5WyPT5ZjvtfvjqOqt5Z/qj1n87Hs0px655GQ7tJirLOpZ8eANR+93DJztOubB42zMIuIQaBAByEprhWPKJlVrhoSTIKj33T0D7N8Gq74/sWpf/eze0crXqBj7eoh/88zv3fteL4KK3YfhLcNaz1rH5b5VSh3cCHx90LyS18D7W9wbv/TA9EYQtEBhjCoAxwFRgJdbooOUi8oiIDLeL3QFcKyJ/Ax8DV5gj+LSLi4tj7969NfqD0hjD3r17iYuLq+yqqFCs/tFqyljxDSz+EN4aArlZ/uV2LLHa9suiMB+Wf01ufj5fvfGoNcQwkCWfWM07s57m1nv/zeafQp8Y1VzSSy8UgieKLqd2w9alF6wIva8pvUyX8yChQenlhvwn8PEel0LqSXDi7dB2sDW0s+sFcPzlpb9+m4FWsOhyfuDznc+FHqPc+w07w2llmHtQDmHtI7DnBEzxOfaAx/YKYEB5X6d58+akpaWxZ88RPUxUG3FxcTRv3ryyq6FKk7EFPv4HdDzb+xvsLw/DmT7fpN8/Dw7vhWNOtdrtHU5riGCgHDSF+dbxX5+EWU+zocttXLDtf/7lAngh5hXILL1cRbv7kZdg+TewfnLJBVsNgM2/l1ymNIPutZrEFr5XcrlAzWYAJ4+DWU9Do66QbI94GjAWfn/BXSa2jjU3YfCDZa+fa3ST6z4NOkDaPO9jXS+EmY9b+xe+ZY1SGvww/Gy/XnUMBEdLdHQ0rVsfpW8dSpUm54D1e59P7pzDAVbCch379DJ3+gOAC96EY//Pvb/4Y/jmerh1KezfDEDtQ4E7ZkuzoagxbRxH2DwDkNLBe6ZuaUIZxnrOC9ZY+Vd8BxaG4IF9VgCF0mf8BirT8WwY8aE1A3mWHaijYq3JZfk53oEgppRFZKJqhdaOf89Wa7LZS8e7j8UmWknmHvKJ2K7JZee9BsdeXPq9j4CmmFCqrGY8bg1hDGbKndZv36bKZV/CmqmBr/EMAmA1Kbms+9kKAgDpa3CNSmmx6YugVRiTF3xI8uj824OeK5U4YLTPfJfajb33r/BJDhAfQhI3RxQ07AhX/ghX/VR6ea9rnR479t+8TYCRN7evDFAeON/ujA6Uwyfapym2tLTRtyxyb7c+ueSyvvWICbJcZc8rraeJ7iP9r6kgNeKJQKmj5lA6/GqPW/f95gawe6U7pYBnE0TDLrB7uTUb1ZX6oCRRcdZw0Kzd1gQxl13LYennpVbzx6LeHDC1qCP+307TTAht5ME07GJ9YNVLtTpvjznNep9ZO2HQfVYahaRmVlmxP7TqBpj70+FMWG0HjJhEqGsv+NLKmojJwH/DzMf8r/PUqKvVnONpyCPWt/mT7oDnu3mfq9PU+v3P76xA64yxAoZrFq/rQ943gMfVhZwM7zLBeKaN/r93rXkHTbtb9/BVtxX0HwMNOlpzP4L9N+GMsvoXwkgDgVJl8e45JZ9/pZ972zO3TMNOViAAWPsTtPefXOhFJPBrBZrQFEABTq7Nu5NPY/07PX+9ZxiE1rXgr6c9fNNhfyAOe9zK9rtpttWRWqepu2nsjCet37GJEJcEzXrC+unWsZEfW6OalnwCZz5lTWLzNPBfVgfscx2t/Wa9YJud+qFOM+uDs/c1Vuevp9oNrWYmVx27XwILfUYKNe1u/fgJ8kHc85/u5qHkdoHLeGrS3RooEF+/5MylInD6f0u/31GgTUNKlcXuFaWXccnY7N52fRsF66ngwHb/Wa2eQvjWX5Jop4MF0pl9d/pPyWmU5JEmocsFfucBaH+G9cQz3CPVQUoH6HOttd3ETvUQFQfdLrLKut5jXB3rqcdVFuBfm+ES+z25PkyL7ElvjiDfsus0geNGWtvdR1r3fDDDGrUDpY/1v38PDH+x5DKeYu1lJhv5pERLaGj9/scHUDuEp6nrfoWxi0N/3SpAnwhUzbJhppUO4MTbQiu/7Csr93tsojUU0PV4/uO/raaLG/+02o5nPhH48fzP8Vb79oaZwfPE97vJv/33ufAuN7r0odMRgdgoJ4xZYGWvHN/HXeC62VbWzFr1oOcV8J49orvXVTB/otUXAO5mkgad4AqPkT/DX7SGOtZzr+HrxbeZQ8Rq4rhisjUsEtxPTCW1eyfZo+QO73ff0xVAnDHBr/Osw03zQlsbuH5rqy2+eW/v432vh5R20G5o4OtqAA0EqmZ571zrd88rAqcH9vXFle7ttoOhURerHX7OeOvYzCeg15XWkD7XsD6X/GyY+u/SXyOpuX9yMx9pscfQPLfsM2TnF7UPOOErLtrjwzWlrd95mhzr3m5zipWkbttCOPFW632daqWToNtFVqAc+qg7RTJYge2YElIhBJN6onu7KITUyv3HWH0RPT1mFA991HqK6BjimsIN2odevzYD/Y85o0pvyqvmtGlI1UylteUHvOZseKq19dvl9+fhheMClw80HDQA07wXBVLyaI/M7ALuyLs+1JoWuyrvTvY6G4ZWuKRvtO2GWO3yUbFw/mvub+IxCXDhG5DYqMx1K5VrYlXjbsHL1KoLF75ptf271GkKF7welpW6IpUGAlV9ZO2xUhQsDT5sspjncqWfXArj7U7cglzrHnNeLX99/tclpGJvbUrhsR8Df9v/R+79ABiEL4tKGW7oo23OexygNklj7YlYbQaWfMHIT60x91VFt4us+tTXOUCVTZuGVPWRbjeB/PWG9SFSmq3zYONM9+zeFd9CSzs3/Y93B075cCQadbWWECwKnPHz0ckrucwZ+IkgG6ud2zVgcVjuE1zmnMalUb+U+rILHjiTImOISoiBS7+E5j2tETuuTJa+fEfmVAVhGhevyqYK/pehVBCuDw3PLOXGwJY5VmbN+RO9y781GKY/6t7/7HL38EWw8sAfgQVNL/Hazzr3TbYWudvPH8sfyVP5//Aq83XhiaTFtAl6T4Pwj14tWGVastY08zuf3cl/RmlSfDT1EuwO03aDrT6Req2gRR+/skqVRAOBqto8J/cUj2RxL4HIsi9h4ulWeuXvQxgp9PXosr3+GO9lC1/o9jXXb/BOj7XJNKWwyF3P9wuH8Eqh1Wk9v8jqqMwingsP+M/oddjPAu0aJfLkRcfy9hW9ibKXeFza4lLoY619Xev/XvO+sMOZZXsfSpVAA4GqmqbcZbXlP9HKasJZ94uVwRO8nwh88/lUpFPv9x42eNZzbDPJZJDoVSxtv/fs3Ry7uad9zrvcX/ep4uP5AVpixQ4EtaKtc4M6NuTik6wRPd06dYJhT8C9O62nocvtLO7dR1lj2pWqIBoIVHjNewtWfgczHvOfuu8pNwt+ug/yDsOSz92LkeRmwqE93sv/bV9krUe74tuSc/6E6qKJ1mxVXzG1+W1tOrud1oiZwvxclm07QD5RXP/B58UAACAASURBVJN3R3GxtP3uoaEvFpyHw27CyiOa8Ze5x6QX4N8e7goExU87QPuh18J5r1q56B0O9+iY1idbyejOfErb1lWF0s5iVX77NliJxeKS/M9N9mgO6TTcmkTkmt5vjLXwd5Pj4K8J1oLdRYUw5xXvexTmez8FAHznvSZ0mTmi3Z27XS/07kuw3fvdaj4snEtj+vDrMev4rvAEVuywFtn7uahncblHJ69ksN1UP7WwD20aJLB2t9URXTfePekpL8D/bk+OGQU//Qyne7y+w2mlRvAl4p2RVKkKok8Eqvxe7AETh5VebulnMOEUWGmP4pn7Orx+sjVhyfVB7xsEAApz/QNBeV1qLwbjavaJ8l/wJ9/+Br+TZDqsv5npWwr9yuwxdbz2c4jm8hNSi/eTakXTuUkdxp7WjgfP9clv06AT7Zo1gCsnW4vFK1VJNBCoirF7hXtWr4vvAuo7lli/99jpgLctsH5vXwzTg6wIBfDpqCMLBK6cNAFMW72fWRcuhH98CMC+XCsFwZx27iYfJ96vOWXpThrVieW2wVYHcMectzkx18pl42r06tS0Hj1auDNNOh3ClLEncduQ9ozsZ4+XT2hoLQ5/3a9lf09KhYEGAlU+not8bJjpfS7fJwWyKy3zby/Amp+sJwTwWks3oP2brJz8ZZXokRK48bFep16ZvZXLP1zFz2v2A7Bsn/W/whvL3WXi8F/JKjkhljO6Wfn3c4gl1+4YdtipbBxiiI8J0n4vAhe/D9dOt2bslmeBdKUqkAYCVT4lrcYULBDkHYSPPNq6cw+Wrw6+C367ZO93b4/6Chq5Uxm42uuveW8+qXdPJh2rf6O+uOsSh/8EsfgYJ+0bJVI71ru9/93k21halMoeZ2PiY0roeus8HOoGqa9SlSSsgUBEhonIahFZJyJ3Bzj/PxFZbP+sEZGMcNZHhUFJqZR9E60V5AYud8heKN13patQjfoq4OHd+93/OX27Lo8/hrpX/crDO/XxL4XWkoGbixrxfIGVmjlO/Os77vQOACx6YAhTb3WnhGjT50zOyXuMQkc0KbVjOLVjQx44u7Pf9UpVRWEbNSQiTmA8MARIA+aJyCR7wXoAjDG3eZS/GdAes6po3wYY3xeu/93K5PjneGsi17XT/T/sn+1krfjU+xr44S7vczuXBL7/aju9cWmrP7mceDv89px73yfFs7n4feSzy9i+Zy8N7a86Yz+x8sPPia1HY9nvN4JnclE/5ue0Zxf1aW/SAMg1VrNP/YQYTu/SmNM6NqRvG2sGcbTTQYfGiXx2XX9Sasew+6AVNASIcjqYeIVPKmOlqrBwDh/tA6wzxmwAEJFPgHOBYCt7jAQeDGN9VEn2rIYdfwdeHHv511azzuIPrKUAXamXM7b4j/I5uB0O4h8EQhHq2PiTx1nDVWc+DnlZ1oifq6ZaM4yBLdKUVkACudzO7TgbdQZ7jZgb88bS37GCLcY/Y+curEXWPy48lXb1o7lr7KPcVOgkPsaJBMln36e1dU3TurUY0DaZ+87SpwBV/YQzEDQDtnrspwF9AxUUkVZAa2B6kPOjgdEALVsGWP9UlZ9r0ZJAgcA1tLLAp/P01ROtCV8V5bQH4Iur/I/XS7XWll3wNgBbs2Bb45H0O68l5pdH+HbVQQ7kNeZyu/jcjCRMUSP+W3ApM4u6FwcBgIWmPQsLg+enb1a3Ftsysml+5p0QFUtCiP+HxEU7+fCafqUXVKoKqioTykYAXxhj/AdqA8aYCcAEgF69epUwPVWVmzH+qzm5RrcU2P0BMbWtb+IlBQFxeucECkXL/tD0eNi+0P9epz1gBQJnDCc9NQOAUzs2Yfq2h+Fza6jP5Xa8uuvbNYS6KG9iXBQHcwq4/pRjOKV9A/ofk1z6RUrVMOEMBNsAz+ERze1jgYwAbgpjXVSoPh0FIz70Pua0A8GaqVb+n1AECwI3L4SXrI5ZouLcwcW1HyiVc0ID9ypWdZrBIWtz+ir/9XhLc2nflnw4dwv1E2L46Nq+tE5JYMX2A/RoGcJqZkrVUOEMBPOAdiLSGisAjAD85s2LSEegHvBnGOuiQrXqe2vc/tZ57nQGrieCg9uP/L7N+0CnsyH5GPex5Hawy2MBmajY4nkJfza7ErqcR7vDi0npO8JaEP2sZ9lc/0R4I/AiL1fmjeOgCbxq1bKHTye/oIjYaAcfzt3CnUM70LGxNStYg4CKdGELBMaYAhEZA0wFnMBEY8xyEXkEmG+MsVMpMgL4xJiSMpKpo+qdsyFzq/XBHV2rYtI79LjUWkfYk8NpjS6a9ybUaQ5RtYrnGty7oQsb1h8C2vFrj0RaAQsaXsCFrwb/vjCjyD3oLKV2LLViHHx5wwkk1Yq2FnG349mmJ0Jc61apCBHWPgJjzBRgis+xB3z2HwpnHdQRyLT7+A9st77B+6aKKIuOZ1tPGc4As2id0XDWs9aPS+uTYN96Mkzt4kPPTVvDCyN6cNU78/3v4aFbsySWbstkVL+WPHpeCevgKqW8VJXOYlUVZaZZq15NGnNk1zfvbXUsB+NwzxvYlH6Ii177g6+ve5j8dlex75204nPfLt5OQaEhM7vkgHTlgFRSascyoG3KkdVXqQilKSaUP1fH7IFt8PfHgcvUbVX6fTxTPAR8Hfe8gc/mbyU9K49/fbOKBVn1/YpOXlpKPiKg/zHJnNy+AU5H4DH/SqnANBBEuoJc/0Xc4+0hlJnbrOYhX816WU04pSkqhF72vIBA5QfcCkBOfiGvzLQ6gP9Yv5dxXwSZgezhs+v6e+3Xjo2iSVLgjmKlVMk0EES6106Exz1W54qOd28fSAu8qliLPt7HBwRZJCZ1ALTsCw9lQlJzv9Nv7z6GnPxCznhhdpmr3ad1fWbfNah4/+8Hh5b5HkopiwaCSJSfDe+fD7tXQvoan3OHIWuXtb3gHVjzg//1Qx7xzjFUy78pB2D3iY9y2rMz2bz3UMDzD3+3gqvfncfGdP/zgTI6nNrRSgsR7bROtqjvDlraHKTUkdPO4ki06TdYPx2m3ut9vFlP92IxLoEWh3dGW0tOAnS9COIDB4LvV2awfs8hJv62kYfP7RqwzO/r9gY8bgw8ddGx7D+Ux5UDWuN0CE6HsPtgDjFO7+8vvVN1HoBS5aGBIBLl2X0ChT65g9oN9Q8EwbgWpOl6AThjvE5NYQCditbxzE+rAdiWkU1BYRFRTgd7s3IJlsTh2f87jszsfB753spLeHEv/7z9DRO9l5Rc998zcARJCKeUCo0GgkiUZzfFbPJpm/fM/hlXF3JKWB7ClQrCEW3lB/JwY44rW4iVZuLnlbv575SVxDgdvD5rA5v8lwcGYHCnRiTFR5NUK5pGdYIU8hHl1NZNpcpLA0EkygvcZo94BIKT74Sf7rO2250Op91vzSlwNQm5ykbFQEIyjJ4JEwYGfcm3f99UarVqx1n/OV7Y079jWSkVPhoIahJjrFm87YeVvMjLmqmBjzs8/nOIrmV92y/Kh0ZdoLHPTN2z/wd/vAStTrT2m/bgAbmJHbmlr8N7U94tCN6jkWaNG6QdvkpVEn2urknW/WxlD/31SfcxY6CoyPoBOLwP1v9S+r2iarmbf+oGWAMiqRlFpz9OdqH14b157yHeyx7AtKJefkUbJHoHh8lF/UjuO6J4//ubT6RlcrzvZUqpo0SfCGqSLDst86yn4dT7rBXHXnevq8u49TBxWPDrPdcUjvL48O5wRsDiz01bw8sz1nFJ35bERwdfXWzqrSdz/H+meR0b3LkRgzo2JDU5gdSUhCBXKqWOBg0ENYlnltBdy72DAFhLTO5dG/z6gmz3dpRHZ63PqCCX9+dYS399NHdLidWqnxDDsodPZ93uLJokxTFz9W5ObJsSdPlHpdTRpU1DNYlnIHjvPP/zSz71P9be4wkh32ORmGjPQBC4v6GoqPTM4UM7NwKsFBDdW9SlUZ04/tG7pQYBpaoQDQQ1iWcgOBTi6l2XeASHEJ8IiooMRUWGQp/0E/ef7V64/b2r+nDFCan857zAE8mUUlWHNg1VV8u+tBZ6v30V1GliHSvPugHg/UTgGQgc0Xw2fytdmybROCmOof/7lfSsPBLjvP/zaeWR8iE1OYGHhncpX32UUkeFBoLqat5b1u+9a92BID/I/IBgblnkve/5RODRHJSVX8RddkbQlNoxpGdZM5IP5hQUlzm2eRK9U92pJpLiSxi+qpSqUrRpqLrKtz+0C3Kt0UHg/Y0+FPXbeO8PfbR484aPFhdvL0lzzzB2BQFPr43qyaQxJ3p9+CfG6ncMpaoLDQTVlWuo54cXuUcHFQQJBHeu85417CsmEZJaWKmiUzoAsD7d/XSwYvuBoJf+ec+pDOvauHi/R8u6ADh0cphS1UZYv7aJyDDgBazF6980xjwRoMzFwEOAAf42xlwSzjrVCFPugt3LvY+9dy5smBm4fFSMNWu4sDDw+X9tcud9rt8a0ldzGHcfwaOTVwa87O4zOvotBvPhNX3J8mgyUkpVfWELBCLiBMYDQ4A0YJ6ITDLGrPAo0w64BxhgjNkvIg3DVZ8aYdYz0PEs+Ot1/3OeQSChofeoIWcsiP3wd+Fb0LCTtXqYrVCcpGfl0qiOE85/nWv+8yJppoHX7Ts1qcPKHd5PBs4AQ0DjY6KIj9FmIaWqk3A2DfUB1hljNhhj8oBPgHN9ylwLjDfG7AcwxoQ45jECZWyF6f+Bt88svWy/6733nTFw2ddw3EjocoGVO6jJscWnb/lkEX0f+4UFm/eTYeL5uain3y0HHJPMW//0Th8RH1tCc5NSqtoI6aubiHwFvAX8YIznYPUSNQO2euynAX19yrS37/87VvPRQ8aYHwO8/mhgNEDLlgHy3kSC5+3x+PnZJZcDSPD+No/DAa36Wz8BTF5iLQx/4at/BL3lCW2TObWjNTnM6RDGDGrL//X0Xy9AKVX9hPoM/wpwJfCiiHwOvG2MWV1Br98OGAg0B2aJSDdjjFcifGPMBGACQK9evUqfzlqTSQgPcb6BoAQm0JrEAbiGhs7992lEOx3UTwicdkIpVf2EFAiMMT8DP4tIEjDS3t4KvAF8YIwJNJNpG+D5lbG5fcxTGjDXvn6jiKzBCgzzyvY2IkgocwXiU0K+3ZZ9h4OeW3buD3SuJ6xo2ru43T/UBWOUUtVHyH0EIpIMXAFcAyzCGg10PDAtyCXzgHYi0lpEYoARwCSfMt9gPQ0gIilYTUUBFsmNYHvWeGcFDUWtuiEXnbU2PeDxh4d3oWuPE3Ck9tfOX6VquFD7CL4GOgDvA+cYY3bYpz4VkfmBrjHGFIjIGGAqVvv/RGPMchF5BJhvjJlknxsqIiuw1jUcZ4wJvJp5JDq8D8b3hu6jynZd7Ubu7aTgfSp5BUXc/80yAE5ql8JsOyh8cX1/erbSBeGVihShftV70RgzI9AJY4z/SiTuc1OAKT7HHvDYNsDt9o/y5VpScvEHZbsurg7ctdHqT4jyXhQmK7eArg/6r1DW1J4PcNewDvTySBWhlKr5Qg0EnUVkkasTV0TqASONMa+Er2qKQv90DiVqfCyc/by1He//Yf75/K2s3HEw4KWuBHKCzghWKtKEGgiuNcaMd+3Yk7+uxRpNpMIllKGiAP1uggNpcPF7QYtsy8hmnJ04zlfHxolcdWJr5mzcywXHNzuSmiqlqrFQA4FTRMRuynHNGtbxg+EWaiAY9ljQU7kFhRgDA56Y7nfu9iHtubx/K+rGW/+U39980hFVUylVvYUaCH7E6hh25Ta4zj6myuvlPnDCGDj+cv9zBSEGgiByCwrpcF/gf6YGibHcfGpbXSlMKRXy8NF/ATOAG+yfX4C7wlWpiGEMpK+GSTdb+8u+soaLAuxYYq0x7GnkpzDMJ29fkPWEAZamZQY8nhgbxbx7B2sQUEoBIQYCY0yRMeZVY8xF9s/rxpggqSxVyIp8/oRfXGkNFwX46T7YudT7fFJz6HcDtBoAfe18QtHxBFJQWMQSn0Dw4sgeABzM1eygSim3kAKBiLQTkS9EZIWIbHD9hLtyNV6Rx4Rs31QPgUYMuYaCXjkFBt1rbXc6u/h02v7DfD7fSu/03ykreeT74kSvRDuFc461VjK79qTW5a+7UqrGCLWP4G3gQeB/wCCsvEO6qE15FXl8M/dcb/j5Y/0DA3g3A8XVgbF/Q2LT4kOXvDGXLfsOBxwdZAyICBsfP1ObhJRSXkL9MK9ljPkFEGPMZmPMQ8BZ4atWhPD88M/3yPmTsRkyt/iXj/LJ81Mv1Vp0xrY9I3jncpEdWDQIKKV8hRoIckXEAawVkTEicj5QO4z1igyefQShDBWNCt4xvPtgTvGHvafeqVaqiMhO2aqUKkmogWAsEA/cAvQERgH/DFelIkZRkCcClybd4SGPDl9nrH8Z4MsFafT57y8UBfi0H3/J8UDgliallIIQ+gjsyWP/MMbcCWRh9Q+oiuDZR/Daif7nfZtxovwDweKtGdzx+d8Bb3/r4HY0SIxlRO8WnN9DZwwrpQIrNRAYYwpFJMCnlCq39LXu7UBPBL55fxz+S0Pe9unioLcfe1o7RIQnLjw2aBmllAq1aWiRiEwSkctE5ALXT1hrVhPlZnnvf1DKn9D1RDDo3qDNQrFR3v+EDo/YoR3DSqlQhBoI4oC9wKnAOfbP2SVeobylr4PHm8GiD8twkf1BfspdcP/u4qOZ2flsTD/EVe/MY9VO72yiHRvXoV58NLcPaV8BlVZKRYJQl6rUfoHy2rvO+r3iW+hx6RHf5v05m4sXkwnkqYuOpWuzpCO+v1Iq8oS6QtnbBBiBaIy5qsJrVFO5OnrXTrVyCnU5P3C5c16A78Za285ov9OPfLc86EuccEyyBgGlVJmFOrP4e4/tOOB8YHvFV6cG85wM9sWVwdcV7nmFOxAEGCUU5XCQX+ido+ieMzrStG4tBnVsWEGVVUpFklCbhr703BeRj4HfwlKjmsrh86de+3Pp1/jMJC4qMmTn++f6u7Bnc1JqB+5MVkqp0hxpvqB2QKlfP0VkmIisFpF1InJ3gPNXiMgeEVls/1xzhPWp+nyTta6bVvo1Hk8ERUWGIf/71a/IxsfP1CCglCqXUPsIDuLdR7ATa42Ckq5xAuOBIUAaME9EJhljVvgU/dQYMyb0KldTvimnD+8r/Rr7icAYQ6///sy+Q+6MpA+e05kLjm+uQ0SVUuUWatNQ4hHcuw+wzhizAUBEPgHOBXwDQWTwfSLIDiEQHHsx2zKy/ZaZfPmSHpx9bNMgFymlVNmE+kRwPjDdGJNp79cFBhpjvinhsmbAVo/9NKBvgHIXisjJwBrgNmPMVt8CIjIaGA3QsmXLUKpc9RT5LAZjioKX9cgvtGa1e/5AlEOYMvYk2jc6krislFKBhdpH8KArCAAYYzKw1icor++AVGPMscA04N1AhYwxE4wxvYwxvRo0aFABL3sUHd4H39wEnwZYk9hT91Fwq3t+wKb0Q6TePZkr355XfOyXO07RIKCUqnChBoJA5Up7mtgGtPDYb24fK2aM2WuMybV338TKbFqz/PoULP4A8g6WXK55T6jr/nON+XihX5FWyQkVXTullAp5HsF8EXkOq/MX4CZgQSnXzAPaiUhrrAAwArjEs4CINDHG7LB3hwMrQ6xP9REgUVxAUXGs2nmAHZk5zF6TzrJtB7xOX3C8Zg9VSoVHqIHgZuB+4FOs0UPTsIJBUMaYAhEZA0wFnMBEY8xyEXkEmG+MmQTcIiLDgQJgH3DFEb2Lqsx3VTFPgx+G7YtgxTcQFcuw52cHLfqkZhBVSoVJqKOGDgF+8wBCuG4KMMXn2AMe2/cA95T1vtVKSYEgsbF7kfoSyiUnxBDt1CWilVLhEdKni4hMs0cKufbricjU8FWrhkibD44S/sRRsVCQ494O4vL+qRVbL6WU8hBq01CKPVIIAGPMfhHRxDYl2b0K3jzNP7WEJ2csdDwb1k+HlA7AEgDaNqzNoA4N6Ny0Dmd0beK35oBSSlWkUANBkYi0NMZsARCRVHQ99OAergfN+1jbvvMHPEXFQK+r4LiREBOPKxAk1Yrm3rM6h7+eSilF6IHgXuA3EfkVa7WUk7AneKkATBFsnVN6OWestQpZTDx7s3KLDyfV8k8/rZRS4RJqZ/GPItIL68N/EfANkB3OilVbpgwPSlFxGGN4efo6np22pvjwcc2DpKhWSqkwCDXFxDXAWKxJYYuBfsCfWEtXKk++yeVKEhXDxvRDXkGgXnw0Nw06JgwVU0qpwELthRwL9AY2G2MGAT2AjJIviVCFeaWXcXHGsnnvYa9D7RolEqVDRZVSR1Gonzg5xpgcABGJNcasAjqEr1rVWFF+yEWNw8krM9d5HfunDhVVSh1loXYWp9nzCL4BponIfmBz+KpVTWXthuz9JZcZeA/MfByAuRv2Mm/TfpokxfH1jQNokBiL06HrCyiljq5QO4tdK60/JCIzgCTgx7DVqrp6pl3pZQbcyuZd+2i18nVWZlh//vvP7kzjpBJmICulVBiF+kRQzBjjv16iCs210yE6jpt2nMnOnO6kT98FwLAujSu5YkqpSKa9kkdTkpVmOqFWLOkkFR92aHOQUqoSlfmJQPnYtQLqNLUmhpUmKo6s3ALmbnQvU/nvMzuGsXJKKVU6DQTlkbUbXu0PqSfB7hCWYo6uxWOT3EsuvDCiO2d1axLGCiqlVOk0EJRHtj2VYlPwdQQ8fbNkNzNWudcgPre7LjajlKp8GgiOVO5B+PPlMl1y66eLw1QZpZQ6choIjtSPd8OiD4748mObJ5VeSCmljgIdNXSkDu0ttUj6nbvZ5fTvA7jihFQ+v75/OGqllFJlpoHgSEnpf7r3/tzMaYf+43f8/B7NiI0KcVF7pZQKs7AGAhEZJiKrRWSdiARd81hELhQRY6e6rh5CGC66MzObLOIZkXcf1+XdBsDfDw7luBaaZlopVXWErY9ARJzAeGAIkAbME5FJxpgVPuUSsbKbzg1XXcKitEDQqCsb0w8BMKfIWm3sguOb6aIzSqkqJ5xPBH2AdcaYDcaYPOAT4NwA5f4DPAnkhLEuYVBCIIhLYuclvzBvk3cCuoeGdwlznZRSquzCOWqoGbDVYz8N6OtZQESOB1oYYyaLyLhgNxKR0dhLY7Zs2TIMVQ1i3luwfyMMfTRApYLE0LF/8+a8dB59/BcA7hjSnkv6tiS5dmwYK6qUUkeu0oaPiogDeA64orSyxpgJwASAXr16lWEtyHKafLv1u9NwaxbxwR3WYvMOJ6yfEfiaeqk8On158W7v1vU1CCilqrRwBoJtQAuP/eb2MZdEoCswU6z29sbAJBEZboyZH8Z6ld1bQ9zbLfpCoy6Qmxmw6OQlO7z268Rpn4BSqmoLZx/BPKCdiLQWkRhgBDDJddIYk2mMSTHGpBpjUoE5QNULAr7ysyFrV+BzLfvzd5r3Cp4JsTpMVClVtYUtEBhjCoAxwFRgJfCZMWa5iDwiIsPD9bpllr4OPrkU8kPsqy7MhcxtAU+ZSz5le0a21zFtFlJKVXVh7SMwxkwBpvgceyBI2YHhrEtQU+6ADTNh8+/Q9rTSyx/YAau+d+/f9BeM7wNA64d+8yq66YmzKrCiSikVHpprqKRhoIF8Pdp7v0GHiquKUkpVAk0xURGi4/0O6aJjSqnqQgNBMQMzHoN1P0PeYXiuc8nFG3eDG+dY27cs4pz8J4tPXdq3JT/eenIY66qUUhVHm4ZcqSIM8Kv9YT78JTgQuEO4WFJLaNjJ2k5szL7E9mB3FD9yblec+kiglKomNBAE6iMoyC39Mof1MLUkLYM3Z29km8doIQ0CSqnqRANBIFPuLLXIku1ZDL978lGojFJKhZf2ERyhTfuqWY48pZQKQp8IitNJly2F0X/zL/U7NmZQW45vpWsNKKWqFw0Erj4CU1R60U7nwMrvANhF/eLDAzs04IURPXStAaVUtaRNQy5FhSWfbzMI/u+9gKeuPrG1BgGlVLUV2YFgy1xYN83a3r4wcJne11i/Hc7ikUKehnZuxEntGoSpgkopFX6RHQgmDnVvz3o6cJn2w7x2f2h4LffnXwHART2b8/yI7mGqnFJKHR3aRxAqY3Umv5A3nFWFBwHo2aoe8TH6J1RKVW+R/UQQl1R6mdg61u/EJgDUT4gpPhXtjOw/n1KqZojsr7PRCZATYKUxZwwU5lnbLfvC+ROg09nkFRTxx/q9R7eOSikVZpEdCBzB3r5Piojj/gHAKfaC9C4FhSEMOVVKqSousts2AowCAjwmmXnbkek9mzhfA4FSqgaI7EAgQdYTLgicPuK4FnXp3KRO8X5eYdlmIyulVFUU2YHAUfrC8ue89BvDnp/F7LV7+HtrBkm1ohl9chtAnwiUUjVDWAOBiAwTkdUisk5E7g5w/noRWSoii0XkNxEpZTWYCha0jwDoeDYZJz3I0m2ZrNp5kMve+guA9XuyuKhncwCGdWl8NGqplFJhFbZAICJOYDxwBtAZGBngg/4jY0w3Y0x34CnguXDVJ3AlS3giGPEh3af5r0dcWGRo3yiRTU+cRWpKQhgrp5RSR0c4nwj6AOuMMRuMMXnAJ8C5ngWMMQc8dhMoawrQ8grSKQyQk++deygx1np6OJxXSk4ipZSqZsIZCJoBWz320+xjXkTkJhFZj/VEcEugG4nIaBGZLyLz9+zZU3E1LKFp6GBOgdf+yR2sfEL/6N2i4l5fKaWqgErvLDbGjDfGHAP8C7gvSJkJxphexpheDRpUYIK3EjqLD+bke+0f2yyJlY8M44Gzj243hlJKhVs4A8E2wPPrc3P7WDCfAOeFsT7+Sugj8Hwi+PeZHRnRpyW1Ypw4dD1ipVQNE85AMA9oJyKtRSQGGAFM8iwgIu08ds8C1oaxPt6+HQNb5wQ9vWXf4eLt0Scfo+sNKKVqrLClmDDGFIjIGGAq4AQmGmOWi8gjwHxjzCRgjIgMBvKB/cA/woZoYwAACfpJREFUw1UfP4veL/H0vE37SIhxsvjBoSWWU0qp6i6suYaMMVOAKT7HHvDYHhvO1y+P7LxC6tSK1gyjSqkaTz/lfBaeAXg58VZyC4qIiy595rFSSlV3GggCdBiv2ZtPTn4hsVH651FK1XyRl4Y6fS0c3One9xlC+lLBeUwu6kfj7QdIqR2DUkrVdJEXCF7u5b3vEwieLbgYgG0Z2ew9lHu0aqWUUpVG2z5KmEuQk6/ZRZVSNV/kPRH4yCmEuNtWsHXDSs77dHdlV0cppY66iH8imLJ8DyQ1Y1ZeO/YSwmL2SilVw0R8IMgrslJG7Dpg9Qe8OLJH8bkSkpMqpVSNEfFNQwU42brvMB/N3cJxLeoy/LimDOvSmGXbM2lQO7ayq6eUUmEX8YEgnyjOfHE2B3MKOLFtMgAxUQ6Ob1mvkmumlFJHR8Q3DRmkONNonq5BrJSKQBEfCMRjUbTCoqO7QJpSSlUFER8IPOkDgVIqEkV8IPB8Iigy+kSglIo8ER8IHB6BYFDHhpVYE6WUqhwRP2rI9UQw7baTaduwdiXXRimljr6IDwTHt6zLptFnVXY1lFKq0kR801DrlPjKroJSSlWqsAYCERkmIqtFZJ2I3B3g/O0iskJElojILyLSKpz1CSTaoXkklFKRLWyBQEScwHjgDKAzMFJEOvsUWwT0MsYcC3wBPBWu+gQTJTpSSCkV2cL5RNAHWGeM2WCMyQM+Ac71LGCMmWGMOWzvzgGah7E+AXkOH1VKqUgUzkDQDNjqsZ9mHwvmauCHMNaHbRnZAY5qIFBKRbYqMWpIREYBvYBTgpwfDYwGaNmy5RG/zvrdWd6RqGV/OHncEd9PKaVqgnA+EWwDWnjsN7ePeRGRwcC9wHBjTMBFgo0xE4wxvYwxvRo0aHDEFTqcV+h94KofoV7qEd9PKaVqgnAGgnlAOxFpLSIxwAhgkmcBEekBvI4VBMK+TmR2fkHx9saBL4f75ZRSqloIWyAwxhQAY4CpwErgM2PMchF5RESG28WeBmoDn4vIYhGZFOR25bZudxbv/r4RgF2mLjHHXRiul1JKqWolrH0ExpgpwBSfYw94bA8O5+t7mr5qFxvTtkMcvF5wDv9K1NXHlFIKImhmcWpyAvXkIAD7TCKxUc5KrpFSSlUNERMIBqR/zpSYfwPQt2vbSq6NUkpVHVVi+OjRkNDyOPZ0G8XqQw5GXjSysqujlFJVRsQEAlqfTIPWJ3Pkg0+VUqpmipimIaWUUoFpIFBKqQingUAppSKcBgKllIpwGgiUUirCaSBQSqkIp4FAKaUinAYCpZSKcGJM9VqhS0T2AJuP8PIUIL0Cq1Md6HuODPqeI0N53nMrY0zAObXVLhCUh4jMN8b0qux6HE36niODvufIEK73rE1DSikV4TQQKKVUhIu0QDChsitQCfQ9RwZ9z5EhLO85ovoIlFJK+Yu0JwKllFI+NBAopVSEi5hAICLDRGS1iKwTkbsruz4VRURaiMgMEVkhIstFZKx9vL6ITBORtfbvevZxEZEX7b/DEhE5vnLfwZEREaeILBKR7+391iIy135fn4pIjH081t5fZ59Prcx6HykRqSsiX4jIKhFZKSL9I+Df+Db7v+llIvKxiMTVxH9nEZkoIrtFZJnHsTL/24rIP+3ya0Xkn2WpQ0QEAhFxAuOBM4DOwEgR6Vy5taowBcAdxpjOQD/gJvu93Q38YoxpB/xi74P1N2hn/4wGXj36Va4QY4GVHvtPAv8zxrQF9gNX28evBvbbx/9nl6uOXgB+NMZ0BI7Deu819t9YRJoBtwC9jDFdAScwgpr57/wOMMznWJn+bUWkPvAg0BfoAzzoCh4hMcbU+B/4//buL0SLKozj+PcXW5Ya/omSTSOzIiIoLQjNAskykKgujDCzsC678apYqou6jv5cRC0UYSUVlpZ4Y2gheJGrhpVYlmboiqZEWQaF6dPFed71dTXcXdd93ZnfB16YOXMYznmfffeZOTNzhhnA6qb1DqCj1e06S339FLgb2A60Z1k7sD2XO4H5TfV76g2XDzApfxx3AqsAUZ62bOsdb2A1MCOX27KeWt2HfvZ3DLCrd7srHuOJwB5gfMZtFXBPVeMMTAa2DjS2wHygs6n8hHqn+9TijIDjf1QN3VlWKXk6PA3YAEyIiH25aT8wIZer8F28AjwFHMv1S4DfI+LfXG/uU09/c/uhrD+cXAUcBN7O4bA3JY2iwjGOiL3Ai8BuYB8lbpupdpyb9Te2ZxTzuiSCypM0GvgYWBwRfzRvi3KIUIn7hCXdCxyIiM2tbssQagNuBl6PiGnAXxwfKgCqFWOAHNa4n5IELwdGcfLwSS0MRWzrkgj2Alc0rU/KskqQdD4lCSyNiOVZ/Iuk9tzeDhzI8uH+XcwE7pP0M/ABZXjoVWCspLas09ynnv7m9jHAr0PZ4EHQDXRHxIZc/4iSGKoaY4C7gF0RcTAijgDLKbGvcpyb9Te2ZxTzuiSCjcC1ecfBBZSLTitb3KZBIUnAW8B3EfFS06aVQOPOgcco1w4a5Y/m3QfTgUNNp6DnvIjoiIhJETGZEsfPI2IB8AUwL6v17m/je5iX9YfVkXNE7Af2SLoui2YD26hojNNuYLqkkfk33uhzZePcS39juxqYI2lcnk3NybK+afVFkiG8GDMX+AHYCTzT6vYMYr9up5w2fgNsyc9cyvjoWuBHYA0wPuuLcgfVTuBbyl0ZLe/HAPs+C1iVy1OALmAHsAwYkeUX5vqO3D6l1e0eYF+nApsyzp8A46oeY+B54HtgK/AuMKKKcQbep1wHOUI5+3tiILEFHs/+7wAW9acNnmLCzKzm6jI0ZGZm/8OJwMys5pwIzMxqzonAzKzmnAjMzGrOicBsCEma1Zgx1exc4URgZlZzTgRmpyDpEUldkrZI6sz3HxyW9HLOkb9W0qVZd6qkL3N++BVNc8dfI2mNpK8lfSXp6tz96KZ3CyzNJ2fNWsaJwKwXSdcDDwEzI2IqcBRYQJn4bFNE3ACso8z/DvAO8HRE3Eh52rNRvhR4LSJuAm6jPD0KZYbYxZR3Y0yhzKFj1jJtp69iVjuzgVuAjXmwfhFl0q9jwIdZ5z1guaQxwNiIWJflS4Blki4GJkbECoCI+Bsg99cVEd25voUyF/36s98ts1NzIjA7mYAlEdFxQqH0XK96A52f5Z+m5aP4d2gt5qEhs5OtBeZJugx63h97JeX30pj58mFgfUQcAn6TdEeWLwTWRcSfQLekB3IfIySNHNJemPWRj0TMeomIbZKeBT6TdB5lVsgnKS+EuTW3HaBcR4AyTfAb+Y/+J2BRli8EOiW9kPt4cAi7YdZnnn3UrI8kHY6I0a1uh9lg89CQmVnN+YzAzKzmfEZgZlZzTgRmZjXnRGBmVnNOBGZmNedEYGZWc/8B9EWgWIMUWlkAAAAASUVORK5CYII=\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model.predict(x_testcnn)"
      ],
      "metadata": {
        "id": "A2xtrN5wDQgY"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_f_ohjXKDUpY",
        "outputId": "ff5542eb-1234-4041-d1e0-ede7aa23c5f8"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[2.4680533e-01, 6.8893857e-02, 1.3777930e-01, 2.9692215e-01,\n",
              "        2.2986443e-01, 1.9734915e-02],\n",
              "       [9.5675512e-07, 1.5553346e-07, 3.1269994e-11, 9.9990082e-01,\n",
              "        1.7361936e-07, 9.7872413e-05],\n",
              "       [1.4613573e-01, 4.0135115e-02, 2.0032154e-02, 6.2300336e-01,\n",
              "        1.1872805e-02, 1.5882088e-01],\n",
              "       ...,\n",
              "       [4.5430552e-06, 1.6489938e-08, 2.2856273e-04, 2.9086700e-04,\n",
              "        9.8752195e-01, 1.1954088e-02],\n",
              "       [4.9989205e-05, 2.7371791e-01, 7.1523792e-01, 2.8393820e-03,\n",
              "        3.7459063e-03, 4.4088932e-03],\n",
              "       [4.0250274e-07, 6.5176067e-07, 4.9942741e-03, 1.1722505e-05,\n",
              "        9.9240255e-01, 2.5903936e-03]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cmA2bFgsDW3D",
        "outputId": "b03b7dcd-d75b-47b7-e57f-de2e6927a74c"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([3, 3, 3, 0, 4, 4, 1, 2, 5, 0, 5, 3, 2, 2, 1, 4, 4, 5, 2, 4, 1, 2,\n",
              "       3, 5, 4, 2, 1, 2, 2, 2, 2, 5, 2, 5, 3, 1, 2, 0, 4, 5, 2, 3, 2, 2,\n",
              "       5, 2, 0, 1, 3, 4, 4, 5, 1, 1, 4, 4, 5, 1, 1, 1, 0, 1, 5, 0, 4, 1,\n",
              "       1, 0, 1, 4, 1, 0, 4, 1, 3, 1, 2, 2, 1, 2, 3, 0, 5, 3, 5, 5, 2, 4,\n",
              "       5, 1, 5, 1, 5, 3, 4, 1, 4, 1, 5, 4, 5, 1, 2, 1, 1, 5, 1, 3, 2, 5,\n",
              "       2, 1, 3, 5, 4, 4, 0, 0, 3, 1, 2, 2, 3, 5, 1, 5, 3, 4, 2, 2, 0, 2,\n",
              "       2, 5, 5, 0, 3, 3, 2, 2, 0, 3, 4, 0, 4, 2, 4, 5, 4, 1, 5, 3, 2, 2,\n",
              "       5, 4, 3, 3, 4, 3, 3, 4, 1, 5, 2, 3, 2, 2, 0, 2, 1, 3, 1, 2, 2, 5,\n",
              "       5, 1, 4, 2, 2, 1, 1, 3, 3, 5, 5, 2, 5, 1, 5, 0, 3, 3, 0, 5, 1, 4,\n",
              "       1, 4, 2, 5, 5, 1, 4, 2, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_Ytest = y_test.astype(int)"
      ],
      "metadata": {
        "id": "0PHDKWJWDY3g"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_Ytest"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k68v2i-pDbZE",
        "outputId": "e8762dc2-78d8-42e5-dd21-e74c433cfed6"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([3, 3, 3, 0, 4, 4, 1, 2, 5, 0, 5, 3, 2, 2, 1, 4, 4, 5, 2, 4, 1, 2,\n",
              "       3, 5, 4, 2, 1, 2, 2, 2, 2, 5, 2, 5, 3, 1, 2, 0, 4, 5, 2, 3, 2, 2,\n",
              "       5, 2, 0, 1, 3, 4, 4, 5, 1, 1, 4, 4, 5, 1, 1, 1, 0, 1, 5, 0, 4, 1,\n",
              "       1, 0, 1, 4, 1, 0, 4, 1, 3, 1, 2, 2, 1, 2, 3, 0, 5, 3, 5, 5, 2, 4,\n",
              "       5, 1, 5, 1, 5, 3, 4, 1, 4, 1, 5, 4, 5, 1, 2, 1, 1, 5, 1, 3, 2, 5,\n",
              "       2, 1, 3, 5, 4, 4, 0, 0, 3, 1, 2, 2, 3, 5, 1, 5, 3, 4, 2, 2, 0, 2,\n",
              "       2, 5, 5, 0, 3, 3, 2, 2, 0, 3, 4, 0, 4, 2, 4, 5, 4, 1, 5, 3, 2, 2,\n",
              "       5, 4, 3, 3, 4, 3, 3, 4, 1, 5, 2, 3, 2, 2, 0, 2, 1, 3, 1, 2, 2, 5,\n",
              "       5, 1, 4, 2, 2, 1, 1, 3, 3, 5, 5, 2, 5, 1, 5, 0, 3, 3, 0, 5, 1, 4,\n",
              "       1, 4, 2, 5, 5, 1, 4, 2, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds1=predictions.argmax(axis=1)\n",
        "preds1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4_cAI39VFhtp",
        "outputId": "01387431-dd4e-4dee-b371-0a1cdc3806d9"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([3, 3, 3, 3, 4, 4, 1, 5, 5, 1, 4, 3, 2, 2, 0, 4, 4, 3, 3, 4, 2, 2,\n",
              "       3, 3, 4, 2, 1, 0, 2, 2, 2, 5, 3, 5, 3, 1, 2, 0, 4, 5, 2, 3, 2, 2,\n",
              "       3, 4, 1, 1, 3, 4, 4, 5, 1, 1, 4, 4, 4, 1, 1, 1, 3, 1, 2, 1, 4, 1,\n",
              "       1, 1, 1, 4, 0, 2, 4, 3, 5, 5, 2, 2, 1, 2, 1, 0, 5, 3, 5, 5, 2, 3,\n",
              "       3, 1, 5, 1, 5, 3, 2, 2, 4, 1, 5, 4, 5, 1, 5, 1, 1, 5, 1, 5, 2, 5,\n",
              "       5, 3, 3, 5, 4, 4, 3, 0, 3, 3, 1, 2, 3, 5, 1, 3, 3, 4, 2, 2, 0, 4,\n",
              "       2, 3, 3, 0, 3, 3, 2, 2, 0, 5, 4, 0, 4, 4, 4, 5, 4, 1, 5, 3, 2, 2,\n",
              "       5, 4, 3, 3, 4, 5, 3, 4, 1, 5, 2, 3, 2, 2, 0, 2, 1, 3, 1, 4, 4, 5,\n",
              "       5, 1, 4, 2, 4, 1, 1, 3, 3, 5, 5, 2, 5, 1, 4, 0, 3, 3, 2, 2, 1, 4,\n",
              "       1, 4, 5, 2, 5, 2, 4, 2, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "abc = preds1.astype(int).flatten()"
      ],
      "metadata": {
        "id": "H4WEmM60NfQn"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "c = confusion_matrix(new_Ytest, abc) \n",
        "c"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bKEBeEBlFjB8",
        "outputId": "16a1617a-4bfa-4a66-d4df-e025def01f08"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 9,  4,  2,  3,  0,  0],\n",
              "       [ 2, 32,  3,  3,  0,  1],\n",
              "       [ 1,  1, 31,  2,  6,  4],\n",
              "       [ 0,  1,  0, 26,  0,  4],\n",
              "       [ 0,  0,  1,  1, 31,  0],\n",
              "       [ 0,  0,  3,  7,  3, 26]])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m4RjG7LWLSQx",
        "outputId": "039180c0-66b6-46d0-9be0-09112add2493"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([3, 3, 3, 0, 4, 4, 1, 2, 5, 0, 5, 3, 2, 2, 1, 4, 4, 5, 2, 4, 1, 2,\n",
              "       3, 5, 4, 2, 1, 2, 2, 2, 2, 5, 2, 5, 3, 1, 2, 0, 4, 5, 2, 3, 2, 2,\n",
              "       5, 2, 0, 1, 3, 4, 4, 5, 1, 1, 4, 4, 5, 1, 1, 1, 0, 1, 5, 0, 4, 1,\n",
              "       1, 0, 1, 4, 1, 0, 4, 1, 3, 1, 2, 2, 1, 2, 3, 0, 5, 3, 5, 5, 2, 4,\n",
              "       5, 1, 5, 1, 5, 3, 4, 1, 4, 1, 5, 4, 5, 1, 2, 1, 1, 5, 1, 3, 2, 5,\n",
              "       2, 1, 3, 5, 4, 4, 0, 0, 3, 1, 2, 2, 3, 5, 1, 5, 3, 4, 2, 2, 0, 2,\n",
              "       2, 5, 5, 0, 3, 3, 2, 2, 0, 3, 4, 0, 4, 2, 4, 5, 4, 1, 5, 3, 2, 2,\n",
              "       5, 4, 3, 3, 4, 3, 3, 4, 1, 5, 2, 3, 2, 2, 0, 2, 1, 3, 1, 2, 2, 5,\n",
              "       5, 1, 4, 2, 2, 1, 1, 3, 3, 5, 5, 2, 5, 1, 5, 0, 3, 3, 0, 5, 1, 4,\n",
              "       1, 4, 2, 5, 5, 1, 4, 2, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss, acc =model.evaluate(x_testcnn, y_test)\n",
        "print(\"Restored model, accuracy: {:5.2f}%\".format(100*acc))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n3kzoqPkDqqS",
        "outputId": "1afcdb16-6d5d-41c4-a92d-43907a4befa7"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7/7 [==============================] - 0s 3ms/step - loss: 0.5958 - accuracy: 0.7488\n",
            "Restored model, accuracy: 74.88%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss, acc =model.evaluate(X_train, y_train)\n",
        "print(\"Restored model train, accuracy: {:5.2f}%\".format(100*acc))"
      ],
      "metadata": {
        "id": "fJDTGH_OUX0z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77d3d537-640c-47b4-ae8f-4649ee8f0705"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "52/52 [==============================] - 0s 4ms/step - loss: 0.2619 - accuracy: 0.9377\n",
            "Restored model train, accuracy: 93.77%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix,accuracy_score\n",
        "import seaborn as sn\n",
        "\n",
        "print(classification_report(new_Ytest,abc))\n",
        "\n",
        "acc = float(accuracy_score(new_Ytest,abc))*100\n",
        "print(\"----accuracy score %s ----\" % acc)\n",
        "\n",
        "cm = confusion_matrix(new_Ytest,abc)\n",
        "#df_cm = pd.DataFrame(cm)\n",
        "class_names = ['neutral','calm', 'happy','sad','angry', 'fearful' ]\n",
        "df_cm = pd.DataFrame(cm, index=class_names, columns=class_names,)\n",
        "sn.heatmap(df_cm, annot=True, fmt='')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 508
        },
        "id": "SfSC3El94LZg",
        "outputId": "292e2de8-075e-4c76-f7ea-b719dd485675"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.50      0.60        18\n",
            "           1       0.84      0.78      0.81        41\n",
            "           2       0.78      0.69      0.73        45\n",
            "           3       0.62      0.84      0.71        31\n",
            "           4       0.78      0.94      0.85        33\n",
            "           5       0.74      0.67      0.70        39\n",
            "\n",
            "    accuracy                           0.75       207\n",
            "   macro avg       0.75      0.74      0.73       207\n",
            "weighted avg       0.76      0.75      0.75       207\n",
            "\n",
            "----accuracy score 74.8792270531401 ----\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "A6UOIsB2xKek"
      },
      "execution_count": 28,
      "outputs": []
    }
  ]
}