{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ramadan adam 0.0002 3.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9SRCO-a_AlH5",
        "outputId": "fb0b6889-f155-4869-c35d-58d2d17adb5c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install librosa"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oi8pWV3yBVjO",
        "outputId": "0193c2da-521b-435a-a03d-6ded2cb1d2bb"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.7/dist-packages (0.8.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.21.6)\n",
            "Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.0.2)\n",
            "Requirement already satisfied: numba>=0.43.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (0.51.2)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.4.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (21.3)\n",
            "Requirement already satisfied: audioread>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (2.1.9)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.1.0)\n",
            "Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.6.0)\n",
            "Requirement already satisfied: resampy>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from librosa) (0.2.2)\n",
            "Requirement already satisfied: decorator>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied: soundfile>=0.10.2 in /usr/local/lib/python3.7/dist-packages (from librosa) (0.10.3.post1)\n",
            "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba>=0.43.0->librosa) (0.34.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba>=0.43.0->librosa) (57.4.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->librosa) (3.0.9)\n",
            "Requirement already satisfied: appdirs>=1.3.0 in /usr/local/lib/python3.7/dist-packages (from pooch>=1.0->librosa) (1.4.4)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from pooch>=1.0->librosa) (2.23.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2022.5.18.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2.10)\n",
            "Requirement already satisfied: six>=1.3 in /usr/local/lib/python3.7/dist-packages (from resampy>=0.2.2->librosa) (1.15.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn!=0.19.0,>=0.14.0->librosa) (3.1.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.7/dist-packages (from soundfile>=0.10.2->librosa) (1.15.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.0->soundfile>=0.10.2->librosa) (2.21)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HJjcbxwy46bG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "831d03c2-0c2e-47d3-9a16-ef986993e82f"
      },
      "source": [
        "# Orignial Notebook: https://github.com/MITESHPUTHRANNEU/Speech-Emotion-Analyzer/blob/master/final_results_gender_test.ipynb\n",
        "# This notebook author: Reza Chu\n",
        "# Last Editing Date: 31st May 2019\n",
        "\n",
        "## Python\n",
        "import os\n",
        "import random\n",
        "import sys\n",
        "\n",
        "import IPython\n",
        "from IPython.display import Audio\n",
        "from IPython.display import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "## Package\n",
        "import glob \n",
        "import keras\n",
        "import IPython.display as ipd\n",
        "import librosa\n",
        "import librosa.display\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import plotly.graph_objs as go\n",
        "import plotly.offline as py\n",
        "import plotly.tools as tls\n",
        "import seaborn as sns\n",
        "import scipy.io.wavfile\n",
        "import tensorflow as tf\n",
        "py.init_notebook_mode(connected=True)\n",
        "\n",
        "## Keras\n",
        "from keras import regularizers\n",
        "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping\n",
        "from keras.callbacks import  History, ReduceLROnPlateau, CSVLogger\n",
        "from keras.models import Model, Sequential\n",
        "from keras.layers import Dense, Embedding, LSTM\n",
        "from keras.layers import Input, Flatten, Dropout, Activation, BatchNormalization\n",
        "from keras.layers import Conv1D, MaxPooling1D, AveragePooling1D\n",
        "from keras.preprocessing import sequence\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.utils import np_utils\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "## Sklearn\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "## Rest\n",
        "from scipy.fftpack import fft\n",
        "from scipy import signal\n",
        "from scipy.io import wavfile\n",
        "from tqdm import tqdm\n",
        "\n",
        "input_duration=3\n",
        "# % pylab inline"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "        <script type=\"text/javascript\">\n",
              "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
              "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
              "        if (typeof require !== 'undefined') {\n",
              "        require.undef(\"plotly\");\n",
              "        requirejs.config({\n",
              "            paths: {\n",
              "                'plotly': ['https://cdn.plot.ly/plotly-2.8.3.min']\n",
              "            }\n",
              "        });\n",
              "        require(['plotly'], function(Plotly) {\n",
              "            window._Plotly = Plotly;\n",
              "        });\n",
              "        }\n",
              "        </script>\n",
              "        "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#radvass speech and song\n",
        "import time\n",
        "import os\n",
        "import librosa\n",
        "from librosa import display\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "count=0\n",
        "path1 = '/content/drive/MyDrive/RAVDESS_speech'\n",
        "path2 = '/content/drive/MyDrive/RAVDESS_song'\n",
        "\n",
        "lst = []\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "for subdir, dirs, files in os.walk(path2):\n",
        "  print(dirs)\n",
        "  print(subdir)\n",
        "  #print(files)\n",
        "  for file in files:\n",
        "      try:\n",
        "        count +=1\n",
        "        #Load librosa array, obtain mfcss, store the file and the mcss information in a new array\n",
        "        X, sample_rate = librosa.load(os.path.join(subdir,file), res_type='kaiser_fast')\n",
        "        mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T,axis=0) \n",
        "        # The instruction below converts the labels (from 1 to 8) to a series from 0 to 7\n",
        "        # This is because our predictor needs to start from 0 otherwise it will try to predict also 0.\n",
        "        file = int(file[7:8]) - 1 \n",
        "        arr = mfccs, file\n",
        "        lst.append(arr)\n",
        "      # If the file is not valid, skip it\n",
        "      except ValueError:\n",
        "        continue\n",
        "\n",
        "for subdir, dirs, files in os.walk(path1):\n",
        "  print(dirs)\n",
        "  print(subdir)\n",
        " # print(files)\n",
        "  for file in files:\n",
        "      try:\n",
        "        #Load librosa array, obtain mfcss, store the file and the mcss information in a new array\n",
        "        X, sample_rate = librosa.load(os.path.join(subdir,file), res_type='kaiser_fast')\n",
        "        mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T,axis=0) \n",
        "        # The instruction below converts the labels (from 1 to 8) to a series from 0 to 7\n",
        "        # This is because our predictor needs to start from 0 otherwise it will try to predict also 0.\n",
        "        file = int(file[7:8]) - 1 \n",
        "        if(file ==6 or file==7):\n",
        "          continue\n",
        "        count +=1\n",
        "        arr = mfccs, file\n",
        "        lst.append(arr)\n",
        "      # If the file is not valid, skip it\n",
        "      except ValueError:\n",
        "        continue\n",
        "\n",
        "\n",
        "\n",
        "print(\"--- Data loaded. Loading time: %s seconds ---\" % (time.time() - start_time))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IfuyRZl42ccZ",
        "outputId": "4d4b951e-feef-4742-fc61-c4f756835bd2"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Actor_10', 'Actor_11', 'Actor_13', 'Actor_12', 'Actor_14', 'Actor_15', 'Actor_16', 'Actor_17', 'Actor_18', 'Actor_19', 'Actor_21', 'Actor_22', 'Actor_23', 'Actor_09', 'Actor_24', 'Actor_04', 'Actor_08', 'Actor_03', 'Actor_02', 'Actor_06', 'Actor_05', 'Actor_01', 'Actor_07', 'Actor_20']\n",
            "/content/drive/MyDrive/RAVDESS_song\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_10\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_11\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_13\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_12\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_14\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_15\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_16\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_17\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_18\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_19\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_21\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_22\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_23\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_09\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_24\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_04\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_08\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_03\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_02\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_06\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_05\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_01\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_07\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_20\n",
            "['Actor_05', 'Actor_08', 'Actor_10', 'Actor_04', 'Actor_09', 'Actor_14', 'Actor_12', 'Actor_13', 'Actor_11', 'Actor_06', 'Actor_24', 'Actor_07', 'Actor_23', 'Actor_22', 'Actor_21', 'Actor_20', 'Actor_02', 'Actor_19', 'Actor_18', 'Actor_17', 'Actor_16', 'Actor_15', 'Actor_03', 'Actor_01']\n",
            "/content/drive/MyDrive/RAVDESS_speech\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_05\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_08\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_10\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_04\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_09\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_14\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_12\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_13\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_11\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_06\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_24\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_07\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_23\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_22\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_21\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_20\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_02\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_19\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_18\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_17\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_16\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_15\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_03\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_01\n",
            "--- Data loaded. Loading time: 209.39799165725708 seconds ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "count"
      ],
      "metadata": {
        "id": "Ltlhi25L2AI5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d6ebf24c-fbc4-4aea-87b4-d5c9178b7d1d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2068"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy.core.fromnumeric import size\n",
        "size(lst)"
      ],
      "metadata": {
        "id": "HMOH7d7mzHB7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd48f706-b38c-4911-8945-d8e5c32be186"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/core/fromnumeric.py:3208: VisibleDeprecationWarning:\n",
            "\n",
            "Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4136"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating X and y: zip makes a list of all the first elements, and a list of all the second elements.\n",
        "X, y = zip(*lst)"
      ],
      "metadata": {
        "id": "ocdL7tSTBoMt"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "X = np.asarray(X)\n",
        "y = np.asarray(y)\n",
        "X.shape, y.shape"
      ],
      "metadata": {
        "id": "vHKwUGTbBtnF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1f12bdd-b3d8-4abc-e592-63e3dbc3bf47"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((2068, 40), (2068,))"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "id": "2sUCtbfMztE5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6886efb-7792-4131-d94c-86bdf8e3d6d9"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2068, 40)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Saving joblib files to not load them again with the loop above\n",
        "\n",
        "# import joblib\n",
        "\n",
        "# X_name = 'x.joblib'\n",
        "# y_name = 'y.joblib'\n",
        "# save_dir = '/content/drive/My Drive/graduation project/audio/paper_code/features'\n",
        "\n",
        "# savedX = joblib.dump(X, os.path.join(save_dir, X_name))\n",
        "# savedy = joblib.dump(y, os.path.join(save_dir, y_name))"
      ],
      "metadata": {
        "id": "UCzic8rlDcuk"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Loading saved models\n",
        "# import joblib\n",
        "# X = joblib.load('/content/drive/My Drive/graduation project/audio/paper_code/features/x.joblib')\n",
        "# y = joblib.load('/content/drive/My Drive/graduation project/audio/paper_code/features/y.joblib')"
      ],
      "metadata": {
        "id": "Q35CN6zDrzg1"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7PSTurzjCo5K",
        "outputId": "88da6ed9-229a-4647-c946-6073b9d9ffcc"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2068, 40)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2,train_size=0.8, random_state=42)\n",
        "X_valid, X_test, y_valid, y_test = train_test_split(X_test,y_test, test_size=0.5,train_size=0.5, random_state=42)"
      ],
      "metadata": {
        "id": "Ai4Fy5cPCiq1"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "x_traincnn = np.expand_dims(X_train, axis=2)\n",
        "x_testcnn = np.expand_dims(X_test, axis=2)\n",
        "X_valid= np.expand_dims(X_valid, axis=2)"
      ],
      "metadata": {
        "id": "tp1Fm5K3CEXu"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_traincnn.shape, x_testcnn.shape , X_valid.shape"
      ],
      "metadata": {
        "id": "RI0MxoIPBws5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e457a17-c466-4528-d1cf-3d2eee256bb9"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1654, 40, 1), (207, 40, 1), (207, 40, 1))"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow"
      ],
      "metadata": {
        "id": "goxL4Y3jKICC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8887b52-ea42-41d0-948d-f28ccb0ab4fb"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (2.8.2+zzzcolab20220527125636)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.21.6)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.17.3)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (14.0.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.46.3)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.0.0)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (4.2.0)\n",
            "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.26.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow) (57.4.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.5.3)\n",
            "Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow) (1.5.2)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.23.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.8.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.35.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.6.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (3.3.7)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.4.6)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.8)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (4.11.4)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (3.8.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2022.5.18.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2.10)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (3.2.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keras"
      ],
      "metadata": {
        "id": "EkcmN9UrKSxj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df62f37f-9dc2-4469-febe-aa9e68951871"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.7/dist-packages (2.8.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from keras.preprocessing import sequence\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from keras.layers import Input, Flatten, Dropout, Activation\n",
        "from keras.layers import Conv1D, MaxPooling1D\n",
        "from keras.models import Model\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras import optimizers\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv1D(128, 8,padding='same', #classifier.add(Convolution2D(64, (3, 3), padding = 'same', input_shape = (128, 128, 3), activation = 'relu'))\n",
        "                 input_shape=(40,1)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(MaxPooling1D(pool_size=(5)))\n",
        "\n",
        "\n",
        "model.add(Conv1D(256,8,padding='same',))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(MaxPooling1D(pool_size=(5)))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(256))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(256))\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "model.add(Dense(6))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "opt = tf.keras.optimizers.Adam(lr=0.0002)\n",
        "#opt = tf.keras.optimizers.RMSprop(lr=0.0001, rho=0.9, epsilon=1e-07, decay=0.0)\n",
        "#opt = tf.keras.optimizers.SGD(lr=0.001, momentum=0.0, decay=0.0, nesterov=False)"
      ],
      "metadata": {
        "id": "g74fXWVAC4Cr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e14501f-b6ee-47c2-a1d3-cc7f3076454c"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning:\n",
            "\n",
            "The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H6ukOxAGC_I4",
        "outputId": "89aa0906-19a6-415a-c564-c50c7569033d"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d (Conv1D)             (None, 40, 128)           1152      \n",
            "                                                                 \n",
            " activation (Activation)     (None, 40, 128)           0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 40, 128)           0         \n",
            "                                                                 \n",
            " max_pooling1d (MaxPooling1D  (None, 8, 128)           0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv1d_1 (Conv1D)           (None, 8, 256)            262400    \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 8, 256)            0         \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 8, 256)            0         \n",
            "                                                                 \n",
            " max_pooling1d_1 (MaxPooling  (None, 1, 256)           0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 256)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 256)               65792     \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 256)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 256)               65792     \n",
            "                                                                 \n",
            " activation_3 (Activation)   (None, 256)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 6)                 1542      \n",
            "                                                                 \n",
            " activation_4 (Activation)   (None, 6)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 396,678\n",
            "Trainable params: 396,678\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='sparse_categorical_crossentropy',\n",
        "              optimizer=opt,\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "AbMlLNk4DCBM"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#cnnhistory=model.fit(x_traincnn, y_train, batch_size=16, epochs=700, validation_data=(x_testcnn, y_test))\n",
        "cnnhistory=model.fit(x_traincnn, y_train, batch_size=16, epochs=500 , validation_data=(X_valid, y_valid))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RI1v2AuADFhy",
        "outputId": "62031a9f-b1dd-4ecb-f971-e312ae125ea0"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "104/104 [==============================] - 4s 9ms/step - loss: 3.9784 - accuracy: 0.1892 - val_loss: 1.8665 - val_accuracy: 0.2029\n",
            "Epoch 2/500\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 2.3255 - accuracy: 0.1977 - val_loss: 1.7990 - val_accuracy: 0.2077\n",
            "Epoch 3/500\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 2.0200 - accuracy: 0.2177 - val_loss: 1.6960 - val_accuracy: 0.2754\n",
            "Epoch 4/500\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 1.9485 - accuracy: 0.2122 - val_loss: 1.7351 - val_accuracy: 0.1932\n",
            "Epoch 5/500\n",
            "104/104 [==============================] - 1s 9ms/step - loss: 1.8539 - accuracy: 0.2231 - val_loss: 1.6752 - val_accuracy: 0.3188\n",
            "Epoch 6/500\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 1.8145 - accuracy: 0.2213 - val_loss: 1.6794 - val_accuracy: 0.2995\n",
            "Epoch 7/500\n",
            "104/104 [==============================] - 1s 9ms/step - loss: 1.8045 - accuracy: 0.2406 - val_loss: 1.7052 - val_accuracy: 0.2899\n",
            "Epoch 8/500\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 1.7469 - accuracy: 0.2437 - val_loss: 1.6990 - val_accuracy: 0.2126\n",
            "Epoch 9/500\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 1.7434 - accuracy: 0.2527 - val_loss: 1.6316 - val_accuracy: 0.3043\n",
            "Epoch 10/500\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 1.6933 - accuracy: 0.2860 - val_loss: 1.6199 - val_accuracy: 0.3140\n",
            "Epoch 11/500\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 1.6653 - accuracy: 0.3029 - val_loss: 1.6202 - val_accuracy: 0.2705\n",
            "Epoch 12/500\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 1.6581 - accuracy: 0.3011 - val_loss: 1.5551 - val_accuracy: 0.3816\n",
            "Epoch 13/500\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 1.6270 - accuracy: 0.3180 - val_loss: 1.6047 - val_accuracy: 0.3285\n",
            "Epoch 14/500\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 1.6389 - accuracy: 0.3180 - val_loss: 1.5663 - val_accuracy: 0.3237\n",
            "Epoch 15/500\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 1.6102 - accuracy: 0.3259 - val_loss: 1.5508 - val_accuracy: 0.3865\n",
            "Epoch 16/500\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 1.6050 - accuracy: 0.3271 - val_loss: 1.5148 - val_accuracy: 0.3720\n",
            "Epoch 17/500\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 1.5363 - accuracy: 0.3640 - val_loss: 1.4691 - val_accuracy: 0.3961\n",
            "Epoch 18/500\n",
            "104/104 [==============================] - 1s 9ms/step - loss: 1.5244 - accuracy: 0.3718 - val_loss: 1.4414 - val_accuracy: 0.4251\n",
            "Epoch 19/500\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 1.4933 - accuracy: 0.3688 - val_loss: 1.4164 - val_accuracy: 0.4734\n",
            "Epoch 20/500\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 1.4961 - accuracy: 0.3857 - val_loss: 1.4459 - val_accuracy: 0.4493\n",
            "Epoch 21/500\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 1.4427 - accuracy: 0.3936 - val_loss: 1.3633 - val_accuracy: 0.4589\n",
            "Epoch 22/500\n",
            "104/104 [==============================] - 1s 9ms/step - loss: 1.4270 - accuracy: 0.4057 - val_loss: 1.3375 - val_accuracy: 0.4686\n",
            "Epoch 23/500\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 1.4119 - accuracy: 0.4141 - val_loss: 1.3459 - val_accuracy: 0.4686\n",
            "Epoch 24/500\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 1.3789 - accuracy: 0.4311 - val_loss: 1.3726 - val_accuracy: 0.4155\n",
            "Epoch 25/500\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 1.3539 - accuracy: 0.4365 - val_loss: 1.3314 - val_accuracy: 0.5024\n",
            "Epoch 26/500\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 1.3183 - accuracy: 0.4752 - val_loss: 1.2392 - val_accuracy: 0.5411\n",
            "Epoch 27/500\n",
            "104/104 [==============================] - 1s 9ms/step - loss: 1.3050 - accuracy: 0.4541 - val_loss: 1.2115 - val_accuracy: 0.5700\n",
            "Epoch 28/500\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 1.2741 - accuracy: 0.4873 - val_loss: 1.2472 - val_accuracy: 0.5314\n",
            "Epoch 29/500\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 1.2602 - accuracy: 0.4728 - val_loss: 1.2263 - val_accuracy: 0.5507\n",
            "Epoch 30/500\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 1.2216 - accuracy: 0.4976 - val_loss: 1.1742 - val_accuracy: 0.5314\n",
            "Epoch 31/500\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 1.2267 - accuracy: 0.4849 - val_loss: 1.1588 - val_accuracy: 0.5894\n",
            "Epoch 32/500\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 1.2073 - accuracy: 0.5006 - val_loss: 1.0980 - val_accuracy: 0.6087\n",
            "Epoch 33/500\n",
            "104/104 [==============================] - 1s 9ms/step - loss: 1.1806 - accuracy: 0.5133 - val_loss: 1.0978 - val_accuracy: 0.5749\n",
            "Epoch 34/500\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 1.1631 - accuracy: 0.5212 - val_loss: 1.0854 - val_accuracy: 0.5797\n",
            "Epoch 35/500\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 1.1557 - accuracy: 0.5230 - val_loss: 1.0645 - val_accuracy: 0.6039\n",
            "Epoch 36/500\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 1.1502 - accuracy: 0.5351 - val_loss: 1.0637 - val_accuracy: 0.5749\n",
            "Epoch 37/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 1.1299 - accuracy: 0.5345 - val_loss: 1.0837 - val_accuracy: 0.5942\n",
            "Epoch 38/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.0937 - accuracy: 0.5641 - val_loss: 1.0666 - val_accuracy: 0.6039\n",
            "Epoch 39/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.1021 - accuracy: 0.5447 - val_loss: 1.0529 - val_accuracy: 0.6039\n",
            "Epoch 40/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0484 - accuracy: 0.5738 - val_loss: 0.9942 - val_accuracy: 0.6039\n",
            "Epoch 41/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.0429 - accuracy: 0.5520 - val_loss: 1.0143 - val_accuracy: 0.6039\n",
            "Epoch 42/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0063 - accuracy: 0.5840 - val_loss: 0.9923 - val_accuracy: 0.6232\n",
            "Epoch 43/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0067 - accuracy: 0.5901 - val_loss: 1.0089 - val_accuracy: 0.5894\n",
            "Epoch 44/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9918 - accuracy: 0.5973 - val_loss: 0.9516 - val_accuracy: 0.6232\n",
            "Epoch 45/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9945 - accuracy: 0.5871 - val_loss: 0.9823 - val_accuracy: 0.6425\n",
            "Epoch 46/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.9820 - accuracy: 0.6010 - val_loss: 0.9722 - val_accuracy: 0.6329\n",
            "Epoch 47/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.9991 - accuracy: 0.5961 - val_loss: 0.9425 - val_accuracy: 0.6232\n",
            "Epoch 48/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.9568 - accuracy: 0.6052 - val_loss: 0.9229 - val_accuracy: 0.6280\n",
            "Epoch 49/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.9485 - accuracy: 0.6131 - val_loss: 0.9095 - val_accuracy: 0.6232\n",
            "Epoch 50/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.9346 - accuracy: 0.6215 - val_loss: 0.9148 - val_accuracy: 0.6135\n",
            "Epoch 51/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9040 - accuracy: 0.6324 - val_loss: 0.9116 - val_accuracy: 0.6329\n",
            "Epoch 52/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.9026 - accuracy: 0.6312 - val_loss: 0.9327 - val_accuracy: 0.6715\n",
            "Epoch 53/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.9188 - accuracy: 0.6360 - val_loss: 0.9327 - val_accuracy: 0.6473\n",
            "Epoch 54/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.8875 - accuracy: 0.6475 - val_loss: 0.9538 - val_accuracy: 0.5990\n",
            "Epoch 55/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8953 - accuracy: 0.6372 - val_loss: 0.8724 - val_accuracy: 0.6618\n",
            "Epoch 56/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.8824 - accuracy: 0.6372 - val_loss: 0.8851 - val_accuracy: 0.6522\n",
            "Epoch 57/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.8683 - accuracy: 0.6499 - val_loss: 0.8618 - val_accuracy: 0.6667\n",
            "Epoch 58/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8282 - accuracy: 0.6747 - val_loss: 0.8834 - val_accuracy: 0.6280\n",
            "Epoch 59/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8439 - accuracy: 0.6602 - val_loss: 0.8458 - val_accuracy: 0.6908\n",
            "Epoch 60/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8353 - accuracy: 0.6705 - val_loss: 0.8298 - val_accuracy: 0.6957\n",
            "Epoch 61/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8329 - accuracy: 0.6626 - val_loss: 0.8808 - val_accuracy: 0.6425\n",
            "Epoch 62/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.8056 - accuracy: 0.6747 - val_loss: 0.8862 - val_accuracy: 0.6135\n",
            "Epoch 63/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.8256 - accuracy: 0.6735 - val_loss: 0.8547 - val_accuracy: 0.6570\n",
            "Epoch 64/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.7988 - accuracy: 0.6651 - val_loss: 0.8864 - val_accuracy: 0.6473\n",
            "Epoch 65/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.8180 - accuracy: 0.6657 - val_loss: 0.8466 - val_accuracy: 0.6667\n",
            "Epoch 66/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.7792 - accuracy: 0.6965 - val_loss: 0.8297 - val_accuracy: 0.6522\n",
            "Epoch 67/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.7807 - accuracy: 0.6917 - val_loss: 0.8449 - val_accuracy: 0.6329\n",
            "Epoch 68/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.7463 - accuracy: 0.7025 - val_loss: 0.8201 - val_accuracy: 0.6957\n",
            "Epoch 69/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7763 - accuracy: 0.6971 - val_loss: 0.8701 - val_accuracy: 0.6425\n",
            "Epoch 70/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.7366 - accuracy: 0.7050 - val_loss: 0.8294 - val_accuracy: 0.6812\n",
            "Epoch 71/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.7496 - accuracy: 0.6832 - val_loss: 0.8211 - val_accuracy: 0.6763\n",
            "Epoch 72/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.7305 - accuracy: 0.7025 - val_loss: 0.8221 - val_accuracy: 0.6715\n",
            "Epoch 73/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.7414 - accuracy: 0.6947 - val_loss: 0.7959 - val_accuracy: 0.6860\n",
            "Epoch 74/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.7438 - accuracy: 0.7013 - val_loss: 0.8432 - val_accuracy: 0.6618\n",
            "Epoch 75/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.7241 - accuracy: 0.7170 - val_loss: 0.8297 - val_accuracy: 0.6908\n",
            "Epoch 76/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.7296 - accuracy: 0.7050 - val_loss: 0.7991 - val_accuracy: 0.6908\n",
            "Epoch 77/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.6923 - accuracy: 0.7304 - val_loss: 0.8158 - val_accuracy: 0.6715\n",
            "Epoch 78/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.7039 - accuracy: 0.7261 - val_loss: 0.7953 - val_accuracy: 0.7053\n",
            "Epoch 79/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6968 - accuracy: 0.7164 - val_loss: 0.8380 - val_accuracy: 0.6667\n",
            "Epoch 80/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.6864 - accuracy: 0.7213 - val_loss: 0.8098 - val_accuracy: 0.6715\n",
            "Epoch 81/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.6752 - accuracy: 0.7328 - val_loss: 0.7698 - val_accuracy: 0.7005\n",
            "Epoch 82/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.6535 - accuracy: 0.7340 - val_loss: 0.7891 - val_accuracy: 0.6957\n",
            "Epoch 83/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.6853 - accuracy: 0.7255 - val_loss: 0.8070 - val_accuracy: 0.6763\n",
            "Epoch 84/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6338 - accuracy: 0.7388 - val_loss: 0.7597 - val_accuracy: 0.6908\n",
            "Epoch 85/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6471 - accuracy: 0.7430 - val_loss: 0.7660 - val_accuracy: 0.6812\n",
            "Epoch 86/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.6112 - accuracy: 0.7533 - val_loss: 0.7727 - val_accuracy: 0.6908\n",
            "Epoch 87/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6328 - accuracy: 0.7491 - val_loss: 0.7652 - val_accuracy: 0.6908\n",
            "Epoch 88/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6126 - accuracy: 0.7563 - val_loss: 0.7597 - val_accuracy: 0.6957\n",
            "Epoch 89/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.6175 - accuracy: 0.7533 - val_loss: 0.7925 - val_accuracy: 0.6812\n",
            "Epoch 90/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6010 - accuracy: 0.7551 - val_loss: 0.8113 - val_accuracy: 0.6618\n",
            "Epoch 91/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.5807 - accuracy: 0.7733 - val_loss: 0.7444 - val_accuracy: 0.7198\n",
            "Epoch 92/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6151 - accuracy: 0.7515 - val_loss: 0.7574 - val_accuracy: 0.7005\n",
            "Epoch 93/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.5727 - accuracy: 0.7836 - val_loss: 0.7562 - val_accuracy: 0.6860\n",
            "Epoch 94/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.5747 - accuracy: 0.7690 - val_loss: 0.7673 - val_accuracy: 0.6812\n",
            "Epoch 95/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.5695 - accuracy: 0.7769 - val_loss: 0.7380 - val_accuracy: 0.7150\n",
            "Epoch 96/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.5573 - accuracy: 0.7884 - val_loss: 0.6976 - val_accuracy: 0.7681\n",
            "Epoch 97/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.5871 - accuracy: 0.7696 - val_loss: 0.7583 - val_accuracy: 0.6812\n",
            "Epoch 98/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5263 - accuracy: 0.7866 - val_loss: 0.7136 - val_accuracy: 0.7343\n",
            "Epoch 99/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.5114 - accuracy: 0.8023 - val_loss: 0.7142 - val_accuracy: 0.7488\n",
            "Epoch 100/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5646 - accuracy: 0.7842 - val_loss: 0.7433 - val_accuracy: 0.7101\n",
            "Epoch 101/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.5450 - accuracy: 0.7878 - val_loss: 0.7038 - val_accuracy: 0.7343\n",
            "Epoch 102/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.5278 - accuracy: 0.7981 - val_loss: 0.6937 - val_accuracy: 0.7198\n",
            "Epoch 103/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.5168 - accuracy: 0.7969 - val_loss: 0.7636 - val_accuracy: 0.6763\n",
            "Epoch 104/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.5128 - accuracy: 0.7999 - val_loss: 0.7273 - val_accuracy: 0.7101\n",
            "Epoch 105/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.4901 - accuracy: 0.8083 - val_loss: 0.7331 - val_accuracy: 0.7005\n",
            "Epoch 106/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.4987 - accuracy: 0.8138 - val_loss: 0.7301 - val_accuracy: 0.6957\n",
            "Epoch 107/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4987 - accuracy: 0.8041 - val_loss: 0.7576 - val_accuracy: 0.6860\n",
            "Epoch 108/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.4925 - accuracy: 0.8083 - val_loss: 0.7146 - val_accuracy: 0.7246\n",
            "Epoch 109/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.4845 - accuracy: 0.8089 - val_loss: 0.7554 - val_accuracy: 0.6957\n",
            "Epoch 110/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.4922 - accuracy: 0.8096 - val_loss: 0.7206 - val_accuracy: 0.7053\n",
            "Epoch 111/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.4654 - accuracy: 0.8241 - val_loss: 0.7468 - val_accuracy: 0.7005\n",
            "Epoch 112/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.4647 - accuracy: 0.8222 - val_loss: 0.7406 - val_accuracy: 0.7053\n",
            "Epoch 113/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.4709 - accuracy: 0.8210 - val_loss: 0.7455 - val_accuracy: 0.7150\n",
            "Epoch 114/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.4573 - accuracy: 0.8271 - val_loss: 0.7231 - val_accuracy: 0.7101\n",
            "Epoch 115/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.4948 - accuracy: 0.8035 - val_loss: 0.7611 - val_accuracy: 0.6763\n",
            "Epoch 116/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.4619 - accuracy: 0.8216 - val_loss: 0.6834 - val_accuracy: 0.7536\n",
            "Epoch 117/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.4476 - accuracy: 0.8325 - val_loss: 0.6875 - val_accuracy: 0.7295\n",
            "Epoch 118/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.4360 - accuracy: 0.8337 - val_loss: 0.6817 - val_accuracy: 0.7150\n",
            "Epoch 119/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.4209 - accuracy: 0.8458 - val_loss: 0.7106 - val_accuracy: 0.7198\n",
            "Epoch 120/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.4397 - accuracy: 0.8247 - val_loss: 0.7097 - val_accuracy: 0.6957\n",
            "Epoch 121/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.4252 - accuracy: 0.8307 - val_loss: 0.6369 - val_accuracy: 0.7440\n",
            "Epoch 122/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.4263 - accuracy: 0.8301 - val_loss: 0.6411 - val_accuracy: 0.7343\n",
            "Epoch 123/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.3837 - accuracy: 0.8531 - val_loss: 0.6655 - val_accuracy: 0.7295\n",
            "Epoch 124/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.4075 - accuracy: 0.8349 - val_loss: 0.6681 - val_accuracy: 0.7101\n",
            "Epoch 125/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.3928 - accuracy: 0.8428 - val_loss: 0.6869 - val_accuracy: 0.7150\n",
            "Epoch 126/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.4056 - accuracy: 0.8470 - val_loss: 0.6192 - val_accuracy: 0.7633\n",
            "Epoch 127/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.4308 - accuracy: 0.8440 - val_loss: 0.6483 - val_accuracy: 0.7440\n",
            "Epoch 128/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.3789 - accuracy: 0.8507 - val_loss: 0.6780 - val_accuracy: 0.7343\n",
            "Epoch 129/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.3986 - accuracy: 0.8428 - val_loss: 0.6859 - val_accuracy: 0.7005\n",
            "Epoch 130/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.3956 - accuracy: 0.8507 - val_loss: 0.7214 - val_accuracy: 0.7246\n",
            "Epoch 131/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.3899 - accuracy: 0.8476 - val_loss: 0.6456 - val_accuracy: 0.7391\n",
            "Epoch 132/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.3755 - accuracy: 0.8609 - val_loss: 0.6753 - val_accuracy: 0.7053\n",
            "Epoch 133/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.3670 - accuracy: 0.8543 - val_loss: 0.6660 - val_accuracy: 0.7488\n",
            "Epoch 134/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.3700 - accuracy: 0.8549 - val_loss: 0.6530 - val_accuracy: 0.7488\n",
            "Epoch 135/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.3645 - accuracy: 0.8597 - val_loss: 0.6299 - val_accuracy: 0.7633\n",
            "Epoch 136/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.3615 - accuracy: 0.8597 - val_loss: 0.6350 - val_accuracy: 0.7440\n",
            "Epoch 137/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.3527 - accuracy: 0.8585 - val_loss: 0.7194 - val_accuracy: 0.7343\n",
            "Epoch 138/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.3522 - accuracy: 0.8585 - val_loss: 0.6668 - val_accuracy: 0.7198\n",
            "Epoch 139/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3371 - accuracy: 0.8706 - val_loss: 0.6410 - val_accuracy: 0.7488\n",
            "Epoch 140/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.3422 - accuracy: 0.8634 - val_loss: 0.6457 - val_accuracy: 0.7585\n",
            "Epoch 141/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3497 - accuracy: 0.8670 - val_loss: 0.6659 - val_accuracy: 0.7536\n",
            "Epoch 142/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.3554 - accuracy: 0.8597 - val_loss: 0.6461 - val_accuracy: 0.7440\n",
            "Epoch 143/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.3192 - accuracy: 0.8815 - val_loss: 0.7503 - val_accuracy: 0.7101\n",
            "Epoch 144/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.3349 - accuracy: 0.8682 - val_loss: 0.6272 - val_accuracy: 0.7681\n",
            "Epoch 145/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.3281 - accuracy: 0.8712 - val_loss: 0.7065 - val_accuracy: 0.7295\n",
            "Epoch 146/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.3159 - accuracy: 0.8803 - val_loss: 0.6726 - val_accuracy: 0.7391\n",
            "Epoch 147/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.3119 - accuracy: 0.8888 - val_loss: 0.6768 - val_accuracy: 0.7488\n",
            "Epoch 148/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.3272 - accuracy: 0.8724 - val_loss: 0.6256 - val_accuracy: 0.7585\n",
            "Epoch 149/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.3282 - accuracy: 0.8736 - val_loss: 0.6523 - val_accuracy: 0.7633\n",
            "Epoch 150/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3144 - accuracy: 0.8791 - val_loss: 0.6289 - val_accuracy: 0.7391\n",
            "Epoch 151/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.3028 - accuracy: 0.8845 - val_loss: 0.5792 - val_accuracy: 0.7971\n",
            "Epoch 152/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.3018 - accuracy: 0.8827 - val_loss: 0.6357 - val_accuracy: 0.7681\n",
            "Epoch 153/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.3162 - accuracy: 0.8742 - val_loss: 0.6787 - val_accuracy: 0.7488\n",
            "Epoch 154/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.2867 - accuracy: 0.8894 - val_loss: 0.7229 - val_accuracy: 0.7343\n",
            "Epoch 155/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.3139 - accuracy: 0.8827 - val_loss: 0.6833 - val_accuracy: 0.7391\n",
            "Epoch 156/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.3080 - accuracy: 0.8803 - val_loss: 0.6780 - val_accuracy: 0.7440\n",
            "Epoch 157/500\n",
            "104/104 [==============================] - 1s 9ms/step - loss: 0.2886 - accuracy: 0.8851 - val_loss: 0.6216 - val_accuracy: 0.7633\n",
            "Epoch 158/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2864 - accuracy: 0.8942 - val_loss: 0.6283 - val_accuracy: 0.7488\n",
            "Epoch 159/500\n",
            "104/104 [==============================] - 1s 10ms/step - loss: 0.2644 - accuracy: 0.9075 - val_loss: 0.5783 - val_accuracy: 0.7874\n",
            "Epoch 160/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2604 - accuracy: 0.9008 - val_loss: 0.6334 - val_accuracy: 0.7874\n",
            "Epoch 161/500\n",
            "104/104 [==============================] - 1s 9ms/step - loss: 0.2752 - accuracy: 0.8954 - val_loss: 0.6350 - val_accuracy: 0.7729\n",
            "Epoch 162/500\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.2663 - accuracy: 0.9045 - val_loss: 0.6171 - val_accuracy: 0.7633\n",
            "Epoch 163/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.2799 - accuracy: 0.8948 - val_loss: 0.6847 - val_accuracy: 0.7343\n",
            "Epoch 164/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.2719 - accuracy: 0.8972 - val_loss: 0.6359 - val_accuracy: 0.7826\n",
            "Epoch 165/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.2947 - accuracy: 0.8863 - val_loss: 0.6557 - val_accuracy: 0.7391\n",
            "Epoch 166/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.2870 - accuracy: 0.8930 - val_loss: 0.6862 - val_accuracy: 0.7488\n",
            "Epoch 167/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.2817 - accuracy: 0.8930 - val_loss: 0.6146 - val_accuracy: 0.7826\n",
            "Epoch 168/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.2450 - accuracy: 0.9002 - val_loss: 0.7076 - val_accuracy: 0.7391\n",
            "Epoch 169/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.2550 - accuracy: 0.9033 - val_loss: 0.6282 - val_accuracy: 0.7778\n",
            "Epoch 170/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.2612 - accuracy: 0.9015 - val_loss: 0.5825 - val_accuracy: 0.7729\n",
            "Epoch 171/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.2368 - accuracy: 0.9148 - val_loss: 0.6006 - val_accuracy: 0.7778\n",
            "Epoch 172/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.2225 - accuracy: 0.9178 - val_loss: 0.6159 - val_accuracy: 0.7778\n",
            "Epoch 173/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.2266 - accuracy: 0.9111 - val_loss: 0.6397 - val_accuracy: 0.7440\n",
            "Epoch 174/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.2609 - accuracy: 0.8984 - val_loss: 0.6372 - val_accuracy: 0.7729\n",
            "Epoch 175/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.2348 - accuracy: 0.9166 - val_loss: 0.6467 - val_accuracy: 0.7681\n",
            "Epoch 176/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2557 - accuracy: 0.9015 - val_loss: 0.5963 - val_accuracy: 0.7633\n",
            "Epoch 177/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.2465 - accuracy: 0.9117 - val_loss: 0.5983 - val_accuracy: 0.7971\n",
            "Epoch 178/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.2412 - accuracy: 0.9081 - val_loss: 0.6056 - val_accuracy: 0.7391\n",
            "Epoch 179/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2180 - accuracy: 0.9184 - val_loss: 0.6439 - val_accuracy: 0.7536\n",
            "Epoch 180/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2139 - accuracy: 0.9208 - val_loss: 0.6580 - val_accuracy: 0.7729\n",
            "Epoch 181/500\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.2342 - accuracy: 0.9093 - val_loss: 0.6095 - val_accuracy: 0.7729\n",
            "Epoch 182/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2083 - accuracy: 0.9196 - val_loss: 0.6781 - val_accuracy: 0.7343\n",
            "Epoch 183/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2096 - accuracy: 0.9166 - val_loss: 0.6893 - val_accuracy: 0.7633\n",
            "Epoch 184/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2115 - accuracy: 0.9208 - val_loss: 0.6046 - val_accuracy: 0.7681\n",
            "Epoch 185/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2327 - accuracy: 0.9069 - val_loss: 0.6632 - val_accuracy: 0.7729\n",
            "Epoch 186/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.2215 - accuracy: 0.9196 - val_loss: 0.6621 - val_accuracy: 0.7729\n",
            "Epoch 187/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.2136 - accuracy: 0.9148 - val_loss: 0.6697 - val_accuracy: 0.7826\n",
            "Epoch 188/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.2366 - accuracy: 0.9045 - val_loss: 0.5897 - val_accuracy: 0.8019\n",
            "Epoch 189/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.2301 - accuracy: 0.9093 - val_loss: 0.5918 - val_accuracy: 0.7826\n",
            "Epoch 190/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.2116 - accuracy: 0.9160 - val_loss: 0.6788 - val_accuracy: 0.7633\n",
            "Epoch 191/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.2009 - accuracy: 0.9208 - val_loss: 0.6073 - val_accuracy: 0.7681\n",
            "Epoch 192/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.2283 - accuracy: 0.9117 - val_loss: 0.6052 - val_accuracy: 0.8068\n",
            "Epoch 193/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.2048 - accuracy: 0.9250 - val_loss: 0.6551 - val_accuracy: 0.7729\n",
            "Epoch 194/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.1697 - accuracy: 0.9407 - val_loss: 0.6859 - val_accuracy: 0.7729\n",
            "Epoch 195/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.2246 - accuracy: 0.9178 - val_loss: 0.5931 - val_accuracy: 0.7874\n",
            "Epoch 196/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.1759 - accuracy: 0.9359 - val_loss: 0.7037 - val_accuracy: 0.7585\n",
            "Epoch 197/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.1893 - accuracy: 0.9226 - val_loss: 0.6181 - val_accuracy: 0.7778\n",
            "Epoch 198/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2119 - accuracy: 0.9141 - val_loss: 0.5977 - val_accuracy: 0.7923\n",
            "Epoch 199/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.2203 - accuracy: 0.9154 - val_loss: 0.6261 - val_accuracy: 0.7633\n",
            "Epoch 200/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.2051 - accuracy: 0.9250 - val_loss: 0.6959 - val_accuracy: 0.7778\n",
            "Epoch 201/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1937 - accuracy: 0.9299 - val_loss: 0.6500 - val_accuracy: 0.7729\n",
            "Epoch 202/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.2129 - accuracy: 0.9196 - val_loss: 0.6264 - val_accuracy: 0.7826\n",
            "Epoch 203/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.1678 - accuracy: 0.9401 - val_loss: 0.6024 - val_accuracy: 0.7729\n",
            "Epoch 204/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1702 - accuracy: 0.9377 - val_loss: 0.6408 - val_accuracy: 0.7923\n",
            "Epoch 205/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1938 - accuracy: 0.9274 - val_loss: 0.7191 - val_accuracy: 0.7488\n",
            "Epoch 206/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.2074 - accuracy: 0.9250 - val_loss: 0.6791 - val_accuracy: 0.7440\n",
            "Epoch 207/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.1872 - accuracy: 0.9377 - val_loss: 0.6923 - val_accuracy: 0.7536\n",
            "Epoch 208/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.2050 - accuracy: 0.9220 - val_loss: 0.7315 - val_accuracy: 0.7391\n",
            "Epoch 209/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.2100 - accuracy: 0.9166 - val_loss: 0.7082 - val_accuracy: 0.7585\n",
            "Epoch 210/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.1956 - accuracy: 0.9250 - val_loss: 0.6556 - val_accuracy: 0.7729\n",
            "Epoch 211/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.1802 - accuracy: 0.9299 - val_loss: 0.6270 - val_accuracy: 0.7923\n",
            "Epoch 212/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.1781 - accuracy: 0.9414 - val_loss: 0.6049 - val_accuracy: 0.8164\n",
            "Epoch 213/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1519 - accuracy: 0.9401 - val_loss: 0.7474 - val_accuracy: 0.7488\n",
            "Epoch 214/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.1723 - accuracy: 0.9389 - val_loss: 0.6297 - val_accuracy: 0.8019\n",
            "Epoch 215/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.1649 - accuracy: 0.9371 - val_loss: 0.6959 - val_accuracy: 0.7729\n",
            "Epoch 216/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.1723 - accuracy: 0.9371 - val_loss: 0.6314 - val_accuracy: 0.8116\n",
            "Epoch 217/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.1638 - accuracy: 0.9407 - val_loss: 0.7024 - val_accuracy: 0.7681\n",
            "Epoch 218/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.1799 - accuracy: 0.9365 - val_loss: 0.6435 - val_accuracy: 0.7778\n",
            "Epoch 219/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.1706 - accuracy: 0.9383 - val_loss: 0.7663 - val_accuracy: 0.7536\n",
            "Epoch 220/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.1698 - accuracy: 0.9407 - val_loss: 0.6295 - val_accuracy: 0.7874\n",
            "Epoch 221/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.1709 - accuracy: 0.9341 - val_loss: 0.6716 - val_accuracy: 0.7681\n",
            "Epoch 222/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1950 - accuracy: 0.9281 - val_loss: 0.6199 - val_accuracy: 0.7923\n",
            "Epoch 223/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.1775 - accuracy: 0.9341 - val_loss: 0.6671 - val_accuracy: 0.7826\n",
            "Epoch 224/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1590 - accuracy: 0.9377 - val_loss: 0.6739 - val_accuracy: 0.7633\n",
            "Epoch 225/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.1792 - accuracy: 0.9323 - val_loss: 0.7041 - val_accuracy: 0.8019\n",
            "Epoch 226/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.1714 - accuracy: 0.9395 - val_loss: 0.6745 - val_accuracy: 0.7971\n",
            "Epoch 227/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.1424 - accuracy: 0.9480 - val_loss: 0.6137 - val_accuracy: 0.8019\n",
            "Epoch 228/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.1403 - accuracy: 0.9516 - val_loss: 0.6861 - val_accuracy: 0.7536\n",
            "Epoch 229/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.1656 - accuracy: 0.9395 - val_loss: 0.6388 - val_accuracy: 0.7971\n",
            "Epoch 230/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1429 - accuracy: 0.9438 - val_loss: 0.6798 - val_accuracy: 0.7874\n",
            "Epoch 231/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.1243 - accuracy: 0.9498 - val_loss: 0.6610 - val_accuracy: 0.7874\n",
            "Epoch 232/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.1480 - accuracy: 0.9498 - val_loss: 0.6595 - val_accuracy: 0.7826\n",
            "Epoch 233/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.1902 - accuracy: 0.9341 - val_loss: 0.6372 - val_accuracy: 0.7874\n",
            "Epoch 234/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.1493 - accuracy: 0.9522 - val_loss: 0.7170 - val_accuracy: 0.7488\n",
            "Epoch 235/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.1493 - accuracy: 0.9468 - val_loss: 0.6429 - val_accuracy: 0.7633\n",
            "Epoch 236/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.1359 - accuracy: 0.9504 - val_loss: 0.6459 - val_accuracy: 0.7971\n",
            "Epoch 237/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.1607 - accuracy: 0.9359 - val_loss: 0.6536 - val_accuracy: 0.7681\n",
            "Epoch 238/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.1464 - accuracy: 0.9395 - val_loss: 0.6948 - val_accuracy: 0.7488\n",
            "Epoch 239/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.1552 - accuracy: 0.9438 - val_loss: 0.5714 - val_accuracy: 0.8068\n",
            "Epoch 240/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.1383 - accuracy: 0.9510 - val_loss: 0.6752 - val_accuracy: 0.7681\n",
            "Epoch 241/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.1613 - accuracy: 0.9407 - val_loss: 0.7366 - val_accuracy: 0.7343\n",
            "Epoch 242/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.1385 - accuracy: 0.9504 - val_loss: 0.6349 - val_accuracy: 0.8164\n",
            "Epoch 243/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.1730 - accuracy: 0.9444 - val_loss: 0.6271 - val_accuracy: 0.8019\n",
            "Epoch 244/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.1480 - accuracy: 0.9492 - val_loss: 0.6485 - val_accuracy: 0.7536\n",
            "Epoch 245/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.1594 - accuracy: 0.9438 - val_loss: 0.6314 - val_accuracy: 0.8019\n",
            "Epoch 246/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.1513 - accuracy: 0.9456 - val_loss: 0.5845 - val_accuracy: 0.8406\n",
            "Epoch 247/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.1487 - accuracy: 0.9474 - val_loss: 0.6790 - val_accuracy: 0.8019\n",
            "Epoch 248/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.1619 - accuracy: 0.9456 - val_loss: 0.6966 - val_accuracy: 0.8116\n",
            "Epoch 249/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.1527 - accuracy: 0.9456 - val_loss: 0.7639 - val_accuracy: 0.7488\n",
            "Epoch 250/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.1660 - accuracy: 0.9395 - val_loss: 0.7193 - val_accuracy: 0.7585\n",
            "Epoch 251/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.1443 - accuracy: 0.9444 - val_loss: 0.6633 - val_accuracy: 0.7874\n",
            "Epoch 252/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.1353 - accuracy: 0.9547 - val_loss: 0.6995 - val_accuracy: 0.7778\n",
            "Epoch 253/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.1558 - accuracy: 0.9456 - val_loss: 0.6866 - val_accuracy: 0.7729\n",
            "Epoch 254/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1675 - accuracy: 0.9395 - val_loss: 0.6887 - val_accuracy: 0.7633\n",
            "Epoch 255/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.1413 - accuracy: 0.9438 - val_loss: 0.6458 - val_accuracy: 0.7923\n",
            "Epoch 256/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.1135 - accuracy: 0.9613 - val_loss: 0.7060 - val_accuracy: 0.7536\n",
            "Epoch 257/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1322 - accuracy: 0.9534 - val_loss: 0.6734 - val_accuracy: 0.7729\n",
            "Epoch 258/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.1348 - accuracy: 0.9504 - val_loss: 0.6509 - val_accuracy: 0.8019\n",
            "Epoch 259/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.1114 - accuracy: 0.9571 - val_loss: 0.6542 - val_accuracy: 0.8068\n",
            "Epoch 260/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1434 - accuracy: 0.9516 - val_loss: 0.7010 - val_accuracy: 0.7874\n",
            "Epoch 261/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.1290 - accuracy: 0.9534 - val_loss: 0.6407 - val_accuracy: 0.8116\n",
            "Epoch 262/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.1388 - accuracy: 0.9480 - val_loss: 0.7033 - val_accuracy: 0.7874\n",
            "Epoch 263/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.1548 - accuracy: 0.9395 - val_loss: 0.8139 - val_accuracy: 0.7681\n",
            "Epoch 264/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1338 - accuracy: 0.9516 - val_loss: 0.6447 - val_accuracy: 0.7778\n",
            "Epoch 265/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1440 - accuracy: 0.9510 - val_loss: 0.6076 - val_accuracy: 0.8116\n",
            "Epoch 266/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.1371 - accuracy: 0.9522 - val_loss: 0.6248 - val_accuracy: 0.7923\n",
            "Epoch 267/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1331 - accuracy: 0.9510 - val_loss: 0.6389 - val_accuracy: 0.7923\n",
            "Epoch 268/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.1153 - accuracy: 0.9516 - val_loss: 0.6997 - val_accuracy: 0.7585\n",
            "Epoch 269/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1102 - accuracy: 0.9613 - val_loss: 0.7156 - val_accuracy: 0.7826\n",
            "Epoch 270/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1253 - accuracy: 0.9559 - val_loss: 0.7179 - val_accuracy: 0.7440\n",
            "Epoch 271/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.1158 - accuracy: 0.9565 - val_loss: 0.6538 - val_accuracy: 0.7874\n",
            "Epoch 272/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.1150 - accuracy: 0.9571 - val_loss: 0.6384 - val_accuracy: 0.8019\n",
            "Epoch 273/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1227 - accuracy: 0.9553 - val_loss: 0.6206 - val_accuracy: 0.8068\n",
            "Epoch 274/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1342 - accuracy: 0.9522 - val_loss: 0.6038 - val_accuracy: 0.8261\n",
            "Epoch 275/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.1336 - accuracy: 0.9553 - val_loss: 0.7378 - val_accuracy: 0.7585\n",
            "Epoch 276/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1494 - accuracy: 0.9450 - val_loss: 0.6696 - val_accuracy: 0.7923\n",
            "Epoch 277/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1386 - accuracy: 0.9553 - val_loss: 0.6712 - val_accuracy: 0.7923\n",
            "Epoch 278/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.1344 - accuracy: 0.9468 - val_loss: 0.6400 - val_accuracy: 0.7826\n",
            "Epoch 279/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.1513 - accuracy: 0.9480 - val_loss: 0.6764 - val_accuracy: 0.7488\n",
            "Epoch 280/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1053 - accuracy: 0.9607 - val_loss: 0.6486 - val_accuracy: 0.8019\n",
            "Epoch 281/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1234 - accuracy: 0.9601 - val_loss: 0.7527 - val_accuracy: 0.7729\n",
            "Epoch 282/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1320 - accuracy: 0.9534 - val_loss: 0.6653 - val_accuracy: 0.7633\n",
            "Epoch 283/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1018 - accuracy: 0.9583 - val_loss: 0.6188 - val_accuracy: 0.8164\n",
            "Epoch 284/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0896 - accuracy: 0.9667 - val_loss: 0.6366 - val_accuracy: 0.7778\n",
            "Epoch 285/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.0915 - accuracy: 0.9710 - val_loss: 0.6167 - val_accuracy: 0.7874\n",
            "Epoch 286/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0913 - accuracy: 0.9631 - val_loss: 0.6351 - val_accuracy: 0.8068\n",
            "Epoch 287/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1186 - accuracy: 0.9583 - val_loss: 0.7164 - val_accuracy: 0.7729\n",
            "Epoch 288/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.1070 - accuracy: 0.9589 - val_loss: 0.6673 - val_accuracy: 0.7778\n",
            "Epoch 289/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.1223 - accuracy: 0.9528 - val_loss: 0.6836 - val_accuracy: 0.7826\n",
            "Epoch 290/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.1641 - accuracy: 0.9407 - val_loss: 0.7491 - val_accuracy: 0.7585\n",
            "Epoch 291/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0995 - accuracy: 0.9643 - val_loss: 0.6902 - val_accuracy: 0.7923\n",
            "Epoch 292/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.1068 - accuracy: 0.9643 - val_loss: 0.6866 - val_accuracy: 0.7923\n",
            "Epoch 293/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.1168 - accuracy: 0.9595 - val_loss: 0.6912 - val_accuracy: 0.8309\n",
            "Epoch 294/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1136 - accuracy: 0.9595 - val_loss: 0.6527 - val_accuracy: 0.8116\n",
            "Epoch 295/500\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 0.1151 - accuracy: 0.9565 - val_loss: 0.6396 - val_accuracy: 0.7681\n",
            "Epoch 296/500\n",
            "104/104 [==============================] - 1s 9ms/step - loss: 0.1049 - accuracy: 0.9710 - val_loss: 0.6358 - val_accuracy: 0.8116\n",
            "Epoch 297/500\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.1139 - accuracy: 0.9559 - val_loss: 0.6573 - val_accuracy: 0.7681\n",
            "Epoch 298/500\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 0.1198 - accuracy: 0.9510 - val_loss: 0.6604 - val_accuracy: 0.8019\n",
            "Epoch 299/500\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 0.0844 - accuracy: 0.9698 - val_loss: 0.6655 - val_accuracy: 0.8213\n",
            "Epoch 300/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1000 - accuracy: 0.9655 - val_loss: 0.6616 - val_accuracy: 0.7874\n",
            "Epoch 301/500\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 0.1201 - accuracy: 0.9547 - val_loss: 0.6358 - val_accuracy: 0.7971\n",
            "Epoch 302/500\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 0.0943 - accuracy: 0.9655 - val_loss: 0.7694 - val_accuracy: 0.7826\n",
            "Epoch 303/500\n",
            "104/104 [==============================] - 1s 9ms/step - loss: 0.1230 - accuracy: 0.9583 - val_loss: 0.7531 - val_accuracy: 0.7729\n",
            "Epoch 304/500\n",
            "104/104 [==============================] - 1s 9ms/step - loss: 0.1239 - accuracy: 0.9541 - val_loss: 0.6335 - val_accuracy: 0.7874\n",
            "Epoch 305/500\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 0.1436 - accuracy: 0.9474 - val_loss: 0.6394 - val_accuracy: 0.7923\n",
            "Epoch 306/500\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 0.1018 - accuracy: 0.9643 - val_loss: 0.6067 - val_accuracy: 0.7874\n",
            "Epoch 307/500\n",
            "104/104 [==============================] - 1s 9ms/step - loss: 0.1079 - accuracy: 0.9571 - val_loss: 0.6335 - val_accuracy: 0.7729\n",
            "Epoch 308/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.0931 - accuracy: 0.9655 - val_loss: 0.6058 - val_accuracy: 0.7729\n",
            "Epoch 309/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.1084 - accuracy: 0.9661 - val_loss: 0.6469 - val_accuracy: 0.7971\n",
            "Epoch 310/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.1088 - accuracy: 0.9583 - val_loss: 0.7031 - val_accuracy: 0.7826\n",
            "Epoch 311/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1080 - accuracy: 0.9601 - val_loss: 0.7366 - val_accuracy: 0.7923\n",
            "Epoch 312/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1032 - accuracy: 0.9661 - val_loss: 0.6505 - val_accuracy: 0.8213\n",
            "Epoch 313/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0788 - accuracy: 0.9698 - val_loss: 0.6151 - val_accuracy: 0.8019\n",
            "Epoch 314/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0951 - accuracy: 0.9667 - val_loss: 0.6317 - val_accuracy: 0.7778\n",
            "Epoch 315/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.0773 - accuracy: 0.9710 - val_loss: 0.7243 - val_accuracy: 0.7536\n",
            "Epoch 316/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1105 - accuracy: 0.9589 - val_loss: 0.7142 - val_accuracy: 0.7923\n",
            "Epoch 317/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1214 - accuracy: 0.9577 - val_loss: 0.6661 - val_accuracy: 0.7923\n",
            "Epoch 318/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.1009 - accuracy: 0.9619 - val_loss: 0.6467 - val_accuracy: 0.7923\n",
            "Epoch 319/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.1030 - accuracy: 0.9655 - val_loss: 0.6705 - val_accuracy: 0.7826\n",
            "Epoch 320/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0931 - accuracy: 0.9686 - val_loss: 0.7314 - val_accuracy: 0.7585\n",
            "Epoch 321/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.1031 - accuracy: 0.9577 - val_loss: 0.6935 - val_accuracy: 0.7874\n",
            "Epoch 322/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.0976 - accuracy: 0.9655 - val_loss: 0.6744 - val_accuracy: 0.7488\n",
            "Epoch 323/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.1212 - accuracy: 0.9528 - val_loss: 0.6228 - val_accuracy: 0.7874\n",
            "Epoch 324/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1079 - accuracy: 0.9559 - val_loss: 0.6026 - val_accuracy: 0.7971\n",
            "Epoch 325/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1219 - accuracy: 0.9541 - val_loss: 0.7154 - val_accuracy: 0.7874\n",
            "Epoch 326/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1088 - accuracy: 0.9607 - val_loss: 0.7004 - val_accuracy: 0.7681\n",
            "Epoch 327/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.0971 - accuracy: 0.9655 - val_loss: 0.6802 - val_accuracy: 0.8019\n",
            "Epoch 328/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.0959 - accuracy: 0.9667 - val_loss: 0.7298 - val_accuracy: 0.7729\n",
            "Epoch 329/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0868 - accuracy: 0.9667 - val_loss: 0.7323 - val_accuracy: 0.7681\n",
            "Epoch 330/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.0876 - accuracy: 0.9680 - val_loss: 0.6306 - val_accuracy: 0.8019\n",
            "Epoch 331/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0770 - accuracy: 0.9692 - val_loss: 0.6245 - val_accuracy: 0.8213\n",
            "Epoch 332/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0983 - accuracy: 0.9667 - val_loss: 0.6124 - val_accuracy: 0.8068\n",
            "Epoch 333/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.0940 - accuracy: 0.9716 - val_loss: 0.6188 - val_accuracy: 0.7874\n",
            "Epoch 334/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1381 - accuracy: 0.9516 - val_loss: 0.6530 - val_accuracy: 0.8019\n",
            "Epoch 335/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.1036 - accuracy: 0.9643 - val_loss: 0.6465 - val_accuracy: 0.7874\n",
            "Epoch 336/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0945 - accuracy: 0.9674 - val_loss: 0.6540 - val_accuracy: 0.8068\n",
            "Epoch 337/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.1107 - accuracy: 0.9649 - val_loss: 0.6439 - val_accuracy: 0.7826\n",
            "Epoch 338/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.1317 - accuracy: 0.9486 - val_loss: 0.6847 - val_accuracy: 0.7633\n",
            "Epoch 339/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1218 - accuracy: 0.9583 - val_loss: 0.6651 - val_accuracy: 0.8116\n",
            "Epoch 340/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0977 - accuracy: 0.9649 - val_loss: 0.6753 - val_accuracy: 0.7778\n",
            "Epoch 341/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0813 - accuracy: 0.9710 - val_loss: 0.6553 - val_accuracy: 0.7971\n",
            "Epoch 342/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.0714 - accuracy: 0.9734 - val_loss: 0.6140 - val_accuracy: 0.8068\n",
            "Epoch 343/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0949 - accuracy: 0.9692 - val_loss: 0.5969 - val_accuracy: 0.8164\n",
            "Epoch 344/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.0767 - accuracy: 0.9752 - val_loss: 0.6911 - val_accuracy: 0.7971\n",
            "Epoch 345/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0800 - accuracy: 0.9722 - val_loss: 0.6887 - val_accuracy: 0.7778\n",
            "Epoch 346/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.0921 - accuracy: 0.9655 - val_loss: 0.6455 - val_accuracy: 0.8019\n",
            "Epoch 347/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.0949 - accuracy: 0.9686 - val_loss: 0.7210 - val_accuracy: 0.7826\n",
            "Epoch 348/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.0991 - accuracy: 0.9643 - val_loss: 0.6539 - val_accuracy: 0.7874\n",
            "Epoch 349/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.0949 - accuracy: 0.9692 - val_loss: 0.6986 - val_accuracy: 0.7874\n",
            "Epoch 350/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.1021 - accuracy: 0.9637 - val_loss: 0.6600 - val_accuracy: 0.7923\n",
            "Epoch 351/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.1027 - accuracy: 0.9631 - val_loss: 0.7089 - val_accuracy: 0.7971\n",
            "Epoch 352/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0845 - accuracy: 0.9680 - val_loss: 0.8103 - val_accuracy: 0.7874\n",
            "Epoch 353/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.0878 - accuracy: 0.9692 - val_loss: 0.7692 - val_accuracy: 0.7874\n",
            "Epoch 354/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.0903 - accuracy: 0.9667 - val_loss: 0.7632 - val_accuracy: 0.7826\n",
            "Epoch 355/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.0957 - accuracy: 0.9680 - val_loss: 0.8198 - val_accuracy: 0.7681\n",
            "Epoch 356/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.0676 - accuracy: 0.9788 - val_loss: 0.7718 - val_accuracy: 0.7681\n",
            "Epoch 357/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0791 - accuracy: 0.9692 - val_loss: 0.6272 - val_accuracy: 0.7923\n",
            "Epoch 358/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.0790 - accuracy: 0.9722 - val_loss: 0.6809 - val_accuracy: 0.8019\n",
            "Epoch 359/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0861 - accuracy: 0.9643 - val_loss: 0.8562 - val_accuracy: 0.7633\n",
            "Epoch 360/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1100 - accuracy: 0.9655 - val_loss: 0.9388 - val_accuracy: 0.7295\n",
            "Epoch 361/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1053 - accuracy: 0.9631 - val_loss: 0.8348 - val_accuracy: 0.7729\n",
            "Epoch 362/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1001 - accuracy: 0.9607 - val_loss: 0.7785 - val_accuracy: 0.7778\n",
            "Epoch 363/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.0982 - accuracy: 0.9643 - val_loss: 0.6699 - val_accuracy: 0.8116\n",
            "Epoch 364/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1036 - accuracy: 0.9643 - val_loss: 0.9326 - val_accuracy: 0.7488\n",
            "Epoch 365/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.1189 - accuracy: 0.9583 - val_loss: 0.7424 - val_accuracy: 0.7971\n",
            "Epoch 366/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.1043 - accuracy: 0.9674 - val_loss: 0.7274 - val_accuracy: 0.7826\n",
            "Epoch 367/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0725 - accuracy: 0.9752 - val_loss: 0.8038 - val_accuracy: 0.7778\n",
            "Epoch 368/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0657 - accuracy: 0.9800 - val_loss: 0.7764 - val_accuracy: 0.7826\n",
            "Epoch 369/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.0662 - accuracy: 0.9758 - val_loss: 0.7583 - val_accuracy: 0.7826\n",
            "Epoch 370/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0784 - accuracy: 0.9740 - val_loss: 0.7327 - val_accuracy: 0.7971\n",
            "Epoch 371/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0987 - accuracy: 0.9661 - val_loss: 0.7202 - val_accuracy: 0.7585\n",
            "Epoch 372/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0830 - accuracy: 0.9655 - val_loss: 0.7369 - val_accuracy: 0.7874\n",
            "Epoch 373/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.0875 - accuracy: 0.9710 - val_loss: 0.6982 - val_accuracy: 0.8068\n",
            "Epoch 374/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.0649 - accuracy: 0.9776 - val_loss: 0.7068 - val_accuracy: 0.8068\n",
            "Epoch 375/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.1121 - accuracy: 0.9625 - val_loss: 0.6903 - val_accuracy: 0.7971\n",
            "Epoch 376/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.1009 - accuracy: 0.9674 - val_loss: 0.7649 - val_accuracy: 0.7729\n",
            "Epoch 377/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0978 - accuracy: 0.9643 - val_loss: 0.6992 - val_accuracy: 0.8019\n",
            "Epoch 378/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1112 - accuracy: 0.9637 - val_loss: 0.7448 - val_accuracy: 0.8116\n",
            "Epoch 379/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0824 - accuracy: 0.9716 - val_loss: 0.6754 - val_accuracy: 0.8068\n",
            "Epoch 380/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.0830 - accuracy: 0.9661 - val_loss: 0.7668 - val_accuracy: 0.7874\n",
            "Epoch 381/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.0902 - accuracy: 0.9686 - val_loss: 0.7337 - val_accuracy: 0.7633\n",
            "Epoch 382/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.0888 - accuracy: 0.9710 - val_loss: 0.7694 - val_accuracy: 0.7729\n",
            "Epoch 383/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0707 - accuracy: 0.9758 - val_loss: 0.7675 - val_accuracy: 0.8116\n",
            "Epoch 384/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0578 - accuracy: 0.9794 - val_loss: 0.7091 - val_accuracy: 0.8019\n",
            "Epoch 385/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0588 - accuracy: 0.9843 - val_loss: 0.6758 - val_accuracy: 0.7923\n",
            "Epoch 386/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0661 - accuracy: 0.9740 - val_loss: 0.7483 - val_accuracy: 0.7923\n",
            "Epoch 387/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0541 - accuracy: 0.9788 - val_loss: 0.7507 - val_accuracy: 0.7874\n",
            "Epoch 388/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0817 - accuracy: 0.9752 - val_loss: 0.7904 - val_accuracy: 0.7488\n",
            "Epoch 389/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1159 - accuracy: 0.9607 - val_loss: 0.7334 - val_accuracy: 0.7923\n",
            "Epoch 390/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.0763 - accuracy: 0.9722 - val_loss: 0.7251 - val_accuracy: 0.7923\n",
            "Epoch 391/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0795 - accuracy: 0.9752 - val_loss: 0.7304 - val_accuracy: 0.7681\n",
            "Epoch 392/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0813 - accuracy: 0.9649 - val_loss: 0.6607 - val_accuracy: 0.7971\n",
            "Epoch 393/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0827 - accuracy: 0.9692 - val_loss: 0.6317 - val_accuracy: 0.8164\n",
            "Epoch 394/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.0852 - accuracy: 0.9680 - val_loss: 0.7341 - val_accuracy: 0.7633\n",
            "Epoch 395/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1061 - accuracy: 0.9619 - val_loss: 0.7750 - val_accuracy: 0.7585\n",
            "Epoch 396/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0673 - accuracy: 0.9728 - val_loss: 0.7485 - val_accuracy: 0.7536\n",
            "Epoch 397/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0636 - accuracy: 0.9752 - val_loss: 0.7306 - val_accuracy: 0.7778\n",
            "Epoch 398/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.0590 - accuracy: 0.9800 - val_loss: 0.8261 - val_accuracy: 0.7778\n",
            "Epoch 399/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0926 - accuracy: 0.9698 - val_loss: 0.7342 - val_accuracy: 0.7923\n",
            "Epoch 400/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.1114 - accuracy: 0.9595 - val_loss: 0.7212 - val_accuracy: 0.8116\n",
            "Epoch 401/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0777 - accuracy: 0.9752 - val_loss: 0.6636 - val_accuracy: 0.7971\n",
            "Epoch 402/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0834 - accuracy: 0.9746 - val_loss: 0.8739 - val_accuracy: 0.7681\n",
            "Epoch 403/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.1117 - accuracy: 0.9607 - val_loss: 0.7249 - val_accuracy: 0.7826\n",
            "Epoch 404/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.0909 - accuracy: 0.9704 - val_loss: 0.8070 - val_accuracy: 0.7633\n",
            "Epoch 405/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.0881 - accuracy: 0.9692 - val_loss: 0.8045 - val_accuracy: 0.7923\n",
            "Epoch 406/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0635 - accuracy: 0.9782 - val_loss: 0.8429 - val_accuracy: 0.7826\n",
            "Epoch 407/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.0865 - accuracy: 0.9680 - val_loss: 0.7302 - val_accuracy: 0.7826\n",
            "Epoch 408/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0617 - accuracy: 0.9813 - val_loss: 0.7456 - val_accuracy: 0.7826\n",
            "Epoch 409/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.0523 - accuracy: 0.9788 - val_loss: 0.8985 - val_accuracy: 0.7633\n",
            "Epoch 410/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0961 - accuracy: 0.9667 - val_loss: 0.7102 - val_accuracy: 0.7874\n",
            "Epoch 411/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0684 - accuracy: 0.9716 - val_loss: 0.7335 - val_accuracy: 0.7971\n",
            "Epoch 412/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0678 - accuracy: 0.9752 - val_loss: 0.7082 - val_accuracy: 0.8019\n",
            "Epoch 413/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.0685 - accuracy: 0.9758 - val_loss: 0.8359 - val_accuracy: 0.7681\n",
            "Epoch 414/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.0618 - accuracy: 0.9770 - val_loss: 0.7593 - val_accuracy: 0.7826\n",
            "Epoch 415/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0584 - accuracy: 0.9794 - val_loss: 0.8425 - val_accuracy: 0.7536\n",
            "Epoch 416/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0840 - accuracy: 0.9740 - val_loss: 0.7809 - val_accuracy: 0.7729\n",
            "Epoch 417/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0731 - accuracy: 0.9752 - val_loss: 0.7419 - val_accuracy: 0.7923\n",
            "Epoch 418/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.0731 - accuracy: 0.9788 - val_loss: 0.7537 - val_accuracy: 0.7874\n",
            "Epoch 419/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.0798 - accuracy: 0.9716 - val_loss: 0.7567 - val_accuracy: 0.8019\n",
            "Epoch 420/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.0730 - accuracy: 0.9746 - val_loss: 0.7994 - val_accuracy: 0.7681\n",
            "Epoch 421/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0658 - accuracy: 0.9746 - val_loss: 0.8810 - val_accuracy: 0.7681\n",
            "Epoch 422/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.0805 - accuracy: 0.9686 - val_loss: 0.7580 - val_accuracy: 0.7923\n",
            "Epoch 423/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.0911 - accuracy: 0.9686 - val_loss: 0.7804 - val_accuracy: 0.7778\n",
            "Epoch 424/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0732 - accuracy: 0.9746 - val_loss: 0.7262 - val_accuracy: 0.8019\n",
            "Epoch 425/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.0837 - accuracy: 0.9740 - val_loss: 0.7461 - val_accuracy: 0.7778\n",
            "Epoch 426/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0673 - accuracy: 0.9788 - val_loss: 0.7670 - val_accuracy: 0.8068\n",
            "Epoch 427/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0645 - accuracy: 0.9770 - val_loss: 0.8412 - val_accuracy: 0.7729\n",
            "Epoch 428/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.0559 - accuracy: 0.9758 - val_loss: 0.8220 - val_accuracy: 0.7826\n",
            "Epoch 429/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0728 - accuracy: 0.9764 - val_loss: 0.7611 - val_accuracy: 0.7874\n",
            "Epoch 430/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.0660 - accuracy: 0.9782 - val_loss: 0.7784 - val_accuracy: 0.7971\n",
            "Epoch 431/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0744 - accuracy: 0.9758 - val_loss: 0.7218 - val_accuracy: 0.8068\n",
            "Epoch 432/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.0683 - accuracy: 0.9776 - val_loss: 0.7518 - val_accuracy: 0.7923\n",
            "Epoch 433/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.0772 - accuracy: 0.9710 - val_loss: 0.7653 - val_accuracy: 0.7729\n",
            "Epoch 434/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0827 - accuracy: 0.9680 - val_loss: 0.8242 - val_accuracy: 0.7826\n",
            "Epoch 435/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0594 - accuracy: 0.9758 - val_loss: 0.9195 - val_accuracy: 0.7633\n",
            "Epoch 436/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0466 - accuracy: 0.9788 - val_loss: 0.8308 - val_accuracy: 0.7826\n",
            "Epoch 437/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.0707 - accuracy: 0.9758 - val_loss: 0.7494 - val_accuracy: 0.7681\n",
            "Epoch 438/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0862 - accuracy: 0.9710 - val_loss: 0.7523 - val_accuracy: 0.8019\n",
            "Epoch 439/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0807 - accuracy: 0.9752 - val_loss: 0.6413 - val_accuracy: 0.8164\n",
            "Epoch 440/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0852 - accuracy: 0.9704 - val_loss: 0.6439 - val_accuracy: 0.8068\n",
            "Epoch 441/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0705 - accuracy: 0.9758 - val_loss: 0.7872 - val_accuracy: 0.7778\n",
            "Epoch 442/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.0733 - accuracy: 0.9740 - val_loss: 0.6776 - val_accuracy: 0.8019\n",
            "Epoch 443/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0605 - accuracy: 0.9752 - val_loss: 0.7537 - val_accuracy: 0.8068\n",
            "Epoch 444/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0646 - accuracy: 0.9807 - val_loss: 0.8301 - val_accuracy: 0.7971\n",
            "Epoch 445/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0672 - accuracy: 0.9776 - val_loss: 0.7583 - val_accuracy: 0.7874\n",
            "Epoch 446/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.0392 - accuracy: 0.9855 - val_loss: 0.7645 - val_accuracy: 0.7729\n",
            "Epoch 447/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0625 - accuracy: 0.9746 - val_loss: 0.7772 - val_accuracy: 0.7874\n",
            "Epoch 448/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0582 - accuracy: 0.9825 - val_loss: 0.7928 - val_accuracy: 0.7874\n",
            "Epoch 449/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0755 - accuracy: 0.9716 - val_loss: 0.8144 - val_accuracy: 0.7778\n",
            "Epoch 450/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.0680 - accuracy: 0.9758 - val_loss: 0.7080 - val_accuracy: 0.8309\n",
            "Epoch 451/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.0602 - accuracy: 0.9728 - val_loss: 0.7085 - val_accuracy: 0.8116\n",
            "Epoch 452/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.0735 - accuracy: 0.9740 - val_loss: 0.8197 - val_accuracy: 0.7488\n",
            "Epoch 453/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0740 - accuracy: 0.9722 - val_loss: 0.7537 - val_accuracy: 0.8068\n",
            "Epoch 454/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0736 - accuracy: 0.9776 - val_loss: 0.8247 - val_accuracy: 0.7778\n",
            "Epoch 455/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.0632 - accuracy: 0.9764 - val_loss: 0.8222 - val_accuracy: 0.8019\n",
            "Epoch 456/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0682 - accuracy: 0.9740 - val_loss: 0.7836 - val_accuracy: 0.7971\n",
            "Epoch 457/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0796 - accuracy: 0.9704 - val_loss: 0.8027 - val_accuracy: 0.7778\n",
            "Epoch 458/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0724 - accuracy: 0.9764 - val_loss: 0.7370 - val_accuracy: 0.8164\n",
            "Epoch 459/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.0777 - accuracy: 0.9746 - val_loss: 0.7423 - val_accuracy: 0.8019\n",
            "Epoch 460/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.0791 - accuracy: 0.9758 - val_loss: 0.8001 - val_accuracy: 0.7971\n",
            "Epoch 461/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.0790 - accuracy: 0.9734 - val_loss: 0.7625 - val_accuracy: 0.8068\n",
            "Epoch 462/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0901 - accuracy: 0.9692 - val_loss: 0.8120 - val_accuracy: 0.7778\n",
            "Epoch 463/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0830 - accuracy: 0.9728 - val_loss: 0.7507 - val_accuracy: 0.7971\n",
            "Epoch 464/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0533 - accuracy: 0.9807 - val_loss: 0.7538 - val_accuracy: 0.7971\n",
            "Epoch 465/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0532 - accuracy: 0.9807 - val_loss: 0.7342 - val_accuracy: 0.7971\n",
            "Epoch 466/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0459 - accuracy: 0.9825 - val_loss: 0.7160 - val_accuracy: 0.8213\n",
            "Epoch 467/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0684 - accuracy: 0.9740 - val_loss: 0.7965 - val_accuracy: 0.7681\n",
            "Epoch 468/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0330 - accuracy: 0.9879 - val_loss: 0.8340 - val_accuracy: 0.7874\n",
            "Epoch 469/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.0639 - accuracy: 0.9764 - val_loss: 0.7806 - val_accuracy: 0.8164\n",
            "Epoch 470/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.0633 - accuracy: 0.9770 - val_loss: 0.7960 - val_accuracy: 0.7633\n",
            "Epoch 471/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.0697 - accuracy: 0.9746 - val_loss: 0.8092 - val_accuracy: 0.7971\n",
            "Epoch 472/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0555 - accuracy: 0.9752 - val_loss: 0.8317 - val_accuracy: 0.7633\n",
            "Epoch 473/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0783 - accuracy: 0.9746 - val_loss: 0.8346 - val_accuracy: 0.7874\n",
            "Epoch 474/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.0571 - accuracy: 0.9800 - val_loss: 0.7965 - val_accuracy: 0.7923\n",
            "Epoch 475/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0758 - accuracy: 0.9746 - val_loss: 0.8984 - val_accuracy: 0.7729\n",
            "Epoch 476/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1128 - accuracy: 0.9649 - val_loss: 0.7791 - val_accuracy: 0.7681\n",
            "Epoch 477/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0596 - accuracy: 0.9764 - val_loss: 0.7324 - val_accuracy: 0.8116\n",
            "Epoch 478/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0716 - accuracy: 0.9770 - val_loss: 0.6570 - val_accuracy: 0.8213\n",
            "Epoch 479/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0852 - accuracy: 0.9704 - val_loss: 0.8376 - val_accuracy: 0.7874\n",
            "Epoch 480/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0707 - accuracy: 0.9746 - val_loss: 0.7047 - val_accuracy: 0.7778\n",
            "Epoch 481/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0586 - accuracy: 0.9825 - val_loss: 0.7298 - val_accuracy: 0.8261\n",
            "Epoch 482/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0390 - accuracy: 0.9891 - val_loss: 0.7539 - val_accuracy: 0.7633\n",
            "Epoch 483/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0481 - accuracy: 0.9837 - val_loss: 0.6690 - val_accuracy: 0.8406\n",
            "Epoch 484/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0425 - accuracy: 0.9837 - val_loss: 0.7045 - val_accuracy: 0.7874\n",
            "Epoch 485/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.0841 - accuracy: 0.9782 - val_loss: 0.7058 - val_accuracy: 0.7971\n",
            "Epoch 486/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.0757 - accuracy: 0.9764 - val_loss: 0.6830 - val_accuracy: 0.8213\n",
            "Epoch 487/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0723 - accuracy: 0.9698 - val_loss: 0.7243 - val_accuracy: 0.8164\n",
            "Epoch 488/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0675 - accuracy: 0.9752 - val_loss: 0.6541 - val_accuracy: 0.8164\n",
            "Epoch 489/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0480 - accuracy: 0.9861 - val_loss: 0.6869 - val_accuracy: 0.8164\n",
            "Epoch 490/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.0562 - accuracy: 0.9819 - val_loss: 0.7075 - val_accuracy: 0.7971\n",
            "Epoch 491/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0708 - accuracy: 0.9788 - val_loss: 0.9223 - val_accuracy: 0.7826\n",
            "Epoch 492/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0735 - accuracy: 0.9740 - val_loss: 0.7115 - val_accuracy: 0.7971\n",
            "Epoch 493/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0520 - accuracy: 0.9837 - val_loss: 0.6925 - val_accuracy: 0.8406\n",
            "Epoch 494/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0475 - accuracy: 0.9831 - val_loss: 0.7818 - val_accuracy: 0.8019\n",
            "Epoch 495/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0734 - accuracy: 0.9740 - val_loss: 0.9148 - val_accuracy: 0.7440\n",
            "Epoch 496/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0712 - accuracy: 0.9746 - val_loss: 0.7780 - val_accuracy: 0.7923\n",
            "Epoch 497/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0560 - accuracy: 0.9794 - val_loss: 0.8419 - val_accuracy: 0.7923\n",
            "Epoch 498/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0591 - accuracy: 0.9782 - val_loss: 0.8375 - val_accuracy: 0.7971\n",
            "Epoch 499/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0639 - accuracy: 0.9758 - val_loss: 0.7104 - val_accuracy: 0.8261\n",
            "Epoch 500/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.0611 - accuracy: 0.9788 - val_loss: 0.6669 - val_accuracy: 0.8406\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(cnnhistory.history['loss'])\n",
        "plt.plot(cnnhistory.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train','test'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "oQYnuaCrDH_A",
        "outputId": "15e33b92-66e6-4f6c-f41f-19b656d47991"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(cnnhistory.history['accuracy'])\n",
        "plt.plot(cnnhistory.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train','test'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "IFkTuO8nDNdq",
        "outputId": "357d330a-2ad4-4e5a-e817-ec5e7246812b"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#predictions = model.predict_classes(x_testcnn)\n",
        "predictions = model.predict(x_testcnn)"
      ],
      "metadata": {
        "id": "A2xtrN5wDQgY"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_f_ohjXKDUpY",
        "outputId": "2c8b3b3c-ef21-48bb-d9cb-a7d7d1173e48"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.15701944e-07, 5.55171287e-09, 2.24317759e-02, 1.32335288e-07,\n",
              "        2.50838980e-06, 9.77565408e-01],\n",
              "       [2.62324512e-03, 9.67977941e-01, 3.49238667e-06, 2.91635748e-02,\n",
              "        4.76181631e-05, 1.84175267e-04],\n",
              "       [5.23801624e-08, 1.07757605e-05, 9.99906659e-01, 3.86751964e-08,\n",
              "        6.90431407e-05, 1.34823595e-05],\n",
              "       ...,\n",
              "       [1.87276843e-08, 2.02349838e-11, 1.96975776e-07, 5.52720216e-08,\n",
              "        9.99988079e-01, 1.17019808e-05],\n",
              "       [1.40412943e-04, 6.68361554e-06, 1.82845327e-03, 9.41782236e-01,\n",
              "        1.13782822e-03, 5.51044755e-02],\n",
              "       [2.30995193e-03, 1.77254304e-04, 6.91760797e-04, 8.53874080e-05,\n",
              "        9.96735156e-01, 4.65615557e-07]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cmA2bFgsDW3D",
        "outputId": "d2bd4a7d-e076-4f01-9d66-2e56e779338c"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5, 1, 2, 5, 3, 4, 2, 0, 3, 1, 3, 2, 1, 4, 3, 0, 5, 0, 2, 5, 0, 0,\n",
              "       1, 3, 2, 3, 2, 5, 4, 2, 2, 3, 1, 2, 5, 5, 3, 5, 3, 3, 4, 1, 3, 2,\n",
              "       3, 1, 5, 3, 1, 2, 4, 4, 5, 5, 5, 1, 2, 3, 2, 5, 0, 2, 4, 2, 5, 4,\n",
              "       3, 0, 1, 2, 5, 2, 1, 2, 4, 5, 4, 1, 5, 5, 3, 1, 5, 3, 2, 4, 2, 5,\n",
              "       0, 5, 0, 5, 4, 0, 2, 4, 0, 2, 2, 0, 2, 3, 5, 3, 5, 5, 3, 1, 2, 2,\n",
              "       2, 1, 3, 2, 1, 3, 4, 4, 1, 1, 2, 4, 4, 1, 4, 2, 0, 4, 5, 5, 3, 1,\n",
              "       2, 1, 5, 5, 1, 2, 3, 3, 0, 3, 3, 0, 1, 0, 1, 2, 1, 5, 1, 2, 2, 0,\n",
              "       1, 1, 1, 1, 1, 4, 0, 1, 5, 1, 4, 5, 5, 4, 1, 0, 3, 5, 2, 3, 0, 4,\n",
              "       1, 3, 1, 0, 5, 5, 3, 5, 4, 5, 4, 0, 4, 1, 2, 1, 5, 0, 4, 3, 2, 1,\n",
              "       0, 3, 5, 0, 4, 5, 4, 5, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_Ytest = y_test.astype(int)"
      ],
      "metadata": {
        "id": "0PHDKWJWDY3g"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_Ytest"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k68v2i-pDbZE",
        "outputId": "f87d2f62-9fa4-4a29-848e-435495cb45bd"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5, 1, 2, 5, 3, 4, 2, 0, 3, 1, 3, 2, 1, 4, 3, 0, 5, 0, 2, 5, 0, 0,\n",
              "       1, 3, 2, 3, 2, 5, 4, 2, 2, 3, 1, 2, 5, 5, 3, 5, 3, 3, 4, 1, 3, 2,\n",
              "       3, 1, 5, 3, 1, 2, 4, 4, 5, 5, 5, 1, 2, 3, 2, 5, 0, 2, 4, 2, 5, 4,\n",
              "       3, 0, 1, 2, 5, 2, 1, 2, 4, 5, 4, 1, 5, 5, 3, 1, 5, 3, 2, 4, 2, 5,\n",
              "       0, 5, 0, 5, 4, 0, 2, 4, 0, 2, 2, 0, 2, 3, 5, 3, 5, 5, 3, 1, 2, 2,\n",
              "       2, 1, 3, 2, 1, 3, 4, 4, 1, 1, 2, 4, 4, 1, 4, 2, 0, 4, 5, 5, 3, 1,\n",
              "       2, 1, 5, 5, 1, 2, 3, 3, 0, 3, 3, 0, 1, 0, 1, 2, 1, 5, 1, 2, 2, 0,\n",
              "       1, 1, 1, 1, 1, 4, 0, 1, 5, 1, 4, 5, 5, 4, 1, 0, 3, 5, 2, 3, 0, 4,\n",
              "       1, 3, 1, 0, 5, 5, 3, 5, 4, 5, 4, 0, 4, 1, 2, 1, 5, 0, 4, 3, 2, 1,\n",
              "       0, 3, 5, 0, 4, 5, 4, 5, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds1=predictions.argmax(axis=1)\n",
        "preds1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4_cAI39VFhtp",
        "outputId": "5ffe06fb-902d-4fe0-e84c-950df3831871"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5, 1, 2, 5, 3, 4, 2, 0, 3, 0, 3, 2, 1, 4, 3, 0, 5, 3, 2, 5, 2, 0,\n",
              "       1, 5, 2, 5, 2, 5, 2, 2, 2, 3, 0, 2, 5, 5, 1, 5, 3, 3, 4, 1, 3, 2,\n",
              "       3, 1, 5, 5, 1, 5, 4, 4, 5, 2, 3, 1, 2, 3, 2, 5, 0, 2, 4, 2, 5, 4,\n",
              "       3, 4, 1, 2, 5, 2, 1, 2, 4, 3, 4, 1, 5, 2, 3, 1, 5, 3, 2, 4, 2, 5,\n",
              "       0, 5, 0, 3, 4, 0, 3, 4, 3, 4, 2, 4, 4, 3, 5, 3, 5, 5, 5, 1, 2, 2,\n",
              "       2, 1, 3, 2, 1, 3, 5, 4, 0, 0, 2, 4, 4, 1, 4, 2, 0, 4, 5, 5, 5, 1,\n",
              "       4, 1, 2, 5, 1, 3, 3, 3, 0, 3, 5, 0, 1, 0, 1, 2, 1, 5, 0, 2, 2, 0,\n",
              "       1, 1, 1, 1, 2, 4, 0, 1, 5, 1, 4, 5, 5, 2, 1, 0, 3, 5, 2, 2, 1, 4,\n",
              "       1, 3, 1, 0, 5, 5, 3, 5, 4, 5, 2, 0, 0, 0, 2, 1, 3, 0, 4, 3, 2, 1,\n",
              "       1, 4, 5, 3, 4, 5, 4, 3, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "abc = preds1.astype(int).flatten()"
      ],
      "metadata": {
        "id": "H4WEmM60NfQn"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "c = confusion_matrix(new_Ytest, abc) \n",
        "c"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bKEBeEBlFjB8",
        "outputId": "9cdbb7d3-ec76-439b-bd70-968a41c1b9df"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[17,  2,  1,  3,  2,  0],\n",
              "       [ 6, 32,  1,  0,  0,  0],\n",
              "       [ 0,  0, 32,  2,  3,  1],\n",
              "       [ 0,  1,  1, 24,  1,  6],\n",
              "       [ 1,  0,  3,  0, 25,  1],\n",
              "       [ 0,  0,  3,  5,  0, 34]])"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m4RjG7LWLSQx",
        "outputId": "a364a582-1bea-4bf8-f304-d3937699a960"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5, 1, 2, 5, 3, 4, 2, 0, 3, 1, 3, 2, 1, 4, 3, 0, 5, 0, 2, 5, 0, 0,\n",
              "       1, 3, 2, 3, 2, 5, 4, 2, 2, 3, 1, 2, 5, 5, 3, 5, 3, 3, 4, 1, 3, 2,\n",
              "       3, 1, 5, 3, 1, 2, 4, 4, 5, 5, 5, 1, 2, 3, 2, 5, 0, 2, 4, 2, 5, 4,\n",
              "       3, 0, 1, 2, 5, 2, 1, 2, 4, 5, 4, 1, 5, 5, 3, 1, 5, 3, 2, 4, 2, 5,\n",
              "       0, 5, 0, 5, 4, 0, 2, 4, 0, 2, 2, 0, 2, 3, 5, 3, 5, 5, 3, 1, 2, 2,\n",
              "       2, 1, 3, 2, 1, 3, 4, 4, 1, 1, 2, 4, 4, 1, 4, 2, 0, 4, 5, 5, 3, 1,\n",
              "       2, 1, 5, 5, 1, 2, 3, 3, 0, 3, 3, 0, 1, 0, 1, 2, 1, 5, 1, 2, 2, 0,\n",
              "       1, 1, 1, 1, 1, 4, 0, 1, 5, 1, 4, 5, 5, 4, 1, 0, 3, 5, 2, 3, 0, 4,\n",
              "       1, 3, 1, 0, 5, 5, 3, 5, 4, 5, 4, 0, 4, 1, 2, 1, 5, 0, 4, 3, 2, 1,\n",
              "       0, 3, 5, 0, 4, 5, 4, 5, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('/content/drive/My Drive/graduation project/audio/paper_code/mariam/original_500 epoch_with_valid_Adam2_3')\n",
        "print(\"MODEL SAVED\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lsJBNeMWDl6Z",
        "outputId": "e016f08b-fc17-4f33-ac96-985afa240939"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/graduation project/audio/paper_code/mariam/original_500 epoch_with_valid_Adam2_3/assets\n",
            "MODEL SAVED\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_model=keras.models.load_model('/content/drive/My Drive/graduation project/audio/paper_code/mariam/original_500 epoch_with_valid_Adam2_3')\n",
        "new_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q3KjaO9GDoNl",
        "outputId": "80e3e5b1-1694-4f17-e06b-441b5088382a"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d (Conv1D)             (None, 40, 128)           1152      \n",
            "                                                                 \n",
            " activation (Activation)     (None, 40, 128)           0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 40, 128)           0         \n",
            "                                                                 \n",
            " max_pooling1d (MaxPooling1D  (None, 8, 128)           0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv1d_1 (Conv1D)           (None, 8, 256)            262400    \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 8, 256)            0         \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 8, 256)            0         \n",
            "                                                                 \n",
            " max_pooling1d_1 (MaxPooling  (None, 1, 256)           0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 256)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 256)               65792     \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 256)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 256)               65792     \n",
            "                                                                 \n",
            " activation_3 (Activation)   (None, 256)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 6)                 1542      \n",
            "                                                                 \n",
            " activation_4 (Activation)   (None, 6)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 396,678\n",
            "Trainable params: 396,678\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss, acc =model.evaluate(x_testcnn, y_test)\n",
        "print(\"Restored model, accuracy: {:5.2f}%\".format(100*acc))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n3kzoqPkDqqS",
        "outputId": "45f1f5cd-b51e-4a07-ac25-9ebf33e53e18"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7/7 [==============================] - 0s 5ms/step - loss: 0.7330 - accuracy: 0.7923\n",
            "Restored model, accuracy: 79.23%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss, acc =model.evaluate(X_train, y_train)\n",
        "print(\"Restored model train, accuracy: {:5.2f}%\".format(100*acc))"
      ],
      "metadata": {
        "id": "fJDTGH_OUX0z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e78c84e7-14f4-4acc-cc00-c4b2234acd6a"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "52/52 [==============================] - 0s 5ms/step - loss: 0.0210 - accuracy: 0.9964\n",
            "Restored model train, accuracy: 99.64%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix,accuracy_score\n",
        "import seaborn as sn\n",
        "\n",
        "print(classification_report(new_Ytest,abc))\n",
        "\n",
        "acc = float(accuracy_score(new_Ytest,abc))*100\n",
        "print(\"----accuracy score %s ----\" % acc)\n",
        "\n",
        "cm = confusion_matrix(new_Ytest,abc)\n",
        "#df_cm = pd.DataFrame(cm)\n",
        "class_names = ['neutral','calm', 'happy','sad','angry', 'fearful' ]\n",
        "df_cm = pd.DataFrame(cm, index=class_names, columns=class_names,)\n",
        "sn.heatmap(df_cm, annot=True, fmt='')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 508
        },
        "id": "SfSC3El94LZg",
        "outputId": "9e26a98d-a429-49f9-ab05-217a94091117"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      0.68      0.69        25\n",
            "           1       0.91      0.82      0.86        39\n",
            "           2       0.78      0.84      0.81        38\n",
            "           3       0.71      0.73      0.72        33\n",
            "           4       0.81      0.83      0.82        30\n",
            "           5       0.81      0.81      0.81        42\n",
            "\n",
            "    accuracy                           0.79       207\n",
            "   macro avg       0.79      0.79      0.79       207\n",
            "weighted avg       0.79      0.79      0.79       207\n",
            "\n",
            "----accuracy score 79.22705314009661 ----\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "LGpgwFQqkpyU"
      },
      "execution_count": 37,
      "outputs": []
    }
  ]
}