{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uzZTLwtNdxKi",
        "outputId": "6a6f5a12-a0d2-4825-e5f7-f9e8cd2dd5ae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: keras in /opt/conda/envs/rapids/lib/python3.7/site-packages (2.8.0)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install keras"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cB9NV-RLdSLZ",
        "outputId": "f3834e7b-d433-417c-ab1e-e1e07c4bc61a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EbHyBIe_dOYb",
        "outputId": "65c42ecd-cb15-422c-9f7c-006f2a33e71f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow in /opt/conda/envs/rapids/lib/python3.7/site-packages (2.8.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: tf-estimator-nightly==2.8.0.dev2021122109 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from tensorflow) (2.8.0.dev2021122109)\n",
            "Requirement already satisfied: numpy>=1.20 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from tensorflow) (1.21.1)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from tensorflow) (13.0.0)\n",
            "Requirement already satisfied: gast>=0.2.1 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from tensorflow) (0.5.3)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from tensorflow) (0.24.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from tensorflow) (3.6.0)\n",
            "Requirement already satisfied: setuptools in /opt/conda/envs/rapids/lib/python3.7/site-packages (from tensorflow) (49.6.0.post20210108)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from tensorflow) (1.44.0)\n",
            "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from tensorflow) (2.8.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from tensorflow) (1.12.1)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from tensorflow) (1.0.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: six>=1.12.0 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: tensorboard<2.9,>=2.8 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from tensorflow) (2.8.0)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from tensorflow) (2.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from tensorflow) (3.10.0.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from tensorflow) (3.16.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from astunparse>=1.6.0->tensorflow) (0.37.0)\n",
            "Requirement already satisfied: cached-property in /opt/conda/envs/rapids/lib/python3.7/site-packages (from h5py>=2.9.0->tensorflow) (1.5.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from tensorboard<2.9,>=2.8->tensorflow) (3.3.4)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.8.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.6.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.6.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.26.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.0.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.4.6)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.2.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata in /opt/conda/envs/rapids/lib/python3.7/site-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (4.6.4)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (1.26.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2021.10.8)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (3.1)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2.0.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (3.2.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from importlib-metadata->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (3.5.0)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-2iPI3-RdOYc",
        "outputId": "2509154d-3389-4ed5-bb2b-ee9ecd547258"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting package metadata (current_repodata.json): done\n",
            "Solving environment: done\n",
            "\n",
            "# All requested packages already installed.\n",
            "\n",
            "\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "conda install librosa "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bcVbQcYAdOYd",
        "outputId": "1390c775-5026-4e4a-9499-dda6f863afb1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: plotly in /opt/conda/envs/rapids/lib/python3.7/site-packages (5.6.0)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from plotly) (8.0.1)\n",
            "Requirement already satisfied: six in /opt/conda/envs/rapids/lib/python3.7/site-packages (from plotly) (1.16.0)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install plotly"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QeizPlDkdOYe",
        "outputId": "0307d276-8ddb-469d-d681-866e0cd6afab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: librosa in /opt/conda/envs/rapids/lib/python3.7/site-packages (0.9.1)\n",
            "Requirement already satisfied: resampy>=0.2.2 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from librosa) (0.2.2)\n",
            "Requirement already satisfied: scikit-learn>=0.19.1 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from librosa) (0.23.1)\n",
            "Requirement already satisfied: pooch>=1.0 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from librosa) (1.5.1)\n",
            "Requirement already satisfied: audioread>=2.1.5 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from librosa) (2.1.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from librosa) (21.0)\n",
            "Requirement already satisfied: numpy>=1.17.0 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from librosa) (1.21.1)\n",
            "Requirement already satisfied: decorator>=4.0.10 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied: joblib>=0.14 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from librosa) (1.0.1)\n",
            "Requirement already satisfied: numba>=0.45.1 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from librosa) (0.53.1)\n",
            "Requirement already satisfied: scipy>=1.2.0 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from librosa) (1.6.0)\n",
            "Requirement already satisfied: soundfile>=0.10.2 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from librosa) (0.10.3.post1)\n",
            "Requirement already satisfied: llvmlite<0.37,>=0.36.0rc1 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from numba>=0.45.1->librosa) (0.36.0)\n",
            "Requirement already satisfied: setuptools in /opt/conda/envs/rapids/lib/python3.7/site-packages (from numba>=0.45.1->librosa) (49.6.0.post20210108)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from packaging>=20.0->librosa) (2.4.7)\n",
            "Requirement already satisfied: requests in /opt/conda/envs/rapids/lib/python3.7/site-packages (from pooch>=1.0->librosa) (2.26.0)\n",
            "Requirement already satisfied: appdirs in /opt/conda/envs/rapids/lib/python3.7/site-packages (from pooch>=1.0->librosa) (1.4.4)\n",
            "Requirement already satisfied: six>=1.3 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from resampy>=0.2.2->librosa) (1.16.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from scikit-learn>=0.19.1->librosa) (2.2.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from soundfile>=0.10.2->librosa) (1.14.6)\n",
            "Requirement already satisfied: pycparser in /opt/conda/envs/rapids/lib/python3.7/site-packages (from cffi>=1.0->soundfile>=0.10.2->librosa) (2.20)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from requests->pooch>=1.0->librosa) (2021.10.8)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from requests->pooch>=1.0->librosa) (1.26.6)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from requests->pooch>=1.0->librosa) (2.0.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from requests->pooch>=1.0->librosa) (3.1)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install librosa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "NgJohC6sdr-S",
        "outputId": "b7be791d-8dc3-42a5-9ac2-77a9f7f7c1ac"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "        <script type=\"text/javascript\">\n",
              "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
              "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
              "        if (typeof require !== 'undefined') {\n",
              "        require.undef(\"plotly\");\n",
              "        requirejs.config({\n",
              "            paths: {\n",
              "                'plotly': ['https://cdn.plot.ly/plotly-2.8.3.min']\n",
              "            }\n",
              "        });\n",
              "        require(['plotly'], function(Plotly) {\n",
              "            window._Plotly = Plotly;\n",
              "        });\n",
              "        }\n",
              "        </script>\n",
              "        "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Orignial Notebook: https://github.com/MITESHPUTHRANNEU/Speech-Emotion-Analyzer/blob/master/final_results_gender_test.ipynb\n",
        "# This notebook author: Reza Chu\n",
        "# Last Editing Date: 31st May 2019\n",
        "\n",
        "## Python\n",
        "import os\n",
        "import random\n",
        "import sys\n",
        "\n",
        "import IPython\n",
        "from IPython.display import Audio\n",
        "from IPython.display import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "## Package\n",
        "import glob \n",
        "import keras\n",
        "import IPython.display as ipd\n",
        "import librosa\n",
        "import librosa.display\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import plotly.graph_objs as go\n",
        "import plotly.offline as py\n",
        "import plotly.tools as tls\n",
        "import seaborn as sns\n",
        "import scipy.io.wavfile\n",
        "import tensorflow as tf\n",
        "py.init_notebook_mode(connected=True)\n",
        "\n",
        "## Keras\n",
        "from keras import regularizers\n",
        "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping\n",
        "from keras.callbacks import  History, ReduceLROnPlateau, CSVLogger\n",
        "from keras.models import Model, Sequential\n",
        "from keras.layers import Dense, Embedding, LSTM\n",
        "from keras.layers import Input, Flatten, Dropout, Activation, BatchNormalization\n",
        "from keras.layers import Conv1D, MaxPooling1D, AveragePooling1D\n",
        "from keras.preprocessing import sequence\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.utils import np_utils\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "## Sklearn\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "## Rest\n",
        "from scipy.fftpack import fft\n",
        "from scipy import signal\n",
        "from scipy.io import wavfile\n",
        "from tqdm import tqdm\n",
        "\n",
        "input_duration=3\n",
        "# % pylab inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a9_TpDKveU1d",
        "outputId": "345cc66b-1bc5-43ed-d92f-d1bef65a55b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Data loaded. Loading time: 23.732166528701782 seconds ---\n"
          ]
        }
      ],
      "source": [
        "#only SAVEE data set\n",
        "import time\n",
        "import os\n",
        "import librosa\n",
        "from librosa import display\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "lst = []\n",
        "count=0\n",
        "start_time = time.time()\n",
        "\n",
        "path3 = '/content/drive/My Drive/data_set/SAVEE'\n",
        "for subdir, dirs, files in os.walk(path3):\n",
        "  for file in files:\n",
        "      try:\n",
        "        #0 = neutral,  1 = fearful, 2 = happy, 3 = sad, 4 = angry\n",
        "        if file.startswith('a'):\n",
        "            emotion=4\n",
        "        elif file.startswith('d'):\n",
        "            continue\n",
        "        elif file.startswith('f'):\n",
        "            emotion=1\n",
        "        elif file.startswith('h'):\n",
        "            emotion=2\n",
        "        elif file.startswith('n'):\n",
        "            emotion=0\n",
        "        elif file.startswith('sa'):\n",
        "            emotion=3\n",
        "        elif file.startswith('su'):\n",
        "            continue\n",
        "        else:\n",
        "            continue\n",
        "        #Load librosa array, obtain mfcss, store the file and the mcss information in a new array\n",
        "        X, sample_rate = librosa.load(os.path.join(subdir,file), res_type='kaiser_fast')\n",
        "        #print(sample_rate)\n",
        "       # mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T,axis=0) \n",
        "        count +=1\n",
        "        # The instruction below converts the labels (from 1 to 8) to a series from 0 to 7\n",
        "        # This is because our predictor needs to start from 0 otherwise it will try to predict also 0.\n",
        "        #file = int(file[7:8]) - 1 \n",
        "        #0 = neutral, 1 = calm, 2 = happy, 3 = sad, 4 = angry, 5 = fearful, 6 = disgust, 7 = surprised\n",
        "        arr = X, emotion\n",
        "        lst.append(arr)\n",
        "      # If the file is not valid, skip it\n",
        "      except ValueError:\n",
        "        continue\n",
        "\n",
        "print(\"--- Data loaded. Loading time: %s seconds ---\" % (time.time() - start_time))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XVaArAIkdOYj",
        "outputId": "dbed4983-c32f-49c7-e067-179c61e47d19"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/core/fromnumeric.py:3208: VisibleDeprecationWarning:\n",
            "\n",
            "Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "720"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "from numpy.core.fromnumeric import size\n",
        "size(lst)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uo6fLwandOYl",
        "outputId": "3db6f29c-dc52-4d30-a502-084fefcc0129"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/core/fromnumeric.py:3208: VisibleDeprecationWarning:\n",
            "\n",
            "Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "720"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "from numpy.core.fromnumeric import size\n",
        "size(lst)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2vTLVo3SdOYm",
        "outputId": "1a9e4016-c492-4df4-8826-2e86271f6483"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: VisibleDeprecationWarning:\n",
            "\n",
            "Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "audio_file, emotion = zip(*lst)\n",
        "audio_file=np.asarray(audio_file)\n",
        "emotion=np.asarray(emotion)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M-pbYcFDd5a2",
        "outputId": "e27c569f-73dc-4f37-ecd6-f59ddd86e5fa"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((288,), (36,), (36,))"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "\n",
        "emotion.shape,audio_file.shape\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "signal_train, signal_test, emo_train, emo_test = train_test_split(audio_file,emotion, test_size=0.2, random_state=42)\n",
        "signal_valid, signal_test, emo_valid, emo_test = train_test_split(signal_test,emo_test, test_size=0.5,train_size=0.5, random_state=42)\n",
        "signal_train.shape,signal_valid.shape,signal_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "OflClL3QfDoj"
      },
      "outputs": [],
      "source": [
        "x_valid=[]\n",
        "x_test=[]\n",
        "for i in range(signal_valid.size):\n",
        "  x_valid.append(np.mean(librosa.feature.mfcc(y=signal_valid[i], sr=sample_rate, n_mfcc=40).T,axis=0))\n",
        "  #x_valid.append(np.mean(librosa.feature.chroma_stft(S=np.abs(librosa.stft(signal_valid[i])), sr=sample_rate ,n_chroma=12).T,axis=0))\n",
        "\n",
        "for i in range(signal_test.size):\n",
        "  x_test.append(np.mean(librosa.feature.mfcc(y=signal_test[i], sr=sample_rate, n_mfcc=40).T,axis=0))\n",
        "  #x_test.append(np.mean(librosa.feature.chroma_stft(S=np.abs(librosa.stft(signal_test[i])), sr=sample_rate,n_chroma=12).T,axis=0))\n",
        "#resv = np.hstack((resv, mfccsv))  \n",
        "#resv = np.hstack((resv, cromav))  \n",
        "#resv = np.hstack((resv, melv))  \n",
        "\n",
        "#rest = np.hstack((rest, mfccst))  \n",
        "#rest = np.hstack((rest, cromat))  \n",
        "#rest = np.hstack((rest, melt))\n",
        "\n",
        "#x_valid.append(resv)\n",
        "#x_test.append(rest)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kJkN-K17gSvD",
        "outputId": "fec1389f-645e-49f9-a27b-0a2f96d55364"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((36, 40), (36, 40))"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "x_valid=np.asarray(x_valid)\n",
        "x_test=np.asarray(x_test)\n",
        "x_valid.shape,x_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "k43cyWMKgXo9"
      },
      "outputs": [],
      "source": [
        "train_lst=[]\n",
        "for i in range(signal_train.size):\n",
        "  emo=emo_train[i]\n",
        "  x=signal_train[i]\n",
        "  arr=x,emo\n",
        "  train_lst.append(arr)\n",
        "  x=librosa.effects.time_stretch(signal_train[i],0.5)\n",
        "  arr=x,emo\n",
        "  train_lst.append(arr)\n",
        "  x=librosa.effects.time_stretch(signal_train[i],1.5)\n",
        "  arr=x,emo\n",
        "  train_lst.append(arr)\n",
        "  x=librosa.effects.pitch_shift(signal_train[i],sample_rate,2)\n",
        "  arr=x,emo\n",
        "  train_lst.append(arr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "gFL9v0A9kYvD"
      },
      "outputs": [],
      "source": [
        "signal, y_train = zip(*train_lst)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ulnUCfZikY7Y",
        "outputId": "855b319a-9a5f-4840-b6b0-b31beb8e34e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: VisibleDeprecationWarning:\n",
            "\n",
            "Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "signal=np.asarray(signal)\n",
        "y_train=np.asarray(y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bt0pm0g4kY9q",
        "outputId": "2c98e12e-59d9-463b-e97c-ce5375b6646b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1152,)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "y_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "yGPv5UDikY_f"
      },
      "outputs": [],
      "source": [
        "x_train=[]\n",
        "for i in range(signal.size):\n",
        "  x_train.append(np.mean(librosa.feature.mfcc(y=signal[i], sr=sample_rate, n_mfcc=40).T,axis=0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7qnveahvkj3U",
        "outputId": "0f7858b5-e969-4510-cf74-e229d0d6bde5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1152, 40)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "x_train=np.asarray(x_train)\n",
        "x_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LFnBsKPXkmDV",
        "outputId": "4a5269d9-d308-4b81-c863-211e4b04944c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1152,)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "y_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zlvfnkyLkxWx",
        "outputId": "09929a3a-cfd9-4a22-9ca3-9de20eeb3b3d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning:\n",
            "\n",
            "The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import keras\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from keras.preprocessing import sequence\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from keras.layers import Input, Flatten, Dropout, Activation\n",
        "from keras.layers import Conv1D, MaxPooling1D\n",
        "from keras.models import Model\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras import optimizers\n",
        "from keras.models import InputLayer\n",
        "\n",
        "model = Sequential(InputLayer((40,1)))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Conv1D(128, 12,padding='same', ))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.1))\n",
        "model.add(MaxPooling1D(pool_size=(5)))\n",
        "\n",
        "\n",
        "model.add(Conv1D(256,12,padding='same',))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(MaxPooling1D(pool_size=(5)))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(6))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "opt = tf.keras.optimizers.Adam(lr=0.0002)\n",
        "#opt = tf.keras.optimizers.RMSprop(lr=0.0001, rho=0.9, epsilon=1e-07, decay=0.0)\n",
        "#opt = tf.keras.optimizers.SGD(lr=0.001, momentum=0.0, decay=0.0, nesterov=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1-Xsvw44kzg1",
        "outputId": "5c39ff4d-a03a-4745-bf01-950ec2c9afdd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " batch_normalization (BatchN  (None, 40, 1)            4         \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " conv1d (Conv1D)             (None, 40, 128)           1664      \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 40, 128)          512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation (Activation)     (None, 40, 128)           0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 40, 128)           0         \n",
            "                                                                 \n",
            " max_pooling1d (MaxPooling1D  (None, 8, 128)           0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv1d_1 (Conv1D)           (None, 8, 256)            393472    \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 8, 256)           1024      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 8, 256)            0         \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 8, 256)            0         \n",
            "                                                                 \n",
            " max_pooling1d_1 (MaxPooling  (None, 1, 256)           0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 256)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 6)                 1542      \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 6)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 398,218\n",
            "Trainable params: 397,448\n",
            "Non-trainable params: 770\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "m0w5VpjNk1d7"
      },
      "outputs": [],
      "source": [
        "model.compile(loss='sparse_categorical_crossentropy',\n",
        "              optimizer=opt,\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tz-HMdw4k3Vt",
        "outputId": "e2369163-4aef-4173-f3d3-8461693cab99"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/400\n",
            "72/72 [==============================] - 3s 30ms/step - loss: 1.6435 - accuracy: 0.4175 - val_loss: 1.7633 - val_accuracy: 0.1389\n",
            "Epoch 2/400\n",
            "72/72 [==============================] - 2s 27ms/step - loss: 1.2628 - accuracy: 0.5304 - val_loss: 2.0254 - val_accuracy: 0.0278\n",
            "Epoch 3/400\n",
            "72/72 [==============================] - 2s 27ms/step - loss: 1.0944 - accuracy: 0.5755 - val_loss: 2.2675 - val_accuracy: 0.0278\n",
            "Epoch 4/400\n",
            "72/72 [==============================] - 2s 27ms/step - loss: 0.9318 - accuracy: 0.6424 - val_loss: 2.3754 - val_accuracy: 0.0278\n",
            "Epoch 5/400\n",
            "72/72 [==============================] - 2s 32ms/step - loss: 0.9222 - accuracy: 0.6450 - val_loss: 2.1651 - val_accuracy: 0.1389\n",
            "Epoch 6/400\n",
            "72/72 [==============================] - 2s 32ms/step - loss: 0.9892 - accuracy: 0.6250 - val_loss: 1.8210 - val_accuracy: 0.0833\n",
            "Epoch 7/400\n",
            "72/72 [==============================] - 2s 27ms/step - loss: 0.8725 - accuracy: 0.6632 - val_loss: 1.2786 - val_accuracy: 0.3889\n",
            "Epoch 8/400\n",
            "72/72 [==============================] - 2s 27ms/step - loss: 0.8357 - accuracy: 0.6719 - val_loss: 0.9554 - val_accuracy: 0.5556\n",
            "Epoch 9/400\n",
            "72/72 [==============================] - 2s 27ms/step - loss: 0.7805 - accuracy: 0.6910 - val_loss: 0.8190 - val_accuracy: 0.6944\n",
            "Epoch 10/400\n",
            "72/72 [==============================] - 3s 42ms/step - loss: 0.7133 - accuracy: 0.7109 - val_loss: 0.8216 - val_accuracy: 0.6389\n",
            "Epoch 11/400\n",
            "72/72 [==============================] - 3s 42ms/step - loss: 0.7339 - accuracy: 0.7161 - val_loss: 1.0073 - val_accuracy: 0.6389\n",
            "Epoch 12/400\n",
            "72/72 [==============================] - 2s 30ms/step - loss: 0.6618 - accuracy: 0.7179 - val_loss: 0.9688 - val_accuracy: 0.6111\n",
            "Epoch 13/400\n",
            "72/72 [==============================] - 3s 35ms/step - loss: 0.6748 - accuracy: 0.7396 - val_loss: 0.6614 - val_accuracy: 0.7778\n",
            "Epoch 14/400\n",
            "72/72 [==============================] - 3s 40ms/step - loss: 0.6182 - accuracy: 0.7535 - val_loss: 0.6769 - val_accuracy: 0.7222\n",
            "Epoch 15/400\n",
            "72/72 [==============================] - 2s 30ms/step - loss: 0.6387 - accuracy: 0.7552 - val_loss: 0.7510 - val_accuracy: 0.7222\n",
            "Epoch 16/400\n",
            "72/72 [==============================] - 2s 27ms/step - loss: 0.6259 - accuracy: 0.7300 - val_loss: 0.6857 - val_accuracy: 0.7222\n",
            "Epoch 17/400\n",
            "72/72 [==============================] - 2s 28ms/step - loss: 0.5974 - accuracy: 0.7700 - val_loss: 0.8318 - val_accuracy: 0.6389\n",
            "Epoch 18/400\n",
            "72/72 [==============================] - 2s 28ms/step - loss: 0.5827 - accuracy: 0.7561 - val_loss: 0.6625 - val_accuracy: 0.6944\n",
            "Epoch 19/400\n",
            "72/72 [==============================] - 2s 27ms/step - loss: 0.5669 - accuracy: 0.7630 - val_loss: 0.6808 - val_accuracy: 0.7222\n",
            "Epoch 20/400\n",
            "72/72 [==============================] - 2s 27ms/step - loss: 0.5405 - accuracy: 0.7726 - val_loss: 0.7412 - val_accuracy: 0.6944\n",
            "Epoch 21/400\n",
            "72/72 [==============================] - 2s 27ms/step - loss: 0.5573 - accuracy: 0.7865 - val_loss: 0.7252 - val_accuracy: 0.6667\n",
            "Epoch 22/400\n",
            "72/72 [==============================] - 2s 28ms/step - loss: 0.4924 - accuracy: 0.7977 - val_loss: 0.8205 - val_accuracy: 0.7222\n",
            "Epoch 23/400\n",
            "72/72 [==============================] - 2s 28ms/step - loss: 0.5493 - accuracy: 0.7786 - val_loss: 0.6659 - val_accuracy: 0.6944\n",
            "Epoch 24/400\n",
            "72/72 [==============================] - 2s 28ms/step - loss: 0.4782 - accuracy: 0.8125 - val_loss: 0.6912 - val_accuracy: 0.6944\n",
            "Epoch 25/400\n",
            "72/72 [==============================] - 2s 28ms/step - loss: 0.4814 - accuracy: 0.8012 - val_loss: 0.6877 - val_accuracy: 0.6111\n",
            "Epoch 26/400\n",
            "72/72 [==============================] - 2s 28ms/step - loss: 0.4630 - accuracy: 0.8099 - val_loss: 0.5610 - val_accuracy: 0.7222\n",
            "Epoch 27/400\n",
            "72/72 [==============================] - 2s 28ms/step - loss: 0.4457 - accuracy: 0.8142 - val_loss: 0.5503 - val_accuracy: 0.7222\n",
            "Epoch 28/400\n",
            "72/72 [==============================] - 2s 28ms/step - loss: 0.4361 - accuracy: 0.8238 - val_loss: 0.6844 - val_accuracy: 0.6667\n",
            "Epoch 29/400\n",
            "72/72 [==============================] - 2s 28ms/step - loss: 0.4346 - accuracy: 0.8238 - val_loss: 0.5650 - val_accuracy: 0.7500\n",
            "Epoch 30/400\n",
            "72/72 [==============================] - 2s 28ms/step - loss: 0.3757 - accuracy: 0.8611 - val_loss: 0.4937 - val_accuracy: 0.7500\n",
            "Epoch 31/400\n",
            "72/72 [==============================] - 2s 28ms/step - loss: 0.3707 - accuracy: 0.8377 - val_loss: 0.5480 - val_accuracy: 0.7500\n",
            "Epoch 32/400\n",
            "72/72 [==============================] - 2s 28ms/step - loss: 0.3764 - accuracy: 0.8377 - val_loss: 0.5483 - val_accuracy: 0.7222\n",
            "Epoch 33/400\n",
            "72/72 [==============================] - 2s 28ms/step - loss: 0.4229 - accuracy: 0.8325 - val_loss: 0.4707 - val_accuracy: 0.7500\n",
            "Epoch 34/400\n",
            "72/72 [==============================] - 2s 28ms/step - loss: 0.3595 - accuracy: 0.8602 - val_loss: 0.6144 - val_accuracy: 0.7500\n",
            "Epoch 35/400\n",
            "72/72 [==============================] - 2s 28ms/step - loss: 0.3650 - accuracy: 0.8628 - val_loss: 0.6025 - val_accuracy: 0.6389\n",
            "Epoch 36/400\n",
            "72/72 [==============================] - 2s 28ms/step - loss: 0.3328 - accuracy: 0.8759 - val_loss: 0.3762 - val_accuracy: 0.8611\n",
            "Epoch 37/400\n",
            "72/72 [==============================] - 2s 28ms/step - loss: 0.3220 - accuracy: 0.8715 - val_loss: 0.4547 - val_accuracy: 0.7500\n",
            "Epoch 38/400\n",
            "72/72 [==============================] - 2s 28ms/step - loss: 0.3596 - accuracy: 0.8516 - val_loss: 0.5613 - val_accuracy: 0.7500\n",
            "Epoch 39/400\n",
            "72/72 [==============================] - 2s 28ms/step - loss: 0.3123 - accuracy: 0.8759 - val_loss: 0.5120 - val_accuracy: 0.7222\n",
            "Epoch 40/400\n",
            "72/72 [==============================] - 2s 28ms/step - loss: 0.3015 - accuracy: 0.8767 - val_loss: 0.4933 - val_accuracy: 0.7778\n",
            "Epoch 41/400\n",
            "72/72 [==============================] - 2s 28ms/step - loss: 0.3124 - accuracy: 0.8776 - val_loss: 0.4235 - val_accuracy: 0.7778\n",
            "Epoch 42/400\n",
            "72/72 [==============================] - 2s 28ms/step - loss: 0.2939 - accuracy: 0.8802 - val_loss: 0.6156 - val_accuracy: 0.7222\n",
            "Epoch 43/400\n",
            "72/72 [==============================] - 2s 28ms/step - loss: 0.2468 - accuracy: 0.9036 - val_loss: 0.4806 - val_accuracy: 0.7500\n",
            "Epoch 44/400\n",
            "72/72 [==============================] - 2s 28ms/step - loss: 0.2961 - accuracy: 0.8776 - val_loss: 0.6137 - val_accuracy: 0.6667\n",
            "Epoch 45/400\n",
            "72/72 [==============================] - 2s 28ms/step - loss: 0.2922 - accuracy: 0.8872 - val_loss: 0.3836 - val_accuracy: 0.8333\n",
            "Epoch 46/400\n",
            "72/72 [==============================] - 2s 28ms/step - loss: 0.2471 - accuracy: 0.9080 - val_loss: 0.4853 - val_accuracy: 0.8333\n",
            "Epoch 47/400\n",
            "72/72 [==============================] - 2s 28ms/step - loss: 0.2221 - accuracy: 0.9141 - val_loss: 0.4605 - val_accuracy: 0.7500\n",
            "Epoch 48/400\n",
            "72/72 [==============================] - 2s 28ms/step - loss: 0.2351 - accuracy: 0.9106 - val_loss: 0.4835 - val_accuracy: 0.8056\n",
            "Epoch 49/400\n",
            "72/72 [==============================] - 2s 28ms/step - loss: 0.2392 - accuracy: 0.9054 - val_loss: 0.4782 - val_accuracy: 0.8056\n",
            "Epoch 50/400\n",
            "72/72 [==============================] - 2s 27ms/step - loss: 0.2192 - accuracy: 0.9149 - val_loss: 0.4955 - val_accuracy: 0.7778\n",
            "Epoch 51/400\n",
            "72/72 [==============================] - 2s 27ms/step - loss: 0.2358 - accuracy: 0.9089 - val_loss: 0.4508 - val_accuracy: 0.8056\n",
            "Epoch 52/400\n",
            "72/72 [==============================] - 2s 27ms/step - loss: 0.2214 - accuracy: 0.9106 - val_loss: 0.4814 - val_accuracy: 0.8056\n",
            "Epoch 53/400\n",
            "72/72 [==============================] - 2s 27ms/step - loss: 0.2038 - accuracy: 0.9314 - val_loss: 0.4618 - val_accuracy: 0.8056\n",
            "Epoch 54/400\n",
            "72/72 [==============================] - 2s 27ms/step - loss: 0.2094 - accuracy: 0.9219 - val_loss: 0.5274 - val_accuracy: 0.7222\n",
            "Epoch 55/400\n",
            "72/72 [==============================] - 2s 28ms/step - loss: 0.2083 - accuracy: 0.9167 - val_loss: 0.6267 - val_accuracy: 0.7500\n",
            "Epoch 56/400\n",
            "72/72 [==============================] - 2s 28ms/step - loss: 0.1998 - accuracy: 0.9288 - val_loss: 0.5352 - val_accuracy: 0.8333\n",
            "Epoch 57/400\n",
            "72/72 [==============================] - 2s 28ms/step - loss: 0.2012 - accuracy: 0.9288 - val_loss: 0.6078 - val_accuracy: 0.6944\n",
            "Epoch 58/400\n",
            "72/72 [==============================] - 2s 28ms/step - loss: 0.2197 - accuracy: 0.9175 - val_loss: 0.3361 - val_accuracy: 0.8611\n",
            "Epoch 59/400\n",
            "72/72 [==============================] - 2s 28ms/step - loss: 0.1933 - accuracy: 0.9184 - val_loss: 0.4518 - val_accuracy: 0.7778\n",
            "Epoch 60/400\n",
            "72/72 [==============================] - 2s 28ms/step - loss: 0.1737 - accuracy: 0.9314 - val_loss: 0.4108 - val_accuracy: 0.8333\n",
            "Epoch 61/400\n",
            "72/72 [==============================] - 2s 28ms/step - loss: 0.1600 - accuracy: 0.9358 - val_loss: 0.4045 - val_accuracy: 0.8611\n",
            "Epoch 62/400\n",
            "72/72 [==============================] - 2s 27ms/step - loss: 0.1620 - accuracy: 0.9384 - val_loss: 0.3320 - val_accuracy: 0.8611\n",
            "Epoch 63/400\n",
            "72/72 [==============================] - 2s 28ms/step - loss: 0.1574 - accuracy: 0.9410 - val_loss: 0.3990 - val_accuracy: 0.8056\n",
            "Epoch 64/400\n",
            "72/72 [==============================] - 2s 28ms/step - loss: 0.1678 - accuracy: 0.9306 - val_loss: 0.5547 - val_accuracy: 0.7778\n",
            "Epoch 65/400\n",
            "72/72 [==============================] - 2s 28ms/step - loss: 0.1790 - accuracy: 0.9227 - val_loss: 0.5224 - val_accuracy: 0.7778\n",
            "Epoch 66/400\n",
            "72/72 [==============================] - 2s 28ms/step - loss: 0.1533 - accuracy: 0.9453 - val_loss: 0.3682 - val_accuracy: 0.8056\n",
            "Epoch 67/400\n",
            "72/72 [==============================] - 2s 28ms/step - loss: 0.1392 - accuracy: 0.9470 - val_loss: 0.4420 - val_accuracy: 0.8333\n",
            "Epoch 68/400\n",
            "72/72 [==============================] - 2s 28ms/step - loss: 0.1588 - accuracy: 0.9392 - val_loss: 0.5141 - val_accuracy: 0.8056\n",
            "Epoch 69/400\n",
            "72/72 [==============================] - 2s 28ms/step - loss: 0.1477 - accuracy: 0.9401 - val_loss: 0.3726 - val_accuracy: 0.8611\n",
            "Epoch 70/400\n",
            "72/72 [==============================] - 2s 28ms/step - loss: 0.1195 - accuracy: 0.9549 - val_loss: 0.5311 - val_accuracy: 0.7778\n",
            "Epoch 71/400\n",
            "72/72 [==============================] - 2s 28ms/step - loss: 0.1272 - accuracy: 0.9566 - val_loss: 0.4061 - val_accuracy: 0.8611\n",
            "Epoch 72/400\n",
            "72/72 [==============================] - 2s 28ms/step - loss: 0.1456 - accuracy: 0.9497 - val_loss: 0.3483 - val_accuracy: 0.8611\n",
            "Epoch 73/400\n",
            "72/72 [==============================] - 2s 28ms/step - loss: 0.1523 - accuracy: 0.9436 - val_loss: 0.3219 - val_accuracy: 0.9167\n",
            "Epoch 74/400\n",
            "72/72 [==============================] - 2s 28ms/step - loss: 0.1437 - accuracy: 0.9488 - val_loss: 0.5023 - val_accuracy: 0.8056\n",
            "Epoch 75/400\n",
            "72/72 [==============================] - 2s 29ms/step - loss: 0.1238 - accuracy: 0.9505 - val_loss: 0.3906 - val_accuracy: 0.8333\n",
            "Epoch 76/400\n",
            "72/72 [==============================] - 2s 28ms/step - loss: 0.1067 - accuracy: 0.9609 - val_loss: 0.4564 - val_accuracy: 0.8056\n",
            "Epoch 77/400\n",
            "72/72 [==============================] - 2s 28ms/step - loss: 0.1099 - accuracy: 0.9627 - val_loss: 0.5495 - val_accuracy: 0.7222\n",
            "Epoch 78/400\n",
            "72/72 [==============================] - 2s 27ms/step - loss: 0.1129 - accuracy: 0.9575 - val_loss: 0.4656 - val_accuracy: 0.7778\n",
            "Epoch 79/400\n",
            "72/72 [==============================] - 2s 28ms/step - loss: 0.0867 - accuracy: 0.9688 - val_loss: 0.4598 - val_accuracy: 0.7778\n",
            "Epoch 80/400\n",
            "72/72 [==============================] - 2s 28ms/step - loss: 0.0949 - accuracy: 0.9670 - val_loss: 0.4902 - val_accuracy: 0.7500\n",
            "Epoch 81/400\n",
            "72/72 [==============================] - 2s 28ms/step - loss: 0.0964 - accuracy: 0.9653 - val_loss: 0.7136 - val_accuracy: 0.7500\n",
            "Epoch 82/400\n",
            "72/72 [==============================] - 2s 28ms/step - loss: 0.0979 - accuracy: 0.9688 - val_loss: 0.4253 - val_accuracy: 0.8056\n",
            "Epoch 83/400\n",
            "72/72 [==============================] - 2s 28ms/step - loss: 0.1032 - accuracy: 0.9627 - val_loss: 0.4923 - val_accuracy: 0.7778\n",
            "Epoch 84/400\n",
            "72/72 [==============================] - 2s 28ms/step - loss: 0.0926 - accuracy: 0.9722 - val_loss: 0.4731 - val_accuracy: 0.7778\n",
            "Epoch 85/400\n",
            "72/72 [==============================] - 2s 28ms/step - loss: 0.0942 - accuracy: 0.9705 - val_loss: 0.4876 - val_accuracy: 0.8611\n",
            "Epoch 86/400\n",
            "72/72 [==============================] - 2s 28ms/step - loss: 0.0993 - accuracy: 0.9653 - val_loss: 0.4856 - val_accuracy: 0.8333\n",
            "Epoch 87/400\n",
            "72/72 [==============================] - 2s 28ms/step - loss: 0.0651 - accuracy: 0.9844 - val_loss: 0.5616 - val_accuracy: 0.7778\n",
            "Epoch 88/400\n",
            "72/72 [==============================] - 2s 28ms/step - loss: 0.0956 - accuracy: 0.9670 - val_loss: 0.3418 - val_accuracy: 0.8056\n",
            "Epoch 89/400\n",
            "72/72 [==============================] - 2s 28ms/step - loss: 0.0762 - accuracy: 0.9766 - val_loss: 0.5243 - val_accuracy: 0.8056\n",
            "Epoch 90/400\n",
            "72/72 [==============================] - 2s 28ms/step - loss: 0.0781 - accuracy: 0.9783 - val_loss: 0.5243 - val_accuracy: 0.8333\n",
            "Epoch 91/400\n",
            "72/72 [==============================] - 2s 28ms/step - loss: 0.0650 - accuracy: 0.9792 - val_loss: 0.4997 - val_accuracy: 0.8333\n",
            "Epoch 92/400\n",
            "72/72 [==============================] - 2s 28ms/step - loss: 0.0933 - accuracy: 0.9661 - val_loss: 0.4339 - val_accuracy: 0.8056\n",
            "Epoch 93/400\n",
            "72/72 [==============================] - 2s 28ms/step - loss: 0.0799 - accuracy: 0.9714 - val_loss: 0.3775 - val_accuracy: 0.8056\n",
            "Epoch 94/400\n",
            "72/72 [==============================] - 2s 29ms/step - loss: 0.0713 - accuracy: 0.9731 - val_loss: 0.3036 - val_accuracy: 0.9167\n",
            "Epoch 95/400\n",
            "72/72 [==============================] - 2s 28ms/step - loss: 0.0848 - accuracy: 0.9679 - val_loss: 0.5382 - val_accuracy: 0.7500\n",
            "Epoch 96/400\n",
            "72/72 [==============================] - 2s 28ms/step - loss: 0.0827 - accuracy: 0.9714 - val_loss: 0.4499 - val_accuracy: 0.7778\n",
            "Epoch 97/400\n",
            "72/72 [==============================] - 2s 28ms/step - loss: 0.1053 - accuracy: 0.9575 - val_loss: 0.6421 - val_accuracy: 0.7500\n",
            "Epoch 98/400\n",
            "72/72 [==============================] - 2s 28ms/step - loss: 0.0854 - accuracy: 0.9688 - val_loss: 0.5305 - val_accuracy: 0.7778\n",
            "Epoch 99/400\n",
            "72/72 [==============================] - 2s 29ms/step - loss: 0.0747 - accuracy: 0.9714 - val_loss: 0.3834 - val_accuracy: 0.8056\n",
            "Epoch 100/400\n",
            "72/72 [==============================] - 2s 29ms/step - loss: 0.0736 - accuracy: 0.9792 - val_loss: 0.4817 - val_accuracy: 0.8056\n",
            "Epoch 101/400\n",
            "72/72 [==============================] - 2s 28ms/step - loss: 0.0781 - accuracy: 0.9722 - val_loss: 0.4851 - val_accuracy: 0.7778\n",
            "Epoch 102/400\n",
            "72/72 [==============================] - 2s 28ms/step - loss: 0.1081 - accuracy: 0.9575 - val_loss: 0.3276 - val_accuracy: 0.8611\n",
            "Epoch 103/400\n",
            "72/72 [==============================] - 2s 28ms/step - loss: 0.0915 - accuracy: 0.9688 - val_loss: 0.4600 - val_accuracy: 0.8333\n",
            "Epoch 104/400\n",
            "72/72 [==============================] - 2s 28ms/step - loss: 0.0555 - accuracy: 0.9861 - val_loss: 0.6275 - val_accuracy: 0.7500\n",
            "Epoch 105/400\n",
            "72/72 [==============================] - 2s 28ms/step - loss: 0.0587 - accuracy: 0.9844 - val_loss: 0.4466 - val_accuracy: 0.8056\n",
            "Epoch 106/400\n",
            "72/72 [==============================] - 2s 28ms/step - loss: 0.0589 - accuracy: 0.9792 - val_loss: 0.5469 - val_accuracy: 0.7500\n",
            "Epoch 107/400\n",
            "72/72 [==============================] - 2s 28ms/step - loss: 0.0571 - accuracy: 0.9800 - val_loss: 0.5154 - val_accuracy: 0.8056\n",
            "Epoch 108/400\n",
            "72/72 [==============================] - 2s 28ms/step - loss: 0.0572 - accuracy: 0.9783 - val_loss: 0.5810 - val_accuracy: 0.8056\n",
            "Epoch 109/400\n",
            "72/72 [==============================] - 2s 28ms/step - loss: 0.0549 - accuracy: 0.9783 - val_loss: 0.5384 - val_accuracy: 0.8056\n",
            "Epoch 110/400\n",
            "72/72 [==============================] - 2s 28ms/step - loss: 0.0524 - accuracy: 0.9826 - val_loss: 0.3770 - val_accuracy: 0.8333\n",
            "Epoch 111/400\n",
            "72/72 [==============================] - 2s 29ms/step - loss: 0.0645 - accuracy: 0.9818 - val_loss: 0.6587 - val_accuracy: 0.7500\n",
            "Epoch 112/400\n",
            "72/72 [==============================] - 2s 28ms/step - loss: 0.0569 - accuracy: 0.9818 - val_loss: 0.4728 - val_accuracy: 0.8611\n",
            "Epoch 113/400\n",
            "72/72 [==============================] - 2s 28ms/step - loss: 0.0599 - accuracy: 0.9800 - val_loss: 0.4494 - val_accuracy: 0.8333\n",
            "Epoch 114/400\n",
            "72/72 [==============================] - 2s 28ms/step - loss: 0.0339 - accuracy: 0.9939 - val_loss: 0.5100 - val_accuracy: 0.8056\n",
            "Epoch 115/400\n",
            "72/72 [==============================] - 2s 28ms/step - loss: 0.0691 - accuracy: 0.9714 - val_loss: 0.5570 - val_accuracy: 0.8056\n",
            "Epoch 116/400\n",
            "72/72 [==============================] - 2s 28ms/step - loss: 0.0513 - accuracy: 0.9826 - val_loss: 0.5472 - val_accuracy: 0.7500\n",
            "Epoch 117/400\n",
            "72/72 [==============================] - 2s 28ms/step - loss: 0.0489 - accuracy: 0.9826 - val_loss: 0.6639 - val_accuracy: 0.7778\n",
            "Epoch 118/400\n",
            "72/72 [==============================] - 2s 28ms/step - loss: 0.0487 - accuracy: 0.9852 - val_loss: 0.4489 - val_accuracy: 0.8611\n",
            "Epoch 119/400\n",
            "72/72 [==============================] - 2s 28ms/step - loss: 0.0504 - accuracy: 0.9878 - val_loss: 0.6061 - val_accuracy: 0.8056\n",
            "Epoch 120/400\n",
            "72/72 [==============================] - 2s 28ms/step - loss: 0.0520 - accuracy: 0.9818 - val_loss: 0.4896 - val_accuracy: 0.8056\n",
            "Epoch 121/400\n",
            "72/72 [==============================] - 2s 28ms/step - loss: 0.0435 - accuracy: 0.9861 - val_loss: 0.5378 - val_accuracy: 0.8056\n",
            "Epoch 122/400\n",
            "72/72 [==============================] - 2s 28ms/step - loss: 0.0344 - accuracy: 0.9896 - val_loss: 0.4394 - val_accuracy: 0.8611\n",
            "Epoch 123/400\n",
            "72/72 [==============================] - 2s 28ms/step - loss: 0.0533 - accuracy: 0.9826 - val_loss: 0.6531 - val_accuracy: 0.7778\n",
            "Epoch 124/400\n",
            "72/72 [==============================] - 2s 28ms/step - loss: 0.0455 - accuracy: 0.9870 - val_loss: 0.5609 - val_accuracy: 0.7778\n",
            "Epoch 125/400\n",
            "72/72 [==============================] - 2s 28ms/step - loss: 0.0643 - accuracy: 0.9740 - val_loss: 0.5111 - val_accuracy: 0.8056\n",
            "Epoch 126/400\n",
            "72/72 [==============================] - 2s 28ms/step - loss: 0.0544 - accuracy: 0.9818 - val_loss: 0.4754 - val_accuracy: 0.8056\n",
            "Epoch 127/400\n",
            "72/72 [==============================] - 2s 28ms/step - loss: 0.0642 - accuracy: 0.9766 - val_loss: 0.3622 - val_accuracy: 0.8611\n",
            "Epoch 128/400\n",
            "72/72 [==============================] - 2s 28ms/step - loss: 0.0509 - accuracy: 0.9809 - val_loss: 0.4050 - val_accuracy: 0.8611\n",
            "Epoch 129/400\n",
            "72/72 [==============================] - 2s 28ms/step - loss: 0.0367 - accuracy: 0.9931 - val_loss: 0.5471 - val_accuracy: 0.8056\n",
            "Epoch 130/400\n",
            "72/72 [==============================] - 2s 28ms/step - loss: 0.0414 - accuracy: 0.9870 - val_loss: 0.4772 - val_accuracy: 0.8333\n",
            "Epoch 131/400\n",
            "72/72 [==============================] - 2s 28ms/step - loss: 0.0318 - accuracy: 0.9896 - val_loss: 0.7112 - val_accuracy: 0.7500\n",
            "Epoch 132/400\n",
            "72/72 [==============================] - 2s 28ms/step - loss: 0.0273 - accuracy: 0.9957 - val_loss: 0.5049 - val_accuracy: 0.8333\n",
            "Epoch 133/400\n",
            "72/72 [==============================] - 2s 28ms/step - loss: 0.0340 - accuracy: 0.9905 - val_loss: 0.4253 - val_accuracy: 0.8611\n",
            "Epoch 134/400\n",
            "72/72 [==============================] - 2s 29ms/step - loss: 0.0378 - accuracy: 0.9870 - val_loss: 0.7933 - val_accuracy: 0.7500\n",
            "Epoch 135/400\n",
            "72/72 [==============================] - 2s 28ms/step - loss: 0.0589 - accuracy: 0.9757 - val_loss: 0.4756 - val_accuracy: 0.7778\n",
            "Epoch 136/400\n",
            "72/72 [==============================] - 2s 29ms/step - loss: 0.0508 - accuracy: 0.9852 - val_loss: 0.7075 - val_accuracy: 0.7500\n",
            "Epoch 137/400\n",
            "72/72 [==============================] - 2s 29ms/step - loss: 0.0549 - accuracy: 0.9818 - val_loss: 0.6826 - val_accuracy: 0.7500\n",
            "Epoch 138/400\n",
            "72/72 [==============================] - 2s 28ms/step - loss: 0.0406 - accuracy: 0.9896 - val_loss: 0.4976 - val_accuracy: 0.7778\n",
            "Epoch 139/400\n",
            "72/72 [==============================] - 2s 28ms/step - loss: 0.0730 - accuracy: 0.9748 - val_loss: 0.5014 - val_accuracy: 0.7778\n",
            "Epoch 140/400\n",
            "72/72 [==============================] - 2s 29ms/step - loss: 0.0593 - accuracy: 0.9748 - val_loss: 0.3338 - val_accuracy: 0.8889\n",
            "Epoch 141/400\n",
            "72/72 [==============================] - 2s 28ms/step - loss: 0.0358 - accuracy: 0.9887 - val_loss: 0.3479 - val_accuracy: 0.8611\n",
            "Epoch 142/400\n",
            "72/72 [==============================] - 2s 29ms/step - loss: 0.0376 - accuracy: 0.9878 - val_loss: 0.3696 - val_accuracy: 0.8333\n",
            "Epoch 143/400\n",
            "72/72 [==============================] - 2s 28ms/step - loss: 0.0381 - accuracy: 0.9861 - val_loss: 0.5657 - val_accuracy: 0.7778\n",
            "Epoch 144/400\n",
            "72/72 [==============================] - 2s 28ms/step - loss: 0.0354 - accuracy: 0.9887 - val_loss: 0.5439 - val_accuracy: 0.8056\n",
            "Epoch 145/400\n",
            "72/72 [==============================] - 2s 28ms/step - loss: 0.0318 - accuracy: 0.9896 - val_loss: 0.4367 - val_accuracy: 0.8611\n",
            "Epoch 146/400\n",
            "72/72 [==============================] - 2s 28ms/step - loss: 0.0237 - accuracy: 0.9965 - val_loss: 0.5204 - val_accuracy: 0.7778\n",
            "Epoch 147/400\n",
            "72/72 [==============================] - 2s 28ms/step - loss: 0.0220 - accuracy: 0.9922 - val_loss: 0.5044 - val_accuracy: 0.8333\n",
            "Epoch 148/400\n",
            "72/72 [==============================] - 2s 28ms/step - loss: 0.0250 - accuracy: 0.9922 - val_loss: 0.3140 - val_accuracy: 0.8889\n",
            "Epoch 149/400\n",
            "72/72 [==============================] - 2s 29ms/step - loss: 0.0184 - accuracy: 0.9974 - val_loss: 0.4802 - val_accuracy: 0.8333\n",
            "Epoch 150/400\n",
            "72/72 [==============================] - 2s 28ms/step - loss: 0.0236 - accuracy: 0.9931 - val_loss: 0.5770 - val_accuracy: 0.8333\n",
            "Epoch 151/400\n",
            "72/72 [==============================] - 2s 28ms/step - loss: 0.0515 - accuracy: 0.9792 - val_loss: 0.5332 - val_accuracy: 0.8333\n",
            "Epoch 152/400\n",
            "72/72 [==============================] - 2s 28ms/step - loss: 0.0446 - accuracy: 0.9878 - val_loss: 0.5853 - val_accuracy: 0.7778\n",
            "Epoch 153/400\n",
            "72/72 [==============================] - 2s 29ms/step - loss: 0.0457 - accuracy: 0.9826 - val_loss: 0.4409 - val_accuracy: 0.8889\n",
            "Epoch 154/400\n",
            "72/72 [==============================] - 2s 28ms/step - loss: 0.0451 - accuracy: 0.9826 - val_loss: 0.4349 - val_accuracy: 0.8611\n",
            "Epoch 155/400\n",
            "72/72 [==============================] - 2s 29ms/step - loss: 0.0341 - accuracy: 0.9905 - val_loss: 0.5357 - val_accuracy: 0.7778\n",
            "Epoch 156/400\n",
            "72/72 [==============================] - 2s 28ms/step - loss: 0.0364 - accuracy: 0.9844 - val_loss: 0.4816 - val_accuracy: 0.8056\n",
            "Epoch 157/400\n",
            "72/72 [==============================] - 2s 28ms/step - loss: 0.0320 - accuracy: 0.9905 - val_loss: 0.5985 - val_accuracy: 0.7222\n",
            "Epoch 158/400\n",
            "72/72 [==============================] - 2s 28ms/step - loss: 0.0315 - accuracy: 0.9905 - val_loss: 0.4019 - val_accuracy: 0.8611\n",
            "Epoch 159/400\n",
            "72/72 [==============================] - 2s 29ms/step - loss: 0.0209 - accuracy: 0.9957 - val_loss: 0.3856 - val_accuracy: 0.9167\n",
            "Epoch 160/400\n",
            "72/72 [==============================] - 2s 28ms/step - loss: 0.0236 - accuracy: 0.9939 - val_loss: 0.3863 - val_accuracy: 0.8333\n",
            "Epoch 161/400\n",
            "72/72 [==============================] - 2s 28ms/step - loss: 0.0211 - accuracy: 0.9948 - val_loss: 0.4266 - val_accuracy: 0.8056\n",
            "Epoch 162/400\n",
            "72/72 [==============================] - 2s 28ms/step - loss: 0.0193 - accuracy: 0.9948 - val_loss: 0.4012 - val_accuracy: 0.8056\n",
            "Epoch 163/400\n",
            "72/72 [==============================] - 2s 28ms/step - loss: 0.0239 - accuracy: 0.9913 - val_loss: 0.5126 - val_accuracy: 0.7778\n",
            "Epoch 164/400\n",
            "72/72 [==============================] - 2s 28ms/step - loss: 0.0312 - accuracy: 0.9870 - val_loss: 0.8217 - val_accuracy: 0.7222\n",
            "Epoch 165/400\n",
            "72/72 [==============================] - 2s 28ms/step - loss: 0.0355 - accuracy: 0.9870 - val_loss: 0.6220 - val_accuracy: 0.7778\n",
            "Epoch 166/400\n",
            "72/72 [==============================] - 2s 29ms/step - loss: 0.0388 - accuracy: 0.9870 - val_loss: 0.5390 - val_accuracy: 0.8056\n",
            "Epoch 167/400\n",
            "72/72 [==============================] - 2s 28ms/step - loss: 0.0391 - accuracy: 0.9887 - val_loss: 0.4210 - val_accuracy: 0.8333\n",
            "Epoch 168/400\n",
            "72/72 [==============================] - 2s 28ms/step - loss: 0.0201 - accuracy: 0.9965 - val_loss: 0.5549 - val_accuracy: 0.8056\n",
            "Epoch 169/400\n",
            "72/72 [==============================] - 2s 28ms/step - loss: 0.0527 - accuracy: 0.9800 - val_loss: 0.3625 - val_accuracy: 0.8333\n",
            "Epoch 170/400\n",
            "72/72 [==============================] - 2s 28ms/step - loss: 0.0388 - accuracy: 0.9852 - val_loss: 0.3971 - val_accuracy: 0.8333\n",
            "Epoch 171/400\n",
            "72/72 [==============================] - 2s 28ms/step - loss: 0.0493 - accuracy: 0.9852 - val_loss: 0.6171 - val_accuracy: 0.7778\n",
            "Epoch 172/400\n",
            "72/72 [==============================] - 2s 29ms/step - loss: 0.0403 - accuracy: 0.9913 - val_loss: 0.5582 - val_accuracy: 0.8333\n",
            "Epoch 173/400\n",
            "72/72 [==============================] - 2s 29ms/step - loss: 0.0208 - accuracy: 0.9948 - val_loss: 0.5899 - val_accuracy: 0.8056\n",
            "Epoch 174/400\n",
            "72/72 [==============================] - 2s 29ms/step - loss: 0.0186 - accuracy: 0.9965 - val_loss: 0.7625 - val_accuracy: 0.7778\n",
            "Epoch 175/400\n",
            "72/72 [==============================] - 2s 29ms/step - loss: 0.0192 - accuracy: 0.9957 - val_loss: 0.4903 - val_accuracy: 0.7778\n",
            "Epoch 176/400\n",
            "72/72 [==============================] - 2s 28ms/step - loss: 0.0134 - accuracy: 0.9983 - val_loss: 0.5133 - val_accuracy: 0.8333\n",
            "Epoch 177/400\n",
            "72/72 [==============================] - 2s 28ms/step - loss: 0.0147 - accuracy: 0.9974 - val_loss: 0.4886 - val_accuracy: 0.7778\n",
            "Epoch 178/400\n",
            "72/72 [==============================] - 2s 29ms/step - loss: 0.0219 - accuracy: 0.9948 - val_loss: 0.5751 - val_accuracy: 0.7222\n",
            "Epoch 179/400\n",
            "72/72 [==============================] - 2s 28ms/step - loss: 0.0189 - accuracy: 0.9957 - val_loss: 0.6220 - val_accuracy: 0.8333\n",
            "Epoch 180/400\n",
            "72/72 [==============================] - 2s 28ms/step - loss: 0.0186 - accuracy: 0.9948 - val_loss: 0.5956 - val_accuracy: 0.8056\n",
            "Epoch 181/400\n",
            "72/72 [==============================] - 2s 28ms/step - loss: 0.0098 - accuracy: 0.9983 - val_loss: 0.5042 - val_accuracy: 0.8056\n",
            "Epoch 182/400\n",
            "72/72 [==============================] - 2s 28ms/step - loss: 0.0162 - accuracy: 0.9948 - val_loss: 0.5071 - val_accuracy: 0.8611\n",
            "Epoch 183/400\n",
            "72/72 [==============================] - 2s 28ms/step - loss: 0.0179 - accuracy: 0.9957 - val_loss: 0.6052 - val_accuracy: 0.7778\n",
            "Epoch 184/400\n",
            "72/72 [==============================] - 2s 28ms/step - loss: 0.0267 - accuracy: 0.9939 - val_loss: 0.5189 - val_accuracy: 0.7778\n",
            "Epoch 185/400\n",
            "72/72 [==============================] - 2s 28ms/step - loss: 0.0164 - accuracy: 0.9983 - val_loss: 0.6605 - val_accuracy: 0.8333\n",
            "Epoch 186/400\n",
            "72/72 [==============================] - 2s 28ms/step - loss: 0.0398 - accuracy: 0.9878 - val_loss: 0.5882 - val_accuracy: 0.7778\n",
            "Epoch 187/400\n",
            "72/72 [==============================] - 2s 28ms/step - loss: 0.0275 - accuracy: 0.9922 - val_loss: 0.5827 - val_accuracy: 0.8611\n",
            "Epoch 188/400\n",
            "72/72 [==============================] - 2s 28ms/step - loss: 0.0171 - accuracy: 0.9957 - val_loss: 0.6352 - val_accuracy: 0.7500\n",
            "Epoch 189/400\n",
            "72/72 [==============================] - 2s 28ms/step - loss: 0.0177 - accuracy: 0.9965 - val_loss: 0.7284 - val_accuracy: 0.7500\n",
            "Epoch 190/400\n",
            "72/72 [==============================] - 2s 28ms/step - loss: 0.0192 - accuracy: 0.9948 - val_loss: 0.6799 - val_accuracy: 0.8056\n",
            "Epoch 191/400\n",
            "72/72 [==============================] - 2s 29ms/step - loss: 0.0246 - accuracy: 0.9922 - val_loss: 1.0466 - val_accuracy: 0.7222\n",
            "Epoch 192/400\n",
            "72/72 [==============================] - 2s 28ms/step - loss: 0.0346 - accuracy: 0.9852 - val_loss: 0.9024 - val_accuracy: 0.7500\n",
            "Epoch 193/400\n",
            "72/72 [==============================] - 2s 29ms/step - loss: 0.0473 - accuracy: 0.9835 - val_loss: 0.4386 - val_accuracy: 0.8611\n",
            "Epoch 194/400\n",
            "72/72 [==============================] - 2s 29ms/step - loss: 0.0335 - accuracy: 0.9896 - val_loss: 0.4635 - val_accuracy: 0.8611\n",
            "Epoch 195/400\n",
            "72/72 [==============================] - 2s 29ms/step - loss: 0.0394 - accuracy: 0.9835 - val_loss: 0.4814 - val_accuracy: 0.8056\n",
            "Epoch 196/400\n",
            "72/72 [==============================] - 2s 29ms/step - loss: 0.0218 - accuracy: 0.9931 - val_loss: 0.5043 - val_accuracy: 0.8611\n",
            "Epoch 197/400\n",
            "72/72 [==============================] - 2s 29ms/step - loss: 0.0319 - accuracy: 0.9861 - val_loss: 0.5385 - val_accuracy: 0.8056\n",
            "Epoch 198/400\n",
            "72/72 [==============================] - 2s 28ms/step - loss: 0.0260 - accuracy: 0.9905 - val_loss: 0.4500 - val_accuracy: 0.8611\n",
            "Epoch 199/400\n",
            "72/72 [==============================] - 2s 28ms/step - loss: 0.0264 - accuracy: 0.9922 - val_loss: 0.7303 - val_accuracy: 0.7778\n",
            "Epoch 200/400\n",
            "72/72 [==============================] - 2s 29ms/step - loss: 0.0361 - accuracy: 0.9887 - val_loss: 0.6372 - val_accuracy: 0.7500\n",
            "Epoch 201/400\n",
            "72/72 [==============================] - 2s 29ms/step - loss: 0.0350 - accuracy: 0.9878 - val_loss: 0.6958 - val_accuracy: 0.7500\n",
            "Epoch 202/400\n",
            "72/72 [==============================] - 2s 29ms/step - loss: 0.0213 - accuracy: 0.9957 - val_loss: 0.6887 - val_accuracy: 0.7500\n",
            "Epoch 203/400\n",
            "72/72 [==============================] - 2s 28ms/step - loss: 0.0172 - accuracy: 0.9957 - val_loss: 0.8921 - val_accuracy: 0.7500\n",
            "Epoch 204/400\n",
            "72/72 [==============================] - 2s 28ms/step - loss: 0.0210 - accuracy: 0.9948 - val_loss: 0.6175 - val_accuracy: 0.7778\n",
            "Epoch 205/400\n",
            "72/72 [==============================] - 2s 29ms/step - loss: 0.0139 - accuracy: 0.9965 - val_loss: 0.6269 - val_accuracy: 0.8056\n",
            "Epoch 206/400\n",
            "72/72 [==============================] - 2s 29ms/step - loss: 0.0111 - accuracy: 0.9983 - val_loss: 0.6942 - val_accuracy: 0.7500\n",
            "Epoch 207/400\n",
            "72/72 [==============================] - 2s 29ms/step - loss: 0.0070 - accuracy: 0.9991 - val_loss: 0.5458 - val_accuracy: 0.7500\n",
            "Epoch 208/400\n",
            "72/72 [==============================] - 2s 29ms/step - loss: 0.0077 - accuracy: 0.9974 - val_loss: 0.6330 - val_accuracy: 0.7778\n",
            "Epoch 209/400\n",
            "72/72 [==============================] - 2s 29ms/step - loss: 0.0096 - accuracy: 0.9991 - val_loss: 0.7171 - val_accuracy: 0.7778\n",
            "Epoch 210/400\n",
            "72/72 [==============================] - 2s 29ms/step - loss: 0.0139 - accuracy: 0.9991 - val_loss: 0.6440 - val_accuracy: 0.7500\n",
            "Epoch 211/400\n",
            "72/72 [==============================] - 2s 29ms/step - loss: 0.0111 - accuracy: 0.9983 - val_loss: 0.5269 - val_accuracy: 0.7778\n",
            "Epoch 212/400\n",
            "72/72 [==============================] - 2s 29ms/step - loss: 0.0099 - accuracy: 0.9983 - val_loss: 0.6728 - val_accuracy: 0.7500\n",
            "Epoch 213/400\n",
            "72/72 [==============================] - 2s 29ms/step - loss: 0.0371 - accuracy: 0.9878 - val_loss: 0.4328 - val_accuracy: 0.7222\n",
            "Epoch 214/400\n",
            "72/72 [==============================] - 2s 29ms/step - loss: 0.0296 - accuracy: 0.9870 - val_loss: 0.7351 - val_accuracy: 0.7778\n",
            "Epoch 215/400\n",
            "72/72 [==============================] - 2s 29ms/step - loss: 0.0241 - accuracy: 0.9957 - val_loss: 0.7767 - val_accuracy: 0.7500\n",
            "Epoch 216/400\n",
            "72/72 [==============================] - 2s 29ms/step - loss: 0.0238 - accuracy: 0.9913 - val_loss: 0.9461 - val_accuracy: 0.7500\n",
            "Epoch 217/400\n",
            "72/72 [==============================] - 2s 29ms/step - loss: 0.0205 - accuracy: 0.9939 - val_loss: 0.7244 - val_accuracy: 0.7778\n",
            "Epoch 218/400\n",
            "72/72 [==============================] - 2s 29ms/step - loss: 0.0262 - accuracy: 0.9896 - val_loss: 0.8581 - val_accuracy: 0.7500\n",
            "Epoch 219/400\n",
            "72/72 [==============================] - 2s 29ms/step - loss: 0.0222 - accuracy: 0.9913 - val_loss: 0.5492 - val_accuracy: 0.7500\n",
            "Epoch 220/400\n",
            "72/72 [==============================] - 2s 28ms/step - loss: 0.0103 - accuracy: 0.9991 - val_loss: 0.4953 - val_accuracy: 0.8056\n",
            "Epoch 221/400\n",
            "72/72 [==============================] - 2s 28ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.5609 - val_accuracy: 0.7500\n",
            "Epoch 222/400\n",
            "72/72 [==============================] - 2s 29ms/step - loss: 0.0147 - accuracy: 0.9957 - val_loss: 0.6361 - val_accuracy: 0.7778\n",
            "Epoch 223/400\n",
            "72/72 [==============================] - 2s 29ms/step - loss: 0.0154 - accuracy: 0.9957 - val_loss: 0.8092 - val_accuracy: 0.7500\n",
            "Epoch 224/400\n",
            "72/72 [==============================] - 2s 29ms/step - loss: 0.0229 - accuracy: 0.9887 - val_loss: 0.6207 - val_accuracy: 0.7222\n",
            "Epoch 225/400\n",
            "72/72 [==============================] - 2s 28ms/step - loss: 0.0287 - accuracy: 0.9931 - val_loss: 0.4930 - val_accuracy: 0.8056\n",
            "Epoch 226/400\n",
            "72/72 [==============================] - 2s 29ms/step - loss: 0.0277 - accuracy: 0.9878 - val_loss: 0.8045 - val_accuracy: 0.7500\n",
            "Epoch 227/400\n",
            "72/72 [==============================] - 2s 28ms/step - loss: 0.0187 - accuracy: 0.9948 - val_loss: 0.6289 - val_accuracy: 0.7500\n",
            "Epoch 228/400\n",
            "72/72 [==============================] - 2s 28ms/step - loss: 0.0293 - accuracy: 0.9905 - val_loss: 0.8266 - val_accuracy: 0.7500\n",
            "Epoch 229/400\n",
            "72/72 [==============================] - 2s 29ms/step - loss: 0.0224 - accuracy: 0.9931 - val_loss: 0.7452 - val_accuracy: 0.8056\n",
            "Epoch 230/400\n",
            "72/72 [==============================] - 2s 29ms/step - loss: 0.0110 - accuracy: 0.9991 - val_loss: 0.4778 - val_accuracy: 0.7778\n",
            "Epoch 231/400\n",
            "72/72 [==============================] - 2s 29ms/step - loss: 0.0119 - accuracy: 0.9983 - val_loss: 0.5299 - val_accuracy: 0.8056\n",
            "Epoch 232/400\n",
            "72/72 [==============================] - 2s 29ms/step - loss: 0.0113 - accuracy: 0.9957 - val_loss: 0.5898 - val_accuracy: 0.8056\n",
            "Epoch 233/400\n",
            "72/72 [==============================] - 2s 29ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.5839 - val_accuracy: 0.8056\n",
            "Epoch 234/400\n",
            "72/72 [==============================] - 2s 29ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.7053 - val_accuracy: 0.7778\n",
            "Epoch 235/400\n",
            "72/72 [==============================] - 2s 29ms/step - loss: 0.0115 - accuracy: 0.9974 - val_loss: 0.5464 - val_accuracy: 0.8611\n",
            "Epoch 236/400\n",
            "72/72 [==============================] - 2s 29ms/step - loss: 0.0135 - accuracy: 0.9957 - val_loss: 0.7904 - val_accuracy: 0.8333\n",
            "Epoch 237/400\n",
            "72/72 [==============================] - 2s 29ms/step - loss: 0.0226 - accuracy: 0.9905 - val_loss: 0.6035 - val_accuracy: 0.8333\n",
            "Epoch 238/400\n",
            "72/72 [==============================] - 2s 29ms/step - loss: 0.0089 - accuracy: 0.9983 - val_loss: 0.5640 - val_accuracy: 0.8611\n",
            "Epoch 239/400\n",
            "72/72 [==============================] - 2s 29ms/step - loss: 0.0119 - accuracy: 0.9991 - val_loss: 0.8050 - val_accuracy: 0.7500\n",
            "Epoch 240/400\n",
            "72/72 [==============================] - 2s 29ms/step - loss: 0.0232 - accuracy: 0.9913 - val_loss: 0.8751 - val_accuracy: 0.7500\n",
            "Epoch 241/400\n",
            "72/72 [==============================] - 2s 29ms/step - loss: 0.0261 - accuracy: 0.9939 - val_loss: 0.5122 - val_accuracy: 0.8333\n",
            "Epoch 242/400\n",
            "72/72 [==============================] - 2s 29ms/step - loss: 0.0211 - accuracy: 0.9939 - val_loss: 0.6089 - val_accuracy: 0.8056\n",
            "Epoch 243/400\n",
            "72/72 [==============================] - 2s 29ms/step - loss: 0.0357 - accuracy: 0.9852 - val_loss: 0.8312 - val_accuracy: 0.7778\n",
            "Epoch 244/400\n",
            "72/72 [==============================] - 2s 28ms/step - loss: 0.0099 - accuracy: 0.9991 - val_loss: 0.6860 - val_accuracy: 0.7778\n",
            "Epoch 245/400\n",
            "72/72 [==============================] - 2s 29ms/step - loss: 0.0117 - accuracy: 0.9965 - val_loss: 0.5458 - val_accuracy: 0.8333\n",
            "Epoch 246/400\n",
            "72/72 [==============================] - 2s 29ms/step - loss: 0.0118 - accuracy: 0.9974 - val_loss: 0.5923 - val_accuracy: 0.7778\n",
            "Epoch 247/400\n",
            "72/72 [==============================] - 2s 29ms/step - loss: 0.0073 - accuracy: 0.9991 - val_loss: 0.5809 - val_accuracy: 0.7778\n",
            "Epoch 248/400\n",
            "72/72 [==============================] - 2s 29ms/step - loss: 0.0115 - accuracy: 0.9974 - val_loss: 0.6012 - val_accuracy: 0.8056\n",
            "Epoch 249/400\n",
            "72/72 [==============================] - 2s 29ms/step - loss: 0.0135 - accuracy: 0.9957 - val_loss: 0.5666 - val_accuracy: 0.8333\n",
            "Epoch 250/400\n",
            "72/72 [==============================] - 2s 29ms/step - loss: 0.0107 - accuracy: 0.9965 - val_loss: 0.7775 - val_accuracy: 0.7500\n",
            "Epoch 251/400\n",
            "72/72 [==============================] - 2s 29ms/step - loss: 0.0176 - accuracy: 0.9939 - val_loss: 0.6543 - val_accuracy: 0.7500\n",
            "Epoch 252/400\n",
            "72/72 [==============================] - 2s 29ms/step - loss: 0.0387 - accuracy: 0.9878 - val_loss: 0.5362 - val_accuracy: 0.7778\n",
            "Epoch 253/400\n",
            "72/72 [==============================] - 2s 29ms/step - loss: 0.0121 - accuracy: 0.9991 - val_loss: 0.5060 - val_accuracy: 0.8056\n",
            "Epoch 254/400\n",
            "72/72 [==============================] - 2s 28ms/step - loss: 0.0127 - accuracy: 0.9957 - val_loss: 0.5191 - val_accuracy: 0.8333\n",
            "Epoch 255/400\n",
            "72/72 [==============================] - 2s 28ms/step - loss: 0.0153 - accuracy: 0.9957 - val_loss: 0.6021 - val_accuracy: 0.8333\n",
            "Epoch 256/400\n",
            "72/72 [==============================] - 2s 28ms/step - loss: 0.0085 - accuracy: 0.9991 - val_loss: 0.6257 - val_accuracy: 0.7778\n",
            "Epoch 257/400\n",
            "72/72 [==============================] - 2s 29ms/step - loss: 0.0060 - accuracy: 0.9991 - val_loss: 0.7072 - val_accuracy: 0.8056\n",
            "Epoch 258/400\n",
            "72/72 [==============================] - 2s 28ms/step - loss: 0.0050 - accuracy: 0.9991 - val_loss: 0.4470 - val_accuracy: 0.8333\n",
            "Epoch 259/400\n",
            "72/72 [==============================] - 2s 29ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.5073 - val_accuracy: 0.8056\n",
            "Epoch 260/400\n",
            "72/72 [==============================] - 2s 29ms/step - loss: 0.0117 - accuracy: 0.9965 - val_loss: 0.7996 - val_accuracy: 0.7778\n",
            "Epoch 261/400\n",
            "72/72 [==============================] - 2s 29ms/step - loss: 0.0096 - accuracy: 0.9974 - val_loss: 0.9228 - val_accuracy: 0.7778\n",
            "Epoch 262/400\n",
            "72/72 [==============================] - 2s 29ms/step - loss: 0.0105 - accuracy: 0.9983 - val_loss: 0.6279 - val_accuracy: 0.7778\n",
            "Epoch 263/400\n",
            "72/72 [==============================] - 2s 29ms/step - loss: 0.0082 - accuracy: 0.9991 - val_loss: 0.8251 - val_accuracy: 0.8333\n",
            "Epoch 264/400\n",
            "72/72 [==============================] - 2s 30ms/step - loss: 0.0076 - accuracy: 0.9983 - val_loss: 1.1421 - val_accuracy: 0.7222\n",
            "Epoch 265/400\n",
            "72/72 [==============================] - 2s 29ms/step - loss: 0.0064 - accuracy: 0.9983 - val_loss: 0.6641 - val_accuracy: 0.8333\n",
            "Epoch 266/400\n",
            "72/72 [==============================] - 2s 29ms/step - loss: 0.0048 - accuracy: 0.9991 - val_loss: 0.5922 - val_accuracy: 0.8333\n",
            "Epoch 267/400\n",
            "72/72 [==============================] - 2s 29ms/step - loss: 0.0126 - accuracy: 0.9965 - val_loss: 0.7166 - val_accuracy: 0.8056\n",
            "Epoch 268/400\n",
            "72/72 [==============================] - 2s 29ms/step - loss: 0.0157 - accuracy: 0.9957 - val_loss: 0.6816 - val_accuracy: 0.7778\n",
            "Epoch 269/400\n",
            "72/72 [==============================] - 2s 30ms/step - loss: 0.0170 - accuracy: 0.9948 - val_loss: 0.7420 - val_accuracy: 0.7500\n",
            "Epoch 270/400\n",
            "72/72 [==============================] - 2s 29ms/step - loss: 0.0120 - accuracy: 0.9991 - val_loss: 0.5123 - val_accuracy: 0.8056\n",
            "Epoch 271/400\n",
            "72/72 [==============================] - 2s 29ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.5705 - val_accuracy: 0.8333\n",
            "Epoch 272/400\n",
            "72/72 [==============================] - 2s 30ms/step - loss: 0.0185 - accuracy: 0.9965 - val_loss: 1.1327 - val_accuracy: 0.7222\n",
            "Epoch 273/400\n",
            "72/72 [==============================] - 2s 30ms/step - loss: 0.0212 - accuracy: 0.9974 - val_loss: 0.3965 - val_accuracy: 0.8333\n",
            "Epoch 274/400\n",
            "72/72 [==============================] - 2s 29ms/step - loss: 0.0104 - accuracy: 0.9983 - val_loss: 0.6034 - val_accuracy: 0.8056\n",
            "Epoch 275/400\n",
            "72/72 [==============================] - 2s 30ms/step - loss: 0.0066 - accuracy: 0.9983 - val_loss: 0.5611 - val_accuracy: 0.8056\n",
            "Epoch 276/400\n",
            "72/72 [==============================] - 2s 30ms/step - loss: 0.0072 - accuracy: 0.9991 - val_loss: 0.7306 - val_accuracy: 0.8056\n",
            "Epoch 277/400\n",
            "72/72 [==============================] - 2s 29ms/step - loss: 0.0139 - accuracy: 0.9948 - val_loss: 0.7172 - val_accuracy: 0.7500\n",
            "Epoch 278/400\n",
            "72/72 [==============================] - 2s 29ms/step - loss: 0.0328 - accuracy: 0.9887 - val_loss: 1.0730 - val_accuracy: 0.7500\n",
            "Epoch 279/400\n",
            "72/72 [==============================] - 2s 30ms/step - loss: 0.0312 - accuracy: 0.9896 - val_loss: 0.4550 - val_accuracy: 0.8333\n",
            "Epoch 280/400\n",
            "72/72 [==============================] - 2s 29ms/step - loss: 0.0277 - accuracy: 0.9905 - val_loss: 0.3323 - val_accuracy: 0.8889\n",
            "Epoch 281/400\n",
            "72/72 [==============================] - 2s 30ms/step - loss: 0.0190 - accuracy: 0.9913 - val_loss: 0.5319 - val_accuracy: 0.7778\n",
            "Epoch 282/400\n",
            "72/72 [==============================] - 2s 29ms/step - loss: 0.0243 - accuracy: 0.9913 - val_loss: 0.7547 - val_accuracy: 0.8056\n",
            "Epoch 283/400\n",
            "72/72 [==============================] - 2s 29ms/step - loss: 0.0157 - accuracy: 0.9948 - val_loss: 0.8885 - val_accuracy: 0.8056\n",
            "Epoch 284/400\n",
            "72/72 [==============================] - 2s 29ms/step - loss: 0.0237 - accuracy: 0.9913 - val_loss: 0.5667 - val_accuracy: 0.8056\n",
            "Epoch 285/400\n",
            "72/72 [==============================] - 2s 29ms/step - loss: 0.0112 - accuracy: 0.9957 - val_loss: 0.6928 - val_accuracy: 0.7778\n",
            "Epoch 286/400\n",
            "72/72 [==============================] - 2s 30ms/step - loss: 0.0138 - accuracy: 0.9939 - val_loss: 0.6824 - val_accuracy: 0.7500\n",
            "Epoch 287/400\n",
            "72/72 [==============================] - 2s 29ms/step - loss: 0.0122 - accuracy: 0.9957 - val_loss: 0.5954 - val_accuracy: 0.8611\n",
            "Epoch 288/400\n",
            "72/72 [==============================] - 2s 29ms/step - loss: 0.0191 - accuracy: 0.9913 - val_loss: 0.8562 - val_accuracy: 0.7778\n",
            "Epoch 289/400\n",
            "72/72 [==============================] - 2s 29ms/step - loss: 0.0199 - accuracy: 0.9939 - val_loss: 0.5244 - val_accuracy: 0.8333\n",
            "Epoch 290/400\n",
            "72/72 [==============================] - 2s 29ms/step - loss: 0.0098 - accuracy: 0.9983 - val_loss: 0.6068 - val_accuracy: 0.7778\n",
            "Epoch 291/400\n",
            "72/72 [==============================] - 2s 29ms/step - loss: 0.0181 - accuracy: 0.9939 - val_loss: 0.5363 - val_accuracy: 0.8333\n",
            "Epoch 292/400\n",
            "72/72 [==============================] - 2s 29ms/step - loss: 0.0117 - accuracy: 0.9957 - val_loss: 0.6619 - val_accuracy: 0.8056\n",
            "Epoch 293/400\n",
            "72/72 [==============================] - 2s 29ms/step - loss: 0.0062 - accuracy: 0.9974 - val_loss: 0.6020 - val_accuracy: 0.7778\n",
            "Epoch 294/400\n",
            "72/72 [==============================] - 2s 29ms/step - loss: 0.0056 - accuracy: 0.9991 - val_loss: 0.6578 - val_accuracy: 0.8056\n",
            "Epoch 295/400\n",
            "72/72 [==============================] - 2s 29ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.6017 - val_accuracy: 0.8056\n",
            "Epoch 296/400\n",
            "72/72 [==============================] - 2s 29ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.5575 - val_accuracy: 0.8056\n",
            "Epoch 297/400\n",
            "72/72 [==============================] - 2s 29ms/step - loss: 0.0100 - accuracy: 0.9965 - val_loss: 0.6048 - val_accuracy: 0.7778\n",
            "Epoch 298/400\n",
            "72/72 [==============================] - 2s 28ms/step - loss: 0.0201 - accuracy: 0.9939 - val_loss: 0.7824 - val_accuracy: 0.7500\n",
            "Epoch 299/400\n",
            "72/72 [==============================] - 2s 29ms/step - loss: 0.0164 - accuracy: 0.9957 - val_loss: 0.6789 - val_accuracy: 0.8056\n",
            "Epoch 300/400\n",
            "72/72 [==============================] - 2s 29ms/step - loss: 0.0209 - accuracy: 0.9948 - val_loss: 0.5351 - val_accuracy: 0.8611\n",
            "Epoch 301/400\n",
            "72/72 [==============================] - 2s 29ms/step - loss: 0.0099 - accuracy: 0.9983 - val_loss: 0.7430 - val_accuracy: 0.7778\n",
            "Epoch 302/400\n",
            "72/72 [==============================] - 2s 29ms/step - loss: 0.0254 - accuracy: 0.9905 - val_loss: 0.8203 - val_accuracy: 0.8056\n",
            "Epoch 303/400\n",
            "72/72 [==============================] - 2s 29ms/step - loss: 0.0188 - accuracy: 0.9922 - val_loss: 0.7284 - val_accuracy: 0.7778\n",
            "Epoch 304/400\n",
            "72/72 [==============================] - 2s 29ms/step - loss: 0.0226 - accuracy: 0.9913 - val_loss: 0.6262 - val_accuracy: 0.8611\n",
            "Epoch 305/400\n",
            "72/72 [==============================] - 2s 29ms/step - loss: 0.0167 - accuracy: 0.9965 - val_loss: 0.7036 - val_accuracy: 0.8056\n",
            "Epoch 306/400\n",
            "72/72 [==============================] - 2s 29ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.7753 - val_accuracy: 0.7778\n",
            "Epoch 307/400\n",
            "72/72 [==============================] - 2s 29ms/step - loss: 0.0040 - accuracy: 0.9991 - val_loss: 0.9525 - val_accuracy: 0.7500\n",
            "Epoch 308/400\n",
            "72/72 [==============================] - 2s 29ms/step - loss: 0.0104 - accuracy: 0.9965 - val_loss: 0.5732 - val_accuracy: 0.8056\n",
            "Epoch 309/400\n",
            "72/72 [==============================] - 2s 30ms/step - loss: 0.0049 - accuracy: 0.9991 - val_loss: 0.4858 - val_accuracy: 0.8056\n",
            "Epoch 310/400\n",
            "72/72 [==============================] - 2s 30ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.5841 - val_accuracy: 0.8056\n",
            "Epoch 311/400\n",
            "72/72 [==============================] - 2s 30ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.6612 - val_accuracy: 0.8333\n",
            "Epoch 312/400\n",
            "72/72 [==============================] - 2s 29ms/step - loss: 0.0062 - accuracy: 0.9983 - val_loss: 0.7205 - val_accuracy: 0.8333\n",
            "Epoch 313/400\n",
            "72/72 [==============================] - 2s 30ms/step - loss: 0.0052 - accuracy: 0.9991 - val_loss: 0.6892 - val_accuracy: 0.8333\n",
            "Epoch 314/400\n",
            "72/72 [==============================] - 2s 29ms/step - loss: 0.0039 - accuracy: 0.9983 - val_loss: 0.6242 - val_accuracy: 0.8056\n",
            "Epoch 315/400\n",
            "72/72 [==============================] - 2s 30ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.5828 - val_accuracy: 0.8611\n",
            "Epoch 316/400\n",
            "72/72 [==============================] - 2s 30ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.6792 - val_accuracy: 0.8333\n",
            "Epoch 317/400\n",
            "72/72 [==============================] - 2s 30ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.7253 - val_accuracy: 0.8333\n",
            "Epoch 318/400\n",
            "72/72 [==============================] - 2s 30ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.7030 - val_accuracy: 0.8333\n",
            "Epoch 319/400\n",
            "72/72 [==============================] - 2s 30ms/step - loss: 0.0042 - accuracy: 0.9983 - val_loss: 0.6630 - val_accuracy: 0.7500\n",
            "Epoch 320/400\n",
            "72/72 [==============================] - 2s 29ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.6052 - val_accuracy: 0.8056\n",
            "Epoch 321/400\n",
            "72/72 [==============================] - 2s 29ms/step - loss: 0.0060 - accuracy: 0.9991 - val_loss: 0.5089 - val_accuracy: 0.8333\n",
            "Epoch 322/400\n",
            "72/72 [==============================] - 2s 29ms/step - loss: 0.0161 - accuracy: 0.9939 - val_loss: 0.9977 - val_accuracy: 0.8056\n",
            "Epoch 323/400\n",
            "72/72 [==============================] - 2s 29ms/step - loss: 0.0302 - accuracy: 0.9870 - val_loss: 0.7830 - val_accuracy: 0.8056\n",
            "Epoch 324/400\n",
            "72/72 [==============================] - 2s 29ms/step - loss: 0.0280 - accuracy: 0.9896 - val_loss: 0.6288 - val_accuracy: 0.8333\n",
            "Epoch 325/400\n",
            "72/72 [==============================] - 2s 29ms/step - loss: 0.0284 - accuracy: 0.9896 - val_loss: 0.6451 - val_accuracy: 0.7778\n",
            "Epoch 326/400\n",
            "72/72 [==============================] - 2s 29ms/step - loss: 0.0277 - accuracy: 0.9922 - val_loss: 0.6295 - val_accuracy: 0.7500\n",
            "Epoch 327/400\n",
            "72/72 [==============================] - 2s 29ms/step - loss: 0.0112 - accuracy: 0.9974 - val_loss: 0.6069 - val_accuracy: 0.7778\n",
            "Epoch 328/400\n",
            "72/72 [==============================] - 2s 29ms/step - loss: 0.0097 - accuracy: 0.9983 - val_loss: 0.7296 - val_accuracy: 0.7778\n",
            "Epoch 329/400\n",
            "72/72 [==============================] - 2s 29ms/step - loss: 0.0166 - accuracy: 0.9948 - val_loss: 0.5268 - val_accuracy: 0.8056\n",
            "Epoch 330/400\n",
            "72/72 [==============================] - 2s 29ms/step - loss: 0.0076 - accuracy: 0.9983 - val_loss: 0.6142 - val_accuracy: 0.8056\n",
            "Epoch 331/400\n",
            "72/72 [==============================] - 2s 29ms/step - loss: 0.0134 - accuracy: 0.9948 - val_loss: 0.4652 - val_accuracy: 0.8056\n",
            "Epoch 332/400\n",
            "72/72 [==============================] - 2s 29ms/step - loss: 0.0218 - accuracy: 0.9939 - val_loss: 0.6841 - val_accuracy: 0.8611\n",
            "Epoch 333/400\n",
            "72/72 [==============================] - 2s 29ms/step - loss: 0.0221 - accuracy: 0.9878 - val_loss: 0.7646 - val_accuracy: 0.7500\n",
            "Epoch 334/400\n",
            "72/72 [==============================] - 2s 29ms/step - loss: 0.0264 - accuracy: 0.9905 - val_loss: 0.8725 - val_accuracy: 0.7222\n",
            "Epoch 335/400\n",
            "72/72 [==============================] - 2s 29ms/step - loss: 0.0169 - accuracy: 0.9957 - val_loss: 0.6022 - val_accuracy: 0.7778\n",
            "Epoch 336/400\n",
            "72/72 [==============================] - 2s 30ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.7856 - val_accuracy: 0.8056\n",
            "Epoch 337/400\n",
            "72/72 [==============================] - 2s 29ms/step - loss: 0.0079 - accuracy: 0.9974 - val_loss: 0.7205 - val_accuracy: 0.8056\n",
            "Epoch 338/400\n",
            "72/72 [==============================] - 2s 30ms/step - loss: 0.0131 - accuracy: 0.9965 - val_loss: 0.7315 - val_accuracy: 0.8056\n",
            "Epoch 339/400\n",
            "72/72 [==============================] - 2s 29ms/step - loss: 0.0083 - accuracy: 0.9991 - val_loss: 0.6823 - val_accuracy: 0.7500\n",
            "Epoch 340/400\n",
            "72/72 [==============================] - 2s 29ms/step - loss: 0.0085 - accuracy: 0.9983 - val_loss: 0.6165 - val_accuracy: 0.8056\n",
            "Epoch 341/400\n",
            "72/72 [==============================] - 2s 29ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.6403 - val_accuracy: 0.7500\n",
            "Epoch 342/400\n",
            "72/72 [==============================] - 2s 29ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.5641 - val_accuracy: 0.8333\n",
            "Epoch 343/400\n",
            "72/72 [==============================] - 2s 29ms/step - loss: 0.0042 - accuracy: 0.9991 - val_loss: 0.6349 - val_accuracy: 0.8056\n",
            "Epoch 344/400\n",
            "72/72 [==============================] - 2s 29ms/step - loss: 0.0021 - accuracy: 0.9991 - val_loss: 0.6271 - val_accuracy: 0.8333\n",
            "Epoch 345/400\n",
            "72/72 [==============================] - 2s 30ms/step - loss: 0.0051 - accuracy: 0.9983 - val_loss: 0.5054 - val_accuracy: 0.8333\n",
            "Epoch 346/400\n",
            "72/72 [==============================] - 2s 29ms/step - loss: 0.0227 - accuracy: 0.9931 - val_loss: 0.4853 - val_accuracy: 0.8611\n",
            "Epoch 347/400\n",
            "72/72 [==============================] - 2s 29ms/step - loss: 0.0054 - accuracy: 0.9991 - val_loss: 0.5232 - val_accuracy: 0.8333\n",
            "Epoch 348/400\n",
            "72/72 [==============================] - 2s 30ms/step - loss: 0.0041 - accuracy: 0.9991 - val_loss: 0.6777 - val_accuracy: 0.8056\n",
            "Epoch 349/400\n",
            "72/72 [==============================] - 2s 29ms/step - loss: 0.0065 - accuracy: 0.9991 - val_loss: 0.6417 - val_accuracy: 0.8333\n",
            "Epoch 350/400\n",
            "72/72 [==============================] - 2s 29ms/step - loss: 0.0114 - accuracy: 0.9965 - val_loss: 0.5707 - val_accuracy: 0.7778\n",
            "Epoch 351/400\n",
            "72/72 [==============================] - 2s 29ms/step - loss: 0.0232 - accuracy: 0.9913 - val_loss: 0.5955 - val_accuracy: 0.8056\n",
            "Epoch 352/400\n",
            "72/72 [==============================] - 2s 29ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.6231 - val_accuracy: 0.7778\n",
            "Epoch 353/400\n",
            "72/72 [==============================] - 2s 29ms/step - loss: 0.0124 - accuracy: 0.9965 - val_loss: 0.9313 - val_accuracy: 0.8056\n",
            "Epoch 354/400\n",
            "72/72 [==============================] - 2s 29ms/step - loss: 0.0125 - accuracy: 0.9974 - val_loss: 0.7163 - val_accuracy: 0.7778\n",
            "Epoch 355/400\n",
            "72/72 [==============================] - 2s 30ms/step - loss: 0.0258 - accuracy: 0.9896 - val_loss: 1.1433 - val_accuracy: 0.7500\n",
            "Epoch 356/400\n",
            "72/72 [==============================] - 2s 29ms/step - loss: 0.0351 - accuracy: 0.9878 - val_loss: 0.5900 - val_accuracy: 0.8056\n",
            "Epoch 357/400\n",
            "72/72 [==============================] - 2s 29ms/step - loss: 0.0094 - accuracy: 0.9974 - val_loss: 0.7354 - val_accuracy: 0.7778\n",
            "Epoch 358/400\n",
            "72/72 [==============================] - 2s 29ms/step - loss: 0.0210 - accuracy: 0.9931 - val_loss: 0.9084 - val_accuracy: 0.7778\n",
            "Epoch 359/400\n",
            "72/72 [==============================] - 2s 29ms/step - loss: 0.0120 - accuracy: 0.9974 - val_loss: 0.5457 - val_accuracy: 0.8333\n",
            "Epoch 360/400\n",
            "72/72 [==============================] - 2s 29ms/step - loss: 0.0051 - accuracy: 0.9991 - val_loss: 0.5475 - val_accuracy: 0.8333\n",
            "Epoch 361/400\n",
            "72/72 [==============================] - 2s 29ms/step - loss: 0.0072 - accuracy: 0.9974 - val_loss: 0.6988 - val_accuracy: 0.8056\n",
            "Epoch 362/400\n",
            "72/72 [==============================] - 2s 29ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.6150 - val_accuracy: 0.8056\n",
            "Epoch 363/400\n",
            "72/72 [==============================] - 2s 29ms/step - loss: 0.0030 - accuracy: 0.9991 - val_loss: 0.6236 - val_accuracy: 0.8333\n",
            "Epoch 364/400\n",
            "72/72 [==============================] - 2s 29ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.6233 - val_accuracy: 0.8333\n",
            "Epoch 365/400\n",
            "72/72 [==============================] - 2s 29ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.6101 - val_accuracy: 0.8056\n",
            "Epoch 366/400\n",
            "72/72 [==============================] - 2s 30ms/step - loss: 0.0027 - accuracy: 0.9991 - val_loss: 0.7072 - val_accuracy: 0.7778\n",
            "Epoch 367/400\n",
            "72/72 [==============================] - 2s 29ms/step - loss: 0.0355 - accuracy: 0.9870 - val_loss: 0.6797 - val_accuracy: 0.8333\n",
            "Epoch 368/400\n",
            "72/72 [==============================] - 2s 29ms/step - loss: 0.0216 - accuracy: 0.9922 - val_loss: 0.6570 - val_accuracy: 0.7778\n",
            "Epoch 369/400\n",
            "72/72 [==============================] - 2s 29ms/step - loss: 0.0066 - accuracy: 0.9983 - val_loss: 1.0092 - val_accuracy: 0.7778\n",
            "Epoch 370/400\n",
            "72/72 [==============================] - 2s 30ms/step - loss: 0.0066 - accuracy: 0.9974 - val_loss: 0.6049 - val_accuracy: 0.8056\n",
            "Epoch 371/400\n",
            "72/72 [==============================] - 2s 30ms/step - loss: 0.0056 - accuracy: 0.9983 - val_loss: 0.6604 - val_accuracy: 0.7500\n",
            "Epoch 372/400\n",
            "72/72 [==============================] - 2s 30ms/step - loss: 0.0055 - accuracy: 0.9983 - val_loss: 0.6850 - val_accuracy: 0.8056\n",
            "Epoch 373/400\n",
            "72/72 [==============================] - 2s 30ms/step - loss: 0.0126 - accuracy: 0.9948 - val_loss: 0.6387 - val_accuracy: 0.8056\n",
            "Epoch 374/400\n",
            "72/72 [==============================] - 2s 30ms/step - loss: 0.0208 - accuracy: 0.9931 - val_loss: 0.9005 - val_accuracy: 0.7222\n",
            "Epoch 375/400\n",
            "72/72 [==============================] - 2s 30ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.7251 - val_accuracy: 0.7778\n",
            "Epoch 376/400\n",
            "72/72 [==============================] - 2s 30ms/step - loss: 0.0084 - accuracy: 0.9983 - val_loss: 0.7081 - val_accuracy: 0.8333\n",
            "Epoch 377/400\n",
            "72/72 [==============================] - 2s 30ms/step - loss: 0.0123 - accuracy: 0.9957 - val_loss: 0.6917 - val_accuracy: 0.8333\n",
            "Epoch 378/400\n",
            "72/72 [==============================] - 2s 30ms/step - loss: 0.0066 - accuracy: 0.9983 - val_loss: 0.7609 - val_accuracy: 0.8056\n",
            "Epoch 379/400\n",
            "72/72 [==============================] - 2s 31ms/step - loss: 0.0079 - accuracy: 0.9983 - val_loss: 0.6148 - val_accuracy: 0.7500\n",
            "Epoch 380/400\n",
            "72/72 [==============================] - 2s 31ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.6268 - val_accuracy: 0.8056\n",
            "Epoch 381/400\n",
            "72/72 [==============================] - 2s 31ms/step - loss: 0.0041 - accuracy: 0.9991 - val_loss: 0.7180 - val_accuracy: 0.8056\n",
            "Epoch 382/400\n",
            "72/72 [==============================] - 2s 31ms/step - loss: 0.0045 - accuracy: 0.9991 - val_loss: 0.5315 - val_accuracy: 0.8611\n",
            "Epoch 383/400\n",
            "72/72 [==============================] - 2s 30ms/step - loss: 0.0107 - accuracy: 0.9965 - val_loss: 0.7829 - val_accuracy: 0.8056\n",
            "Epoch 384/400\n",
            "72/72 [==============================] - 2s 30ms/step - loss: 0.0049 - accuracy: 0.9991 - val_loss: 0.5075 - val_accuracy: 0.8611\n",
            "Epoch 385/400\n",
            "72/72 [==============================] - 2s 31ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.7564 - val_accuracy: 0.7778\n",
            "Epoch 386/400\n",
            "72/72 [==============================] - 2s 31ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.5817 - val_accuracy: 0.8333\n",
            "Epoch 387/400\n",
            "72/72 [==============================] - 2s 30ms/step - loss: 0.0046 - accuracy: 0.9991 - val_loss: 0.7482 - val_accuracy: 0.8056\n",
            "Epoch 388/400\n",
            "72/72 [==============================] - 2s 30ms/step - loss: 0.0041 - accuracy: 0.9991 - val_loss: 0.6309 - val_accuracy: 0.7778\n",
            "Epoch 389/400\n",
            "72/72 [==============================] - 2s 30ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.7286 - val_accuracy: 0.7778\n",
            "Epoch 390/400\n",
            "72/72 [==============================] - 2s 30ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.7562 - val_accuracy: 0.7778\n",
            "Epoch 391/400\n",
            "72/72 [==============================] - 2s 30ms/step - loss: 0.0038 - accuracy: 0.9991 - val_loss: 0.5075 - val_accuracy: 0.8056\n",
            "Epoch 392/400\n",
            "72/72 [==============================] - 2s 30ms/step - loss: 0.0216 - accuracy: 0.9931 - val_loss: 0.7910 - val_accuracy: 0.8056\n",
            "Epoch 393/400\n",
            "72/72 [==============================] - 2s 30ms/step - loss: 0.0114 - accuracy: 0.9983 - val_loss: 0.8050 - val_accuracy: 0.7778\n",
            "Epoch 394/400\n",
            "72/72 [==============================] - 2s 30ms/step - loss: 0.0053 - accuracy: 0.9983 - val_loss: 0.5289 - val_accuracy: 0.8333\n",
            "Epoch 395/400\n",
            "72/72 [==============================] - 2s 30ms/step - loss: 0.0049 - accuracy: 0.9983 - val_loss: 0.8081 - val_accuracy: 0.7500\n",
            "Epoch 396/400\n",
            "72/72 [==============================] - 2s 30ms/step - loss: 0.0278 - accuracy: 0.9922 - val_loss: 0.6289 - val_accuracy: 0.8056\n",
            "Epoch 397/400\n",
            "72/72 [==============================] - 2s 30ms/step - loss: 0.0074 - accuracy: 0.9983 - val_loss: 0.4484 - val_accuracy: 0.8333\n",
            "Epoch 398/400\n",
            "72/72 [==============================] - 2s 30ms/step - loss: 0.0098 - accuracy: 0.9965 - val_loss: 0.4148 - val_accuracy: 0.8333\n",
            "Epoch 399/400\n",
            "72/72 [==============================] - 2s 30ms/step - loss: 0.0030 - accuracy: 0.9991 - val_loss: 0.6765 - val_accuracy: 0.7778\n",
            "Epoch 400/400\n",
            "72/72 [==============================] - 2s 31ms/step - loss: 0.0147 - accuracy: 0.9965 - val_loss: 0.5502 - val_accuracy: 0.8333\n"
          ]
        }
      ],
      "source": [
        "cnnhistory=model.fit(x_train, y_train, batch_size=16, epochs=400,validation_data=(x_valid, emo_valid))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EWT6F8K425LT",
        "outputId": "94ae6aad-cf49-439a-ccd0-bc7d324dea15"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9622395807504653\n"
          ]
        }
      ],
      "source": [
        "ava_acc=np.mean(cnnhistory.history['accuracy']) # numpy assumed imported as np\n",
        "print(ava_acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "3_HGLS8F29Qr",
        "outputId": "d5fa8f57-b60c-4fd3-ff81-9c5cbbc91bd8"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.plot(cnnhistory.history['loss'])\n",
        "plt.plot(cnnhistory.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'valid'], loc='upper left')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "YlkBpKyX3El2",
        "outputId": "bc147118-6cdc-43c5-f4ff-dae53f45ccb4"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOydZ5hcxZWw35qcs/JIGmUUUUIIRE4WGZOjTVhjG7OAw9qs7cWsw9pr1vZnbNbGxgsGk2WyCSaILAQSAgUkoTSSRqM8QZN6pnu6vh91q+/tO90zLWlaI6nP+zzzTPeNdavr1qkT6pTSWiMIgiCkLml9XQBBEAShbxFBIAiCkOKIIBAEQUhxRBAIgiCkOCIIBEEQUhwRBIIgCCmOCAIhpVBKPaCU+mmCx1YrpU5LdpkEoa8RQSAIgpDiiCAQhEMQpVRGX5dBOHwQQSAcdDgmmX9TSi1VSrUopf6ilBqglHpJKdWklHpNKVXqOf48pdQKpVSDUupNpdR4z75pSqmPnfMeB3J89zpHKfWJc+77SqkpCZbxbKXUEqXUHqXUZqXUnb79xznXa3D2X+tsz1VK/UoptVEp1aiUetfZdpJSqiZGPZzmfL5TKTVPKfU3pdQe4Fql1Cyl1ALnHluVUr9XSmV5zp+olHpVKVWnlNqulPq+UmqgUqpVKVXuOW66UmqnUiozkWcXDj9EEAgHKxcBpwNjgXOBl4DvA/0w7fYWAKXUWOBR4DZn34vA80qpLKdTfAZ4CCgDnnSui3PuNOD/gK8C5cC9wHNKqewEytcCfAkoAc4Gvq6UusC57nCnvL9zyjQV+MQ573+AGcCxTpm+C4QTrJPzgXnOPR8GOoFvAhXAMcCpwE1OGQqB14CXgcHAaOB1rfU24E3gUs91rwEe01oHEyyHcJghgkA4WPmd1nq71noL8A6wUGu9RGsdAJ4GpjnHXQb8Q2v9qtOR/Q+Qi+loZwOZwP/TWge11vOAjzz3uBG4V2u9UGvdqbX+K9DunNctWus3tdbLtNZhrfVSjDA60dl9JfCa1vpR5767tdafKKXSgOuBW7XWW5x7vq+1bk+wThZorZ9x7tmmtV6stf5Aax3SWldjBJktwznANq31r7TWAa11k9Z6obPvr8DVAEqpdOAKjLAUUhQRBMLBynbP57YY3wucz4OBjXaH1joMbAaGOPu26OjMihs9n4cD33ZMKw1KqQZgqHNetyiljlZKzXdMKo3A1zAjc5xrrItxWgXGNBVrXyJs9pVhrFLqBaXUNsdc9F8JlAHgWWCCUmoERutq1Fp/uI9lEg4DRBAIhzq1mA4dAKWUwnSCW4CtwBBnm2WY5/Nm4Gda6xLPX57W+tEE7vsI8BwwVGtdDPwRsPfZDIyKcc4uIBBnXwuQ53mOdIxZyYs/VfAfgFXAGK11EcZ05i3DyFgFd7SqJzBawTWINpDyiCAQDnWeAM5WSp3qODu/jTHvvA8sAELALUqpTKXUhcAsz7l/Br7mjO6VUirfcQIXJnDfQqBOax1QSs3CmIMsDwOnKaUuVUplKKXKlVJTHW3l/4BfK6UGK6XSlVLHOD6Jz4Ec5/6ZwA+BnnwVhcAeoFkpdQTwdc++F4BBSqnblFLZSqlCpdTRnv0PAtcC5yGCIOURQSAc0mitV2NGtr/DjLjPBc7VWndorTuACzEdXh3Gn/CU59xFwFeA3wP1wFrn2ES4CfixUqoJuAMjkOx1NwFnYYRSHcZRfKSz+zvAMoyvog74byBNa93oXPM+jDbTAkRFEcXgOxgB1IQRao97ytCEMfucC2wD1gAne/a/h3FSf6y19prLhBREycI0gpCaKKXeAB7RWt/X12UR+hYRBIKQgiiljgJexfg4mvq6PELfIqYhQUgxlFJ/xcwxuE2EgACiEQiCIKQ8ohEIgiCkOIdc4qqKigpdVVXV18UQBEE4pFi8ePEurbV/bgpwCAqCqqoqFi1a1NfFEARBOKRQSsUNExbTkCAIQoojgkAQBCHFEUEgCIKQ4hxyPoJYBINBampqCAQCfV2UpJOTk0NlZSWZmbKGiCAIvcNhIQhqamooLCykqqqK6ESThxdaa3bv3k1NTQ0jRozo6+IIgnCYkDTTkFLq/5RSO5RSy+PsV0qpu5VSa5VZknD6vt4rEAhQXl5+WAsBAKUU5eXlKaH5CIJw4Eimj+ABYG43+88Exjh/N2Jyq+8zh7sQsKTKcwqCcOBImmlIa/22Uqqqm0POBx50Vo/6QClVopQapLXemqwyCYKfpkCQzPQ0cjLTAWhsC1Kca/wvrR0h8rL2/RWpqW+lelcrxbmZ1NS3MrQsjyEluZTmZ0UdF+wM8/SSLRTnZvKFiQO7XGfj7hZ2NbfTryCHp5dsYcLgIk6fMID2UCeLq+sZN7CQ8gKzdMGK2kaqyvOpqW8jKyONERX5kessq2lk/KBCVm1rYlNdK41tQQYUZXP8mH6s3LqHpkCI8oIs6luCzBpRBsBLy7cS7Axz3pFDqG1oY0dTgOLcLEb3L+hSTj/N7SHys0y9frC+jkXVdZTkZXLFrGFkpKcRDmsCoc5IHb+zZieb69o4bnQFb63Zyc6mdiYMKiQrI40t9W3sbDIreg4pzaWlvZMRFfmcNK5fZHCktaah1fx+zR0hinJcP9rLy7cyqDiXQcU5fLZ1D2u2N9Me6mR4eT5DSnMZP7CItz7fCWhmjyxnU10re9pCHDemIuqZaupb2b4nwKptTYTDmp1N7QwszuWiGUMIh6EjFGZPIEh+dgZFORk89tFmZo0oY2BxDmu2N/HxxgYGleQwaXAxn2xuYP3OZvoV5ZCbmc6mulYqCrK4YNoQGluDBDvDjKjIp6E1yPamAMW5mQwqzu2x3veFvvQRDCF66b0aZ1sXQaCUuhGjNTBs2DD/7j6noaGBRx55hJtuummvzjvrrLN45JFHKCkpSVLJDgxrdzQxun8ia7lAqDOMUopV2/awYN1ubjhuRI9azi9eWsXAomz2BEK8+tl2HrjuqEjHZ9Fa85d3N0S+jx9UxJzR5iUOBDv59pOf8pXjRzJ1aAltHZ387o01LFi/mxVb9oCCL0wcSFtHJ6+v2s5Rw8vIyUrn7c938qtLjqS5PcQrK7Yxc3gpXztpVKTj6gxrwlqTmW4U645QmF++vIqWjk62Nrbx5uqdXZ6lMCeD1799Io9/uJnTJgygNC+Lhz6o5p75ZlXJc6YM4vtnjadfYTbvrtnFqH4FXPLHBexoil7W+PgxFbS0h/h4UwNzRpdz88ljCIXDXPOX6BUnpw4tYVBxDseOKuc/nl1BRUE2u1va8aYYy8lMIxAMR503YVARFYXZvP25eYbvP7WctmAnAPlZ6cz7+rGMH1QEGOH55uodNAVCNLYF2dMWZM7oCr72t8UcVVXGruZ2VtTuiVz7uU9rOWJgEW+s2kFaGrz2rRN5dkkt3/370u6aAUqBPzXaXRdP4ZKZQ+kMa77y4CLeWLWDioIsmgIhfnjOBC6ZUckbq3Zw08Mfd3ttL+X5Wexu6Yg86/3XzeL389eiteb9dbvpDHfNz7axroX31u5i+RbznFnpaYwfXMSnmxsi12np6Ezo/nc8uyLyeVhZHpvqWiPX+NWlRzJ30qCEnyVRkpp0ztEIXtBaT4qx7wXgF1rrd53vrwPfcxYLicvMmTO1f2bxypUrGT9+fG8Ve6+prq7mnHPOYfnyaHdIKBQiI6P3ZW1fP6+XZ5Zs4bbHP+Gv18/ixLFm9rrWGq3h3bW7mD2ynKwM1wJ5yR/fpyMUZtW2JtpDYe44ZwLXH2cc30s21TO0LI+8rHR2N3cwuCSXRz/cxA+fia7Xc6YM4ndXTEMpxd8X1zCwOIcHF1TzyortUcf97IuTuOro4fz1/Wp+9NwKThjbj798eSZX3beQj6rrGN2vgKqKfNKV4vVV20lTipH9Cli3o5mOzuiOcWhZLpvr2hg3oJBnb57Dkk0N3P/eBtbsaGZWVRmf1jRwZGUJjy8yY5uSvEy+dEwVY/oX0BQIMXlIMS8sq+Xet9YzflARK7fuibr+8WMqKMjO4KXl22LW8zWzh7N0SyN3nDOBJZvq+ek/Vsb9TWYML+XsyYNoaAvy8vKtVO9qjTzP4OIcZlaV8fWTRpGdkcazn9TS2BZkxvBSinMzaWgLsr0xwAtLa1lRu4cvHVPFsLJcVm9vZkplMWGt+fU/P6dfYTYXz6hk8cZ6PqquZ1dze5dyFGRn0NweYlS/fL56wijOnjKIpz6u4ScvrOxSvwDHja7g5lNGM29xDV8+pooxAwpYsH432elpFOVmMmlIMVprltY0kpeVzg+eXs6K2kZ+dO5E3l27i+c+rWX2yDKW1TQyoCiH9btaGFycQ2NbkMEluZw+YQB1LR3MGV3BpCHF9CvMpqa+ld+9sZZ/LN3KraeO4eiRZVz554UAjKjIZ8OulqgyHjuqnC9OG8Kg4lyGlxsN75J7F7BkUz1hDWdMGMAJY/sxb3ENn2xuYEz/AmZWlVHb0MaF04cwY3gpO5raeXJRDSeN68dp4wewtbGN9lCY4WV53PfuBn7x0irOmDCAisJsHlm4CYBvnDyKpTWNfOeMcRw5dN8GjkqpxVrrmTH39aEguBd4064Pq5RaDZzUk2noYBQEl19+Oc8++yzjxo0jMzOTnJwcSktLWbVqFZ9//jkXXHABmzdvJhAIcOutt3LjjTcCbrqM5uZmzjzzTI477jjef/99hgwZwrPPPktubmw1cH+ed+PuFvKzM6go6GkVRJf739tAeyjMtcdWRUwolpseXsyLy7bxg7PGc+nMofzoueW8t243o/rl88H6OtLTFF86Zjg/OnciWxramPOLNyLn2lHST86fSENrkF+9+jnHjiqnvCCb5z+tjRw3pCSXC6cPIU0pNte18tSSLVQUZHPdnCruemV15LizpwzillPGUJKXye1/X8pbn++ksjSP2oY2QmFNYU4G04aVRkb6F82ojJwbdkZ5aWmKcFizo6mdvy6o5g9vruPiGZX88qIpvLJiG19/+OOYI2jLkZXFPH3TnMi1vGitOfGuNyMjvKlDS/hkcwPDyvJ44LqjGNmvgHvmr416pqFluXz79HFcMG1I1LWe/7SWB96v5vdXTuOul1eTnZnGox8aIbTh52dFaVnvr93Flfct5PgxFTx0w9EkSqgzTEZ6VzfiKyu28dWHFkfKN6wsjymVJbS0h7huzgiWbWnkzdU7+O4XjqC1I0RVeX5UXdS1dJCZrsjPyuDmRz9m+552Kgqy+OkFk+lXmHi7XLO9idN/8zZgtIVvnDSab58xFq3N4s6/+udq/vfNdVQUZPH8vx4X16zSEQrzwfrdzBldQXqaYuH63by4bCt3nDuRRxZu5D+eXYFS8L9XTueEsf3Iz44e3D3w3gbufP4zLpg6mP93+TTAaItvr9nJ+IFFDCzOSfiZwmHNe+t2MWtEGQrFQx9s5LwjB+9VvcTjYBUEZwM3Y5b0Oxq4W2s9y3+cn54EwX8+v4LPavfEOnWfmTC4iB+dOzHufq9G8Oabb3L22WezfPnySIhnXV0dZWVltLW1cdRRR/HWW29RXl4eJQhGjx7NokWLmDp1KpdeeinnnXceV199dcz77Y8gqLr9H5TnZ/HRD05j9fYmBhTlUOazWQNsrmulLD+LjHTFuB++DJhO7qsnjqI5EOLnL61kYHFul5FtepqKqTofP6aCopxM/rFsK+cdOZgrZg1j+vAS5v6/d6JGXelpirzMdFo6Qpw4th9zJw3knCmDIy/fi8u2xlTzf3v5VM6f6naWrR0hfv3Pz9nVbGy4u5rbmbfYrPx4yYxK7rrkyC7X8BMIdvLGqh2cMWFApEP86kOLojSPY0eVc+H0Sk4c2483Vm3nqKoyRvaLbz9fUdvIk4tquHD6EKZUlhAIdpKZnkZ6mmvnXrez2fFVJGaLt+dddd9Cjqoq45unj+2y/9XPtjN5SPFedUrdsbSmgYFFOfQv6p3r7StPLNqM1pozJgyM6Xt5YWktJ4/rT0le1zaeCFprFqzbTWZGGkdVlcU8prEtyD3z13LTSaP2+T4Hgu4EQdJ8BEqpR4GTgAqlVA3wIyATQGv9R+BFjBBYC7QC1yWrLAeaWbNmRcX533333Tz99NMAbN68mTVr1lBeXh51zogRI5g6dSoAM2bMoLq6utfLZdX33S0dnPabt1i/s4UTx/bjr9fPQmsdGUXWtXRw/C/nM6uqjNvPOgKAUf3y+bSmMdIJl+Zl0r8wm+pd6RHb8eDiHO69ZiYb61rY2hDgohmV/Oqfq3l44SbeWbMLgJnDS7n7immRMp1yRP+IbX/sgAI+395MU3uIe66cztlTutpCjx1l6u2YkeXMrCpl9shyplQWU5gTPcEuLyuDH54zIfL94031PPdpLQ9cexTHjo52AMYjJzOdsyZHl+EPV83gw+o6RlTkU9vQxrRhpZF9lx3Vs/9q4uBiJp5XHHUPL0qphP0t/vMe+crsuPtPnzBgr6/ZHVMqDw6/1qUzh8bdl5mexhenVcbdnwhKqR7bS3FuJt8/6+Aw1e4ryYwauqKH/Rr4Rm/ft7uR+4EiP9+N1HjzzTd57bXXWLBgAXl5eZx00kkx5wFkZ7uqX3p6Om1tbftVhub2ENkZaShgV3MHtz2+hDaPOWP9zhb6F2bz1uc7OfO377B9T4DTxvfnS8dU8ciHxi75YXUdf/vAJCz8278cTWNbkK0NAXY2tTN38sBIVMacX7zBloY2fnvFNCZXFjO50u3ofnL+JB527JxfnDaEfz/ziKhyfumY4bz9+U7+cPV0lFKc+qu3yMpIY87oaEFpKcnL4r3bT2FAYXZMs0U8pg8rZdWP53Yx1+wtaWmK2SNN2Qb08WhYEHqLw2JmcV9TWFhIU1PsFf8aGxspLS0lLy+PVatW8cEHHyS9PO2hTk7+nzfJTFPkZKWzfmdLl2OGlORy1yVTuPLPCyPmnScW1fDEImM+uWDqYJ77tJanPt7CoOIcJ/QulyMGFnW51l0XT+GJRZuZ4RkdW9LSFO9+72QKszMpzuuaFmN4eT6vfuvEyPdP7jidtDQVFfoXq+z7wv4KAUE4XBFB0AuUl5czZ84cJk2aRG5uLgMGuGr43Llz+eMf/8j48eMZN24cs2fHV9/3l7aOTn7wzDKe+ngL4JpaAAqzM5gzuoLaxjamDyvlmmOGM7Q0jzmjy7nq6OGU5GXyzcc/Yfuedo4cWsJvLpvKito9rNnRzMlH9O/2vseOruhWfa4szUv4GQ5mG6sgHK6IIOglHnnkkZjbs7Ozeemll2Lus36AioqKqNDT73znOwndc832Ju5/v5prZg9n/KAi5n1cExECAP+45XjSlOLvH9cwbkAhUyqL0Tp6ZPzwv7iC6eaTR/Mfz65gVlUpSikzCWZHM2dO6jrJSRCEwwcRBIcwX3lwEdW7W1lW08jjX53NvEWbGTuggFtOHUNn2J3o5HWodTd366IZldQ0tHHTSaMB+K8vTubJxTUcOyox56ogCIcmIggOMVraQ9S1dPDGqu1U725l2rASlmxqYMIdrwDwk/Mncs6Uwft07bysDP79TDf6YWhZHt+KEYooCMLhhSxMcwjQGdbsbm6nM6zZVNdKa0cn1z9g5lL8/MLJDC83Nvi7r5jG1bOH92VRBUE4BBGN4CCntT3EpvpWOkJh2kNhgp1h0h3zzoCibMYNKOSJrx7Dyq17OGlc905dQRCEWIggOEhoCgRRSlGQnUE4rFEK2kNhNuxuIV0pcjLSIxPCSvOzuP/ao5hcWYxSigFFORLTLgjCPiOC4CDBplkYXJJLbUMbxbmZZKSnoTWM7F9Ac3uQmnozySwzPa3HkE5BEIREER9BH1BQYPLH1NbWcvHFF0fl5qltMJ39xed8gXffX0hBdgZZGWmU5Lrx9ekyMUoQhF5EBEEfobVm8ODBPPLYEwSC0XnK7cIoYW0yZoKJ/a8qz2dwrAyKu9fBsnn7Xpj6alj65L6ff7Cw4hnY+Xlfl0IQDjnENNQL3H777QwdOpRvfMOkTrrzzjvJyMhg/vz51NfXEwwG+elPf8r5558fOWfl1iYC9Vu59MILeOr1BQTa2vjF92/l008+ZdLE8YQ62inOzYyaaVvkCIguy5384VgIBWDyxfv2AH86CdrqYcol+3b+wcKTXwaVBj+q7+uSCMIhxeEnCF66HbYt691rDpwMZ/4i7u7LLruM2267LSIInnjiCV555RVuueUWioqK2LVrF7Nnz+a8884jrCGsIRQOs32Pu5jH3x++n+KCfNatWc3SpUuZPn06/YtyEjMDhZwkduFOSEvv/thYtNXv3/kHAyGnLnXsdQIEQYjP4ScI+oBp06axY8cOamtr2blzJ6WlpQwcOJBvfvObvP3226SlpbFlyxbeX76OKWNMnH9laS5bNkOaUgwqzmXlkoXcduutAEyZMoUpU6bsfUFCAcjK7/m4eHR2QFpy1kRNOm0NfV0CQThkOfwEQTcj92RyySWXMG/ePLZt28Zll13Gww8/zM6dO1m8eDGZmZkMGTqcPc2tNLQGASjMyWTsgAKyMtLoV5hNWg/r9iZEsBcEQeYhKggCIggEYV8RZ3Evcdlll/HYY48xb948LrnkEhobG+nfvz+ZmZnMnz+f2hqTk39PwAiCjDRFeppb/SeccEIkcd3y5ctZurT7hbxjEuq6zsFe0Rncv/P7EtEIBGGfEUHQS0ycOJGmpiaGDBnCoEGDuOqqq1i0aBGTJ0/mwQcfZORok7OnM6xRELWmLMDXv/51mpubGT9+PHfccQczZszY+0IcDoJg4wK4/2zX5m/ZtQb+dLLrz1g2D/73WLBLrbaJg/iA89Yv4eFL+7oUQi9w+JmG+pBly1wndUVFBQsWLADMgtQrahuxswXW1Zq4n6qqqkj66dzcXB577LH9K0Bw/1Y1o7Nj/87vDWo+go3vQt166D8+envtx0YgDJ0Fz94MoTZo2QUF/TymIZljccCY/7O+LoHQS4hGkARCnWE6w2HCYU1Dawc1DW14l3Mv7c3FV7ydv38UvbccDBqBfYa6DdHb7YjfmoAKnTUS6jdEb0+XhW0EYW8RjSAJrN/VQiDYSUVBNrua20lTioqCbLIy0ggEO8nO7MUQTa9tPHQYaAT2Ger9gsB5TisQCgeZY+qrjYZgt6dJkxaEveWweWu01l3s7n1BsDMcmSm8q7mdzPQ0jhhY2Gtl01pHb/BGy+yvjyB8EGgEQecZ6qujt9vntP8L+pn/VnOw20Ntxm9wELSFlEHq+5DnsDAN5eTksHv37q6d5AFAa027J0VEQ2uQdMJkYCY2ZWek7ZsQCHVAOAydIWhvgnAnWmt2795NTk4OtDfDnq2w8X33nGA3giDcaezu3eE3DXWGuppovLTsgta66G271roO3N3r3M/hTuMI9l6vZXfX860ws8e1N0HTtq6mIYsVGHa7Du+ficxfTx0tsKc2+phda2Dzh6bsLbuin/NA0FgDHa3mmZt3HLj7xsOrSWpt6qMnwmH3uETOadxifou9wdZTT2htftMDRfMO89slUk8HiMNCI6isrKSmpoadO7skX0g6ze0hGlqD9C/MBmBHUzuVypRju+5HS3Y67bv2wW7dsAkyckzKhGArZBdBbgk5OTlUVlbCfSfDdt8M6u40gnd/A2/8BL7xEfSLs+qY3zQ0/2fw7q/htuVQMrTr8X+/AbIK4PKHzfcN78Bfz4Hz7zGzse89Ac74GRx7M3z+Mjx2JWQXw7+bUFruGgkqHX7kEQYhn0Zw74lQtw5Gn26+W4FghV6Dc61Ao3uNjhbI3Me03PN/Bu/8Cm5dCqXD4f6zYOsncKdzfa3h9zPN56JKU55gC5zzG5h5/b7dc2/5zUQYdixs/dTc+87Gns/pbbyDhlAAMkz759NH4Zmvw5efhxEnxD9/5XMw73r49ir47Fl48TvwL69D5czYx/9mAgyeDjfOT6x8Wpt6GnUKXPN098dWvwN/PRe++g4M2oeJnHvLY1dBzYfm83Uvw/Bjkn/PHjgsBEFmZiYjRozok3t/+4lP+fvHW/mvL04mrDU/fK6a6pwrATgz8Ag3nTSK7849Yu8uqjX8p7OofMU42LUaJl8CF93nHuMVAuPOgtUvdi8IapeY/ztWJC4Iaj4y/3eviS0ImndAcKP7ffda83/zQiPEvNewo+r2RjMatHModHTCvYjzu2GjMzp3Rk1+05D1JXQ0Od89zx5sAcpjP2NPrHnV/G+rM4Jg6yfR+7332VPjft7y8YERBGGnvja93/1xycarmQUDkFNsPkfa2cruBUHjZvPbt+yCLYvNtp2rYwsC+8y1HydePtuO1r3R87HbV7hlPhCCoHGz+7lu/UEhCA4L01Bfkp9tHL87mgJsqmslKyO6SmeP3IcOyTvaanA62u7i5KuON/+7Cx8tcNYvaO5Ga+oMRX/Pd+zwTdtiHx8KmEZtz0vPdK4TdJ/BbvN2HB1NxuQT85qOWaezI9okE3EWN0QfZ1V/rxDbWxOCF1tuf84ia/qJJ2ztcyabYAKmjgOBtz16gxSUEwgR9gn4eOcHW10Hf7xghcA+aDx7M6/Eap9+v1Sy8JbtQLWbHjgsNIK+pLHNdBxrdzQT6tQMK8uDPWbfJ3ecHpU9NGG8L4TteLqbOZtXHn1sLOyIzTuKBTM6j3Vf73XrNxKTYADCIXPN0ipIs4Kgw72WDef0OrXbGroRBJ5OxftiWlu4vY4VerbT9/oFErELx8OW23+Nzg5j/ojnhzlQYav7I+R6k6ggBU/d26SFPSX/s+25o9mtu3jhy96OM9HEiLZ86dk9H2v9Uf5ItWQQDES/p+rgGIsfHKU4hNm+x/yoLyzdyssrthlB4LBPQgC6dsg5xd3n0klEEMSLxun0vMT++9ooongviO207Ytk79/Z4Y5cY2kEgYZurtkOxcO63rfdGRXaTsF2PsEW9zmyi8znjubY104E+8z+kbcVPPFCdA/UyO5gEQRRpiGvRhDH5OfHtueOVrfu4rVfb9tv2rp35UvEV2TbWXeBEb2F/z3e30mgvYQIgv1kx57oCJWC7B6UrEX3w/O3mYifWOxaCwvvjd42eJonVXQY3v6f6P05xeYFfO9uc34sbOdoGzRfpYUAACAASURBVPuWxfDMN2DVP9xj/CMyOyruEsrZCG/+wu2U7H77vTPovohW7fe+AG/81DiWwfUlWIJtUD7KnBfrxWzYZGYV71odfc9QB+SWONfwdeIrnoaVz8ML34IF95j6tREbix8wtuHq94zT0tZBe5NxsFus4IkXkXSgooZiCYKm7cbBHQ6ben/rl2bk3N4M839u6gZMZMyzN8Pyv5sonHd/45Z7y8fw6ePwxs/g5X93n3PXWvjwz6bd7ljp3jPKNBRjhLv6ZVj9krl/LA0tohG0uOf4O8n3fgvP3GTKY3nhW/DJIybizD7ne3dDw+boc+21/O3LW/63fmmutctZzKi+2jxrvAiiPVvNu7vo/4xv44Vvwgd/MM83/+ex20bDZnj+Vvj4Ife+XlY8BWtf73pe9Xvw2XPmd3r+VnOfp74K69+KXbb9RExD+8mOpnaum1PFl46p4tRfvcmp4/vD6m5OeOE283/IdJj+pa777zulq010wCTTcWoNO1eZ6B8v2QVGFW/fA4vvhy/EmPpvO0c7ovrwPvj0kWino38ege10/KOwV74PS/7mfrcjqogg6PCM3K1pqx5ySswLuuaf7rl+1T0UgKzBZsJYg88kNfIk2L0eljzkKXPIdHSd7c45m6DF5wd5+fvQ5AsBPfYWOO0/Tccy60ZY+Aez3WpXO1fD27/0lMsZucUbwR0o232s+6x4Gl7/MYydaxyf838GY84wjva3fgEjT4Thx5pOb8lDULPILEL0+o9h/HlG8P755OhrHnE2VB0H9x4ffU8bodS+x93mFQTWbLPpfdi0ANAwcBKMPzf6+hETX4t7fa+W0d4Mr95hzEZWU03LhOp3YedK09bm/8yYJF/9D9Omrn3BPd+2v3iCYP7P4UPPgKvqeBM99OJ3oGQY3BZjTZPPXzbvF5hyLfo/87l4qKnn4ceauvay6h9msLHkYZh+TVcT77o3ILAHRp8avf2Bs8z/L/yXOT9SzuNiP89+IhrBfnD362tobg8xoCiHERX5rP3ZWZw/dUhiJ8dT8f1CIDPPOHp1pxnVx3JoZbrmqLgOL3u/tgYjUOxx3ph5v2nIml38Izr/SN1eK3J8i0f199y3tKprufymllDAvLw5JV19EzNvgG8ug6xC37M1G2FQOsJoEt46CAa6CgEwwqujydSrdyRqy9vo86VY01o888X++CX2BqvZXf9PmOukXLeCr77a7QADDV01NSuwA43ubxjPHGK3xxNw3vbr9ZtEOYm1Wy4/tpwdLe61vL+DPWeyJ6ndN5fDkZeb4+3+je+Z//7fJWIaipNW3etnOOHfYMa17ve476anfDWL3M/bl3fd7z8nHDQdfqxjuvNN+H8fq/X2MiII9pFtjQF+89rnZKQp5oyqAMy6wlH4o3DAdagmauvNKTF/YBp3rEaTVeB+7kkQhIPm5Y51nS6mIeccf2fgn8RU59MI2ho8qr9zbqABymKE+HZ2RDusgwFj180t6VpG+xLY/3b0Hmw1GkFWnhmdeV8ev1Zh8Xaascwcfqd6yCcIcnwv5P74JfYGW59Z+W7sfutu879uQ/Qz+X8X2za8QiJeJ9RTBI23TXiFeSxBGUvYeNtHRwyNwN5/lEdTySkxz93R6u5fN9/d58V2uGlxfDd5nmi+0hHmz3ufWHjbyXrPfAYbMhsrUsm7zdvmvLTuNkIiFv7fIV7Z9hMRBHvJ8i2N7Gxq5+GFG9EaXvvWiUyuLI59cHfO20QFQW4J5Jaaz96X20uWRyOo2xDbXu29X9M2Y+6p8M0n8GsE9gUNtkZ31i0eQZCeZRqr1tGdfiyNoCiOtuStp1AbZOSa57YdnMW+BNYpnFfh3qMzaMxMZSOiX564I97q+LOVoetsYltGO/otHBS9/0CZhmx9ZuWZegK3nuo3RIfZ+jUC7yh/p2O/jNfh18dpR3Zw421PXtt4rDbvFzZau5pvR7MrRKM6Tecc71yEzBwjCEJtro/HCnrvOwBuPXTG8el4NZeyEdHaarxRt19Q2fcnIghitKOoczbEPsZeL+Z2/2CoNPZx+0lSBYFSaq5SarVSaq1S6vYY+4cppeYrpZYopZYqpc5KZnl6g3N+9y5H/ew17pm/lnOmDKKqopsVwfwvhdbxo1LikVPiNkzvSM6i0qLtoMEW48jyE2wlkqLZNtyRPrtwF43AM8r1ltdrvqoYa+zFbfXRL3QkTrzFmG2CLfFHM1GCoN2MdGMda18Cq+7bUV1Hi3NelnmhvS+Pt768L3tHk9uZBBogtyz6Xo1bor/7o4Zs9tPI9Q5QNI81v2UVeDQCZ2Z2fXX0xLuIya7V/B6BBnfka4V53A6oGpq3d91uNaUo05BHI4gVXuu/R3uTG1UUbHXbltdsUrfBBEHY+S8WuwLfzpXR2/0jav8MdD9BT/lLqyCvzB1ghGNo8rZ8JcPd78Nmm8GHradYo/2AxyQaTyOA+JrZ7rWJCan9JGnOYqVUOnAPcDpQA3yklHpOa/2Z57AfAk9orf+glJoAvAhUJatM+0tLu9tA8rMy+OXFPcxC9AsCbwNb+EcTvXLE2cYRHGqD2Td1vUZ2gcc0VN+1wWTmd034VV/tJmV76XbYttS8uMWVZgLY328w+0adEu0ws4Lg1TtMdI23vL+dYo7/7Lnoe/Ufb2ykv5sBQ5zFdDo73EiMjhb424Xmc16c0YytJ61Np5KZGzuJmX0JrCDIdwSBdXSmZ0NZP1NPf7sYrp5n6kulGWf64OnRnZJXpc8pMrOJI2Xy+S42fwgPXQAnfs98t9pNWoapJ7+P4KkbTd0c983Yz+xl4/vw4r/BDa+ake38n8OyJ+CWJaaNvPNr01HtXutqbZl5bj14TUPWFNK8w/VzeH1Lg6d52pCKrTFVjDXbYwmJ382Aic7vmVNsBgUv3AYvfReGHm3K6adhE/z5FNi2DIoGw5VPuvs+/JP7ua3eROzcd5q57qAju14railWRcQPYTvY3evgvlM9Ew+dtvXXc2HTB5Df31x3tRMtl5ELBQNNeyutMu/K1k/NIkjZBcZHsXOV8QlkZJsBQLDV+GXKRprZ57atBxrgrjHm+uvegMkXm3KVDDOCatk8c/1Y2Lr+00mmnrwMnubuPwRNQ7OAtVrr9VrrDuAx4HzfMRpwxDDFQAyv3sFBa0eIZz9xi3fe1MHkZfUgR/2jkS4TZjSsesHEyOcUx55Cn57ldjr1G81LddS/mBw+4L4Y178CZzpRLt6R1cI/GIdaR0u0aabqeBhzusmRc+odTvmcTmbdG64QsOaX1t2w7Elzvzm3utcZO9dct63OjIzKRhnn23HfgsqjTPTHpg/MaGvCBSYHTYbPgWdHlJ0dpk6ss9iLSnd9IXYknOebtZ2RBVMuM8Kx+h3XKd5/AlzwR5hzS/TxtU76iLYGo1FkF8FJ/+4+s5eFfzT/VzqRKbO+Ahf9BS59yDynV3vS2kSLeBMCdkfNIiNMrTnqrV+4TvyXvgvN22DHZ9FaSGaeqwlaQdCwyf28dSmRTrKj1e3wB091rzF4qqkffyRU//Hm9/QnRRsyw6Q82bzQdIbe+i8caOo8lukjHDLhyoUDzf1sSgk/bfUmJUmgwUTYnPFTs/3GN+Fap+PO9AiCE79r2ln5aLfN1ywy15l5PfSfaARBMGAGW7llRqOxQgDg4v9z052cdZfpdMG8ixveNu/Cgt/D5g/cyLfzfg8nfBeOvDLat7BrrdG01r5qNJ6aRaY+ckuNZmOFwNxfwIV/jn5269+pXdJVI6kYZ/6nZe7fmuTdkExBMATwBvfWONu83AlcrZSqwWgD/xrrQkqpG5VSi5RSi/oisRzAvz6yhO8/bST1V08YyX+cM6Hnk/waQbwp9Jl5JklbLPNCeqartm5aYK4xYKKrPVjb6LDZbqqJWI7LtjozGrPM/bmJnJh5PRz/bTOa7uwwnVhdtXucXzUvG2HCLi25JabzBNizxYQinvJDOO1H5qVqqjXmsNPuhPwKY/Md5uRRsh1ZJEY/4G7320JzS1wtwZ7nFwTp2aa8p91prtW83bxgpVUw9QrTYYAbt241gs5288IeeTmcdHt0PVlsuKQ1aZQONyO+I84yv4fXdNayy/wGia6j7M+jZAm2RZv9Jl3sfk5L6yoIwkEjMCA6R5I3ymaQRxCMPNmYSPxx8/3Gd70GwMnfN+GLgQbzfF5zmi2bHR1bVHrXY/zXBVfwW+F84vdghNOeB09zwya9HeGwY0w7G3WKW9f1GwBlwi7HnG7qsGEToLuGdvY7wvx+kevNNmG3XrwaeN160w7HzYVTfgCFA6LNNrY9WUIBU1c5JdHteca1MOVSIqZale6urRELew/vO9DL9LWz+ArgAa11JXAW8JBSXedca63/pLWeqbWe2a9fvwNeSK01r69yHaRXHT2cnHiLy3gdbF0EQZwp9KVVZrQbUxBkuWqrjZAoHWE6gsy86BfDfo4XyljskcP+UM70LDMSaa1zE7mBm2/IkuNrjNaxC6ZDilUeiI4YstsjM6JtjL5TXzZqKHK/9OgXyXaA/tGR1RTsverWG2eifdasAmPKySkxzl6vnTjU5p4fa9RlR2nWyejVajLzo3+7SGrsBPPdxIpeAtO5eTWjUT6fjp01qzvdiXt2EGD/p2WY56zfYH7L4kq3/EOPNp/9mmh/J0lira/DznB+l0CjsfNne6LVbCfrn3PS3zNgsuXfEkPztULadqbxTCBep7C3jQScZIb11UaQZ+YY01k46CYutKP9yLVi/M7+AYjXdNbR3HW/t10Hfe9vR7P5TXM9kX/p2Z6QVqev6D/BlDteYIO9R5IcxZBcQbAF8KasrHS2ebkBeAJAa70AyAFi6OV9y6pt0XlxBhR3k7/EG43gV7m7aAROh1o6whEEMTpwO/2+tMrtMG3DyMqPDh2NCII4jssCj2kh2xeLn55hymdHQFYd9efQ8TurMn2j93iCwCt4IoLAGVH6Y/S9pqHcEvOM3o7BdoDKJ4xtWe29Nn1grmnrSyl3dOYXhOB27t2p33bkn+FpA1mOILCDgEi8foIagT+hniXQ4OaISstwO25/ecH9vbxk5pmO32oEpVXub1VaZWzc0HUk288RBH5bdUau+zvs2Rrd9vpPjP1sAya4fovB08zz+K8Lbnvctsw8a7zfwHvPSBspBbQxsdZtcM01dsCwc5V7fy+ZvkgjcB3GFv9v6BdQsdpR5Nw95p3yBnzE6swHTzUzkHfHyQpQPNRosUnyD0ByBcFHwBil1AilVBZwOeDzNLIJOBVAKTUeIwj6xvYD5kX2vxTA259HFyk7o5ukV177Xqjd2H0/e8685P6Zu7Zhlo0wI51YJh37EnlHHkXOqC4zL7ox25dn9xqTUsE/wuyug0vPgm3L3ckxQ48y//3RTf6G7Lfne2243s/FnjFBRBA4Mn/T+6bubcrqjBz3uXJKTN14BZDtAP3Jx6wgKBkGKDfW2x91kVsSbduNXNfp3GN1EJaWXc46ER6tKCsP0K7g9y6W01bvpgrwpltubzIO3YbNbmez9ZPohXraGtzBQ/HQaOHjLS9AxZiuZY1omq3G3Fc6whUsZSPceqp+L/q8/P7G7ON3mGdku79/U210PeVXRHfSltwyY0bLqzCdfemI2PmaOoOmbKE2c494JhDvPW1ZbNvY+qmx5ZdVOeV1BMGOlaYtlvvqKFZ5e4rm8w+EYrWjCNotp7+sXgZPM1rd6heN1uYXRnllpm6SFDEESRQEWusQcDPwCrASEx20Qin1Y6XUec5h3wa+opT6FHgUuFb3xTJjlkV/MV57Xw7zd9fuYkz/Ai6ZUckxPaWVjhIEbfCP78AT15gFXqxpyHbulUeZBjroSNM5xkq3a6eeD5hk/leMM6N3MC9YqSecLSMHUCYS4/Gr4bU7o69lbd8D40Q7bXof/vkf5vO0a8x/vznCPyrJyIluoF5No8iJtS8bGZ2Uzb7M1jT0xk+No9FGMxUMcMs69SoTslc2yj3f1knlUb6yZLv/CwfBpoXme0mVe0z5aHOtAc4I1mv6siq7darHEgid7V3TFthnth26VfHDQfMbPHEN/PE4Ezmz+UO4Zxb87SKTq+bxq1yBveD3Jl2CxYZ8ghtBk1vmCljvrNmcIlcrsHXVf4LTrho8GWLTzf9BU41mVTHGDBy8ZOa4Aw9vCpDM3Ojf2gr0gVNc86WXvArjMxo01S2/PSYtMzp8eczpbqfa3cjXO5iJzCdx2tGjVzjPPdF9DjA+kJJhXTvSWFlMB052rxlr3kvJsOjvpcNNJ221qFh4TUPeZ5t0kfk/ZLr5X7vE/GazvhJ9fmau226TRFJzDWmtX8Q4gb3b7vB8/gyYk8wy7BXWabZjJY2Djucn//iMfz1lNAs31HHN7OGJOYi9giAYMBEfYEZ/kZwp6aaTKBkG31phVu2q29A1Y+PX3nUb5uRLzAvldd5e8Xh0Y1bKGQE6pqzNzgj7jJ+axWvKRsL3a2Mv8G5jodv3GBPSsNnwvWqj1bzxU/e4Lqah3OgRjPdFmXAB3Lyoq5/BjsS8zl6bTOuYm10n4feqzYsz7aroMo87E7630ZTl9s3wC0fb8Jqx8src1BLekMZLHgCUEUyjTzN1/odjzT7bwZ/+Y5MHqny0sfv+z7joiUl+QWBjyxs2GQHmdTDa38CGptrUBJsXmhFqY41xOlrsRC9wBEGjqZNTfmi2fcsTfe3VCDLz4YZ/mrDG0hHGaVs2wnSOWz814bO2c//au+4z3PBPo7U21sAjl7rPVzrCifQZ4K4C59f+svKd9uQxX25fDtOuNpExWptjpl3jpqWO2LtL4MonnJnlIdOGapcYrai7ka9XENhoH9vmgq0w4kQ4+mtuecH4LcpGmnclu8h1/MeaL2DbfUau0dr+x/FdnP5jGHe2EWxeMnNNXqLMPBNltegvZiCm0t33Oco05Hm2L/4Jzv2tGUjc8okpf8lwc61JF7ntEuBLz8afJd0LSNI5Lx4b+/NLa5m3uIZ5i00s9henJZhDKEojCEQ7Aq0g0DFUxlhmm3xPp69U15XF/LMp7XWsINjhrLxUNtJtwImEn3mdU/51A2KZhuL5ApSKbbLwO4vBNeN4NZDu6ibiKPQIIW/H6C2nNYdA9Ci6/xHR5jPbcWRkGdu2/ZyZEy0I/KmN7Ui2boPpSOqr3Q7H/gYWr+mxYaPjl6l2t3k/N242HWjhILfc3vJ7fQRZ+a7ZC9zyZ+W7Qsj+Nl6tzbZBK0TTMl2tAdxEftA1misrP/Zvn1UQfQ/vYMUek1Ni6jbDI7wTcYrGagveSV5jTncFhFcQ2DkuuSWuIIgXvBGZuJhjtJrWXeY3rhgd+3jbvvof4WoRxUPcesst9fkzHNIzIN2pJ3/6Ff/M9SSFjVr6Omro4MKaAjpaokyUk4cUM2lInDQSfroIAo8j0E7PtxePcqzG6NT3Jcd9rOvsrZPJa/f0m0dimYa8lRUrn5AfW0bvSN3az7u1ufaAVyOwL2d2cfcLmWQXE3Hax8td75/34P9eMtRco36D8RM0bY2eDOUNs/QKgljhxN7MqdbEFK9jjHJYx/FrRHXU3dSt7TStoLG/Y9TcBZ8Z0N827DnxMn56yxDrmRIxDfnrHsyz20CIqLbrNZ3FMM3EC+f24tVgEsEeZ/14dpt93kTfxSR3/H5EEHhxKn/h5zXc946r3n/z9Bij2nhEmYbaXLt/oKFrw/N2XLEcV/siCOzL6e189tbJ5B3V+ztR/7X8L328fEJeYpmGwERGeJ3Ke0uURmBHYD0I8LQ0V6uI1cn4rxvve3GlGc3bjKneCBWvluO3x3eHNTHF+/2iHNYx2g+4HUpGjvG9xMN2mvb3tG0gr8I1y8UyDXmx53QrCJxjYj1Td/ssaXG6LHuut+3GbA9eQRBHI4h13UQ7cHucdy5KPNNQdxyoFe8cxDTkxQlH3LR1BxtCJgTzR+dO4ORx/WMfHw67Mz8HTXVmBn7i7vc6/nauMqkbwDUNeX/sWI7JfWkMVhANngbrnAUv9lYj6G5U77+W/8VMZBlB+6z5vkjhospoU8Hekh7DNJRI7HVuqRHY/g7e4vepxEptXFplFhixC6R4Z/COPNksBrO32DDLRH6/eJFOdntpVfxOFDyOdisIPCPhjBzjK0pLj/59uwgC55zuVgUrrnTncvgpS0AjiEfZCBMxFCUIPL+Td86BxR/FF4vSfdQI7JwdlWbMhLE0ku5I0sSxeIgg8KA721FAnjLx7GP6F3DdnG46xT018NGfTYe98vn4x+WWGTvtFsdReM5vzGIiwz3OoFiq4L44h6zWMfo0Ez+eXdj9SNAy97/NzOCdq90ZypbZ3zDX2b7c9TVc/mj0VP0z70o8kV7lUSY1xaAjTVRQ4UD4/J8w/pzEzo+HV4jszYtnj4mXu37SRfD5S2bRFx2OLVwmX2LSUAQaTP2NPs39DY4426Qr6Ghx66yo0kQu5VeY2cBjzjABBXbhk/z+Zl92kUn5EI+Z15sJWv4IKsuok2H9m2YWdHfYTtN24oWDYMrlMPp0WPzX6LV1p3/ZpEuwdndLyXAze7jqBOKSlm6cuUNndd1XVGlShIw+rfuyHnNz1zxEEy80Ass7yc1rerS/8cQLjHN59zozO7gnjjjbaHGFMWabx2LQkaZtjzzZrLCWU2wEcOlwswiQf3Zzd8z6qjsLP8mIIPBQ19RKOdAvuxMSGCxEJm5VHdcl5JTzfgfPORkzykbAFk98+MBJJhLGS0xBsA+WO+uHKK2CG15J/LzZX4u/b+5/dd12xFnR0/OPvjHxexUNgisfN58v+F/z/9Q74h+fKOk9mALiYY+JZ9I45Qfm76ELjZYVy9Y+48vmz8vVHi3goj+b+QRWEHxjYXSnZVnxtBEmc3/ec+cNZlDRHVYg9UR6hhmp2zpIS4MLnYSEmbnRguC8u+Nf4+K/9HyvWCvoRe75p9j7ejp/7Bnmz4s3gs0K70kXuWGbiTB4qhNpliC5paZtW0exFUAZ2XDZQ/HPi8VZv+z5mF5CfAQettWZaIJhzvvZFIiTjtZiZwLbmHQv3pGoP746lsmnt5xDViNI4nT0g46IDdtTr3trGoLubdvgCv5EHOKxsOd1lzwsMms8js0/mWTkxK6DjOye6+ZgJJaP4EBhf79D5D0UQeChvsm86GUZxjTU3N6TIHBmAtvJXl68jl7/CDKWyae72ax7Q0QQHOCG35fY+vRqBPtkGuqhs7M5/P2CPVG8ztB4NuBICGYvtYe9ISMndh1k5PZcNwc7OQe4Q44EbRwa76GYhjw0OoIgs6ORE0YVcd0JMfK3WDqDriAoH2M6I6/zyetg9C9iEisaqLdGgDYSIol5SQ46bF17Na3eNA1Zmp3Qzn0Ncc0uNFE43f029toHOHwQ6F4jOLC+y97DvpcHukPOyDbBJ4fIeygagYfGFmPqUXtqeHDLOZzc/qZJEfH012HJ3+DOYpNff918+EkFPHalOTG70IzkvJkW09LdlL/+ySHdmYbsTOJ9xU46O0RGIr2CnTzljWixeYxirS3gxx7TU+dr03mU7EeIa/mortFS/v3gzG84wGQXxh6QZBdCVmHX7YcC1tmac4DrUylzz+5+64MI0QgwaaZ/+Mxyxna0mxo57U54/Scm5HPDW8YXYCc81a3vmiUwKx++eK8xy9w/12xLy4SrnzKRQmPOMCkCbKqGmIIgz0y5HzIT7hq57w9z5RNm0lK8CJjDkSseM6kbvMKvdDhc+mBijtJpV5kOuKfO4qp5JsInXphpIpz9KzfdQiwmXeTklkleXpm4nP/72CPYL/wsOqvuocRlD8HGBX3TIV/64L6bEQ8wIgiApz7ewsMLN/Hk4Bx0x0DUcd+Ed35j0ivUO2kAbLha4+au6wxk5UHljOg00mkZZinFsV8w36d/2SMI4oSF2mP3h/wKM80+lcgr6xoxAjDBvyBeHHJLTf6iniga5CbS21d60vgyc/cuqqU3qZwZe3usYIhDhdzS6Oi2A8mI43s+5iBBTEPAP5ZtZURFPjOHFqBsJ52Vb2KNO9sxuc6d/CR1G7ouQZnpmb1p8U9C8pod9mXGsCAIQpIQQQCsqG1k6tASVDjkdtJZeWYCkaXRWVOnvjpGnnabsMtTnf4Ztt5Zjgd4+rggCEJ3pLwg2NXYzPCmT5g4uMiYgGwnnZXvppAGN/vk4gfcySLd4R/1dyckBEEQ+pCU9xG0vvITnsj+I0szp5rQS9uBR620leemTwgHYdmTPV84Vs7/RCka4i7oLgiCkGRSXiPo2GGyQY7OctYLSPP4CMCE8dnY7qlXJz7xa38EwW3L4Dt7kaVSEARhP0h5QbCr3Zhp8lSHoxFY05BnZmAkJW+ZJ8NiDzHn+yMI0tL3Lc+QIAjCPpDyvc32NqcKgq3RpqFIrpCS6JWTrKbgny3sZ38EgSAIwgEkpQVBY1uQHQGvIPA4i60JKKckOkdMVoI5REQQCIJwiJDSguCZJVsI4HT8HVYQ+HwEuaXRS+hZTSHealYWmSsgCMIhQkoPWx/9cBM3FGZBG2aFqqh5BNZZXADDjjYLjwyfA6tfMtszc+C0/4y9ODvEDhG99MHEQk8FQRAOICkrCLTWVO9uYejgdEcQNMQ2DaVnmaRbF91nvnvXgD3utvg3iGUaSjTlgSAIwgEkZU1DewIhAsEwhRlOArA2nyCwKzL5ZwFnxUgnEYt9WWZSEAShD0hJQdDaEeKdNSa3fH6Gk1Ux0GCihuxI3i7w4rf1RwRBDxkoxVksCMIhQsr1Vq0dIab++FU6QkYTyEt3ViGr2xCtEdgFXvwagTUZad39jSSNhCAIhwgppxGs3dEcEQIAucrRCJq3QVud2/HbdMP+1aisRqDj5GevcFY1i7cUoSAIwkFGymkEzb4F6XPSQiZEtK3ebLCmoKlXQX4/s6iMFysI4i3Ucd1LULeuF0ssCIKQXFJOI9jjEwQZOmhG/TOvXb15owAAFFRJREFUNxusIFDKLBTjH9lbjSGeRpBfDkNn9WKJBUEQkkvKCYLm9mhBoELtpnMvcdajDbbFOMt7glNlh+rSfYIgCD5S0DRknMDvfu9k8rIy4LHfmgig4kpzwJ4t3V/AOoG7W3dWEAThECKpGoFSaq5SarVSaq1S6vY4x1yqlPpMKbVCKfVIMssD0OSYhvoX5lCWn+VECmWbNQAA9tR2fwElgkAQhMOLhASBUuoppdTZSqmEBYdSKh24BzgTmABcoZSa4DtmDPDvwByt9USgm6m6vUNze4jsjDSyMpxHCXUYjWCAU7RpV3d/AbuI/ZFXJK+QgiAIB5BETUP/C1wH3K2UehK4X2u9uodzZgFrtdbrAZRSjwHnA595jvkKcI/Wuh5Aa71jbwq/L+wJhCjM8UwS63R8BDnFcGdjzxcoGZrYcYIgCIcICY3wtdavaa2vAqYD1cBrSqn3lVLXKaXi5VIYAmz2fK9xtnkZC4xVSr2nlPpAKTV374q/9zS3hyjM8cg/qxEIgiCkKHtj6ikHrgX+BVgC/BYjGF7dj/tnAGOAk4ArgD8rpbok+ldK3aiUWqSUWrRz5879uJ1xFhdkewSB1QgEQRBSlER9BE8D7wB5wLla6/O01o9rrf8VKIhz2hZgqOd7pbPNSw3wnNY6qLXeAHyOEQxRaK3/pLWeqbWe2a9fv0SKHJemgF8jaBeNQBCElCZRjeBurfUErfXPtdZbvTu01jPjnPMRMEYpNUIplQVcDjznO+YZjDaAUqoCYypan2jh94Xm9pBPI+gQjUAQhJQmUUEwwWuyUUqVKqVu6u4ErXUIuBl4BVgJPKG1XqGU+rFS6jznsFeA3Uqpz4D5wL9prXfv9VPsBU1+Z7FoBIIgpDiJRg19RWt9j/2ita5XSn0FE00UF631i8CLvm13eD5r4FvO3wFhTyDomobCnSZVRLoIAkEQUpdENYJ0pdykO84cgUPOnhLsDNMUCFGa5xQ91G7+y/rCgiCkMIlqBC8Djyul7nW+f9XZdkhR32IWmykvsGsOOIJATEOCIKQwiQqC72E6/687318F7ktKiZLIrmZHEOT3sPiMIAhCCpGQINBah4E/OH+HLHWORlCW7zMNiUYgCEIKk5AgcHIC/RyTMyiyarvWemSSypUUdreYjt81Ddl1iUUjEAQhdUnUWXw/RhsIAScDDwJ/S1ahkoXVCMrzHQ0gYhoSZ7EgCKlLooIgV2v9OqC01hu11ncCZyevWMlhd3MH6WmK4lyn4w+Lj0AQBCFRZ3G7k4J6jVLqZkyqiHipJQ5adrd0UJqXSVqaEwkrpiFBEISENYJbMXmGbgFmAFcDX05WoZJFfUuH6ygG1zSUlnILtQmCIETosQd0Jo9dprX+DtCMWZfgkKSlI2SWp7SIRiAIgtCzRqC17gSOOwBlSTrtoTA5mZ5HlnkEgiAICfsIliilngOeBFrsRq31U0kpVZJoD3ZSkhfDNCRRQ4IgpDCJCoIcYDdwimebBg4tQdBFI7CmIREEgiCkLonOLD5k/QJeAsFOsjPS3Q3iIxAEQUh4ZvH9GA0gCq319b1eoiTSRSMIh8x/0QgEQUhhEjUNveD5nAN8Eajt/eIkF9EIBEEQupKoaejv3u9KqUeBd5NSoiQS10eQJhqBIAipS6ITyvyMAfr3ZkGSjdY6hkYgUUOCIAiJ+giaiPYRbMOsUXDIEAprwhqZRyAIguAjUdNQYbILkmwCwU4A8REIgiD4SMg0pJT6olKq2PO9RCl1QfKK1fu0h8JAPI1ATEOCIKQuifoIfqS1brRftNYNwI+SU6TkEFcjSMsApfqoVIIgCH1PooIg1nGHVMpOqxFkR80jCIpZSBCElCdRQbBIKfVrpdQo5+/XwOJkFqy3ia0RBMUsJAhCypOoIPhXoAN4HHgMCADfSFahkkEgGMtH0CEagSAIKU+iUUMtwO1JLktSaQ/F8xGIRiAIQmqTaNTQq0qpEs/3UqXUK8krVu/THlMjCIlpSBCElCdR01CFEykEgNa6nkNsZnFcjUBMQ4IgpDiJCoKwUmqY/aKUqiJGNtKDGfERCIIgxCbRENAfAO8qpd4CFHA8cGPSSpUEIhpBpj9q6JCKghUEQeh1EnUWv6yUmonp/JcAzwBtySxYbxPRCDJkHoEgCIKXRJPO/QtwK1AJfALMBhYQvXTlQU18jUAEgSAIqU2iPoJbgaOAjVrrk4FpQEP3p4BSaq5SarVSaq1SKm74qVLqIqWUdrSOpHDsqAruPHcCuZl+Z7FEDQmCkNokaiAPaK0DSimUUtla61VKqXHdnaCUSgfuAU4HaoCPlFLPaa0/8x1XiBE0C/eh/AkzaUgxk4YUR2/s7IDsomTeVhAE4aAnUY2gxplH8AzwqlLqWWBjD+fMAtZqrddrrTswM5LPj3HcT4D/xsxWPrB0hsQ0JAhCypOos/iLzsc7lVLzgWLg5R5OGwJs9nyvAY72HqCUmg4M1Vr/Qyn1b/EupJS6ESdKadiwYfEO23vENCQIgrD3GUS11m/1xo2VUmnAr4FrE7jnn4A/AcycObP35i/IPAJBEIR9XrM4EbYAQz3fK51tlkJgEvCmUqoaE4n0XDIdxl3oDJr1CARBEFKYZAqCj4AxSqkRSqks4HLgObtTa92ota7QWldprauAD4DztNaLklimaHQnpKX3fJwgCMJhTNIEgdY6BNwMvAKsBJ7QWq9QSv1YKXVesu67V4RFEAiCICTVLqK1fhF40bftjjjHnpTMssREd4ppSBCElCeZpqGDn3AIlGgEgiCkNikuCMJiGhIEIeVJbUGgO0GldhUIgiCkdi8ozmJBEIQUFwS6U3wEgiCkPKktCEQjEARBSGFBEA4DWsJHBUFIeVJXEGizUI2YhgRBSHVSVxCEHUGQlrpVIAiCAKksCEQjEARBAFJZEEQ0AhEEgiCkNqkrCEQjEARBAFJZEITD5r9EDQmCkOKksCAImf/iLBYEIcVJ3V5QTEOCIAhAKgsCcRYLgiAAqSwIRCMQBEEAUlkQiEYgCIIApLIg0E7UkGgEgiCkOKkrCCJRQyIIBEFIbVJYEIhpSBAEAVJZEIizWBAEAUhlQSAagSAIApDKgkCcxYIgCEAqCwJZj0AQBAFIZUFgfQSSdE4QhBQndQWBDR8V05AgCClOCgsCcRYLgiBAKgsCCR8VBEEAUlkQRBamEUEgCEJqk7qCIKIRpG4VCIIgQCoLAvERCIIgAEkWBEqpuUqp1UqptUqp22Ps/5ZS6jOl1FKl1OtKqeHJLE8UkaRzEj4qCEJqkzRBoJRKB+4BzgQmAFcopSb4DlsCzNRaTwHmAb9MVnm6IM5iQRAEILkawSxgrdZ6vda6A3gMON97gNZ6vta61fn6AVCZxPJEI85iQRAEILmCYAiw2fO9xtkWjxuAl2LtUErdqJRapJRatHPnzt4pnTiLBUEQgIPEWayUuhqYCdwVa7/W+k9a65la65n9+vXrnZuKs1gQBAGAZHpKtwBDPd8rnW1RKKVOA34AnKi1bk9ieaIRH4EgCAKQXI3gI2CMUmqEUioLuBx4znuAUmoacC9wntZ6RxLL0pWwJJ0TBEGAJAoCrXUIuBl4BVgJPKG1XqGU+rFS6jznsLuAAuBJpdQnSqnn4lyu95E1iwVBEIDkmobQWr8IvOjbdofn82nJvH+3yMI0giAIwEHiLO4TZGEaQRAEIJUFgTiLBUEQgFQWBBI+KgiCAKSyIBCNQBAEAUhlQSDho4IgCEAqCYLaT+CDPxgB0NECa18z28U0JAhCipM6gmDD2/Dy7RBsgxe+BZsXmu1K9W25BEEQ+pjUEQSZueZ/KAB16/q2LIIgCAcRqSMIMrLN/1AAMnL6tiyCIAgHESkkCByNICiCQBAEwUsKCQKrEbRBpggCQRAES+oIgoiPoF00AkEQBA+pIwhs5x9sg7TMvi2LIAjCQUTqCYJQADoP3Po3giAIBzupIwgyPYIgGOjbsgiCIBxEpI4giJiGAkYYCIIgCEAqCoJQmwgCQRAED6kjCLxRQ8G2vi2LIAjCQUTqCAI7jyDYZoRB5VHwjY/6tkyCIAgHASkkCDy5hkJtUDIc+o3t2zIJgiAcBKSOIEjPMIvQ2KghmVQmCIIApJIgAOMnsFFDkmZCEAQBSDVBkJHjRg2JRiAIggCkoiCwGoEIAkEQBCDVBEFmDnQ0gQ6LaUgQBMEhtQRBRi60NTifRRAIgiBAygmCbBEEgiAIPlJLEGTmQqDB/SwIgiCkmCDIyIY9W5zPohEIgiAAZPR1AQ4oM2+ArHzjK6g6rq9LIwiCcFCQWoLgiLPMnyAIghAhqaYhpdRcpdRqpdRapdTtMfZnK6Ued/YvVEpVJbM8giAIQleSJgiUUunAPcCZwATgCqXUBN9hNwD1WuvRwG+A/05WeQRBEITYJFMjmAWs1Vqv11p3AI8B5/uOOR/4q/N5HnCqUkolsUyCIAiCj2QKgiHAZs/3GmdbzGO01iGgEShPYpkEQRAEH4dE+KhS6kal1CKl1KKdO3f+//buPkauqg7j+PextAUpoVZW0lgCLZIoGqy1GhQkBONbNYJJDY2IjTExUUgkxggNqEjiH5r4mhALaqVAUURpbEiMQtvU8AeUAtvS8lqlJjSV9Q20Jjba/vzj/MYOszvbWdx777T3+SSTvXPm7swzv5nZM/fM7DlNxzEzO6ZU2RHsBU7rOr8g2ybcR9JxwMnAX3qvKCJujoilEbF0ZGSkorhmZu1UZUfwEHCWpIWSZgErgA09+2wAVub2cmBTRESFmczMrEdl/0cQEf+RdCXwa2AGsCYidkm6AdgWERuAHwG3SdoN/JXSWZiZWY10tL0Bl/Qn4A8v89dPAf48jXGmy7DmguHN5lxT41xTcyzmOj0iJhxbP+o6gv+HpG0RsbTpHL2GNRcMbzbnmhrnmpq25ToqvjVkZmbVcUdgZtZybesIbm46QB/DmguGN5tzTY1zTU2rcrXqMwIzMxuvbUcEZmbWwx2BmVnLtaYjONLaCDVn2SPpMUmjkrZl2zxJ90p6Jn++qoYcaySNSdrZ1TZhDhXfy/rtkLSk5lzXS9qbNRuVtKzrslWZ6ylJ76sw12mSNkt6XNIuSZ/L9kZrNkmuRmsm6XhJWyVtz1xfzfaFuf7I7lyPZFa217Y+ySTZbpH0bFfNFmd7nc//GZIelXRPnq++XhFxzJ8o/9n8O2ARMAvYDpzdYJ49wCk9bd8Arsnta4Cv15DjAmAJsPNIOYBlwK8AAecCD9ac63rgCxPse3Y+nrOBhfk4z6go13xgSW6fBDydt99ozSbJ1WjN8n7Pye2ZwINZh58BK7J9NfCZ3P4ssDq3VwB3Vvgc65ftFmD5BPvX+fz/PHAHcE+er7xebTkiGGRthKZ1r82wFrik6huMiN9SpvYYJMfFwK1RPADMlTS/xlz9XAz8NCIORMSzwG7K411Frn0R8Uhu/wN4gjKVeqM1myRXP7XULO/3/jw7M08BXERZfwTG16uW9UkmydZPLY+lpAXAB4Ef5nlRQ73a0hEMsjZCnQL4jaSHJX06206NiH25/Ufg1Gai9c0xDDW8Mg/L13QNnTWSKw/D30J5Jzk0NevJBQ3XLIc5RoEx4F7K0ccLUdYf6b3tWtcn6c0WEZ2afS1r9m1Js3uzTZB7On0H+CJwKM+/mhrq1ZaOYNicHxFLKMt4XiHpgu4LoxzrNf693mHJkb4PnAksBvYB32wqiKQ5wC+AqyLi792XNVmzCXI1XrOIOBgRiynT0L8deH3dGfrpzSbpTcAqSsa3AfOAq+vKI+lDwFhEPFzXbXa0pSMYZG2E2kTE3vw5BqynvECe7xxq5s+xhuL1y9FoDSPi+XzhHgJ+wOGhjFpzSZpJ+WO7LiLuzubGazZRrmGpWWZ5AdgMvIMyrNKZ+bj7tgdan6TCbO/PYbaIiAPAj6m3ZucBH5a0hzJ8fRHwXWqoV1s6gkHWRqiFpBMlndTZBt4L7OSlazOsBH7ZRL5JcmwAPpHfnjgXeLFrOKRyPeOxH6HUrJNrRX6DYiFwFrC1ogyiTJ3+RER8q+uiRmvWL1fTNZM0Imlubp8AvIfy+cVmyvojML5etaxP0ifbk10duihj8d01q/SxjIhVEbEgIs6g/I3aFBGXUUe9puuT7mE/UT71f5oyRnltgzkWUb6xsR3Y1clCGdvbCDwD3AfMqyHLTyhDBv+mjD1+ql8Oyrclbsz6PQYsrTnXbXm7O/IFML9r/2sz11PAByrMdT5l2GcHMJqnZU3XbJJcjdYMOAd4NG9/J/DlrtfAVsqH1HcBs7P9+Dy/Oy9fVOFj2S/bpqzZTuB2Dn+zqLbnf97ehRz+1lDl9fIUE2ZmLdeWoSEzM+vDHYGZWcu5IzAzazl3BGZmLeeOwMys5dwRmNVI0oWdWSXNhoU7AjOzlnNHYDYBSR/P+epHJd2UE5Ttz4nIdknaKGkk910s6YGcqGy9Dq9H8DpJ96nMef+IpDPz6udI+rmkJyWtq2qGTbNBuSMw6yHpDcClwHlRJiU7CFwGnAhsi4g3AluAr+Sv3ApcHRHnUP7rtNO+DrgxIt4MvJPy39JQZge9irIuwCLKHDNmjTnuyLuYtc67gbcCD+Wb9RMoE8kdAu7MfW4H7pZ0MjA3IrZk+1rgrpxP6rURsR4gIv4FkNe3NSKey/OjwBnA/dXfLbOJuSMwG0/A2ohY9ZJG6Us9+73c+VkOdG0fxK9Da5iHhszG2wgsl/Qa+N+axKdTXi+dWSA/BtwfES8Cf5P0rmy/HNgSZaWw5yRdktcxW9Ira70XZgPyOxGzHhHxuKTrKKvIvYIyC+oVwD8pC5hcRxkqujR/ZSWwOv/Q/x74ZLZfDtwk6Ya8jo/WeDfMBubZR80GJGl/RMxpOofZdPPQkJlZy/mIwMys5XxEYGbWcu4IzMxazh2BmVnLuSMwM2s5dwRmZi33XxiHzQGDEGXiAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.plot(cnnhistory.history['accuracy'])\n",
        "plt.plot(cnnhistory.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'valid'], loc='upper left')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jVaxLrTj3Hxc",
        "outputId": "bfe19b5c-5887-413f-a799-fcd73dae55fe"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.00000000e+00, 5.79582167e-15, 1.10842918e-14, 2.41427683e-10,\n",
              "        1.40107435e-13, 4.27788696e-18],\n",
              "       [4.46586368e-09, 6.19677544e-01, 3.76804858e-01, 3.47956615e-08,\n",
              "        3.51750362e-03, 5.68248365e-11],\n",
              "       [9.99987483e-01, 2.07249897e-07, 2.32793403e-11, 1.16558522e-05,\n",
              "        5.77966148e-07, 7.04327048e-12],\n",
              "       [3.02750175e-03, 9.42558572e-02, 6.35768652e-01, 1.75120216e-03,\n",
              "        2.65196174e-01, 5.90612046e-07],\n",
              "       [1.23612335e-16, 9.99795735e-01, 1.64793235e-07, 2.04115131e-04,\n",
              "        9.63621716e-09, 9.62876387e-19],\n",
              "       [1.83467233e-08, 1.78572312e-01, 4.01857972e-01, 3.06967172e-06,\n",
              "        4.19566661e-01, 5.57431878e-10],\n",
              "       [2.09840825e-13, 1.44145358e-03, 1.00670349e-11, 9.98526216e-01,\n",
              "        3.22033375e-05, 9.73090640e-17],\n",
              "       [1.97705731e-07, 9.99981999e-01, 8.47582851e-06, 9.08108632e-06,\n",
              "        2.59412303e-07, 1.45152007e-11],\n",
              "       [9.02196007e-06, 8.72027278e-02, 9.05566931e-01, 7.96601744e-05,\n",
              "        7.14169303e-03, 1.83932212e-08],\n",
              "       [9.99128282e-01, 9.41911327e-10, 2.67111139e-10, 8.71386554e-04,\n",
              "        3.14277798e-07, 2.28966585e-13],\n",
              "       [4.95889399e-04, 1.40998213e-10, 9.45116652e-10, 3.45276498e-12,\n",
              "        9.99504089e-01, 4.19375880e-15],\n",
              "       [1.98967145e-11, 3.52233738e-01, 6.06053732e-02, 6.03922626e-06,\n",
              "        5.87154806e-01, 7.06705944e-11],\n",
              "       [7.04720787e-06, 3.19082453e-03, 9.91636813e-01, 3.92136350e-03,\n",
              "        1.24392344e-03, 1.77217547e-08],\n",
              "       [3.24072456e-03, 1.18004894e-02, 7.58205206e-05, 9.32901978e-01,\n",
              "        5.19809052e-02, 1.38013654e-08],\n",
              "       [5.47386182e-04, 1.11553096e-03, 3.95536274e-02, 1.44764315e-04,\n",
              "        9.58638549e-01, 9.08835247e-08],\n",
              "       [9.99970078e-01, 1.07388374e-08, 4.96386747e-07, 2.94023703e-05,\n",
              "        4.54932619e-11, 6.47946106e-12],\n",
              "       [6.33927910e-11, 1.65218577e-08, 5.98317058e-07, 3.54956370e-10,\n",
              "        9.99999404e-01, 8.52908442e-14],\n",
              "       [2.23072879e-02, 9.21864796e-07, 2.41594603e-06, 9.77689266e-01,\n",
              "        1.55788001e-07, 1.60593328e-09],\n",
              "       [1.00000000e+00, 1.13806166e-10, 8.07648965e-14, 5.39343397e-08,\n",
              "        5.37900000e-08, 7.60328351e-14],\n",
              "       [8.15510532e-07, 1.23944413e-03, 3.66008282e-01, 6.07837283e-05,\n",
              "        6.32690668e-01, 2.90904856e-09],\n",
              "       [1.47106709e-06, 3.00647389e-06, 8.37009847e-02, 1.47636356e-07,\n",
              "        9.16294336e-01, 1.17284016e-10],\n",
              "       [1.12177736e-06, 2.40069777e-02, 2.16380768e-02, 9.43212015e-08,\n",
              "        9.54353750e-01, 3.56990171e-09],\n",
              "       [4.99145267e-13, 9.33119059e-01, 6.64582327e-02, 2.24740052e-06,\n",
              "        4.20424243e-04, 4.69554662e-15],\n",
              "       [9.99068081e-01, 1.64350809e-06, 5.71455589e-13, 9.30162030e-04,\n",
              "        8.64164917e-08, 1.08320280e-11],\n",
              "       [5.10892768e-08, 1.05061255e-04, 1.25402836e-02, 9.26635323e-07,\n",
              "        9.87353683e-01, 7.86413956e-09],\n",
              "       [1.00000000e+00, 3.57801809e-11, 1.59004347e-13, 2.77565597e-08,\n",
              "        3.47174485e-08, 2.61543411e-14],\n",
              "       [2.38767033e-08, 1.65944148e-04, 1.97083056e-02, 8.81898177e-06,\n",
              "        9.80116904e-01, 3.82249010e-10],\n",
              "       [5.69036638e-04, 6.81253674e-04, 4.03290167e-02, 1.25050673e-03,\n",
              "        9.57170188e-01, 7.48906359e-09],\n",
              "       [1.79836839e-01, 1.62471412e-03, 2.25428585e-03, 7.69848228e-02,\n",
              "        7.39299238e-01, 8.28830835e-08],\n",
              "       [9.99999881e-01, 2.49347001e-11, 3.30263974e-13, 1.40743438e-07,\n",
              "        1.89506688e-10, 2.83814779e-15],\n",
              "       [4.56324924e-04, 1.27957528e-02, 3.95631604e-03, 3.41715386e-05,\n",
              "        9.82757390e-01, 8.28583938e-11],\n",
              "       [1.98839371e-06, 2.39404763e-08, 1.07835085e-09, 9.99997973e-01,\n",
              "        2.83860602e-09, 4.74838094e-12],\n",
              "       [3.14230250e-13, 1.98810041e-01, 1.97660182e-12, 8.01188827e-01,\n",
              "        1.12528380e-06, 1.00275466e-18],\n",
              "       [1.05503132e-05, 1.58282086e-01, 8.39591682e-01, 2.39130168e-06,\n",
              "        2.11338676e-03, 2.14550910e-09],\n",
              "       [6.29321539e-06, 3.75771424e-06, 7.62205957e-07, 1.19137567e-07,\n",
              "        9.99989033e-01, 1.40150868e-12],\n",
              "       [1.01687774e-01, 4.07022271e-05, 7.92279025e-06, 8.98260117e-01,\n",
              "        3.37658480e-06, 3.03683301e-08]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "#predictions = model.predict_classes(x_testcnn)\n",
        "predictions = model.predict(x_test)\n",
        "predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y01xRIqN3Kv7",
        "outputId": "11bcd629-2f95-45af-db2f-2da87e0eb0a2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 2, 0, 2, 1, 1, 3, 1, 2, 0, 4, 4, 2, 3, 4, 0, 4, 0, 0, 4, 4, 1,\n",
              "       2, 0, 4, 0, 4, 2, 0, 0, 1, 3, 3, 2, 4, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "emo_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DLhoAcuI3N3Z",
        "outputId": "135d5ccc-aa36-4430-c57e-5d08df3df4e5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 2, 0, 2, 1, 1, 3, 1, 2, 0, 4, 4, 2, 3, 4, 0, 4, 0, 0, 4, 4, 1,\n",
              "       2, 0, 4, 0, 4, 2, 0, 0, 1, 3, 3, 2, 4, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "new_Ytest = emo_test.astype(int)\n",
        "new_Ytest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "msg0xsZw3ROh",
        "outputId": "eb72f4e3-2e99-4aa8-fb09-5532c3b8a3b8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 0, 2, 1, 4, 3, 1, 2, 0, 4, 4, 2, 3, 4, 0, 4, 3, 0, 4, 4, 4,\n",
              "       1, 0, 4, 0, 4, 4, 4, 0, 4, 3, 3, 2, 4, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "preds1=predictions.argmax(axis=1)\n",
        "preds1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-nADWckp3UHg",
        "outputId": "1657b6af-67a2-4a9a-ae6b-bd8705846a25"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[8, 0, 0, 2, 1],\n",
              "       [0, 2, 0, 0, 3],\n",
              "       [0, 2, 4, 0, 1],\n",
              "       [0, 0, 0, 4, 0],\n",
              "       [0, 0, 0, 0, 9]])"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "abc = preds1.astype(int).flatten()\n",
        "from sklearn.metrics import confusion_matrix\n",
        "c = confusion_matrix(new_Ytest, abc) \n",
        "c"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2fbTq6qW3UOm",
        "outputId": "60ea0c34-4e1e-44cc-de4a-ea981b130fa6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 2, 0, 2, 1, 1, 3, 1, 2, 0, 4, 4, 2, 3, 4, 0, 4, 0, 0, 4, 4, 1,\n",
              "       2, 0, 4, 0, 4, 2, 0, 0, 1, 3, 3, 2, 4, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "emo_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vcuBTzA93UQk",
        "outputId": "8bd8abdb-10cd-4035-b09f-6ad6a8f3934f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/graduation project/audio/model/original_augmation_Savee_400_epoch_12_kernal_size_and_bat2/assets\n",
            "MODEL SAVED\n"
          ]
        }
      ],
      "source": [
        "#model.save('/content/drive/My Drive/augmanted_radvass')\n",
        "model.save('/content/drive/My Drive/graduation project/audio/model/original_augmation_Savee_400_epoch_12_kernal_size_and_bat2')\n",
        "print(\"MODEL SAVED\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gleoIwgk3aRm",
        "outputId": "096170f4-73bd-41bc-a822-ad9245c1b19c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " batch_normalization (BatchN  (None, 40, 1)            4         \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " conv1d (Conv1D)             (None, 40, 128)           1664      \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 40, 128)          512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation (Activation)     (None, 40, 128)           0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 40, 128)           0         \n",
            "                                                                 \n",
            " max_pooling1d (MaxPooling1D  (None, 8, 128)           0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv1d_1 (Conv1D)           (None, 8, 256)            393472    \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 8, 256)           1024      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 8, 256)            0         \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 8, 256)            0         \n",
            "                                                                 \n",
            " max_pooling1d_1 (MaxPooling  (None, 1, 256)           0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 256)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 6)                 1542      \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 6)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 398,218\n",
            "Trainable params: 397,448\n",
            "Non-trainable params: 770\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "#new_model=keras.models.load_model('/content/drive/My Drive/augmanted_radvass')\n",
        "new_model=keras.models.load_model('/content/drive/My Drive/graduation project/audio/model/original_augmation_Savee_400_epoch_12_kernal_size_and_bat2')\n",
        "new_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pufwy7Ia3b12",
        "outputId": "6a1d5c97-ed66-4daa-a3c1-9f04beb2602e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 7ms/step - loss: 0.7416 - accuracy: 0.7500\n",
            "Restored model, accuracy: 75.00%\n"
          ]
        }
      ],
      "source": [
        "loss, acc = model.evaluate(x_test, emo_test)\n",
        "print(\"Restored model, accuracy: {:5.2f}%\".format(100*acc))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gqYIsrpY3drM",
        "outputId": "efc4812d-d940-4b4f-bd06-76062c2b8df5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "36/36 [==============================] - 0s 7ms/step - loss: 0.0014 - accuracy: 1.0000\n",
            "Restored model, accuracy: 100.00%\n"
          ]
        }
      ],
      "source": [
        "loss, acc = model.evaluate(x_train, y_train)\n",
        "print(\"Restored model, accuracy: {:5.2f}%\".format(100*acc))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 606
        },
        "id": "biI56TZV3fPV",
        "outputId": "6d528c93-1e32-4c0c-c97b-0175d5c418e3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.73      0.84        11\n",
            "           1       0.50      0.40      0.44         5\n",
            "           2       1.00      0.57      0.73         7\n",
            "           3       0.67      1.00      0.80         4\n",
            "           4       0.64      1.00      0.78         9\n",
            "\n",
            "    accuracy                           0.75        36\n",
            "   macro avg       0.76      0.74      0.72        36\n",
            "weighted avg       0.80      0.75      0.74        36\n",
            "\n",
            "----accuracy score 75.0 ----\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-ced4651393a1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m#df_cm = pd.DataFrame(cm)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mclass_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'neutral'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'calm'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'happy'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'sad'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'angry'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'fearful'\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mdf_cm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0msn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheatmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_cm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mannot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfmt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    676\u001b[0m                     \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m                     \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 678\u001b[0;31m                     \u001b[0mtyp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmanager\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    679\u001b[0m                 )\n\u001b[1;32m    680\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36mndarray_to_mgr\u001b[0;34m(values, index, columns, dtype, copy, typ)\u001b[0m\n\u001b[1;32m    322\u001b[0m     )\n\u001b[1;32m    323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m     \u001b[0m_check_values_indices_shape_match\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtyp\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"array\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36m_check_values_indices_shape_match\u001b[0;34m(values, index, columns)\u001b[0m\n\u001b[1;32m    391\u001b[0m         \u001b[0mpassed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m         \u001b[0mimplied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 393\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Shape of passed values is {passed}, indices imply {implied}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Shape of passed values is (5, 5), indices imply (6, 6)"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix,accuracy_score\n",
        "import seaborn as sn\n",
        "\n",
        "print(classification_report(emo_test,abc))\n",
        "\n",
        "acc = float(accuracy_score(emo_test,abc))*100\n",
        "print(\"----accuracy score %s ----\" % acc)\n",
        "\n",
        "cm = confusion_matrix(emo_test,abc)\n",
        "#df_cm = pd.DataFrame(cm)\n",
        "class_names = ['neutral','calm', 'happy','sad','angry', 'fearful' ]\n",
        "df_cm = pd.DataFrame(cm, index=class_names, columns=class_names,)\n",
        "sn.heatmap(df_cm, annot=True, fmt='')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "59mA6uxedOYx"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "_original_augmation_Savee_400_epoch_12_kernal_size_and_bat2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}