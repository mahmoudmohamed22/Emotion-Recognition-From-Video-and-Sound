{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Augmanted_CNN_2_radvass&savee.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9SRCO-a_AlH5",
        "outputId": "2e98f7f7-a830-45fe-956e-6b51d5cbd738"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HJjcbxwy46bG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "04eb5d93-5436-4f2b-e807-f76f1d0ddc8b"
      },
      "source": [
        "# Orignial Notebook: https://github.com/MITESHPUTHRANNEU/Speech-Emotion-Analyzer/blob/master/final_results_gender_test.ipynb\n",
        "# This notebook author: Reza Chu\n",
        "# Last Editing Date: 31st May 2019\n",
        "\n",
        "## Python\n",
        "import os\n",
        "import random\n",
        "import sys\n",
        "\n",
        "import IPython\n",
        "from IPython.display import Audio\n",
        "from IPython.display import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "## Package\n",
        "import glob \n",
        "import keras\n",
        "import IPython.display as ipd\n",
        "import librosa\n",
        "import librosa.display\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import plotly.graph_objs as go\n",
        "import plotly.offline as py\n",
        "import plotly.tools as tls\n",
        "import seaborn as sns\n",
        "import scipy.io.wavfile\n",
        "import tensorflow as tf\n",
        "py.init_notebook_mode(connected=True)\n",
        "\n",
        "## Keras\n",
        "from keras import regularizers\n",
        "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping\n",
        "from keras.callbacks import  History, ReduceLROnPlateau, CSVLogger\n",
        "from keras.models import Model, Sequential\n",
        "from keras.layers import Dense, Embedding, LSTM\n",
        "from keras.layers import Input, Flatten, Dropout, Activation, BatchNormalization\n",
        "from keras.layers import Conv1D, MaxPooling1D, AveragePooling1D\n",
        "from keras.preprocessing import sequence\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.utils import np_utils\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "## Sklearn\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "## Rest\n",
        "from scipy.fftpack import fft\n",
        "from scipy import signal\n",
        "from scipy.io import wavfile\n",
        "from tqdm import tqdm\n",
        "\n",
        "input_duration=3\n",
        "# % pylab inline"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "        <script type=\"text/javascript\">\n",
              "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
              "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
              "        if (typeof require !== 'undefined') {\n",
              "        require.undef(\"plotly\");\n",
              "        requirejs.config({\n",
              "            paths: {\n",
              "                'plotly': ['https://cdn.plot.ly/plotly-2.8.3.min']\n",
              "            }\n",
              "        });\n",
              "        require(['plotly'], function(Plotly) {\n",
              "            window._Plotly = Plotly;\n",
              "        });\n",
              "        }\n",
              "        </script>\n",
              "        "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import os\n",
        "import librosa\n",
        "from librosa import display\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "path1 = '/content/drive/My Drive/data_set/RAVDESS_speech'\n",
        "path2 = '/content/drive/My Drive/data_set/RAVDESS_song'\n",
        "path3 = '/content/drive/My Drive/data_set/SAVEE'\n",
        "lst = []\n",
        "count=0\n",
        "start_time = time.time()\n",
        "\n",
        "for subdir, dirs, files in os.walk(path1):\n",
        "  for file in files:\n",
        "      try:\n",
        "        emo = int(file[7:8]) - 1 \n",
        "        if(emo==6 or emo==7):\n",
        "          continue\n",
        "        count +=1\n",
        "        #Load librosa array, obtain mfcss, store the file and the mcss information in a new array\n",
        "        X, sample_rate = librosa.load(os.path.join(subdir,file), res_type='kaiser_fast')\n",
        "        #mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T,axis=0) \n",
        "        # The instruction below converts the labels (from 1 to 8) to a series from 0 to 7\n",
        "        # This is because our predictor needs to start from 0 otherwise it will try to predict also 0.\n",
        "        arr =X, emo\n",
        "        lst.append(arr)\n",
        "      # If the file is not valid, skip it\n",
        "      except ValueError:\n",
        "        continue\n",
        "\n",
        "for subdir, dirs, files in os.walk(path2):\n",
        "  for file in files:\n",
        "      try:\n",
        "        count +=1\n",
        "        #Load librosa array, obtain mfcss, store the file and the mcss information in a new array\n",
        "        X, sample_rate = librosa.load(os.path.join(subdir,file), res_type='kaiser_fast')\n",
        "        #mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T,axis=0) \n",
        "        # The instruction below converts the labels (from 1 to 8) to a series from 0 to 7\n",
        "        # This is because our predictor needs to start from 0 otherwise it will try to predict also 0.\n",
        "        file = int(file[7:8]) - 1 \n",
        "        arr = X, file\n",
        "        lst.append(arr)\n",
        "      # If the file is not valid, skip it\n",
        "      except ValueError:\n",
        "        continue\n",
        "\n",
        "for subdir, dirs, files in os.walk(path3):\n",
        "  for file in files:\n",
        "      try:\n",
        "        #Load librosa array, obtain mfcss, store the file and the mcss information in a new array\n",
        "        \n",
        "        #mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T,axis=0) \n",
        "        \n",
        "        # The instruction below converts the labels (from 1 to 8) to a series from 0 to 7\n",
        "        # This is because our predictor needs to start from 0 otherwise it will try to predict also 0.\n",
        "        #file = int(file[7:8]) - 1 \n",
        "        #0 = neutral, 1 = calm, 2 = happy, 3 = sad, 4 = angry, 5 = fearful, 6 = disgust, 7 = surprised\n",
        "        if file.startswith('a'):\n",
        "            emotion=4\n",
        "        elif file.startswith('d'):\n",
        "            continue\n",
        "        elif file.startswith('f'):\n",
        "            emotion=5\n",
        "        elif file.startswith('h'):\n",
        "            emotion=2\n",
        "        elif file.startswith('n'):\n",
        "            emotion=0\n",
        "        elif file.startswith('sa'):\n",
        "            emotion=3\n",
        "        elif file.startswith('su'):\n",
        "            continue\n",
        "        else:\n",
        "            continue\n",
        "        count +=1\n",
        "        X, sample_rate = librosa.load(os.path.join(subdir,file), res_type='kaiser_fast')\n",
        "        arr = X, emotion\n",
        "        lst.append(arr)\n",
        "      # If the file is not valid, skip it\n",
        "      except ValueError:\n",
        "        continue\n",
        "\n",
        "print(\"--- Data loaded. Loading time: %s seconds ---\" % (time.time() - start_time))"
      ],
      "metadata": {
        "id": "-1eNUEyyPzeb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c8ca032-7997-41d6-d377-60b5c9f594a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Data loaded. Loading time: 560.1471893787384 seconds ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy.core.fromnumeric import size\n",
        "size(lst)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HMOH7d7mzHB7",
        "outputId": "59ab46f8-01f3-471a-f81e-08c43d27c636"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/core/fromnumeric.py:3208: VisibleDeprecationWarning:\n",
            "\n",
            "Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4856"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating X and y: zip makes a list of all the first elements, and a list of all the second elements.\n",
        "audio_file, emotion = zip(*lst)"
      ],
      "metadata": {
        "id": "QSTRDNOgHLr6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "audio_file=np.asarray(audio_file)\n",
        "emotion=np.asarray(emotion)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ong1QDBXHrvk",
        "outputId": "6e0ed553-4390-4ead-c415-7d2bedaf4c32"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: VisibleDeprecationWarning:\n",
            "\n",
            "Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "emotion.shape,audio_file.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2sUCtbfMztE5",
        "outputId": "c3577465-f802-4a68-b4e2-c31b3bc98720"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((2428,), (2428,))"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "signal_train, signal_test, emo_train, emo_test = train_test_split(audio_file,emotion, test_size=0.20, random_state=42)"
      ],
      "metadata": {
        "id": "62_CZk5SH_08"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "signal_valid, signal_test, emo_valid, emo_test = train_test_split(signal_test,emo_test, test_size=0.5,train_size=0.5, random_state=42)"
      ],
      "metadata": {
        "id": "3yaCr-AlIhEK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "signal_train.shape,signal_valid.shape,signal_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bmJZBOwkI58f",
        "outputId": "cd040fcd-3c45-4f14-f9da-fe74abad0126"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1942,), (243,), (243,))"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_valid=[]\n",
        "x_test=[]\n"
      ],
      "metadata": {
        "id": "4suaNiPyLgqh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(signal_valid.size):\n",
        "  x_valid.append(np.mean(librosa.feature.mfcc(y=signal_valid[i], sr=sample_rate, n_mfcc=40).T,axis=0))\n",
        "\n",
        "for i in range(signal_test.size):\n",
        "  x_test.append(np.mean(librosa.feature.mfcc(y=signal_test[i], sr=sample_rate, n_mfcc=40).T,axis=0))"
      ],
      "metadata": {
        "id": "cc-N9EM8KXlq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_valid=np.asarray(x_valid)\n",
        "x_test=np.asarray(x_test)"
      ],
      "metadata": {
        "id": "FjxfamKtNikQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_valid.shape,x_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2BEbwS0hNlvq",
        "outputId": "08125613-25d7-47f5-f1e8-f042aea77e08"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((243, 40), (243, 40))"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "train_lst=[]"
      ],
      "metadata": {
        "id": "LtvpT7lYRdL-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(signal_train.size):\n",
        "  emo=emo_train[i]\n",
        "  x=signal_train[i]\n",
        "  arr=x,emo\n",
        "  train_lst.append(arr)\n",
        "  x=librosa.effects.time_stretch(signal_train[i],0.5)\n",
        "  arr=x,emo\n",
        "  train_lst.append(arr)\n",
        "  x=librosa.effects.time_stretch(signal_train[i],1.5)\n",
        "  arr=x,emo\n",
        "  train_lst.append(arr)\n",
        "  x=librosa.effects.pitch_shift(signal_train[i],sample_rate,2)\n",
        "  arr=x,emo\n",
        "  train_lst.append(arr)"
      ],
      "metadata": {
        "id": "xf2odgMXQgOH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "signal, y_train = zip(*train_lst)"
      ],
      "metadata": {
        "id": "CMkZ_U0rZs0z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "signal=np.asarray(signal)\n",
        "y_train=np.asarray(y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IJbOKuiIaBxx",
        "outputId": "711733cf-d2d8-4019-ef9a-82b3e2b2aeaf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: VisibleDeprecationWarning:\n",
            "\n",
            "Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train=[]"
      ],
      "metadata": {
        "id": "iGuQyoqTaKzR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(signal.size):\n",
        "  x_train.append(np.mean(librosa.feature.mfcc(y=signal[i], sr=sample_rate, n_mfcc=40).T,axis=0))"
      ],
      "metadata": {
        "id": "Y_9_-pxcWjtj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train=np.asarray(x_train)"
      ],
      "metadata": {
        "id": "W-giRONHaPnr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TxH7IFawa__X",
        "outputId": "589751c0-e8cd-4f3f-ba35-7969aa6579ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7768, 40)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AvCXMuBobZAo",
        "outputId": "77d64f5f-bb6f-49f3-84f1-57baa06daade"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7768,)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#orignal\n",
        "import keras\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from keras.preprocessing import sequence\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from keras.layers import Input, Flatten, Dropout, Activation\n",
        "from keras.layers import Conv1D, MaxPooling1D\n",
        "from keras.models import Model\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.optimizers import schedules\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv1D(64, 5,padding='same', #classifier.add(Convolution2D(64, (3, 3), padding = 'same', input_shape = (128, 128, 3), activation = 'relu'))\n",
        "                 input_shape=(40,1)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.1))\n",
        "model.add(MaxPooling1D(pool_size=(4)))\n",
        "model.add(Conv1D(128, 5,padding='same',))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.1))\n",
        "model.add(MaxPooling1D(pool_size=(4)))\n",
        "model.add(Conv1D(256, 5,padding='same',))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.1))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(6))\n",
        "model.add(Activation('softmax'))\n",
        "lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n",
        "    initial_learning_rate=0.0001,\n",
        "    decay_steps=10000,\n",
        "    decay_rate=0.0)\n",
        "opt = keras.optimizers.SGD(learning_rate=lr_schedule)\n",
        "#opt = tf.keras.optimizers.RMSprop(lr=0.0001, rho=0.9, epsilon=1e-07, decay=0.0)\n",
        "#opt = tf.keras.optimizers.SGD(lr=0.001, momentum=0.0, decay=0.0, nesterov=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 234
        },
        "id": "g74fXWVAC4Cr",
        "outputId": "b0bedf98-5dd6-47db-eee5-ef445e5629fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-e75d63f46732>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mActivation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'softmax'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n\u001b[0m\u001b[1;32m     34\u001b[0m     \u001b[0minitial_learning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0001\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0mdecay_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'keras.optimizers' has no attribute 'schedules'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#adding new layer\n",
        "import keras\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from keras.preprocessing import sequence\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from keras.layers import Input, Flatten, Dropout, Activation\n",
        "from keras.layers import Conv1D, MaxPooling1D\n",
        "from keras.models import Model\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.optimizers import schedules\n",
        "\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv1D(64, 5,padding='same', #classifier.add(Convolution2D(64, (3, 3), padding = 'same', input_shape = (128, 128, 3), activation = 'relu'))\n",
        "                 input_shape=(40,1)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.1))\n",
        "model.add(MaxPooling1D(pool_size=(4)))\n",
        "model.add(Conv1D(128, 5,padding='same',))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(MaxPooling1D(pool_size=(4)))\n",
        "model.add(Conv1D(128, 5,padding='same',))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(MaxPooling1D(pool_size=(2)))\n",
        "model.add(Conv1D(256, 5,padding='same',))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.4))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(6))\n",
        "model.add(Activation('softmax'))\n",
        "opt = keras.optimizers.Adam(learning_rate=0.0001)\n",
        "#opt = tf.keras.optimizers.RMSprop(lr=0.0001, rho=0.9, epsilon=1e-07, decay=0.0)\n",
        "#opt = tf.keras.optimizers.SGD(lr=0.001, momentum=0.0, decay=0.0, nesterov=False)"
      ],
      "metadata": {
        "id": "gudVTxSh0_hK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#changing dropout\n",
        "import keras\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from keras.preprocessing import sequence\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from keras.layers import Input, Flatten, Dropout, Activation\n",
        "from keras.layers import Conv1D, MaxPooling1D\n",
        "from keras.models import Model\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.optimizers import schedules\n",
        "\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv1D(64, 5,padding='same', #classifier.add(Convolution2D(64, (3, 3), padding = 'same', input_shape = (128, 128, 3), activation = 'relu'))\n",
        "                 input_shape=(40,1)))\n",
        "model.add(Activation('sigmoid'))\n",
        "model.add(Dropout(0.1))\n",
        "model.add(MaxPooling1D(pool_size=(4)))\n",
        "model.add(Conv1D(128, 5,padding='same',))\n",
        "model.add(Activation('sigmoid'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(MaxPooling1D(pool_size=(4)))\n",
        "model.add(Conv1D(256, 5,padding='same',))\n",
        "model.add(Activation('sigmoid'))\n",
        "model.add(Dropout(0.4))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(6))\n",
        "model.add(Activation('softmax'))\n",
        "opt = keras.optimizers.Adam(learning_rate=0.0001)\n",
        "#opt = tf.keras.optimizers.RMSprop(lr=0.0001, rho=0.9, epsilon=1e-07, decay=0.0)\n",
        "#opt = tf.keras.optimizers.SGD(lr=0.001, momentum=0.0, decay=0.0, nesterov=False)"
      ],
      "metadata": {
        "id": "xXlmfjiQ04ha"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H6ukOxAGC_I4",
        "outputId": "0aa451fb-d8d5-40ef-e8ca-0917468bdc9f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d (Conv1D)             (None, 40, 64)            384       \n",
            "                                                                 \n",
            " activation (Activation)     (None, 40, 64)            0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 40, 64)            0         \n",
            "                                                                 \n",
            " max_pooling1d (MaxPooling1D  (None, 10, 64)           0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv1d_1 (Conv1D)           (None, 10, 128)           41088     \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 10, 128)           0         \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 10, 128)           0         \n",
            "                                                                 \n",
            " max_pooling1d_1 (MaxPooling  (None, 2, 128)           0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " conv1d_2 (Conv1D)           (None, 2, 128)            82048     \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 2, 128)            0         \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 2, 128)            0         \n",
            "                                                                 \n",
            " max_pooling1d_2 (MaxPooling  (None, 1, 128)           0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " conv1d_3 (Conv1D)           (None, 1, 256)            164096    \n",
            "                                                                 \n",
            " activation_3 (Activation)   (None, 1, 256)            0         \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 1, 256)            0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 256)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 6)                 1542      \n",
            "                                                                 \n",
            " activation_4 (Activation)   (None, 6)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 289,158\n",
            "Trainable params: 289,158\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='sparse_categorical_crossentropy',\n",
        "              optimizer=opt,\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "AbMlLNk4DCBM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnnhistory=model.fit(x_train, y_train, batch_size=16, epochs=500, validation_data=(x_valid, emo_valid))\n",
        "#cnnhistory=model.fit(x_traincnn, y_train, batch_size=16, epochs=700,validation_split=0.1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RI1v2AuADFhy",
        "outputId": "47cc83ce-4d94-4f1f-d9ec-eff6f5ef59ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "486/486 [==============================] - 12s 20ms/step - loss: 2.3910 - accuracy: 0.1813 - val_loss: 1.7761 - val_accuracy: 0.2263\n",
            "Epoch 2/500\n",
            "486/486 [==============================] - 8s 16ms/step - loss: 1.8147 - accuracy: 0.2008 - val_loss: 1.7424 - val_accuracy: 0.2593\n",
            "Epoch 3/500\n",
            "486/486 [==============================] - 8s 16ms/step - loss: 1.7649 - accuracy: 0.2258 - val_loss: 1.6956 - val_accuracy: 0.2551\n",
            "Epoch 4/500\n",
            "486/486 [==============================] - 8s 16ms/step - loss: 1.7312 - accuracy: 0.2433 - val_loss: 1.6503 - val_accuracy: 0.3045\n",
            "Epoch 5/500\n",
            "486/486 [==============================] - 8s 16ms/step - loss: 1.6819 - accuracy: 0.2716 - val_loss: 1.6323 - val_accuracy: 0.3128\n",
            "Epoch 6/500\n",
            "486/486 [==============================] - 8s 16ms/step - loss: 1.6487 - accuracy: 0.2877 - val_loss: 1.5902 - val_accuracy: 0.3004\n",
            "Epoch 7/500\n",
            "486/486 [==============================] - 8s 16ms/step - loss: 1.6099 - accuracy: 0.3048 - val_loss: 1.5323 - val_accuracy: 0.3457\n",
            "Epoch 8/500\n",
            "486/486 [==============================] - 8s 16ms/step - loss: 1.5755 - accuracy: 0.3257 - val_loss: 1.5168 - val_accuracy: 0.3374\n",
            "Epoch 9/500\n",
            "486/486 [==============================] - 8s 16ms/step - loss: 1.5456 - accuracy: 0.3431 - val_loss: 1.4747 - val_accuracy: 0.3951\n",
            "Epoch 10/500\n",
            "486/486 [==============================] - 8s 16ms/step - loss: 1.5126 - accuracy: 0.3572 - val_loss: 1.4660 - val_accuracy: 0.3909\n",
            "Epoch 11/500\n",
            "486/486 [==============================] - 8s 16ms/step - loss: 1.4950 - accuracy: 0.3617 - val_loss: 1.4469 - val_accuracy: 0.3868\n",
            "Epoch 12/500\n",
            "486/486 [==============================] - 9s 18ms/step - loss: 1.4676 - accuracy: 0.3800 - val_loss: 1.4153 - val_accuracy: 0.4198\n",
            "Epoch 13/500\n",
            "486/486 [==============================] - 8s 17ms/step - loss: 1.4466 - accuracy: 0.3880 - val_loss: 1.3913 - val_accuracy: 0.4115\n",
            "Epoch 14/500\n",
            "486/486 [==============================] - 8s 16ms/step - loss: 1.4291 - accuracy: 0.4063 - val_loss: 1.3506 - val_accuracy: 0.4486\n",
            "Epoch 15/500\n",
            "486/486 [==============================] - 8s 16ms/step - loss: 1.3915 - accuracy: 0.4189 - val_loss: 1.3231 - val_accuracy: 0.4527\n",
            "Epoch 16/500\n",
            "486/486 [==============================] - 8s 16ms/step - loss: 1.3634 - accuracy: 0.4271 - val_loss: 1.2893 - val_accuracy: 0.4774\n",
            "Epoch 17/500\n",
            "486/486 [==============================] - 8s 16ms/step - loss: 1.3408 - accuracy: 0.4480 - val_loss: 1.2507 - val_accuracy: 0.5021\n",
            "Epoch 18/500\n",
            "486/486 [==============================] - 8s 16ms/step - loss: 1.3040 - accuracy: 0.4618 - val_loss: 1.2249 - val_accuracy: 0.5144\n",
            "Epoch 19/500\n",
            "486/486 [==============================] - 8s 16ms/step - loss: 1.2659 - accuracy: 0.4754 - val_loss: 1.1899 - val_accuracy: 0.5185\n",
            "Epoch 20/500\n",
            "486/486 [==============================] - 8s 16ms/step - loss: 1.2364 - accuracy: 0.4985 - val_loss: 1.1737 - val_accuracy: 0.5556\n",
            "Epoch 21/500\n",
            "486/486 [==============================] - 8s 16ms/step - loss: 1.2148 - accuracy: 0.4968 - val_loss: 1.1176 - val_accuracy: 0.5802\n",
            "Epoch 22/500\n",
            "486/486 [==============================] - 8s 16ms/step - loss: 1.1841 - accuracy: 0.5129 - val_loss: 1.1030 - val_accuracy: 0.5926\n",
            "Epoch 23/500\n",
            "486/486 [==============================] - 8s 16ms/step - loss: 1.1623 - accuracy: 0.5299 - val_loss: 1.0633 - val_accuracy: 0.5885\n",
            "Epoch 24/500\n",
            "486/486 [==============================] - 8s 16ms/step - loss: 1.1373 - accuracy: 0.5303 - val_loss: 1.0468 - val_accuracy: 0.6214\n",
            "Epoch 25/500\n",
            "486/486 [==============================] - 8s 16ms/step - loss: 1.1223 - accuracy: 0.5351 - val_loss: 1.0405 - val_accuracy: 0.6132\n",
            "Epoch 26/500\n",
            "486/486 [==============================] - 8s 16ms/step - loss: 1.0958 - accuracy: 0.5481 - val_loss: 1.0102 - val_accuracy: 0.6008\n",
            "Epoch 27/500\n",
            "486/486 [==============================] - 8s 16ms/step - loss: 1.0775 - accuracy: 0.5633 - val_loss: 1.0083 - val_accuracy: 0.6132\n",
            "Epoch 28/500\n",
            "486/486 [==============================] - 8s 16ms/step - loss: 1.0659 - accuracy: 0.5664 - val_loss: 1.0029 - val_accuracy: 0.6132\n",
            "Epoch 29/500\n",
            "486/486 [==============================] - 8s 16ms/step - loss: 1.0457 - accuracy: 0.5747 - val_loss: 0.9724 - val_accuracy: 0.6337\n",
            "Epoch 30/500\n",
            "486/486 [==============================] - 8s 16ms/step - loss: 1.0271 - accuracy: 0.5803 - val_loss: 0.9542 - val_accuracy: 0.6379\n",
            "Epoch 31/500\n",
            "486/486 [==============================] - 8s 16ms/step - loss: 1.0096 - accuracy: 0.5839 - val_loss: 0.9333 - val_accuracy: 0.6255\n",
            "Epoch 32/500\n",
            "486/486 [==============================] - 9s 18ms/step - loss: 0.9966 - accuracy: 0.6016 - val_loss: 0.9288 - val_accuracy: 0.6214\n",
            "Epoch 33/500\n",
            "486/486 [==============================] - 9s 18ms/step - loss: 0.9709 - accuracy: 0.6058 - val_loss: 0.9324 - val_accuracy: 0.6214\n",
            "Epoch 34/500\n",
            "486/486 [==============================] - 8s 16ms/step - loss: 0.9592 - accuracy: 0.6097 - val_loss: 0.8957 - val_accuracy: 0.6543\n",
            "Epoch 35/500\n",
            "486/486 [==============================] - 8s 17ms/step - loss: 0.9496 - accuracy: 0.6098 - val_loss: 0.8861 - val_accuracy: 0.6584\n",
            "Epoch 36/500\n",
            "486/486 [==============================] - 8s 17ms/step - loss: 0.9471 - accuracy: 0.6162 - val_loss: 0.8750 - val_accuracy: 0.6626\n",
            "Epoch 37/500\n",
            "486/486 [==============================] - 8s 16ms/step - loss: 0.9203 - accuracy: 0.6245 - val_loss: 0.8633 - val_accuracy: 0.6626\n",
            "Epoch 38/500\n",
            "486/486 [==============================] - 8s 16ms/step - loss: 0.9040 - accuracy: 0.6311 - val_loss: 0.8431 - val_accuracy: 0.6955\n",
            "Epoch 39/500\n",
            "486/486 [==============================] - 8s 16ms/step - loss: 0.8904 - accuracy: 0.6403 - val_loss: 0.8492 - val_accuracy: 0.6708\n",
            "Epoch 40/500\n",
            "486/486 [==============================] - 8s 16ms/step - loss: 0.8798 - accuracy: 0.6460 - val_loss: 0.8015 - val_accuracy: 0.6749\n",
            "Epoch 41/500\n",
            "486/486 [==============================] - 8s 16ms/step - loss: 0.8834 - accuracy: 0.6402 - val_loss: 0.8008 - val_accuracy: 0.7119\n",
            "Epoch 42/500\n",
            "486/486 [==============================] - 8s 16ms/step - loss: 0.8663 - accuracy: 0.6531 - val_loss: 0.8058 - val_accuracy: 0.7037\n",
            "Epoch 43/500\n",
            "486/486 [==============================] - 8s 16ms/step - loss: 0.8445 - accuracy: 0.6571 - val_loss: 0.7804 - val_accuracy: 0.6955\n",
            "Epoch 44/500\n",
            "486/486 [==============================] - 8s 16ms/step - loss: 0.8392 - accuracy: 0.6565 - val_loss: 0.7846 - val_accuracy: 0.6955\n",
            "Epoch 45/500\n",
            "486/486 [==============================] - 8s 16ms/step - loss: 0.8268 - accuracy: 0.6689 - val_loss: 0.7710 - val_accuracy: 0.6914\n",
            "Epoch 46/500\n",
            "486/486 [==============================] - 8s 16ms/step - loss: 0.8091 - accuracy: 0.6716 - val_loss: 0.7580 - val_accuracy: 0.6955\n",
            "Epoch 47/500\n",
            "486/486 [==============================] - 8s 16ms/step - loss: 0.8021 - accuracy: 0.6712 - val_loss: 0.7668 - val_accuracy: 0.7119\n",
            "Epoch 48/500\n",
            "486/486 [==============================] - 8s 16ms/step - loss: 0.8064 - accuracy: 0.6707 - val_loss: 0.7997 - val_accuracy: 0.7037\n",
            "Epoch 49/500\n",
            "486/486 [==============================] - 8s 16ms/step - loss: 0.7932 - accuracy: 0.6787 - val_loss: 0.7444 - val_accuracy: 0.7325\n",
            "Epoch 50/500\n",
            "486/486 [==============================] - 8s 16ms/step - loss: 0.7699 - accuracy: 0.6887 - val_loss: 0.7351 - val_accuracy: 0.7243\n",
            "Epoch 51/500\n",
            "486/486 [==============================] - 8s 16ms/step - loss: 0.7795 - accuracy: 0.6822 - val_loss: 0.7413 - val_accuracy: 0.7243\n",
            "Epoch 52/500\n",
            "486/486 [==============================] - 8s 16ms/step - loss: 0.7497 - accuracy: 0.6932 - val_loss: 0.7445 - val_accuracy: 0.7119\n",
            "Epoch 53/500\n",
            "486/486 [==============================] - 8s 16ms/step - loss: 0.7504 - accuracy: 0.6945 - val_loss: 0.7167 - val_accuracy: 0.7366\n",
            "Epoch 54/500\n",
            "486/486 [==============================] - 8s 16ms/step - loss: 0.7580 - accuracy: 0.6881 - val_loss: 0.7258 - val_accuracy: 0.7202\n",
            "Epoch 55/500\n",
            "486/486 [==============================] - 8s 16ms/step - loss: 0.7330 - accuracy: 0.7025 - val_loss: 0.7065 - val_accuracy: 0.7366\n",
            "Epoch 56/500\n",
            "486/486 [==============================] - 8s 16ms/step - loss: 0.7292 - accuracy: 0.7085 - val_loss: 0.7206 - val_accuracy: 0.6996\n",
            "Epoch 57/500\n",
            "486/486 [==============================] - 8s 16ms/step - loss: 0.7148 - accuracy: 0.7128 - val_loss: 0.6812 - val_accuracy: 0.7407\n",
            "Epoch 58/500\n",
            "486/486 [==============================] - 8s 16ms/step - loss: 0.7141 - accuracy: 0.7185 - val_loss: 0.6809 - val_accuracy: 0.7243\n",
            "Epoch 59/500\n",
            "486/486 [==============================] - 8s 16ms/step - loss: 0.6988 - accuracy: 0.7138 - val_loss: 0.6818 - val_accuracy: 0.7325\n",
            "Epoch 60/500\n",
            "486/486 [==============================] - 8s 16ms/step - loss: 0.6929 - accuracy: 0.7210 - val_loss: 0.6814 - val_accuracy: 0.7325\n",
            "Epoch 61/500\n",
            "486/486 [==============================] - 8s 16ms/step - loss: 0.6880 - accuracy: 0.7244 - val_loss: 0.6679 - val_accuracy: 0.7325\n",
            "Epoch 62/500\n",
            "486/486 [==============================] - 8s 16ms/step - loss: 0.6796 - accuracy: 0.7261 - val_loss: 0.6682 - val_accuracy: 0.7325\n",
            "Epoch 63/500\n",
            "486/486 [==============================] - 8s 16ms/step - loss: 0.6812 - accuracy: 0.7300 - val_loss: 0.6714 - val_accuracy: 0.7407\n",
            "Epoch 64/500\n",
            "486/486 [==============================] - 8s 16ms/step - loss: 0.6679 - accuracy: 0.7353 - val_loss: 0.6680 - val_accuracy: 0.7202\n",
            "Epoch 65/500\n",
            "486/486 [==============================] - 8s 16ms/step - loss: 0.6681 - accuracy: 0.7374 - val_loss: 0.6585 - val_accuracy: 0.7325\n",
            "Epoch 66/500\n",
            "486/486 [==============================] - 8s 16ms/step - loss: 0.6573 - accuracy: 0.7344 - val_loss: 0.6600 - val_accuracy: 0.7490\n",
            "Epoch 67/500\n",
            "486/486 [==============================] - 8s 16ms/step - loss: 0.6528 - accuracy: 0.7445 - val_loss: 0.6672 - val_accuracy: 0.7449\n",
            "Epoch 68/500\n",
            "486/486 [==============================] - 8s 16ms/step - loss: 0.6311 - accuracy: 0.7506 - val_loss: 0.6634 - val_accuracy: 0.7407\n",
            "Epoch 69/500\n",
            "486/486 [==============================] - 8s 16ms/step - loss: 0.6414 - accuracy: 0.7425 - val_loss: 0.6454 - val_accuracy: 0.7490\n",
            "Epoch 70/500\n",
            "486/486 [==============================] - 8s 16ms/step - loss: 0.6269 - accuracy: 0.7546 - val_loss: 0.6709 - val_accuracy: 0.7407\n",
            "Epoch 71/500\n",
            "486/486 [==============================] - 8s 16ms/step - loss: 0.6329 - accuracy: 0.7467 - val_loss: 0.6285 - val_accuracy: 0.7531\n",
            "Epoch 72/500\n",
            "486/486 [==============================] - 8s 16ms/step - loss: 0.6221 - accuracy: 0.7537 - val_loss: 0.6499 - val_accuracy: 0.7531\n",
            "Epoch 73/500\n",
            "486/486 [==============================] - 8s 16ms/step - loss: 0.6061 - accuracy: 0.7585 - val_loss: 0.6217 - val_accuracy: 0.7695\n",
            "Epoch 74/500\n",
            "486/486 [==============================] - 8s 16ms/step - loss: 0.5970 - accuracy: 0.7600 - val_loss: 0.6412 - val_accuracy: 0.7490\n",
            "Epoch 75/500\n",
            "486/486 [==============================] - 8s 16ms/step - loss: 0.6021 - accuracy: 0.7611 - val_loss: 0.6296 - val_accuracy: 0.7819\n",
            "Epoch 76/500\n",
            "486/486 [==============================] - 8s 16ms/step - loss: 0.5923 - accuracy: 0.7622 - val_loss: 0.6259 - val_accuracy: 0.7654\n",
            "Epoch 77/500\n",
            "486/486 [==============================] - 8s 16ms/step - loss: 0.5942 - accuracy: 0.7626 - val_loss: 0.6255 - val_accuracy: 0.7572\n",
            "Epoch 78/500\n",
            "486/486 [==============================] - 8s 16ms/step - loss: 0.5848 - accuracy: 0.7734 - val_loss: 0.6099 - val_accuracy: 0.7860\n",
            "Epoch 79/500\n",
            "486/486 [==============================] - 8s 16ms/step - loss: 0.5802 - accuracy: 0.7756 - val_loss: 0.6332 - val_accuracy: 0.7737\n",
            "Epoch 80/500\n",
            "486/486 [==============================] - 8s 16ms/step - loss: 0.5869 - accuracy: 0.7714 - val_loss: 0.6216 - val_accuracy: 0.7737\n",
            "Epoch 81/500\n",
            "486/486 [==============================] - 8s 16ms/step - loss: 0.5754 - accuracy: 0.7723 - val_loss: 0.6029 - val_accuracy: 0.7737\n",
            "Epoch 82/500\n",
            "486/486 [==============================] - 8s 16ms/step - loss: 0.5678 - accuracy: 0.7769 - val_loss: 0.5784 - val_accuracy: 0.7819\n",
            "Epoch 83/500\n",
            "486/486 [==============================] - 8s 16ms/step - loss: 0.5631 - accuracy: 0.7757 - val_loss: 0.5961 - val_accuracy: 0.7572\n",
            "Epoch 84/500\n",
            "486/486 [==============================] - 8s 16ms/step - loss: 0.5479 - accuracy: 0.7822 - val_loss: 0.6168 - val_accuracy: 0.7613\n",
            "Epoch 85/500\n",
            "486/486 [==============================] - 8s 16ms/step - loss: 0.5566 - accuracy: 0.7791 - val_loss: 0.6008 - val_accuracy: 0.7737\n",
            "Epoch 86/500\n",
            "486/486 [==============================] - 8s 16ms/step - loss: 0.5466 - accuracy: 0.7822 - val_loss: 0.6035 - val_accuracy: 0.7737\n",
            "Epoch 87/500\n",
            "486/486 [==============================] - 8s 16ms/step - loss: 0.5371 - accuracy: 0.7886 - val_loss: 0.6147 - val_accuracy: 0.7695\n",
            "Epoch 88/500\n",
            "486/486 [==============================] - 8s 16ms/step - loss: 0.5445 - accuracy: 0.7836 - val_loss: 0.5867 - val_accuracy: 0.7695\n",
            "Epoch 89/500\n",
            "486/486 [==============================] - 8s 16ms/step - loss: 0.5381 - accuracy: 0.7866 - val_loss: 0.6078 - val_accuracy: 0.7654\n",
            "Epoch 90/500\n",
            "486/486 [==============================] - 8s 16ms/step - loss: 0.5265 - accuracy: 0.7898 - val_loss: 0.5924 - val_accuracy: 0.7819\n",
            "Epoch 91/500\n",
            "486/486 [==============================] - 8s 16ms/step - loss: 0.5112 - accuracy: 0.8016 - val_loss: 0.5996 - val_accuracy: 0.7737\n",
            "Epoch 92/500\n",
            "486/486 [==============================] - 8s 16ms/step - loss: 0.5221 - accuracy: 0.7913 - val_loss: 0.6058 - val_accuracy: 0.7737\n",
            "Epoch 93/500\n",
            "486/486 [==============================] - 8s 16ms/step - loss: 0.5093 - accuracy: 0.8033 - val_loss: 0.5690 - val_accuracy: 0.7860\n",
            "Epoch 94/500\n",
            "486/486 [==============================] - 8s 16ms/step - loss: 0.5122 - accuracy: 0.8039 - val_loss: 0.5879 - val_accuracy: 0.7778\n",
            "Epoch 95/500\n",
            "486/486 [==============================] - 8s 16ms/step - loss: 0.5135 - accuracy: 0.7967 - val_loss: 0.6051 - val_accuracy: 0.7901\n",
            "Epoch 96/500\n",
            "486/486 [==============================] - 8s 16ms/step - loss: 0.5025 - accuracy: 0.8048 - val_loss: 0.6076 - val_accuracy: 0.7778\n",
            "Epoch 97/500\n",
            "486/486 [==============================] - 8s 16ms/step - loss: 0.5009 - accuracy: 0.8005 - val_loss: 0.5721 - val_accuracy: 0.8066\n",
            "Epoch 98/500\n",
            "486/486 [==============================] - 8s 16ms/step - loss: 0.4989 - accuracy: 0.8114 - val_loss: 0.5802 - val_accuracy: 0.7984\n",
            "Epoch 99/500\n",
            "486/486 [==============================] - 8s 16ms/step - loss: 0.4905 - accuracy: 0.8061 - val_loss: 0.5831 - val_accuracy: 0.8025\n",
            "Epoch 100/500\n",
            "486/486 [==============================] - 8s 16ms/step - loss: 0.4894 - accuracy: 0.8101 - val_loss: 0.5588 - val_accuracy: 0.7984\n",
            "Epoch 101/500\n",
            "486/486 [==============================] - 8s 16ms/step - loss: 0.4795 - accuracy: 0.8106 - val_loss: 0.5889 - val_accuracy: 0.7984\n",
            "Epoch 102/500\n",
            "486/486 [==============================] - 8s 16ms/step - loss: 0.4811 - accuracy: 0.8153 - val_loss: 0.5646 - val_accuracy: 0.8148\n",
            "Epoch 103/500\n",
            "486/486 [==============================] - 8s 16ms/step - loss: 0.4773 - accuracy: 0.8162 - val_loss: 0.5743 - val_accuracy: 0.8025\n",
            "Epoch 104/500\n",
            "486/486 [==============================] - 8s 16ms/step - loss: 0.4645 - accuracy: 0.8203 - val_loss: 0.5742 - val_accuracy: 0.7984\n",
            "Epoch 105/500\n",
            "486/486 [==============================] - 8s 16ms/step - loss: 0.4704 - accuracy: 0.8169 - val_loss: 0.5773 - val_accuracy: 0.8189\n",
            "Epoch 106/500\n",
            "486/486 [==============================] - 8s 16ms/step - loss: 0.4837 - accuracy: 0.8083 - val_loss: 0.5579 - val_accuracy: 0.7901\n",
            "Epoch 107/500\n",
            "486/486 [==============================] - 8s 16ms/step - loss: 0.4632 - accuracy: 0.8243 - val_loss: 0.5824 - val_accuracy: 0.8148\n",
            "Epoch 108/500\n",
            "486/486 [==============================] - 8s 16ms/step - loss: 0.4647 - accuracy: 0.8220 - val_loss: 0.5932 - val_accuracy: 0.7654\n",
            "Epoch 109/500\n",
            "486/486 [==============================] - 8s 16ms/step - loss: 0.4639 - accuracy: 0.8207 - val_loss: 0.5714 - val_accuracy: 0.7901\n",
            "Epoch 110/500\n",
            "486/486 [==============================] - 8s 16ms/step - loss: 0.4501 - accuracy: 0.8254 - val_loss: 0.5616 - val_accuracy: 0.8025\n",
            "Epoch 111/500\n",
            "486/486 [==============================] - 8s 16ms/step - loss: 0.4506 - accuracy: 0.8263 - val_loss: 0.5927 - val_accuracy: 0.7942\n",
            "Epoch 112/500\n",
            "486/486 [==============================] - 8s 16ms/step - loss: 0.4470 - accuracy: 0.8252 - val_loss: 0.5624 - val_accuracy: 0.8025\n",
            "Epoch 113/500\n",
            "486/486 [==============================] - 8s 16ms/step - loss: 0.4365 - accuracy: 0.8288 - val_loss: 0.5671 - val_accuracy: 0.7942\n",
            "Epoch 114/500\n",
            "486/486 [==============================] - 8s 16ms/step - loss: 0.4479 - accuracy: 0.8252 - val_loss: 0.5494 - val_accuracy: 0.8189\n",
            "Epoch 115/500\n",
            "486/486 [==============================] - 8s 16ms/step - loss: 0.4427 - accuracy: 0.8294 - val_loss: 0.5527 - val_accuracy: 0.8025\n",
            "Epoch 116/500\n",
            "486/486 [==============================] - 8s 16ms/step - loss: 0.4385 - accuracy: 0.8324 - val_loss: 0.5654 - val_accuracy: 0.7737\n",
            "Epoch 117/500\n",
            "486/486 [==============================] - 8s 16ms/step - loss: 0.4325 - accuracy: 0.8320 - val_loss: 0.5594 - val_accuracy: 0.7860\n",
            "Epoch 118/500\n",
            "486/486 [==============================] - 8s 16ms/step - loss: 0.4392 - accuracy: 0.8325 - val_loss: 0.5729 - val_accuracy: 0.7860\n",
            "Epoch 119/500\n",
            "486/486 [==============================] - 8s 16ms/step - loss: 0.4307 - accuracy: 0.8355 - val_loss: 0.5695 - val_accuracy: 0.7819\n",
            "Epoch 120/500\n",
            "486/486 [==============================] - 8s 16ms/step - loss: 0.4096 - accuracy: 0.8453 - val_loss: 0.5432 - val_accuracy: 0.8148\n",
            "Epoch 121/500\n",
            "486/486 [==============================] - 8s 16ms/step - loss: 0.4090 - accuracy: 0.8423 - val_loss: 0.5669 - val_accuracy: 0.7984\n",
            "Epoch 122/500\n",
            "486/486 [==============================] - 8s 16ms/step - loss: 0.4168 - accuracy: 0.8390 - val_loss: 0.5728 - val_accuracy: 0.8066\n",
            "Epoch 123/500\n",
            "486/486 [==============================] - 8s 16ms/step - loss: 0.4154 - accuracy: 0.8396 - val_loss: 0.5917 - val_accuracy: 0.7819\n",
            "Epoch 124/500\n",
            "486/486 [==============================] - 8s 16ms/step - loss: 0.4123 - accuracy: 0.8423 - val_loss: 0.5624 - val_accuracy: 0.8066\n",
            "Epoch 125/500\n",
            "486/486 [==============================] - 8s 16ms/step - loss: 0.4083 - accuracy: 0.8428 - val_loss: 0.5666 - val_accuracy: 0.8066\n",
            "Epoch 126/500\n",
            "486/486 [==============================] - 8s 16ms/step - loss: 0.4036 - accuracy: 0.8478 - val_loss: 0.5466 - val_accuracy: 0.8066\n",
            "Epoch 127/500\n",
            "486/486 [==============================] - 8s 16ms/step - loss: 0.4068 - accuracy: 0.8455 - val_loss: 0.5506 - val_accuracy: 0.8066\n",
            "Epoch 128/500\n",
            "486/486 [==============================] - 8s 16ms/step - loss: 0.3916 - accuracy: 0.8539 - val_loss: 0.5607 - val_accuracy: 0.7860\n",
            "Epoch 129/500\n",
            "486/486 [==============================] - 8s 16ms/step - loss: 0.3968 - accuracy: 0.8467 - val_loss: 0.5555 - val_accuracy: 0.7942\n",
            "Epoch 130/500\n",
            "486/486 [==============================] - 8s 16ms/step - loss: 0.3992 - accuracy: 0.8484 - val_loss: 0.5965 - val_accuracy: 0.7901\n",
            "Epoch 131/500\n",
            "486/486 [==============================] - 8s 16ms/step - loss: 0.3873 - accuracy: 0.8509 - val_loss: 0.5811 - val_accuracy: 0.7984\n",
            "Epoch 132/500\n",
            "486/486 [==============================] - 8s 16ms/step - loss: 0.3936 - accuracy: 0.8473 - val_loss: 0.5597 - val_accuracy: 0.7778\n",
            "Epoch 133/500\n",
            "486/486 [==============================] - 8s 16ms/step - loss: 0.3804 - accuracy: 0.8540 - val_loss: 0.5453 - val_accuracy: 0.8189\n",
            "Epoch 134/500\n",
            "486/486 [==============================] - 8s 16ms/step - loss: 0.3849 - accuracy: 0.8531 - val_loss: 0.5516 - val_accuracy: 0.7984\n",
            "Epoch 135/500\n",
            "486/486 [==============================] - 8s 16ms/step - loss: 0.3842 - accuracy: 0.8513 - val_loss: 0.5266 - val_accuracy: 0.8107\n",
            "Epoch 136/500\n",
            "486/486 [==============================] - 8s 16ms/step - loss: 0.3749 - accuracy: 0.8565 - val_loss: 0.5661 - val_accuracy: 0.8107\n",
            "Epoch 137/500\n",
            "486/486 [==============================] - 8s 16ms/step - loss: 0.3869 - accuracy: 0.8568 - val_loss: 0.5453 - val_accuracy: 0.7942\n",
            "Epoch 138/500\n",
            "486/486 [==============================] - 8s 16ms/step - loss: 0.3693 - accuracy: 0.8584 - val_loss: 0.5555 - val_accuracy: 0.8107\n",
            "Epoch 139/500\n",
            "486/486 [==============================] - 8s 16ms/step - loss: 0.3681 - accuracy: 0.8565 - val_loss: 0.5428 - val_accuracy: 0.8189\n",
            "Epoch 140/500\n",
            "486/486 [==============================] - 8s 16ms/step - loss: 0.3745 - accuracy: 0.8545 - val_loss: 0.5483 - val_accuracy: 0.8025\n",
            "Epoch 141/500\n",
            "486/486 [==============================] - 8s 16ms/step - loss: 0.3647 - accuracy: 0.8594 - val_loss: 0.5632 - val_accuracy: 0.7901\n",
            "Epoch 142/500\n",
            "486/486 [==============================] - 8s 16ms/step - loss: 0.3624 - accuracy: 0.8601 - val_loss: 0.5576 - val_accuracy: 0.8025\n",
            "Epoch 143/500\n",
            "486/486 [==============================] - 8s 16ms/step - loss: 0.3652 - accuracy: 0.8594 - val_loss: 0.5418 - val_accuracy: 0.8354\n",
            "Epoch 144/500\n",
            "486/486 [==============================] - 8s 16ms/step - loss: 0.3761 - accuracy: 0.8534 - val_loss: 0.6107 - val_accuracy: 0.8025\n",
            "Epoch 145/500\n",
            "486/486 [==============================] - 8s 16ms/step - loss: 0.3554 - accuracy: 0.8682 - val_loss: 0.5626 - val_accuracy: 0.8066\n",
            "Epoch 146/500\n",
            "486/486 [==============================] - 8s 16ms/step - loss: 0.3732 - accuracy: 0.8550 - val_loss: 0.5499 - val_accuracy: 0.8107\n",
            "Epoch 147/500\n",
            "486/486 [==============================] - 8s 17ms/step - loss: 0.3463 - accuracy: 0.8701 - val_loss: 0.5821 - val_accuracy: 0.7942\n",
            "Epoch 148/500\n",
            "486/486 [==============================] - 8s 16ms/step - loss: 0.3452 - accuracy: 0.8702 - val_loss: 0.5569 - val_accuracy: 0.8066\n",
            "Epoch 149/500\n",
            "486/486 [==============================] - 8s 16ms/step - loss: 0.3584 - accuracy: 0.8677 - val_loss: 0.5296 - val_accuracy: 0.8230\n",
            "Epoch 150/500\n",
            "486/486 [==============================] - 8s 16ms/step - loss: 0.3520 - accuracy: 0.8660 - val_loss: 0.5459 - val_accuracy: 0.7901\n",
            "Epoch 151/500\n",
            "486/486 [==============================] - 8s 16ms/step - loss: 0.3529 - accuracy: 0.8675 - val_loss: 0.5418 - val_accuracy: 0.8148\n",
            "Epoch 152/500\n",
            "486/486 [==============================] - 8s 16ms/step - loss: 0.3453 - accuracy: 0.8691 - val_loss: 0.5492 - val_accuracy: 0.7901\n",
            "Epoch 153/500\n",
            "486/486 [==============================] - 8s 16ms/step - loss: 0.3379 - accuracy: 0.8737 - val_loss: 0.5459 - val_accuracy: 0.8230\n",
            "Epoch 154/500\n",
            "486/486 [==============================] - 8s 16ms/step - loss: 0.3456 - accuracy: 0.8722 - val_loss: 0.5521 - val_accuracy: 0.8189\n",
            "Epoch 155/500\n",
            "486/486 [==============================] - 8s 16ms/step - loss: 0.3464 - accuracy: 0.8688 - val_loss: 0.5603 - val_accuracy: 0.7901\n",
            "Epoch 156/500\n",
            "486/486 [==============================] - 8s 16ms/step - loss: 0.3357 - accuracy: 0.8747 - val_loss: 0.5315 - val_accuracy: 0.7984\n",
            "Epoch 157/500\n",
            "486/486 [==============================] - 8s 16ms/step - loss: 0.3332 - accuracy: 0.8756 - val_loss: 0.5595 - val_accuracy: 0.8025\n",
            "Epoch 158/500\n",
            "486/486 [==============================] - 8s 16ms/step - loss: 0.3400 - accuracy: 0.8726 - val_loss: 0.5859 - val_accuracy: 0.7984\n",
            "Epoch 159/500\n",
            "486/486 [==============================] - 8s 16ms/step - loss: 0.3366 - accuracy: 0.8737 - val_loss: 0.5534 - val_accuracy: 0.8148\n",
            "Epoch 160/500\n",
            "486/486 [==============================] - 8s 16ms/step - loss: 0.3363 - accuracy: 0.8727 - val_loss: 0.5402 - val_accuracy: 0.8025\n",
            "Epoch 161/500\n",
            "486/486 [==============================] - 8s 16ms/step - loss: 0.3380 - accuracy: 0.8728 - val_loss: 0.5814 - val_accuracy: 0.7860\n",
            "Epoch 162/500\n",
            "486/486 [==============================] - 8s 16ms/step - loss: 0.3347 - accuracy: 0.8724 - val_loss: 0.5635 - val_accuracy: 0.8272\n",
            "Epoch 163/500\n",
            "486/486 [==============================] - 8s 16ms/step - loss: 0.3254 - accuracy: 0.8814 - val_loss: 0.5597 - val_accuracy: 0.8025\n",
            "Epoch 164/500\n",
            "486/486 [==============================] - 8s 16ms/step - loss: 0.3311 - accuracy: 0.8754 - val_loss: 0.5269 - val_accuracy: 0.8107\n",
            "Epoch 165/500\n",
            "486/486 [==============================] - 8s 16ms/step - loss: 0.3030 - accuracy: 0.8883 - val_loss: 0.5263 - val_accuracy: 0.8025\n",
            "Epoch 166/500\n",
            "486/486 [==============================] - 8s 16ms/step - loss: 0.3268 - accuracy: 0.8737 - val_loss: 0.5327 - val_accuracy: 0.8148\n",
            "Epoch 167/500\n",
            "486/486 [==============================] - 8s 16ms/step - loss: 0.3162 - accuracy: 0.8820 - val_loss: 0.5633 - val_accuracy: 0.8272\n",
            "Epoch 168/500\n",
            "486/486 [==============================] - 8s 16ms/step - loss: 0.3164 - accuracy: 0.8807 - val_loss: 0.5449 - val_accuracy: 0.8189\n",
            "Epoch 169/500\n",
            "486/486 [==============================] - 8s 16ms/step - loss: 0.3168 - accuracy: 0.8782 - val_loss: 0.5442 - val_accuracy: 0.8148\n",
            "Epoch 170/500\n",
            "486/486 [==============================] - 8s 16ms/step - loss: 0.3175 - accuracy: 0.8801 - val_loss: 0.5487 - val_accuracy: 0.8107\n",
            "Epoch 171/500\n",
            "486/486 [==============================] - 8s 16ms/step - loss: 0.3213 - accuracy: 0.8807 - val_loss: 0.5861 - val_accuracy: 0.8148\n",
            "Epoch 172/500\n",
            "486/486 [==============================] - 8s 16ms/step - loss: 0.3106 - accuracy: 0.8850 - val_loss: 0.5668 - val_accuracy: 0.8230\n",
            "Epoch 173/500\n",
            "486/486 [==============================] - 8s 16ms/step - loss: 0.3024 - accuracy: 0.8880 - val_loss: 0.6159 - val_accuracy: 0.8066\n",
            "Epoch 174/500\n",
            "486/486 [==============================] - 8s 16ms/step - loss: 0.3189 - accuracy: 0.8817 - val_loss: 0.5819 - val_accuracy: 0.8025\n",
            "Epoch 175/500\n",
            "486/486 [==============================] - 8s 16ms/step - loss: 0.3133 - accuracy: 0.8796 - val_loss: 0.5558 - val_accuracy: 0.8107\n",
            "Epoch 176/500\n",
            "486/486 [==============================] - 8s 16ms/step - loss: 0.3067 - accuracy: 0.8853 - val_loss: 0.5216 - val_accuracy: 0.8477\n",
            "Epoch 177/500\n",
            "486/486 [==============================] - 8s 16ms/step - loss: 0.3049 - accuracy: 0.8840 - val_loss: 0.5345 - val_accuracy: 0.8148\n",
            "Epoch 178/500\n",
            "486/486 [==============================] - 8s 16ms/step - loss: 0.3121 - accuracy: 0.8836 - val_loss: 0.5537 - val_accuracy: 0.8313\n",
            "Epoch 179/500\n",
            "486/486 [==============================] - 8s 16ms/step - loss: 0.3020 - accuracy: 0.8849 - val_loss: 0.5635 - val_accuracy: 0.8025\n",
            "Epoch 180/500\n",
            "486/486 [==============================] - 8s 17ms/step - loss: 0.3048 - accuracy: 0.8850 - val_loss: 0.5575 - val_accuracy: 0.8230\n",
            "Epoch 181/500\n",
            "486/486 [==============================] - 8s 16ms/step - loss: 0.2908 - accuracy: 0.8948 - val_loss: 0.5795 - val_accuracy: 0.8025\n",
            "Epoch 182/500\n",
            "486/486 [==============================] - 8s 16ms/step - loss: 0.2942 - accuracy: 0.8913 - val_loss: 0.5583 - val_accuracy: 0.8148\n",
            "Epoch 183/500\n",
            "486/486 [==============================] - 8s 16ms/step - loss: 0.3038 - accuracy: 0.8854 - val_loss: 0.5326 - val_accuracy: 0.8148\n",
            "Epoch 184/500\n",
            "486/486 [==============================] - 8s 16ms/step - loss: 0.3113 - accuracy: 0.8862 - val_loss: 0.5280 - val_accuracy: 0.8354\n",
            "Epoch 185/500\n",
            "486/486 [==============================] - 8s 16ms/step - loss: 0.2961 - accuracy: 0.8862 - val_loss: 0.5146 - val_accuracy: 0.8148\n",
            "Epoch 186/500\n",
            "486/486 [==============================] - 8s 16ms/step - loss: 0.2882 - accuracy: 0.8961 - val_loss: 0.5705 - val_accuracy: 0.8025\n",
            "Epoch 187/500\n",
            "486/486 [==============================] - 8s 16ms/step - loss: 0.2926 - accuracy: 0.8895 - val_loss: 0.5693 - val_accuracy: 0.8107\n",
            "Epoch 188/500\n",
            "486/486 [==============================] - 8s 16ms/step - loss: 0.2916 - accuracy: 0.8890 - val_loss: 0.5438 - val_accuracy: 0.8272\n",
            "Epoch 189/500\n",
            "486/486 [==============================] - 8s 16ms/step - loss: 0.3031 - accuracy: 0.8844 - val_loss: 0.5600 - val_accuracy: 0.8230\n",
            "Epoch 190/500\n",
            "486/486 [==============================] - 8s 16ms/step - loss: 0.2880 - accuracy: 0.8930 - val_loss: 0.5471 - val_accuracy: 0.8189\n",
            "Epoch 191/500\n",
            "486/486 [==============================] - 8s 16ms/step - loss: 0.3024 - accuracy: 0.8893 - val_loss: 0.5258 - val_accuracy: 0.8395\n",
            "Epoch 192/500\n",
            "486/486 [==============================] - 8s 16ms/step - loss: 0.2861 - accuracy: 0.8920 - val_loss: 0.5514 - val_accuracy: 0.8272\n",
            "Epoch 193/500\n",
            "486/486 [==============================] - 8s 16ms/step - loss: 0.2790 - accuracy: 0.8939 - val_loss: 0.5647 - val_accuracy: 0.8107\n",
            "Epoch 194/500\n",
            "486/486 [==============================] - 8s 16ms/step - loss: 0.2803 - accuracy: 0.8938 - val_loss: 0.5279 - val_accuracy: 0.8230\n",
            "Epoch 195/500\n",
            "486/486 [==============================] - 8s 16ms/step - loss: 0.2860 - accuracy: 0.8939 - val_loss: 0.5288 - val_accuracy: 0.8313\n",
            "Epoch 196/500\n",
            "486/486 [==============================] - 8s 16ms/step - loss: 0.2886 - accuracy: 0.8937 - val_loss: 0.5560 - val_accuracy: 0.8148\n",
            "Epoch 197/500\n",
            "486/486 [==============================] - 8s 16ms/step - loss: 0.2809 - accuracy: 0.9004 - val_loss: 0.5343 - val_accuracy: 0.8148\n",
            "Epoch 198/500\n",
            "486/486 [==============================] - 8s 16ms/step - loss: 0.2748 - accuracy: 0.8998 - val_loss: 0.5599 - val_accuracy: 0.8230\n",
            "Epoch 199/500\n",
            "486/486 [==============================] - 8s 16ms/step - loss: 0.2684 - accuracy: 0.8995 - val_loss: 0.5489 - val_accuracy: 0.8189\n",
            "Epoch 200/500\n",
            "486/486 [==============================] - 8s 16ms/step - loss: 0.2736 - accuracy: 0.8975 - val_loss: 0.5439 - val_accuracy: 0.8230\n",
            "Epoch 201/500\n",
            "486/486 [==============================] - 8s 16ms/step - loss: 0.2856 - accuracy: 0.8929 - val_loss: 0.5492 - val_accuracy: 0.8107\n",
            "Epoch 202/500\n",
            "486/486 [==============================] - 8s 16ms/step - loss: 0.2640 - accuracy: 0.9016 - val_loss: 0.5411 - val_accuracy: 0.8272\n",
            "Epoch 203/500\n",
            "486/486 [==============================] - 8s 16ms/step - loss: 0.2775 - accuracy: 0.8995 - val_loss: 0.5804 - val_accuracy: 0.8230\n",
            "Epoch 204/500\n",
            "486/486 [==============================] - 8s 16ms/step - loss: 0.2708 - accuracy: 0.8986 - val_loss: 0.5486 - val_accuracy: 0.8189\n",
            "Epoch 205/500\n",
            "486/486 [==============================] - 8s 16ms/step - loss: 0.2695 - accuracy: 0.9025 - val_loss: 0.5572 - val_accuracy: 0.8189\n",
            "Epoch 206/500\n",
            "486/486 [==============================] - 8s 16ms/step - loss: 0.2630 - accuracy: 0.9004 - val_loss: 0.5672 - val_accuracy: 0.8066\n",
            "Epoch 207/500\n",
            "486/486 [==============================] - 8s 16ms/step - loss: 0.2678 - accuracy: 0.9044 - val_loss: 0.5681 - val_accuracy: 0.8272\n",
            "Epoch 208/500\n",
            "486/486 [==============================] - 8s 16ms/step - loss: 0.2775 - accuracy: 0.8966 - val_loss: 0.5476 - val_accuracy: 0.8107\n",
            "Epoch 209/500\n",
            "486/486 [==============================] - 8s 16ms/step - loss: 0.2637 - accuracy: 0.9004 - val_loss: 0.5983 - val_accuracy: 0.8025\n",
            "Epoch 210/500\n",
            "486/486 [==============================] - 8s 16ms/step - loss: 0.2667 - accuracy: 0.9015 - val_loss: 0.5660 - val_accuracy: 0.7984\n",
            "Epoch 211/500\n",
            "486/486 [==============================] - 8s 16ms/step - loss: 0.2796 - accuracy: 0.8978 - val_loss: 0.5423 - val_accuracy: 0.8230\n",
            "Epoch 212/500\n",
            "486/486 [==============================] - 8s 17ms/step - loss: 0.2724 - accuracy: 0.8988 - val_loss: 0.5570 - val_accuracy: 0.8189\n",
            "Epoch 213/500\n",
            "486/486 [==============================] - 8s 17ms/step - loss: 0.2546 - accuracy: 0.9067 - val_loss: 0.5403 - val_accuracy: 0.8354\n",
            "Epoch 214/500\n",
            "486/486 [==============================] - 8s 17ms/step - loss: 0.2585 - accuracy: 0.9035 - val_loss: 0.5489 - val_accuracy: 0.8230\n",
            "Epoch 215/500\n",
            "486/486 [==============================] - 8s 16ms/step - loss: 0.2571 - accuracy: 0.9051 - val_loss: 0.5320 - val_accuracy: 0.8107\n",
            "Epoch 216/500\n",
            "486/486 [==============================] - 8s 17ms/step - loss: 0.2580 - accuracy: 0.9086 - val_loss: 0.5386 - val_accuracy: 0.8189\n",
            "Epoch 217/500\n",
            "486/486 [==============================] - 8s 16ms/step - loss: 0.2480 - accuracy: 0.9056 - val_loss: 0.5938 - val_accuracy: 0.7942\n",
            "Epoch 218/500\n",
            "486/486 [==============================] - 8s 16ms/step - loss: 0.2547 - accuracy: 0.9074 - val_loss: 0.5435 - val_accuracy: 0.8066\n",
            "Epoch 219/500\n",
            "486/486 [==============================] - 8s 17ms/step - loss: 0.2594 - accuracy: 0.9059 - val_loss: 0.5448 - val_accuracy: 0.8189\n",
            "Epoch 220/500\n",
            "486/486 [==============================] - 8s 17ms/step - loss: 0.2477 - accuracy: 0.9044 - val_loss: 0.5992 - val_accuracy: 0.8148\n",
            "Epoch 221/500\n",
            "486/486 [==============================] - 8s 17ms/step - loss: 0.2677 - accuracy: 0.8980 - val_loss: 0.5729 - val_accuracy: 0.8313\n",
            "Epoch 222/500\n",
            "486/486 [==============================] - 8s 16ms/step - loss: 0.2492 - accuracy: 0.9054 - val_loss: 0.5874 - val_accuracy: 0.8107\n",
            "Epoch 223/500\n",
            "486/486 [==============================] - 8s 16ms/step - loss: 0.2505 - accuracy: 0.9092 - val_loss: 0.5738 - val_accuracy: 0.7984\n",
            "Epoch 224/500\n",
            "486/486 [==============================] - 8s 17ms/step - loss: 0.2445 - accuracy: 0.9127 - val_loss: 0.5588 - val_accuracy: 0.8148\n",
            "Epoch 225/500\n",
            "486/486 [==============================] - 8s 17ms/step - loss: 0.2543 - accuracy: 0.9055 - val_loss: 0.5964 - val_accuracy: 0.8148\n",
            "Epoch 226/500\n",
            "486/486 [==============================] - 8s 17ms/step - loss: 0.2623 - accuracy: 0.9072 - val_loss: 0.6204 - val_accuracy: 0.8025\n",
            "Epoch 227/500\n",
            "486/486 [==============================] - 8s 17ms/step - loss: 0.2582 - accuracy: 0.9054 - val_loss: 0.5323 - val_accuracy: 0.8230\n",
            "Epoch 228/500\n",
            "486/486 [==============================] - 8s 17ms/step - loss: 0.2582 - accuracy: 0.9076 - val_loss: 0.5060 - val_accuracy: 0.8272\n",
            "Epoch 229/500\n",
            "486/486 [==============================] - 8s 17ms/step - loss: 0.2458 - accuracy: 0.9059 - val_loss: 0.6248 - val_accuracy: 0.7942\n",
            "Epoch 230/500\n",
            "486/486 [==============================] - 8s 17ms/step - loss: 0.2428 - accuracy: 0.9121 - val_loss: 0.5024 - val_accuracy: 0.8066\n",
            "Epoch 231/500\n",
            "486/486 [==============================] - 8s 16ms/step - loss: 0.2602 - accuracy: 0.9024 - val_loss: 0.5469 - val_accuracy: 0.8189\n",
            "Epoch 232/500\n",
            "486/486 [==============================] - 8s 17ms/step - loss: 0.2372 - accuracy: 0.9095 - val_loss: 0.5417 - val_accuracy: 0.8189\n",
            "Epoch 233/500\n",
            "486/486 [==============================] - 8s 17ms/step - loss: 0.2537 - accuracy: 0.9078 - val_loss: 0.5477 - val_accuracy: 0.8148\n",
            "Epoch 234/500\n",
            "486/486 [==============================] - 8s 17ms/step - loss: 0.2352 - accuracy: 0.9130 - val_loss: 0.5823 - val_accuracy: 0.8189\n",
            "Epoch 235/500\n",
            "486/486 [==============================] - 8s 17ms/step - loss: 0.2477 - accuracy: 0.9087 - val_loss: 0.5290 - val_accuracy: 0.8189\n",
            "Epoch 236/500\n",
            "486/486 [==============================] - 8s 17ms/step - loss: 0.2552 - accuracy: 0.9058 - val_loss: 0.5747 - val_accuracy: 0.8148\n",
            "Epoch 237/500\n",
            "486/486 [==============================] - 8s 17ms/step - loss: 0.2539 - accuracy: 0.9060 - val_loss: 0.5838 - val_accuracy: 0.8189\n",
            "Epoch 238/500\n",
            "486/486 [==============================] - 8s 16ms/step - loss: 0.2425 - accuracy: 0.9109 - val_loss: 0.5938 - val_accuracy: 0.8107\n",
            "Epoch 239/500\n",
            "486/486 [==============================] - 8s 17ms/step - loss: 0.2452 - accuracy: 0.9100 - val_loss: 0.5858 - val_accuracy: 0.8107\n",
            "Epoch 240/500\n",
            "486/486 [==============================] - 9s 18ms/step - loss: 0.2376 - accuracy: 0.9157 - val_loss: 0.5297 - val_accuracy: 0.8230\n",
            "Epoch 241/500\n",
            "486/486 [==============================] - 8s 17ms/step - loss: 0.2288 - accuracy: 0.9165 - val_loss: 0.5657 - val_accuracy: 0.8189\n",
            "Epoch 242/500\n",
            "486/486 [==============================] - 8s 17ms/step - loss: 0.2402 - accuracy: 0.9143 - val_loss: 0.5753 - val_accuracy: 0.8272\n",
            "Epoch 243/500\n",
            "486/486 [==============================] - 9s 18ms/step - loss: 0.2266 - accuracy: 0.9171 - val_loss: 0.5520 - val_accuracy: 0.8354\n",
            "Epoch 244/500\n",
            "486/486 [==============================] - 8s 17ms/step - loss: 0.2363 - accuracy: 0.9126 - val_loss: 0.6242 - val_accuracy: 0.8025\n",
            "Epoch 245/500\n",
            "486/486 [==============================] - 12s 25ms/step - loss: 0.2324 - accuracy: 0.9134 - val_loss: 0.5638 - val_accuracy: 0.8189\n",
            "Epoch 246/500\n",
            "486/486 [==============================] - 9s 18ms/step - loss: 0.2265 - accuracy: 0.9134 - val_loss: 0.5632 - val_accuracy: 0.8272\n",
            "Epoch 247/500\n",
            "486/486 [==============================] - 8s 17ms/step - loss: 0.2305 - accuracy: 0.9150 - val_loss: 0.5286 - val_accuracy: 0.8272\n",
            "Epoch 248/500\n",
            "486/486 [==============================] - 8s 17ms/step - loss: 0.2307 - accuracy: 0.9153 - val_loss: 0.5421 - val_accuracy: 0.8272\n",
            "Epoch 249/500\n",
            "486/486 [==============================] - 8s 17ms/step - loss: 0.2414 - accuracy: 0.9092 - val_loss: 0.5644 - val_accuracy: 0.8189\n",
            "Epoch 250/500\n",
            "486/486 [==============================] - 8s 17ms/step - loss: 0.2282 - accuracy: 0.9171 - val_loss: 0.5888 - val_accuracy: 0.8230\n",
            "Epoch 251/500\n",
            "486/486 [==============================] - 8s 17ms/step - loss: 0.2175 - accuracy: 0.9211 - val_loss: 0.5565 - val_accuracy: 0.8025\n",
            "Epoch 252/500\n",
            "486/486 [==============================] - 9s 18ms/step - loss: 0.2330 - accuracy: 0.9140 - val_loss: 0.5852 - val_accuracy: 0.8313\n",
            "Epoch 253/500\n",
            "486/486 [==============================] - 8s 17ms/step - loss: 0.2326 - accuracy: 0.9174 - val_loss: 0.6017 - val_accuracy: 0.8066\n",
            "Epoch 254/500\n",
            "486/486 [==============================] - 8s 17ms/step - loss: 0.2290 - accuracy: 0.9141 - val_loss: 0.5717 - val_accuracy: 0.8066\n",
            "Epoch 255/500\n",
            "486/486 [==============================] - 8s 17ms/step - loss: 0.2239 - accuracy: 0.9181 - val_loss: 0.5823 - val_accuracy: 0.8066\n",
            "Epoch 256/500\n",
            "486/486 [==============================] - 9s 18ms/step - loss: 0.2273 - accuracy: 0.9177 - val_loss: 0.5840 - val_accuracy: 0.8148\n",
            "Epoch 257/500\n",
            "486/486 [==============================] - 8s 17ms/step - loss: 0.2288 - accuracy: 0.9153 - val_loss: 0.5239 - val_accuracy: 0.8395\n",
            "Epoch 258/500\n",
            "486/486 [==============================] - 11s 22ms/step - loss: 0.2263 - accuracy: 0.9188 - val_loss: 0.5895 - val_accuracy: 0.8066\n",
            "Epoch 259/500\n",
            "486/486 [==============================] - 9s 18ms/step - loss: 0.2235 - accuracy: 0.9143 - val_loss: 0.5242 - val_accuracy: 0.8313\n",
            "Epoch 260/500\n",
            "486/486 [==============================] - 9s 18ms/step - loss: 0.2326 - accuracy: 0.9148 - val_loss: 0.5578 - val_accuracy: 0.8230\n",
            "Epoch 261/500\n",
            "486/486 [==============================] - 8s 17ms/step - loss: 0.2136 - accuracy: 0.9228 - val_loss: 0.5348 - val_accuracy: 0.8313\n",
            "Epoch 262/500\n",
            "486/486 [==============================] - 8s 17ms/step - loss: 0.2294 - accuracy: 0.9126 - val_loss: 0.5202 - val_accuracy: 0.8477\n",
            "Epoch 263/500\n",
            "486/486 [==============================] - 8s 17ms/step - loss: 0.2192 - accuracy: 0.9193 - val_loss: 0.5677 - val_accuracy: 0.8230\n",
            "Epoch 264/500\n",
            "486/486 [==============================] - 8s 17ms/step - loss: 0.2256 - accuracy: 0.9190 - val_loss: 0.5689 - val_accuracy: 0.8230\n",
            "Epoch 265/500\n",
            "486/486 [==============================] - 9s 18ms/step - loss: 0.2232 - accuracy: 0.9203 - val_loss: 0.5630 - val_accuracy: 0.8272\n",
            "Epoch 266/500\n",
            "486/486 [==============================] - 8s 17ms/step - loss: 0.2239 - accuracy: 0.9193 - val_loss: 0.5883 - val_accuracy: 0.8230\n",
            "Epoch 267/500\n",
            "486/486 [==============================] - 8s 17ms/step - loss: 0.2191 - accuracy: 0.9229 - val_loss: 0.5836 - val_accuracy: 0.8189\n",
            "Epoch 268/500\n",
            "486/486 [==============================] - 8s 17ms/step - loss: 0.2176 - accuracy: 0.9222 - val_loss: 0.5901 - val_accuracy: 0.8107\n",
            "Epoch 269/500\n",
            "486/486 [==============================] - 8s 17ms/step - loss: 0.2006 - accuracy: 0.9270 - val_loss: 0.5661 - val_accuracy: 0.8313\n",
            "Epoch 270/500\n",
            "486/486 [==============================] - 8s 17ms/step - loss: 0.2326 - accuracy: 0.9189 - val_loss: 0.5167 - val_accuracy: 0.8272\n",
            "Epoch 271/500\n",
            "486/486 [==============================] - 8s 17ms/step - loss: 0.2191 - accuracy: 0.9174 - val_loss: 0.5642 - val_accuracy: 0.8272\n",
            "Epoch 272/500\n",
            "486/486 [==============================] - 8s 17ms/step - loss: 0.2189 - accuracy: 0.9207 - val_loss: 0.5462 - val_accuracy: 0.8313\n",
            "Epoch 273/500\n",
            "486/486 [==============================] - 9s 18ms/step - loss: 0.2104 - accuracy: 0.9255 - val_loss: 0.5590 - val_accuracy: 0.8230\n",
            "Epoch 274/500\n",
            "486/486 [==============================] - 8s 17ms/step - loss: 0.2149 - accuracy: 0.9219 - val_loss: 0.5656 - val_accuracy: 0.8354\n",
            "Epoch 275/500\n",
            "486/486 [==============================] - 8s 17ms/step - loss: 0.2095 - accuracy: 0.9231 - val_loss: 0.5533 - val_accuracy: 0.8107\n",
            "Epoch 276/500\n",
            "486/486 [==============================] - 9s 18ms/step - loss: 0.2262 - accuracy: 0.9143 - val_loss: 0.5279 - val_accuracy: 0.8354\n",
            "Epoch 277/500\n",
            "486/486 [==============================] - 9s 18ms/step - loss: 0.2046 - accuracy: 0.9251 - val_loss: 0.5840 - val_accuracy: 0.8272\n",
            "Epoch 278/500\n",
            "486/486 [==============================] - 9s 18ms/step - loss: 0.2149 - accuracy: 0.9213 - val_loss: 0.5733 - val_accuracy: 0.8148\n",
            "Epoch 279/500\n",
            "486/486 [==============================] - 9s 18ms/step - loss: 0.2078 - accuracy: 0.9252 - val_loss: 0.5696 - val_accuracy: 0.8395\n",
            "Epoch 280/500\n",
            "486/486 [==============================] - 9s 18ms/step - loss: 0.2050 - accuracy: 0.9231 - val_loss: 0.5897 - val_accuracy: 0.8230\n",
            "Epoch 281/500\n",
            "486/486 [==============================] - 9s 18ms/step - loss: 0.2084 - accuracy: 0.9237 - val_loss: 0.5695 - val_accuracy: 0.8354\n",
            "Epoch 282/500\n",
            "486/486 [==============================] - 9s 18ms/step - loss: 0.2049 - accuracy: 0.9264 - val_loss: 0.5794 - val_accuracy: 0.8313\n",
            "Epoch 283/500\n",
            "486/486 [==============================] - 9s 18ms/step - loss: 0.1938 - accuracy: 0.9334 - val_loss: 0.5635 - val_accuracy: 0.8395\n",
            "Epoch 284/500\n",
            "486/486 [==============================] - 8s 17ms/step - loss: 0.2022 - accuracy: 0.9256 - val_loss: 0.5823 - val_accuracy: 0.8148\n",
            "Epoch 285/500\n",
            "486/486 [==============================] - 8s 17ms/step - loss: 0.2037 - accuracy: 0.9234 - val_loss: 0.6045 - val_accuracy: 0.8189\n",
            "Epoch 286/500\n",
            "486/486 [==============================] - 8s 17ms/step - loss: 0.2240 - accuracy: 0.9213 - val_loss: 0.5282 - val_accuracy: 0.8354\n",
            "Epoch 287/500\n",
            "486/486 [==============================] - 9s 18ms/step - loss: 0.2191 - accuracy: 0.9211 - val_loss: 0.5130 - val_accuracy: 0.8436\n",
            "Epoch 288/500\n",
            "486/486 [==============================] - 8s 17ms/step - loss: 0.2092 - accuracy: 0.9284 - val_loss: 0.5817 - val_accuracy: 0.8148\n",
            "Epoch 289/500\n",
            "486/486 [==============================] - 8s 17ms/step - loss: 0.2158 - accuracy: 0.9208 - val_loss: 0.5843 - val_accuracy: 0.8148\n",
            "Epoch 290/500\n",
            "486/486 [==============================] - 8s 17ms/step - loss: 0.1962 - accuracy: 0.9300 - val_loss: 0.5684 - val_accuracy: 0.8354\n",
            "Epoch 291/500\n",
            "486/486 [==============================] - 8s 17ms/step - loss: 0.2168 - accuracy: 0.9220 - val_loss: 0.6028 - val_accuracy: 0.8148\n",
            "Epoch 292/500\n",
            "486/486 [==============================] - 8s 17ms/step - loss: 0.1959 - accuracy: 0.9322 - val_loss: 0.6116 - val_accuracy: 0.8066\n",
            "Epoch 293/500\n",
            "486/486 [==============================] - 8s 17ms/step - loss: 0.2088 - accuracy: 0.9261 - val_loss: 0.5705 - val_accuracy: 0.8107\n",
            "Epoch 294/500\n",
            "486/486 [==============================] - 9s 17ms/step - loss: 0.2069 - accuracy: 0.9249 - val_loss: 0.5917 - val_accuracy: 0.7942\n",
            "Epoch 295/500\n",
            "486/486 [==============================] - 8s 17ms/step - loss: 0.1955 - accuracy: 0.9293 - val_loss: 0.5363 - val_accuracy: 0.8395\n",
            "Epoch 296/500\n",
            "486/486 [==============================] - 8s 17ms/step - loss: 0.2051 - accuracy: 0.9244 - val_loss: 0.5085 - val_accuracy: 0.8436\n",
            "Epoch 297/500\n",
            "486/486 [==============================] - 9s 18ms/step - loss: 0.1979 - accuracy: 0.9305 - val_loss: 0.5220 - val_accuracy: 0.8313\n",
            "Epoch 298/500\n",
            "486/486 [==============================] - 8s 17ms/step - loss: 0.1999 - accuracy: 0.9253 - val_loss: 0.5836 - val_accuracy: 0.8148\n",
            "Epoch 299/500\n",
            "486/486 [==============================] - 8s 17ms/step - loss: 0.1933 - accuracy: 0.9295 - val_loss: 0.5683 - val_accuracy: 0.8189\n",
            "Epoch 300/500\n",
            "486/486 [==============================] - 8s 17ms/step - loss: 0.1917 - accuracy: 0.9293 - val_loss: 0.5611 - val_accuracy: 0.8395\n",
            "Epoch 301/500\n",
            "486/486 [==============================] - 9s 18ms/step - loss: 0.2151 - accuracy: 0.9235 - val_loss: 0.6015 - val_accuracy: 0.8107\n",
            "Epoch 302/500\n",
            "486/486 [==============================] - 9s 18ms/step - loss: 0.2044 - accuracy: 0.9289 - val_loss: 0.5912 - val_accuracy: 0.8354\n",
            "Epoch 303/500\n",
            "486/486 [==============================] - 9s 18ms/step - loss: 0.1824 - accuracy: 0.9313 - val_loss: 0.6064 - val_accuracy: 0.8313\n",
            "Epoch 304/500\n",
            "486/486 [==============================] - 9s 17ms/step - loss: 0.1935 - accuracy: 0.9316 - val_loss: 0.5642 - val_accuracy: 0.8395\n",
            "Epoch 305/500\n",
            "486/486 [==============================] - 8s 17ms/step - loss: 0.2004 - accuracy: 0.9275 - val_loss: 0.6346 - val_accuracy: 0.8148\n",
            "Epoch 306/500\n",
            "486/486 [==============================] - 8s 17ms/step - loss: 0.1878 - accuracy: 0.9325 - val_loss: 0.5891 - val_accuracy: 0.7984\n",
            "Epoch 307/500\n",
            "486/486 [==============================] - 9s 18ms/step - loss: 0.1877 - accuracy: 0.9296 - val_loss: 0.6298 - val_accuracy: 0.8107\n",
            "Epoch 308/500\n",
            "486/486 [==============================] - 8s 17ms/step - loss: 0.2096 - accuracy: 0.9251 - val_loss: 0.5730 - val_accuracy: 0.8230\n",
            "Epoch 309/500\n",
            "486/486 [==============================] - 8s 17ms/step - loss: 0.2065 - accuracy: 0.9255 - val_loss: 0.6172 - val_accuracy: 0.8107\n",
            "Epoch 310/500\n",
            "486/486 [==============================] - 8s 17ms/step - loss: 0.1986 - accuracy: 0.9292 - val_loss: 0.5731 - val_accuracy: 0.8272\n",
            "Epoch 311/500\n",
            "486/486 [==============================] - 9s 18ms/step - loss: 0.1794 - accuracy: 0.9327 - val_loss: 0.5662 - val_accuracy: 0.8272\n",
            "Epoch 312/500\n",
            "486/486 [==============================] - 8s 17ms/step - loss: 0.2051 - accuracy: 0.9240 - val_loss: 0.5964 - val_accuracy: 0.8189\n",
            "Epoch 313/500\n",
            "486/486 [==============================] - 8s 17ms/step - loss: 0.1989 - accuracy: 0.9252 - val_loss: 0.5418 - val_accuracy: 0.8189\n",
            "Epoch 314/500\n",
            "486/486 [==============================] - 8s 17ms/step - loss: 0.1920 - accuracy: 0.9302 - val_loss: 0.5768 - val_accuracy: 0.8272\n",
            "Epoch 315/500\n",
            "486/486 [==============================] - 8s 17ms/step - loss: 0.1868 - accuracy: 0.9331 - val_loss: 0.6391 - val_accuracy: 0.8107\n",
            "Epoch 316/500\n",
            "486/486 [==============================] - 9s 18ms/step - loss: 0.1956 - accuracy: 0.9260 - val_loss: 0.6095 - val_accuracy: 0.8230\n",
            "Epoch 317/500\n",
            "486/486 [==============================] - 8s 17ms/step - loss: 0.2055 - accuracy: 0.9268 - val_loss: 0.5970 - val_accuracy: 0.8313\n",
            "Epoch 318/500\n",
            "486/486 [==============================] - 8s 17ms/step - loss: 0.1798 - accuracy: 0.9367 - val_loss: 0.6119 - val_accuracy: 0.8148\n",
            "Epoch 319/500\n",
            "486/486 [==============================] - 9s 18ms/step - loss: 0.1970 - accuracy: 0.9280 - val_loss: 0.6193 - val_accuracy: 0.8025\n",
            "Epoch 320/500\n",
            "486/486 [==============================] - 8s 17ms/step - loss: 0.1871 - accuracy: 0.9319 - val_loss: 0.5353 - val_accuracy: 0.8313\n",
            "Epoch 321/500\n",
            "486/486 [==============================] - 8s 17ms/step - loss: 0.1857 - accuracy: 0.9319 - val_loss: 0.5480 - val_accuracy: 0.8313\n",
            "Epoch 322/500\n",
            "486/486 [==============================] - 8s 17ms/step - loss: 0.1894 - accuracy: 0.9307 - val_loss: 0.6018 - val_accuracy: 0.8107\n",
            "Epoch 323/500\n",
            "486/486 [==============================] - 8s 17ms/step - loss: 0.1795 - accuracy: 0.9376 - val_loss: 0.5805 - val_accuracy: 0.8189\n",
            "Epoch 324/500\n",
            "486/486 [==============================] - 8s 17ms/step - loss: 0.1853 - accuracy: 0.9325 - val_loss: 0.5886 - val_accuracy: 0.8354\n",
            "Epoch 325/500\n",
            "486/486 [==============================] - 9s 17ms/step - loss: 0.1869 - accuracy: 0.9345 - val_loss: 0.6313 - val_accuracy: 0.8313\n",
            "Epoch 326/500\n",
            "486/486 [==============================] - 8s 17ms/step - loss: 0.1818 - accuracy: 0.9340 - val_loss: 0.5909 - val_accuracy: 0.8272\n",
            "Epoch 327/500\n",
            "486/486 [==============================] - 9s 18ms/step - loss: 0.1915 - accuracy: 0.9275 - val_loss: 0.6022 - val_accuracy: 0.8313\n",
            "Epoch 328/500\n",
            "486/486 [==============================] - 9s 19ms/step - loss: 0.1876 - accuracy: 0.9296 - val_loss: 0.6264 - val_accuracy: 0.8436\n",
            "Epoch 329/500\n",
            "486/486 [==============================] - 8s 17ms/step - loss: 0.1916 - accuracy: 0.9307 - val_loss: 0.6060 - val_accuracy: 0.8272\n",
            "Epoch 330/500\n",
            "486/486 [==============================] - 8s 17ms/step - loss: 0.1996 - accuracy: 0.9283 - val_loss: 0.6430 - val_accuracy: 0.8066\n",
            "Epoch 331/500\n",
            "486/486 [==============================] - 9s 18ms/step - loss: 0.1918 - accuracy: 0.9296 - val_loss: 0.5619 - val_accuracy: 0.8519\n",
            "Epoch 332/500\n",
            "486/486 [==============================] - 8s 17ms/step - loss: 0.1916 - accuracy: 0.9314 - val_loss: 0.5638 - val_accuracy: 0.8272\n",
            "Epoch 333/500\n",
            "486/486 [==============================] - 8s 17ms/step - loss: 0.1836 - accuracy: 0.9345 - val_loss: 0.5993 - val_accuracy: 0.8148\n",
            "Epoch 334/500\n",
            "486/486 [==============================] - 9s 18ms/step - loss: 0.1848 - accuracy: 0.9369 - val_loss: 0.6224 - val_accuracy: 0.8066\n",
            "Epoch 335/500\n",
            "486/486 [==============================] - 9s 18ms/step - loss: 0.1852 - accuracy: 0.9354 - val_loss: 0.6377 - val_accuracy: 0.8313\n",
            "Epoch 336/500\n",
            "486/486 [==============================] - 8s 17ms/step - loss: 0.1811 - accuracy: 0.9343 - val_loss: 0.5759 - val_accuracy: 0.8313\n",
            "Epoch 337/500\n",
            "486/486 [==============================] - 8s 17ms/step - loss: 0.1769 - accuracy: 0.9346 - val_loss: 0.6367 - val_accuracy: 0.8230\n",
            "Epoch 338/500\n",
            "486/486 [==============================] - 9s 18ms/step - loss: 0.1770 - accuracy: 0.9360 - val_loss: 0.6553 - val_accuracy: 0.8189\n",
            "Epoch 339/500\n",
            "486/486 [==============================] - 8s 17ms/step - loss: 0.1867 - accuracy: 0.9316 - val_loss: 0.6529 - val_accuracy: 0.8189\n",
            "Epoch 340/500\n",
            "486/486 [==============================] - 8s 17ms/step - loss: 0.1977 - accuracy: 0.9309 - val_loss: 0.5750 - val_accuracy: 0.8230\n",
            "Epoch 341/500\n",
            "486/486 [==============================] - 9s 18ms/step - loss: 0.1817 - accuracy: 0.9340 - val_loss: 0.5900 - val_accuracy: 0.8230\n",
            "Epoch 342/500\n",
            "486/486 [==============================] - 8s 17ms/step - loss: 0.1757 - accuracy: 0.9367 - val_loss: 0.5925 - val_accuracy: 0.8354\n",
            "Epoch 343/500\n",
            "486/486 [==============================] - 9s 18ms/step - loss: 0.1814 - accuracy: 0.9351 - val_loss: 0.6435 - val_accuracy: 0.8189\n",
            "Epoch 344/500\n",
            "486/486 [==============================] - 8s 17ms/step - loss: 0.1756 - accuracy: 0.9377 - val_loss: 0.6190 - val_accuracy: 0.8272\n",
            "Epoch 345/500\n",
            "486/486 [==============================] - 8s 17ms/step - loss: 0.1855 - accuracy: 0.9331 - val_loss: 0.6112 - val_accuracy: 0.8272\n",
            "Epoch 346/500\n",
            "486/486 [==============================] - 8s 17ms/step - loss: 0.1739 - accuracy: 0.9361 - val_loss: 0.6207 - val_accuracy: 0.8230\n",
            "Epoch 347/500\n",
            "486/486 [==============================] - 8s 17ms/step - loss: 0.1742 - accuracy: 0.9363 - val_loss: 0.6261 - val_accuracy: 0.8230\n",
            "Epoch 348/500\n",
            "486/486 [==============================] - 8s 17ms/step - loss: 0.1739 - accuracy: 0.9391 - val_loss: 0.5683 - val_accuracy: 0.8148\n",
            "Epoch 349/500\n",
            "486/486 [==============================] - 8s 17ms/step - loss: 0.1688 - accuracy: 0.9412 - val_loss: 0.6031 - val_accuracy: 0.8272\n",
            "Epoch 350/500\n",
            "486/486 [==============================] - 8s 17ms/step - loss: 0.1815 - accuracy: 0.9341 - val_loss: 0.6019 - val_accuracy: 0.8313\n",
            "Epoch 351/500\n",
            "486/486 [==============================] - 9s 18ms/step - loss: 0.1897 - accuracy: 0.9320 - val_loss: 0.6473 - val_accuracy: 0.8189\n",
            "Epoch 352/500\n",
            "486/486 [==============================] - 8s 17ms/step - loss: 0.1788 - accuracy: 0.9343 - val_loss: 0.6247 - val_accuracy: 0.8395\n",
            "Epoch 353/500\n",
            "486/486 [==============================] - 9s 18ms/step - loss: 0.1805 - accuracy: 0.9374 - val_loss: 0.6093 - val_accuracy: 0.8148\n",
            "Epoch 354/500\n",
            "486/486 [==============================] - 9s 18ms/step - loss: 0.1794 - accuracy: 0.9341 - val_loss: 0.5885 - val_accuracy: 0.8354\n",
            "Epoch 355/500\n",
            "486/486 [==============================] - 8s 17ms/step - loss: 0.1695 - accuracy: 0.9385 - val_loss: 0.6123 - val_accuracy: 0.8354\n",
            "Epoch 356/500\n",
            "486/486 [==============================] - 9s 18ms/step - loss: 0.1808 - accuracy: 0.9356 - val_loss: 0.6075 - val_accuracy: 0.8272\n",
            "Epoch 357/500\n",
            "486/486 [==============================] - 9s 18ms/step - loss: 0.1877 - accuracy: 0.9313 - val_loss: 0.6250 - val_accuracy: 0.8066\n",
            "Epoch 358/500\n",
            "486/486 [==============================] - 9s 18ms/step - loss: 0.1830 - accuracy: 0.9304 - val_loss: 0.6154 - val_accuracy: 0.8313\n",
            "Epoch 359/500\n",
            "486/486 [==============================] - 8s 17ms/step - loss: 0.1751 - accuracy: 0.9355 - val_loss: 0.6536 - val_accuracy: 0.8148\n",
            "Epoch 360/500\n",
            "486/486 [==============================] - 8s 17ms/step - loss: 0.1723 - accuracy: 0.9377 - val_loss: 0.6475 - val_accuracy: 0.8066\n",
            "Epoch 361/500\n",
            "486/486 [==============================] - 8s 17ms/step - loss: 0.1765 - accuracy: 0.9381 - val_loss: 0.6187 - val_accuracy: 0.8477\n",
            "Epoch 362/500\n",
            "486/486 [==============================] - 9s 18ms/step - loss: 0.1761 - accuracy: 0.9391 - val_loss: 0.6299 - val_accuracy: 0.8272\n",
            "Epoch 363/500\n",
            "486/486 [==============================] - 9s 18ms/step - loss: 0.1791 - accuracy: 0.9350 - val_loss: 0.6312 - val_accuracy: 0.8272\n",
            "Epoch 364/500\n",
            "486/486 [==============================] - 9s 18ms/step - loss: 0.1738 - accuracy: 0.9394 - val_loss: 0.6352 - val_accuracy: 0.8189\n",
            "Epoch 365/500\n",
            "486/486 [==============================] - 9s 18ms/step - loss: 0.1720 - accuracy: 0.9382 - val_loss: 0.6189 - val_accuracy: 0.8436\n",
            "Epoch 366/500\n",
            "486/486 [==============================] - 8s 17ms/step - loss: 0.1684 - accuracy: 0.9410 - val_loss: 0.6365 - val_accuracy: 0.8313\n",
            "Epoch 367/500\n",
            "486/486 [==============================] - 8s 17ms/step - loss: 0.1564 - accuracy: 0.9427 - val_loss: 0.6534 - val_accuracy: 0.8354\n",
            "Epoch 368/500\n",
            "486/486 [==============================] - 9s 18ms/step - loss: 0.1782 - accuracy: 0.9361 - val_loss: 0.6691 - val_accuracy: 0.8230\n",
            "Epoch 369/500\n",
            "486/486 [==============================] - 8s 17ms/step - loss: 0.1740 - accuracy: 0.9385 - val_loss: 0.6879 - val_accuracy: 0.8230\n",
            "Epoch 370/500\n",
            "486/486 [==============================] - 9s 18ms/step - loss: 0.1718 - accuracy: 0.9376 - val_loss: 0.6384 - val_accuracy: 0.8354\n",
            "Epoch 371/500\n",
            "486/486 [==============================] - 9s 18ms/step - loss: 0.1809 - accuracy: 0.9367 - val_loss: 0.6432 - val_accuracy: 0.8519\n",
            "Epoch 372/500\n",
            "486/486 [==============================] - 9s 18ms/step - loss: 0.1703 - accuracy: 0.9430 - val_loss: 0.6485 - val_accuracy: 0.8272\n",
            "Epoch 373/500\n",
            "486/486 [==============================] - 9s 18ms/step - loss: 0.1715 - accuracy: 0.9369 - val_loss: 0.6284 - val_accuracy: 0.8230\n",
            "Epoch 374/500\n",
            "486/486 [==============================] - 9s 18ms/step - loss: 0.1655 - accuracy: 0.9419 - val_loss: 0.6685 - val_accuracy: 0.8272\n",
            "Epoch 375/500\n",
            "486/486 [==============================] - 8s 17ms/step - loss: 0.1662 - accuracy: 0.9385 - val_loss: 0.6428 - val_accuracy: 0.8148\n",
            "Epoch 376/500\n",
            "486/486 [==============================] - 8s 17ms/step - loss: 0.1619 - accuracy: 0.9413 - val_loss: 0.6167 - val_accuracy: 0.8148\n",
            "Epoch 377/500\n",
            "486/486 [==============================] - 8s 17ms/step - loss: 0.1803 - accuracy: 0.9351 - val_loss: 0.5992 - val_accuracy: 0.8436\n",
            "Epoch 378/500\n",
            "486/486 [==============================] - 9s 18ms/step - loss: 0.1731 - accuracy: 0.9399 - val_loss: 0.6465 - val_accuracy: 0.8066\n",
            "Epoch 379/500\n",
            "486/486 [==============================] - 9s 18ms/step - loss: 0.1711 - accuracy: 0.9408 - val_loss: 0.6468 - val_accuracy: 0.8272\n",
            "Epoch 380/500\n",
            "486/486 [==============================] - 8s 17ms/step - loss: 0.1668 - accuracy: 0.9416 - val_loss: 0.7091 - val_accuracy: 0.8025\n",
            "Epoch 381/500\n",
            "486/486 [==============================] - 8s 17ms/step - loss: 0.1597 - accuracy: 0.9404 - val_loss: 0.6100 - val_accuracy: 0.8354\n",
            "Epoch 382/500\n",
            "486/486 [==============================] - 8s 17ms/step - loss: 0.1624 - accuracy: 0.9385 - val_loss: 0.6071 - val_accuracy: 0.8189\n",
            "Epoch 383/500\n",
            "486/486 [==============================] - 9s 18ms/step - loss: 0.1469 - accuracy: 0.9485 - val_loss: 0.6306 - val_accuracy: 0.8354\n",
            "Epoch 384/500\n",
            "486/486 [==============================] - 8s 17ms/step - loss: 0.1617 - accuracy: 0.9422 - val_loss: 0.6229 - val_accuracy: 0.8477\n",
            "Epoch 385/500\n",
            "486/486 [==============================] - 9s 18ms/step - loss: 0.1647 - accuracy: 0.9436 - val_loss: 0.6692 - val_accuracy: 0.8025\n",
            "Epoch 386/500\n",
            "486/486 [==============================] - 8s 17ms/step - loss: 0.1614 - accuracy: 0.9444 - val_loss: 0.6825 - val_accuracy: 0.8189\n",
            "Epoch 387/500\n",
            "486/486 [==============================] - 8s 17ms/step - loss: 0.1780 - accuracy: 0.9361 - val_loss: 0.6792 - val_accuracy: 0.8189\n",
            "Epoch 388/500\n",
            "486/486 [==============================] - 8s 17ms/step - loss: 0.1676 - accuracy: 0.9409 - val_loss: 0.6490 - val_accuracy: 0.8354\n",
            "Epoch 389/500\n",
            "486/486 [==============================] - 8s 17ms/step - loss: 0.1588 - accuracy: 0.9434 - val_loss: 0.6711 - val_accuracy: 0.8066\n",
            "Epoch 390/500\n",
            "486/486 [==============================] - 8s 17ms/step - loss: 0.1709 - accuracy: 0.9374 - val_loss: 0.6085 - val_accuracy: 0.8354\n",
            "Epoch 391/500\n",
            "486/486 [==============================] - 8s 17ms/step - loss: 0.1682 - accuracy: 0.9395 - val_loss: 0.6081 - val_accuracy: 0.8107\n",
            "Epoch 392/500\n",
            "486/486 [==============================] - 9s 18ms/step - loss: 0.1604 - accuracy: 0.9428 - val_loss: 0.6393 - val_accuracy: 0.8230\n",
            "Epoch 393/500\n",
            "486/486 [==============================] - 8s 17ms/step - loss: 0.1816 - accuracy: 0.9396 - val_loss: 0.6685 - val_accuracy: 0.8148\n",
            "Epoch 394/500\n",
            "486/486 [==============================] - 8s 17ms/step - loss: 0.1572 - accuracy: 0.9426 - val_loss: 0.6647 - val_accuracy: 0.8189\n",
            "Epoch 395/500\n",
            "486/486 [==============================] - 8s 17ms/step - loss: 0.1595 - accuracy: 0.9444 - val_loss: 0.6422 - val_accuracy: 0.8189\n",
            "Epoch 396/500\n",
            "486/486 [==============================] - 8s 17ms/step - loss: 0.1622 - accuracy: 0.9430 - val_loss: 0.6627 - val_accuracy: 0.8313\n",
            "Epoch 397/500\n",
            "486/486 [==============================] - 8s 17ms/step - loss: 0.1619 - accuracy: 0.9416 - val_loss: 0.6155 - val_accuracy: 0.8313\n",
            "Epoch 398/500\n",
            "486/486 [==============================] - 8s 17ms/step - loss: 0.1609 - accuracy: 0.9459 - val_loss: 0.6658 - val_accuracy: 0.8066\n",
            "Epoch 399/500\n",
            "486/486 [==============================] - 8s 17ms/step - loss: 0.1619 - accuracy: 0.9434 - val_loss: 0.6052 - val_accuracy: 0.8313\n",
            "Epoch 400/500\n",
            "486/486 [==============================] - 9s 18ms/step - loss: 0.1630 - accuracy: 0.9421 - val_loss: 0.6422 - val_accuracy: 0.8436\n",
            "Epoch 401/500\n",
            "486/486 [==============================] - 8s 17ms/step - loss: 0.1622 - accuracy: 0.9446 - val_loss: 0.6796 - val_accuracy: 0.8107\n",
            "Epoch 402/500\n",
            "486/486 [==============================] - 8s 17ms/step - loss: 0.1756 - accuracy: 0.9396 - val_loss: 0.6242 - val_accuracy: 0.8189\n",
            "Epoch 403/500\n",
            "486/486 [==============================] - 9s 18ms/step - loss: 0.1716 - accuracy: 0.9412 - val_loss: 0.6175 - val_accuracy: 0.8230\n",
            "Epoch 404/500\n",
            "486/486 [==============================] - 8s 17ms/step - loss: 0.1573 - accuracy: 0.9470 - val_loss: 0.6307 - val_accuracy: 0.8230\n",
            "Epoch 405/500\n",
            "486/486 [==============================] - 8s 17ms/step - loss: 0.1568 - accuracy: 0.9418 - val_loss: 0.6142 - val_accuracy: 0.8354\n",
            "Epoch 406/500\n",
            "486/486 [==============================] - 9s 18ms/step - loss: 0.1618 - accuracy: 0.9436 - val_loss: 0.6615 - val_accuracy: 0.8395\n",
            "Epoch 407/500\n",
            "486/486 [==============================] - 9s 18ms/step - loss: 0.1528 - accuracy: 0.9475 - val_loss: 0.6213 - val_accuracy: 0.8107\n",
            "Epoch 408/500\n",
            "486/486 [==============================] - 8s 17ms/step - loss: 0.1550 - accuracy: 0.9439 - val_loss: 0.6773 - val_accuracy: 0.8066\n",
            "Epoch 409/500\n",
            "486/486 [==============================] - 8s 17ms/step - loss: 0.1587 - accuracy: 0.9430 - val_loss: 0.6875 - val_accuracy: 0.8107\n",
            "Epoch 410/500\n",
            "486/486 [==============================] - 8s 17ms/step - loss: 0.1699 - accuracy: 0.9394 - val_loss: 0.6665 - val_accuracy: 0.8066\n",
            "Epoch 411/500\n",
            "486/486 [==============================] - 9s 18ms/step - loss: 0.1575 - accuracy: 0.9464 - val_loss: 0.6256 - val_accuracy: 0.8230\n",
            "Epoch 412/500\n",
            "486/486 [==============================] - 8s 17ms/step - loss: 0.1710 - accuracy: 0.9377 - val_loss: 0.6227 - val_accuracy: 0.8272\n",
            "Epoch 413/500\n",
            "486/486 [==============================] - 9s 18ms/step - loss: 0.1562 - accuracy: 0.9462 - val_loss: 0.6394 - val_accuracy: 0.8189\n",
            "Epoch 414/500\n",
            "486/486 [==============================] - 9s 18ms/step - loss: 0.1529 - accuracy: 0.9454 - val_loss: 0.6264 - val_accuracy: 0.8313\n",
            "Epoch 415/500\n",
            "486/486 [==============================] - 8s 17ms/step - loss: 0.1649 - accuracy: 0.9436 - val_loss: 0.6864 - val_accuracy: 0.8189\n",
            "Epoch 416/500\n",
            "486/486 [==============================] - 9s 18ms/step - loss: 0.1636 - accuracy: 0.9423 - val_loss: 0.5910 - val_accuracy: 0.8395\n",
            "Epoch 417/500\n",
            "486/486 [==============================] - 8s 17ms/step - loss: 0.1709 - accuracy: 0.9380 - val_loss: 0.6153 - val_accuracy: 0.8189\n",
            "Epoch 418/500\n",
            "486/486 [==============================] - 9s 18ms/step - loss: 0.1504 - accuracy: 0.9462 - val_loss: 0.6503 - val_accuracy: 0.8436\n",
            "Epoch 419/500\n",
            "486/486 [==============================] - 9s 18ms/step - loss: 0.1591 - accuracy: 0.9444 - val_loss: 0.6260 - val_accuracy: 0.8189\n",
            "Epoch 420/500\n",
            "486/486 [==============================] - 9s 18ms/step - loss: 0.1608 - accuracy: 0.9412 - val_loss: 0.6668 - val_accuracy: 0.8272\n",
            "Epoch 421/500\n",
            "486/486 [==============================] - 9s 18ms/step - loss: 0.1613 - accuracy: 0.9408 - val_loss: 0.6516 - val_accuracy: 0.8189\n",
            "Epoch 422/500\n",
            "486/486 [==============================] - 9s 18ms/step - loss: 0.1522 - accuracy: 0.9452 - val_loss: 0.6565 - val_accuracy: 0.8477\n",
            "Epoch 423/500\n",
            "486/486 [==============================] - 9s 18ms/step - loss: 0.1574 - accuracy: 0.9405 - val_loss: 0.6153 - val_accuracy: 0.8230\n",
            "Epoch 424/500\n",
            "486/486 [==============================] - 8s 17ms/step - loss: 0.1502 - accuracy: 0.9462 - val_loss: 0.6139 - val_accuracy: 0.8313\n",
            "Epoch 425/500\n",
            "486/486 [==============================] - 9s 18ms/step - loss: 0.1672 - accuracy: 0.9414 - val_loss: 0.5921 - val_accuracy: 0.8148\n",
            "Epoch 426/500\n",
            "486/486 [==============================] - 9s 18ms/step - loss: 0.1613 - accuracy: 0.9441 - val_loss: 0.7173 - val_accuracy: 0.8025\n",
            "Epoch 427/500\n",
            "486/486 [==============================] - 9s 18ms/step - loss: 0.1666 - accuracy: 0.9413 - val_loss: 0.6482 - val_accuracy: 0.8189\n",
            "Epoch 428/500\n",
            "486/486 [==============================] - 8s 17ms/step - loss: 0.1605 - accuracy: 0.9459 - val_loss: 0.5828 - val_accuracy: 0.8354\n",
            "Epoch 429/500\n",
            "486/486 [==============================] - 9s 18ms/step - loss: 0.1544 - accuracy: 0.9466 - val_loss: 0.6559 - val_accuracy: 0.8107\n",
            "Epoch 430/500\n",
            "486/486 [==============================] - 8s 17ms/step - loss: 0.1562 - accuracy: 0.9461 - val_loss: 0.6204 - val_accuracy: 0.8148\n",
            "Epoch 431/500\n",
            "486/486 [==============================] - 8s 17ms/step - loss: 0.1518 - accuracy: 0.9457 - val_loss: 0.6167 - val_accuracy: 0.8477\n",
            "Epoch 432/500\n",
            "486/486 [==============================] - 9s 18ms/step - loss: 0.1634 - accuracy: 0.9435 - val_loss: 0.6140 - val_accuracy: 0.8189\n",
            "Epoch 433/500\n",
            "486/486 [==============================] - 9s 18ms/step - loss: 0.1478 - accuracy: 0.9466 - val_loss: 0.6160 - val_accuracy: 0.8107\n",
            "Epoch 434/500\n",
            "486/486 [==============================] - 8s 17ms/step - loss: 0.1644 - accuracy: 0.9413 - val_loss: 0.6028 - val_accuracy: 0.8436\n",
            "Epoch 435/500\n",
            "486/486 [==============================] - 9s 18ms/step - loss: 0.1510 - accuracy: 0.9480 - val_loss: 0.6354 - val_accuracy: 0.8107\n",
            "Epoch 436/500\n",
            "486/486 [==============================] - 9s 18ms/step - loss: 0.1566 - accuracy: 0.9430 - val_loss: 0.6255 - val_accuracy: 0.8230\n",
            "Epoch 437/500\n",
            "486/486 [==============================] - 9s 18ms/step - loss: 0.1576 - accuracy: 0.9437 - val_loss: 0.6561 - val_accuracy: 0.8189\n",
            "Epoch 438/500\n",
            "486/486 [==============================] - 8s 17ms/step - loss: 0.1544 - accuracy: 0.9462 - val_loss: 0.6901 - val_accuracy: 0.8230\n",
            "Epoch 439/500\n",
            "486/486 [==============================] - 9s 18ms/step - loss: 0.1520 - accuracy: 0.9484 - val_loss: 0.6282 - val_accuracy: 0.8272\n",
            "Epoch 440/500\n",
            "486/486 [==============================] - 9s 18ms/step - loss: 0.1667 - accuracy: 0.9426 - val_loss: 0.6652 - val_accuracy: 0.8230\n",
            "Epoch 441/500\n",
            "486/486 [==============================] - 9s 18ms/step - loss: 0.1557 - accuracy: 0.9457 - val_loss: 0.6024 - val_accuracy: 0.8272\n",
            "Epoch 442/500\n",
            "486/486 [==============================] - 9s 18ms/step - loss: 0.1606 - accuracy: 0.9437 - val_loss: 0.6499 - val_accuracy: 0.8148\n",
            "Epoch 443/500\n",
            "486/486 [==============================] - 8s 17ms/step - loss: 0.1566 - accuracy: 0.9449 - val_loss: 0.6477 - val_accuracy: 0.8395\n",
            "Epoch 444/500\n",
            "486/486 [==============================] - 9s 18ms/step - loss: 0.1546 - accuracy: 0.9463 - val_loss: 0.6566 - val_accuracy: 0.8313\n",
            "Epoch 445/500\n",
            "486/486 [==============================] - 9s 18ms/step - loss: 0.1489 - accuracy: 0.9467 - val_loss: 0.6873 - val_accuracy: 0.8313\n",
            "Epoch 446/500\n",
            "486/486 [==============================] - 9s 18ms/step - loss: 0.1568 - accuracy: 0.9423 - val_loss: 0.6754 - val_accuracy: 0.8313\n",
            "Epoch 447/500\n",
            "486/486 [==============================] - 9s 18ms/step - loss: 0.1511 - accuracy: 0.9476 - val_loss: 0.6834 - val_accuracy: 0.8395\n",
            "Epoch 448/500\n",
            "486/486 [==============================] - 9s 18ms/step - loss: 0.1516 - accuracy: 0.9468 - val_loss: 0.6473 - val_accuracy: 0.8230\n",
            "Epoch 449/500\n",
            "486/486 [==============================] - 9s 19ms/step - loss: 0.1547 - accuracy: 0.9450 - val_loss: 0.6538 - val_accuracy: 0.8230\n",
            "Epoch 450/500\n",
            "486/486 [==============================] - 9s 18ms/step - loss: 0.1468 - accuracy: 0.9461 - val_loss: 0.6832 - val_accuracy: 0.8395\n",
            "Epoch 451/500\n",
            "486/486 [==============================] - 9s 18ms/step - loss: 0.1477 - accuracy: 0.9453 - val_loss: 0.6483 - val_accuracy: 0.8313\n",
            "Epoch 452/500\n",
            "486/486 [==============================] - 8s 17ms/step - loss: 0.1453 - accuracy: 0.9477 - val_loss: 0.7133 - val_accuracy: 0.8189\n",
            "Epoch 453/500\n",
            "486/486 [==============================] - 9s 18ms/step - loss: 0.1451 - accuracy: 0.9454 - val_loss: 0.6769 - val_accuracy: 0.8230\n",
            "Epoch 454/500\n",
            "486/486 [==============================] - 9s 18ms/step - loss: 0.1536 - accuracy: 0.9498 - val_loss: 0.7149 - val_accuracy: 0.8107\n",
            "Epoch 455/500\n",
            "486/486 [==============================] - 9s 18ms/step - loss: 0.1619 - accuracy: 0.9419 - val_loss: 0.6461 - val_accuracy: 0.8436\n",
            "Epoch 456/500\n",
            "486/486 [==============================] - 9s 18ms/step - loss: 0.1482 - accuracy: 0.9468 - val_loss: 0.6866 - val_accuracy: 0.8272\n",
            "Epoch 457/500\n",
            "486/486 [==============================] - 9s 18ms/step - loss: 0.1527 - accuracy: 0.9471 - val_loss: 0.7037 - val_accuracy: 0.8066\n",
            "Epoch 458/500\n",
            "486/486 [==============================] - 8s 17ms/step - loss: 0.1481 - accuracy: 0.9454 - val_loss: 0.6607 - val_accuracy: 0.8189\n",
            "Epoch 459/500\n",
            "486/486 [==============================] - 9s 17ms/step - loss: 0.1462 - accuracy: 0.9476 - val_loss: 0.7120 - val_accuracy: 0.8189\n",
            "Epoch 460/500\n",
            "486/486 [==============================] - 9s 18ms/step - loss: 0.1463 - accuracy: 0.9503 - val_loss: 0.6620 - val_accuracy: 0.8272\n",
            "Epoch 461/500\n",
            "486/486 [==============================] - 9s 18ms/step - loss: 0.1390 - accuracy: 0.9497 - val_loss: 0.6382 - val_accuracy: 0.8230\n",
            "Epoch 462/500\n",
            "486/486 [==============================] - 9s 18ms/step - loss: 0.1468 - accuracy: 0.9499 - val_loss: 0.6696 - val_accuracy: 0.8354\n",
            "Epoch 463/500\n",
            "486/486 [==============================] - 9s 18ms/step - loss: 0.1595 - accuracy: 0.9466 - val_loss: 0.6238 - val_accuracy: 0.8189\n",
            "Epoch 464/500\n",
            "486/486 [==============================] - 9s 17ms/step - loss: 0.1401 - accuracy: 0.9503 - val_loss: 0.7215 - val_accuracy: 0.8230\n",
            "Epoch 465/500\n",
            "486/486 [==============================] - 9s 18ms/step - loss: 0.1446 - accuracy: 0.9484 - val_loss: 0.7088 - val_accuracy: 0.8313\n",
            "Epoch 466/500\n",
            "486/486 [==============================] - 9s 18ms/step - loss: 0.1562 - accuracy: 0.9473 - val_loss: 0.6567 - val_accuracy: 0.8189\n",
            "Epoch 467/500\n",
            "486/486 [==============================] - 9s 18ms/step - loss: 0.1439 - accuracy: 0.9481 - val_loss: 0.6691 - val_accuracy: 0.8230\n",
            "Epoch 468/500\n",
            "486/486 [==============================] - 9s 18ms/step - loss: 0.1460 - accuracy: 0.9470 - val_loss: 0.6968 - val_accuracy: 0.7778\n",
            "Epoch 469/500\n",
            "486/486 [==============================] - 9s 18ms/step - loss: 0.1517 - accuracy: 0.9472 - val_loss: 0.6361 - val_accuracy: 0.8395\n",
            "Epoch 470/500\n",
            "486/486 [==============================] - 9s 18ms/step - loss: 0.1420 - accuracy: 0.9516 - val_loss: 0.6362 - val_accuracy: 0.8519\n",
            "Epoch 471/500\n",
            "486/486 [==============================] - 9s 18ms/step - loss: 0.1455 - accuracy: 0.9506 - val_loss: 0.6696 - val_accuracy: 0.8189\n",
            "Epoch 472/500\n",
            "486/486 [==============================] - 9s 18ms/step - loss: 0.1400 - accuracy: 0.9501 - val_loss: 0.6768 - val_accuracy: 0.8230\n",
            "Epoch 473/500\n",
            "486/486 [==============================] - 8s 17ms/step - loss: 0.1466 - accuracy: 0.9485 - val_loss: 0.6693 - val_accuracy: 0.8230\n",
            "Epoch 474/500\n",
            "486/486 [==============================] - 9s 18ms/step - loss: 0.1579 - accuracy: 0.9419 - val_loss: 0.6864 - val_accuracy: 0.8272\n",
            "Epoch 475/500\n",
            "486/486 [==============================] - 9s 18ms/step - loss: 0.1452 - accuracy: 0.9488 - val_loss: 0.6759 - val_accuracy: 0.8189\n",
            "Epoch 476/500\n",
            "486/486 [==============================] - 9s 18ms/step - loss: 0.1436 - accuracy: 0.9494 - val_loss: 0.6704 - val_accuracy: 0.8272\n",
            "Epoch 477/500\n",
            "486/486 [==============================] - 9s 18ms/step - loss: 0.1505 - accuracy: 0.9461 - val_loss: 0.6612 - val_accuracy: 0.8230\n",
            "Epoch 478/500\n",
            "486/486 [==============================] - 9s 18ms/step - loss: 0.1474 - accuracy: 0.9470 - val_loss: 0.6218 - val_accuracy: 0.8477\n",
            "Epoch 479/500\n",
            "486/486 [==============================] - 9s 18ms/step - loss: 0.1505 - accuracy: 0.9490 - val_loss: 0.6416 - val_accuracy: 0.8230\n",
            "Epoch 480/500\n",
            "486/486 [==============================] - 9s 18ms/step - loss: 0.1499 - accuracy: 0.9470 - val_loss: 0.6400 - val_accuracy: 0.8230\n",
            "Epoch 481/500\n",
            "486/486 [==============================] - 9s 18ms/step - loss: 0.1503 - accuracy: 0.9481 - val_loss: 0.6426 - val_accuracy: 0.8230\n",
            "Epoch 482/500\n",
            "486/486 [==============================] - 9s 18ms/step - loss: 0.1359 - accuracy: 0.9526 - val_loss: 0.6925 - val_accuracy: 0.8272\n",
            "Epoch 483/500\n",
            "486/486 [==============================] - 9s 18ms/step - loss: 0.1462 - accuracy: 0.9498 - val_loss: 0.6118 - val_accuracy: 0.7984\n",
            "Epoch 484/500\n",
            "486/486 [==============================] - 9s 18ms/step - loss: 0.1497 - accuracy: 0.9459 - val_loss: 0.6391 - val_accuracy: 0.8436\n",
            "Epoch 485/500\n",
            "486/486 [==============================] - 9s 18ms/step - loss: 0.1457 - accuracy: 0.9490 - val_loss: 0.6923 - val_accuracy: 0.8395\n",
            "Epoch 486/500\n",
            "486/486 [==============================] - 9s 18ms/step - loss: 0.1305 - accuracy: 0.9569 - val_loss: 0.6151 - val_accuracy: 0.8519\n",
            "Epoch 487/500\n",
            "486/486 [==============================] - 9s 18ms/step - loss: 0.1526 - accuracy: 0.9439 - val_loss: 0.6251 - val_accuracy: 0.8395\n",
            "Epoch 488/500\n",
            "486/486 [==============================] - 9s 18ms/step - loss: 0.1347 - accuracy: 0.9534 - val_loss: 0.6642 - val_accuracy: 0.8107\n",
            "Epoch 489/500\n",
            "486/486 [==============================] - 9s 18ms/step - loss: 0.1446 - accuracy: 0.9528 - val_loss: 0.6341 - val_accuracy: 0.8272\n",
            "Epoch 490/500\n",
            "486/486 [==============================] - 9s 18ms/step - loss: 0.1406 - accuracy: 0.9494 - val_loss: 0.6610 - val_accuracy: 0.8272\n",
            "Epoch 491/500\n",
            "486/486 [==============================] - 9s 18ms/step - loss: 0.1371 - accuracy: 0.9507 - val_loss: 0.6570 - val_accuracy: 0.8148\n",
            "Epoch 492/500\n",
            "486/486 [==============================] - 9s 18ms/step - loss: 0.1381 - accuracy: 0.9510 - val_loss: 0.6906 - val_accuracy: 0.8189\n",
            "Epoch 493/500\n",
            "486/486 [==============================] - 8s 17ms/step - loss: 0.1405 - accuracy: 0.9526 - val_loss: 0.7171 - val_accuracy: 0.7984\n",
            "Epoch 494/500\n",
            "486/486 [==============================] - 9s 18ms/step - loss: 0.1423 - accuracy: 0.9495 - val_loss: 0.6309 - val_accuracy: 0.8436\n",
            "Epoch 495/500\n",
            "486/486 [==============================] - 9s 18ms/step - loss: 0.1480 - accuracy: 0.9502 - val_loss: 0.7098 - val_accuracy: 0.8189\n",
            "Epoch 496/500\n",
            "486/486 [==============================] - 9s 18ms/step - loss: 0.1332 - accuracy: 0.9497 - val_loss: 0.6738 - val_accuracy: 0.8354\n",
            "Epoch 497/500\n",
            "486/486 [==============================] - 9s 18ms/step - loss: 0.1490 - accuracy: 0.9471 - val_loss: 0.5976 - val_accuracy: 0.8272\n",
            "Epoch 498/500\n",
            "486/486 [==============================] - 9s 18ms/step - loss: 0.1406 - accuracy: 0.9521 - val_loss: 0.6726 - val_accuracy: 0.8189\n",
            "Epoch 499/500\n",
            "486/486 [==============================] - 9s 18ms/step - loss: 0.1535 - accuracy: 0.9461 - val_loss: 0.6915 - val_accuracy: 0.8230\n",
            "Epoch 500/500\n",
            "486/486 [==============================] - 9s 18ms/step - loss: 0.1431 - accuracy: 0.9498 - val_loss: 0.6510 - val_accuracy: 0.8148\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ava_acc=np.mean(cnnhistory.history['accuracy']) # numpy assumed imported as np\n",
        "print(ava_acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fu7omyRcaIN3",
        "outputId": "9de8c724-6f46-44b0-db2d-01e7fe65f330"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8582427906692028\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(cnnhistory.history['loss'])\n",
        "plt.plot(cnnhistory.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'valid'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "oQYnuaCrDH_A",
        "outputId": "9a674819-7dc3-4f7b-b41c-67565cf3abcc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(cnnhistory.history['accuracy'])\n",
        "plt.plot(cnnhistory.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'valid'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "IFkTuO8nDNdq",
        "outputId": "fd4a2fc2-e1c7-4477-f279-e3d5863a3873"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdd3zU9f3A8dc7ew9CSCCBhD1lyHArblFB60LUto66qdsWqz9rrV3WarVVW7VaNyKOoqIoiogKyhAZssJMgIQMErLn5/fH5y73veQSIuRIyL2fj0ced/cd9/3cJfm8P/srxhiUUkoFrqCOToBSSqmOpYFAKaUCnAYCpZQKcBoIlFIqwGkgUEqpAKeBQCmlApwGAhVQROS/IvJQG4/dJiKn+TtNSnU0DQRKKRXgNBAodRgSkZCOToPqOjQQqE7H1SRzt4isEpFyEfmPiKSIyIciUioi80Uk0XH8FBFZKyLFIvK5iAx17BsjIitc570BRDS51rkistJ17tciMrKNaTxHRL4TkX0iki0iDzTZf7zr/Ypd+690bY8Ukb+JyHYRKRGRL13bJopIjo/v4TTX8wdEZLaIvCIi+4ArRWSCiCx2XWO3iPxTRMIc5w8XkU9EpEhE8kTkNyKSKiIVIpLkOO5IEckXkdC2fHbV9WggUJ3VhcDpwCBgMvAh8BsgGft3ewuAiAwCXgduc+2bC7wnImGuTPFd4GWgG/Cm631xnTsGeB64HkgC/g3MEZHwNqSvHPgZkACcA9woIue73jfDld5/uNI0GljpOu8RYCxwrCtNvwIa2vidnAfMdl3zVaAeuB3oDhwDnArc5EpDLDAf+AjoBQwAPjXG5AKfA5c43venwExjTG0b06G6GA0EqrP6hzEmzxizE1gEfGOM+c4YUwW8A4xxHTcV+MAY84krI3sEiMRmtEcDocDfjTG1xpjZwFLHNa4D/m2M+cYYU2+MeRGodp3XKmPM58aY1caYBmPMKmwwOsm1+zJgvjHmddd1C40xK0UkCLgauNUYs9N1za+NMdVt/E4WG2PedV2z0hiz3BizxBhTZ4zZhg1k7jScC+QaY/5mjKkyxpQaY75x7XsRuAJARIKBadhgqQKUBgLVWeU5nlf6eB3jet4L2O7eYYxpALKBNNe+ncZ7ZcXtjucZwJ2uppViESkGervOa5WIHCUiC1xNKiXADdiSOa732OzjtO7Ypilf+9oiu0kaBonI+yKS62ou+mMb0gDwP2CYiPTF1rpKjDHfHmCaVBeggUAd7nZhM3QARESwmeBOYDeQ5trm1sfxPBv4gzEmwfETZYx5vQ3XfQ2YA/Q2xsQD/wLc18kG+vs4pwCoamFfORDl+BzB2GYlp6ZLBT8NrAcGGmPisE1nzjT085VwV61qFrZW8FO0NhDwNBCow90s4BwROdXV2Xkntnnna2AxUAfcIiKhInIBMMFx7rPADa7SvYhItKsTOLYN140FiowxVSIyAdsc5PYqcJqIXCIiISKSJCKjXbWV54FHRaSXiASLyDGuPomNQITr+qHAfcD++ipigX1AmYgMAW507Hsf6Ckit4lIuIjEishRjv0vAVcCU9BAEPA0EKjDmjFmA7Zk+w9siXsyMNkYU2OMqQEuwGZ4Rdj+hLcd5y4DrgX+CewFslzHtsVNwIMiUgrcjw1I7vfdAZyNDUpF2I7iUa7ddwGrsX0VRcBfgCBjTInrPZ/D1mbKAa9RRD7chQ1Apdig9oYjDaXYZp/JQC6wCTjZsf8rbCf1CmOMs7lMBSDRG9MoFZhE5DPgNWPMcx2dFtWxNBAoFYBEZDzwCbaPo7Sj06M6ljYNKRVgRORF7ByD2zQIKNAagVJKBTytESilVIA77Bau6t69u8nMzOzoZCil1GFl+fLlBcaYpnNTgMMwEGRmZrJs2bKOToZSSh1WRKTFYcLaNKSUUgFOA4FSSgU4DQRKKRXgDrs+Al9qa2vJycmhqqqqo5PidxEREaSnpxMaqvcQUUq1jy4RCHJycoiNjSUzMxPvhSa7FmMMhYWF5OTk0Ldv345OjlKqi+gSTUNVVVUkJSV16SAAICIkJSUFRM1HKXXodIlAAHT5IOAWKJ9TKXXodJlAoJRSh6uNeaV8uamgw66vgaAdFBcX89RTT/3o884++2yKi4v9kCKlVGdgjKGwrOVbUi/alE9JZS1nPPYFV/znG/7wwQ+s2VnC3vIa5q3NpaHBYIxh7a4Sv6azS3QWdzR3ILjpppu8ttfV1RES0vJXPHfuXH8nTanDRll1HRty9zE2o9uPPre2voFgEYKCDrzptLiiBmMgJiKEtbv2Mbp3QuM+YwwllbUkRIVhjCFnbyVPL9zMTRP7k5YQyTvf7WTWsmxiwkPZU1rFT8akMbp3At9uLeJPH65nRFoc008ewOb8cjKS7B1JtxdW8Nd5G+gWHdZ4nWcXbeXZRVsbXydFh1FYXtP4+uVrJnDCQJ+rRBwUDQTtYMaMGWzevJnRo0cTGhpKREQEiYmJrF+/no0bN3L++eeTnZ1NVVUVt956K9dddx3gWS6jrKyMSZMmcfzxx/P111+TlpbG//73PyIjIzv4kyl16Nz/vzW8vWInz/5sHP2To+nbPRpjIChIMMawdNteukWH8vxX27jy2ExKq+r4bH0eK7YXU1xZS4/YcG4/fRAPvreW6PAQxmV048pjM/nde2s5Y3gKqfGRfLouj+2FFdw4sT8vLd7Gt1uL6N0tih1FFWzJLwfglCE9+Gz9HoakxjKhbzeWbtvLut37AOiXHE11bQM7iysBeO2bHY3pDw8JorquAYBVOd4l+NKqOm54ZYXPz13kyOgBhveKY1xGIut2l7KvqtYrEAT5qY/wsFuGety4cabpWkPr1q1j6NChAPzuvbX8sGtfu15zWK84fjt5eIv7t23bxrnnnsuaNWv4/PPPOeecc1izZk3jEM+ioiK6detGZWUl48ePZ+HChSQlJXkFggEDBrBs2TJGjx7NJZdcwpQpU7jiiit8Xs/5eZXqCBU1dbz//W6mjO5FRGhwi8cZY5i3NpenP9/M3y4ZTXR4MNOeWUJm92jG9klkbGYipVV1rMwu5unPNzeeFxwkDEqJJTMpisLyGr7dWuSXzzGqdwKrc4ppaCUbDBIa9yfHhlPfYLwy77SESEamx/PY1NEs376X3JIqkmLCyNlbSUllLZeO783O4kqm/PMrACaP6kVGtyjiI0M5d1RPXl68nW7RYTz0wTomjUjl6SvGel3/03V5rMwuJiI0mJtPHnDAn1VElhtjxvnapzUCP5gwYYLXOP8nnniCd955B4Ds7Gw2bdpEUlKS1zl9+/Zl9OjRAIwdO5Zt27YdsvSqwLF8exFHpCUQGiz858utnDk8ld7doryOKa+uY8GGPZw6JIWq2nqiwoOpqWvgi40FZO0p45QhPbh79veszy2lrLqOgSkxfLpuD8UVNfzpgpGsz93HvxZuZv66PdQ7ctjTHl3IsJ5xbCusYFthBZ9vyPeZxgE9YsjaU8a63fsaS+IAJw9OprymnoxuUWTvrWDJFhsc+nWP5qrjMkGE/3t3TePxL149gZ8//y0Ag1Ji2JhX5nWdkwYl88KV48ndV8XbK3KYtSyHc0b25KRBydTWN7C1oJzBKbGMzUjkj3PXc/6YXoxM9zQXfbY+j4/W5PLnC0Y2NkkdN6C7z8/ULTqMaRP6cOqQHpw2LMVr36/OGtKYnqa/C4BTh6Zw6tCUZtvbU5cLBK2V3A+V6Ojoxueff/458+fPZ/HixURFRTFx4kSf8wDCw8MbnwcHB1NZWXlI0qo6p9ySKr7YmM/F49K9hgwXlFUTFxFKWEjzcR519Q3UG8OOwgoGpsRSU9fA6p3FjM3oxpIthQgw9ZklXDw2nVOG9OChD9bx0AfrOHdkT35/3ggSo8OorW/gxldX8MXGfOIjQymrruO0oT3YW17Lt9tsxvvY/I24k/Tg+z94paGsuo6vsgoJCZLGIHDcgCRCg4P4fEM+63I9GXtaQiQ7iysZn5nIk5cfyb8XbuGnR2eQEBXK6Ac/YUhqLABXHJ1BZlI0xw3wniu0ZmcJMeEhZHb3/L/1jIvgo7W59E6M4qRBycyYNIS6+gZuPnkAFTX11NY3EB8Z6vU+vRIimX7KQKafMtDrszjb4u+fPKzZ933KkBROGdK2DFpE+NMFR7R6zMCU2Da9lz90uUDQEWJjYykt9X3Hv5KSEhITE4mKimL9+vUsWbLkEKdOHY5ueGU5K7OLGdU7obGEPGtZNv/5ciunDU3hjOEpLN1aRGxEKIlRoXSLCeMPH6yjoqYegCcvO5IlWwp5ecl27j5zMH+dt6Hxvd9cnsOby3MaX7+/ajfz1uYyODUWY2Dtrn1MP3kAWwvK+WD1buatzQNsibWwvJrq2gYemzqajXml3DHrexKiQjkiLZ7a+gbmr9sDwKJfnUxheQ15+6o4c3gq5dV17KuqJT4ylCARQoODEODlJds5d2RPkmLC+b9zPZntZ3eeRFpiJOEhLTc7jUiLb7bttGEpXiXuG07q3/g8Olyzu5boN9MOkpKSOO644xgxYgSRkZGkpHj+EM866yz+9a9/MXToUAYPHszRRx/dgSlVnUFNXQPXvLiUyyb04Yj0eNbvLuW0YSks2LCHIBGSosNYmW2HFX+0Jpfa+gb+uSCr8fz56/KYvy6v2fs6+xFvfs3TMekMAm6Xju/NmD4JnDY0hZ89/y1rd+1jzc59hAUH8cDkYVx5nG3afLSunhe+2kZiVChTx/fBGNPYgTsiLZ5BKbH0drV376uq5a8fbaB3t0h6d4vyauaIDg/xmRH//NhMn99Rv+SY1r9E1a66XGdxIAi0z3u4WL69iL7dY7yGAwL8ce46hvaMZfLIXnyfU8wVz31LZW09iVGhRIYGs6ukeVNhcJAQFhxETX2DVzu7L+7j5kw/jh1FFYQGB3HTqysYkhpLVW09m/PLueuMQXz8Qx4XjU1nTO9Ejkj3lKa3F5azrbCCQSkxBImQEhfRPl+I6lS0s1ipdmKMIW9fNSWVtSRGh9Ij1maaa3aWcOHTi+kZH8Gtpw5k7a59VNXWEx0ewn+/3gbAfe+sodzVdAOwt6KWvdQ2u8blR/Xh7CN6MjI9numvfcfCjZ5O1SmjevHXi0dSXddASUUtvbtFkbevim+3FjEyPaGxM3PVb88gKiyY7KJKKmrrGJIa16wN3C0jKZqMpGif+1Rg0ECgFLajNWdvZWPHY32DQQADrMopZkyfRAB+O2ctLy323PHvxon9+XD1brYVVgCwu6SKGW+v9nmN8pp6rjuxHxMHJZOeGMXPnv+GtMRIXrxqAgPu/RCAzX88m2DHpKj/XjWe4opaQkOCCBYhMsy2mYeHBBMXYZciT4mLYPKoXl7XcjfD9ElqPgpFqaY0EKiAVFBWTfcYz0itB95by8xvs1n065PpGR/J2Y8vIiwkiIjQIJZu28u/rhjLxz/k8vaKnXSLDmscR+4c+54aF0F5TR2x4SHcc/ZQ1u7ax+LNBeTtqyZ3XxVPTBvDFEeGveCuiY3t7fdMGkJFTb1XEAA72iSxSVOTUu3Nr4FARM4CHgeCgeeMMX9usj8DeB5IBoqAK4wxOc3eSKkDVF1XT7AIIcFBVNbU87v31mIMvLEsG4BbTh3IuIxEXlliZ4ge86fPfL7PDa8sb3z+7k3H0btbJKt3lpCWEEn23krOf/Ir/njBCK/hhO5SujGGDXmlDEmN83pPEWns4L3eMbpFqUPNb4FARIKBJ4HTgRxgqYjMMcY4Bx4/ArxkjHlRRE4B/gT81F9pUl1XdV09ghAWEsTqnBKiwoN5a3kOT32+mUkjUrl4XDo791Yyc2m213lPfLoJsGPaU+LCWbGj+SKA/7piLPe9u4a0hAjeuP6Yxpm07vb4pJhw1vzuTGJaGJ4oIs2CgFKdiT9rBBOALGPMFgARmQmcBzgDwTDgDtfzBcC7fkyP6qLqGwxnPPYFu4urOHFQcrOhlR+uyeXDNbmNr+84fRDXntCPiNAgrn1pOfPX5XHWiFR+c/ZQBKipb6Cqtp7rXlrOg+cPZ0hqHGcOT2n1XhAtBQGlDgf+XIY6DXAWv3Jc25y+By5wPf8JECsiSU2OQUSuE5FlIrIsP9/3tPTDSUyMHSO9a9cuLrroIp/HTJw4kabDZAPRx2tzeW7RFgAe/XgDZz72BcY1e7aovIYXvtrKwx+tZ3thBScN9g4CZwxL4eaTbZOLezjmvWcP5ZZTBxIZFoyIcMfpg+gVH8FlR/UhOMiuXhkRGkxCVBizbjimsSSvNwRSXVlHF2PuAv4pIlcCXwA7gfqmBxljngGeATuP4FAm0J969erF7NmzOzoZndp1L9u2+YEpsTzxmZ1U9cjHG3hywWav47rHhPGPaWO4/uXlLNyYz/L7TiMpJhxjDCcMTGZcRiLBQdIsQx/WK46v7zn10HwYpTopfwaCnUBvx+t017ZGxphduGoEIhIDXGiMOezu1DJjxgx69+7NzTffDMADDzxASEgICxYsYO/evdTW1vLQQw9x3nnneZ3nXLW0srKSq666iu+//54hQ4Z0+bWG3v1uJ7e9sdKrbf3JBVl8vbmAJy4dQ229oca1pC/QuHiYPc4TBF6/9miGpMYSERpMRGgwz/xsLNsKKkhyjQgSEY7u16ySqZRy8GcgWAoMFJG+2ABwKXCZ8wAR6Q4UGWMagHuwI4gOzoczINf3OO4DlnoETPpzi7unTp3Kbbfd1hgIZs2axbx587jllluIi4ujoKCAo48+milTprTYxPD0008TFRXFunXrWLVqFUceeWT7foZOpKSiltveWAnAvz7fzLUn9GNd7r7GpRDGPjTf6/iTBiWzcGM+4SFBPH7p6MZ13d2lfqfwkGAGp3bc4l1KHY78FgiMMXUiMh2Yhx0++rwxZq2IPAgsM8bMASYCfxIRg20autlf6fGnMWPGsGfPHnbt2kV+fj6JiYmkpqZy++2388UXXxAUFMTOnTvJy8sjNTXV53t88cUX3HLLLQCMHDmSkSNHHsqPcEhd+qxn4b1/LshqXEfHOT4/LiKEC12rZB7bvzu7iitJT4xERHj7pmOJCAluFgSUUgfGr30Expi5wNwm2+53PJ8NtG8jeSsld3+6+OKLmT17Nrm5uUydOpVXX32V/Px8li9fTmhoKJmZmT6Xn+7KckuqqGtoYOHGfD5cnctU10JnzjXmARKjQpnQtxt3njGY+gbD2ytyuP30QUSFef48nQuYHema5auUah8d3VncZUydOpVrr72WgoICFi5cyKxZs+jRowehoaEsWLCA7du3t3r+iSeeyGuvvcYpp5zCmjVrWLVq1SFKefspq67jg1W7OLJPIpndo5n6zGK2u5ZeAPgyq6DxeWx4CKXVdfTtHs2nd5zkda/Ze89pvva7Usp/NBC0k+HDh1NaWkpaWho9e/bk8ssvZ/LkyRxxxBGMGzeOIUOGtHr+jTfeyFVXXcXQoUMZOnQoY8eObfX4zublxdv4v/+tBexQzf7J0V5B4KnLj6SgrJq6ekN9g+Fnx2ZQW28ICTq4G44rpQ6eLkN9GOqMnzdzxgeNz4ekxrK9sIK7zxzMlNG92FpQzvjMbh2YOqWULkOt2t1XWQWkxkfw36+2sXZXSeP26LBg3vvl8VTU1BMfaVfH7K6dukp1ahoIVKuyiypIjg0nIjSYrQXl1NQ18MvXV7AxrwwRaFqhrK03hAYHER/pz0nrSqn21GUCgTEmIJYBOJRNeaVVtZzw8AJOH5bC0f2S+L3jRuU/OyaD73YUExIsnDuyV+O+v10y6pClT7Wz2iqYeyec8n8Q63uY80Fb/l8IjYKRl/jn/Tubws3w9RNw9t8guJXsdv0HULARjr/90KXNoUsEgoiICAoLC0lKSurSwcAYQ2FhIRER/rmVYEODQcTOxi2uqOG0R78A4JMf8vjkB7uGT3piJKcPS+G3k4cDdsG3ILH9Asf0S2qfjt9170NtJYy8+ODfqzOoKoHPHoJTfwvhnfhevJs+hu9egZoKuPiFg3uvpc9B0gDoN9F7+3u32seWAsGy5yGhDww47eCu78vGj6EsF478mWdbXTV88ls48W6I9sMM9NenQcEGOOoG6OHq19v9vf2uT7zbc9xM11zbY37ZesDwky4RCNLT08nJyaErLEi3PxEREaSnp/vlvS94+mv6dIvi4YtGcu87aygoqwbsKKB+3aPpmRDJi1eN9wq27hupHDege/sl5I3L7WNXCQRfPgbfPmMzxqOu/3HnGgNfPQ6DJ0HyYM/2nStg2yI47tb2SeNXT2Dvx4YNXAfrgzvt4y0rYc1sOOEuaKjzPqahAb54GMZeaWsgDQ3wvqtE/EAraWhogEWPwOjLIH4//wvuaxz5c3jN9ffkDATr34dvnobi7ZAyAibOgKDgtn3G3NWwYwlMuLblYwrtZEmqyzzbnjsd6qvhmOkQGmmDr1vBRkhxDZ/e8CEgMPistqXnIHSJQBAaGkrfvn07OhmHtT37qliZXczK7GLmfL8LgImDk7n37KH0T47pfEM8c9fYf8TR0zo6Jb5Vl8K3z9qMutw9f6IN3+Gat6Bbf4jqZjOCfhNh/m9thvUL19Ib9bXw7Mn2+ZifwvczYcQFULwD9u2C4ef/uLSW5sIn/+d5XVvR8rFNVRTBdy/bkmyQj36hOb+0AWvwORDsuNOaMZCzFD7/E+z6Di57A/Zubds1c76FBX+w5017HfZugx/mwLG/BGeLQFUJ/G86rJtjr+W8tvu4Btd6Vhvm2p/eR8FAR21k7bsQ1wvi0mDt25B5AuSvh1GXwn/OhNpyGHOFzdB9Ma41NCv3erbV2wIWZXmQmAn/cyyokLvKEwhev9Q+thYU20mXCATq4C3eUgjAiLQ4thVUcM/ZQ5g2vk/bAkDWpxCdDD39uCxG1qcQlQS9RtvXz50GdZUw/CcQ2samsoYGWPYf2ywREX9w6dn4McSmQM8W+kQ+/T18+2/o1g9qXKXB6hb+ode+azPfuDSYfbX3vuNus49hMfDNMzDmcpvZu61+E+bdY3/chrcx49i3CzZ+BLHe9ztuTG/TY7d8bkvhTu/fDj+8C9u+gqGT4cifQl2NZ3+DKyOcM91m1G5VJZ6AU1NuM/Vlruao4DAoL7QZeEMdjL4cwhz3XnaXsoNDbab+uOt3cMTFENfTc9z8B+x7AFQ61rKs3GsD7apZNng6NdR6v37z5/YxZQTkrfFsHzzJk/6irTbzrq2yfSDjr7Fpq3fUgCqLaKbUFQic3J/NafVsOML3cvXtRQNBgFu3ex+PzNvA0m1FpCVE8u5NxxEkP3KS1yuuW0q0d8llzVsw4kLf16hzrc66Zy0UbILBZ0PEfu4CtuNrmHuXbVb5ydN2W30trHoDRk1re5NAXQ3MvgoGnAqXvOTZXlNu+zdGXmJLewArX7MlVrD/+G4//M8GkY0fw4eOtuKm1r1nH7cssD/F223p3y3r0+bnNNT7/iy7VkJ9jc0ICzbZx0WPQHKTOSk1FZC9FLYuhHFX20zz1YttRjjgdIhJtsflb7RBAGDTPPsT18tewy3ENXR453L47A+e7WV5ttYENtN8ZqJnX1wavHW1DTxgP/MZD9nvcdWbkO1aqyoy0Tsolud7AsHe7fa7b+QYZPHNv+Dom+DtayE02vuz11V7f49uziAAsHmBvX5lERRttoHg6ydsTaW+2n6GgWd4jnfWCBq/g1xX7STY1hxXvOioPTq8dQ30PRFiejTf1040EASgqtp6Vmzfy9/nb+LbbbakcvyA7txz9hBCgv087LOhwZbShk6x1fO179iSZLCdc+BVipp9NQw5F4Icf6ZV+2wGERRqS2+LHrXNJkffBGf9yR6zYwlEdYfuA2zmFxYN3QfaJhCwVXu3JU/BJ/eDBHlKu5s+sZl0S/94O762peaKItskUbwd+p0MS5+1JcKEPp7McNM8z3kFG23G3/dEmPUzn2/dTJH3fRco2+PJQMF2OjZVUWjTvuFDWxLuN9Fe+6Up3sfFuEYG5a/z3l5TDh/fC9nf2Ncn3uXJCD++F8b/AnqNgSfHN7/2Kxd4v96ywPO8cJPn+fczPcFq5wrvc+prIG+t57X79/bl32G5oxO7qsR2vDZ+7gLP+7mbztx2eu45zcK/QC/X6r615d7HVe61JfvNn8G+nbRo2yJPICjcbH8vS56y+z5xLaf2C0eQriiyQdsZXErzbGHH1EN4rK1Vb/zINimOucL7eps+sbVBP9FAEEBeWryNqtp6XvtmB9scyz+8du1RHNv/ADt762ubb8v6FPqeZNt8TYN3J+d3L8N7t8C5f4eYFFuyPvFXcMq9kDXfVsGdVr0B/U/xvF75Gnz0a8/r9e/bx4pC2PCRHXHx5tUQ3R1uWgLPnGT335tr/8HAOyN1l9bdTQfbv4ZXL7LNEec/1fyzFW2FRX+zz3NXwyzXLbbj0mwGClBV7F0qdtu60P6c+cfm+5oaNQ2+f933PnfHY0SCvZZb5gk2gyrNhexvPZ3uLSnLhbh0G1D7ngSrZ9ntlUWe4LvpExg51XPOqjdcNajLmr9fS0ZcBEVbYNcKmwHvWgFfPurZX9XkFiTVpd4l8x1LbFORM9MHW3r+6u+O14X2p2kQ8MUZoJ1Wv2nTt8JR07vkJVtw+V2CZ9uqWVDtWjxx71Z477bmpf5Pf+d5/sXDza/17TOe4Bgeawsv+ettrbVp0+WSp22zaMrw/X+2A6CBIAB8tj6Poqzl/PnLSiqw7ek/OyaDwfH1pEph24PAnnV2dEdkoq3S7lhsR8I4bfgIXp9qq/ILH7b/LDOyPc027lJb0RbPP9L2r22G8+pFtvPTac4vbWnfbVeT0qObO4Nyqy6Bd2/0vF7+oqdJoWgzbFloS7XbF7uOd6XFnQGYBpummBQoybFtuXVVtiRf4roDqzsDG36B7Uh0q9rnnZGBHanifu95v7GPl8+2JcClzzX/PEf+3BMI3LUfsKVgdyDrOcoGFreeo2wgWP5f2xfSFoPPgkl/hW1feAJBfQ3sy7HPs5fA30c0P+/715pv6znKO7MefTmsfNWWrDOPt7+7kZdAxrGw+J8tp6nae3VaSrJtGpp2Ym9bZB8TMmytrCZqUqMAACAASURBVKLA01S1Pxt91KQAtn9lf5xie9raa59jbW0waYB3W/72xXaIaFNbv2g9Dc4aUngsRDoCzTf/9j42bzU8fSz8tti7Q7yd6PTPLm7FqlXc+995XLRsGq+FPUS/yApuP20QD543gsu3/JpTF/zE0xxTnO27LdPtqaPhP652z6//AS9MgjWODNAY2OOadLb9a88/9AbXSuR71nlGjtRVwW7XCqs7l9kMA7ybbdyWOErmWxZCZDdbYo1qJYDF9rTDFt3KHO3zpsE2k7x4rqdZpDDLZvzuZorsb21g+vcJMHMaPH2MLWm6g0CUa8x5XJr3eHCwJe2yPZ7Xt62Bcx+HuzfDZW96tif1t5nw4HO8z79jHWQc43nd90TP85IcTyBoWjrs6epId2eQ0LwNvKnug+xon/jezfedeLetMQSFwMUvQkikHVUzvYV7aUc3aUo7wjVcc9BZcPqDcNcmO57+zD94B3enljrx3UEgrMlNhzKOh5u/te3s5QW+O1udfvGZDazuQNeSOx0Ze0yKffzZ/+BXW+2EOyd3EJj8uOczNxUcDpOfsM9v+BLuzYM7HH/r4bH2f8Jtp+M7HjrZca2Nraf7AGkg6IJq6xv4cPVusvaUceTbJ7A4wo7WGB20hfncwK2nDbQH7nCVhktcIyf+PgKePMr3m7qDRcFGW1V3l7ycJcCCjZ4Md4PjNhSlubBvtw0kH99nt+Wvt+22qSPtP8Dad1zv4Sgl+VKWaztpf7XVlizBM/Ji7JWe4y57w/u8nKU2I7vpG882Z9pXv2kzfvc/tbNtvmnAOfV+T0aWmGk7Cs91NFEUZ3sCBtgO1KAg21w1wHF/5Lg0u9097DLY1bHqznhiUm3QG3Wp55yiLXb4JNimICf3qC1nZnHLdzbza0m/kz1pbKr7IJj+rQ1Mw8+HX2+FKz+w/S0AKUfAb3ZBSIQd1eQcHgr2u7lnJxx7iy3FxvTwlGYzjmt+vZPvs5PuwH7upi54Doae671t3FV21FhUku043rHENi/OyIbf7LZNgvfm2nTckwPpY+1ILqem6b4nx9Z8x7lGcLl/HyFhtuN82Hlw0gzvcwZNsrW485+238kvHTXXK96Ce7Jh7M9hxg57x8PQCO8RTmExnvkb3fp7tp/7GEx9BW5w1VJ89Qm1A78GAhE5S0Q2iEiWiMzwsb+PiCwQke9EZJWInO3P9ASKd79ew22vLuHsR+c32xdkHJ2xQa4O2sItnm1lebZja/cqWzouc03Sc1bXnz/T0/nm7IR7coIdkdFUhY+S2tYvbNvqkHPsZCOwpVd3c8ulTZoezn7E8zxpoG1qcmeEF70A1y+Cs/7i6WRLGgDhjlFE2xZBYoZ3fwXYzuimJXK3iHj49TZbkr17sw0kYPss3DWCSNdNcpyl83XveTdjOEfwBAV7Rum4R9T0dfVjXP2hDXDu42/+Bu74wbax3/g1XPgfO1pqtatWMXiSLbm6P3NCn+ZDQWNTIM3VMdo0cIAnU3eOg3eXymN62I52d6d5aKSnU39GNlzzsd1/92a4a2PzGbER8XYmta/5BUPOsX04TdPq/p25hwm73bHee4Khu2bg7j+K62Wbq3atsNeNiLNDTkMj7U94jC11A6S6mrrcv8+mf2vu485+BO7e0nx4sjgmeYnrs2UcY7cHh9rvJNpReIhI9PyuW6rxhMd6ZmFf8ZZnu7tDP3UEXDkXxrcyee0g+C0QiEgw8CQwCRgGTBORpnccuQ+YZYwZg72nsY/eOdUWVbX1vLJkO49+vIGLPz2B2WEPMFBaGPVQXWo7Nt0dgkWbvdu0H+5rm0SePRmedzUFNW23dfPVNtpUeWHL95HuOQpOuc+WOsdd5dk+qMlsSmeV291UMuFaO3M17UhbGg6NsCXz29bYf8amY69jUuw/662OmkDfkyBtjO+0pY60Gb27ND99KVz/he1bcM+SdQcC5wzXslxPJuPLtZ/CnY5S+/hfuD7HWFvidItMsJlYUJANNIMneb+PiC25nvMY3P6DPdZdyjxmuucaIjYjvWyW59zpy2wG7qu9efwv7GNsz+b73NwZLdhMNizatqGD57OHx/o+152mHkO9g3B9rWdYsLOZ6c4Nns+V7lpF+dJX7Gd2f1/Opqb9dajGpbnOudH+LQw83X4/d26wgdgtKLjlZSd6jbHnnv1X+zqtyf1DwhxLibQ02cwpPM7WMm5bDd36Qnwf13bHd5h5XNvnzPxI/uwsngBkGWO2AIjITOA84AfHMQZwF9vigV2oH23mtzuY8bbNaIUG7oiAI4K28UH4b3yf8Kcm0/KLtthagFNwmJ2stWqWHTdfUXjgCfz+Nfi+hX09R9lMIa6XrYov/qddZ6bpOPjIBFsTKNwE6a5hiyL2n8Yr3aGQ4GrvnvQwTLjejpVf/abnHzIx0zX0b68NIM5RRODY12SyWEJvz3u7F2Xr7WpKczcfJGbamklCb1uaazpBCWymGeZou/f1OXwJi4ZrPoH/nO69PSQM4l2Zmzug9znGlrDd3BlpxnG2MzQx01O6d7tzgy0cRHazHeBNa0/7c9T10PcE27RRvKP5+/ty4XN27P3if7qG3bq+r4xj4PTf2VqrMzMed439bE0z+1FTPTUfX81cTr1cgb/7IE+zYlwrQa8liZkw9mrf6XH+/bYWCILD7byD8Bhbo0pwBYCIeCjBNrsdAv4MBGmAo6GUHKBpA/QDwMci8ksgGvC50pSIXAdcB9CnT592T+jhzh0EAOL4EcsDuJXtad5JHB5rmxJWvQGbP/VMd3cafLbtC4hKsu2YH9/n3VTUmhsX24XlnP+0Sf1tR5q7xDZ9uR3B4i4FXf2RDVhtXZQrOBR6DLEzWle/aYdbusWk2CGjKSM8wz6H/8R2Zm5dBAseannWMNgmpas/ht4T7OugYNvUEdfr4Gctt8Z9vZb0HG3H/Kf6GOkDtlawd6vvTNq54mhL57dGxJMhJg9q2zlhUXaE2bDz7GczxvO9+qqtOK/RlLuZa3+G/8T+nnq30B/2Y7hra60JjWp5X8axdq6FswYBNhDmrW5bbaIddPTw0WnAf40xfxORY4CXRWSEMabBeZAx5hngGbB3KOuAdHZaTZelnjIgzIbcIy62E6RMAyQPgcda+WOtKPBMgY9OtjM0wdPc4QwCp/7WzordvRKGnW8DQXCY/YNOHtJyIDjp17a0415XJaVpK6FL6hGe592bDE2N7u7d9tpWPUfZzMU51DUuzWY64TH256qPbOYXHgv5ruaunqN9vx+4hhM2yUjcq0t2pLMftr/3pksXuIXHeH/HnYGIJ8D5+l79cb0+R/v3Gk6tZeaXvGRH0zVdlfaMP9jCxoEE5APgz0CwE3COSUt3bXO6BjgLwBizWEQigO7AHlSrjDH8+4stJDvu/nXFEdH8fpNros/oy7wnYg051zP5CmwHa3CYHW9emuepERxzs12jBXwPKRx2nh0Tn7fWU411TwKb9Bc78eata5qvVzP+WluSdy6wdSg1zVzO+rNn8S/wHq55xEW2xtDWUu2hdtOS5ncEcguLtm3JqvNoLRBExPkOfCFh0O8k/6Wp6eX8+N5LgYEi0hcbAC4Fmk5H3AGcCvxXRIYCEUDXX0v6x1o1y66ZfvuaxrbHtbv28ecP7Tjk7jFhvHt+JOmzHR1vTYc8nvekHYO+e6UtDbvXq9n0sZ1O/4Zr5EkPR0nd3e7sFB5nS+XuP9KLXvCMdgiPtaMpbvwK8n6wwSDjWLtSqHt9ms6itUw+LPqQLP17wDpDzUO1XVv6SjqY3wKBMaZORKYD84Bg4HljzFoReRBYZoyZA9wJPCsit2M7jq80h/IWXJ1d3g+2WaZ4u32duxrev53H5TIe22zb1uMp4/O4J4j5tMmaKU2bUCIT7DDD3Su92yObHufuIIzrZUsyFzxnq+2Pu8aoN13YbUSTtWXANks4myacI2ouf+vAOuaUUn7j1z4CY8xcYG6Tbfc7nv8AaD22Je4bZrjUfPlPwnat4KSGYh7jIW4+uT+39FpP+Ftrmp8b5WPYmzsAOEesuCcxDZpkm5ISM+Gcv3mGbza9OUzIQd6IfqDP8QBKqQ7U0Z3FqjXuMeouQWvfAoFSE8X3vR8lrm4MUuEYKREWY5ezDY/znWG7A4AzELhXXxx4mmf8uPvR6fpF3tPelVKtu2Z+89VjOykNBJ3V1i/sLQodPmsYwxnByzkheI3tSclvsh7J0Td7d3q2xNk0dOytdp7A6P2sVNlzpH9vPKNUV9N7vP05DOhaQ53Vi5O9Xn4Vcya9bniHhgGumb5BId7LA099Zf9BoNY1a9M5VC06CSb9+ZCNV1ZKdT5aIzhMRMcnMSItHuJck35SRsAFz9hJNL76A3wZco6dMXr67/2XUKXUYUcDwWFiaJRrMTb3HY76TbSPTZdAbk14DFz8wv6PU0oFFA0EncyybUW89eLf+ZNzY8ZxhJ/kWqFz9GV2HZcT7uiI5CmluiANBJ3FloXMWVfMvK+W8bfQp8G5zMpVjhG4mcfDle83O10ppQ6UBoJOwrx/GycU7mFKmF2a4bHaC7kteSly5M87OGVKqa5OA8GhVl8HWZ/YCVsisHe7vRnM3u0kSn3jYWeeehpyyvMdmFClVKDQQHCo7N1mlz1e8jSsmgkX/9cuh+taukGAHQ3J9AmySy0NG39Ki2+llFLtSQOBv+1cDj3HwONN1rZf+p9mh95WezNv/+EWQHzf3k8ppfxAA4E/7f4enj3FrsXf1LZF9sfh5ovObH5nLqWU8jMtdvqT+wYvC//ic/eOc17l9+aaxtenjm3hZi1KKeVHWiPwp6b3AW5i8twwBoaMhPpWD1NKKb/SGoE/lbd8j53xVU9RWVPPI79w3UxmyLmHKFFKKeVNA0F7amjwfl2ebxeH6+66G9Zwz01c8klgUGoMmT2T7Y3cL3zuECZUKaU8NBC0l9oqeGSgva0kwOrZ8OVj0FAHfV23dRx2ntcpd585xD5JGaarfyqlOoxfA4GInCUiG0QkS0Rm+Nj/mIisdP1sFJFif6bHr8rzoaLAEwhWvurZd+Yf4bJZVPU5sXHTtj+fw0mDOtl9fJVSAclvgUBEgoEngUnAMGCaiHgNizHG3G6MGW2MGQ38A3jbX+nxuypXDNu2CGoqIDTKsy8kDAadybysct/nKqVUB/JnjWACkGWM2WKMqQFmAue1cvw04HU/pse/qkrsY12VvbtY0VYIj4drFzQesmTr3g5KnFJKtcyfw0fTgGzH6xzgKF8HikgG0Bf4rIX91wHXAfTp06d9U9keZl8NFYWe16+77hx29M2QdiT1DYYXvtrK699mk5R6H3ddpiOElFKdR2fpLL4UmG2M8Tmi3hjzjDFmnDFmXHJyJ2xXX/MWbPncPnfeKGboZGrrG3jtm+089ME6APaknwE9hh76NCqlVAv8WSPYCfR2vE53bfPlUuBmP6bFf+prvV8fczP0PRHyN0DGMfzmze95c3lO4+7E6LBDnECllGqdPwPBUmCgiPTFBoBLgcuaHiQiQ4BEYLEf0+I/lc6BTmL7BfqeaH/AKwg8cvEozhyecogTqJRSrfNb05Axpg6YDswD1gGzjDFrReRBEZniOPRSYKYxxvgrLX5V6egADo/zWjV0X5WntvD784Zz0dh0YiNCD2XqlFJqv/y61pAxZi4wt8m2+5u8fsCfafC7Ssd6QuK96+usAgBmXnc0R/dLOoSJUkqpttNF5w6Wc2G5aNuRXVpVy33vrmHFjr3ERYQwNiOxgxKnlFL711lGDR2+3E1DEQkw9RUA/vbxRj5YtZvQoCCuODqD0GD9mpVSnZfWCA5GQwMsdS0Wd9sqiIgHYNn2Io7pn8TL1/icNqGUUp2KFlUPxqqZsGsFxPayHcVAeXUda3buY1ivuA5OnFJKtY0GggNVXQrzH4C0cXD7WhChuq6eEx+2S0qM6BXfselTSqk20qahA7XpEyjLgwv/0zhk9K3lOyksr+HckT05fZjOF1BKHR40EBwo99pCyYMBKK6o4cM1u+keE8Y/po1BRFo5WSmlOo82NQ2JyNsico6IaFOSm3vYaKQdGnruP75k0aYCBqXEahBQSh1W2pqxP4VdHmKTiPxZRAb7MU2dW1WJ7R+o3Gs7iINDydpTSs7eSgDCQjRWKqUOL21qGjLGzAfmi0g89r4B80UkG3gWeMUYU9vqG3QVdTXw5z6QPh669YPIBAA+W78HgMmjevHLUwZ0ZAqVUupHa3MfgYgkAVcAPwW+A14Fjgd+Dkz0R+I6nXVz7GPOUjuBLLIbAF9lFTKgRwz/mDamAxOnlFIHpq19BO8Ai4AoYLIxZoox5g1jzC+BGH8msFMp3Ox5vvt7iEyktKqWJVsKOX5A945Ll1JKHYS21gieMMYs8LXDGDOuHdPTuZU4brhWvgeiTuDDNblU1zVw3uheHZcupZQ6CG3t2RwmIgnuFyKSKCI3+SlNncu69+GBeNs5XJIDPUdDz1F2X1QSn/yQR1pCJKN7J7T+Pkop1Um1NRBca4xpvAOLMWYvcK1/ktTJuNcSyvoU9u2EhD4w9VU45f+oHnc9X2UVcMqQHjpkVCl12GprIAgWR04nIsFAYNxzsftA+/jWNVCwEeLTIaE3nHgXH+2KpKKmntN0FrFS6jDW1kDwEfCGiJwqIqcCr7u2tUpEzhKRDSKSJSIzWjjmEhH5QUTWishrbU/6IVK1z/v12CsBWLB+D7fOXElKXLh2FCulDmtt7Sz+NXA9cKPr9SfAc62d4Ko1PAmcDuQAS0VkjjHmB8cxA4F7gOOMMXtFpMePTL//Oe9ANuoySB5MVW099727huTYcJ6+YizBQdospJQ6fLV1QlkD8LTrp60mAFnGmC0AIjITOA/4wXHMtcCTrj4HjDF7fsT7HxrOexJH2KWlX1mynZ3Flbx+7dEc2UfvPqaUOry1KRC4Su5/AoYBEe7txph+rZyWBjjGW5IDNL1TyyDX+38FBAMPGGOaNTmJyHXAdQB9+vRpS5LbT0URDDzD3obyhDsBWJldTJ9uURzTX+9DrJQ6/LW1j+AFbG2gDjgZeAl4pR2uHwIMxM5MngY86xym6maMecYYM84YMy45ObkdLttGWfOhaLMdKXT+UxBjW66yiyrISIo6dOlQSik/amsgiDTGfAqIMWa7MeYB4Jz9nLMT6O14ne7a5pQDzDHG1BpjtgIbsYGhc3j1YvtYXeq1eXtRBb27aSBQSnUNbQ0E1a4lqDeJyHQR+Qn7X1piKTBQRPqKSBhwKTCnyTHv4lqnSES6Y5uKtrQ18X5lDODqBB59WePmkspaiitqydBAoJTqItoaCG7FrjN0CzAWu/jcz1s7wRhTB0wH5gHrgFnGmLUi8qCITHEdNg8oFJEfgAXA3caYwh//Mfxg7zYw9TD5ceg3sXHzrKW222O43opSKdVF7Lez2DUMdKox5i6gDLiqrW9ujJkLzG2y7X7HcwPc4frpXAo22cfkoY2bqmrrefLzLCYOTua4AdpRrJTqGvZbIzDG1GOXmw4sZbn2Ma5n46YP1+ymuKKW60/sr0tKKKW6jLZOKPtOROYAbwLl7o3GmLf9kqrOoDTPPsZ4lo/4dN0eesSGc3S/bh2UKKWUan9tDQQRQCFwimObAbpuICjLtfcjDgkHYE9pFQs35HPWiFStDSilupS2zixuc79Al1Ga61Ub+OdnWdTUN3Dtia3NoVNKqcNPW2cWv4CtAXgxxlzd7inqLMryvALBmp0ljO6dwKCU2A5MlFJKtb+2Dh99H/jA9fMpEIcdQdR1le1pDATGGDbllTE4VYOAUqrraWvT0FvO1yLyOvClX1LUWVQW2z4CYHdJFaXVdQzU2oBSqgtqa42gqYFA51syur00NED1Poi0yx5tyLNLTAzWQKCU6oLa2kdQincfQS72HgVdU3UJYCDCBoJNrkAwKGV/q2oopdThp61NQ4FVFK4qsY8RdhmJDbll9IgNJyEqMO7OqZQKLG1qGhKRn4hIvON1goic779kdbDKYvsYmYAxhlU5xTpaSCnVZbW1j+C3xpgS9wtjTDHwW/8kqRNw1QhMeBy3zFzJpj1lTB7Vcz8nKaXU4amtgcDXcW2dlXz4qbI1gvy6KN77fhcDe8TwkzHpHZwopZTyj7YGgmUi8qiI9Hf9PAos92fCOpSrRrCjIhSAB6YMJyzkQAdYKaVU59bW3O2XQA3wBjATqAJu9leiOlx5AQCby2ylJ7N7dEemRiml/Kqto4bKgRl+TkvnUF8Ly16AlCPI2msIDwmiZ1xER6dKKaX8pq2jhj5x3lReRBJFZJ7/ktWB8tZAyQ44/ja2FlaSkRRFUJCuNqqU6rra2jTU3TVSCABjzF7aMLNYRM4SkQ0ikiUizWoUInKliOSLyErXzy/annQ/2f29fUw7km2F5WQmabOQUqpra2sgaBCRPu4XIpKJj9VInVy3uHwSmAQMA6aJyDAfh75hjBnt+nmujenxn92rIDyO+vgMdhRW0Ff7B5RSXVxbh4DeC3wpIgsBAU4ArtvPOROALGPMFgARmQmcB/xwgGk9NAo3QfJgHv/U3n9AO4qVUl1dm2oExpiPgHHABuB14E6gcj+npQHZjtc5rm1NXSgiq0Rktoj09vVGInKdiCwTkWX5+fltSfKBK82D2FSe+CwLgGE94/x7PaWU6mBt7Sz+BfY+BHcCdwEvAw+0w/XfAzKNMSOBT4AXfR1kjHnGGDPOGDMuOTm5HS7birJc6qPtfQguGpvOqN4J+zlBKaUOb23tI7gVGA9sN8acDIwBils/hZ2As4Sf7trWyBhTaIypdr18DhjbxvT4R20lVJVQFmJvTj8hU29Sr5Tq+toaCKqMMVUAIhJujFkPDN7POUuBgSLSV0TCgEuBOc4DRMS5gM8UYF0b0+MfZXsA2BtkA0CPuPCOTI1SSh0Sbe0sznHNI3gX+ERE9gLbWzvBGFMnItOBeUAw8LwxZq2IPAgsM8bMAW4RkSlAHVAEXHmAn6N9lOUBsAfbHJQarxPJlFJdX1tnFv/E9fQBEVkAxAMfteG8ucDcJtvudzy/B7inzan1t9JcAHbWxQOGVJ1RrJQKAD96BVFjzEJ/JKRTcNUI1pdFERtRTXxkaAcnSCml/E+X1HQqzQUJ4ruCYIakxiKiS0sopbo+DQROZXmY6B6s21OhdyRTSgUMDQROZXnURiZTWlXHkFQNBEqpwKCBwKk0l1LXHILBqTqjWCkVGDQQuNVWQfEO8nAFAm0aUkoFCA0EbitegqpiPg89gdS4COKjdMSQUiowdN0b0P9YBRshIoH5VUPI7K7xUSkVODTHc6sqhsgEdpdU0SshsqNTo5RSh4wGAreqEkx4PHn7qkjTQKCUCiAaCNwqi6kOjaPBQM94DQRKqcChgcCtqoSKoBgAeiXoGkNKqcChgcCtqpjCOlsT0PsUK6UCiY4aAtj0CZTlkRUUQkZSFH26RXV0ipRS6pDRGgHAqxcBsKE4iBMHJutic0qpgKI1AoekhgJ6pcd3dDKUUuqQ8muNQETOEpENIpIlIjNaOe5CETEiMs6f6dmfd+qPZ3gvXWNIKRVY/BYIRCQYeBKYBAwDponIMB/HxQK3At/4Ky2tamgAhK/TrmaVDGZgD11jSCkVWPxZI5gAZBljthhjaoCZwHk+jvs98Begyo9paVlVMWDYVRNJemIkYSHabaKUCiz+zPXSgGzH6xzXtkYiciTQ2xjzQWtvJCLXicgyEVmWn5/ffims3AvZ3wKwozKC3jpaSCkVgDqs+CsiQcCjwJ37O9YY84wxZpwxZlxycnL7JeL92+H1qQBsLQ/TQKCUCkj+DAQ7gd6O1+mubW6xwAjgcxHZBhwNzDmkHcblBY1Pc6oidP6AUiog+TMQLAUGikhfEQkDLgXmuHcaY0qMMd2NMZnGmExgCTDFGLPMj2nyFtWt8Wmu6caA5JhDdmmllOos/BYIjDF1wHRgHrAOmGWMWSsiD4rIFH9d90epqYCeo3h6+OsUBidzTP+kjk6RUkodcn6dUGaMmQvMbbLt/haOnejPtPhUWwlhMXy0J56xGcFEh+v8OqVU4AnssZK15RAaRXZRBZm60JxSKkAFdiCoqaAuOIKi8hrtKFZKBazADgS1lZSZcAB6d9Ob0SilAlOAB4JySmpDAbRGoJQKWIEdCGoqWJVXQ4/YcAal6BpDSqnAFLiBoKEB6irZss9w+VEZRIQGd3SKlFKqQwRuIKirBKDChOvS00qpgBa4gWDxkwBUEqbNQkqpgBa4gWDBHwCoD7bLTyulVKAK3EDgMjCyjKAgvUexUipwBXwgWNf9jI5OglJKdajAXFzHGJBgnjFTiOjRv6NTo5RSHSowawS1lWDq2VsbrjejUUoFvMAMBDVlAJSiHcVKKRWYgaC6FIByE0F6otYIlFKBLTADwbYvASjTGoFSSvk3EIjIWSKyQUSyRGSGj/03iMhqEVkpIl+KyDB/pgeAsj3w3i0A1IfGEB8Z6vdLKqVUZ+a3QCAiwcCTwCRgGDDNR0b/mjHmCGPMaOBh4FF/padR1vzGp9GxCYjoHAKlVGDzZ41gApBljNlijKkBZgLnOQ8wxuxzvIwGjB/TY23/qvFpXEK3Vg5USqnA4M95BGlAtuN1DnBU04NE5GbgDiAMOMWP6bEqixufJiUl+/1ySinV2XV4Z7Ex5kljTH/g18B9vo4RketEZJmILMvPzz+4C9aUU5MymtOrHya5Z++Dey+llOoC/BkIdgLOnDbdta0lM4Hzfe0wxjxjjBlnjBmXnHyQpfiaciqCYthk0umbpDesV0opfwaCpcBAEekrImHApcAc5wEiMtDx8hxgkx/TY9WUUdpg71Oc2V3nECillN/6CIwxdSIyHZgHBAPPG2PWisiDwDJjzBxguoicBtQCe4Gf+ys9jWrKKA4OJywkiF7xOodAKaX8uuicMWYuMLfJtvsd9Y1CjAAACNJJREFUz2/15/V9qi6jIDSEjG5Ruvy0UkrRCTqLD7macvKqQ8nsrv0DSikFgbYMdX0t1FeTWxNMXw0ESikFBFqNwLXq6L6GcHrGR3RwYpRSqnMIsEBQDkAZEXSLDuvgxCilVOcQWIFg0d8AqDARdI8J7+DEKKVU5xBYgWDZ8wDUEkJSjNYIlFIKAi0QuHzXMECbhpRSyiVwAkFtFQBfZdzEHhLpFqWBQCmlIJACQeVeAAobokmMCiUkOHA+ulJKtSZwcsPKIgB2VkfSI1aHjiqllFsABQJbI9haHkqfJF1sTiml3AInEFTYGsHGfaFkdNNAoJRSboETCFxNQ3m10WRojUAppRoFUCCwTUN7iaG31giUUqpR4Cw6d+TPWVR/BFUfVpGq6wwppVSjwKkRRHUjK6Q/IDpqSCmlHAInEAD5pdWEBAkJkaEdnRSllOo0/BoIROQsEdkgIlkiMsPH/jtE5AcRWSUin4pIhj/Ts6e0muTYcL0zmVJKOfgtEIhIMPAkMAkYBkwTkWFNDvsOGGeMGQnMBh72V3rAEwiUUkp5+LNGMAHIMsZsMcbUADOB85wHGGMWGGMqXC+XAOl+TA/5pdX00ECglFJe/BkI0oBsx+sc17aWXAN86GuHiFwnIstEZFl+fv4BJ2h3SSUpcdpRrJRSTp2is1hErgDGAX/1td8Y84wxZpwxZlxycvIBXaOsuo7iilrSE3UOgVJKOflzHsFOoLfjdbprmxcROQ24FzjJGFPtt8TsrQQgLTHSX5dQSqnDkj9rBEuBgSLSV0TCgEuBOc4DRGQM8G9gijFmjx/Tws5i2xWRroFAKaW8+C0QGGPqgOnAPGAdMMsYs1ZEHhSRKa7D/grEAG+KyEoRmdPC2x00d40gPUEDgVJKOfl1iQljzFxgbpNt9zuen+bP6zulxEVwxrAUvWm9Uko1ETBrDZ0xPJUzhqd2dDKUUqrT6RSjhpRSSnUcDQRKKRXgNBAopVSA00CglFIBTgOBUkoFOA0ESikV4DQQKKVUgNNAoJRSAU6MMR2dhh9FRPKB7Qd4enegoB2TczjQzxwY9DMHhoP5zBnGGJ/LNx92geBgiMgyY8y4jk7HoaSfOTDoZw4M/vrM2jSklFIBTgOBUkoFuEALBM90dAI6gH7mwKCfOTD45TMHVB+BUkqp5gKtRqCUUqoJDQRKKRXgAiYQiMhZIrJBRLJEZEZHp6e9iMjzIrJHRNY4tnUTkU9EZJPrMdG1XUTkCdd3sEpEjuy4lP9/e/cXYlUVxXH8+0vLv6FkJuJIZg6UgU0UpmkwGYVJRA9GmZmE4IsPCkE19I966yXrQcqHIKOhxFISX0xHEXzwv2P+L42BFGsgdMogSV097HWG02hg49x7mnPWBw737HX2XPa6c+7d9+x77969J2m8pK2Sjkg6LGmpx0ubt6TBknZJOuA5v+PxOyTt9NxW+/rgSBrk5RN+fEKR7e8tSQMk7Ze0wculzhdAUoekg7587x6P1fTcrkRHIGkAsAJ4ApgMzJM0udhW9ZlPgdk9Yq8BbWbWCLR5GVL+jb4tBj6qUxv72kXgZTObDEwDlvj/s8x5XwBmmdm9QBMwW9I04D1guZlNAs4Ci7z+IuCsx5d7vf5oKWnN80zZ8808YmZNud8M1PbcNrPSb8B0YGOu3AK0FN2uPsxvAnAoVz4OjPX9scBx318JzLtavf68Ad8Aj1Ulb2AosA94kPQr04Ee7z7PgY3AdN8f6PVUdNv/Y54N/qI3C9gAqMz55vLuAG7tEavpuV2JKwJgHPBTrnzKY2U1xszO+P7PwBjfL93j4EMA9wE7KXnePkzSDnQCm4CTwDkzu+hV8nl15+zHu4BR9W3xdfsAeAW47OVRlDvfjAHfStorabHHanpuV2bx+qoyM5NUyu8ISxoOfA0sM7PfJHUfK2PeZnYJaJI0ElgH3FVwk2pG0pNAp5ntldRcdHvqbKaZnZZ0G7BJ0rH8wVqc21W5IjgNjM+VGzxWVr9IGgvgt50eL83jIOlGUifQamZrPVz6vAHM7BywlTQ0MlJS9oYun1d3zn58BPBrnZt6PWYAT0nqAL4kDQ99SHnz7WZmp/22k9ThT6XG53ZVOoLdQKN/4+Am4DlgfcFtqqX1wELfX0gaQ8/iL/o3DaYBXbnLzX5D6a3/J8BRM3s/d6i0eUsa7VcCSBpC+kzkKKlDmOvVeuacPRZzgS3mg8j9gZm1mFmDmU0gPV+3mNl8SppvRtIwSTdn+8DjwCFqfW4X/cFIHT+AmQN8TxpXfb3o9vRhXl8AZ4C/SOODi0hjo23AD8Bm4BavK9K3p04CB4EHim5/L3OeSRpH/Q5o921OmfMGpgD7PedDwFsenwjsAk4Aa4BBHh/s5RN+fGLROVxH7s3Ahirk6/kd8O1w9lpV63M7ppgIIYSKq8rQUAghhH8RHUEIIVRcdAQhhFBx0RGEEELFRUcQQggVFx1BCHUkqTmbSTOE/4voCEIIoeKiIwjhKiS94PP/t0ta6RO+nZe03NcDaJM02us2Sdrh88Gvy80VP0nSZl9DYJ+kO/3uh0v6StIxSa3KT5IUQgGiIwihB0l3A88CM8ysCbgEzAeGAXvM7B5gG/C2/8lnwKtmNoX0684s3gqssLSGwEOkX4BDmi11GWltjImkeXVCKEzMPhrClR4F7gd2+5v1IaRJvi4Dq73O58BaSSOAkWa2zeOrgDU+X8w4M1sHYGZ/Avj97TKzU15uJ60nsb32aYVwddERhHAlAavMrOUfQenNHvV6Oz/Lhdz+JeJ5GAoWQ0MhXKkNmOvzwWfrxd5Oer5kM18+D2w3sy7grKSHPb4A2GZmvwOnJD3t9zFI0tC6ZhHCNYp3IiH0YGZHJL1BWiXqBtLMrkuAP4CpfqyT9DkCpGmBP/YX+h+Blzy+AFgp6V2/j2fqmEYI1yxmHw3hGkk6b2bDi25HCH0thoZCCKHi4ooghBAqLq4IQgih4qIjCCGEiouOIIQQKi46ghBCqLjoCEIIoeL+Bh7wEbgLMis9AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#predictions = model.predict_classes(x_testcnn)\n",
        "predictions = model.predict(x_test)"
      ],
      "metadata": {
        "id": "A2xtrN5wDQgY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_f_ohjXKDUpY",
        "outputId": "0d1f2347-4551-4a0f-ae5a-072e3977503e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.17244525e-09, 1.36082812e-09, 3.68658477e-03, 4.89051395e-08,\n",
              "        9.95869815e-01, 4.43583413e-04],\n",
              "       [4.14356293e-07, 3.57410390e-09, 5.33300336e-05, 2.16882545e-05,\n",
              "        9.96729732e-01, 3.19481664e-03],\n",
              "       [4.12691792e-04, 1.17192621e-05, 9.24428999e-01, 1.70444197e-03,\n",
              "        3.56566859e-04, 7.30855241e-02],\n",
              "       ...,\n",
              "       [2.38598601e-04, 9.99490738e-01, 1.40505465e-04, 1.03305960e-04,\n",
              "        1.46054435e-05, 1.21021731e-05],\n",
              "       [4.33894587e-10, 1.17429844e-09, 1.34422572e-03, 4.49764775e-06,\n",
              "        9.01958108e-01, 9.66931432e-02],\n",
              "       [9.99984264e-01, 3.64366280e-11, 3.42513398e-13, 1.19530096e-05,\n",
              "        3.45569947e-06, 2.99028898e-07]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "emo_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cmA2bFgsDW3D",
        "outputId": "464584b3-0098-4a5f-f103-bc2d33285909"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([4, 4, 2, 3, 0, 3, 4, 4, 5, 3, 3, 4, 4, 1, 0, 3, 2, 1, 1, 5, 4, 5,\n",
              "       3, 0, 0, 3, 2, 0, 4, 4, 3, 1, 2, 0, 4, 3, 5, 1, 4, 4, 1, 5, 1, 4,\n",
              "       0, 4, 2, 5, 5, 1, 4, 3, 5, 5, 5, 0, 5, 3, 0, 5, 2, 2, 2, 1, 3, 1,\n",
              "       3, 1, 5, 2, 4, 0, 1, 1, 4, 4, 2, 5, 0, 0, 5, 5, 4, 4, 5, 2, 2, 5,\n",
              "       1, 5, 3, 4, 2, 3, 5, 3, 3, 3, 3, 3, 0, 4, 5, 5, 2, 4, 1, 0, 5, 1,\n",
              "       4, 2, 0, 3, 5, 4, 3, 4, 2, 1, 2, 4, 3, 5, 1, 1, 5, 2, 0, 1, 1, 3,\n",
              "       1, 3, 2, 3, 1, 3, 2, 3, 2, 3, 5, 2, 3, 3, 5, 2, 4, 5, 5, 2, 0, 5,\n",
              "       0, 4, 5, 2, 4, 1, 5, 3, 4, 4, 2, 0, 0, 1, 3, 4, 4, 0, 2, 0, 1, 3,\n",
              "       3, 5, 5, 4, 4, 2, 0, 4, 2, 1, 1, 5, 4, 3, 0, 4, 1, 1, 3, 0, 2, 1,\n",
              "       4, 3, 2, 1, 3, 5, 0, 1, 2, 3, 5, 0, 4, 3, 5, 0, 1, 5, 2, 5, 4, 4,\n",
              "       0, 3, 4, 0, 5, 3, 5, 3, 4, 2, 1, 5, 2, 1, 3, 5, 4, 5, 2, 1, 1, 5,\n",
              "       0])"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_Ytest = emo_test.astype(int)"
      ],
      "metadata": {
        "id": "0PHDKWJWDY3g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_Ytest"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k68v2i-pDbZE",
        "outputId": "ce76b944-cbeb-4e92-9563-dd3e054a7498"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([4, 4, 2, 3, 0, 3, 4, 4, 5, 3, 3, 4, 4, 1, 0, 3, 2, 1, 1, 5, 4, 5,\n",
              "       3, 0, 0, 3, 2, 0, 4, 4, 3, 1, 2, 0, 4, 3, 5, 1, 4, 4, 1, 5, 1, 4,\n",
              "       0, 4, 2, 5, 5, 1, 4, 3, 5, 5, 5, 0, 5, 3, 0, 5, 2, 2, 2, 1, 3, 1,\n",
              "       3, 1, 5, 2, 4, 0, 1, 1, 4, 4, 2, 5, 0, 0, 5, 5, 4, 4, 5, 2, 2, 5,\n",
              "       1, 5, 3, 4, 2, 3, 5, 3, 3, 3, 3, 3, 0, 4, 5, 5, 2, 4, 1, 0, 5, 1,\n",
              "       4, 2, 0, 3, 5, 4, 3, 4, 2, 1, 2, 4, 3, 5, 1, 1, 5, 2, 0, 1, 1, 3,\n",
              "       1, 3, 2, 3, 1, 3, 2, 3, 2, 3, 5, 2, 3, 3, 5, 2, 4, 5, 5, 2, 0, 5,\n",
              "       0, 4, 5, 2, 4, 1, 5, 3, 4, 4, 2, 0, 0, 1, 3, 4, 4, 0, 2, 0, 1, 3,\n",
              "       3, 5, 5, 4, 4, 2, 0, 4, 2, 1, 1, 5, 4, 3, 0, 4, 1, 1, 3, 0, 2, 1,\n",
              "       4, 3, 2, 1, 3, 5, 0, 1, 2, 3, 5, 0, 4, 3, 5, 0, 1, 5, 2, 5, 4, 4,\n",
              "       0, 3, 4, 0, 5, 3, 5, 3, 4, 2, 1, 5, 2, 1, 3, 5, 4, 5, 2, 1, 1, 5,\n",
              "       0])"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds1=predictions.argmax(axis=1)"
      ],
      "metadata": {
        "id": "VEw0FiZFMcOQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vvyRw0M0NBOb",
        "outputId": "a3879fb9-2b81-4f15-d62f-7f70243aafcd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([4, 4, 2, 5, 0, 3, 4, 4, 5, 0, 5, 4, 2, 1, 0, 3, 2, 1, 1, 5, 4, 5,\n",
              "       1, 4, 4, 3, 5, 0, 4, 4, 3, 1, 2, 0, 4, 3, 5, 1, 3, 4, 1, 5, 1, 4,\n",
              "       4, 4, 1, 5, 3, 1, 5, 5, 5, 2, 2, 0, 5, 3, 0, 4, 2, 2, 4, 1, 5, 1,\n",
              "       3, 1, 5, 2, 4, 0, 3, 1, 4, 4, 1, 5, 3, 0, 5, 1, 4, 4, 5, 2, 2, 5,\n",
              "       1, 5, 5, 4, 4, 3, 4, 5, 4, 0, 3, 3, 1, 4, 5, 5, 2, 4, 1, 0, 5, 2,\n",
              "       4, 2, 0, 3, 5, 2, 3, 0, 2, 1, 2, 4, 3, 5, 4, 1, 5, 2, 0, 1, 0, 3,\n",
              "       1, 3, 2, 0, 1, 2, 2, 3, 2, 3, 5, 2, 3, 3, 5, 2, 4, 5, 5, 5, 0, 3,\n",
              "       0, 4, 5, 2, 4, 1, 5, 5, 4, 4, 2, 1, 0, 1, 3, 4, 2, 0, 5, 4, 5, 3,\n",
              "       3, 5, 5, 4, 4, 2, 0, 4, 2, 1, 2, 4, 4, 3, 0, 4, 1, 1, 3, 2, 2, 1,\n",
              "       4, 5, 2, 4, 3, 5, 0, 1, 2, 5, 5, 0, 4, 3, 5, 0, 1, 5, 2, 5, 4, 4,\n",
              "       0, 5, 4, 0, 3, 3, 5, 5, 4, 2, 1, 3, 2, 1, 2, 5, 4, 5, 2, 1, 1, 4,\n",
              "       0])"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "abc = preds1.astype(int).flatten()"
      ],
      "metadata": {
        "id": "H4WEmM60NfQn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "c = confusion_matrix(new_Ytest, abc) \n",
        "c"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bKEBeEBlFjB8",
        "outputId": "f0242ecb-f969-462d-9ba0-5815c617ee6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[23,  2,  1,  1,  4,  0],\n",
              "       [ 1, 31,  2,  1,  2,  1],\n",
              "       [ 0,  2, 29,  0,  2,  3],\n",
              "       [ 3,  1,  2, 27,  1, 11],\n",
              "       [ 1,  0,  3,  1, 40,  1],\n",
              "       [ 0,  1,  2,  4,  4, 36]])"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "emo_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m4RjG7LWLSQx",
        "outputId": "c803ba20-4924-43ef-d0a1-9b1559649649"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([4, 4, 2, 3, 0, 3, 4, 4, 5, 3, 3, 4, 4, 1, 0, 3, 2, 1, 1, 5, 4, 5,\n",
              "       3, 0, 0, 3, 2, 0, 4, 4, 3, 1, 2, 0, 4, 3, 5, 1, 4, 4, 1, 5, 1, 4,\n",
              "       0, 4, 2, 5, 5, 1, 4, 3, 5, 5, 5, 0, 5, 3, 0, 5, 2, 2, 2, 1, 3, 1,\n",
              "       3, 1, 5, 2, 4, 0, 1, 1, 4, 4, 2, 5, 0, 0, 5, 5, 4, 4, 5, 2, 2, 5,\n",
              "       1, 5, 3, 4, 2, 3, 5, 3, 3, 3, 3, 3, 0, 4, 5, 5, 2, 4, 1, 0, 5, 1,\n",
              "       4, 2, 0, 3, 5, 4, 3, 4, 2, 1, 2, 4, 3, 5, 1, 1, 5, 2, 0, 1, 1, 3,\n",
              "       1, 3, 2, 3, 1, 3, 2, 3, 2, 3, 5, 2, 3, 3, 5, 2, 4, 5, 5, 2, 0, 5,\n",
              "       0, 4, 5, 2, 4, 1, 5, 3, 4, 4, 2, 0, 0, 1, 3, 4, 4, 0, 2, 0, 1, 3,\n",
              "       3, 5, 5, 4, 4, 2, 0, 4, 2, 1, 1, 5, 4, 3, 0, 4, 1, 1, 3, 0, 2, 1,\n",
              "       4, 3, 2, 1, 3, 5, 0, 1, 2, 3, 5, 0, 4, 3, 5, 0, 1, 5, 2, 5, 4, 4,\n",
              "       0, 3, 4, 0, 5, 3, 5, 3, 4, 2, 1, 5, 2, 1, 3, 5, 4, 5, 2, 1, 1, 5,\n",
              "       0])"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('/content/drive/My Drive/graduation project/audio/improvement1/mariam/augmanted_radvass_savee_newlayer_1')\n",
        "print(\"MODEL SAVED\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lsJBNeMWDl6Z",
        "outputId": "226dc1b7-5a5d-4d39-f230-bec3dc077002"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/graduation project/audio/improvement1/mariam/augmanted_radvass_savee_newlayer_1/assets\n",
            "MODEL SAVED\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_model=keras.models.load_model('/content/drive/My Drive/graduation project/audio/improvement1/mariam/augmanted_radvass_savee_newlayer_1')\n",
        "new_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q3KjaO9GDoNl",
        "outputId": "36fab8d7-3f06-46b7-e4ff-a0fc7ac749ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d (Conv1D)             (None, 40, 64)            384       \n",
            "                                                                 \n",
            " activation (Activation)     (None, 40, 64)            0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 40, 64)            0         \n",
            "                                                                 \n",
            " max_pooling1d (MaxPooling1D  (None, 10, 64)           0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv1d_1 (Conv1D)           (None, 10, 128)           41088     \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 10, 128)           0         \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 10, 128)           0         \n",
            "                                                                 \n",
            " max_pooling1d_1 (MaxPooling  (None, 2, 128)           0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " conv1d_2 (Conv1D)           (None, 2, 128)            82048     \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 2, 128)            0         \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 2, 128)            0         \n",
            "                                                                 \n",
            " max_pooling1d_2 (MaxPooling  (None, 1, 128)           0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " conv1d_3 (Conv1D)           (None, 1, 256)            164096    \n",
            "                                                                 \n",
            " activation_3 (Activation)   (None, 1, 256)            0         \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 1, 256)            0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 256)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 6)                 1542      \n",
            "                                                                 \n",
            " activation_4 (Activation)   (None, 6)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 289,158\n",
            "Trainable params: 289,158\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss, acc = new_model.evaluate(x_test, emo_test)\n",
        "print(\"Restored model, accuracy: {:5.2f}%\".format(100*acc))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n3kzoqPkDqqS",
        "outputId": "c3ce2c1a-e7e9-4481-d663-9b4e361cb6ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8/8 [==============================] - 0s 5ms/step - loss: 0.6782 - accuracy: 0.7654\n",
            "Restored model, accuracy: 76.54%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix,accuracy_score\n",
        "import seaborn as sn\n",
        "\n",
        "print(classification_report(emo_test,abc))\n",
        "\n",
        "acc = float(accuracy_score(emo_test,abc))*100\n",
        "print(\"----accuracy score %s ----\" % acc)\n",
        "\n",
        "cm = confusion_matrix(emo_test,abc)\n",
        "#df_cm = pd.DataFrame(cm)\n",
        "class_names = ['neutral','calm', 'happy','sad','angry', 'fearful' ]\n",
        "df_cm = pd.DataFrame(cm, index=class_names, columns=class_names,)\n",
        "sn.heatmap(df_cm, annot=True, fmt='')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Yx8ogGOnNneV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 512
        },
        "outputId": "30d259bf-951b-419b-b99d-f4343b24925d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.74      0.78        31\n",
            "           1       0.84      0.82      0.83        38\n",
            "           2       0.74      0.81      0.77        36\n",
            "           3       0.79      0.60      0.68        45\n",
            "           4       0.75      0.87      0.81        46\n",
            "           5       0.69      0.77      0.73        47\n",
            "\n",
            "    accuracy                           0.77       243\n",
            "   macro avg       0.77      0.77      0.77       243\n",
            "weighted avg       0.77      0.77      0.76       243\n",
            "\n",
            "----accuracy score 76.5432098765432 ----\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVoAAAD8CAYAAAA2Y2wxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dd5xU1d3H8c9vdmCBBaRKV1A0NpQixdiwo1EhRkFiwfJILEk0MUafYItBouQRAwZRjLAUC4gFAQtKCYIiTUCKgAsoHQRpS9ud+T1/3Ls4wO7OnWXu3JnN7/163dfO3Lnlu7OzZ8+ee+45oqoYY4zxTyjoAMYYU95ZQWuMMT6zgtYYY3xmBa0xxvjMClpjjPGZFbTGGOMzK2iNMaYUIpIlIl+JyHj3eTMR+VJEvhWRUSJSMd4xrKA1xpjS3Q8sjXn+LPC8qjYHfgTujHcAK2iNMaYEItIY+AXwb/e5ABcDY9xNhgFd4h0n7FfAImvaXpJRt561WrYm6AgJ21t4IOgI5V6jnDpBR0jYyh0bgo6QsMID6+Roj1Hww0rPZU7Fuif+BugZs2qwqg6Oef5P4M9ANfd5bWC7qha6z9cCjeKdx/eC1hhj0pVbqA4u7jURuRrYrKpzRaTj0ZzHClpjTPkSjSTrSOcC14rIVUAloDrQH6ghImG3VtsYWBfvQNZGa4wpXyKF3pdSqOr/qmpjVW0K3AhMVtWbgCnA9e5mPYCx8SKVWqMVkV1Ace0d4uTQ6vFOYIwxqaQa9fsUDwNvikhv4Cvg1Xg7lFrQqmq10l43xpi0E01+QauqU4Gp7uOVQLtE9k+ojVZEjsVpqyg6+feJ7G+MMb7zv0abME8FrYhcCzwHNAQ2A8fjdOA93b9oxhhTBsm7GJY0Xi+G/Q3oACxX1WbAJcBM31IZY0xZadT7kiJemw4KVHWriIREJKSqU0Tkn74mM8aYMtA4vQmC4LWg3S4iVYFpwGsishnI9y+WMcaUkQ8Xw46W16aDzsAe4A/AR0AecI1foYwxpswyselARLKA8ap6ERDFGUTBGGPSUxpeDItb0KpqRESiInKMqu5IRShjjCmzNOze5bXpYDfwtYi8KiIDihY/g8XKqleXuoOeo/6oIdQf9SpVb7wOgOp330a911+h3msvU/eFZwnVqZ2qSAlp2Kg+740fzoxZHzD9ywn0vOfWoCPFNeilvqxePYfZsz8OOoonmZa3SCgU4r3Jr/Hya88HHcWTKy7vyOJF0/hmyXT+/NB9QccpXpJuwU0mrwXtO8BjOBfD5rrLHL9CHU4LI2z/50ts7HYHm27/LVWv70y42fHsGjGaTb++i003/Ya902dyzP/ckqpICYkURni81zOc2+4qOl3SlTvvuomTf3Zi0LFKNXLEGLp06RF0DM8yLW+RHj27k7d8VdAxPAmFQgzo/zRXX3MzLc66iG7dunDqqScFHetI0aj3JUW8FrQ1VHVY7ALU9DNYrOjWbRQsWwGA7tlL4ervyKpbB83fc3AbqVwJND2Hvt20aQsLFywBYPfufJYvy6NBw3oBpyrdjBmz2LYtc1qKMi0vQL0Gx9LxsnN5a+R7QUfxpF3bVuTlrWbVqu8pKChg9OixXHvNFUHHOoJqxPOSKl4L2uKqCrclMYdnWQ3qUeFnzTmw2JlZ4ph77qDB+DfI6XQJO17ODSJSQpoc14gWZ57G3DkLgo5iAtbr6Qfp+9cBRKPpWUE4XMNG9Vmzdv3B52vXbaBhw/oBJipBGvY6KLWgFZHuIjIOaCYi78csU4BtpezXU0TmiMic17bEHarRM6lciTrPPsn2fi8erM3uGDSEDVd3J/+jSVTtGndGiUDl5FQhd8QL9HqkD7t3WTfk/2YdLzuPrVu2sXjhN0FHKX/SsOkgXq+Dz4ENQB2csQ6K7AIWlrRT7KjlSZvKJiuL2s8+Sf5Hk9g7ZfoRL+/5cBJ1+/dh5+D07H0WDocZOvIFxowex4RxE4OOYwLWpv1ZXNLpAi689FyyK1WkatWq/OPFp3jo3seDjlai9es20qRxw4PPGzdqwPr1GwNMVII07HUQb5jE74DvgHNSE6dktR77E4Wrv2f362MOrgs3aUThGqfGXPnCn1OwOn3n++o/sA/Ll+UxaODQoKOYNPBc74E813sgAO1+3oY777s5rQtZgNlz5tO8eTOaNm3CunUb6dq1M7fcmoY9DyIFQSc4gtfRu2IHAK8IVADyUzXwd8WzziDnF5dzYMVK6r32MgA7Br5KTucrqXB8EzSqRDZu4se/p+fwC+07tKFb9y4sXvQNU6Y7g7E//VQ/Pp34n4CTlSw3dwDnX9CB2rVrsnzFF/Tu/TzDh40OOlaJMi1vJopEItz/wKN8MOF1skIhcoeNYsmS5UHHOlIa3oIrmuCVene63c5AB1V9JN72Nguu/2wWXP/ZLLipkYxZcPd98YbnMqfSOd2P+nxeJDxnmDreA9KvX4cxxmTgxTAAROS6mKch4Gxgny+JjDHmaCSpABWRSjg3aWXjlJVjVPUJEckFLgSKOm7fpqrzSzuW12ESY0fqKgRW4zQfGGNMWtHkXQzbD1ysqrtFpAIwXUQ+dF97SFXHlLLvITwVtKp6exlCGmNM6iWpe5c6F7B2u08ruEuZrjl5aqMVkZNFZJKILHKfnykij5blhMYY46skttGKSJaIzMeZK/ETVf3SfelpEVkoIs+LSHa843i9GPYK8L9AAYCqLgRu9LivMcakTgK34MbexeouPQ85lGpEVVsCjYF2InIGTll4CtAWqAU8HC+S1zbaKqo6y+nZdVD6TcxjjDEJXAyLvYs1znbb3aEHOqnq/7mr94vIUOBP8fb3WqP9QUROxG2fEJHrcW7NNcaY9JKkQWVEpK6I1HAfVwYuA74RkQbuOgG6AIviRfJao70Pp9Q/RUTWAauAmzzua4wxqVOYtH+2GwDD3Om8QsBoVR0vIpNFpC4gwHzg7ngH8lrQrgOGAlNw2iR24gyd+FQZwhtjjH+S1+tgIdCqmPUXJ3osrwXtWGA7MA9YH2dbY4wJThqOdeC1oG2sqp18TWKMMcmQhsMker0Y9rmItPA1iTHGJEOmjnUAnAfcJiKrcG5LE5wbJ86Mt+Mpi/OOIl7qbXn2qqAjJOy4Xp8GHSFhmTbi2Lb9O4OOkLDscIWgIwQjDWu0XgvaK31NYYwxyZK8XgdJ43Wsg+/8DmKMMUmRhrNhe63RGmNMZsjgXgfGGJMZrKA1xhifZfDFMGOMyQyRSNAJjmAFrTGmfLGmA2OM8ZkVtMYY47NMbqMVkTOBprH7qOo7PmQyxpgy02iG9qMVkSHAmcBioOjPhQJW0Bpj0ksGNx10UNXTfE1ijDHJkIa9DryO3vWFiFhBa4xJfxk8etdwnMJ2IwmO3mWMMSmVwU0HrwK3AF/zUxttIAa91JcrO13Mli1badv2iiCjlGp/YYQ735nHgUiUiCqXnngs97Q/gTcXruH1BWtYs2Mvk+88n5qVKwYd9QgNG9XnxZf7UvfYOqgqw3NHMXjQ8KBjlSpTPhex7H32SRoOKuO16WCLqr6vqqtU9buixddkJRg5YgxduvQI4tQJqZgVYnCXVozu3p43u7Xj8++3snDjDlo2qMFLnVvRoFqloCOWKFIY4fFez3Buu6vodElX7rzrJk7+2YlBxypVpnwuYtn77JMkNR2ISCURmSUiC0RksYj81V3fTES+FJFvRWSUiMStLXktaL8SkddFpLuIXFe0eNw3qWbMmMW2bTuCOHVCRIQqFZ1/GAqjSmFUEeCUutVoWL1ysOHi2LRpCwsXLAFg9+58li/Lo0HDegGnKl2mfC5i2fvsk6h6X0q3H7hYVc8CWgKdRKQD8CzwvKo2B34E7ox3IK9NB5Xdk14es866d8URiSq/Hj2LNTv20q1FY1rUPyboSAlrclwjWpx5GnPnLAg6Srlm73MSJanXgaoqsNt9WsFdFLgY+LW7fhjwJDCotGN5Hfj79kQCikhPoCdAxQq1CIerJbJ7uZEVEkbd2J5d+wv44wcL+XbrbprXrhp0LM9ycqqQO+IFej3Sh9278oOOU27Z+5xcmsDFsNiyyjVYVQfHvJ4FzAWaAwOBPGC7qhZN47AWaBTvPKUWtCLyAk4JXixV/X0J6wcDgwFyqjRNv5bpFKuWXYGzG9Xk8++2ZkxBGw6HGTryBcaMHseEcRODjlNu2fvsgwTuDIstq0p4PQK0FJEawLvAKWWJFK9GO6csBzWwbe8BKoSEatkV2FcY4cs127itddOgY3nWf2Afli/LY9DAoUFHKdfsffaBD2MdqOp2EZkCnAPUEJGwW6ttDKyLt3+pF8NUdVhpS3K+hcTk5g5gytR3OOnkE1i+4gtu7dE1iBhx/ZC/n7venUfXN77k5tGzad+kFhc0q8PrC9ZwxdDpbN69n65vfMlfJy8NOuoR2ndoQ7fuXTj/gg5MmT6WKdPHcunlFwYdq1SZ8rmIZe+zT5J0MUxE6ro1WUSkMnAZsBSYAlzvbtYDGBsvkqiHPmciUhd4GDgNONgvSVUvjrdvpjUd2HTjqZFp041XDqdff+d4Mu09Bsjfs1qO+hiP3+i5zMl56s0Sz+cOpDUMyMKplI5W1adE5ATgTaAW8BVws6ruL+08XnsdvAaMAn4B3I1Tim/xuK8xxqROkpoOVHUh0KqY9SuBdokcy2s/2tqq+ipQoKr/UdU7cLo4GGNMekleP9qk8VqjLXC/bhCRXwDrcarNxhiTVhLp3pUqXgva3iJyDPAg8AJQHXjAt1TGGFNWaTjwt9emgxtwLpwtUtWLcK6+/dK/WMYYU0YZ3HRwpqpuL3qiqttE5IhGYmOMCVwaDvzttaANiUhNVf0RQERqJbCvMcakTMbOGQY8hzPw91vu8xuAp/2JZIwxRyFTC1pVHS4ic/ipS9d1qrrEv1jGGFNGGdzrALdgtcLVGJPeMrVGa4wxGcMKWmOM8ZdGMrjpoKz2FxbE3yiNZOIALd/d3zLoCAk75tkZQUdISCYOKlO70n/ngPtWozXGGJ9lcvcuY4zJDFbQGmOMz9KvidYKWmNM+aKF6VfSWkFrjClf0q+c9TZ6l4j8TkRq+h3GGGOOlkbV85IqXodJrAfMFpHRItJJRI56Xh9jjPFFNIGlFCLSRESmiMgSEVksIve7658UkXUiMt9d4k406KmgVdVHgZOAV4HbgBUi0kdETvSyvzHGpEoSa7SFwIOqehrQAbhPRE5zX3teVVu6ywfxDuS1Ros60+VudJdCoCYwRkT6ej2GMcb4Lkk1WlXdoKrz3Me7cKYab1SWSF7baO8XkblAX2AG0EJV7wHaAL8qy4mNMcYPWuh9EZGeIjInZulZ3DFFpCnOjLhfuqt+KyILRWSIl+tXXnsd1MIZGvG7Q74h1aiIXO3xGMYY47tEZhtX1cHA4NK2EZGqwNvAA6q6U0QGAX8D1P36HHBHacfwOh7tEyLSWkQ6uwefEVOlXurlGMYYkxJJ7N4lIhVwCtnXVPUdAFXdFPP6K8D4eMfx2nTwGDAMqA3UAYaKyKNlyG2MMb7SqPelNG7vqleBparaL2Z9g5jNfgksipfJa9PBzcBZqrrPPdEzwHygt8f9jTEmJRJpOojjXOAW4GsRme+u+wvQXURa4vx3vxr4TbwDeS1o1wOVgH3u82xgXQKBk+qKyzvSr99TZIVCDBn6Bn3/MTCoKJ40bFSfF1/uS91j66CqDM8dxeBBw4OOdQipXpvsX92HVK0BKAWzP6Vw5oeE6h9PxWvuQrIrEf1xC/vHDID9e4OOWyz7XPgrO7sib43PpWJ2RcLhLD54/xP6PfNi0LGOoJHkdPNX1elAcQeL253rcF4L2h3AYhH5BKcUvwyYJSID3EC/T/TEZRUKhRjQ/2k6XdWdtWs3MPOLDxg3fiJLl65IVYSERQojPN7rGRYuWELVqjlMmvYOUyfPYPmyvKCj/SQa4cBHI4huWAUVK1H5nmeI5C2kYuffcODjEURXLyXc+iIqnHctBZNGBZ32CPa58N/+/Qe4scud7MnfSzgc5u0PhzHl0+l8NWdh0NEOkcQabdJ47Uf7Lk6VeQowFegFjAXmukvKtGvbiry81axa9T0FBQWMHj2Wa6+5IpURErZp0xYWLnCmW9u9O5/ly/Jo0LBewKkOpbu3O4UswIF9RLesQ6rXIlSnIdHVzvXOyLcLCZ/WPsCUJbPPRWrsyXf+mwlXCBMOh3G616cXjYrnJVW89joYJiIVgVNwarTLVPWAr8lK0LBRfdasXX/w+dp1G2jXtlUQUcqkyXGNaHHmacydsyDoKCWSGnUJNWhGdO23RDevIevUtkSWzibrjA7IMbWDjlcs+1ykRigUYsKUUTRtdhzDX32T+XO/DjrSETK2Ruvey5sHDAD+BXwrIleWsv3BTsDRaH5ykpYDOTlVyB3xAr0e6cPuXWn6vlTMJvvGBznwYS7s38v+dwdRod3lVLr7GSS7MkQKg05Y7mTE58IVjUa58sIbaH/GpZzV+gxOPrV50JGOoCqel1Tx2kbbD7hIVb8FcMc4mAB8WNzGsZ2AwxUbJfV/i/XrNtKkccODzxs3asD69RuTeQpfhMNhho58gTGjxzFh3MSg4xQvlEX2jQ9SuPAzIktmAaA/rGffsKcBkNoNyDq5dZAJS2Sfi9TauXMXX0yfTcdLzmX50m+DjnOIjK3RAruKClnXSmCXD3nimj1nPs2bN6Np0yZUqFCBrl07M258+n9A+w/sw/JleQwaODToKCWq+Mu70S3rKPx8wk8rc6o7X0Wo0PE6Cmd/Eky4OOxz4b9atWtSvboz4WN2pWzO79iBvOWrAk51pGhEPC+p4rVGO0dEPgBG47TR3oAzbOJ1AEV3TKRCJBLh/gce5YMJr5MVCpE7bBRLlixP1enLpH2HNnTr3oXFi75hyvSxADz9VD8+nfifgJP9JHTcz6jQ8kKiG7+j0r3OOEEFn7yB1K5PhfbORaXCJbMonDclyJglss+F/46tV5d+L/YmKyuLUEgY/95EJk2cFnSsI6TyIpdX4uWqoYiU9udWVbXE+3yT3XTgtxqVcoKOkDCbbtx/mfi5qBLODjpCwr7f9vVRl5KrW17mucxpOv+TlJTKXnsd3O53EGOMSYY07HHmraAVkUrAncDpOHeIAVBaTdYYY4KQjk0HXi+GjQDqA1cA/wEaE9DFMGOMKU0md+9qrqo3iEhn9+aF14HP/AxmjDFlEUlhbwKvvBa0Be7X7SJyBs50Nsf6E8kYY8oulTVVr7wWtIPd6RoeBd4HqgKP+ZbKGGPKKB3baL0WtCNw5gZrijMAODhTkBtjTFrJ2F4HOCN17cAZqWu/f3GMMeboZHKNtrGqdvI1iTHGJEEk6rUzVep4TfS5iLTwNYkxxiSBqvclVUqt0YrI1zhjG4SB20VkJU7TgeDcenum/xGNMca7aJJ6HYhIE2A4zvUoBQaran8RqQWMwrlmtRroqqo/lnaseE0HVx91WmOMSaEkdu8qBB5U1XkiUg2Y607ndRswSVWfEZFHgEeAh0s7UKkFrap+l6TAxhiTEslqElDVDcAG9/EuEVkKNAI6Ax3dzYbhTO9V9oI2GRpWreX3KZJq677Mu7P4+P7z42+UZrb1OD3oCAlp8Fp6D7lYnBtrZc5UPsmUSNOBiPQEesasGuxOXHD4dk2BVsCXQD23EAbn5q24XV19L2iNMSaVEul1EDsbTElEpCrwNvCAqu4U+akgV1UVkbh16PTrB2GMMUdBE1jiEZEKOIXsazETHGwSkQbu6w2AzfGOYwWtMaZciap4XkojTtX1VWCpqvaLeel9oIf7uAfODV2lsqYDY0y5ksReB+cCtwBfi0jRhZC/AM8Ao0XkTuA7oGu8A1lBa4wpV5I1Ca6qTse5Z6A4lyRyLCtojTHlipZYNgbHClpjTLlSmMHj0RpjTEawGq0xxvgsWW20yWQFrTGmXLEarTHG+MxqtMYY47NIptVoY8ajLZaNR2uMSTdpOJON5/Fo73O/jnC/3uRPnPiysyvy1vhcKmZXJBzO4oP3P6HfMy8GFceTQS/15cpOF7Nly1batr0i6DhxNWxUnxdf7kvdY+ugqgzPHcXgQcODjnUEqVmXync8hFSvCSgF0z7gwKT3qNzzL4TqN3G2qZyD7s0n/6l7gg1bjEz4XNzU927OuLg1u7bupM8VfwKg1VUduOqB66nXvBH/17kX33+9MuCUh4pmWo22aDxaEblMVWPHXHtERObhDHibUvv3H+DGLneyJ38v4XCYtz8cxpRPp/PVnIWpjuLZyBFjePmlYbzySr/4G6eBSGGEx3s9w8IFS6haNYdJ095h6uQZLF+WF3S0Q0Uj7HtrMNHvv4XsyuQ8NpDCJfPYO7jPwU2yb+iJ7s0PMGTJMuFzMXPMf/jPsI+5td99B9etX7aGV+5+ju597gowWcnScBJcz4PKiIicG/Pk5wnsm3R78vcCEK4QJhwOo+k4v3CMGTNmsW3bjqBjeLZp0xYWLlgCwO7d+SxflkeDhuk3u7zu2OYUsgD79xLd8D1So84h21Q4+0IKZ00JIF18mfC5yJu1lD07dh+yblPeOjav3FDCHsGLJrCkiteLYXcCQ0TkGJx7f38E7vAtVRyhUIgJU0bRtNlxDH/1TebP/TqoKOVek+Ma0eLM05g7Z0HQUUolteuR1aQ5kVXfHFyXdVILdOePRDevDzCZSbWopF/TgadaqarOVdWzgLOAM1W1parOK2l7EekpInNEZM7u/duSlfWgaDTKlRfeQPszLuWs1mdw8qnNk34OAzk5Vcgd8QK9HunD7l3p+e83ANmVqHLP4+wbNQj27Tm4ukK7jhSkaW3W+CeSwJIqnrt3icgvgNOBSkUjjKvqU8VtGztq+XG1Wvj2f/3Onbv4YvpsOl5yLsuXfuvXaf4rhcNhho58gTGjxzFh3MSg45QsK4sq9zxOwZeTKfxqxk/rQyHCrc8jv/d9Je9ryqV07HXgqUYrIi8B3YDf4TQd3AAc72OuEtWqXZPq1asBkF0pm/M7diBv+aogopRr/Qf2YfmyPAYNHBp0lFJV6vFHIhu+58Anbx+yPuvU1kQ3rEF//CGgZCYoUcTzkipeL2j9XFVvBX5U1b8C5wAn+xerZMfWq8ub77/Kx5+9zfhJb/DZ1JlMmjgtiCie5eYOYMrUdzjp5BNYvuILbu0Rd5zgQLXv0IZu3btw/gUdmDJ9LFOmj+XSyy8MOtYRspqfTsVzLiN8SktyHh9EzuODCJ/RFnCbDWand7NBJnwubhvwex5852/UO6EBf/viRc7pehFnXtGWv33xIk1bnczdQx7mvuF/CTrmIZI5lU2yiJcr9iIyS1XbichM4DpgG7BIVeM2jvrZdOCHTJwFt3K4YtARErayW9OgIyQkE2fBvf3Y9kFHSNi/Vo866mrm8EY3ey5zbl03MiXVWq9ttONEpAbwD2Aezh+DV3xLZYwxZZSOYx14bTr4Boio6tvAQGAm8J5vqYwxpowi4n2JR0SGiMhmEVkUs+5JEVknIvPd5ap4x/Fa0D6mqrtE5DzgYuDfwCCP+xpjTMok+YaFXKBTMeufd7u5tlTVD+IdxGtBW9Tl7BfAK6o6Aci8hkFjTLmXzIJWVafhXJM6Kl4L2nUi8jJOF68PRCQ7gX2NMSZlVLwvsTdXuUtPj6f5rYgsdJsWasbb2Gth2RX4GLhCVbcDtYCHPO5rjDEpk0iNVlUHq+rZMctgD6cYBJwItAQ2AM/F28FTrwNV3QO8E/N8g3sCY4xJK37fWquqm4oei8grwPh4+9gMC8aYcsXvW3BFpIFb2QT4JbCotO3BClpjTDmTzH60IvIG0BGoIyJrgSeAjiLSEud+gtXAb+IdxwpaY0y5ksyCVlW7F7P61USPYwWtMaZcScd7/q2gNcaUK+k4TKIVtMaYciWVA3p75XtBm2mjYe0vLAg6QsJqV6oWdISEZdpoWNu/nxx0hITVOO7ioCMk7F9JOEY0DRsPrEZrjClX0nH0LitojTHlSvrVZ62gNcaUM1ajNcYYnxVK+tVpraA1xpQr6VfMWkFrjCln0rHpwOt047/zMuaiMcYELYp6XlLF63i09YDZIjJaRDqJSBree2GMMek53binglZVHwVOwhlM4TZghYj0EZETfcxmjDEJS/KcYUnheToaVVVgo7sUAjWBMSLS16dsxhiTsAjqeUkVTxfDROR+4FbgB5wZcB9S1QIRCQErgD/7F9EYY7xLx4thXnsd1ASuU9XvYleqalRErk5+LGOMKRtNww5ecZsORCQLuPHwQraIqi5NeipjjCmjjGyjVdUIsExEjktBnrgGvdSX1avnMHv2x0FHScgVl3dk8aJpfLNkOn9+6L6g45QqO7si73/yOh9NG8Onn7/LHx+5N+hIcWXS5yISiXD9bfdx70NPALB2/Ua63/UAV3a9gwcf+zsFBek7glwmvM+Z3L2rJrBYRCaJyPtFi5/BSjJyxBi6dOkRxKnLLBQKMaD/01x9zc20OOsiunXrwqmnnhR0rBLt33+AG7vcSacLrqfTBTdw4SXn0ursM4OOVapM+lyMfGssJzT9qd7y/KAh3NKtCx+OHkL1alV5e3z6FmKZ8D4ns3uXiAwRkc0isihmXS0R+UREVrhf495j4LWgfQy4GngKZw7zoiXlZsyYxbZtO4I4dZm1a9uKvLzVrFr1PQUFBYwePZZrr7ki6Fil2pO/F4BwhTDhcBin00n6ypTPxcbNW5j2+Sx+5f78VZUv5y7g8o7nA9D5qkuZPO2LICOWKhPe50LU8+JBLtDpsHWPAJNU9SRgkvu8VJ4uhqnqf7xsZ4rXsFF91qxdf/D52nUbaNe2VYCJ4guFQkyYMoqmzY5j+KtvMn/u10FHKhee7f8yf7z3TvL3OH/Itu/YSbWqOYTDWQDUq1uHzVu2Bhkx4yXzYpiqThORpoet7owzMy7AMGAq8HBpx/F6C+4uEdl52LJGRN4VkROK2b6niMwRkTmFhZk1w4JxRKNRrrzwBtqfcSlntT6Dk09tHnSkjDd1xpfUqlmD009J32aj8iCRi2GxZZW79PRwinqqusF9vBHnztlSee3e9U9gLfA6IMCNwInAPGAIP5XuAECDPYIAABEkSURBVKjqYGAwQE6Vpun9P2cKrF+3kSaNGx583rhRA9av3xhgIu927tzFF9Nn0/GSc1m+9Nug42S0rxYuYer0mXz2xWz2HyggP38Pz/zzJXbtzqewMEI4nMWmLT9wbN3aQUfNaInUaGPLqjKdS1VF4o/L6LWN9lpVfVlVd6nqTjfcFao6CudCmSnF7Dnzad68GU2bNqFChQp07dqZceMnBh2rRLVq16R6dWcesuxK2ZzfsQN5y1cFnCrz/eGe25n03kgmvj2Mf/z1Edq1OYtnn3yYdq3PZOLUzwAY+8GnXHz+OQEnzWwp6N61SUQaALhfN8fbwWtBu0dEuopIyF26Avvc11JaY83NHcCUqe9w0sknsHzFF9zao2sqT18mkUiE+x94lA8mvM6ihVMZM2YcS5ak7+SEx9ary5vvv8rHn73N+Elv8NnUmUyaOC3oWKXKxM9FkT/ccwfD33yXK7vewY6dO7nu6suDjlSiTHifI6qelzJ6HyjqetEDGBtvB/FyNdlth+0PnINTsM4E/gCsA9qo6vSS9s20poNMnAW3YdVaQUdIWKbNjmyz4KZG/p7VRz0y4K+P/6XnMuf1794t9Xwi8gZO02gdYBPwBPAeMBo4DvgO6Kqq20o7jtdeByuBa0p4ucRC1hhjUi3JvQ66l/DSJYkcx+ugMnWBu4Cmsfuo6h2JnMwYY/yWyYPKjAU+Az4FIv7FMcaYo5PKW2u98lrQVlHVUjvkGmNMOsjI0btc40XkKl+TGGNMEqSg10HCvNZo7wf+IiL7gQKcmxZUVav7lswYY8ogY5sOVLWaiNTCmTeskr+RjDGm7DL2YpiI/A9OrbYxMB/oAHxOgl0cjDHGb5ncRns/0Bb4TlUvAloB6T1WmjHmv1I6DvzttY12n6ruExFEJFtVvxGRn/mazBhjyiAdx072WtCuFZEaOLeefSIiP+LcemaMMWklldOIe+X1Ytgv3YdPisgU4BjgI99SGWNMGWVsr4NYNtuCMSadZXLTQZll2mhY2eEKQUdI2J7C/UFHSFijnDpBR0jI6aem33CA8Wyd9PegIwSiXNRojTEmnaVj9y4raI0x5Uoqb631ygpaY0y5Yk0HxhjjMytojTHGZxnV60BEdlH8xIs2cpcxJm0ls0YrIquBXTgTHhSq6tllOU6JBa2qVitbNGOMCY4PvQ4uUtUfjuYAcZsOROS44tar6vdHc2JjjPFDRNNvoEQvbbQTYh5XApoBy4DTfUlkjDFHIclttApMFBEFXlbVwWU5SNyCVlVbxD4XkdbAvWU5mTHG+C2RNloR6Qn0jFk1+LDC9DxVXScix+IMqPWNqk5LNFNZxjqYJyLtE93PGGNSIZE2WrdQLbGWqqrr3K+bReRdoB2Q/IJWRP4Y8zQEtAbWJ3oiY4xJhWiSmg5EJAcIqeou9/HlwFNlOZaXGm1s74NCnDbbt8tyMmOM8VsSex3UA94VEXDKytdVtUzDw5bWj3aEqt4CbFfV/mWKaYwxKZasXgequhI4KxnHKq1G20ZEGgJ3iMhwnBsVYkNsS0aAsrji8o706/cUWaEQQ4a+Qd9/DAwqiieDXurLlZ0uZsuWrbRte0XQceJq2Kg+L77cl7rH1kFVGZ47isGDhgcdy5NQKMQ7n45g04bN/OamPwQdJ650z7v/QAG3/30oBYURCiNRLmt7Gvf+8iJUlX+9PZmJsxeTFQpxw8Vnc9NlHYKOCySv6SCZSitoXwImAScAczm0oFV3fcqFQiEG9H+aTld1Z+3aDcz84gPGjZ/I0qUrgojjycgRY3j5pWG88kq/oKN4EimM8HivZ1i4YAlVq+Ywado7TJ08g+XL8oKOFlePnt3JW76KqtVygo7iSbrnrVghzL8f7kGVStkUFEa4rc8QzmvRnJUbfmDjth2M/ftvCYVCbN25O+ioB6XjMIklzoKrqgNU9VRgiKqeoKrNYpZAClmAdm1bkZe3mlWrvqegoIDRo8dy7TXpXUucMWMW27ZlzqTBmzZtYeGCJQDs3p3P8mV5NGhYL+BU8dVrcCwdLzuXt0a+F3QUTzIhr4hQpVI2AIWRCIWRCIgwevJsftP5QkIhpwipXb1qkDEPEVX1vKRKqRfDRCQLuChFWTxp2Kg+a9b+1Olh7boNtGvbKsBE5VuT4xrR4szTmDtnQdBR4ur19IP0/esAcqqmZ+3wcJmSNxKN0v2Jl/l+8za6XdKOM09szNrNP/Lxl4uZPG8pNavl8PBNV3J8/dpBRwUyrEYLoKoRYFlJt+GWRER6isgcEZkTjeYfVUATnJycKuSOeIFej/Rh9670/jl2vOw8tm7ZxuKF3wQdxZNMypsVCjH6b/cwsd8fWbRyHSvWbuJAYSEVK4R548nfcN2FrXliyNigYx4U0YjnJVW8dO+qCSwWkVnAwd82Vb22pB1iOwGHKzZK6p+X9es20qRxw4PPGzdqwPr1G5N5CgOEw2GGjnyBMaPHMWHcxKDjxNWm/Vlc0ukCLrz0XLIrVaRq1ar848WneOjex4OOVqxMywtQPacybU9tyudff0u9mtW55OxTAbikzak88Wr6FLQZNUxijMd8T5GA2XPm07x5M5o2bcK6dRvp2rUzt9x6X9Cxyp3+A/uwfFkegwYODTqKJ8/1HshzvZ3eJ+1+3oY777s5rQutTMm7bWc+4awQ1XMqs+9AATMXr+T2q87lotanMHvpKhrXrcmcb1anTbMBZOjA3+k2vXgkEuH+Bx7lgwmvkxUKkTtsFEuWLA86Vqlycwdw/gUdqF27JstXfEHv3s8zfNjooGOVqH2HNnTr3oXFi75hynSnpvL0U/34dGJafRRMCvywYxePvvIe0WiUqCqXtzudC1v+jFYnHcdfXn6HkRNnUiW7Ik/cXuI/uCmXjjVaiRdKRDoALwCnAhWBLCDf68DfyW468FsmTjdeOVwx6AgJq5Vt48b7beH7DwYdIWGVzuku8bcqXYMap3kuczZsX3LU5/PCS9PBv4AbgbeAs4FbgZP9DGWMMWWVcb0Oiqjqt0CWqkZUdSjQyd9YxhhTNhGNel5SxUuNdo+IVATmi0hfYAMeC2hjjEm1dGyj9VJg3uJu91uc7l1NgF/5GcoYY8oq4+4MA1DV70SkMtBAVf+agkzGGFNmGVmjFZFrgPnAR+7zliLyvt/BjDGmLKKo5yVVvDQdPIkzfcN2AFWdjzNBozHGpB1V9bykipeLYQWqusMdZbxI+tXNjTGGzJ1ufLGI/BrIEpGTgN8Dn/sbyxhjyiYdB/4uselAREa4D/OA04H9wBvATuAB/6MZY0ziMq3poGgqm244Y9I+F/NaFWCfn8GMMaYsknlnmIh0AvrjDD3wb1V9pizH8TqVzZzYcxPgVDbGGFOaZNVU3YkPBgKXAWuB2SLyvqouSfRYJRa0qjoAGCAig1T1njKnNcaYFEpiG2074Ft3NlxE5E2gM5C8grbI0RayhQfW+TY6joj0dAcZzwiZlhcyL3Om5QXLnGyJlDki0hPoGbNqcMz31QhYE/PaWqB9WTJl+pgFPeNvklYyLS9kXuZMywuWOTCqOlhVz45ZfPnjkekFrTHG+GUdztguRRq76xJmBa0xxhRvNnCSiDRzRzC8ESjT8ANeblhIZ2nZRlSKTMsLmZc50/KCZU5LqlooIr8FPsbp3jVEVReX5Vhxp7IxxhhzdKzpwBhjfGYFrTHG+CyjC1oRaeoOeFOWfXcnO4+Hc94mIv8K4LxNRWRRqs+bTuw9OJKI/F5ElorIa6k6VhC/d+kg0y+GNQV+Dbx++AsiElbVwpQnMiaJfP4c3wtcqqpry3qAmHxHfazyLJAarVu7WCoir4jIYhGZKCKVReREEflIROaKyGcicoq7fa6IXB+zf9FfxWeA80Vkvoj8wa0xvi8ik4FJIlJVRCaJyDwR+VpEOvv0/dwqIgtFZIGIjBCRa0TkSxH5SkQ+FZF6xeyTKyKDRGSmiKwUkY4iMsR9X3J9iJlVzPt9l4jMdnO/LSJVYrK9JCJzRGS5iFztrr9NRMaKyFQRWSEiT7jrnxKRgyO6icjTInK/D98DIpIjIhPczItEpJuIPO5+H4tEZLC4gyeLSBt3uwXAfX7kKSbfe+7nd7F71xEistt9Txa4P+967voT3edfi0jvos+1+1n4TJyZTJb48f6KyEs445V8KCK93M/eLPcz29ndpqmbY567/LyEfLHH+oOIPCkif4o51yIRaXo0eTNeIkOKJWvBqYkWAi3d56OBm3EGsTnJXdcemOw+zgWuj9l/t/u1IzA+Zv1tOLfJ1XKfh4Hq7uM6wLf81NNid5K+l9OB5UAd93ktoGbMef4HeC4m379ivqc3cQbp6Ywz/GQLnD9+c4veG5/f79ox2/QGfheT7SM3y0nue1rJzb8BqA1UBhYBZ7vHn+fuG8IZWrN2svIf9r38Cngl5vkxRT9v9/kI4Br38ULgAvfxP4BFKfhsF332it6f2jiDMBVl6gs86j4eD3R3H9992Oc6H2gW8/NL+vsLrHZ/L/oAN7vrarif5xycUfoquetPAuYUly/2WO7jJ4E/xby2CGiazN+7TFuCbDpYpc60OOAULE2BnwNvyU+zOWSX4bifqOo297EAfUTkAiCKc+9yPWBjWUMX42LgLVX9AUBVt4lIC2CUiDQAKgKrSth3nKqqiHwNbFLVrwFEZDHO+zG/hP3Korj3+wwR6Y3zy1UVp79gkdGqGgVWiMhK4BR3/SequtXN+Q5wnqr+U0S2ikgrnPf3q6JtfPA18JyIPIvzR/YzEfmViPwZp2CohTNY/WdADVWd5u43ArjSp0yxfi8iv3QfN8EpoA7gFKrgvPeXuY/PAbq4j18H/i/mOLNUdRWAqq72+f29HLg2phZaCTgOWA/8S0RaAhHg5OLymfiCLGj3xzyO4HyAtqtqy2K2LcRt5hCREE7hVZL8mMc3AXWBNqpaICKrcT5EfnsB6Keq74tIR5y/8MUpeg+iHPp+REn+z+bw97syTs21i6ouEJHbcGoqRQ7vYK1x1v8bp8ZbHxhy1GlLoKrLRaQ1cBXQW0Qm4TQLnK2qa0TkSVLzMz6C+7O+FDhHVfeIyFQ3S4G61Tmc997Lzzb/sOd+vr8C/EpVlx2y0nkvNwFn4fz+xY5BfXi+WAd/X12B/DzSSTr1OtgJrBKRGwDEcZb72mqgjfv4WqCC+3gXUK2UYx4DbHYL2YuA45OeGiYDN4hIbQARqeWet+ie6B4+nDNZqgEbRKQCzh+lWDeISEhETsRpfyv6JbxMRGqJMwV9F2CGu/5doBPQlkNrxkklzmD0e1R1JE5zQGv3pR9EpCpwPYCqbge2i8h57uuHf39+OAb40S1kTwE6xNl+Jk5TCDi3d5bGz/f3Y+B3MW3brdz1xwAb3P9sbsG5O8qL1bg/F/eP4n/9ZK7p1uvgJmCQiDyKU5i+CSwAXgHGuhc1PuKnv6YLgYi7Phf48bDjvQaMc/81nwN8k+zAqrpYRJ4G/iMiEeArnBrsWyLyI05BnK4ftMeAL4Et7tfYP1rfA7OA6sDdqrrP/T2cBbyNM8DGSFWdA6CqB0RkCs5/JREfM7cA/iEiUaAAuAenwF+E0yQ0O2bb24EhIqLARB8zFfkIuFtEluL8YZoZZ/sHgJEi0svdd0dJG/r8/v4N+Cew0P2PcRVwNfAi8LaI3Mqhv3fxvA3c6jaBfYnT5vtfzW7BNUcQp9fDeFUdc9j623D+Rf9tMfuEgHnADaq6IhU5M504vTz2uu30N+JcGCu2Z4y9v5ktnZoOTIYSkdNwenRMskIgIW2A+SKyEKcf6oPFbWTvb+azGq0xxvjMarTGGOMzK2iNMcZnVtAaY4zPrKA1xhifWUFrjDE++38w2RUuvzTBvAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "fJDTGH_OUX0z"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}