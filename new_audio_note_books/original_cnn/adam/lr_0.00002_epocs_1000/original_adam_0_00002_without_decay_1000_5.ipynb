{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "original_adam_0.00002_without decay_1000_5.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9SRCO-a_AlH5",
        "outputId": "9af93663-7ba9-4ef0-95ff-dee923208e8d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install librosa"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Lo4mUwG9RMd",
        "outputId": "0508fc4a-e12d-493f-90fe-06d26b9edf5a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.7/dist-packages (0.8.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (21.3)\n",
            "Requirement already satisfied: numba>=0.43.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (0.51.2)\n",
            "Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.6.0)\n",
            "Requirement already satisfied: soundfile>=0.10.2 in /usr/local/lib/python3.7/dist-packages (from librosa) (0.10.3.post1)\n",
            "Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.0.2)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.1.0)\n",
            "Requirement already satisfied: audioread>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (2.1.9)\n",
            "Requirement already satisfied: decorator>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied: resampy>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from librosa) (0.2.2)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.21.6)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.4.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba>=0.43.0->librosa) (57.4.0)\n",
            "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba>=0.43.0->librosa) (0.34.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->librosa) (3.0.9)\n",
            "Requirement already satisfied: appdirs>=1.3.0 in /usr/local/lib/python3.7/dist-packages (from pooch>=1.0->librosa) (1.4.4)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from pooch>=1.0->librosa) (2.23.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2022.5.18.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (3.0.4)\n",
            "Requirement already satisfied: six>=1.3 in /usr/local/lib/python3.7/dist-packages (from resampy>=0.2.2->librosa) (1.15.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn!=0.19.0,>=0.14.0->librosa) (3.1.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.7/dist-packages (from soundfile>=0.10.2->librosa) (1.15.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.0->soundfile>=0.10.2->librosa) (2.21)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HJjcbxwy46bG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "1e1de3cf-d05c-4ab0-e485-f734c00343ec"
      },
      "source": [
        "# Orignial Notebook: https://github.com/MITESHPUTHRANNEU/Speech-Emotion-Analyzer/blob/master/final_results_gender_test.ipynb\n",
        "# This notebook author: Reza Chu\n",
        "# Last Editing Date: 31st May 2019\n",
        "\n",
        "## Python\n",
        "import os\n",
        "import random\n",
        "import sys\n",
        "\n",
        "import IPython\n",
        "from IPython.display import Audio\n",
        "from IPython.display import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "## Package\n",
        "import glob \n",
        "import keras\n",
        "import IPython.display as ipd\n",
        "import librosa\n",
        "import librosa.display\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import plotly.graph_objs as go\n",
        "import plotly.offline as py\n",
        "import plotly.tools as tls\n",
        "import seaborn as sns\n",
        "import scipy.io.wavfile\n",
        "import tensorflow as tf\n",
        "py.init_notebook_mode(connected=True)\n",
        "\n",
        "## Keras\n",
        "from keras import regularizers\n",
        "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping\n",
        "from keras.callbacks import  History, ReduceLROnPlateau, CSVLogger\n",
        "from keras.models import Model, Sequential\n",
        "from keras.layers import Dense, Embedding, LSTM\n",
        "from keras.layers import Input, Flatten, Dropout, Activation, BatchNormalization\n",
        "from keras.layers import Conv1D, MaxPooling1D, AveragePooling1D\n",
        "from keras.preprocessing import sequence\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.utils import np_utils\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "## Sklearn\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "## Rest\n",
        "from scipy.fftpack import fft\n",
        "from scipy import signal\n",
        "from scipy.io import wavfile\n",
        "from tqdm import tqdm\n",
        "\n",
        "input_duration=3\n",
        "# % pylab inline"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "        <script type=\"text/javascript\">\n",
              "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
              "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
              "        if (typeof require !== 'undefined') {\n",
              "        require.undef(\"plotly\");\n",
              "        requirejs.config({\n",
              "            paths: {\n",
              "                'plotly': ['https://cdn.plot.ly/plotly-2.8.3.min']\n",
              "            }\n",
              "        });\n",
              "        require(['plotly'], function(Plotly) {\n",
              "            window._Plotly = Plotly;\n",
              "        });\n",
              "        }\n",
              "        </script>\n",
              "        "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Saving joblib files to not load them again with the loop above\n",
        "\n",
        "# import joblib\n",
        "\n",
        "# X_name = 'x.joblib'\n",
        "# y_name = 'y.joblib'\n",
        "# save_dir = '/content/drive/My Drive/graduation project/audio/paper_code/features'\n",
        "\n",
        "# savedX = joblib.dump(X, os.path.join(save_dir, X_name))\n",
        "# savedy = joblib.dump(y, os.path.join(save_dir, y_name))"
      ],
      "metadata": {
        "id": "UCzic8rlDcuk"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Loading saved models\n",
        "import joblib\n",
        "X = joblib.load('/content/drive/My Drive/graduation project/audio/paper_code/features/x.joblib')\n",
        "y = joblib.load('/content/drive/My Drive/graduation project/audio/paper_code/features/y.joblib')"
      ],
      "metadata": {
        "id": "Q35CN6zDrzg1"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7PSTurzjCo5K",
        "outputId": "b3ff6a8d-f13c-428f-c9bf-4438e47b42b5"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2068, 40)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.1 ,shuffle = True\n",
        "                                                    , random_state=42)\n",
        "X_train , X_valid, y_train, y_valid = train_test_split(X_train,y_train, test_size=0.1112305212 , shuffle = True \n",
        "                                                       , random_state=42)"
      ],
      "metadata": {
        "id": "Ai4Fy5cPCiq1"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "x_traincnn = np.expand_dims(X_train, axis=2)\n",
        "x_testcnn = np.expand_dims(X_test, axis=2)\n",
        "X_valid= np.expand_dims(X_valid, axis=2)"
      ],
      "metadata": {
        "id": "tp1Fm5K3CEXu"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_traincnn.shape, x_testcnn.shape , X_valid.shape\n",
        "#1861"
      ],
      "metadata": {
        "id": "RI0MxoIPBws5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a59cf56-81cf-4a7f-bd8c-6870f4ccae12"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1654, 40, 1), (207, 40, 1), (207, 40, 1))"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oALhiMUd9G2Y",
        "outputId": "bc5bed13-adc1-4792-c170-068a6b6b7581"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (2.8.2+zzzcolab20220527125636)\n",
            "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.17.3)\n",
            "Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.5.3)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.21.6)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (4.2.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.26.0)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.46.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow) (57.4.0)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.0.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (14.0.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow) (1.5.2)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.35.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.4.6)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.6.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.8.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (3.3.7)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.23.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.8)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.2.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (4.11.4)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (3.8.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2022.5.18.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (1.24.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (3.2.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from keras.preprocessing import sequence\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from keras.layers import Input, Flatten, Dropout, Activation\n",
        "from keras.layers import Conv1D, MaxPooling1D\n",
        "from keras.models import Model\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras import optimizers\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv1D(128, 8,padding='same', #classifier.add(Convolution2D(64, (3, 3), padding = 'same', input_shape = (128, 128, 3), activation = 'relu'))\n",
        "                 input_shape=(40,1)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(MaxPooling1D(pool_size=(5)))\n",
        "\n",
        "\n",
        "model.add(Conv1D(256,8,padding='same',))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(MaxPooling1D(pool_size=(5)))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(256))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(256))\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "model.add(Dense(6))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "opt = tf.keras.optimizers.Adam(lr=0.00002 , decay=0.0)\n",
        "#opt = tf.keras.optimizers.RMSprop(lr=0.0001, rho=0.9, epsilon=1e-07, decay=0.0)\n",
        "#opt = tf.keras.optimizers.SGD(lr=0.001, momentum=0.0, decay=0.0, nesterov=False)"
      ],
      "metadata": {
        "id": "g74fXWVAC4Cr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd1a911c-5135-44af-a6dd-96d4f0f4c437"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning:\n",
            "\n",
            "The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H6ukOxAGC_I4",
        "outputId": "17980263-7cff-44b9-98ef-b31384bd5537"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d (Conv1D)             (None, 40, 128)           1152      \n",
            "                                                                 \n",
            " activation (Activation)     (None, 40, 128)           0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 40, 128)           0         \n",
            "                                                                 \n",
            " max_pooling1d (MaxPooling1D  (None, 8, 128)           0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv1d_1 (Conv1D)           (None, 8, 256)            262400    \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 8, 256)            0         \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 8, 256)            0         \n",
            "                                                                 \n",
            " max_pooling1d_1 (MaxPooling  (None, 1, 256)           0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 256)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 256)               65792     \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 256)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 256)               65792     \n",
            "                                                                 \n",
            " activation_3 (Activation)   (None, 256)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 6)                 1542      \n",
            "                                                                 \n",
            " activation_4 (Activation)   (None, 6)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 396,678\n",
            "Trainable params: 396,678\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='sparse_categorical_crossentropy',\n",
        "              optimizer=opt,\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "AbMlLNk4DCBM"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an Instance of Early Stopping Callback.\n",
        "early_stopping_callback = EarlyStopping(monitor = 'val_loss', patience = 25, mode = 'min', restore_best_weights = True)\n",
        "\n",
        "cnnhistory=model.fit(x_traincnn, y_train, batch_size=16, epochs=1000 , shuffle = True, \n",
        "                     validation_data=(X_valid, y_valid) \n",
        "                     , callbacks = [early_stopping_callback]\n",
        "                     )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RI1v2AuADFhy",
        "outputId": "bc78132b-c421-4815-dd5f-a23fe69ec312"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "104/104 [==============================] - 5s 13ms/step - loss: 6.4236 - accuracy: 0.1518 - val_loss: 2.1553 - val_accuracy: 0.1739\n",
            "Epoch 2/1000\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 4.6444 - accuracy: 0.1711 - val_loss: 2.0054 - val_accuracy: 0.1787\n",
            "Epoch 3/1000\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 3.9437 - accuracy: 0.1941 - val_loss: 1.9718 - val_accuracy: 0.1932\n",
            "Epoch 4/1000\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 3.6057 - accuracy: 0.1838 - val_loss: 1.9341 - val_accuracy: 0.1981\n",
            "Epoch 5/1000\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 3.2980 - accuracy: 0.1844 - val_loss: 1.8122 - val_accuracy: 0.1691\n",
            "Epoch 6/1000\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 3.0465 - accuracy: 0.1838 - val_loss: 1.8728 - val_accuracy: 0.1594\n",
            "Epoch 7/1000\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 2.9002 - accuracy: 0.1820 - val_loss: 1.7782 - val_accuracy: 0.1981\n",
            "Epoch 8/1000\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 2.7762 - accuracy: 0.1778 - val_loss: 1.7687 - val_accuracy: 0.2077\n",
            "Epoch 9/1000\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 2.5841 - accuracy: 0.1989 - val_loss: 1.8023 - val_accuracy: 0.1932\n",
            "Epoch 10/1000\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 2.5584 - accuracy: 0.1971 - val_loss: 1.7550 - val_accuracy: 0.1932\n",
            "Epoch 11/1000\n",
            "104/104 [==============================] - 1s 9ms/step - loss: 2.4028 - accuracy: 0.2183 - val_loss: 1.7618 - val_accuracy: 0.2077\n",
            "Epoch 12/1000\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 2.3434 - accuracy: 0.2074 - val_loss: 1.7706 - val_accuracy: 0.2222\n",
            "Epoch 13/1000\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 2.2804 - accuracy: 0.2025 - val_loss: 1.7512 - val_accuracy: 0.2222\n",
            "Epoch 14/1000\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 2.2667 - accuracy: 0.1929 - val_loss: 1.7434 - val_accuracy: 0.2222\n",
            "Epoch 15/1000\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 2.1730 - accuracy: 0.2104 - val_loss: 1.7325 - val_accuracy: 0.2319\n",
            "Epoch 16/1000\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 2.1724 - accuracy: 0.2080 - val_loss: 1.7510 - val_accuracy: 0.2271\n",
            "Epoch 17/1000\n",
            "104/104 [==============================] - 1s 9ms/step - loss: 2.1484 - accuracy: 0.2122 - val_loss: 1.7589 - val_accuracy: 0.2705\n",
            "Epoch 18/1000\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 2.0860 - accuracy: 0.2195 - val_loss: 1.7455 - val_accuracy: 0.2754\n",
            "Epoch 19/1000\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 2.0618 - accuracy: 0.2068 - val_loss: 1.7578 - val_accuracy: 0.2609\n",
            "Epoch 20/1000\n",
            "104/104 [==============================] - 1s 9ms/step - loss: 2.0097 - accuracy: 0.2237 - val_loss: 1.7453 - val_accuracy: 0.2609\n",
            "Epoch 21/1000\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 2.0042 - accuracy: 0.2177 - val_loss: 1.7400 - val_accuracy: 0.2705\n",
            "Epoch 22/1000\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 2.0353 - accuracy: 0.2056 - val_loss: 1.7314 - val_accuracy: 0.2512\n",
            "Epoch 23/1000\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 1.9419 - accuracy: 0.2412 - val_loss: 1.7303 - val_accuracy: 0.2512\n",
            "Epoch 24/1000\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 1.9730 - accuracy: 0.2237 - val_loss: 1.7217 - val_accuracy: 0.2850\n",
            "Epoch 25/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 1.9234 - accuracy: 0.2316 - val_loss: 1.7316 - val_accuracy: 0.2899\n",
            "Epoch 26/1000\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 1.9290 - accuracy: 0.2346 - val_loss: 1.7237 - val_accuracy: 0.3043\n",
            "Epoch 27/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 1.9157 - accuracy: 0.2177 - val_loss: 1.6994 - val_accuracy: 0.3188\n",
            "Epoch 28/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.9291 - accuracy: 0.2189 - val_loss: 1.7163 - val_accuracy: 0.2754\n",
            "Epoch 29/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.9020 - accuracy: 0.2443 - val_loss: 1.7062 - val_accuracy: 0.2995\n",
            "Epoch 30/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.8684 - accuracy: 0.2376 - val_loss: 1.7040 - val_accuracy: 0.2995\n",
            "Epoch 31/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.8587 - accuracy: 0.2491 - val_loss: 1.7032 - val_accuracy: 0.2899\n",
            "Epoch 32/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.8513 - accuracy: 0.2249 - val_loss: 1.6943 - val_accuracy: 0.2995\n",
            "Epoch 33/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.8197 - accuracy: 0.2388 - val_loss: 1.7039 - val_accuracy: 0.2995\n",
            "Epoch 34/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.8323 - accuracy: 0.2328 - val_loss: 1.6893 - val_accuracy: 0.3188\n",
            "Epoch 35/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.8106 - accuracy: 0.2455 - val_loss: 1.6826 - val_accuracy: 0.3623\n",
            "Epoch 36/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.8097 - accuracy: 0.2430 - val_loss: 1.6888 - val_accuracy: 0.2802\n",
            "Epoch 37/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.7992 - accuracy: 0.2424 - val_loss: 1.6796 - val_accuracy: 0.2995\n",
            "Epoch 38/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.8131 - accuracy: 0.2310 - val_loss: 1.6955 - val_accuracy: 0.3285\n",
            "Epoch 39/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.7509 - accuracy: 0.2551 - val_loss: 1.6891 - val_accuracy: 0.2899\n",
            "Epoch 40/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.7546 - accuracy: 0.2696 - val_loss: 1.6677 - val_accuracy: 0.2995\n",
            "Epoch 41/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.7585 - accuracy: 0.2684 - val_loss: 1.6701 - val_accuracy: 0.3140\n",
            "Epoch 42/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.8033 - accuracy: 0.2497 - val_loss: 1.6690 - val_accuracy: 0.2754\n",
            "Epoch 43/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.7549 - accuracy: 0.2721 - val_loss: 1.6495 - val_accuracy: 0.3430\n",
            "Epoch 44/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.7443 - accuracy: 0.2799 - val_loss: 1.6449 - val_accuracy: 0.3285\n",
            "Epoch 45/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.7009 - accuracy: 0.2757 - val_loss: 1.6405 - val_accuracy: 0.3285\n",
            "Epoch 46/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.7494 - accuracy: 0.2666 - val_loss: 1.6377 - val_accuracy: 0.2705\n",
            "Epoch 47/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.7391 - accuracy: 0.2878 - val_loss: 1.6319 - val_accuracy: 0.2995\n",
            "Epoch 48/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.7213 - accuracy: 0.2745 - val_loss: 1.6295 - val_accuracy: 0.3575\n",
            "Epoch 49/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.7353 - accuracy: 0.2775 - val_loss: 1.6337 - val_accuracy: 0.3140\n",
            "Epoch 50/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.7142 - accuracy: 0.2842 - val_loss: 1.6355 - val_accuracy: 0.3478\n",
            "Epoch 51/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.6949 - accuracy: 0.3053 - val_loss: 1.6270 - val_accuracy: 0.3333\n",
            "Epoch 52/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.6797 - accuracy: 0.3005 - val_loss: 1.6064 - val_accuracy: 0.3333\n",
            "Epoch 53/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.7180 - accuracy: 0.2926 - val_loss: 1.6095 - val_accuracy: 0.3333\n",
            "Epoch 54/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.6937 - accuracy: 0.2878 - val_loss: 1.6096 - val_accuracy: 0.3237\n",
            "Epoch 55/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.7108 - accuracy: 0.2703 - val_loss: 1.6034 - val_accuracy: 0.3478\n",
            "Epoch 56/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.6872 - accuracy: 0.2920 - val_loss: 1.6099 - val_accuracy: 0.3720\n",
            "Epoch 57/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.6840 - accuracy: 0.2914 - val_loss: 1.5870 - val_accuracy: 0.4300\n",
            "Epoch 58/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.6669 - accuracy: 0.3144 - val_loss: 1.5995 - val_accuracy: 0.3333\n",
            "Epoch 59/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.6607 - accuracy: 0.3241 - val_loss: 1.6210 - val_accuracy: 0.3188\n",
            "Epoch 60/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.6696 - accuracy: 0.2938 - val_loss: 1.5924 - val_accuracy: 0.3430\n",
            "Epoch 61/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.6573 - accuracy: 0.3289 - val_loss: 1.5873 - val_accuracy: 0.3527\n",
            "Epoch 62/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.6542 - accuracy: 0.3174 - val_loss: 1.5747 - val_accuracy: 0.3913\n",
            "Epoch 63/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.6457 - accuracy: 0.3229 - val_loss: 1.5917 - val_accuracy: 0.3478\n",
            "Epoch 64/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.6302 - accuracy: 0.3277 - val_loss: 1.5574 - val_accuracy: 0.4300\n",
            "Epoch 65/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.6368 - accuracy: 0.3180 - val_loss: 1.5794 - val_accuracy: 0.3478\n",
            "Epoch 66/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.6283 - accuracy: 0.3356 - val_loss: 1.5768 - val_accuracy: 0.3237\n",
            "Epoch 67/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.6135 - accuracy: 0.3186 - val_loss: 1.5512 - val_accuracy: 0.4203\n",
            "Epoch 68/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.6148 - accuracy: 0.3204 - val_loss: 1.5579 - val_accuracy: 0.4058\n",
            "Epoch 69/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.6213 - accuracy: 0.3204 - val_loss: 1.5699 - val_accuracy: 0.3720\n",
            "Epoch 70/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.6102 - accuracy: 0.3356 - val_loss: 1.5584 - val_accuracy: 0.3382\n",
            "Epoch 71/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.6319 - accuracy: 0.3156 - val_loss: 1.5499 - val_accuracy: 0.4010\n",
            "Epoch 72/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.5894 - accuracy: 0.3464 - val_loss: 1.5567 - val_accuracy: 0.3816\n",
            "Epoch 73/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.5868 - accuracy: 0.3489 - val_loss: 1.5340 - val_accuracy: 0.4348\n",
            "Epoch 74/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.6066 - accuracy: 0.3277 - val_loss: 1.5415 - val_accuracy: 0.3913\n",
            "Epoch 75/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.5760 - accuracy: 0.3501 - val_loss: 1.5259 - val_accuracy: 0.3961\n",
            "Epoch 76/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.5982 - accuracy: 0.3319 - val_loss: 1.5259 - val_accuracy: 0.3865\n",
            "Epoch 77/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.5759 - accuracy: 0.3362 - val_loss: 1.5247 - val_accuracy: 0.4493\n",
            "Epoch 78/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.5886 - accuracy: 0.3386 - val_loss: 1.5364 - val_accuracy: 0.3768\n",
            "Epoch 79/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.5625 - accuracy: 0.3609 - val_loss: 1.5170 - val_accuracy: 0.4638\n",
            "Epoch 80/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.5737 - accuracy: 0.3507 - val_loss: 1.5220 - val_accuracy: 0.4058\n",
            "Epoch 81/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.5507 - accuracy: 0.3531 - val_loss: 1.5201 - val_accuracy: 0.3768\n",
            "Epoch 82/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.5547 - accuracy: 0.3519 - val_loss: 1.5075 - val_accuracy: 0.4010\n",
            "Epoch 83/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.5447 - accuracy: 0.3712 - val_loss: 1.5256 - val_accuracy: 0.3865\n",
            "Epoch 84/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.5543 - accuracy: 0.3622 - val_loss: 1.5034 - val_accuracy: 0.4348\n",
            "Epoch 85/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.5308 - accuracy: 0.3791 - val_loss: 1.5037 - val_accuracy: 0.4251\n",
            "Epoch 86/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.5323 - accuracy: 0.3706 - val_loss: 1.4974 - val_accuracy: 0.4444\n",
            "Epoch 87/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.5285 - accuracy: 0.3652 - val_loss: 1.4980 - val_accuracy: 0.4541\n",
            "Epoch 88/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.5333 - accuracy: 0.3688 - val_loss: 1.4921 - val_accuracy: 0.4155\n",
            "Epoch 89/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.5188 - accuracy: 0.3682 - val_loss: 1.4868 - val_accuracy: 0.4058\n",
            "Epoch 90/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.5178 - accuracy: 0.3742 - val_loss: 1.4862 - val_accuracy: 0.4155\n",
            "Epoch 91/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.5350 - accuracy: 0.3628 - val_loss: 1.4815 - val_accuracy: 0.4348\n",
            "Epoch 92/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.5054 - accuracy: 0.3718 - val_loss: 1.4707 - val_accuracy: 0.4251\n",
            "Epoch 93/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.5180 - accuracy: 0.3507 - val_loss: 1.4833 - val_accuracy: 0.3816\n",
            "Epoch 94/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.4940 - accuracy: 0.3730 - val_loss: 1.4699 - val_accuracy: 0.4300\n",
            "Epoch 95/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.5085 - accuracy: 0.3815 - val_loss: 1.4872 - val_accuracy: 0.3913\n",
            "Epoch 96/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.4772 - accuracy: 0.4021 - val_loss: 1.4442 - val_accuracy: 0.4444\n",
            "Epoch 97/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.4722 - accuracy: 0.3906 - val_loss: 1.4584 - val_accuracy: 0.4058\n",
            "Epoch 98/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.4763 - accuracy: 0.3851 - val_loss: 1.4396 - val_accuracy: 0.4831\n",
            "Epoch 99/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.4525 - accuracy: 0.3857 - val_loss: 1.4278 - val_accuracy: 0.4541\n",
            "Epoch 100/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.4896 - accuracy: 0.4015 - val_loss: 1.4220 - val_accuracy: 0.5121\n",
            "Epoch 101/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.4657 - accuracy: 0.3984 - val_loss: 1.4371 - val_accuracy: 0.4396\n",
            "Epoch 102/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.4769 - accuracy: 0.3888 - val_loss: 1.4318 - val_accuracy: 0.4493\n",
            "Epoch 103/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.4621 - accuracy: 0.4087 - val_loss: 1.4131 - val_accuracy: 0.5266\n",
            "Epoch 104/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.4697 - accuracy: 0.3936 - val_loss: 1.4214 - val_accuracy: 0.4831\n",
            "Epoch 105/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.4536 - accuracy: 0.3918 - val_loss: 1.4254 - val_accuracy: 0.4541\n",
            "Epoch 106/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.4489 - accuracy: 0.4045 - val_loss: 1.4079 - val_accuracy: 0.5024\n",
            "Epoch 107/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.4258 - accuracy: 0.4178 - val_loss: 1.4058 - val_accuracy: 0.4638\n",
            "Epoch 108/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.4390 - accuracy: 0.4178 - val_loss: 1.4013 - val_accuracy: 0.4976\n",
            "Epoch 109/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.4425 - accuracy: 0.4099 - val_loss: 1.4042 - val_accuracy: 0.4831\n",
            "Epoch 110/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.4338 - accuracy: 0.4256 - val_loss: 1.4013 - val_accuracy: 0.4783\n",
            "Epoch 111/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.4020 - accuracy: 0.4407 - val_loss: 1.3925 - val_accuracy: 0.4686\n",
            "Epoch 112/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.4247 - accuracy: 0.4117 - val_loss: 1.3933 - val_accuracy: 0.4589\n",
            "Epoch 113/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.4209 - accuracy: 0.4226 - val_loss: 1.3795 - val_accuracy: 0.4396\n",
            "Epoch 114/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.4225 - accuracy: 0.4220 - val_loss: 1.3941 - val_accuracy: 0.4493\n",
            "Epoch 115/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.3899 - accuracy: 0.4492 - val_loss: 1.3670 - val_accuracy: 0.4928\n",
            "Epoch 116/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.3928 - accuracy: 0.4305 - val_loss: 1.3605 - val_accuracy: 0.4831\n",
            "Epoch 117/1000\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 1.3829 - accuracy: 0.4462 - val_loss: 1.3498 - val_accuracy: 0.5169\n",
            "Epoch 118/1000\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 1.3954 - accuracy: 0.4160 - val_loss: 1.3516 - val_accuracy: 0.4686\n",
            "Epoch 119/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 1.3667 - accuracy: 0.4492 - val_loss: 1.3453 - val_accuracy: 0.5072\n",
            "Epoch 120/1000\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 1.3775 - accuracy: 0.4323 - val_loss: 1.3462 - val_accuracy: 0.5072\n",
            "Epoch 121/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.3675 - accuracy: 0.4432 - val_loss: 1.3402 - val_accuracy: 0.5072\n",
            "Epoch 122/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.3766 - accuracy: 0.4287 - val_loss: 1.3378 - val_accuracy: 0.4928\n",
            "Epoch 123/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.3597 - accuracy: 0.4565 - val_loss: 1.3258 - val_accuracy: 0.5072\n",
            "Epoch 124/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.3611 - accuracy: 0.4595 - val_loss: 1.3230 - val_accuracy: 0.5024\n",
            "Epoch 125/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.3348 - accuracy: 0.4655 - val_loss: 1.3225 - val_accuracy: 0.5072\n",
            "Epoch 126/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.3486 - accuracy: 0.4498 - val_loss: 1.3262 - val_accuracy: 0.5024\n",
            "Epoch 127/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.3494 - accuracy: 0.4395 - val_loss: 1.3258 - val_accuracy: 0.5024\n",
            "Epoch 128/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.3317 - accuracy: 0.4686 - val_loss: 1.3093 - val_accuracy: 0.5024\n",
            "Epoch 129/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.3316 - accuracy: 0.4601 - val_loss: 1.3232 - val_accuracy: 0.5121\n",
            "Epoch 130/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.3400 - accuracy: 0.4583 - val_loss: 1.3009 - val_accuracy: 0.5217\n",
            "Epoch 131/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.3293 - accuracy: 0.4601 - val_loss: 1.3177 - val_accuracy: 0.5072\n",
            "Epoch 132/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.3285 - accuracy: 0.4637 - val_loss: 1.3145 - val_accuracy: 0.5266\n",
            "Epoch 133/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.3308 - accuracy: 0.4619 - val_loss: 1.2944 - val_accuracy: 0.4928\n",
            "Epoch 134/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.3172 - accuracy: 0.4861 - val_loss: 1.2908 - val_accuracy: 0.5072\n",
            "Epoch 135/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.3118 - accuracy: 0.4704 - val_loss: 1.2798 - val_accuracy: 0.5169\n",
            "Epoch 136/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.3053 - accuracy: 0.4885 - val_loss: 1.2812 - val_accuracy: 0.5217\n",
            "Epoch 137/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.3124 - accuracy: 0.4680 - val_loss: 1.2887 - val_accuracy: 0.5266\n",
            "Epoch 138/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.2951 - accuracy: 0.4807 - val_loss: 1.2727 - val_accuracy: 0.5266\n",
            "Epoch 139/1000\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 1.2876 - accuracy: 0.4825 - val_loss: 1.2683 - val_accuracy: 0.5169\n",
            "Epoch 140/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.2930 - accuracy: 0.4807 - val_loss: 1.2662 - val_accuracy: 0.5266\n",
            "Epoch 141/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.2812 - accuracy: 0.4704 - val_loss: 1.2745 - val_accuracy: 0.5459\n",
            "Epoch 142/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.2755 - accuracy: 0.4825 - val_loss: 1.2600 - val_accuracy: 0.5217\n",
            "Epoch 143/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.2742 - accuracy: 0.4758 - val_loss: 1.2482 - val_accuracy: 0.5266\n",
            "Epoch 144/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.2525 - accuracy: 0.5054 - val_loss: 1.2463 - val_accuracy: 0.5169\n",
            "Epoch 145/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.2518 - accuracy: 0.4897 - val_loss: 1.2400 - val_accuracy: 0.5121\n",
            "Epoch 146/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.2787 - accuracy: 0.4776 - val_loss: 1.2390 - val_accuracy: 0.5314\n",
            "Epoch 147/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.2602 - accuracy: 0.5018 - val_loss: 1.2310 - val_accuracy: 0.5314\n",
            "Epoch 148/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.2425 - accuracy: 0.4940 - val_loss: 1.2314 - val_accuracy: 0.5217\n",
            "Epoch 149/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.2718 - accuracy: 0.4740 - val_loss: 1.2376 - val_accuracy: 0.5507\n",
            "Epoch 150/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.2310 - accuracy: 0.5091 - val_loss: 1.2312 - val_accuracy: 0.5507\n",
            "Epoch 151/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.2277 - accuracy: 0.4903 - val_loss: 1.2161 - val_accuracy: 0.5556\n",
            "Epoch 152/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.2356 - accuracy: 0.5054 - val_loss: 1.2115 - val_accuracy: 0.5314\n",
            "Epoch 153/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.2386 - accuracy: 0.5048 - val_loss: 1.2172 - val_accuracy: 0.5507\n",
            "Epoch 154/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.2257 - accuracy: 0.5109 - val_loss: 1.1977 - val_accuracy: 0.5845\n",
            "Epoch 155/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.2082 - accuracy: 0.5127 - val_loss: 1.2063 - val_accuracy: 0.5700\n",
            "Epoch 156/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.2394 - accuracy: 0.4976 - val_loss: 1.2075 - val_accuracy: 0.5556\n",
            "Epoch 157/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.2436 - accuracy: 0.5169 - val_loss: 1.1998 - val_accuracy: 0.5556\n",
            "Epoch 158/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.2248 - accuracy: 0.4994 - val_loss: 1.2076 - val_accuracy: 0.5700\n",
            "Epoch 159/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.2016 - accuracy: 0.5187 - val_loss: 1.1899 - val_accuracy: 0.5894\n",
            "Epoch 160/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.2106 - accuracy: 0.5242 - val_loss: 1.1942 - val_accuracy: 0.5604\n",
            "Epoch 161/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.2321 - accuracy: 0.5109 - val_loss: 1.1955 - val_accuracy: 0.5507\n",
            "Epoch 162/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.2171 - accuracy: 0.5212 - val_loss: 1.1947 - val_accuracy: 0.5845\n",
            "Epoch 163/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.1983 - accuracy: 0.5139 - val_loss: 1.1949 - val_accuracy: 0.5411\n",
            "Epoch 164/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 1.2016 - accuracy: 0.5242 - val_loss: 1.2135 - val_accuracy: 0.5072\n",
            "Epoch 165/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.2029 - accuracy: 0.5157 - val_loss: 1.1785 - val_accuracy: 0.5604\n",
            "Epoch 166/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.1899 - accuracy: 0.5242 - val_loss: 1.1782 - val_accuracy: 0.5652\n",
            "Epoch 167/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.1948 - accuracy: 0.5230 - val_loss: 1.1662 - val_accuracy: 0.5604\n",
            "Epoch 168/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.2038 - accuracy: 0.5139 - val_loss: 1.1678 - val_accuracy: 0.5411\n",
            "Epoch 169/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.1823 - accuracy: 0.5193 - val_loss: 1.1660 - val_accuracy: 0.5652\n",
            "Epoch 170/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.1665 - accuracy: 0.5230 - val_loss: 1.1689 - val_accuracy: 0.5556\n",
            "Epoch 171/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.1818 - accuracy: 0.5326 - val_loss: 1.1590 - val_accuracy: 0.5604\n",
            "Epoch 172/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.1948 - accuracy: 0.5206 - val_loss: 1.1646 - val_accuracy: 0.5411\n",
            "Epoch 173/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.1742 - accuracy: 0.5157 - val_loss: 1.1604 - val_accuracy: 0.5652\n",
            "Epoch 174/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.1831 - accuracy: 0.5248 - val_loss: 1.1527 - val_accuracy: 0.5556\n",
            "Epoch 175/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.1531 - accuracy: 0.5314 - val_loss: 1.1419 - val_accuracy: 0.5700\n",
            "Epoch 176/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.1573 - accuracy: 0.5423 - val_loss: 1.1390 - val_accuracy: 0.5507\n",
            "Epoch 177/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.1654 - accuracy: 0.5441 - val_loss: 1.1372 - val_accuracy: 0.5362\n",
            "Epoch 178/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.1270 - accuracy: 0.5490 - val_loss: 1.1370 - val_accuracy: 0.5749\n",
            "Epoch 179/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.1460 - accuracy: 0.5320 - val_loss: 1.1327 - val_accuracy: 0.5749\n",
            "Epoch 180/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.1622 - accuracy: 0.5242 - val_loss: 1.1249 - val_accuracy: 0.5797\n",
            "Epoch 181/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.1473 - accuracy: 0.5284 - val_loss: 1.1155 - val_accuracy: 0.5990\n",
            "Epoch 182/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.1501 - accuracy: 0.5351 - val_loss: 1.1189 - val_accuracy: 0.5942\n",
            "Epoch 183/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.1472 - accuracy: 0.5308 - val_loss: 1.1196 - val_accuracy: 0.6039\n",
            "Epoch 184/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.1322 - accuracy: 0.5357 - val_loss: 1.1251 - val_accuracy: 0.5652\n",
            "Epoch 185/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.1060 - accuracy: 0.5586 - val_loss: 1.1205 - val_accuracy: 0.5700\n",
            "Epoch 186/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.1009 - accuracy: 0.5726 - val_loss: 1.0978 - val_accuracy: 0.6087\n",
            "Epoch 187/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.1214 - accuracy: 0.5490 - val_loss: 1.1039 - val_accuracy: 0.6135\n",
            "Epoch 188/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.1157 - accuracy: 0.5514 - val_loss: 1.1208 - val_accuracy: 0.5797\n",
            "Epoch 189/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.1274 - accuracy: 0.5484 - val_loss: 1.1124 - val_accuracy: 0.6039\n",
            "Epoch 190/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.1122 - accuracy: 0.5562 - val_loss: 1.0987 - val_accuracy: 0.5894\n",
            "Epoch 191/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.1222 - accuracy: 0.5623 - val_loss: 1.1012 - val_accuracy: 0.6039\n",
            "Epoch 192/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.0977 - accuracy: 0.5665 - val_loss: 1.0987 - val_accuracy: 0.6039\n",
            "Epoch 193/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.1013 - accuracy: 0.5520 - val_loss: 1.1000 - val_accuracy: 0.5749\n",
            "Epoch 194/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.1078 - accuracy: 0.5701 - val_loss: 1.0994 - val_accuracy: 0.5845\n",
            "Epoch 195/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.0983 - accuracy: 0.5647 - val_loss: 1.1052 - val_accuracy: 0.5604\n",
            "Epoch 196/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.1005 - accuracy: 0.5544 - val_loss: 1.0984 - val_accuracy: 0.5700\n",
            "Epoch 197/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.0837 - accuracy: 0.5713 - val_loss: 1.0771 - val_accuracy: 0.6377\n",
            "Epoch 198/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0896 - accuracy: 0.5659 - val_loss: 1.0852 - val_accuracy: 0.5652\n",
            "Epoch 199/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0755 - accuracy: 0.5738 - val_loss: 1.0790 - val_accuracy: 0.6377\n",
            "Epoch 200/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0762 - accuracy: 0.5677 - val_loss: 1.0761 - val_accuracy: 0.5942\n",
            "Epoch 201/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.0804 - accuracy: 0.5647 - val_loss: 1.0605 - val_accuracy: 0.6184\n",
            "Epoch 202/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0809 - accuracy: 0.5738 - val_loss: 1.0810 - val_accuracy: 0.6039\n",
            "Epoch 203/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.0755 - accuracy: 0.5623 - val_loss: 1.0719 - val_accuracy: 0.5942\n",
            "Epoch 204/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0913 - accuracy: 0.5544 - val_loss: 1.0673 - val_accuracy: 0.6232\n",
            "Epoch 205/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.0901 - accuracy: 0.5671 - val_loss: 1.0609 - val_accuracy: 0.6232\n",
            "Epoch 206/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.0579 - accuracy: 0.5883 - val_loss: 1.0808 - val_accuracy: 0.5700\n",
            "Epoch 207/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0671 - accuracy: 0.5713 - val_loss: 1.0652 - val_accuracy: 0.6039\n",
            "Epoch 208/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0658 - accuracy: 0.5931 - val_loss: 1.0526 - val_accuracy: 0.6425\n",
            "Epoch 209/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0536 - accuracy: 0.5786 - val_loss: 1.0408 - val_accuracy: 0.6473\n",
            "Epoch 210/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0579 - accuracy: 0.5762 - val_loss: 1.0485 - val_accuracy: 0.6184\n",
            "Epoch 211/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0719 - accuracy: 0.5689 - val_loss: 1.0421 - val_accuracy: 0.6232\n",
            "Epoch 212/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 1.0492 - accuracy: 0.5816 - val_loss: 1.0625 - val_accuracy: 0.5797\n",
            "Epoch 213/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 1.0593 - accuracy: 0.5780 - val_loss: 1.0492 - val_accuracy: 0.6329\n",
            "Epoch 214/1000\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 1.0503 - accuracy: 0.5985 - val_loss: 1.0449 - val_accuracy: 0.6377\n",
            "Epoch 215/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 1.0541 - accuracy: 0.5846 - val_loss: 1.0462 - val_accuracy: 0.6039\n",
            "Epoch 216/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 1.0412 - accuracy: 0.5871 - val_loss: 1.0530 - val_accuracy: 0.6232\n",
            "Epoch 217/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.0497 - accuracy: 0.5865 - val_loss: 1.0400 - val_accuracy: 0.6232\n",
            "Epoch 218/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0331 - accuracy: 0.5985 - val_loss: 1.0275 - val_accuracy: 0.6232\n",
            "Epoch 219/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0262 - accuracy: 0.5973 - val_loss: 1.0353 - val_accuracy: 0.6087\n",
            "Epoch 220/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0238 - accuracy: 0.6064 - val_loss: 1.0235 - val_accuracy: 0.6280\n",
            "Epoch 221/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0158 - accuracy: 0.5949 - val_loss: 1.0245 - val_accuracy: 0.6329\n",
            "Epoch 222/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.0268 - accuracy: 0.5895 - val_loss: 1.0277 - val_accuracy: 0.6184\n",
            "Epoch 223/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0409 - accuracy: 0.5955 - val_loss: 1.0254 - val_accuracy: 0.6232\n",
            "Epoch 224/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.9989 - accuracy: 0.6082 - val_loss: 1.0235 - val_accuracy: 0.6135\n",
            "Epoch 225/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0168 - accuracy: 0.5943 - val_loss: 1.0216 - val_accuracy: 0.6232\n",
            "Epoch 226/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9963 - accuracy: 0.6070 - val_loss: 1.0008 - val_accuracy: 0.6570\n",
            "Epoch 227/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0256 - accuracy: 0.5810 - val_loss: 1.0083 - val_accuracy: 0.6473\n",
            "Epoch 228/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0404 - accuracy: 0.5967 - val_loss: 1.0074 - val_accuracy: 0.6280\n",
            "Epoch 229/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.9977 - accuracy: 0.5943 - val_loss: 1.0046 - val_accuracy: 0.6232\n",
            "Epoch 230/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.0010 - accuracy: 0.6131 - val_loss: 1.0101 - val_accuracy: 0.6135\n",
            "Epoch 231/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.0191 - accuracy: 0.5877 - val_loss: 1.0129 - val_accuracy: 0.6039\n",
            "Epoch 232/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.0016 - accuracy: 0.5961 - val_loss: 1.0086 - val_accuracy: 0.6473\n",
            "Epoch 233/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.0072 - accuracy: 0.5979 - val_loss: 0.9977 - val_accuracy: 0.6425\n",
            "Epoch 234/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9950 - accuracy: 0.6070 - val_loss: 0.9912 - val_accuracy: 0.6763\n",
            "Epoch 235/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.9915 - accuracy: 0.6088 - val_loss: 0.9839 - val_accuracy: 0.6715\n",
            "Epoch 236/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.9923 - accuracy: 0.6028 - val_loss: 0.9785 - val_accuracy: 0.6425\n",
            "Epoch 237/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9972 - accuracy: 0.6034 - val_loss: 0.9804 - val_accuracy: 0.6860\n",
            "Epoch 238/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9853 - accuracy: 0.6161 - val_loss: 0.9897 - val_accuracy: 0.6522\n",
            "Epoch 239/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.9866 - accuracy: 0.6131 - val_loss: 0.9832 - val_accuracy: 0.6570\n",
            "Epoch 240/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9884 - accuracy: 0.6149 - val_loss: 0.9762 - val_accuracy: 0.6425\n",
            "Epoch 241/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.9770 - accuracy: 0.6197 - val_loss: 0.9811 - val_accuracy: 0.6570\n",
            "Epoch 242/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9752 - accuracy: 0.6125 - val_loss: 0.9819 - val_accuracy: 0.6232\n",
            "Epoch 243/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.9709 - accuracy: 0.6125 - val_loss: 0.9657 - val_accuracy: 0.6570\n",
            "Epoch 244/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.9657 - accuracy: 0.6179 - val_loss: 0.9625 - val_accuracy: 0.6522\n",
            "Epoch 245/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9800 - accuracy: 0.6221 - val_loss: 0.9507 - val_accuracy: 0.6957\n",
            "Epoch 246/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9768 - accuracy: 0.6040 - val_loss: 0.9547 - val_accuracy: 0.6618\n",
            "Epoch 247/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.9643 - accuracy: 0.6245 - val_loss: 0.9594 - val_accuracy: 0.6667\n",
            "Epoch 248/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.9738 - accuracy: 0.6252 - val_loss: 0.9588 - val_accuracy: 0.6667\n",
            "Epoch 249/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.9562 - accuracy: 0.6203 - val_loss: 0.9542 - val_accuracy: 0.6715\n",
            "Epoch 250/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.9667 - accuracy: 0.6203 - val_loss: 0.9565 - val_accuracy: 0.6570\n",
            "Epoch 251/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.9576 - accuracy: 0.6203 - val_loss: 0.9535 - val_accuracy: 0.6667\n",
            "Epoch 252/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.9497 - accuracy: 0.6173 - val_loss: 0.9511 - val_accuracy: 0.6570\n",
            "Epoch 253/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9651 - accuracy: 0.6076 - val_loss: 0.9538 - val_accuracy: 0.6715\n",
            "Epoch 254/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.9463 - accuracy: 0.6191 - val_loss: 0.9500 - val_accuracy: 0.6763\n",
            "Epoch 255/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.9403 - accuracy: 0.6294 - val_loss: 0.9546 - val_accuracy: 0.6570\n",
            "Epoch 256/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9282 - accuracy: 0.6312 - val_loss: 0.9495 - val_accuracy: 0.6667\n",
            "Epoch 257/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9570 - accuracy: 0.6239 - val_loss: 0.9410 - val_accuracy: 0.6667\n",
            "Epoch 258/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9423 - accuracy: 0.6227 - val_loss: 0.9425 - val_accuracy: 0.6763\n",
            "Epoch 259/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.9375 - accuracy: 0.6245 - val_loss: 0.9389 - val_accuracy: 0.6715\n",
            "Epoch 260/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.9317 - accuracy: 0.6185 - val_loss: 0.9337 - val_accuracy: 0.6667\n",
            "Epoch 261/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9591 - accuracy: 0.6149 - val_loss: 0.9564 - val_accuracy: 0.6618\n",
            "Epoch 262/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9346 - accuracy: 0.6360 - val_loss: 0.9424 - val_accuracy: 0.6763\n",
            "Epoch 263/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9267 - accuracy: 0.6324 - val_loss: 0.9557 - val_accuracy: 0.6812\n",
            "Epoch 264/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.9179 - accuracy: 0.6270 - val_loss: 0.9307 - val_accuracy: 0.6763\n",
            "Epoch 265/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.9492 - accuracy: 0.6082 - val_loss: 0.9431 - val_accuracy: 0.6425\n",
            "Epoch 266/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.9379 - accuracy: 0.6227 - val_loss: 0.9156 - val_accuracy: 0.7005\n",
            "Epoch 267/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.9226 - accuracy: 0.6397 - val_loss: 0.9101 - val_accuracy: 0.6957\n",
            "Epoch 268/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9434 - accuracy: 0.6227 - val_loss: 0.9112 - val_accuracy: 0.6812\n",
            "Epoch 269/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.9172 - accuracy: 0.6397 - val_loss: 0.9116 - val_accuracy: 0.7005\n",
            "Epoch 270/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.9304 - accuracy: 0.6342 - val_loss: 0.9229 - val_accuracy: 0.6812\n",
            "Epoch 271/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9116 - accuracy: 0.6433 - val_loss: 0.9158 - val_accuracy: 0.6957\n",
            "Epoch 272/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.9246 - accuracy: 0.6282 - val_loss: 0.9262 - val_accuracy: 0.6908\n",
            "Epoch 273/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8961 - accuracy: 0.6518 - val_loss: 0.9339 - val_accuracy: 0.6570\n",
            "Epoch 274/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9128 - accuracy: 0.6481 - val_loss: 0.9026 - val_accuracy: 0.6860\n",
            "Epoch 275/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9224 - accuracy: 0.6360 - val_loss: 0.9144 - val_accuracy: 0.6812\n",
            "Epoch 276/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9310 - accuracy: 0.6348 - val_loss: 0.9052 - val_accuracy: 0.6763\n",
            "Epoch 277/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.8933 - accuracy: 0.6451 - val_loss: 0.9051 - val_accuracy: 0.7005\n",
            "Epoch 278/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9086 - accuracy: 0.6439 - val_loss: 0.9200 - val_accuracy: 0.6570\n",
            "Epoch 279/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9174 - accuracy: 0.6324 - val_loss: 0.9058 - val_accuracy: 0.6860\n",
            "Epoch 280/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8944 - accuracy: 0.6457 - val_loss: 0.9288 - val_accuracy: 0.6812\n",
            "Epoch 281/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9065 - accuracy: 0.6312 - val_loss: 0.8988 - val_accuracy: 0.6812\n",
            "Epoch 282/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8911 - accuracy: 0.6481 - val_loss: 0.9019 - val_accuracy: 0.6957\n",
            "Epoch 283/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.8960 - accuracy: 0.6421 - val_loss: 0.9011 - val_accuracy: 0.6763\n",
            "Epoch 284/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8965 - accuracy: 0.6499 - val_loss: 0.8944 - val_accuracy: 0.6763\n",
            "Epoch 285/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.8941 - accuracy: 0.6493 - val_loss: 0.8965 - val_accuracy: 0.6860\n",
            "Epoch 286/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8912 - accuracy: 0.6530 - val_loss: 0.8979 - val_accuracy: 0.7053\n",
            "Epoch 287/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9158 - accuracy: 0.6354 - val_loss: 0.8932 - val_accuracy: 0.6812\n",
            "Epoch 288/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.8720 - accuracy: 0.6457 - val_loss: 0.8945 - val_accuracy: 0.6860\n",
            "Epoch 289/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8843 - accuracy: 0.6487 - val_loss: 0.8808 - val_accuracy: 0.7005\n",
            "Epoch 290/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.8673 - accuracy: 0.6590 - val_loss: 0.8683 - val_accuracy: 0.6860\n",
            "Epoch 291/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8932 - accuracy: 0.6324 - val_loss: 0.8972 - val_accuracy: 0.6715\n",
            "Epoch 292/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8947 - accuracy: 0.6457 - val_loss: 0.8799 - val_accuracy: 0.7005\n",
            "Epoch 293/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8925 - accuracy: 0.6487 - val_loss: 0.8974 - val_accuracy: 0.6715\n",
            "Epoch 294/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8883 - accuracy: 0.6372 - val_loss: 0.8912 - val_accuracy: 0.7101\n",
            "Epoch 295/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8689 - accuracy: 0.6566 - val_loss: 0.8843 - val_accuracy: 0.6763\n",
            "Epoch 296/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8568 - accuracy: 0.6638 - val_loss: 0.8757 - val_accuracy: 0.6860\n",
            "Epoch 297/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8624 - accuracy: 0.6711 - val_loss: 0.8984 - val_accuracy: 0.6570\n",
            "Epoch 298/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.8669 - accuracy: 0.6536 - val_loss: 0.8831 - val_accuracy: 0.7053\n",
            "Epoch 299/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.8761 - accuracy: 0.6632 - val_loss: 0.9124 - val_accuracy: 0.6425\n",
            "Epoch 300/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8477 - accuracy: 0.6681 - val_loss: 0.8811 - val_accuracy: 0.6860\n",
            "Epoch 301/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8776 - accuracy: 0.6505 - val_loss: 0.8655 - val_accuracy: 0.6908\n",
            "Epoch 302/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8781 - accuracy: 0.6681 - val_loss: 0.8696 - val_accuracy: 0.6763\n",
            "Epoch 303/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8517 - accuracy: 0.6530 - val_loss: 0.8720 - val_accuracy: 0.6957\n",
            "Epoch 304/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8449 - accuracy: 0.6765 - val_loss: 0.8734 - val_accuracy: 0.6860\n",
            "Epoch 305/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8478 - accuracy: 0.6681 - val_loss: 0.8565 - val_accuracy: 0.6908\n",
            "Epoch 306/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8640 - accuracy: 0.6560 - val_loss: 0.8538 - val_accuracy: 0.7053\n",
            "Epoch 307/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8536 - accuracy: 0.6681 - val_loss: 0.8645 - val_accuracy: 0.6812\n",
            "Epoch 308/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8413 - accuracy: 0.6675 - val_loss: 0.8595 - val_accuracy: 0.6812\n",
            "Epoch 309/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8675 - accuracy: 0.6560 - val_loss: 0.8705 - val_accuracy: 0.6473\n",
            "Epoch 310/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8399 - accuracy: 0.6675 - val_loss: 0.8647 - val_accuracy: 0.7053\n",
            "Epoch 311/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.8573 - accuracy: 0.6614 - val_loss: 0.8589 - val_accuracy: 0.6618\n",
            "Epoch 312/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.8488 - accuracy: 0.6747 - val_loss: 0.8530 - val_accuracy: 0.6908\n",
            "Epoch 313/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8457 - accuracy: 0.6711 - val_loss: 0.8540 - val_accuracy: 0.6908\n",
            "Epoch 314/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8489 - accuracy: 0.6705 - val_loss: 0.8548 - val_accuracy: 0.6667\n",
            "Epoch 315/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.8651 - accuracy: 0.6626 - val_loss: 0.8538 - val_accuracy: 0.6667\n",
            "Epoch 316/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.8470 - accuracy: 0.6735 - val_loss: 0.8405 - val_accuracy: 0.7005\n",
            "Epoch 317/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.8307 - accuracy: 0.6675 - val_loss: 0.8441 - val_accuracy: 0.6860\n",
            "Epoch 318/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8371 - accuracy: 0.6602 - val_loss: 0.8430 - val_accuracy: 0.7005\n",
            "Epoch 319/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.8364 - accuracy: 0.6699 - val_loss: 0.8553 - val_accuracy: 0.6763\n",
            "Epoch 320/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8565 - accuracy: 0.6663 - val_loss: 0.8474 - val_accuracy: 0.7005\n",
            "Epoch 321/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8433 - accuracy: 0.6602 - val_loss: 0.8466 - val_accuracy: 0.7005\n",
            "Epoch 322/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.8457 - accuracy: 0.6675 - val_loss: 0.8415 - val_accuracy: 0.7246\n",
            "Epoch 323/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.8281 - accuracy: 0.6632 - val_loss: 0.8403 - val_accuracy: 0.7101\n",
            "Epoch 324/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8337 - accuracy: 0.6771 - val_loss: 0.8376 - val_accuracy: 0.7053\n",
            "Epoch 325/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.8275 - accuracy: 0.6735 - val_loss: 0.8478 - val_accuracy: 0.7005\n",
            "Epoch 326/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8238 - accuracy: 0.6784 - val_loss: 0.8329 - val_accuracy: 0.7053\n",
            "Epoch 327/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.8239 - accuracy: 0.6741 - val_loss: 0.8307 - val_accuracy: 0.6908\n",
            "Epoch 328/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8216 - accuracy: 0.6705 - val_loss: 0.8343 - val_accuracy: 0.6908\n",
            "Epoch 329/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.8251 - accuracy: 0.6632 - val_loss: 0.8366 - val_accuracy: 0.6957\n",
            "Epoch 330/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8143 - accuracy: 0.6814 - val_loss: 0.8164 - val_accuracy: 0.7101\n",
            "Epoch 331/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.8108 - accuracy: 0.6814 - val_loss: 0.8263 - val_accuracy: 0.7053\n",
            "Epoch 332/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8070 - accuracy: 0.6784 - val_loss: 0.8165 - val_accuracy: 0.6957\n",
            "Epoch 333/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.8014 - accuracy: 0.6850 - val_loss: 0.8393 - val_accuracy: 0.6957\n",
            "Epoch 334/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8028 - accuracy: 0.6941 - val_loss: 0.8285 - val_accuracy: 0.6957\n",
            "Epoch 335/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.7976 - accuracy: 0.6790 - val_loss: 0.8113 - val_accuracy: 0.7150\n",
            "Epoch 336/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8111 - accuracy: 0.6850 - val_loss: 0.8104 - val_accuracy: 0.7198\n",
            "Epoch 337/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7986 - accuracy: 0.6796 - val_loss: 0.8194 - val_accuracy: 0.7053\n",
            "Epoch 338/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8046 - accuracy: 0.6880 - val_loss: 0.8294 - val_accuracy: 0.6957\n",
            "Epoch 339/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.7987 - accuracy: 0.6892 - val_loss: 0.8170 - val_accuracy: 0.7101\n",
            "Epoch 340/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8053 - accuracy: 0.6778 - val_loss: 0.8126 - val_accuracy: 0.7101\n",
            "Epoch 341/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7813 - accuracy: 0.6941 - val_loss: 0.7980 - val_accuracy: 0.7391\n",
            "Epoch 342/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8024 - accuracy: 0.6705 - val_loss: 0.8124 - val_accuracy: 0.7053\n",
            "Epoch 343/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8014 - accuracy: 0.6838 - val_loss: 0.8145 - val_accuracy: 0.7005\n",
            "Epoch 344/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8100 - accuracy: 0.6735 - val_loss: 0.8039 - val_accuracy: 0.7198\n",
            "Epoch 345/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8101 - accuracy: 0.6796 - val_loss: 0.8138 - val_accuracy: 0.7295\n",
            "Epoch 346/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8091 - accuracy: 0.6868 - val_loss: 0.8105 - val_accuracy: 0.7198\n",
            "Epoch 347/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.7905 - accuracy: 0.6971 - val_loss: 0.8031 - val_accuracy: 0.7101\n",
            "Epoch 348/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.7926 - accuracy: 0.6874 - val_loss: 0.8086 - val_accuracy: 0.7150\n",
            "Epoch 349/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7939 - accuracy: 0.6911 - val_loss: 0.8014 - val_accuracy: 0.7101\n",
            "Epoch 350/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7690 - accuracy: 0.6971 - val_loss: 0.7948 - val_accuracy: 0.7295\n",
            "Epoch 351/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.7748 - accuracy: 0.6904 - val_loss: 0.8055 - val_accuracy: 0.7246\n",
            "Epoch 352/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8011 - accuracy: 0.6820 - val_loss: 0.7990 - val_accuracy: 0.7343\n",
            "Epoch 353/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7967 - accuracy: 0.6862 - val_loss: 0.8081 - val_accuracy: 0.7295\n",
            "Epoch 354/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7864 - accuracy: 0.6965 - val_loss: 0.7999 - val_accuracy: 0.7391\n",
            "Epoch 355/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7748 - accuracy: 0.7056 - val_loss: 0.8072 - val_accuracy: 0.6860\n",
            "Epoch 356/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7841 - accuracy: 0.6868 - val_loss: 0.8021 - val_accuracy: 0.6908\n",
            "Epoch 357/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7883 - accuracy: 0.6989 - val_loss: 0.7965 - val_accuracy: 0.7150\n",
            "Epoch 358/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7906 - accuracy: 0.6820 - val_loss: 0.8032 - val_accuracy: 0.7101\n",
            "Epoch 359/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7769 - accuracy: 0.6929 - val_loss: 0.8102 - val_accuracy: 0.7198\n",
            "Epoch 360/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.7863 - accuracy: 0.6989 - val_loss: 0.8139 - val_accuracy: 0.7005\n",
            "Epoch 361/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7734 - accuracy: 0.6796 - val_loss: 0.8107 - val_accuracy: 0.6957\n",
            "Epoch 362/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7688 - accuracy: 0.7007 - val_loss: 0.7929 - val_accuracy: 0.7246\n",
            "Epoch 363/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7764 - accuracy: 0.6838 - val_loss: 0.7880 - val_accuracy: 0.7198\n",
            "Epoch 364/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7590 - accuracy: 0.7037 - val_loss: 0.7852 - val_accuracy: 0.7295\n",
            "Epoch 365/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7775 - accuracy: 0.6977 - val_loss: 0.8074 - val_accuracy: 0.6763\n",
            "Epoch 366/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.7699 - accuracy: 0.6917 - val_loss: 0.7920 - val_accuracy: 0.7198\n",
            "Epoch 367/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7749 - accuracy: 0.6965 - val_loss: 0.7928 - val_accuracy: 0.7295\n",
            "Epoch 368/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7801 - accuracy: 0.6947 - val_loss: 0.7769 - val_accuracy: 0.7488\n",
            "Epoch 369/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7398 - accuracy: 0.7098 - val_loss: 0.7936 - val_accuracy: 0.7101\n",
            "Epoch 370/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7531 - accuracy: 0.7110 - val_loss: 0.8391 - val_accuracy: 0.6812\n",
            "Epoch 371/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7746 - accuracy: 0.6917 - val_loss: 0.7809 - val_accuracy: 0.7101\n",
            "Epoch 372/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7570 - accuracy: 0.7031 - val_loss: 0.7805 - val_accuracy: 0.7150\n",
            "Epoch 373/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7590 - accuracy: 0.7001 - val_loss: 0.7932 - val_accuracy: 0.7053\n",
            "Epoch 374/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7553 - accuracy: 0.7092 - val_loss: 0.8002 - val_accuracy: 0.7198\n",
            "Epoch 375/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7590 - accuracy: 0.6989 - val_loss: 0.7894 - val_accuracy: 0.7005\n",
            "Epoch 376/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7545 - accuracy: 0.7062 - val_loss: 0.7787 - val_accuracy: 0.7150\n",
            "Epoch 377/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.7575 - accuracy: 0.7013 - val_loss: 0.7859 - val_accuracy: 0.7150\n",
            "Epoch 378/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.7445 - accuracy: 0.7068 - val_loss: 0.7732 - val_accuracy: 0.7198\n",
            "Epoch 379/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7469 - accuracy: 0.7098 - val_loss: 0.7635 - val_accuracy: 0.7343\n",
            "Epoch 380/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7399 - accuracy: 0.7225 - val_loss: 0.7762 - val_accuracy: 0.7246\n",
            "Epoch 381/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7448 - accuracy: 0.7050 - val_loss: 0.7746 - val_accuracy: 0.7391\n",
            "Epoch 382/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7473 - accuracy: 0.7019 - val_loss: 0.7711 - val_accuracy: 0.7488\n",
            "Epoch 383/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.7625 - accuracy: 0.6947 - val_loss: 0.7690 - val_accuracy: 0.7198\n",
            "Epoch 384/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7477 - accuracy: 0.7062 - val_loss: 0.7890 - val_accuracy: 0.7150\n",
            "Epoch 385/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.7571 - accuracy: 0.7086 - val_loss: 0.7868 - val_accuracy: 0.7053\n",
            "Epoch 386/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7451 - accuracy: 0.7104 - val_loss: 0.8045 - val_accuracy: 0.7246\n",
            "Epoch 387/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7297 - accuracy: 0.7110 - val_loss: 0.7575 - val_accuracy: 0.7295\n",
            "Epoch 388/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.7489 - accuracy: 0.7031 - val_loss: 0.7950 - val_accuracy: 0.7150\n",
            "Epoch 389/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7341 - accuracy: 0.7116 - val_loss: 0.7802 - val_accuracy: 0.7198\n",
            "Epoch 390/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7348 - accuracy: 0.7158 - val_loss: 0.7781 - val_accuracy: 0.7343\n",
            "Epoch 391/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7393 - accuracy: 0.7019 - val_loss: 0.7743 - val_accuracy: 0.7343\n",
            "Epoch 392/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7264 - accuracy: 0.7273 - val_loss: 0.7774 - val_accuracy: 0.6957\n",
            "Epoch 393/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7260 - accuracy: 0.7195 - val_loss: 0.7916 - val_accuracy: 0.7005\n",
            "Epoch 394/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7163 - accuracy: 0.7092 - val_loss: 0.7666 - val_accuracy: 0.7246\n",
            "Epoch 395/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.7324 - accuracy: 0.7068 - val_loss: 0.7686 - val_accuracy: 0.7343\n",
            "Epoch 396/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7519 - accuracy: 0.6929 - val_loss: 0.7583 - val_accuracy: 0.7198\n",
            "Epoch 397/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7182 - accuracy: 0.7213 - val_loss: 0.7700 - val_accuracy: 0.7150\n",
            "Epoch 398/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7241 - accuracy: 0.7110 - val_loss: 0.7582 - val_accuracy: 0.7101\n",
            "Epoch 399/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7329 - accuracy: 0.7140 - val_loss: 0.7573 - val_accuracy: 0.7246\n",
            "Epoch 400/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7125 - accuracy: 0.7104 - val_loss: 0.7861 - val_accuracy: 0.7005\n",
            "Epoch 401/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.7143 - accuracy: 0.7237 - val_loss: 0.7562 - val_accuracy: 0.7246\n",
            "Epoch 402/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7245 - accuracy: 0.7086 - val_loss: 0.7622 - val_accuracy: 0.7150\n",
            "Epoch 403/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7073 - accuracy: 0.7219 - val_loss: 0.7858 - val_accuracy: 0.6957\n",
            "Epoch 404/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7103 - accuracy: 0.7285 - val_loss: 0.7606 - val_accuracy: 0.7295\n",
            "Epoch 405/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7212 - accuracy: 0.7177 - val_loss: 0.7541 - val_accuracy: 0.7246\n",
            "Epoch 406/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7004 - accuracy: 0.7207 - val_loss: 0.7745 - val_accuracy: 0.7391\n",
            "Epoch 407/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.7123 - accuracy: 0.7255 - val_loss: 0.7471 - val_accuracy: 0.7343\n",
            "Epoch 408/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7115 - accuracy: 0.7189 - val_loss: 0.7518 - val_accuracy: 0.7343\n",
            "Epoch 409/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7041 - accuracy: 0.7279 - val_loss: 0.7425 - val_accuracy: 0.7536\n",
            "Epoch 410/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7042 - accuracy: 0.7291 - val_loss: 0.7472 - val_accuracy: 0.7246\n",
            "Epoch 411/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7017 - accuracy: 0.7158 - val_loss: 0.7348 - val_accuracy: 0.7391\n",
            "Epoch 412/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7077 - accuracy: 0.7195 - val_loss: 0.7305 - val_accuracy: 0.7343\n",
            "Epoch 413/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7084 - accuracy: 0.7201 - val_loss: 0.7244 - val_accuracy: 0.7343\n",
            "Epoch 414/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.7049 - accuracy: 0.7219 - val_loss: 0.7349 - val_accuracy: 0.7488\n",
            "Epoch 415/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.7019 - accuracy: 0.7304 - val_loss: 0.7299 - val_accuracy: 0.7585\n",
            "Epoch 416/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7200 - accuracy: 0.7158 - val_loss: 0.7474 - val_accuracy: 0.7440\n",
            "Epoch 417/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7065 - accuracy: 0.7177 - val_loss: 0.7227 - val_accuracy: 0.7488\n",
            "Epoch 418/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6966 - accuracy: 0.7273 - val_loss: 0.7333 - val_accuracy: 0.7681\n",
            "Epoch 419/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6987 - accuracy: 0.7207 - val_loss: 0.7224 - val_accuracy: 0.7440\n",
            "Epoch 420/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6855 - accuracy: 0.7189 - val_loss: 0.7231 - val_accuracy: 0.7440\n",
            "Epoch 421/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.7097 - accuracy: 0.7134 - val_loss: 0.7425 - val_accuracy: 0.7343\n",
            "Epoch 422/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6941 - accuracy: 0.7255 - val_loss: 0.7362 - val_accuracy: 0.7343\n",
            "Epoch 423/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.7297 - val_loss: 0.7488 - val_accuracy: 0.7295\n",
            "Epoch 424/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6882 - accuracy: 0.7279 - val_loss: 0.7133 - val_accuracy: 0.7585\n",
            "Epoch 425/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6928 - accuracy: 0.7322 - val_loss: 0.7245 - val_accuracy: 0.7681\n",
            "Epoch 426/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6888 - accuracy: 0.7297 - val_loss: 0.7319 - val_accuracy: 0.7440\n",
            "Epoch 427/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6959 - accuracy: 0.7267 - val_loss: 0.7476 - val_accuracy: 0.7391\n",
            "Epoch 428/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6982 - accuracy: 0.7340 - val_loss: 0.7284 - val_accuracy: 0.7391\n",
            "Epoch 429/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6856 - accuracy: 0.7225 - val_loss: 0.7252 - val_accuracy: 0.7488\n",
            "Epoch 430/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6884 - accuracy: 0.7273 - val_loss: 0.7230 - val_accuracy: 0.7488\n",
            "Epoch 431/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6745 - accuracy: 0.7340 - val_loss: 0.7398 - val_accuracy: 0.7488\n",
            "Epoch 432/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6688 - accuracy: 0.7322 - val_loss: 0.7162 - val_accuracy: 0.7440\n",
            "Epoch 433/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6830 - accuracy: 0.7219 - val_loss: 0.7194 - val_accuracy: 0.7391\n",
            "Epoch 434/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6713 - accuracy: 0.7352 - val_loss: 0.7213 - val_accuracy: 0.7488\n",
            "Epoch 435/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.6598 - accuracy: 0.7430 - val_loss: 0.7196 - val_accuracy: 0.7440\n",
            "Epoch 436/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6898 - accuracy: 0.7328 - val_loss: 0.7122 - val_accuracy: 0.7488\n",
            "Epoch 437/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6680 - accuracy: 0.7382 - val_loss: 0.7295 - val_accuracy: 0.7536\n",
            "Epoch 438/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6900 - accuracy: 0.7237 - val_loss: 0.7234 - val_accuracy: 0.7488\n",
            "Epoch 439/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.6656 - accuracy: 0.7461 - val_loss: 0.7257 - val_accuracy: 0.7295\n",
            "Epoch 440/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6796 - accuracy: 0.7304 - val_loss: 0.7263 - val_accuracy: 0.7295\n",
            "Epoch 441/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6693 - accuracy: 0.7340 - val_loss: 0.7079 - val_accuracy: 0.7681\n",
            "Epoch 442/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6670 - accuracy: 0.7370 - val_loss: 0.7306 - val_accuracy: 0.7536\n",
            "Epoch 443/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6745 - accuracy: 0.7322 - val_loss: 0.7169 - val_accuracy: 0.7536\n",
            "Epoch 444/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6739 - accuracy: 0.7334 - val_loss: 0.7236 - val_accuracy: 0.7343\n",
            "Epoch 445/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6638 - accuracy: 0.7322 - val_loss: 0.7298 - val_accuracy: 0.7440\n",
            "Epoch 446/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6702 - accuracy: 0.7346 - val_loss: 0.7103 - val_accuracy: 0.7585\n",
            "Epoch 447/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.6585 - accuracy: 0.7449 - val_loss: 0.7290 - val_accuracy: 0.7488\n",
            "Epoch 448/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6980 - accuracy: 0.7310 - val_loss: 0.7262 - val_accuracy: 0.7488\n",
            "Epoch 449/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6765 - accuracy: 0.7261 - val_loss: 0.7265 - val_accuracy: 0.7536\n",
            "Epoch 450/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6506 - accuracy: 0.7509 - val_loss: 0.7363 - val_accuracy: 0.7440\n",
            "Epoch 451/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6582 - accuracy: 0.7316 - val_loss: 0.7184 - val_accuracy: 0.7295\n",
            "Epoch 452/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6701 - accuracy: 0.7358 - val_loss: 0.7212 - val_accuracy: 0.7391\n",
            "Epoch 453/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6553 - accuracy: 0.7449 - val_loss: 0.7156 - val_accuracy: 0.7633\n",
            "Epoch 454/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6770 - accuracy: 0.7364 - val_loss: 0.6996 - val_accuracy: 0.7778\n",
            "Epoch 455/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6414 - accuracy: 0.7503 - val_loss: 0.6976 - val_accuracy: 0.7729\n",
            "Epoch 456/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6611 - accuracy: 0.7461 - val_loss: 0.7302 - val_accuracy: 0.7343\n",
            "Epoch 457/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6698 - accuracy: 0.7388 - val_loss: 0.7186 - val_accuracy: 0.7343\n",
            "Epoch 458/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6413 - accuracy: 0.7594 - val_loss: 0.7193 - val_accuracy: 0.7391\n",
            "Epoch 459/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6590 - accuracy: 0.7394 - val_loss: 0.7167 - val_accuracy: 0.7633\n",
            "Epoch 460/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6550 - accuracy: 0.7455 - val_loss: 0.7152 - val_accuracy: 0.7488\n",
            "Epoch 461/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6536 - accuracy: 0.7503 - val_loss: 0.7263 - val_accuracy: 0.7440\n",
            "Epoch 462/1000\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.6465 - accuracy: 0.7443 - val_loss: 0.7071 - val_accuracy: 0.7536\n",
            "Epoch 463/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6585 - accuracy: 0.7394 - val_loss: 0.7196 - val_accuracy: 0.7488\n",
            "Epoch 464/1000\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.6383 - accuracy: 0.7491 - val_loss: 0.7064 - val_accuracy: 0.7585\n",
            "Epoch 465/1000\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.6408 - accuracy: 0.7557 - val_loss: 0.6979 - val_accuracy: 0.7585\n",
            "Epoch 466/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6272 - accuracy: 0.7449 - val_loss: 0.7011 - val_accuracy: 0.7488\n",
            "Epoch 467/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6474 - accuracy: 0.7533 - val_loss: 0.6982 - val_accuracy: 0.7391\n",
            "Epoch 468/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6344 - accuracy: 0.7527 - val_loss: 0.7004 - val_accuracy: 0.7681\n",
            "Epoch 469/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6463 - accuracy: 0.7382 - val_loss: 0.6941 - val_accuracy: 0.7585\n",
            "Epoch 470/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6357 - accuracy: 0.7412 - val_loss: 0.6969 - val_accuracy: 0.7729\n",
            "Epoch 471/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6439 - accuracy: 0.7473 - val_loss: 0.7076 - val_accuracy: 0.7391\n",
            "Epoch 472/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6371 - accuracy: 0.7479 - val_loss: 0.7169 - val_accuracy: 0.7633\n",
            "Epoch 473/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6422 - accuracy: 0.7509 - val_loss: 0.7210 - val_accuracy: 0.7585\n",
            "Epoch 474/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6349 - accuracy: 0.7527 - val_loss: 0.7106 - val_accuracy: 0.7633\n",
            "Epoch 475/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6286 - accuracy: 0.7618 - val_loss: 0.6929 - val_accuracy: 0.7923\n",
            "Epoch 476/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6400 - accuracy: 0.7461 - val_loss: 0.7019 - val_accuracy: 0.7778\n",
            "Epoch 477/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6566 - accuracy: 0.7394 - val_loss: 0.7264 - val_accuracy: 0.7488\n",
            "Epoch 478/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6319 - accuracy: 0.7539 - val_loss: 0.7139 - val_accuracy: 0.7536\n",
            "Epoch 479/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6415 - accuracy: 0.7551 - val_loss: 0.6973 - val_accuracy: 0.7536\n",
            "Epoch 480/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6195 - accuracy: 0.7594 - val_loss: 0.6999 - val_accuracy: 0.7536\n",
            "Epoch 481/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6239 - accuracy: 0.7527 - val_loss: 0.7028 - val_accuracy: 0.7536\n",
            "Epoch 482/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6148 - accuracy: 0.7715 - val_loss: 0.6834 - val_accuracy: 0.7488\n",
            "Epoch 483/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6449 - accuracy: 0.7479 - val_loss: 0.6981 - val_accuracy: 0.7681\n",
            "Epoch 484/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6265 - accuracy: 0.7461 - val_loss: 0.6772 - val_accuracy: 0.7633\n",
            "Epoch 485/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.6430 - accuracy: 0.7430 - val_loss: 0.6876 - val_accuracy: 0.7488\n",
            "Epoch 486/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6454 - accuracy: 0.7437 - val_loss: 0.7209 - val_accuracy: 0.7488\n",
            "Epoch 487/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6143 - accuracy: 0.7521 - val_loss: 0.7144 - val_accuracy: 0.7198\n",
            "Epoch 488/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6176 - accuracy: 0.7588 - val_loss: 0.7112 - val_accuracy: 0.7246\n",
            "Epoch 489/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6138 - accuracy: 0.7503 - val_loss: 0.6945 - val_accuracy: 0.7488\n",
            "Epoch 490/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6271 - accuracy: 0.7588 - val_loss: 0.6928 - val_accuracy: 0.7585\n",
            "Epoch 491/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5963 - accuracy: 0.7642 - val_loss: 0.7078 - val_accuracy: 0.7633\n",
            "Epoch 492/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6122 - accuracy: 0.7642 - val_loss: 0.6889 - val_accuracy: 0.7536\n",
            "Epoch 493/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6373 - accuracy: 0.7473 - val_loss: 0.7050 - val_accuracy: 0.7488\n",
            "Epoch 494/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.5929 - accuracy: 0.7678 - val_loss: 0.7055 - val_accuracy: 0.7536\n",
            "Epoch 495/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6309 - accuracy: 0.7485 - val_loss: 0.6899 - val_accuracy: 0.7633\n",
            "Epoch 496/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6441 - accuracy: 0.7412 - val_loss: 0.7026 - val_accuracy: 0.7585\n",
            "Epoch 497/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.5956 - accuracy: 0.7781 - val_loss: 0.6856 - val_accuracy: 0.7633\n",
            "Epoch 498/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.6070 - accuracy: 0.7690 - val_loss: 0.6943 - val_accuracy: 0.7440\n",
            "Epoch 499/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6220 - accuracy: 0.7509 - val_loss: 0.6764 - val_accuracy: 0.7633\n",
            "Epoch 500/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5953 - accuracy: 0.7836 - val_loss: 0.6839 - val_accuracy: 0.7681\n",
            "Epoch 501/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6016 - accuracy: 0.7588 - val_loss: 0.7035 - val_accuracy: 0.7729\n",
            "Epoch 502/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6102 - accuracy: 0.7551 - val_loss: 0.6838 - val_accuracy: 0.7874\n",
            "Epoch 503/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6088 - accuracy: 0.7721 - val_loss: 0.6871 - val_accuracy: 0.7681\n",
            "Epoch 504/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6150 - accuracy: 0.7527 - val_loss: 0.6805 - val_accuracy: 0.7681\n",
            "Epoch 505/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5795 - accuracy: 0.7739 - val_loss: 0.6845 - val_accuracy: 0.7585\n",
            "Epoch 506/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6133 - accuracy: 0.7563 - val_loss: 0.7029 - val_accuracy: 0.7633\n",
            "Epoch 507/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5746 - accuracy: 0.7678 - val_loss: 0.6899 - val_accuracy: 0.7633\n",
            "Epoch 508/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5988 - accuracy: 0.7582 - val_loss: 0.6941 - val_accuracy: 0.7633\n",
            "Epoch 509/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6132 - accuracy: 0.7551 - val_loss: 0.6758 - val_accuracy: 0.7585\n",
            "Epoch 510/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5806 - accuracy: 0.7763 - val_loss: 0.6759 - val_accuracy: 0.7681\n",
            "Epoch 511/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6121 - accuracy: 0.7600 - val_loss: 0.6772 - val_accuracy: 0.7633\n",
            "Epoch 512/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6062 - accuracy: 0.7660 - val_loss: 0.6668 - val_accuracy: 0.7681\n",
            "Epoch 513/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5962 - accuracy: 0.7775 - val_loss: 0.6954 - val_accuracy: 0.7440\n",
            "Epoch 514/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5948 - accuracy: 0.7678 - val_loss: 0.6720 - val_accuracy: 0.7585\n",
            "Epoch 515/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6065 - accuracy: 0.7588 - val_loss: 0.6778 - val_accuracy: 0.7585\n",
            "Epoch 516/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.5595 - accuracy: 0.7878 - val_loss: 0.6688 - val_accuracy: 0.7536\n",
            "Epoch 517/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5963 - accuracy: 0.7751 - val_loss: 0.6539 - val_accuracy: 0.7633\n",
            "Epoch 518/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5781 - accuracy: 0.7805 - val_loss: 0.6550 - val_accuracy: 0.7778\n",
            "Epoch 519/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6044 - accuracy: 0.7648 - val_loss: 0.6646 - val_accuracy: 0.7681\n",
            "Epoch 520/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.6068 - accuracy: 0.7497 - val_loss: 0.6929 - val_accuracy: 0.7681\n",
            "Epoch 521/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.5990 - accuracy: 0.7618 - val_loss: 0.6636 - val_accuracy: 0.7729\n",
            "Epoch 522/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5856 - accuracy: 0.7715 - val_loss: 0.6672 - val_accuracy: 0.7729\n",
            "Epoch 523/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.5711 - accuracy: 0.7854 - val_loss: 0.6625 - val_accuracy: 0.7729\n",
            "Epoch 524/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.5952 - accuracy: 0.7576 - val_loss: 0.6593 - val_accuracy: 0.7681\n",
            "Epoch 525/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5628 - accuracy: 0.7805 - val_loss: 0.6519 - val_accuracy: 0.7633\n",
            "Epoch 526/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.5723 - accuracy: 0.7823 - val_loss: 0.6616 - val_accuracy: 0.7729\n",
            "Epoch 527/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5788 - accuracy: 0.7721 - val_loss: 0.6563 - val_accuracy: 0.7729\n",
            "Epoch 528/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5617 - accuracy: 0.7890 - val_loss: 0.6631 - val_accuracy: 0.7633\n",
            "Epoch 529/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5804 - accuracy: 0.7860 - val_loss: 0.6672 - val_accuracy: 0.7778\n",
            "Epoch 530/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.5661 - accuracy: 0.7690 - val_loss: 0.6545 - val_accuracy: 0.7923\n",
            "Epoch 531/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5690 - accuracy: 0.7805 - val_loss: 0.6743 - val_accuracy: 0.7826\n",
            "Epoch 532/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5881 - accuracy: 0.7678 - val_loss: 0.6713 - val_accuracy: 0.7488\n",
            "Epoch 533/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.5529 - accuracy: 0.7842 - val_loss: 0.6607 - val_accuracy: 0.7536\n",
            "Epoch 534/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.5631 - accuracy: 0.7799 - val_loss: 0.6644 - val_accuracy: 0.7729\n",
            "Epoch 535/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.5627 - accuracy: 0.7787 - val_loss: 0.6617 - val_accuracy: 0.7633\n",
            "Epoch 536/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5824 - accuracy: 0.7715 - val_loss: 0.6566 - val_accuracy: 0.7778\n",
            "Epoch 537/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5680 - accuracy: 0.7775 - val_loss: 0.6575 - val_accuracy: 0.7826\n",
            "Epoch 538/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5630 - accuracy: 0.7866 - val_loss: 0.6558 - val_accuracy: 0.7633\n",
            "Epoch 539/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.5690 - accuracy: 0.7739 - val_loss: 0.6554 - val_accuracy: 0.7585\n",
            "Epoch 540/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.5642 - accuracy: 0.7836 - val_loss: 0.6729 - val_accuracy: 0.7729\n",
            "Epoch 541/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5673 - accuracy: 0.7836 - val_loss: 0.6586 - val_accuracy: 0.7681\n",
            "Epoch 542/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.5806 - accuracy: 0.7660 - val_loss: 0.6617 - val_accuracy: 0.7778\n",
            "Epoch 543/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.5515 - accuracy: 0.7842 - val_loss: 0.6526 - val_accuracy: 0.7826\n",
            "Epoch 544/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5627 - accuracy: 0.7836 - val_loss: 0.6605 - val_accuracy: 0.7874\n",
            "Epoch 545/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.5807 - accuracy: 0.7727 - val_loss: 0.6576 - val_accuracy: 0.7729\n",
            "Epoch 546/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5644 - accuracy: 0.7775 - val_loss: 0.6642 - val_accuracy: 0.7778\n",
            "Epoch 547/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.5523 - accuracy: 0.7751 - val_loss: 0.6610 - val_accuracy: 0.7874\n",
            "Epoch 548/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5589 - accuracy: 0.7787 - val_loss: 0.6541 - val_accuracy: 0.7778\n",
            "Epoch 549/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5648 - accuracy: 0.7696 - val_loss: 0.6625 - val_accuracy: 0.7971\n",
            "Epoch 550/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5438 - accuracy: 0.7926 - val_loss: 0.6478 - val_accuracy: 0.7826\n",
            "Epoch 551/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5764 - accuracy: 0.7563 - val_loss: 0.6607 - val_accuracy: 0.7874\n",
            "Epoch 552/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.5717 - accuracy: 0.7745 - val_loss: 0.6422 - val_accuracy: 0.7633\n",
            "Epoch 553/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.5557 - accuracy: 0.7799 - val_loss: 0.6521 - val_accuracy: 0.7826\n",
            "Epoch 554/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5561 - accuracy: 0.7836 - val_loss: 0.6480 - val_accuracy: 0.7826\n",
            "Epoch 555/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5560 - accuracy: 0.7781 - val_loss: 0.6524 - val_accuracy: 0.7874\n",
            "Epoch 556/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.5750 - accuracy: 0.7648 - val_loss: 0.6522 - val_accuracy: 0.7826\n",
            "Epoch 557/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5512 - accuracy: 0.7866 - val_loss: 0.6624 - val_accuracy: 0.7585\n",
            "Epoch 558/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5556 - accuracy: 0.7787 - val_loss: 0.6704 - val_accuracy: 0.7826\n",
            "Epoch 559/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5551 - accuracy: 0.7727 - val_loss: 0.6579 - val_accuracy: 0.7874\n",
            "Epoch 560/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.5387 - accuracy: 0.7914 - val_loss: 0.6532 - val_accuracy: 0.7923\n",
            "Epoch 561/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.5337 - accuracy: 0.7944 - val_loss: 0.6402 - val_accuracy: 0.7971\n",
            "Epoch 562/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.5465 - accuracy: 0.7884 - val_loss: 0.6539 - val_accuracy: 0.7826\n",
            "Epoch 563/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5412 - accuracy: 0.8065 - val_loss: 0.6453 - val_accuracy: 0.7874\n",
            "Epoch 564/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.5516 - accuracy: 0.7872 - val_loss: 0.6508 - val_accuracy: 0.7874\n",
            "Epoch 565/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5528 - accuracy: 0.7842 - val_loss: 0.6526 - val_accuracy: 0.7874\n",
            "Epoch 566/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.5382 - accuracy: 0.8017 - val_loss: 0.6488 - val_accuracy: 0.8019\n",
            "Epoch 567/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.5235 - accuracy: 0.8017 - val_loss: 0.6514 - val_accuracy: 0.8019\n",
            "Epoch 568/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.5389 - accuracy: 0.7932 - val_loss: 0.6473 - val_accuracy: 0.7923\n",
            "Epoch 569/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.5147 - accuracy: 0.7950 - val_loss: 0.6413 - val_accuracy: 0.7778\n",
            "Epoch 570/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5546 - accuracy: 0.7817 - val_loss: 0.6508 - val_accuracy: 0.7826\n",
            "Epoch 571/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.5177 - accuracy: 0.8035 - val_loss: 0.6402 - val_accuracy: 0.7826\n",
            "Epoch 572/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5246 - accuracy: 0.7896 - val_loss: 0.6378 - val_accuracy: 0.7729\n",
            "Epoch 573/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5223 - accuracy: 0.7993 - val_loss: 0.6345 - val_accuracy: 0.7923\n",
            "Epoch 574/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5517 - accuracy: 0.7896 - val_loss: 0.6453 - val_accuracy: 0.7778\n",
            "Epoch 575/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5405 - accuracy: 0.7956 - val_loss: 0.6409 - val_accuracy: 0.7923\n",
            "Epoch 576/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5642 - accuracy: 0.7787 - val_loss: 0.6472 - val_accuracy: 0.7971\n",
            "Epoch 577/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.5386 - accuracy: 0.7854 - val_loss: 0.6487 - val_accuracy: 0.7633\n",
            "Epoch 578/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.5618 - accuracy: 0.7793 - val_loss: 0.6379 - val_accuracy: 0.7971\n",
            "Epoch 579/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.5312 - accuracy: 0.7987 - val_loss: 0.6389 - val_accuracy: 0.7923\n",
            "Epoch 580/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.5461 - accuracy: 0.7932 - val_loss: 0.6383 - val_accuracy: 0.7729\n",
            "Epoch 581/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.5456 - accuracy: 0.7842 - val_loss: 0.6472 - val_accuracy: 0.7681\n",
            "Epoch 582/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.5356 - accuracy: 0.8017 - val_loss: 0.6409 - val_accuracy: 0.7585\n",
            "Epoch 583/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.5185 - accuracy: 0.8023 - val_loss: 0.6301 - val_accuracy: 0.7874\n",
            "Epoch 584/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5114 - accuracy: 0.7981 - val_loss: 0.6318 - val_accuracy: 0.7874\n",
            "Epoch 585/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.5130 - accuracy: 0.7944 - val_loss: 0.6371 - val_accuracy: 0.7778\n",
            "Epoch 586/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.5084 - accuracy: 0.8023 - val_loss: 0.6488 - val_accuracy: 0.7681\n",
            "Epoch 587/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.5203 - accuracy: 0.7987 - val_loss: 0.6416 - val_accuracy: 0.7778\n",
            "Epoch 588/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5019 - accuracy: 0.8053 - val_loss: 0.6519 - val_accuracy: 0.7971\n",
            "Epoch 589/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5302 - accuracy: 0.7872 - val_loss: 0.6257 - val_accuracy: 0.7826\n",
            "Epoch 590/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.5153 - accuracy: 0.8017 - val_loss: 0.6460 - val_accuracy: 0.7923\n",
            "Epoch 591/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.5068 - accuracy: 0.7938 - val_loss: 0.6182 - val_accuracy: 0.7874\n",
            "Epoch 592/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5324 - accuracy: 0.7956 - val_loss: 0.6545 - val_accuracy: 0.7681\n",
            "Epoch 593/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5131 - accuracy: 0.8005 - val_loss: 0.6162 - val_accuracy: 0.7923\n",
            "Epoch 594/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5259 - accuracy: 0.7914 - val_loss: 0.6308 - val_accuracy: 0.7778\n",
            "Epoch 595/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5185 - accuracy: 0.8047 - val_loss: 0.6321 - val_accuracy: 0.7874\n",
            "Epoch 596/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.5183 - accuracy: 0.7981 - val_loss: 0.6377 - val_accuracy: 0.7874\n",
            "Epoch 597/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5184 - accuracy: 0.7975 - val_loss: 0.6299 - val_accuracy: 0.7971\n",
            "Epoch 598/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5323 - accuracy: 0.7956 - val_loss: 0.6184 - val_accuracy: 0.7923\n",
            "Epoch 599/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5122 - accuracy: 0.8053 - val_loss: 0.6452 - val_accuracy: 0.7874\n",
            "Epoch 600/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5069 - accuracy: 0.8065 - val_loss: 0.6307 - val_accuracy: 0.7778\n",
            "Epoch 601/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4822 - accuracy: 0.8017 - val_loss: 0.6238 - val_accuracy: 0.7971\n",
            "Epoch 602/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5069 - accuracy: 0.7999 - val_loss: 0.6254 - val_accuracy: 0.8068\n",
            "Epoch 603/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.5063 - accuracy: 0.8150 - val_loss: 0.6096 - val_accuracy: 0.7826\n",
            "Epoch 604/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.5124 - accuracy: 0.7950 - val_loss: 0.6380 - val_accuracy: 0.7778\n",
            "Epoch 605/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.5257 - accuracy: 0.7956 - val_loss: 0.6298 - val_accuracy: 0.7971\n",
            "Epoch 606/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5103 - accuracy: 0.8089 - val_loss: 0.6328 - val_accuracy: 0.7923\n",
            "Epoch 607/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5161 - accuracy: 0.8083 - val_loss: 0.6356 - val_accuracy: 0.7971\n",
            "Epoch 608/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5058 - accuracy: 0.8071 - val_loss: 0.6387 - val_accuracy: 0.7874\n",
            "Epoch 609/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5210 - accuracy: 0.7944 - val_loss: 0.6327 - val_accuracy: 0.7971\n",
            "Epoch 610/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.5061 - accuracy: 0.8047 - val_loss: 0.6159 - val_accuracy: 0.8019\n",
            "Epoch 611/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.5095 - accuracy: 0.8053 - val_loss: 0.6450 - val_accuracy: 0.7778\n",
            "Epoch 612/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.5134 - accuracy: 0.7890 - val_loss: 0.6204 - val_accuracy: 0.8019\n",
            "Epoch 613/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5032 - accuracy: 0.7993 - val_loss: 0.6256 - val_accuracy: 0.7874\n",
            "Epoch 614/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4831 - accuracy: 0.8204 - val_loss: 0.6297 - val_accuracy: 0.7826\n",
            "Epoch 615/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.5055 - accuracy: 0.8041 - val_loss: 0.6395 - val_accuracy: 0.7874\n",
            "Epoch 616/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4959 - accuracy: 0.8035 - val_loss: 0.6443 - val_accuracy: 0.7729\n",
            "Epoch 617/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4931 - accuracy: 0.8029 - val_loss: 0.6516 - val_accuracy: 0.7778\n",
            "Epoch 618/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4804 - accuracy: 0.8126 - val_loss: 0.6334 - val_accuracy: 0.7874\n",
            "Epoch 619/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.5031 - accuracy: 0.8071 - val_loss: 0.6253 - val_accuracy: 0.7971\n",
            "Epoch 620/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4957 - accuracy: 0.8132 - val_loss: 0.6178 - val_accuracy: 0.7826\n",
            "Epoch 621/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4959 - accuracy: 0.7987 - val_loss: 0.6187 - val_accuracy: 0.7971\n",
            "Epoch 622/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.4848 - accuracy: 0.8029 - val_loss: 0.6311 - val_accuracy: 0.7874\n",
            "Epoch 623/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4841 - accuracy: 0.8162 - val_loss: 0.6300 - val_accuracy: 0.8019\n",
            "Epoch 624/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5191 - accuracy: 0.7896 - val_loss: 0.6299 - val_accuracy: 0.8068\n",
            "Epoch 625/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.4694 - accuracy: 0.8259 - val_loss: 0.6124 - val_accuracy: 0.7971\n",
            "Epoch 626/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4802 - accuracy: 0.8132 - val_loss: 0.6240 - val_accuracy: 0.7923\n",
            "Epoch 627/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4898 - accuracy: 0.8023 - val_loss: 0.6389 - val_accuracy: 0.7971\n",
            "Epoch 628/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.4723 - accuracy: 0.8156 - val_loss: 0.6076 - val_accuracy: 0.8019\n",
            "Epoch 629/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.4845 - accuracy: 0.8096 - val_loss: 0.6143 - val_accuracy: 0.7971\n",
            "Epoch 630/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4849 - accuracy: 0.8102 - val_loss: 0.6101 - val_accuracy: 0.7923\n",
            "Epoch 631/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4833 - accuracy: 0.8108 - val_loss: 0.6091 - val_accuracy: 0.7923\n",
            "Epoch 632/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5036 - accuracy: 0.7969 - val_loss: 0.6057 - val_accuracy: 0.7729\n",
            "Epoch 633/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4749 - accuracy: 0.8144 - val_loss: 0.6181 - val_accuracy: 0.7778\n",
            "Epoch 634/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4899 - accuracy: 0.8144 - val_loss: 0.6301 - val_accuracy: 0.7729\n",
            "Epoch 635/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4674 - accuracy: 0.8216 - val_loss: 0.6267 - val_accuracy: 0.7681\n",
            "Epoch 636/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4726 - accuracy: 0.8271 - val_loss: 0.6366 - val_accuracy: 0.7923\n",
            "Epoch 637/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4988 - accuracy: 0.8126 - val_loss: 0.6195 - val_accuracy: 0.7826\n",
            "Epoch 638/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4697 - accuracy: 0.8180 - val_loss: 0.6319 - val_accuracy: 0.7923\n",
            "Epoch 639/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4802 - accuracy: 0.8138 - val_loss: 0.6133 - val_accuracy: 0.7923\n",
            "Epoch 640/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5016 - accuracy: 0.8053 - val_loss: 0.6297 - val_accuracy: 0.7971\n",
            "Epoch 641/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4676 - accuracy: 0.8168 - val_loss: 0.6184 - val_accuracy: 0.7826\n",
            "Epoch 642/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4473 - accuracy: 0.8295 - val_loss: 0.6245 - val_accuracy: 0.7874\n",
            "Epoch 643/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4826 - accuracy: 0.8108 - val_loss: 0.6326 - val_accuracy: 0.7633\n",
            "Epoch 644/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.4887 - accuracy: 0.8186 - val_loss: 0.6201 - val_accuracy: 0.7826\n",
            "Epoch 645/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4717 - accuracy: 0.8108 - val_loss: 0.6235 - val_accuracy: 0.7826\n",
            "Epoch 646/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.4799 - accuracy: 0.8210 - val_loss: 0.5979 - val_accuracy: 0.8019\n",
            "Epoch 647/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.4694 - accuracy: 0.8174 - val_loss: 0.5841 - val_accuracy: 0.8164\n",
            "Epoch 648/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4721 - accuracy: 0.8180 - val_loss: 0.5961 - val_accuracy: 0.7971\n",
            "Epoch 649/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4740 - accuracy: 0.8174 - val_loss: 0.6107 - val_accuracy: 0.7923\n",
            "Epoch 650/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4824 - accuracy: 0.8186 - val_loss: 0.6189 - val_accuracy: 0.8019\n",
            "Epoch 651/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4819 - accuracy: 0.8126 - val_loss: 0.6112 - val_accuracy: 0.7826\n",
            "Epoch 652/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4493 - accuracy: 0.8241 - val_loss: 0.6063 - val_accuracy: 0.8019\n",
            "Epoch 653/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4500 - accuracy: 0.8307 - val_loss: 0.6166 - val_accuracy: 0.8019\n",
            "Epoch 654/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.4715 - accuracy: 0.8174 - val_loss: 0.6125 - val_accuracy: 0.7923\n",
            "Epoch 655/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.4784 - accuracy: 0.8156 - val_loss: 0.6054 - val_accuracy: 0.7971\n",
            "Epoch 656/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4605 - accuracy: 0.8180 - val_loss: 0.6236 - val_accuracy: 0.7874\n",
            "Epoch 657/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4739 - accuracy: 0.8120 - val_loss: 0.6089 - val_accuracy: 0.7826\n",
            "Epoch 658/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4543 - accuracy: 0.8277 - val_loss: 0.6038 - val_accuracy: 0.7971\n",
            "Epoch 659/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4600 - accuracy: 0.8259 - val_loss: 0.6176 - val_accuracy: 0.7874\n",
            "Epoch 660/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.4549 - accuracy: 0.8313 - val_loss: 0.6110 - val_accuracy: 0.7971\n",
            "Epoch 661/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4512 - accuracy: 0.8362 - val_loss: 0.5943 - val_accuracy: 0.7874\n",
            "Epoch 662/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.4355 - accuracy: 0.8356 - val_loss: 0.6070 - val_accuracy: 0.7923\n",
            "Epoch 663/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4721 - accuracy: 0.8198 - val_loss: 0.5950 - val_accuracy: 0.7826\n",
            "Epoch 664/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4661 - accuracy: 0.8204 - val_loss: 0.6031 - val_accuracy: 0.7874\n",
            "Epoch 665/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.4761 - accuracy: 0.8229 - val_loss: 0.6038 - val_accuracy: 0.7923\n",
            "Epoch 666/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.4487 - accuracy: 0.8222 - val_loss: 0.6078 - val_accuracy: 0.8019\n",
            "Epoch 667/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4686 - accuracy: 0.8289 - val_loss: 0.6105 - val_accuracy: 0.7874\n",
            "Epoch 668/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4514 - accuracy: 0.8313 - val_loss: 0.6105 - val_accuracy: 0.7923\n",
            "Epoch 669/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.4357 - accuracy: 0.8325 - val_loss: 0.6157 - val_accuracy: 0.7826\n",
            "Epoch 670/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.4670 - accuracy: 0.8162 - val_loss: 0.6288 - val_accuracy: 0.7778\n",
            "Epoch 671/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4682 - accuracy: 0.8144 - val_loss: 0.5958 - val_accuracy: 0.7971\n",
            "Epoch 672/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.4270 - accuracy: 0.8464 - val_loss: 0.6087 - val_accuracy: 0.7826\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(cnnhistory.history['loss'])\n",
        "plt.plot(cnnhistory.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train','test'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "oQYnuaCrDH_A",
        "outputId": "2c62d96b-1c2c-472b-904c-19f630d80465"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(cnnhistory.history['accuracy'])\n",
        "plt.plot(cnnhistory.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train','test'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "IFkTuO8nDNdq",
        "outputId": "5b5d5abe-3aae-4839-887d-64211d0d3b57"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model.predict(x_testcnn)"
      ],
      "metadata": {
        "id": "A2xtrN5wDQgY"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_f_ohjXKDUpY",
        "outputId": "2ab24d1d-a028-4ea0-8353-6bef68aac91a"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[2.95749009e-01, 9.60946903e-02, 1.91961542e-01, 2.20100135e-01,\n",
              "        1.36085212e-01, 6.00094199e-02],\n",
              "       [1.00769015e-04, 8.52677913e-05, 8.07077413e-07, 9.89600301e-01,\n",
              "        4.82035575e-05, 1.01647004e-02],\n",
              "       [1.86388567e-01, 1.20311961e-01, 8.04312378e-02, 4.15143222e-01,\n",
              "        5.92816435e-02, 1.38443306e-01],\n",
              "       ...,\n",
              "       [2.32196369e-04, 1.56278077e-06, 7.49859086e-04, 7.28073530e-04,\n",
              "        9.85956073e-01, 1.23322932e-02],\n",
              "       [1.77525853e-05, 5.04659414e-01, 4.93483096e-01, 6.93028443e-04,\n",
              "        2.30903403e-04, 9.15841956e-04],\n",
              "       [4.96042077e-04, 3.63764004e-04, 1.07865885e-01, 1.76702067e-03,\n",
              "        8.01423788e-01, 8.80834162e-02]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cmA2bFgsDW3D",
        "outputId": "d271f4d0-d886-4a10-fa37-04439e6e43bb"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([3, 3, 3, 0, 4, 4, 1, 2, 5, 0, 5, 3, 2, 2, 1, 4, 4, 5, 2, 4, 1, 2,\n",
              "       3, 5, 4, 2, 1, 2, 2, 2, 2, 5, 2, 5, 3, 1, 2, 0, 4, 5, 2, 3, 2, 2,\n",
              "       5, 2, 0, 1, 3, 4, 4, 5, 1, 1, 4, 4, 5, 1, 1, 1, 0, 1, 5, 0, 4, 1,\n",
              "       1, 0, 1, 4, 1, 0, 4, 1, 3, 1, 2, 2, 1, 2, 3, 0, 5, 3, 5, 5, 2, 4,\n",
              "       5, 1, 5, 1, 5, 3, 4, 1, 4, 1, 5, 4, 5, 1, 2, 1, 1, 5, 1, 3, 2, 5,\n",
              "       2, 1, 3, 5, 4, 4, 0, 0, 3, 1, 2, 2, 3, 5, 1, 5, 3, 4, 2, 2, 0, 2,\n",
              "       2, 5, 5, 0, 3, 3, 2, 2, 0, 3, 4, 0, 4, 2, 4, 5, 4, 1, 5, 3, 2, 2,\n",
              "       5, 4, 3, 3, 4, 3, 3, 4, 1, 5, 2, 3, 2, 2, 0, 2, 1, 3, 1, 2, 2, 5,\n",
              "       5, 1, 4, 2, 2, 1, 1, 3, 3, 5, 5, 2, 5, 1, 5, 0, 3, 3, 0, 5, 1, 4,\n",
              "       1, 4, 2, 5, 5, 1, 4, 2, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_Ytest = y_test.astype(int)"
      ],
      "metadata": {
        "id": "0PHDKWJWDY3g"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_Ytest"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k68v2i-pDbZE",
        "outputId": "7046e0f5-5de8-4394-c8a4-596d7f640636"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([3, 3, 3, 0, 4, 4, 1, 2, 5, 0, 5, 3, 2, 2, 1, 4, 4, 5, 2, 4, 1, 2,\n",
              "       3, 5, 4, 2, 1, 2, 2, 2, 2, 5, 2, 5, 3, 1, 2, 0, 4, 5, 2, 3, 2, 2,\n",
              "       5, 2, 0, 1, 3, 4, 4, 5, 1, 1, 4, 4, 5, 1, 1, 1, 0, 1, 5, 0, 4, 1,\n",
              "       1, 0, 1, 4, 1, 0, 4, 1, 3, 1, 2, 2, 1, 2, 3, 0, 5, 3, 5, 5, 2, 4,\n",
              "       5, 1, 5, 1, 5, 3, 4, 1, 4, 1, 5, 4, 5, 1, 2, 1, 1, 5, 1, 3, 2, 5,\n",
              "       2, 1, 3, 5, 4, 4, 0, 0, 3, 1, 2, 2, 3, 5, 1, 5, 3, 4, 2, 2, 0, 2,\n",
              "       2, 5, 5, 0, 3, 3, 2, 2, 0, 3, 4, 0, 4, 2, 4, 5, 4, 1, 5, 3, 2, 2,\n",
              "       5, 4, 3, 3, 4, 3, 3, 4, 1, 5, 2, 3, 2, 2, 0, 2, 1, 3, 1, 2, 2, 5,\n",
              "       5, 1, 4, 2, 2, 1, 1, 3, 3, 5, 5, 2, 5, 1, 5, 0, 3, 3, 0, 5, 1, 4,\n",
              "       1, 4, 2, 5, 5, 1, 4, 2, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds1=predictions.argmax(axis=1)\n",
        "preds1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4_cAI39VFhtp",
        "outputId": "0e8e782e-e288-4c19-b8bf-aeac68b9cfdc"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 3, 3, 4, 4, 4, 1, 2, 5, 1, 4, 3, 2, 2, 1, 4, 4, 3, 2, 4, 2, 2,\n",
              "       3, 5, 5, 2, 2, 1, 2, 2, 2, 5, 2, 5, 3, 1, 2, 0, 4, 5, 2, 3, 2, 2,\n",
              "       3, 2, 1, 1, 3, 4, 4, 2, 1, 1, 4, 4, 5, 1, 1, 1, 0, 1, 2, 1, 4, 1,\n",
              "       1, 1, 1, 4, 1, 2, 4, 1, 5, 4, 2, 2, 1, 2, 1, 0, 5, 3, 5, 5, 2, 3,\n",
              "       3, 1, 0, 1, 5, 3, 2, 2, 4, 1, 5, 4, 5, 1, 2, 1, 1, 5, 1, 3, 2, 5,\n",
              "       3, 2, 3, 5, 4, 4, 2, 0, 3, 1, 1, 2, 1, 5, 1, 3, 3, 3, 2, 2, 0, 4,\n",
              "       2, 3, 3, 0, 3, 3, 2, 4, 0, 3, 4, 1, 4, 4, 4, 5, 4, 1, 5, 3, 2, 2,\n",
              "       5, 4, 4, 3, 4, 5, 3, 4, 1, 5, 2, 3, 2, 2, 0, 2, 1, 3, 1, 2, 4, 3,\n",
              "       5, 1, 4, 2, 4, 1, 1, 3, 3, 5, 5, 2, 5, 1, 2, 1, 3, 3, 2, 4, 2, 4,\n",
              "       1, 4, 3, 2, 5, 1, 4, 1, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "abc = preds1.astype(int).flatten()"
      ],
      "metadata": {
        "id": "H4WEmM60NfQn"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "c = confusion_matrix(new_Ytest, abc) \n",
        "c"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bKEBeEBlFjB8",
        "outputId": "1c52e1be-fbdd-45f0-c532-11aaed832e0e"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 8,  6,  3,  0,  1,  0],\n",
              "       [ 0, 35,  5,  0,  1,  0],\n",
              "       [ 0,  3, 35,  2,  5,  0],\n",
              "       [ 1,  2,  0, 25,  1,  2],\n",
              "       [ 0,  0,  1,  2, 29,  1],\n",
              "       [ 1,  0,  4,  7,  2, 25]])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m4RjG7LWLSQx",
        "outputId": "c3195db2-5447-47f7-ed1a-7f3f5aaf1805"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([3, 3, 3, 0, 4, 4, 1, 2, 5, 0, 5, 3, 2, 2, 1, 4, 4, 5, 2, 4, 1, 2,\n",
              "       3, 5, 4, 2, 1, 2, 2, 2, 2, 5, 2, 5, 3, 1, 2, 0, 4, 5, 2, 3, 2, 2,\n",
              "       5, 2, 0, 1, 3, 4, 4, 5, 1, 1, 4, 4, 5, 1, 1, 1, 0, 1, 5, 0, 4, 1,\n",
              "       1, 0, 1, 4, 1, 0, 4, 1, 3, 1, 2, 2, 1, 2, 3, 0, 5, 3, 5, 5, 2, 4,\n",
              "       5, 1, 5, 1, 5, 3, 4, 1, 4, 1, 5, 4, 5, 1, 2, 1, 1, 5, 1, 3, 2, 5,\n",
              "       2, 1, 3, 5, 4, 4, 0, 0, 3, 1, 2, 2, 3, 5, 1, 5, 3, 4, 2, 2, 0, 2,\n",
              "       2, 5, 5, 0, 3, 3, 2, 2, 0, 3, 4, 0, 4, 2, 4, 5, 4, 1, 5, 3, 2, 2,\n",
              "       5, 4, 3, 3, 4, 3, 3, 4, 1, 5, 2, 3, 2, 2, 0, 2, 1, 3, 1, 2, 2, 5,\n",
              "       5, 1, 4, 2, 2, 1, 1, 3, 3, 5, 5, 2, 5, 1, 5, 0, 3, 3, 0, 5, 1, 4,\n",
              "       1, 4, 2, 5, 5, 1, 4, 2, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss, acc =model.evaluate(x_testcnn, y_test)\n",
        "print(\"Restored model, accuracy: {:5.2f}%\".format(100*acc))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n3kzoqPkDqqS",
        "outputId": "425662c3-9baa-4628-ea35-2f76b283e29d"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7/7 [==============================] - 0s 3ms/step - loss: 0.6196 - accuracy: 0.7585\n",
            "Restored model, accuracy: 75.85%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss, acc =model.evaluate(X_train, y_train)\n",
        "print(\"Restored model train, accuracy: {:5.2f}%\".format(100*acc))"
      ],
      "metadata": {
        "id": "fJDTGH_OUX0z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a2b88b7-a905-4e6b-9859-ddd2b249de05"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "52/52 [==============================] - 0s 3ms/step - loss: 0.3849 - accuracy: 0.8936\n",
            "Restored model train, accuracy: 89.36%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix,accuracy_score\n",
        "import seaborn as sn\n",
        "\n",
        "print(classification_report(new_Ytest,abc))\n",
        "\n",
        "acc = float(accuracy_score(new_Ytest,abc))*100\n",
        "print(\"----accuracy score %s ----\" % acc)\n",
        "\n",
        "cm = confusion_matrix(new_Ytest,abc)\n",
        "#df_cm = pd.DataFrame(cm)\n",
        "class_names = ['neutral','calm', 'happy','sad','angry', 'fearful' ]\n",
        "df_cm = pd.DataFrame(cm, index=class_names, columns=class_names,)\n",
        "sn.heatmap(df_cm, annot=True, fmt='')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 512
        },
        "id": "SfSC3El94LZg",
        "outputId": "b9db8c51-680a-4902-a6af-b2dd28ab4e7b"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.44      0.57        18\n",
            "           1       0.76      0.85      0.80        41\n",
            "           2       0.73      0.78      0.75        45\n",
            "           3       0.69      0.81      0.75        31\n",
            "           4       0.74      0.88      0.81        33\n",
            "           5       0.89      0.64      0.75        39\n",
            "\n",
            "    accuracy                           0.76       207\n",
            "   macro avg       0.77      0.73      0.74       207\n",
            "weighted avg       0.77      0.76      0.75       207\n",
            "\n",
            "----accuracy score 75.84541062801932 ----\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "A6UOIsB2xKek"
      },
      "execution_count": 28,
      "outputs": []
    }
  ]
}