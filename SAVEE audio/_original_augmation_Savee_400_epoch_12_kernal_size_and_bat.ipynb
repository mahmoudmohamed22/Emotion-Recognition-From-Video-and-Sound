{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uzZTLwtNdxKi",
        "outputId": "6a6f5a12-a0d2-4825-e5f7-f9e8cd2dd5ae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: keras in /opt/conda/envs/rapids/lib/python3.7/site-packages (2.8.0)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install keras"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cB9NV-RLdSLZ",
        "outputId": "2c1a7a0b-1023-4dbc-94ff-bfd7991f7f2f"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EbHyBIe_dOYb",
        "outputId": "65c42ecd-cb15-422c-9f7c-006f2a33e71f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow in /opt/conda/envs/rapids/lib/python3.7/site-packages (2.8.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: tf-estimator-nightly==2.8.0.dev2021122109 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from tensorflow) (2.8.0.dev2021122109)\n",
            "Requirement already satisfied: numpy>=1.20 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from tensorflow) (1.21.1)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from tensorflow) (13.0.0)\n",
            "Requirement already satisfied: gast>=0.2.1 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from tensorflow) (0.5.3)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from tensorflow) (0.24.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from tensorflow) (3.6.0)\n",
            "Requirement already satisfied: setuptools in /opt/conda/envs/rapids/lib/python3.7/site-packages (from tensorflow) (49.6.0.post20210108)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from tensorflow) (1.44.0)\n",
            "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from tensorflow) (2.8.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from tensorflow) (1.12.1)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from tensorflow) (1.0.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: six>=1.12.0 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: tensorboard<2.9,>=2.8 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from tensorflow) (2.8.0)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from tensorflow) (2.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from tensorflow) (3.10.0.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from tensorflow) (3.16.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from astunparse>=1.6.0->tensorflow) (0.37.0)\n",
            "Requirement already satisfied: cached-property in /opt/conda/envs/rapids/lib/python3.7/site-packages (from h5py>=2.9.0->tensorflow) (1.5.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from tensorboard<2.9,>=2.8->tensorflow) (3.3.4)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.8.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.6.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.6.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.26.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.0.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.4.6)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.2.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata in /opt/conda/envs/rapids/lib/python3.7/site-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (4.6.4)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (1.26.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2021.10.8)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (3.1)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2.0.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (3.2.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from importlib-metadata->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (3.5.0)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-2iPI3-RdOYc",
        "outputId": "2509154d-3389-4ed5-bb2b-ee9ecd547258"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting package metadata (current_repodata.json): done\n",
            "Solving environment: done\n",
            "\n",
            "# All requested packages already installed.\n",
            "\n",
            "\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "conda install librosa "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bcVbQcYAdOYd",
        "outputId": "1390c775-5026-4e4a-9499-dda6f863afb1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: plotly in /opt/conda/envs/rapids/lib/python3.7/site-packages (5.6.0)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from plotly) (8.0.1)\n",
            "Requirement already satisfied: six in /opt/conda/envs/rapids/lib/python3.7/site-packages (from plotly) (1.16.0)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install plotly"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QeizPlDkdOYe",
        "outputId": "0307d276-8ddb-469d-d681-866e0cd6afab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: librosa in /opt/conda/envs/rapids/lib/python3.7/site-packages (0.9.1)\n",
            "Requirement already satisfied: resampy>=0.2.2 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from librosa) (0.2.2)\n",
            "Requirement already satisfied: scikit-learn>=0.19.1 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from librosa) (0.23.1)\n",
            "Requirement already satisfied: pooch>=1.0 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from librosa) (1.5.1)\n",
            "Requirement already satisfied: audioread>=2.1.5 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from librosa) (2.1.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from librosa) (21.0)\n",
            "Requirement already satisfied: numpy>=1.17.0 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from librosa) (1.21.1)\n",
            "Requirement already satisfied: decorator>=4.0.10 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied: joblib>=0.14 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from librosa) (1.0.1)\n",
            "Requirement already satisfied: numba>=0.45.1 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from librosa) (0.53.1)\n",
            "Requirement already satisfied: scipy>=1.2.0 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from librosa) (1.6.0)\n",
            "Requirement already satisfied: soundfile>=0.10.2 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from librosa) (0.10.3.post1)\n",
            "Requirement already satisfied: llvmlite<0.37,>=0.36.0rc1 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from numba>=0.45.1->librosa) (0.36.0)\n",
            "Requirement already satisfied: setuptools in /opt/conda/envs/rapids/lib/python3.7/site-packages (from numba>=0.45.1->librosa) (49.6.0.post20210108)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from packaging>=20.0->librosa) (2.4.7)\n",
            "Requirement already satisfied: requests in /opt/conda/envs/rapids/lib/python3.7/site-packages (from pooch>=1.0->librosa) (2.26.0)\n",
            "Requirement already satisfied: appdirs in /opt/conda/envs/rapids/lib/python3.7/site-packages (from pooch>=1.0->librosa) (1.4.4)\n",
            "Requirement already satisfied: six>=1.3 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from resampy>=0.2.2->librosa) (1.16.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from scikit-learn>=0.19.1->librosa) (2.2.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from soundfile>=0.10.2->librosa) (1.14.6)\n",
            "Requirement already satisfied: pycparser in /opt/conda/envs/rapids/lib/python3.7/site-packages (from cffi>=1.0->soundfile>=0.10.2->librosa) (2.20)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from requests->pooch>=1.0->librosa) (2021.10.8)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from requests->pooch>=1.0->librosa) (1.26.6)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from requests->pooch>=1.0->librosa) (2.0.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/envs/rapids/lib/python3.7/site-packages (from requests->pooch>=1.0->librosa) (3.1)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install librosa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "NgJohC6sdr-S",
        "outputId": "a867d195-9554-404c-b9f3-30ed53014e80"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "        <script type=\"text/javascript\">\n",
              "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
              "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
              "        if (typeof require !== 'undefined') {\n",
              "        require.undef(\"plotly\");\n",
              "        requirejs.config({\n",
              "            paths: {\n",
              "                'plotly': ['https://cdn.plot.ly/plotly-2.8.3.min']\n",
              "            }\n",
              "        });\n",
              "        require(['plotly'], function(Plotly) {\n",
              "            window._Plotly = Plotly;\n",
              "        });\n",
              "        }\n",
              "        </script>\n",
              "        "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Orignial Notebook: https://github.com/MITESHPUTHRANNEU/Speech-Emotion-Analyzer/blob/master/final_results_gender_test.ipynb\n",
        "# This notebook author: Reza Chu\n",
        "# Last Editing Date: 31st May 2019\n",
        "\n",
        "## Python\n",
        "import os\n",
        "import random\n",
        "import sys\n",
        "\n",
        "import IPython\n",
        "from IPython.display import Audio\n",
        "from IPython.display import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "## Package\n",
        "import glob \n",
        "import keras\n",
        "import IPython.display as ipd\n",
        "import librosa\n",
        "import librosa.display\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import plotly.graph_objs as go\n",
        "import plotly.offline as py\n",
        "import plotly.tools as tls\n",
        "import seaborn as sns\n",
        "import scipy.io.wavfile\n",
        "import tensorflow as tf\n",
        "py.init_notebook_mode(connected=True)\n",
        "\n",
        "## Keras\n",
        "from keras import regularizers\n",
        "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping\n",
        "from keras.callbacks import  History, ReduceLROnPlateau, CSVLogger\n",
        "from keras.models import Model, Sequential\n",
        "from keras.layers import Dense, Embedding, LSTM\n",
        "from keras.layers import Input, Flatten, Dropout, Activation, BatchNormalization\n",
        "from keras.layers import Conv1D, MaxPooling1D, AveragePooling1D\n",
        "from keras.preprocessing import sequence\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.utils import np_utils\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "## Sklearn\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "## Rest\n",
        "from scipy.fftpack import fft\n",
        "from scipy import signal\n",
        "from scipy.io import wavfile\n",
        "from tqdm import tqdm\n",
        "\n",
        "input_duration=3\n",
        "# % pylab inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a9_TpDKveU1d",
        "outputId": "262306be-5c57-4d6e-9ea8-10431b8861f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Data loaded. Loading time: 28.808045148849487 seconds ---\n"
          ]
        }
      ],
      "source": [
        "#only SAVEE data set\n",
        "import time\n",
        "import os\n",
        "import librosa\n",
        "from librosa import display\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "lst = []\n",
        "count=0\n",
        "start_time = time.time()\n",
        "\n",
        "path3 = '/content/drive/My Drive/data_set/SAVEE'\n",
        "for subdir, dirs, files in os.walk(path3):\n",
        "  for file in files:\n",
        "      try:\n",
        "        #0 = neutral,  1 = fearful, 2 = happy, 3 = sad, 4 = angry\n",
        "        if file.startswith('a'):\n",
        "            emotion=4\n",
        "        elif file.startswith('d'):\n",
        "            continue\n",
        "        elif file.startswith('f'):\n",
        "            emotion=1\n",
        "        elif file.startswith('h'):\n",
        "            emotion=2\n",
        "        elif file.startswith('n'):\n",
        "            emotion=0\n",
        "        elif file.startswith('sa'):\n",
        "            emotion=3\n",
        "        elif file.startswith('su'):\n",
        "            continue\n",
        "        else:\n",
        "            continue\n",
        "        #Load librosa array, obtain mfcss, store the file and the mcss information in a new array\n",
        "        X, sample_rate = librosa.load(os.path.join(subdir,file), res_type='kaiser_fast')\n",
        "        #print(sample_rate)\n",
        "       # mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T,axis=0) \n",
        "        count +=1\n",
        "        # The instruction below converts the labels (from 1 to 8) to a series from 0 to 7\n",
        "        # This is because our predictor needs to start from 0 otherwise it will try to predict also 0.\n",
        "        #file = int(file[7:8]) - 1 \n",
        "        #0 = neutral, 1 = calm, 2 = happy, 3 = sad, 4 = angry, 5 = fearful, 6 = disgust, 7 = surprised\n",
        "        arr = X, emotion\n",
        "        lst.append(arr)\n",
        "      # If the file is not valid, skip it\n",
        "      except ValueError:\n",
        "        continue\n",
        "\n",
        "print(\"--- Data loaded. Loading time: %s seconds ---\" % (time.time() - start_time))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XVaArAIkdOYj",
        "outputId": "0b3ce596-6d50-4539-e0bc-f28a817cda9e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/core/fromnumeric.py:3208: VisibleDeprecationWarning:\n",
            "\n",
            "Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "720"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "from numpy.core.fromnumeric import size\n",
        "size(lst)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uo6fLwandOYl",
        "outputId": "f2591226-9f8e-4d2a-97d3-2eb68773afba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/core/fromnumeric.py:3208: VisibleDeprecationWarning:\n",
            "\n",
            "Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "720"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "from numpy.core.fromnumeric import size\n",
        "size(lst)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2vTLVo3SdOYm",
        "outputId": "e5fcba67-f474-413b-8193-9690ebf0f00d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: VisibleDeprecationWarning:\n",
            "\n",
            "Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "audio_file, emotion = zip(*lst)\n",
        "audio_file=np.asarray(audio_file)\n",
        "emotion=np.asarray(emotion)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M-pbYcFDd5a2",
        "outputId": "0c16cadf-252d-4b14-dc61-5c8a31f63024"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((288,), (36,), (36,))"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "\n",
        "emotion.shape,audio_file.shape\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "signal_train, signal_test, emo_train, emo_test = train_test_split(audio_file,emotion, test_size=0.2, random_state=42)\n",
        "signal_valid, signal_test, emo_valid, emo_test = train_test_split(signal_test,emo_test, test_size=0.5,train_size=0.5, random_state=42)\n",
        "signal_train.shape,signal_valid.shape,signal_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "OflClL3QfDoj"
      },
      "outputs": [],
      "source": [
        "x_valid=[]\n",
        "x_test=[]\n",
        "for i in range(signal_valid.size):\n",
        "  x_valid.append(np.mean(librosa.feature.mfcc(y=signal_valid[i], sr=sample_rate, n_mfcc=40).T,axis=0))\n",
        "  #x_valid.append(np.mean(librosa.feature.chroma_stft(S=np.abs(librosa.stft(signal_valid[i])), sr=sample_rate ,n_chroma=12).T,axis=0))\n",
        "\n",
        "for i in range(signal_test.size):\n",
        "  x_test.append(np.mean(librosa.feature.mfcc(y=signal_test[i], sr=sample_rate, n_mfcc=40).T,axis=0))\n",
        "  #x_test.append(np.mean(librosa.feature.chroma_stft(S=np.abs(librosa.stft(signal_test[i])), sr=sample_rate,n_chroma=12).T,axis=0))\n",
        "#resv = np.hstack((resv, mfccsv))  \n",
        "#resv = np.hstack((resv, cromav))  \n",
        "#resv = np.hstack((resv, melv))  \n",
        "\n",
        "#rest = np.hstack((rest, mfccst))  \n",
        "#rest = np.hstack((rest, cromat))  \n",
        "#rest = np.hstack((rest, melt))\n",
        "\n",
        "#x_valid.append(resv)\n",
        "#x_test.append(rest)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kJkN-K17gSvD",
        "outputId": "34604380-ec27-48d2-9052-a0eaf0c2a100"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((36, 40), (36, 40))"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "x_valid=np.asarray(x_valid)\n",
        "x_test=np.asarray(x_test)\n",
        "x_valid.shape,x_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "k43cyWMKgXo9"
      },
      "outputs": [],
      "source": [
        "train_lst=[]\n",
        "for i in range(signal_train.size):\n",
        "  emo=emo_train[i]\n",
        "  x=signal_train[i]\n",
        "  arr=x,emo\n",
        "  train_lst.append(arr)\n",
        "  x=librosa.effects.time_stretch(signal_train[i],0.5)\n",
        "  arr=x,emo\n",
        "  train_lst.append(arr)\n",
        "  x=librosa.effects.time_stretch(signal_train[i],1.5)\n",
        "  arr=x,emo\n",
        "  train_lst.append(arr)\n",
        "  x=librosa.effects.pitch_shift(signal_train[i],sample_rate,2)\n",
        "  arr=x,emo\n",
        "  train_lst.append(arr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "gFL9v0A9kYvD"
      },
      "outputs": [],
      "source": [
        "signal, y_train = zip(*train_lst)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ulnUCfZikY7Y",
        "outputId": "8b61d4f3-90d0-4c24-d1a8-e03b0878a7c2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: VisibleDeprecationWarning:\n",
            "\n",
            "Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "signal=np.asarray(signal)\n",
        "y_train=np.asarray(y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bt0pm0g4kY9q",
        "outputId": "da2646b3-dc75-4ca8-eadd-c94ecf359ff7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1152,)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "y_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "yGPv5UDikY_f"
      },
      "outputs": [],
      "source": [
        "x_train=[]\n",
        "for i in range(signal.size):\n",
        "  x_train.append(np.mean(librosa.feature.mfcc(y=signal[i], sr=sample_rate, n_mfcc=40).T,axis=0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7qnveahvkj3U",
        "outputId": "7596001e-551b-4b58-9b78-6931cb35f698"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1152, 40)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "x_train=np.asarray(x_train)\n",
        "x_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LFnBsKPXkmDV",
        "outputId": "5f90dd47-0569-4287-835a-73182df068b4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1152,)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "y_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zlvfnkyLkxWx",
        "outputId": "f2430f78-035c-47e5-ac71-d94b86f22522"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning:\n",
            "\n",
            "The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import keras\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from keras.preprocessing import sequence\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from keras.layers import Input, Flatten, Dropout, Activation\n",
        "from keras.layers import Conv1D, MaxPooling1D\n",
        "from keras.models import Model\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras import optimizers\n",
        "from keras.models import InputLayer\n",
        "\n",
        "model = Sequential(InputLayer((40,1)))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Conv1D(128, 12,padding='same', ))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.1))\n",
        "model.add(MaxPooling1D(pool_size=(5)))\n",
        "\n",
        "\n",
        "model.add(Conv1D(256,12,padding='same',))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(MaxPooling1D(pool_size=(5)))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(6))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "opt = tf.keras.optimizers.Adam(lr=0.0002)\n",
        "#opt = tf.keras.optimizers.RMSprop(lr=0.0001, rho=0.9, epsilon=1e-07, decay=0.0)\n",
        "#opt = tf.keras.optimizers.SGD(lr=0.001, momentum=0.0, decay=0.0, nesterov=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1-Xsvw44kzg1",
        "outputId": "7a91c348-e6d7-4144-c602-2bfe4990d4a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " batch_normalization (BatchN  (None, 40, 1)            4         \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " conv1d (Conv1D)             (None, 40, 128)           1664      \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 40, 128)          512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation (Activation)     (None, 40, 128)           0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 40, 128)           0         \n",
            "                                                                 \n",
            " max_pooling1d (MaxPooling1D  (None, 8, 128)           0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv1d_1 (Conv1D)           (None, 8, 256)            393472    \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 8, 256)           1024      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 8, 256)            0         \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 8, 256)            0         \n",
            "                                                                 \n",
            " max_pooling1d_1 (MaxPooling  (None, 1, 256)           0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 256)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 6)                 1542      \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 6)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 398,218\n",
            "Trainable params: 397,448\n",
            "Non-trainable params: 770\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "m0w5VpjNk1d7"
      },
      "outputs": [],
      "source": [
        "model.compile(loss='sparse_categorical_crossentropy',\n",
        "              optimizer=opt,\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tz-HMdw4k3Vt",
        "outputId": "5fdc164f-d75e-40c2-8585-539b9b939a33"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/400\n",
            "72/72 [==============================] - 3s 23ms/step - loss: 1.7240 - accuracy: 0.3741 - val_loss: 1.8565 - val_accuracy: 0.1389\n",
            "Epoch 2/400\n",
            "72/72 [==============================] - 1s 20ms/step - loss: 1.2785 - accuracy: 0.5104 - val_loss: 2.0463 - val_accuracy: 0.0278\n",
            "Epoch 3/400\n",
            "72/72 [==============================] - 2s 21ms/step - loss: 1.0766 - accuracy: 0.5825 - val_loss: 2.5100 - val_accuracy: 0.0278\n",
            "Epoch 4/400\n",
            "72/72 [==============================] - 1s 20ms/step - loss: 0.9936 - accuracy: 0.6189 - val_loss: 2.6372 - val_accuracy: 0.0278\n",
            "Epoch 5/400\n",
            "72/72 [==============================] - 2s 21ms/step - loss: 0.9372 - accuracy: 0.6302 - val_loss: 2.3385 - val_accuracy: 0.0278\n",
            "Epoch 6/400\n",
            "72/72 [==============================] - 1s 21ms/step - loss: 0.8726 - accuracy: 0.6675 - val_loss: 1.7168 - val_accuracy: 0.0833\n",
            "Epoch 7/400\n",
            "72/72 [==============================] - 1s 20ms/step - loss: 0.8065 - accuracy: 0.6832 - val_loss: 1.6207 - val_accuracy: 0.2778\n",
            "Epoch 8/400\n",
            "72/72 [==============================] - 1s 20ms/step - loss: 0.8075 - accuracy: 0.6736 - val_loss: 1.0208 - val_accuracy: 0.6111\n",
            "Epoch 9/400\n",
            "72/72 [==============================] - 1s 20ms/step - loss: 0.7645 - accuracy: 0.6918 - val_loss: 0.8884 - val_accuracy: 0.5833\n",
            "Epoch 10/400\n",
            "72/72 [==============================] - 1s 20ms/step - loss: 0.7331 - accuracy: 0.7118 - val_loss: 0.8727 - val_accuracy: 0.6111\n",
            "Epoch 11/400\n",
            "72/72 [==============================] - 1s 20ms/step - loss: 0.7031 - accuracy: 0.7326 - val_loss: 0.6739 - val_accuracy: 0.7222\n",
            "Epoch 12/400\n",
            "72/72 [==============================] - 1s 20ms/step - loss: 0.6990 - accuracy: 0.7231 - val_loss: 0.6933 - val_accuracy: 0.6667\n",
            "Epoch 13/400\n",
            "72/72 [==============================] - 1s 21ms/step - loss: 0.6869 - accuracy: 0.7292 - val_loss: 0.8260 - val_accuracy: 0.6944\n",
            "Epoch 14/400\n",
            "72/72 [==============================] - 1s 20ms/step - loss: 0.6133 - accuracy: 0.7517 - val_loss: 0.7494 - val_accuracy: 0.6667\n",
            "Epoch 15/400\n",
            "72/72 [==============================] - 2s 21ms/step - loss: 0.6337 - accuracy: 0.7517 - val_loss: 0.8007 - val_accuracy: 0.6944\n",
            "Epoch 16/400\n",
            "72/72 [==============================] - 1s 20ms/step - loss: 0.5834 - accuracy: 0.7648 - val_loss: 0.6301 - val_accuracy: 0.7222\n",
            "Epoch 17/400\n",
            "72/72 [==============================] - 1s 20ms/step - loss: 0.5594 - accuracy: 0.7630 - val_loss: 0.9743 - val_accuracy: 0.6389\n",
            "Epoch 18/400\n",
            "72/72 [==============================] - 1s 21ms/step - loss: 0.5931 - accuracy: 0.7491 - val_loss: 0.7228 - val_accuracy: 0.6389\n",
            "Epoch 19/400\n",
            "72/72 [==============================] - 2s 29ms/step - loss: 0.5335 - accuracy: 0.7882 - val_loss: 0.7450 - val_accuracy: 0.7222\n",
            "Epoch 20/400\n",
            "72/72 [==============================] - 1s 20ms/step - loss: 0.5865 - accuracy: 0.7752 - val_loss: 0.5659 - val_accuracy: 0.7222\n",
            "Epoch 21/400\n",
            "72/72 [==============================] - 1s 21ms/step - loss: 0.5402 - accuracy: 0.7752 - val_loss: 0.7585 - val_accuracy: 0.6667\n",
            "Epoch 22/400\n",
            "72/72 [==============================] - 1s 21ms/step - loss: 0.5112 - accuracy: 0.7882 - val_loss: 0.6273 - val_accuracy: 0.7222\n",
            "Epoch 23/400\n",
            "72/72 [==============================] - 1s 21ms/step - loss: 0.4952 - accuracy: 0.7917 - val_loss: 0.8569 - val_accuracy: 0.6389\n",
            "Epoch 24/400\n",
            "72/72 [==============================] - 1s 20ms/step - loss: 0.4975 - accuracy: 0.8003 - val_loss: 0.5922 - val_accuracy: 0.6944\n",
            "Epoch 25/400\n",
            "72/72 [==============================] - 2s 25ms/step - loss: 0.4655 - accuracy: 0.8142 - val_loss: 0.5423 - val_accuracy: 0.7500\n",
            "Epoch 26/400\n",
            "72/72 [==============================] - 1s 20ms/step - loss: 0.4531 - accuracy: 0.8212 - val_loss: 0.4977 - val_accuracy: 0.8056\n",
            "Epoch 27/400\n",
            "72/72 [==============================] - 1s 21ms/step - loss: 0.4242 - accuracy: 0.8168 - val_loss: 0.5925 - val_accuracy: 0.7500\n",
            "Epoch 28/400\n",
            "72/72 [==============================] - 1s 21ms/step - loss: 0.4176 - accuracy: 0.8299 - val_loss: 0.5894 - val_accuracy: 0.6944\n",
            "Epoch 29/400\n",
            "72/72 [==============================] - 1s 20ms/step - loss: 0.4029 - accuracy: 0.8299 - val_loss: 0.6216 - val_accuracy: 0.7500\n",
            "Epoch 30/400\n",
            "72/72 [==============================] - 1s 21ms/step - loss: 0.4179 - accuracy: 0.8264 - val_loss: 0.8778 - val_accuracy: 0.6667\n",
            "Epoch 31/400\n",
            "72/72 [==============================] - 2s 21ms/step - loss: 0.4206 - accuracy: 0.8342 - val_loss: 0.6152 - val_accuracy: 0.6944\n",
            "Epoch 32/400\n",
            "72/72 [==============================] - 2s 21ms/step - loss: 0.3858 - accuracy: 0.8446 - val_loss: 0.4847 - val_accuracy: 0.8056\n",
            "Epoch 33/400\n",
            "72/72 [==============================] - 2s 22ms/step - loss: 0.3781 - accuracy: 0.8481 - val_loss: 0.8812 - val_accuracy: 0.6111\n",
            "Epoch 34/400\n",
            "72/72 [==============================] - 2s 22ms/step - loss: 0.3690 - accuracy: 0.8516 - val_loss: 0.4754 - val_accuracy: 0.7778\n",
            "Epoch 35/400\n",
            "72/72 [==============================] - 2s 21ms/step - loss: 0.3335 - accuracy: 0.8568 - val_loss: 0.4680 - val_accuracy: 0.7778\n",
            "Epoch 36/400\n",
            "72/72 [==============================] - 1s 21ms/step - loss: 0.3317 - accuracy: 0.8628 - val_loss: 0.7040 - val_accuracy: 0.6944\n",
            "Epoch 37/400\n",
            "72/72 [==============================] - 1s 21ms/step - loss: 0.3199 - accuracy: 0.8733 - val_loss: 0.5719 - val_accuracy: 0.7778\n",
            "Epoch 38/400\n",
            "72/72 [==============================] - 2s 21ms/step - loss: 0.3605 - accuracy: 0.8628 - val_loss: 0.6977 - val_accuracy: 0.7778\n",
            "Epoch 39/400\n",
            "72/72 [==============================] - 1s 21ms/step - loss: 0.3431 - accuracy: 0.8620 - val_loss: 0.6273 - val_accuracy: 0.6944\n",
            "Epoch 40/400\n",
            "72/72 [==============================] - 1s 21ms/step - loss: 0.3442 - accuracy: 0.8533 - val_loss: 0.3859 - val_accuracy: 0.7778\n",
            "Epoch 41/400\n",
            "72/72 [==============================] - 1s 20ms/step - loss: 0.2809 - accuracy: 0.8906 - val_loss: 0.6244 - val_accuracy: 0.6944\n",
            "Epoch 42/400\n",
            "72/72 [==============================] - 1s 20ms/step - loss: 0.2891 - accuracy: 0.8880 - val_loss: 0.6322 - val_accuracy: 0.7500\n",
            "Epoch 43/400\n",
            "72/72 [==============================] - 1s 21ms/step - loss: 0.3008 - accuracy: 0.8741 - val_loss: 0.4695 - val_accuracy: 0.7500\n",
            "Epoch 44/400\n",
            "72/72 [==============================] - 2s 21ms/step - loss: 0.2870 - accuracy: 0.8854 - val_loss: 0.4836 - val_accuracy: 0.8056\n",
            "Epoch 45/400\n",
            "72/72 [==============================] - 1s 21ms/step - loss: 0.2930 - accuracy: 0.8819 - val_loss: 0.4898 - val_accuracy: 0.8333\n",
            "Epoch 46/400\n",
            "72/72 [==============================] - 1s 21ms/step - loss: 0.2910 - accuracy: 0.8837 - val_loss: 0.6516 - val_accuracy: 0.6944\n",
            "Epoch 47/400\n",
            "72/72 [==============================] - 2s 21ms/step - loss: 0.2616 - accuracy: 0.8880 - val_loss: 0.7153 - val_accuracy: 0.6944\n",
            "Epoch 48/400\n",
            "72/72 [==============================] - 2s 21ms/step - loss: 0.2591 - accuracy: 0.8915 - val_loss: 0.5710 - val_accuracy: 0.7222\n",
            "Epoch 49/400\n",
            "72/72 [==============================] - 2s 21ms/step - loss: 0.2314 - accuracy: 0.9062 - val_loss: 0.6438 - val_accuracy: 0.7500\n",
            "Epoch 50/400\n",
            "72/72 [==============================] - 2s 21ms/step - loss: 0.2379 - accuracy: 0.9123 - val_loss: 0.3896 - val_accuracy: 0.8333\n",
            "Epoch 51/400\n",
            "72/72 [==============================] - 1s 21ms/step - loss: 0.2351 - accuracy: 0.9089 - val_loss: 0.4320 - val_accuracy: 0.7778\n",
            "Epoch 52/400\n",
            "72/72 [==============================] - 2s 21ms/step - loss: 0.2218 - accuracy: 0.9201 - val_loss: 0.3781 - val_accuracy: 0.8056\n",
            "Epoch 53/400\n",
            "72/72 [==============================] - 1s 21ms/step - loss: 0.2172 - accuracy: 0.9097 - val_loss: 0.4373 - val_accuracy: 0.8056\n",
            "Epoch 54/400\n",
            "72/72 [==============================] - 1s 20ms/step - loss: 0.2334 - accuracy: 0.9123 - val_loss: 0.3789 - val_accuracy: 0.8611\n",
            "Epoch 55/400\n",
            "72/72 [==============================] - 2s 21ms/step - loss: 0.1963 - accuracy: 0.9245 - val_loss: 0.4512 - val_accuracy: 0.8333\n",
            "Epoch 56/400\n",
            "72/72 [==============================] - 1s 20ms/step - loss: 0.1935 - accuracy: 0.9201 - val_loss: 0.2740 - val_accuracy: 0.9167\n",
            "Epoch 57/400\n",
            "72/72 [==============================] - 2s 21ms/step - loss: 0.2065 - accuracy: 0.9201 - val_loss: 0.5559 - val_accuracy: 0.7500\n",
            "Epoch 58/400\n",
            "72/72 [==============================] - 2s 21ms/step - loss: 0.2082 - accuracy: 0.9141 - val_loss: 0.4116 - val_accuracy: 0.8056\n",
            "Epoch 59/400\n",
            "72/72 [==============================] - 1s 21ms/step - loss: 0.1755 - accuracy: 0.9332 - val_loss: 0.4336 - val_accuracy: 0.7500\n",
            "Epoch 60/400\n",
            "72/72 [==============================] - 2s 21ms/step - loss: 0.1667 - accuracy: 0.9488 - val_loss: 0.4261 - val_accuracy: 0.7500\n",
            "Epoch 61/400\n",
            "72/72 [==============================] - 1s 21ms/step - loss: 0.1724 - accuracy: 0.9332 - val_loss: 0.6712 - val_accuracy: 0.7500\n",
            "Epoch 62/400\n",
            "72/72 [==============================] - 1s 21ms/step - loss: 0.1655 - accuracy: 0.9392 - val_loss: 0.5849 - val_accuracy: 0.7222\n",
            "Epoch 63/400\n",
            "72/72 [==============================] - 1s 21ms/step - loss: 0.1971 - accuracy: 0.9349 - val_loss: 0.4603 - val_accuracy: 0.7500\n",
            "Epoch 64/400\n",
            "72/72 [==============================] - 2s 21ms/step - loss: 0.1787 - accuracy: 0.9358 - val_loss: 0.2720 - val_accuracy: 0.8889\n",
            "Epoch 65/400\n",
            "72/72 [==============================] - 2s 21ms/step - loss: 0.1596 - accuracy: 0.9427 - val_loss: 0.4348 - val_accuracy: 0.7778\n",
            "Epoch 66/400\n",
            "72/72 [==============================] - 2s 21ms/step - loss: 0.1433 - accuracy: 0.9505 - val_loss: 0.2826 - val_accuracy: 0.8889\n",
            "Epoch 67/400\n",
            "72/72 [==============================] - 2s 21ms/step - loss: 0.1414 - accuracy: 0.9444 - val_loss: 0.3982 - val_accuracy: 0.8056\n",
            "Epoch 68/400\n",
            "72/72 [==============================] - 1s 21ms/step - loss: 0.1715 - accuracy: 0.9366 - val_loss: 0.2787 - val_accuracy: 0.8889\n",
            "Epoch 69/400\n",
            "72/72 [==============================] - 1s 21ms/step - loss: 0.1568 - accuracy: 0.9358 - val_loss: 0.6286 - val_accuracy: 0.7222\n",
            "Epoch 70/400\n",
            "72/72 [==============================] - 1s 20ms/step - loss: 0.1547 - accuracy: 0.9470 - val_loss: 0.5003 - val_accuracy: 0.7500\n",
            "Epoch 71/400\n",
            "72/72 [==============================] - 2s 21ms/step - loss: 0.1498 - accuracy: 0.9444 - val_loss: 0.4032 - val_accuracy: 0.8056\n",
            "Epoch 72/400\n",
            "72/72 [==============================] - 2s 21ms/step - loss: 0.1706 - accuracy: 0.9349 - val_loss: 0.4828 - val_accuracy: 0.8056\n",
            "Epoch 73/400\n",
            "72/72 [==============================] - 2s 21ms/step - loss: 0.1323 - accuracy: 0.9566 - val_loss: 0.6422 - val_accuracy: 0.7778\n",
            "Epoch 74/400\n",
            "72/72 [==============================] - 1s 21ms/step - loss: 0.1568 - accuracy: 0.9410 - val_loss: 0.4598 - val_accuracy: 0.8056\n",
            "Epoch 75/400\n",
            "72/72 [==============================] - 1s 21ms/step - loss: 0.1401 - accuracy: 0.9479 - val_loss: 0.4956 - val_accuracy: 0.8333\n",
            "Epoch 76/400\n",
            "72/72 [==============================] - 2s 21ms/step - loss: 0.1121 - accuracy: 0.9653 - val_loss: 0.4061 - val_accuracy: 0.8611\n",
            "Epoch 77/400\n",
            "72/72 [==============================] - 2s 21ms/step - loss: 0.1150 - accuracy: 0.9601 - val_loss: 0.4484 - val_accuracy: 0.8333\n",
            "Epoch 78/400\n",
            "72/72 [==============================] - 2s 22ms/step - loss: 0.1163 - accuracy: 0.9540 - val_loss: 0.4035 - val_accuracy: 0.7778\n",
            "Epoch 79/400\n",
            "72/72 [==============================] - 2s 21ms/step - loss: 0.1277 - accuracy: 0.9549 - val_loss: 0.5251 - val_accuracy: 0.7500\n",
            "Epoch 80/400\n",
            "72/72 [==============================] - 2s 21ms/step - loss: 0.0901 - accuracy: 0.9714 - val_loss: 0.6018 - val_accuracy: 0.8333\n",
            "Epoch 81/400\n",
            "72/72 [==============================] - 2s 21ms/step - loss: 0.0944 - accuracy: 0.9679 - val_loss: 0.4849 - val_accuracy: 0.7500\n",
            "Epoch 82/400\n",
            "72/72 [==============================] - 2s 22ms/step - loss: 0.1084 - accuracy: 0.9609 - val_loss: 0.5225 - val_accuracy: 0.6944\n",
            "Epoch 83/400\n",
            "72/72 [==============================] - 2s 21ms/step - loss: 0.1031 - accuracy: 0.9661 - val_loss: 0.3290 - val_accuracy: 0.8333\n",
            "Epoch 84/400\n",
            "72/72 [==============================] - 2s 22ms/step - loss: 0.1010 - accuracy: 0.9609 - val_loss: 0.2935 - val_accuracy: 0.8889\n",
            "Epoch 85/400\n",
            "72/72 [==============================] - 2s 21ms/step - loss: 0.1134 - accuracy: 0.9583 - val_loss: 0.6097 - val_accuracy: 0.7500\n",
            "Epoch 86/400\n",
            "72/72 [==============================] - 2s 21ms/step - loss: 0.1285 - accuracy: 0.9514 - val_loss: 0.5149 - val_accuracy: 0.7500\n",
            "Epoch 87/400\n",
            "72/72 [==============================] - 2s 22ms/step - loss: 0.1322 - accuracy: 0.9531 - val_loss: 0.3210 - val_accuracy: 0.8333\n",
            "Epoch 88/400\n",
            "72/72 [==============================] - 2s 22ms/step - loss: 0.0933 - accuracy: 0.9653 - val_loss: 0.3144 - val_accuracy: 0.8056\n",
            "Epoch 89/400\n",
            "72/72 [==============================] - 2s 22ms/step - loss: 0.0907 - accuracy: 0.9670 - val_loss: 0.4757 - val_accuracy: 0.8056\n",
            "Epoch 90/400\n",
            "72/72 [==============================] - 2s 21ms/step - loss: 0.0993 - accuracy: 0.9609 - val_loss: 0.3861 - val_accuracy: 0.8333\n",
            "Epoch 91/400\n",
            "72/72 [==============================] - 2s 21ms/step - loss: 0.0804 - accuracy: 0.9696 - val_loss: 0.3845 - val_accuracy: 0.8056\n",
            "Epoch 92/400\n",
            "72/72 [==============================] - 2s 22ms/step - loss: 0.1005 - accuracy: 0.9670 - val_loss: 0.5525 - val_accuracy: 0.7500\n",
            "Epoch 93/400\n",
            "72/72 [==============================] - 2s 21ms/step - loss: 0.0957 - accuracy: 0.9705 - val_loss: 0.5066 - val_accuracy: 0.7222\n",
            "Epoch 94/400\n",
            "72/72 [==============================] - 2s 21ms/step - loss: 0.0845 - accuracy: 0.9679 - val_loss: 0.4037 - val_accuracy: 0.8056\n",
            "Epoch 95/400\n",
            "72/72 [==============================] - 2s 21ms/step - loss: 0.0838 - accuracy: 0.9731 - val_loss: 0.3808 - val_accuracy: 0.7778\n",
            "Epoch 96/400\n",
            "72/72 [==============================] - 2s 21ms/step - loss: 0.1026 - accuracy: 0.9609 - val_loss: 0.3319 - val_accuracy: 0.8056\n",
            "Epoch 97/400\n",
            "72/72 [==============================] - 2s 21ms/step - loss: 0.1086 - accuracy: 0.9592 - val_loss: 0.4286 - val_accuracy: 0.8056\n",
            "Epoch 98/400\n",
            "72/72 [==============================] - 2s 21ms/step - loss: 0.1108 - accuracy: 0.9592 - val_loss: 0.2866 - val_accuracy: 0.8611\n",
            "Epoch 99/400\n",
            "72/72 [==============================] - 2s 21ms/step - loss: 0.0998 - accuracy: 0.9566 - val_loss: 0.6705 - val_accuracy: 0.8056\n",
            "Epoch 100/400\n",
            "72/72 [==============================] - 2s 21ms/step - loss: 0.1172 - accuracy: 0.9549 - val_loss: 0.3992 - val_accuracy: 0.8333\n",
            "Epoch 101/400\n",
            "72/72 [==============================] - 2s 21ms/step - loss: 0.0742 - accuracy: 0.9748 - val_loss: 0.4537 - val_accuracy: 0.7778\n",
            "Epoch 102/400\n",
            "72/72 [==============================] - 2s 22ms/step - loss: 0.0605 - accuracy: 0.9826 - val_loss: 0.4009 - val_accuracy: 0.8333\n",
            "Epoch 103/400\n",
            "72/72 [==============================] - 2s 22ms/step - loss: 0.0578 - accuracy: 0.9826 - val_loss: 0.4654 - val_accuracy: 0.8333\n",
            "Epoch 104/400\n",
            "72/72 [==============================] - 2s 22ms/step - loss: 0.0810 - accuracy: 0.9740 - val_loss: 0.4032 - val_accuracy: 0.8333\n",
            "Epoch 105/400\n",
            "72/72 [==============================] - 2s 21ms/step - loss: 0.0736 - accuracy: 0.9748 - val_loss: 0.6684 - val_accuracy: 0.6944\n",
            "Epoch 106/400\n",
            "72/72 [==============================] - 2s 22ms/step - loss: 0.0695 - accuracy: 0.9757 - val_loss: 0.4438 - val_accuracy: 0.8611\n",
            "Epoch 107/400\n",
            "72/72 [==============================] - 2s 22ms/step - loss: 0.0651 - accuracy: 0.9809 - val_loss: 0.3664 - val_accuracy: 0.7778\n",
            "Epoch 108/400\n",
            "72/72 [==============================] - 2s 21ms/step - loss: 0.0615 - accuracy: 0.9800 - val_loss: 0.5368 - val_accuracy: 0.8056\n",
            "Epoch 109/400\n",
            "72/72 [==============================] - 2s 21ms/step - loss: 0.0664 - accuracy: 0.9748 - val_loss: 0.4255 - val_accuracy: 0.7778\n",
            "Epoch 110/400\n",
            "72/72 [==============================] - 1s 21ms/step - loss: 0.0608 - accuracy: 0.9809 - val_loss: 0.6691 - val_accuracy: 0.7222\n",
            "Epoch 111/400\n",
            "72/72 [==============================] - 2s 21ms/step - loss: 0.0636 - accuracy: 0.9792 - val_loss: 0.5161 - val_accuracy: 0.7778\n",
            "Epoch 112/400\n",
            "72/72 [==============================] - 2s 21ms/step - loss: 0.0752 - accuracy: 0.9757 - val_loss: 0.3884 - val_accuracy: 0.8056\n",
            "Epoch 113/400\n",
            "72/72 [==============================] - 2s 22ms/step - loss: 0.0743 - accuracy: 0.9696 - val_loss: 0.3634 - val_accuracy: 0.8056\n",
            "Epoch 114/400\n",
            "72/72 [==============================] - 2s 21ms/step - loss: 0.0641 - accuracy: 0.9800 - val_loss: 0.4506 - val_accuracy: 0.8056\n",
            "Epoch 115/400\n",
            "72/72 [==============================] - 2s 21ms/step - loss: 0.0652 - accuracy: 0.9792 - val_loss: 0.5685 - val_accuracy: 0.7778\n",
            "Epoch 116/400\n",
            "72/72 [==============================] - 2s 22ms/step - loss: 0.0586 - accuracy: 0.9818 - val_loss: 0.4673 - val_accuracy: 0.8056\n",
            "Epoch 117/400\n",
            "72/72 [==============================] - 2s 22ms/step - loss: 0.0660 - accuracy: 0.9766 - val_loss: 0.5186 - val_accuracy: 0.8056\n",
            "Epoch 118/400\n",
            "72/72 [==============================] - 2s 21ms/step - loss: 0.0638 - accuracy: 0.9774 - val_loss: 0.5113 - val_accuracy: 0.7778\n",
            "Epoch 119/400\n",
            "72/72 [==============================] - 2s 21ms/step - loss: 0.0498 - accuracy: 0.9852 - val_loss: 0.5383 - val_accuracy: 0.8056\n",
            "Epoch 120/400\n",
            "72/72 [==============================] - 2s 21ms/step - loss: 0.0497 - accuracy: 0.9844 - val_loss: 0.4536 - val_accuracy: 0.8333\n",
            "Epoch 121/400\n",
            "72/72 [==============================] - 2s 22ms/step - loss: 0.0391 - accuracy: 0.9896 - val_loss: 0.3831 - val_accuracy: 0.8056\n",
            "Epoch 122/400\n",
            "72/72 [==============================] - 2s 21ms/step - loss: 0.0438 - accuracy: 0.9861 - val_loss: 0.4575 - val_accuracy: 0.8056\n",
            "Epoch 123/400\n",
            "72/72 [==============================] - 2s 22ms/step - loss: 0.0561 - accuracy: 0.9809 - val_loss: 0.3874 - val_accuracy: 0.7778\n",
            "Epoch 124/400\n",
            "72/72 [==============================] - 2s 21ms/step - loss: 0.0553 - accuracy: 0.9783 - val_loss: 0.5563 - val_accuracy: 0.7778\n",
            "Epoch 125/400\n",
            "72/72 [==============================] - 2s 22ms/step - loss: 0.0584 - accuracy: 0.9800 - val_loss: 0.5657 - val_accuracy: 0.8056\n",
            "Epoch 126/400\n",
            "72/72 [==============================] - 2s 21ms/step - loss: 0.0811 - accuracy: 0.9714 - val_loss: 0.4414 - val_accuracy: 0.7778\n",
            "Epoch 127/400\n",
            "72/72 [==============================] - 2s 22ms/step - loss: 0.0409 - accuracy: 0.9896 - val_loss: 0.4408 - val_accuracy: 0.8333\n",
            "Epoch 128/400\n",
            "72/72 [==============================] - 2s 22ms/step - loss: 0.0628 - accuracy: 0.9740 - val_loss: 0.5166 - val_accuracy: 0.7778\n",
            "Epoch 129/400\n",
            "72/72 [==============================] - 2s 21ms/step - loss: 0.0530 - accuracy: 0.9800 - val_loss: 0.3094 - val_accuracy: 0.8611\n",
            "Epoch 130/400\n",
            "72/72 [==============================] - 2s 21ms/step - loss: 0.0569 - accuracy: 0.9818 - val_loss: 0.3227 - val_accuracy: 0.8611\n",
            "Epoch 131/400\n",
            "72/72 [==============================] - 2s 22ms/step - loss: 0.0536 - accuracy: 0.9809 - val_loss: 0.4978 - val_accuracy: 0.7778\n",
            "Epoch 132/400\n",
            "72/72 [==============================] - 2s 21ms/step - loss: 0.0401 - accuracy: 0.9878 - val_loss: 0.4073 - val_accuracy: 0.8889\n",
            "Epoch 133/400\n",
            "72/72 [==============================] - 2s 22ms/step - loss: 0.0531 - accuracy: 0.9826 - val_loss: 0.7204 - val_accuracy: 0.7778\n",
            "Epoch 134/400\n",
            "72/72 [==============================] - 2s 22ms/step - loss: 0.0659 - accuracy: 0.9757 - val_loss: 0.3910 - val_accuracy: 0.8333\n",
            "Epoch 135/400\n",
            "72/72 [==============================] - 2s 21ms/step - loss: 0.0535 - accuracy: 0.9792 - val_loss: 0.4136 - val_accuracy: 0.8056\n",
            "Epoch 136/400\n",
            "72/72 [==============================] - 2s 21ms/step - loss: 0.0533 - accuracy: 0.9835 - val_loss: 0.3472 - val_accuracy: 0.7778\n",
            "Epoch 137/400\n",
            "72/72 [==============================] - 2s 22ms/step - loss: 0.0387 - accuracy: 0.9887 - val_loss: 0.2921 - val_accuracy: 0.8333\n",
            "Epoch 138/400\n",
            "72/72 [==============================] - 1s 21ms/step - loss: 0.0423 - accuracy: 0.9887 - val_loss: 0.4623 - val_accuracy: 0.8333\n",
            "Epoch 139/400\n",
            "72/72 [==============================] - 1s 21ms/step - loss: 0.0413 - accuracy: 0.9852 - val_loss: 0.3780 - val_accuracy: 0.8056\n",
            "Epoch 140/400\n",
            "72/72 [==============================] - 2s 21ms/step - loss: 0.0374 - accuracy: 0.9870 - val_loss: 0.4924 - val_accuracy: 0.8056\n",
            "Epoch 141/400\n",
            "72/72 [==============================] - 2s 21ms/step - loss: 0.0566 - accuracy: 0.9792 - val_loss: 0.4519 - val_accuracy: 0.8056\n",
            "Epoch 142/400\n",
            "72/72 [==============================] - 2s 21ms/step - loss: 0.0327 - accuracy: 0.9913 - val_loss: 0.3908 - val_accuracy: 0.7778\n",
            "Epoch 143/400\n",
            "72/72 [==============================] - 2s 21ms/step - loss: 0.0407 - accuracy: 0.9852 - val_loss: 0.5530 - val_accuracy: 0.8056\n",
            "Epoch 144/400\n",
            "72/72 [==============================] - 2s 21ms/step - loss: 0.0399 - accuracy: 0.9878 - val_loss: 0.5210 - val_accuracy: 0.7500\n",
            "Epoch 145/400\n",
            "72/72 [==============================] - 2s 22ms/step - loss: 0.0269 - accuracy: 0.9931 - val_loss: 0.4491 - val_accuracy: 0.8056\n",
            "Epoch 146/400\n",
            "72/72 [==============================] - 2s 21ms/step - loss: 0.0512 - accuracy: 0.9774 - val_loss: 0.4249 - val_accuracy: 0.8056\n",
            "Epoch 147/400\n",
            "72/72 [==============================] - 2s 22ms/step - loss: 0.0379 - accuracy: 0.9913 - val_loss: 0.5892 - val_accuracy: 0.8056\n",
            "Epoch 148/400\n",
            "72/72 [==============================] - 2s 22ms/step - loss: 0.0448 - accuracy: 0.9835 - val_loss: 0.7480 - val_accuracy: 0.7222\n",
            "Epoch 149/400\n",
            "72/72 [==============================] - 2s 22ms/step - loss: 0.0326 - accuracy: 0.9913 - val_loss: 0.3405 - val_accuracy: 0.8333\n",
            "Epoch 150/400\n",
            "72/72 [==============================] - 2s 22ms/step - loss: 0.0387 - accuracy: 0.9887 - val_loss: 0.4141 - val_accuracy: 0.8056\n",
            "Epoch 151/400\n",
            "72/72 [==============================] - 2s 21ms/step - loss: 0.0337 - accuracy: 0.9887 - val_loss: 0.4925 - val_accuracy: 0.8056\n",
            "Epoch 152/400\n",
            "72/72 [==============================] - 2s 21ms/step - loss: 0.0354 - accuracy: 0.9896 - val_loss: 0.5235 - val_accuracy: 0.8056\n",
            "Epoch 153/400\n",
            "72/72 [==============================] - 2s 22ms/step - loss: 0.0406 - accuracy: 0.9852 - val_loss: 0.4168 - val_accuracy: 0.8056\n",
            "Epoch 154/400\n",
            "72/72 [==============================] - 2s 21ms/step - loss: 0.0299 - accuracy: 0.9913 - val_loss: 0.4830 - val_accuracy: 0.8333\n",
            "Epoch 155/400\n",
            "72/72 [==============================] - 2s 22ms/step - loss: 0.0258 - accuracy: 0.9913 - val_loss: 0.3608 - val_accuracy: 0.8333\n",
            "Epoch 156/400\n",
            "72/72 [==============================] - 2s 21ms/step - loss: 0.0377 - accuracy: 0.9905 - val_loss: 0.4017 - val_accuracy: 0.7778\n",
            "Epoch 157/400\n",
            "72/72 [==============================] - 2s 22ms/step - loss: 0.0256 - accuracy: 0.9931 - val_loss: 0.4104 - val_accuracy: 0.8056\n",
            "Epoch 158/400\n",
            "72/72 [==============================] - 2s 21ms/step - loss: 0.0280 - accuracy: 0.9922 - val_loss: 0.3556 - val_accuracy: 0.8056\n",
            "Epoch 159/400\n",
            "72/72 [==============================] - 2s 21ms/step - loss: 0.0364 - accuracy: 0.9878 - val_loss: 0.7169 - val_accuracy: 0.7778\n",
            "Epoch 160/400\n",
            "72/72 [==============================] - 2s 22ms/step - loss: 0.0312 - accuracy: 0.9922 - val_loss: 0.4601 - val_accuracy: 0.7778\n",
            "Epoch 161/400\n",
            "72/72 [==============================] - 2s 21ms/step - loss: 0.0280 - accuracy: 0.9939 - val_loss: 0.3683 - val_accuracy: 0.8333\n",
            "Epoch 162/400\n",
            "72/72 [==============================] - 2s 22ms/step - loss: 0.0289 - accuracy: 0.9939 - val_loss: 0.5117 - val_accuracy: 0.7778\n",
            "Epoch 163/400\n",
            "72/72 [==============================] - 2s 21ms/step - loss: 0.0188 - accuracy: 0.9974 - val_loss: 0.3225 - val_accuracy: 0.8333\n",
            "Epoch 164/400\n",
            "72/72 [==============================] - 2s 21ms/step - loss: 0.0274 - accuracy: 0.9887 - val_loss: 0.3866 - val_accuracy: 0.8333\n",
            "Epoch 165/400\n",
            "72/72 [==============================] - 2s 22ms/step - loss: 0.0218 - accuracy: 0.9939 - val_loss: 0.4524 - val_accuracy: 0.8056\n",
            "Epoch 166/400\n",
            "72/72 [==============================] - 2s 22ms/step - loss: 0.0194 - accuracy: 0.9939 - val_loss: 0.5530 - val_accuracy: 0.8333\n",
            "Epoch 167/400\n",
            "72/72 [==============================] - 2s 23ms/step - loss: 0.0245 - accuracy: 0.9931 - val_loss: 0.5003 - val_accuracy: 0.7778\n",
            "Epoch 168/400\n",
            "72/72 [==============================] - 2s 22ms/step - loss: 0.0263 - accuracy: 0.9913 - val_loss: 0.3680 - val_accuracy: 0.7778\n",
            "Epoch 169/400\n",
            "72/72 [==============================] - 2s 23ms/step - loss: 0.0602 - accuracy: 0.9774 - val_loss: 0.2958 - val_accuracy: 0.8056\n",
            "Epoch 170/400\n",
            "72/72 [==============================] - 2s 21ms/step - loss: 0.0492 - accuracy: 0.9861 - val_loss: 0.4912 - val_accuracy: 0.8333\n",
            "Epoch 171/400\n",
            "72/72 [==============================] - 2s 22ms/step - loss: 0.0278 - accuracy: 0.9965 - val_loss: 0.3983 - val_accuracy: 0.8333\n",
            "Epoch 172/400\n",
            "72/72 [==============================] - 2s 22ms/step - loss: 0.0288 - accuracy: 0.9905 - val_loss: 0.4580 - val_accuracy: 0.7778\n",
            "Epoch 173/400\n",
            "72/72 [==============================] - 2s 23ms/step - loss: 0.0338 - accuracy: 0.9878 - val_loss: 0.5233 - val_accuracy: 0.8611\n",
            "Epoch 174/400\n",
            "72/72 [==============================] - 2s 23ms/step - loss: 0.0401 - accuracy: 0.9896 - val_loss: 0.5028 - val_accuracy: 0.8056\n",
            "Epoch 175/400\n",
            "72/72 [==============================] - 2s 23ms/step - loss: 0.0194 - accuracy: 0.9957 - val_loss: 0.3961 - val_accuracy: 0.8056\n",
            "Epoch 176/400\n",
            "72/72 [==============================] - 2s 22ms/step - loss: 0.0341 - accuracy: 0.9887 - val_loss: 0.2898 - val_accuracy: 0.8611\n",
            "Epoch 177/400\n",
            "72/72 [==============================] - 2s 22ms/step - loss: 0.0191 - accuracy: 0.9983 - val_loss: 0.3672 - val_accuracy: 0.8611\n",
            "Epoch 178/400\n",
            "72/72 [==============================] - 2s 22ms/step - loss: 0.0178 - accuracy: 0.9957 - val_loss: 0.5301 - val_accuracy: 0.7778\n",
            "Epoch 179/400\n",
            "72/72 [==============================] - 2s 22ms/step - loss: 0.0097 - accuracy: 0.9991 - val_loss: 0.5258 - val_accuracy: 0.8056\n",
            "Epoch 180/400\n",
            "72/72 [==============================] - 2s 22ms/step - loss: 0.0290 - accuracy: 0.9913 - val_loss: 0.7396 - val_accuracy: 0.7222\n",
            "Epoch 181/400\n",
            "72/72 [==============================] - 2s 21ms/step - loss: 0.0291 - accuracy: 0.9948 - val_loss: 0.5711 - val_accuracy: 0.7778\n",
            "Epoch 182/400\n",
            "72/72 [==============================] - 2s 22ms/step - loss: 0.0250 - accuracy: 0.9957 - val_loss: 0.4536 - val_accuracy: 0.8333\n",
            "Epoch 183/400\n",
            "72/72 [==============================] - 2s 22ms/step - loss: 0.0201 - accuracy: 0.9957 - val_loss: 0.4728 - val_accuracy: 0.7778\n",
            "Epoch 184/400\n",
            "72/72 [==============================] - 2s 21ms/step - loss: 0.0336 - accuracy: 0.9905 - val_loss: 0.3378 - val_accuracy: 0.8611\n",
            "Epoch 185/400\n",
            "72/72 [==============================] - 2s 22ms/step - loss: 0.0411 - accuracy: 0.9861 - val_loss: 0.5010 - val_accuracy: 0.8056\n",
            "Epoch 186/400\n",
            "72/72 [==============================] - 2s 22ms/step - loss: 0.0234 - accuracy: 0.9939 - val_loss: 0.5000 - val_accuracy: 0.8056\n",
            "Epoch 187/400\n",
            "72/72 [==============================] - 2s 22ms/step - loss: 0.0211 - accuracy: 0.9939 - val_loss: 0.4662 - val_accuracy: 0.7778\n",
            "Epoch 188/400\n",
            "72/72 [==============================] - 2s 23ms/step - loss: 0.0182 - accuracy: 0.9983 - val_loss: 0.6186 - val_accuracy: 0.8056\n",
            "Epoch 189/400\n",
            "72/72 [==============================] - 2s 21ms/step - loss: 0.0256 - accuracy: 0.9948 - val_loss: 0.2889 - val_accuracy: 0.8333\n",
            "Epoch 190/400\n",
            "72/72 [==============================] - 2s 23ms/step - loss: 0.0267 - accuracy: 0.9922 - val_loss: 0.4782 - val_accuracy: 0.8333\n",
            "Epoch 191/400\n",
            "72/72 [==============================] - 2s 22ms/step - loss: 0.0295 - accuracy: 0.9922 - val_loss: 0.4613 - val_accuracy: 0.8611\n",
            "Epoch 192/400\n",
            "72/72 [==============================] - 2s 22ms/step - loss: 0.0194 - accuracy: 0.9965 - val_loss: 0.3965 - val_accuracy: 0.8333\n",
            "Epoch 193/400\n",
            "72/72 [==============================] - 2s 22ms/step - loss: 0.0259 - accuracy: 0.9887 - val_loss: 0.4025 - val_accuracy: 0.8333\n",
            "Epoch 194/400\n",
            "72/72 [==============================] - 2s 22ms/step - loss: 0.0272 - accuracy: 0.9913 - val_loss: 0.3872 - val_accuracy: 0.8333\n",
            "Epoch 195/400\n",
            "72/72 [==============================] - 2s 22ms/step - loss: 0.0285 - accuracy: 0.9931 - val_loss: 0.4670 - val_accuracy: 0.8056\n",
            "Epoch 196/400\n",
            "72/72 [==============================] - 2s 21ms/step - loss: 0.0240 - accuracy: 0.9922 - val_loss: 0.5733 - val_accuracy: 0.7778\n",
            "Epoch 197/400\n",
            "72/72 [==============================] - 2s 21ms/step - loss: 0.0220 - accuracy: 0.9939 - val_loss: 0.3577 - val_accuracy: 0.8333\n",
            "Epoch 198/400\n",
            "72/72 [==============================] - 2s 23ms/step - loss: 0.0310 - accuracy: 0.9905 - val_loss: 0.6579 - val_accuracy: 0.7500\n",
            "Epoch 199/400\n",
            "72/72 [==============================] - 2s 24ms/step - loss: 0.0323 - accuracy: 0.9887 - val_loss: 0.4500 - val_accuracy: 0.7778\n",
            "Epoch 200/400\n",
            "72/72 [==============================] - 2s 24ms/step - loss: 0.0257 - accuracy: 0.9905 - val_loss: 0.7324 - val_accuracy: 0.7222\n",
            "Epoch 201/400\n",
            "72/72 [==============================] - 2s 25ms/step - loss: 0.0232 - accuracy: 0.9939 - val_loss: 0.5353 - val_accuracy: 0.8056\n",
            "Epoch 202/400\n",
            "72/72 [==============================] - 2s 22ms/step - loss: 0.0184 - accuracy: 0.9948 - val_loss: 0.5673 - val_accuracy: 0.8056\n",
            "Epoch 203/400\n",
            "72/72 [==============================] - 2s 22ms/step - loss: 0.0119 - accuracy: 0.9974 - val_loss: 0.5713 - val_accuracy: 0.8333\n",
            "Epoch 204/400\n",
            "72/72 [==============================] - 2s 22ms/step - loss: 0.0234 - accuracy: 0.9931 - val_loss: 0.4700 - val_accuracy: 0.7778\n",
            "Epoch 205/400\n",
            "72/72 [==============================] - 2s 22ms/step - loss: 0.0142 - accuracy: 0.9957 - val_loss: 0.5388 - val_accuracy: 0.7778\n",
            "Epoch 206/400\n",
            "72/72 [==============================] - 2s 22ms/step - loss: 0.0140 - accuracy: 0.9957 - val_loss: 0.5291 - val_accuracy: 0.8056\n",
            "Epoch 207/400\n",
            "72/72 [==============================] - 2s 23ms/step - loss: 0.0212 - accuracy: 0.9939 - val_loss: 0.3997 - val_accuracy: 0.8333\n",
            "Epoch 208/400\n",
            "72/72 [==============================] - 2s 22ms/step - loss: 0.0238 - accuracy: 0.9931 - val_loss: 0.4225 - val_accuracy: 0.8056\n",
            "Epoch 209/400\n",
            "72/72 [==============================] - 2s 22ms/step - loss: 0.0159 - accuracy: 0.9974 - val_loss: 0.4447 - val_accuracy: 0.8611\n",
            "Epoch 210/400\n",
            "72/72 [==============================] - 2s 22ms/step - loss: 0.0224 - accuracy: 0.9939 - val_loss: 0.8392 - val_accuracy: 0.7500\n",
            "Epoch 211/400\n",
            "72/72 [==============================] - 2s 22ms/step - loss: 0.0376 - accuracy: 0.9852 - val_loss: 0.6482 - val_accuracy: 0.7778\n",
            "Epoch 212/400\n",
            "72/72 [==============================] - 2s 23ms/step - loss: 0.0168 - accuracy: 0.9957 - val_loss: 0.4850 - val_accuracy: 0.8056\n",
            "Epoch 213/400\n",
            "72/72 [==============================] - 2s 22ms/step - loss: 0.0121 - accuracy: 0.9974 - val_loss: 0.4953 - val_accuracy: 0.8333\n",
            "Epoch 214/400\n",
            "72/72 [==============================] - 2s 22ms/step - loss: 0.0266 - accuracy: 0.9931 - val_loss: 0.4265 - val_accuracy: 0.8333\n",
            "Epoch 215/400\n",
            "72/72 [==============================] - 2s 21ms/step - loss: 0.0164 - accuracy: 0.9957 - val_loss: 0.4816 - val_accuracy: 0.7778\n",
            "Epoch 216/400\n",
            "72/72 [==============================] - 2s 22ms/step - loss: 0.0091 - accuracy: 0.9991 - val_loss: 0.4647 - val_accuracy: 0.8056\n",
            "Epoch 217/400\n",
            "72/72 [==============================] - 2s 21ms/step - loss: 0.0147 - accuracy: 0.9948 - val_loss: 0.4373 - val_accuracy: 0.8056\n",
            "Epoch 218/400\n",
            "72/72 [==============================] - 2s 22ms/step - loss: 0.0222 - accuracy: 0.9931 - val_loss: 0.4873 - val_accuracy: 0.8056\n",
            "Epoch 219/400\n",
            "72/72 [==============================] - 2s 22ms/step - loss: 0.0246 - accuracy: 0.9887 - val_loss: 0.7964 - val_accuracy: 0.7222\n",
            "Epoch 220/400\n",
            "72/72 [==============================] - 2s 23ms/step - loss: 0.0277 - accuracy: 0.9913 - val_loss: 0.4826 - val_accuracy: 0.7778\n",
            "Epoch 221/400\n",
            "72/72 [==============================] - 2s 22ms/step - loss: 0.0190 - accuracy: 0.9939 - val_loss: 0.5064 - val_accuracy: 0.8056\n",
            "Epoch 222/400\n",
            "72/72 [==============================] - 2s 21ms/step - loss: 0.0289 - accuracy: 0.9878 - val_loss: 0.6355 - val_accuracy: 0.7500\n",
            "Epoch 223/400\n",
            "72/72 [==============================] - 2s 22ms/step - loss: 0.0218 - accuracy: 0.9948 - val_loss: 0.5130 - val_accuracy: 0.7778\n",
            "Epoch 224/400\n",
            "72/72 [==============================] - 2s 21ms/step - loss: 0.0135 - accuracy: 0.9974 - val_loss: 0.5037 - val_accuracy: 0.8056\n",
            "Epoch 225/400\n",
            "72/72 [==============================] - 2s 22ms/step - loss: 0.0227 - accuracy: 0.9905 - val_loss: 0.6119 - val_accuracy: 0.7778\n",
            "Epoch 226/400\n",
            "72/72 [==============================] - 2s 22ms/step - loss: 0.0121 - accuracy: 0.9974 - val_loss: 0.5926 - val_accuracy: 0.8056\n",
            "Epoch 227/400\n",
            "72/72 [==============================] - 2s 22ms/step - loss: 0.0154 - accuracy: 0.9965 - val_loss: 0.4320 - val_accuracy: 0.8056\n",
            "Epoch 228/400\n",
            "72/72 [==============================] - 2s 22ms/step - loss: 0.0231 - accuracy: 0.9939 - val_loss: 0.4573 - val_accuracy: 0.8333\n",
            "Epoch 229/400\n",
            "72/72 [==============================] - 2s 22ms/step - loss: 0.0226 - accuracy: 0.9922 - val_loss: 0.7391 - val_accuracy: 0.7500\n",
            "Epoch 230/400\n",
            "72/72 [==============================] - 2s 23ms/step - loss: 0.0171 - accuracy: 0.9948 - val_loss: 0.4716 - val_accuracy: 0.8333\n",
            "Epoch 231/400\n",
            "72/72 [==============================] - 2s 25ms/step - loss: 0.0132 - accuracy: 0.9983 - val_loss: 0.5400 - val_accuracy: 0.8056\n",
            "Epoch 232/400\n",
            "72/72 [==============================] - 2s 23ms/step - loss: 0.0103 - accuracy: 0.9983 - val_loss: 0.7086 - val_accuracy: 0.7778\n",
            "Epoch 233/400\n",
            "72/72 [==============================] - 2s 23ms/step - loss: 0.0107 - accuracy: 0.9965 - val_loss: 0.4656 - val_accuracy: 0.8056\n",
            "Epoch 234/400\n",
            "72/72 [==============================] - 2s 22ms/step - loss: 0.0199 - accuracy: 0.9931 - val_loss: 0.6327 - val_accuracy: 0.8056\n",
            "Epoch 235/400\n",
            "72/72 [==============================] - 2s 22ms/step - loss: 0.0237 - accuracy: 0.9913 - val_loss: 0.3733 - val_accuracy: 0.8333\n",
            "Epoch 236/400\n",
            "72/72 [==============================] - 2s 23ms/step - loss: 0.0413 - accuracy: 0.9878 - val_loss: 0.3234 - val_accuracy: 0.8611\n",
            "Epoch 237/400\n",
            "72/72 [==============================] - 2s 23ms/step - loss: 0.0270 - accuracy: 0.9905 - val_loss: 0.6194 - val_accuracy: 0.7500\n",
            "Epoch 238/400\n",
            "72/72 [==============================] - 2s 22ms/step - loss: 0.0267 - accuracy: 0.9905 - val_loss: 0.4943 - val_accuracy: 0.8333\n",
            "Epoch 239/400\n",
            "72/72 [==============================] - 2s 22ms/step - loss: 0.0403 - accuracy: 0.9826 - val_loss: 0.6112 - val_accuracy: 0.7500\n",
            "Epoch 240/400\n",
            "72/72 [==============================] - 2s 23ms/step - loss: 0.0385 - accuracy: 0.9835 - val_loss: 0.3675 - val_accuracy: 0.8056\n",
            "Epoch 241/400\n",
            "72/72 [==============================] - 2s 21ms/step - loss: 0.0168 - accuracy: 0.9948 - val_loss: 0.6098 - val_accuracy: 0.7500\n",
            "Epoch 242/400\n",
            "72/72 [==============================] - 2s 22ms/step - loss: 0.0081 - accuracy: 0.9991 - val_loss: 0.4571 - val_accuracy: 0.8333\n",
            "Epoch 243/400\n",
            "72/72 [==============================] - 2s 22ms/step - loss: 0.0114 - accuracy: 0.9983 - val_loss: 0.6315 - val_accuracy: 0.8056\n",
            "Epoch 244/400\n",
            "72/72 [==============================] - 2s 22ms/step - loss: 0.0077 - accuracy: 0.9991 - val_loss: 0.5090 - val_accuracy: 0.7778\n",
            "Epoch 245/400\n",
            "72/72 [==============================] - 2s 22ms/step - loss: 0.0138 - accuracy: 0.9965 - val_loss: 0.4547 - val_accuracy: 0.8333\n",
            "Epoch 246/400\n",
            "72/72 [==============================] - 2s 21ms/step - loss: 0.0134 - accuracy: 0.9965 - val_loss: 0.4313 - val_accuracy: 0.8333\n",
            "Epoch 247/400\n",
            "72/72 [==============================] - 2s 21ms/step - loss: 0.0099 - accuracy: 0.9983 - val_loss: 0.5455 - val_accuracy: 0.7778\n",
            "Epoch 248/400\n",
            "72/72 [==============================] - 2s 21ms/step - loss: 0.0072 - accuracy: 0.9991 - val_loss: 0.4990 - val_accuracy: 0.8056\n",
            "Epoch 249/400\n",
            "72/72 [==============================] - 2s 22ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.5493 - val_accuracy: 0.7500\n",
            "Epoch 250/400\n",
            "72/72 [==============================] - 2s 22ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.4434 - val_accuracy: 0.8056\n",
            "Epoch 251/400\n",
            "72/72 [==============================] - 2s 21ms/step - loss: 0.0066 - accuracy: 0.9991 - val_loss: 0.6959 - val_accuracy: 0.8056\n",
            "Epoch 252/400\n",
            "72/72 [==============================] - 2s 21ms/step - loss: 0.0164 - accuracy: 0.9948 - val_loss: 0.5725 - val_accuracy: 0.7778\n",
            "Epoch 253/400\n",
            "72/72 [==============================] - 2s 22ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 0.4577 - val_accuracy: 0.7778\n",
            "Epoch 254/400\n",
            "72/72 [==============================] - 2s 22ms/step - loss: 0.0108 - accuracy: 0.9974 - val_loss: 0.4261 - val_accuracy: 0.8056\n",
            "Epoch 255/400\n",
            "72/72 [==============================] - 2s 22ms/step - loss: 0.0127 - accuracy: 0.9965 - val_loss: 0.6439 - val_accuracy: 0.7778\n",
            "Epoch 256/400\n",
            "72/72 [==============================] - 2s 22ms/step - loss: 0.0167 - accuracy: 0.9957 - val_loss: 0.7182 - val_accuracy: 0.8056\n",
            "Epoch 257/400\n",
            "72/72 [==============================] - 2s 22ms/step - loss: 0.0118 - accuracy: 0.9957 - val_loss: 0.6879 - val_accuracy: 0.8056\n",
            "Epoch 258/400\n",
            "72/72 [==============================] - 2s 22ms/step - loss: 0.0095 - accuracy: 0.9974 - val_loss: 0.4798 - val_accuracy: 0.8056\n",
            "Epoch 259/400\n",
            "72/72 [==============================] - 2s 22ms/step - loss: 0.0219 - accuracy: 0.9957 - val_loss: 0.5400 - val_accuracy: 0.7778\n",
            "Epoch 260/400\n",
            "72/72 [==============================] - 2s 22ms/step - loss: 0.0391 - accuracy: 0.9852 - val_loss: 0.4784 - val_accuracy: 0.8056\n",
            "Epoch 261/400\n",
            "72/72 [==============================] - 2s 22ms/step - loss: 0.0421 - accuracy: 0.9844 - val_loss: 0.5137 - val_accuracy: 0.8333\n",
            "Epoch 262/400\n",
            "72/72 [==============================] - 2s 23ms/step - loss: 0.0524 - accuracy: 0.9792 - val_loss: 0.3271 - val_accuracy: 0.8611\n",
            "Epoch 263/400\n",
            "72/72 [==============================] - 2s 23ms/step - loss: 0.0363 - accuracy: 0.9878 - val_loss: 0.3580 - val_accuracy: 0.8611\n",
            "Epoch 264/400\n",
            "72/72 [==============================] - 2s 21ms/step - loss: 0.0352 - accuracy: 0.9861 - val_loss: 0.4055 - val_accuracy: 0.8611\n",
            "Epoch 265/400\n",
            "72/72 [==============================] - 2s 22ms/step - loss: 0.0184 - accuracy: 0.9939 - val_loss: 0.3354 - val_accuracy: 0.8056\n",
            "Epoch 266/400\n",
            "72/72 [==============================] - 2s 22ms/step - loss: 0.0206 - accuracy: 0.9939 - val_loss: 0.3977 - val_accuracy: 0.8611\n",
            "Epoch 267/400\n",
            "72/72 [==============================] - 2s 22ms/step - loss: 0.0073 - accuracy: 0.9991 - val_loss: 0.4998 - val_accuracy: 0.8056\n",
            "Epoch 268/400\n",
            "72/72 [==============================] - 2s 22ms/step - loss: 0.0068 - accuracy: 0.9983 - val_loss: 0.7105 - val_accuracy: 0.7500\n",
            "Epoch 269/400\n",
            "72/72 [==============================] - 2s 23ms/step - loss: 0.0060 - accuracy: 0.9991 - val_loss: 0.4571 - val_accuracy: 0.8611\n",
            "Epoch 270/400\n",
            "72/72 [==============================] - 2s 22ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.4613 - val_accuracy: 0.7778\n",
            "Epoch 271/400\n",
            "72/72 [==============================] - 2s 21ms/step - loss: 0.0189 - accuracy: 0.9948 - val_loss: 0.7834 - val_accuracy: 0.7778\n",
            "Epoch 272/400\n",
            "72/72 [==============================] - 2s 22ms/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 0.4378 - val_accuracy: 0.8611\n",
            "Epoch 273/400\n",
            "72/72 [==============================] - 2s 22ms/step - loss: 0.0044 - accuracy: 0.9991 - val_loss: 0.4424 - val_accuracy: 0.8333\n",
            "Epoch 274/400\n",
            "72/72 [==============================] - 2s 22ms/step - loss: 0.0110 - accuracy: 0.9957 - val_loss: 0.5192 - val_accuracy: 0.8333\n",
            "Epoch 275/400\n",
            "72/72 [==============================] - 2s 21ms/step - loss: 0.0305 - accuracy: 0.9905 - val_loss: 0.6397 - val_accuracy: 0.7222\n",
            "Epoch 276/400\n",
            "72/72 [==============================] - 2s 23ms/step - loss: 0.0142 - accuracy: 0.9974 - val_loss: 0.5150 - val_accuracy: 0.7778\n",
            "Epoch 277/400\n",
            "72/72 [==============================] - 2s 22ms/step - loss: 0.0157 - accuracy: 0.9957 - val_loss: 0.5139 - val_accuracy: 0.7778\n",
            "Epoch 278/400\n",
            "72/72 [==============================] - 2s 22ms/step - loss: 0.0112 - accuracy: 0.9957 - val_loss: 0.5030 - val_accuracy: 0.7778\n",
            "Epoch 279/400\n",
            "72/72 [==============================] - 2s 24ms/step - loss: 0.0128 - accuracy: 0.9965 - val_loss: 0.5161 - val_accuracy: 0.8333\n",
            "Epoch 280/400\n",
            "72/72 [==============================] - 2s 22ms/step - loss: 0.0138 - accuracy: 0.9965 - val_loss: 0.4781 - val_accuracy: 0.8333\n",
            "Epoch 281/400\n",
            "72/72 [==============================] - 2s 22ms/step - loss: 0.0068 - accuracy: 0.9991 - val_loss: 0.5123 - val_accuracy: 0.8056\n",
            "Epoch 282/400\n",
            "72/72 [==============================] - 2s 23ms/step - loss: 0.0125 - accuracy: 0.9974 - val_loss: 0.6227 - val_accuracy: 0.8056\n",
            "Epoch 283/400\n",
            "72/72 [==============================] - 2s 23ms/step - loss: 0.0348 - accuracy: 0.9896 - val_loss: 0.4680 - val_accuracy: 0.7500\n",
            "Epoch 284/400\n",
            "72/72 [==============================] - 2s 22ms/step - loss: 0.0258 - accuracy: 0.9905 - val_loss: 0.4377 - val_accuracy: 0.8056\n",
            "Epoch 285/400\n",
            "72/72 [==============================] - 2s 22ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.4829 - val_accuracy: 0.8056\n",
            "Epoch 286/400\n",
            "72/72 [==============================] - 2s 22ms/step - loss: 0.0218 - accuracy: 0.9922 - val_loss: 0.7049 - val_accuracy: 0.7778\n",
            "Epoch 287/400\n",
            "72/72 [==============================] - 2s 22ms/step - loss: 0.0143 - accuracy: 0.9948 - val_loss: 0.3294 - val_accuracy: 0.8056\n",
            "Epoch 288/400\n",
            "72/72 [==============================] - 2s 22ms/step - loss: 0.0124 - accuracy: 0.9965 - val_loss: 0.4912 - val_accuracy: 0.8056\n",
            "Epoch 289/400\n",
            "72/72 [==============================] - 2s 22ms/step - loss: 0.0112 - accuracy: 0.9965 - val_loss: 0.4129 - val_accuracy: 0.8056\n",
            "Epoch 290/400\n",
            "72/72 [==============================] - 2s 22ms/step - loss: 0.0082 - accuracy: 0.9991 - val_loss: 0.5458 - val_accuracy: 0.7778\n",
            "Epoch 291/400\n",
            "72/72 [==============================] - 2s 22ms/step - loss: 0.0126 - accuracy: 0.9965 - val_loss: 0.5377 - val_accuracy: 0.8056\n",
            "Epoch 292/400\n",
            "72/72 [==============================] - 2s 22ms/step - loss: 0.0111 - accuracy: 0.9957 - val_loss: 0.5324 - val_accuracy: 0.8333\n",
            "Epoch 293/400\n",
            "72/72 [==============================] - 2s 23ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 0.4796 - val_accuracy: 0.8333\n",
            "Epoch 294/400\n",
            "72/72 [==============================] - 2s 22ms/step - loss: 0.0092 - accuracy: 0.9974 - val_loss: 0.7015 - val_accuracy: 0.7778\n",
            "Epoch 295/400\n",
            "72/72 [==============================] - 2s 23ms/step - loss: 0.0081 - accuracy: 0.9983 - val_loss: 0.6032 - val_accuracy: 0.7778\n",
            "Epoch 296/400\n",
            "72/72 [==============================] - 2s 22ms/step - loss: 0.0065 - accuracy: 0.9983 - val_loss: 0.2968 - val_accuracy: 0.8611\n",
            "Epoch 297/400\n",
            "72/72 [==============================] - 2s 23ms/step - loss: 0.0282 - accuracy: 0.9922 - val_loss: 0.6406 - val_accuracy: 0.8333\n",
            "Epoch 298/400\n",
            "72/72 [==============================] - 2s 22ms/step - loss: 0.0106 - accuracy: 0.9974 - val_loss: 0.6555 - val_accuracy: 0.7500\n",
            "Epoch 299/400\n",
            "72/72 [==============================] - 2s 23ms/step - loss: 0.0155 - accuracy: 0.9965 - val_loss: 0.5905 - val_accuracy: 0.7778\n",
            "Epoch 300/400\n",
            "72/72 [==============================] - 2s 22ms/step - loss: 0.0124 - accuracy: 0.9974 - val_loss: 0.4343 - val_accuracy: 0.8333\n",
            "Epoch 301/400\n",
            "72/72 [==============================] - 2s 22ms/step - loss: 0.0079 - accuracy: 0.9974 - val_loss: 0.6071 - val_accuracy: 0.8333\n",
            "Epoch 302/400\n",
            "72/72 [==============================] - 2s 22ms/step - loss: 0.0100 - accuracy: 0.9991 - val_loss: 0.6955 - val_accuracy: 0.7500\n",
            "Epoch 303/400\n",
            "72/72 [==============================] - 2s 22ms/step - loss: 0.0083 - accuracy: 0.9965 - val_loss: 0.5559 - val_accuracy: 0.7778\n",
            "Epoch 304/400\n",
            "72/72 [==============================] - 2s 22ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.5144 - val_accuracy: 0.8056\n",
            "Epoch 305/400\n",
            "72/72 [==============================] - 2s 23ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.4605 - val_accuracy: 0.8056\n",
            "Epoch 306/400\n",
            "72/72 [==============================] - 2s 23ms/step - loss: 0.0044 - accuracy: 0.9991 - val_loss: 0.4889 - val_accuracy: 0.8333\n",
            "Epoch 307/400\n",
            "72/72 [==============================] - 2s 23ms/step - loss: 0.0063 - accuracy: 0.9983 - val_loss: 0.5599 - val_accuracy: 0.8056\n",
            "Epoch 308/400\n",
            "72/72 [==============================] - 2s 23ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.6091 - val_accuracy: 0.7778\n",
            "Epoch 309/400\n",
            "72/72 [==============================] - 2s 22ms/step - loss: 0.0077 - accuracy: 0.9983 - val_loss: 0.3536 - val_accuracy: 0.8333\n",
            "Epoch 310/400\n",
            "72/72 [==============================] - 2s 23ms/step - loss: 0.0081 - accuracy: 0.9965 - val_loss: 0.3532 - val_accuracy: 0.8056\n",
            "Epoch 311/400\n",
            "72/72 [==============================] - 2s 25ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.4736 - val_accuracy: 0.8056\n",
            "Epoch 312/400\n",
            "72/72 [==============================] - 2s 25ms/step - loss: 0.0068 - accuracy: 0.9991 - val_loss: 0.4955 - val_accuracy: 0.8333\n",
            "Epoch 313/400\n",
            "72/72 [==============================] - 2s 24ms/step - loss: 0.0103 - accuracy: 0.9983 - val_loss: 0.7538 - val_accuracy: 0.7778\n",
            "Epoch 314/400\n",
            "72/72 [==============================] - 2s 23ms/step - loss: 0.0298 - accuracy: 0.9870 - val_loss: 0.3938 - val_accuracy: 0.8611\n",
            "Epoch 315/400\n",
            "72/72 [==============================] - 2s 22ms/step - loss: 0.0218 - accuracy: 0.9922 - val_loss: 0.4286 - val_accuracy: 0.7500\n",
            "Epoch 316/400\n",
            "72/72 [==============================] - 2s 24ms/step - loss: 0.0191 - accuracy: 0.9948 - val_loss: 0.6407 - val_accuracy: 0.8056\n",
            "Epoch 317/400\n",
            "72/72 [==============================] - 2s 22ms/step - loss: 0.0187 - accuracy: 0.9948 - val_loss: 0.5820 - val_accuracy: 0.8056\n",
            "Epoch 318/400\n",
            "72/72 [==============================] - 2s 23ms/step - loss: 0.0243 - accuracy: 0.9905 - val_loss: 0.4450 - val_accuracy: 0.8611\n",
            "Epoch 319/400\n",
            "72/72 [==============================] - 2s 22ms/step - loss: 0.0332 - accuracy: 0.9887 - val_loss: 0.5067 - val_accuracy: 0.8056\n",
            "Epoch 320/400\n",
            "72/72 [==============================] - 2s 23ms/step - loss: 0.0291 - accuracy: 0.9931 - val_loss: 0.6002 - val_accuracy: 0.7500\n",
            "Epoch 321/400\n",
            "72/72 [==============================] - 2s 23ms/step - loss: 0.0251 - accuracy: 0.9913 - val_loss: 0.4760 - val_accuracy: 0.7778\n",
            "Epoch 322/400\n",
            "72/72 [==============================] - 2s 25ms/step - loss: 0.0086 - accuracy: 0.9983 - val_loss: 0.3870 - val_accuracy: 0.8611\n",
            "Epoch 323/400\n",
            "72/72 [==============================] - 2s 24ms/step - loss: 0.0111 - accuracy: 0.9974 - val_loss: 0.4463 - val_accuracy: 0.8333\n",
            "Epoch 324/400\n",
            "72/72 [==============================] - 2s 24ms/step - loss: 0.0188 - accuracy: 0.9922 - val_loss: 0.4906 - val_accuracy: 0.8889\n",
            "Epoch 325/400\n",
            "72/72 [==============================] - 2s 25ms/step - loss: 0.0138 - accuracy: 0.9957 - val_loss: 0.5540 - val_accuracy: 0.8056\n",
            "Epoch 326/400\n",
            "72/72 [==============================] - 2s 23ms/step - loss: 0.0128 - accuracy: 0.9983 - val_loss: 0.8915 - val_accuracy: 0.7500\n",
            "Epoch 327/400\n",
            "72/72 [==============================] - 2s 23ms/step - loss: 0.0274 - accuracy: 0.9922 - val_loss: 0.6652 - val_accuracy: 0.8056\n",
            "Epoch 328/400\n",
            "72/72 [==============================] - 2s 24ms/step - loss: 0.0123 - accuracy: 0.9983 - val_loss: 0.5169 - val_accuracy: 0.7778\n",
            "Epoch 329/400\n",
            "72/72 [==============================] - 2s 24ms/step - loss: 0.0186 - accuracy: 0.9957 - val_loss: 0.4952 - val_accuracy: 0.8333\n",
            "Epoch 330/400\n",
            "72/72 [==============================] - 2s 22ms/step - loss: 0.0097 - accuracy: 0.9965 - val_loss: 0.5918 - val_accuracy: 0.8056\n",
            "Epoch 331/400\n",
            "72/72 [==============================] - 2s 23ms/step - loss: 0.0075 - accuracy: 0.9974 - val_loss: 0.5969 - val_accuracy: 0.7778\n",
            "Epoch 332/400\n",
            "72/72 [==============================] - 2s 22ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.6765 - val_accuracy: 0.7500\n",
            "Epoch 333/400\n",
            "72/72 [==============================] - 2s 22ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.6858 - val_accuracy: 0.8333\n",
            "Epoch 334/400\n",
            "72/72 [==============================] - 2s 22ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.5513 - val_accuracy: 0.8333\n",
            "Epoch 335/400\n",
            "72/72 [==============================] - 2s 22ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.5706 - val_accuracy: 0.8056\n",
            "Epoch 336/400\n",
            "72/72 [==============================] - 2s 23ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.6139 - val_accuracy: 0.8333\n",
            "Epoch 337/400\n",
            "72/72 [==============================] - 2s 22ms/step - loss: 0.0038 - accuracy: 0.9991 - val_loss: 0.5962 - val_accuracy: 0.8056\n",
            "Epoch 338/400\n",
            "72/72 [==============================] - 2s 23ms/step - loss: 0.0028 - accuracy: 0.9991 - val_loss: 0.4944 - val_accuracy: 0.8333\n",
            "Epoch 339/400\n",
            "72/72 [==============================] - 2s 22ms/step - loss: 0.0058 - accuracy: 0.9991 - val_loss: 0.6690 - val_accuracy: 0.7500\n",
            "Epoch 340/400\n",
            "72/72 [==============================] - 2s 23ms/step - loss: 0.0223 - accuracy: 0.9931 - val_loss: 0.5351 - val_accuracy: 0.7778\n",
            "Epoch 341/400\n",
            "72/72 [==============================] - 2s 24ms/step - loss: 0.0173 - accuracy: 0.9957 - val_loss: 0.7311 - val_accuracy: 0.8056\n",
            "Epoch 342/400\n",
            "72/72 [==============================] - 2s 23ms/step - loss: 0.0163 - accuracy: 0.9965 - val_loss: 0.4815 - val_accuracy: 0.8056\n",
            "Epoch 343/400\n",
            "72/72 [==============================] - 2s 23ms/step - loss: 0.0152 - accuracy: 0.9957 - val_loss: 0.8016 - val_accuracy: 0.6944\n",
            "Epoch 344/400\n",
            "72/72 [==============================] - 2s 22ms/step - loss: 0.0106 - accuracy: 0.9983 - val_loss: 0.4156 - val_accuracy: 0.8333\n",
            "Epoch 345/400\n",
            "72/72 [==============================] - 2s 24ms/step - loss: 0.0078 - accuracy: 0.9983 - val_loss: 0.4681 - val_accuracy: 0.8056\n",
            "Epoch 346/400\n",
            "72/72 [==============================] - 2s 22ms/step - loss: 0.0073 - accuracy: 0.9991 - val_loss: 0.4600 - val_accuracy: 0.7778\n",
            "Epoch 347/400\n",
            "72/72 [==============================] - 2s 23ms/step - loss: 0.0088 - accuracy: 0.9983 - val_loss: 0.5529 - val_accuracy: 0.7778\n",
            "Epoch 348/400\n",
            "72/72 [==============================] - 2s 22ms/step - loss: 0.0327 - accuracy: 0.9905 - val_loss: 0.4709 - val_accuracy: 0.8333\n",
            "Epoch 349/400\n",
            "72/72 [==============================] - 2s 22ms/step - loss: 0.0305 - accuracy: 0.9905 - val_loss: 0.6701 - val_accuracy: 0.7778\n",
            "Epoch 350/400\n",
            "72/72 [==============================] - 2s 22ms/step - loss: 0.0263 - accuracy: 0.9905 - val_loss: 0.8729 - val_accuracy: 0.7500\n",
            "Epoch 351/400\n",
            "72/72 [==============================] - 2s 22ms/step - loss: 0.0201 - accuracy: 0.9913 - val_loss: 0.6469 - val_accuracy: 0.7778\n",
            "Epoch 352/400\n",
            "72/72 [==============================] - 2s 23ms/step - loss: 0.0063 - accuracy: 0.9991 - val_loss: 0.6355 - val_accuracy: 0.8056\n",
            "Epoch 353/400\n",
            "72/72 [==============================] - 2s 22ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.5605 - val_accuracy: 0.8056\n",
            "Epoch 354/400\n",
            "72/72 [==============================] - 2s 23ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.7130 - val_accuracy: 0.7778\n",
            "Epoch 355/400\n",
            "72/72 [==============================] - 2s 24ms/step - loss: 0.0060 - accuracy: 0.9991 - val_loss: 0.7711 - val_accuracy: 0.7778\n",
            "Epoch 356/400\n",
            "72/72 [==============================] - 2s 24ms/step - loss: 0.0126 - accuracy: 0.9931 - val_loss: 0.5641 - val_accuracy: 0.8056\n",
            "Epoch 357/400\n",
            "72/72 [==============================] - 2s 23ms/step - loss: 0.0154 - accuracy: 0.9948 - val_loss: 0.8200 - val_accuracy: 0.7778\n",
            "Epoch 358/400\n",
            "72/72 [==============================] - 2s 23ms/step - loss: 0.0169 - accuracy: 0.9939 - val_loss: 0.6285 - val_accuracy: 0.8333\n",
            "Epoch 359/400\n",
            "72/72 [==============================] - 2s 23ms/step - loss: 0.0160 - accuracy: 0.9948 - val_loss: 0.4438 - val_accuracy: 0.8333\n",
            "Epoch 360/400\n",
            "72/72 [==============================] - 2s 23ms/step - loss: 0.0059 - accuracy: 0.9991 - val_loss: 0.4428 - val_accuracy: 0.8333\n",
            "Epoch 361/400\n",
            "72/72 [==============================] - 2s 23ms/step - loss: 0.0104 - accuracy: 0.9974 - val_loss: 0.5725 - val_accuracy: 0.8056\n",
            "Epoch 362/400\n",
            "72/72 [==============================] - 2s 22ms/step - loss: 0.0113 - accuracy: 0.9983 - val_loss: 0.4249 - val_accuracy: 0.8333\n",
            "Epoch 363/400\n",
            "72/72 [==============================] - 2s 22ms/step - loss: 0.0074 - accuracy: 0.9974 - val_loss: 0.4184 - val_accuracy: 0.8333\n",
            "Epoch 364/400\n",
            "72/72 [==============================] - 2s 23ms/step - loss: 0.0172 - accuracy: 0.9948 - val_loss: 0.7851 - val_accuracy: 0.7222\n",
            "Epoch 365/400\n",
            "72/72 [==============================] - 2s 23ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.6190 - val_accuracy: 0.8056\n",
            "Epoch 366/400\n",
            "72/72 [==============================] - 2s 23ms/step - loss: 0.0072 - accuracy: 0.9983 - val_loss: 0.5321 - val_accuracy: 0.7778\n",
            "Epoch 367/400\n",
            "72/72 [==============================] - 2s 24ms/step - loss: 0.0173 - accuracy: 0.9931 - val_loss: 0.4979 - val_accuracy: 0.8333\n",
            "Epoch 368/400\n",
            "72/72 [==============================] - 2s 23ms/step - loss: 0.0110 - accuracy: 0.9965 - val_loss: 0.5749 - val_accuracy: 0.7778\n",
            "Epoch 369/400\n",
            "72/72 [==============================] - 2s 23ms/step - loss: 0.0072 - accuracy: 0.9991 - val_loss: 0.5249 - val_accuracy: 0.8056\n",
            "Epoch 370/400\n",
            "72/72 [==============================] - 2s 22ms/step - loss: 0.0226 - accuracy: 0.9922 - val_loss: 0.9819 - val_accuracy: 0.7778\n",
            "Epoch 371/400\n",
            "72/72 [==============================] - 2s 22ms/step - loss: 0.0223 - accuracy: 0.9896 - val_loss: 0.5983 - val_accuracy: 0.8056\n",
            "Epoch 372/400\n",
            "72/72 [==============================] - 2s 24ms/step - loss: 0.0132 - accuracy: 0.9974 - val_loss: 0.5264 - val_accuracy: 0.8056\n",
            "Epoch 373/400\n",
            "72/72 [==============================] - 2s 24ms/step - loss: 0.0073 - accuracy: 0.9974 - val_loss: 0.5730 - val_accuracy: 0.8333\n",
            "Epoch 374/400\n",
            "72/72 [==============================] - 2s 23ms/step - loss: 0.0052 - accuracy: 0.9983 - val_loss: 0.6471 - val_accuracy: 0.8056\n",
            "Epoch 375/400\n",
            "72/72 [==============================] - 2s 22ms/step - loss: 0.0112 - accuracy: 0.9974 - val_loss: 0.5947 - val_accuracy: 0.8333\n",
            "Epoch 376/400\n",
            "72/72 [==============================] - 2s 22ms/step - loss: 0.0093 - accuracy: 0.9965 - val_loss: 0.6658 - val_accuracy: 0.8056\n",
            "Epoch 377/400\n",
            "72/72 [==============================] - 2s 24ms/step - loss: 0.0131 - accuracy: 0.9948 - val_loss: 0.6995 - val_accuracy: 0.7222\n",
            "Epoch 378/400\n",
            "72/72 [==============================] - 2s 23ms/step - loss: 0.0102 - accuracy: 0.9974 - val_loss: 0.6620 - val_accuracy: 0.8056\n",
            "Epoch 379/400\n",
            "72/72 [==============================] - 2s 24ms/step - loss: 0.0068 - accuracy: 0.9983 - val_loss: 0.5760 - val_accuracy: 0.8056\n",
            "Epoch 380/400\n",
            "72/72 [==============================] - 2s 23ms/step - loss: 0.0137 - accuracy: 0.9957 - val_loss: 0.8807 - val_accuracy: 0.7500\n",
            "Epoch 381/400\n",
            "72/72 [==============================] - 2s 23ms/step - loss: 0.0155 - accuracy: 0.9948 - val_loss: 0.9700 - val_accuracy: 0.7500\n",
            "Epoch 382/400\n",
            "72/72 [==============================] - 2s 23ms/step - loss: 0.0119 - accuracy: 0.9983 - val_loss: 0.4363 - val_accuracy: 0.8333\n",
            "Epoch 383/400\n",
            "72/72 [==============================] - 2s 24ms/step - loss: 0.0056 - accuracy: 0.9991 - val_loss: 0.4769 - val_accuracy: 0.7778\n",
            "Epoch 384/400\n",
            "72/72 [==============================] - 2s 23ms/step - loss: 0.0043 - accuracy: 0.9983 - val_loss: 0.3895 - val_accuracy: 0.8333\n",
            "Epoch 385/400\n",
            "72/72 [==============================] - 2s 24ms/step - loss: 0.0064 - accuracy: 0.9983 - val_loss: 0.4363 - val_accuracy: 0.8611\n",
            "Epoch 386/400\n",
            "72/72 [==============================] - 2s 24ms/step - loss: 0.0070 - accuracy: 0.9974 - val_loss: 0.4057 - val_accuracy: 0.8333\n",
            "Epoch 387/400\n",
            "72/72 [==============================] - 2s 24ms/step - loss: 0.0074 - accuracy: 0.9983 - val_loss: 0.5741 - val_accuracy: 0.8611\n",
            "Epoch 388/400\n",
            "72/72 [==============================] - 2s 23ms/step - loss: 0.0048 - accuracy: 0.9983 - val_loss: 0.8227 - val_accuracy: 0.7778\n",
            "Epoch 389/400\n",
            "72/72 [==============================] - 2s 23ms/step - loss: 0.0129 - accuracy: 0.9983 - val_loss: 0.5636 - val_accuracy: 0.8056\n",
            "Epoch 390/400\n",
            "72/72 [==============================] - 2s 24ms/step - loss: 0.0108 - accuracy: 0.9974 - val_loss: 0.7913 - val_accuracy: 0.7222\n",
            "Epoch 391/400\n",
            "72/72 [==============================] - 2s 23ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.7858 - val_accuracy: 0.6944\n",
            "Epoch 392/400\n",
            "72/72 [==============================] - 2s 24ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.5348 - val_accuracy: 0.7778\n",
            "Epoch 393/400\n",
            "72/72 [==============================] - 2s 22ms/step - loss: 0.0074 - accuracy: 0.9974 - val_loss: 0.3876 - val_accuracy: 0.8889\n",
            "Epoch 394/400\n",
            "72/72 [==============================] - 2s 23ms/step - loss: 0.0064 - accuracy: 0.9983 - val_loss: 0.5681 - val_accuracy: 0.8056\n",
            "Epoch 395/400\n",
            "72/72 [==============================] - 2s 23ms/step - loss: 0.0064 - accuracy: 0.9983 - val_loss: 0.7066 - val_accuracy: 0.7778\n",
            "Epoch 396/400\n",
            "72/72 [==============================] - 2s 24ms/step - loss: 0.0042 - accuracy: 0.9983 - val_loss: 0.5103 - val_accuracy: 0.8056\n",
            "Epoch 397/400\n",
            "72/72 [==============================] - 2s 23ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.5468 - val_accuracy: 0.8056\n",
            "Epoch 398/400\n",
            "72/72 [==============================] - 2s 23ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.6052 - val_accuracy: 0.7778\n",
            "Epoch 399/400\n",
            "72/72 [==============================] - 2s 26ms/step - loss: 0.0127 - accuracy: 0.9957 - val_loss: 0.8160 - val_accuracy: 0.7500\n",
            "Epoch 400/400\n",
            "72/72 [==============================] - 2s 23ms/step - loss: 0.0055 - accuracy: 0.9991 - val_loss: 0.4967 - val_accuracy: 0.8056\n"
          ]
        }
      ],
      "source": [
        "cnnhistory=model.fit(x_train, y_train, batch_size=16, epochs=400,validation_data=(x_valid, emo_valid))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EWT6F8K425LT",
        "outputId": "7fc83d06-94ea-44e1-a6a4-9ce6e41b05a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9611566822975874\n"
          ]
        }
      ],
      "source": [
        "ava_acc=np.mean(cnnhistory.history['accuracy']) # numpy assumed imported as np\n",
        "print(ava_acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "3_HGLS8F29Qr",
        "outputId": "9bcb435c-f985-4485-9fae-3006c2444efe"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.plot(cnnhistory.history['loss'])\n",
        "plt.plot(cnnhistory.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'valid'], loc='upper left')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "YlkBpKyX3El2",
        "outputId": "abfea4ba-d3ef-4074-e475-b5220b0225f9"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.plot(cnnhistory.history['accuracy'])\n",
        "plt.plot(cnnhistory.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'valid'], loc='upper left')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jVaxLrTj3Hxc",
        "outputId": "d7d58f9f-3627-4b5f-dec7-4b78dbfabe88"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[9.99999762e-01, 4.02139558e-13, 7.24186119e-13, 2.13038717e-07,\n",
              "        2.13097630e-11, 6.81063790e-18],\n",
              "       [4.64277505e-09, 4.24458951e-01, 5.74484110e-01, 1.04840154e-07,\n",
              "        1.05686008e-03, 6.05665684e-10],\n",
              "       [9.99992847e-01, 2.39948577e-07, 3.07057374e-12, 6.06177855e-06,\n",
              "        8.28732936e-07, 6.39795291e-12],\n",
              "       [7.16699380e-03, 3.03201880e-02, 3.18247676e-01, 7.82211404e-03,\n",
              "        6.36442184e-01, 8.80233813e-07],\n",
              "       [1.10778027e-14, 9.98096287e-01, 2.67979021e-06, 1.90097548e-03,\n",
              "        9.18297438e-09, 3.16892860e-17],\n",
              "       [2.34937936e-08, 6.98978156e-02, 8.06823432e-01, 1.12251109e-05,\n",
              "        1.23267516e-01, 6.21458263e-09],\n",
              "       [6.10921105e-11, 3.34959506e-04, 3.45912543e-09, 9.99664545e-01,\n",
              "        4.68665974e-07, 5.81675101e-16],\n",
              "       [1.88169622e-07, 9.99984622e-01, 7.01072986e-06, 6.89684020e-06,\n",
              "        1.13337842e-06, 2.29247454e-11],\n",
              "       [5.02273963e-07, 5.03921732e-02, 9.46564853e-01, 7.62650045e-04,\n",
              "        2.27985857e-03, 7.33074224e-09],\n",
              "       [9.54597414e-01, 3.92195032e-09, 8.95941765e-10, 4.54024374e-02,\n",
              "        7.64799779e-08, 2.31579968e-12],\n",
              "       [9.18928301e-04, 3.72867875e-10, 1.56369229e-08, 2.87510445e-12,\n",
              "        9.99081016e-01, 1.85688223e-14],\n",
              "       [9.89226034e-10, 3.22345465e-01, 2.58061498e-01, 3.60976685e-07,\n",
              "        4.19592619e-01, 1.07294659e-10],\n",
              "       [5.67508823e-06, 4.49584877e-05, 9.99698043e-01, 5.21949005e-05,\n",
              "        1.99102462e-04, 1.42324319e-09],\n",
              "       [6.37330534e-03, 3.78934294e-03, 3.14473527e-06, 9.88692641e-01,\n",
              "        1.14160706e-03, 7.35730854e-09],\n",
              "       [5.45466086e-04, 5.49611577e-04, 3.76558751e-01, 3.63216677e-04,\n",
              "        6.21982872e-01, 1.26288171e-07],\n",
              "       [9.99974608e-01, 4.87835905e-09, 2.54536104e-07, 2.51074543e-05,\n",
              "        1.11711862e-09, 1.68896429e-12],\n",
              "       [9.29617286e-11, 7.69704158e-08, 5.35937765e-08, 5.71126566e-12,\n",
              "        9.99999881e-01, 1.50063515e-13],\n",
              "       [3.52249073e-04, 3.13423044e-07, 3.26325477e-07, 9.99647021e-01,\n",
              "        1.44841820e-07, 2.97505326e-10],\n",
              "       [9.99997616e-01, 1.02642495e-09, 3.00971487e-13, 5.27788693e-08,\n",
              "        2.34789172e-06, 1.41213782e-13],\n",
              "       [1.53134806e-07, 2.05765449e-04, 3.96302305e-02, 8.54754944e-06,\n",
              "        9.60155308e-01, 8.52680315e-10],\n",
              "       [1.11749294e-07, 8.34593550e-07, 2.65854895e-01, 6.75191529e-07,\n",
              "        7.34143436e-01, 1.27836991e-10],\n",
              "       [1.19181341e-05, 2.11659539e-02, 2.60674092e-03, 6.56360939e-08,\n",
              "        9.76215363e-01, 1.14493046e-08],\n",
              "       [1.36054206e-11, 9.79617238e-02, 9.00875330e-01, 9.92337391e-06,\n",
              "        1.15308946e-03, 5.88110696e-14],\n",
              "       [9.99929309e-01, 1.36073390e-06, 2.91313550e-13, 6.92917456e-05,\n",
              "        1.29373603e-07, 8.36272544e-12],\n",
              "       [2.69992654e-07, 5.89684409e-04, 6.41249400e-03, 5.05676496e-07,\n",
              "        9.92997110e-01, 2.57354582e-08],\n",
              "       [9.99996662e-01, 2.67605627e-09, 1.20095331e-11, 7.53081792e-07,\n",
              "        2.65213248e-06, 2.57065311e-13],\n",
              "       [3.67262203e-08, 1.96641395e-05, 1.41706422e-03, 5.21642960e-06,\n",
              "        9.98557985e-01, 6.35955233e-10],\n",
              "       [2.72492238e-04, 3.96917994e-06, 6.66899145e-01, 2.38571010e-04,\n",
              "        3.32585871e-01, 3.98459088e-09],\n",
              "       [6.08394980e-01, 1.61655387e-03, 3.50472576e-04, 1.75564915e-01,\n",
              "        2.14072987e-01, 7.81017562e-08],\n",
              "       [9.99999762e-01, 1.35865798e-11, 6.98840779e-13, 2.31202620e-07,\n",
              "        1.58173812e-08, 5.65739076e-16],\n",
              "       [7.04958588e-02, 4.57392493e-03, 3.60557903e-03, 6.02455635e-04,\n",
              "        9.20722187e-01, 1.43007262e-09],\n",
              "       [4.14516848e-07, 3.89665189e-09, 5.89331431e-11, 9.99999523e-01,\n",
              "        1.02456876e-09, 6.29336047e-13],\n",
              "       [1.51147733e-10, 4.89481807e-01, 2.30777161e-10, 5.10517716e-01,\n",
              "        4.06148843e-07, 6.50634528e-17],\n",
              "       [4.08298956e-06, 3.31536680e-02, 9.66300786e-01, 3.06090328e-06,\n",
              "        5.38250897e-04, 1.73253423e-09],\n",
              "       [1.71406835e-04, 5.58486954e-06, 3.57227486e-06, 6.99736063e-07,\n",
              "        9.99818742e-01, 6.28645955e-11],\n",
              "       [9.93952248e-03, 1.00165607e-05, 2.86825775e-06, 9.90040839e-01,\n",
              "        6.69837254e-06, 3.83022680e-09]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "#predictions = model.predict_classes(x_testcnn)\n",
        "predictions = model.predict(x_test)\n",
        "predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y01xRIqN3Kv7",
        "outputId": "309437fb-c73e-4ed9-9967-798922f0a4c8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 2, 0, 2, 1, 1, 3, 1, 2, 0, 4, 4, 2, 3, 4, 0, 4, 0, 0, 4, 4, 1,\n",
              "       2, 0, 4, 0, 4, 2, 0, 0, 1, 3, 3, 2, 4, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "emo_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DLhoAcuI3N3Z",
        "outputId": "367dcad1-0074-4a33-d417-2b950167d247"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 2, 0, 2, 1, 1, 3, 1, 2, 0, 4, 4, 2, 3, 4, 0, 4, 0, 0, 4, 4, 1,\n",
              "       2, 0, 4, 0, 4, 2, 0, 0, 1, 3, 3, 2, 4, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "new_Ytest = emo_test.astype(int)\n",
        "new_Ytest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "msg0xsZw3ROh",
        "outputId": "1abe2971-3366-46bc-9ec3-90e9026cc666"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 2, 0, 4, 1, 2, 3, 1, 2, 0, 4, 4, 2, 3, 4, 0, 4, 3, 0, 4, 4, 4,\n",
              "       2, 0, 4, 0, 4, 2, 0, 0, 4, 3, 3, 2, 4, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "preds1=predictions.argmax(axis=1)\n",
        "preds1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-nADWckp3UHg",
        "outputId": "f7056cca-b003-46ba-cdee-458de5f4494a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[9, 0, 0, 2, 0],\n",
              "       [0, 2, 1, 0, 2],\n",
              "       [0, 0, 6, 0, 1],\n",
              "       [0, 0, 0, 4, 0],\n",
              "       [0, 0, 0, 0, 9]])"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "abc = preds1.astype(int).flatten()\n",
        "from sklearn.metrics import confusion_matrix\n",
        "c = confusion_matrix(new_Ytest, abc) \n",
        "c"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2fbTq6qW3UOm",
        "outputId": "59b9c4d6-f6db-4fe9-ca57-69dc09161b1d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 2, 0, 2, 1, 1, 3, 1, 2, 0, 4, 4, 2, 3, 4, 0, 4, 0, 0, 4, 4, 1,\n",
              "       2, 0, 4, 0, 4, 2, 0, 0, 1, 3, 3, 2, 4, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "emo_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vcuBTzA93UQk",
        "outputId": "66daa917-2408-41a5-f703-47f61f54d807"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/graduation project/audio/model/bestloss2/assets\n",
            "MODEL SAVED\n"
          ]
        }
      ],
      "source": [
        "#model.save('/content/drive/My Drive/augmanted_radvass')\n",
        "model.save('/content/drive/My Drive/graduation project/audio/model/bestloss2')\n",
        "print(\"MODEL SAVED\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gleoIwgk3aRm",
        "outputId": "1c5483f9-af16-41e1-9765-13a64fd3b64c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " batch_normalization_6 (Batc  (None, 40, 1)            4         \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " conv1d_8 (Conv1D)           (None, 40, 128)           1664      \n",
            "                                                                 \n",
            " batch_normalization_7 (Batc  (None, 40, 128)          512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_12 (Activation)  (None, 40, 128)           0         \n",
            "                                                                 \n",
            " dropout_8 (Dropout)         (None, 40, 128)           0         \n",
            "                                                                 \n",
            " max_pooling1d_8 (MaxPooling  (None, 8, 128)           0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " conv1d_9 (Conv1D)           (None, 8, 256)            393472    \n",
            "                                                                 \n",
            " batch_normalization_8 (Batc  (None, 8, 256)           1024      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_13 (Activation)  (None, 8, 256)            0         \n",
            "                                                                 \n",
            " dropout_9 (Dropout)         (None, 8, 256)            0         \n",
            "                                                                 \n",
            " max_pooling1d_9 (MaxPooling  (None, 1, 256)           0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " flatten_4 (Flatten)         (None, 256)               0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 6)                 1542      \n",
            "                                                                 \n",
            " activation_14 (Activation)  (None, 6)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 398,218\n",
            "Trainable params: 397,448\n",
            "Non-trainable params: 770\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "#new_model=keras.models.load_model('/content/drive/My Drive/augmanted_radvass')\n",
        "new_model=keras.models.load_model('/content/drive/My Drive/graduation project/audio/model/bestloss2')\n",
        "new_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pufwy7Ia3b12",
        "outputId": "5d7f4243-73aa-4e74-8325-27a74eaeb7dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 8ms/step - loss: 0.8249 - accuracy: 0.8333\n",
            "Restored model, accuracy: 83.33%\n"
          ]
        }
      ],
      "source": [
        "loss, acc = model.evaluate(x_test, emo_test)\n",
        "print(\"Restored model, accuracy: {:5.2f}%\".format(100*acc))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gqYIsrpY3drM",
        "outputId": "63fe654c-c106-4c03-d234-f05661eb2602"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "36/36 [==============================] - 0s 6ms/step - loss: 9.5669e-04 - accuracy: 1.0000\n",
            "Restored model, accuracy: 100.00%\n"
          ]
        }
      ],
      "source": [
        "loss, acc = model.evaluate(x_train, y_train)\n",
        "print(\"Restored model, accuracy: {:5.2f}%\".format(100*acc))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 606
        },
        "id": "biI56TZV3fPV",
        "outputId": "024b3daa-2358-4840-c9fe-2d191c8517ec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.82      0.90        11\n",
            "           1       1.00      0.40      0.57         5\n",
            "           2       0.86      0.86      0.86         7\n",
            "           3       0.67      1.00      0.80         4\n",
            "           4       0.75      1.00      0.86         9\n",
            "\n",
            "    accuracy                           0.83        36\n",
            "   macro avg       0.85      0.82      0.80        36\n",
            "weighted avg       0.87      0.83      0.82        36\n",
            "\n",
            "----accuracy score 83.33333333333334 ----\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-ced4651393a1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m#df_cm = pd.DataFrame(cm)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mclass_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'neutral'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'calm'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'happy'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'sad'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'angry'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'fearful'\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mdf_cm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0msn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheatmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_cm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mannot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfmt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    676\u001b[0m                     \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m                     \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 678\u001b[0;31m                     \u001b[0mtyp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmanager\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    679\u001b[0m                 )\n\u001b[1;32m    680\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36mndarray_to_mgr\u001b[0;34m(values, index, columns, dtype, copy, typ)\u001b[0m\n\u001b[1;32m    322\u001b[0m     )\n\u001b[1;32m    323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m     \u001b[0m_check_values_indices_shape_match\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtyp\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"array\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36m_check_values_indices_shape_match\u001b[0;34m(values, index, columns)\u001b[0m\n\u001b[1;32m    391\u001b[0m         \u001b[0mpassed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m         \u001b[0mimplied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 393\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Shape of passed values is {passed}, indices imply {implied}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Shape of passed values is (5, 5), indices imply (6, 6)"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix,accuracy_score\n",
        "import seaborn as sn\n",
        "\n",
        "print(classification_report(emo_test,abc))\n",
        "\n",
        "acc = float(accuracy_score(emo_test,abc))*100\n",
        "print(\"----accuracy score %s ----\" % acc)\n",
        "\n",
        "cm = confusion_matrix(emo_test,abc)\n",
        "#df_cm = pd.DataFrame(cm)\n",
        "class_names = ['neutral','calm', 'happy','sad','angry', 'fearful' ]\n",
        "df_cm = pd.DataFrame(cm, index=class_names, columns=class_names,)\n",
        "sn.heatmap(df_cm, annot=True, fmt='')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "59mA6uxedOYx"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "_original_augmation_Savee_400_epoch_12_kernal_size_and_bat.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}