{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ramadan adam 0.0002 1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9SRCO-a_AlH5",
        "outputId": "cf78dd6f-2f5d-40a6-b705-e1dc53b36add"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install librosa"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oi8pWV3yBVjO",
        "outputId": "6adae4b5-9daf-4317-ef51-6adbbcea06d8"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.7/dist-packages (0.8.1)\n",
            "Requirement already satisfied: resampy>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from librosa) (0.2.2)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.21.6)\n",
            "Requirement already satisfied: numba>=0.43.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (0.51.2)\n",
            "Requirement already satisfied: audioread>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (2.1.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (21.3)\n",
            "Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.0.2)\n",
            "Requirement already satisfied: soundfile>=0.10.2 in /usr/local/lib/python3.7/dist-packages (from librosa) (0.10.3.post1)\n",
            "Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.6.0)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.4.1)\n",
            "Requirement already satisfied: decorator>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.1.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba>=0.43.0->librosa) (57.4.0)\n",
            "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba>=0.43.0->librosa) (0.34.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->librosa) (3.0.9)\n",
            "Requirement already satisfied: appdirs>=1.3.0 in /usr/local/lib/python3.7/dist-packages (from pooch>=1.0->librosa) (1.4.4)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from pooch>=1.0->librosa) (2.23.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2022.5.18.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (3.0.4)\n",
            "Requirement already satisfied: six>=1.3 in /usr/local/lib/python3.7/dist-packages (from resampy>=0.2.2->librosa) (1.15.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn!=0.19.0,>=0.14.0->librosa) (3.1.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.7/dist-packages (from soundfile>=0.10.2->librosa) (1.15.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.0->soundfile>=0.10.2->librosa) (2.21)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HJjcbxwy46bG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "064b56ad-4a82-43c5-a716-cbae78a34b82"
      },
      "source": [
        "# Orignial Notebook: https://github.com/MITESHPUTHRANNEU/Speech-Emotion-Analyzer/blob/master/final_results_gender_test.ipynb\n",
        "# This notebook author: Reza Chu\n",
        "# Last Editing Date: 31st May 2019\n",
        "\n",
        "## Python\n",
        "import os\n",
        "import random\n",
        "import sys\n",
        "\n",
        "import IPython\n",
        "from IPython.display import Audio\n",
        "from IPython.display import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "## Package\n",
        "import glob \n",
        "import keras\n",
        "import IPython.display as ipd\n",
        "import librosa\n",
        "import librosa.display\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import plotly.graph_objs as go\n",
        "import plotly.offline as py\n",
        "import plotly.tools as tls\n",
        "import seaborn as sns\n",
        "import scipy.io.wavfile\n",
        "import tensorflow as tf\n",
        "py.init_notebook_mode(connected=True)\n",
        "\n",
        "## Keras\n",
        "from keras import regularizers\n",
        "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping\n",
        "from keras.callbacks import  History, ReduceLROnPlateau, CSVLogger\n",
        "from keras.models import Model, Sequential\n",
        "from keras.layers import Dense, Embedding, LSTM\n",
        "from keras.layers import Input, Flatten, Dropout, Activation, BatchNormalization\n",
        "from keras.layers import Conv1D, MaxPooling1D, AveragePooling1D\n",
        "from keras.preprocessing import sequence\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.utils import np_utils\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "## Sklearn\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "## Rest\n",
        "from scipy.fftpack import fft\n",
        "from scipy import signal\n",
        "from scipy.io import wavfile\n",
        "from tqdm import tqdm\n",
        "\n",
        "input_duration=3\n",
        "# % pylab inline"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "        <script type=\"text/javascript\">\n",
              "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
              "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
              "        if (typeof require !== 'undefined') {\n",
              "        require.undef(\"plotly\");\n",
              "        requirejs.config({\n",
              "            paths: {\n",
              "                'plotly': ['https://cdn.plot.ly/plotly-2.8.3.min']\n",
              "            }\n",
              "        });\n",
              "        require(['plotly'], function(Plotly) {\n",
              "            window._Plotly = Plotly;\n",
              "        });\n",
              "        }\n",
              "        </script>\n",
              "        "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#radvass speech and song\n",
        "import time\n",
        "import os\n",
        "import librosa\n",
        "from librosa import display\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "count=0\n",
        "path1 = '/content/drive/MyDrive/RAVDESS_speech'\n",
        "path2 = '/content/drive/MyDrive/RAVDESS_song'\n",
        "\n",
        "lst = []\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "for subdir, dirs, files in os.walk(path2):\n",
        "  print(dirs)\n",
        "  print(subdir)\n",
        "  #print(files)\n",
        "  for file in files:\n",
        "      try:\n",
        "        count +=1\n",
        "        #Load librosa array, obtain mfcss, store the file and the mcss information in a new array\n",
        "        X, sample_rate = librosa.load(os.path.join(subdir,file), res_type='kaiser_fast')\n",
        "        mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T,axis=0) \n",
        "        # The instruction below converts the labels (from 1 to 8) to a series from 0 to 7\n",
        "        # This is because our predictor needs to start from 0 otherwise it will try to predict also 0.\n",
        "        file = int(file[7:8]) - 1 \n",
        "        arr = mfccs, file\n",
        "        lst.append(arr)\n",
        "      # If the file is not valid, skip it\n",
        "      except ValueError:\n",
        "        continue\n",
        "\n",
        "for subdir, dirs, files in os.walk(path1):\n",
        "  print(dirs)\n",
        "  print(subdir)\n",
        " # print(files)\n",
        "  for file in files:\n",
        "      try:\n",
        "        #Load librosa array, obtain mfcss, store the file and the mcss information in a new array\n",
        "        X, sample_rate = librosa.load(os.path.join(subdir,file), res_type='kaiser_fast')\n",
        "        mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T,axis=0) \n",
        "        # The instruction below converts the labels (from 1 to 8) to a series from 0 to 7\n",
        "        # This is because our predictor needs to start from 0 otherwise it will try to predict also 0.\n",
        "        file = int(file[7:8]) - 1 \n",
        "        if(file ==6 or file==7):\n",
        "          continue\n",
        "        count +=1\n",
        "        arr = mfccs, file\n",
        "        lst.append(arr)\n",
        "      # If the file is not valid, skip it\n",
        "      except ValueError:\n",
        "        continue\n",
        "\n",
        "\n",
        "\n",
        "print(\"--- Data loaded. Loading time: %s seconds ---\" % (time.time() - start_time))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IfuyRZl42ccZ",
        "outputId": "14a0de75-6b9d-4dbd-8400-53655dc2d74e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Actor_10', 'Actor_11', 'Actor_13', 'Actor_12', 'Actor_14', 'Actor_15', 'Actor_16', 'Actor_17', 'Actor_18', 'Actor_19', 'Actor_21', 'Actor_22', 'Actor_23', 'Actor_09', 'Actor_24', 'Actor_04', 'Actor_08', 'Actor_03', 'Actor_02', 'Actor_06', 'Actor_05', 'Actor_01', 'Actor_07', 'Actor_20']\n",
            "/content/drive/MyDrive/RAVDESS_song\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_10\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_11\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_13\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_12\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_14\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_15\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_16\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_17\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_18\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_19\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_21\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_22\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_23\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_09\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_24\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_04\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_08\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_03\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_02\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_06\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_05\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_01\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_07\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_20\n",
            "['Actor_05', 'Actor_08', 'Actor_10', 'Actor_04', 'Actor_09', 'Actor_14', 'Actor_12', 'Actor_13', 'Actor_11', 'Actor_06', 'Actor_24', 'Actor_07', 'Actor_23', 'Actor_22', 'Actor_21', 'Actor_20', 'Actor_02', 'Actor_19', 'Actor_18', 'Actor_17', 'Actor_16', 'Actor_15', 'Actor_03', 'Actor_01']\n",
            "/content/drive/MyDrive/RAVDESS_speech\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_05\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_08\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_10\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_04\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_09\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_14\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_12\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_13\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_11\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_06\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_24\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_07\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_23\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_22\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_21\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_20\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_02\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_19\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_18\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_17\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_16\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_15\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_03\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_01\n",
            "--- Data loaded. Loading time: 670.0365371704102 seconds ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "count"
      ],
      "metadata": {
        "id": "Ltlhi25L2AI5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e427ab9-f047-4d67-db4c-a2e9820348ac"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2068"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy.core.fromnumeric import size\n",
        "size(lst)"
      ],
      "metadata": {
        "id": "HMOH7d7mzHB7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e16df90c-a928-435a-a1a6-c9d90043bb93"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/core/fromnumeric.py:3208: VisibleDeprecationWarning:\n",
            "\n",
            "Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4136"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating X and y: zip makes a list of all the first elements, and a list of all the second elements.\n",
        "X, y = zip(*lst)"
      ],
      "metadata": {
        "id": "ocdL7tSTBoMt"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "X = np.asarray(X)\n",
        "y = np.asarray(y)\n",
        "X.shape, y.shape"
      ],
      "metadata": {
        "id": "vHKwUGTbBtnF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c260080-8f2f-4b9c-c31e-cfc3f5e80d65"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((2068, 40), (2068,))"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "id": "2sUCtbfMztE5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "68306598-78d5-460c-f7a1-122fbc218f3d"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2068, 40)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Saving joblib files to not load them again with the loop above\n",
        "\n",
        "# import joblib\n",
        "\n",
        "# X_name = 'x.joblib'\n",
        "# y_name = 'y.joblib'\n",
        "# save_dir = '/content/drive/My Drive/graduation project/audio/paper_code/features'\n",
        "\n",
        "# savedX = joblib.dump(X, os.path.join(save_dir, X_name))\n",
        "# savedy = joblib.dump(y, os.path.join(save_dir, y_name))"
      ],
      "metadata": {
        "id": "UCzic8rlDcuk"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Loading saved models\n",
        "# import joblib\n",
        "# X = joblib.load('/content/drive/My Drive/graduation project/audio/paper_code/features/x.joblib')\n",
        "# y = joblib.load('/content/drive/My Drive/graduation project/audio/paper_code/features/y.joblib')"
      ],
      "metadata": {
        "id": "Q35CN6zDrzg1"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7PSTurzjCo5K",
        "outputId": "edd32da8-7747-4021-b6ee-38fb63e01a1a"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2068, 40)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2,train_size=0.8, random_state=42)\n",
        "X_valid, X_test, y_valid, y_test = train_test_split(X_test,y_test, test_size=0.5,train_size=0.5, random_state=42)"
      ],
      "metadata": {
        "id": "Ai4Fy5cPCiq1"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "x_traincnn = np.expand_dims(X_train, axis=2)\n",
        "x_testcnn = np.expand_dims(X_test, axis=2)\n",
        "X_valid= np.expand_dims(X_valid, axis=2)"
      ],
      "metadata": {
        "id": "tp1Fm5K3CEXu"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_traincnn.shape, x_testcnn.shape , X_valid.shape"
      ],
      "metadata": {
        "id": "RI0MxoIPBws5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33091c07-f795-4b73-a1b3-c6bb54994544"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1654, 40, 1), (207, 40, 1), (207, 40, 1))"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow"
      ],
      "metadata": {
        "id": "goxL4Y3jKICC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74fb0c55-15cf-424f-8618-c07d20c451a6"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (2.8.2+zzzcolab20220527125636)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (14.0.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.0.0)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.21.6)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (4.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.46.3)\n",
            "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.26.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n",
            "Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.5.3)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.17.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow) (57.4.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow) (1.5.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.8.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (3.3.7)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.23.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.4.6)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.35.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.6.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.2.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (4.11.4)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (3.8.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2022.5.18.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (1.24.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (3.2.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keras"
      ],
      "metadata": {
        "id": "EkcmN9UrKSxj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72e616e7-5ded-4def-d1db-f38ef5607aad"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.7/dist-packages (2.8.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from keras.preprocessing import sequence\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from keras.layers import Input, Flatten, Dropout, Activation\n",
        "from keras.layers import Conv1D, MaxPooling1D\n",
        "from keras.models import Model\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras import optimizers\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv1D(128, 8,padding='same', #classifier.add(Convolution2D(64, (3, 3), padding = 'same', input_shape = (128, 128, 3), activation = 'relu'))\n",
        "                 input_shape=(40,1)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(MaxPooling1D(pool_size=(5)))\n",
        "\n",
        "\n",
        "model.add(Conv1D(256,8,padding='same',))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(MaxPooling1D(pool_size=(5)))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(256))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(256))\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "model.add(Dense(6))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "#opt = tf.keras.optimizers.Adam(lr=0.00002)\n",
        "opt = tf.keras.optimizers.RMSprop(lr=0.0001, rho=0.9, epsilon=1e-07, decay=0.0)\n",
        "#opt = tf.keras.optimizers.SGD(lr=0.001, momentum=0.0, decay=0.0, nesterov=False)"
      ],
      "metadata": {
        "id": "g74fXWVAC4Cr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e6235c92-2b7f-40c6-8c36-ce7e5cdadaef"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/rmsprop.py:130: UserWarning:\n",
            "\n",
            "The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H6ukOxAGC_I4",
        "outputId": "79d97057-d7ea-4cf4-ef2e-dd26550ee3d3"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d (Conv1D)             (None, 40, 128)           1152      \n",
            "                                                                 \n",
            " activation (Activation)     (None, 40, 128)           0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 40, 128)           0         \n",
            "                                                                 \n",
            " max_pooling1d (MaxPooling1D  (None, 8, 128)           0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv1d_1 (Conv1D)           (None, 8, 256)            262400    \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 8, 256)            0         \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 8, 256)            0         \n",
            "                                                                 \n",
            " max_pooling1d_1 (MaxPooling  (None, 1, 256)           0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 256)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 256)               65792     \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 256)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 256)               65792     \n",
            "                                                                 \n",
            " activation_3 (Activation)   (None, 256)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 6)                 1542      \n",
            "                                                                 \n",
            " activation_4 (Activation)   (None, 6)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 396,678\n",
            "Trainable params: 396,678\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='sparse_categorical_crossentropy',\n",
        "              optimizer=opt,\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "AbMlLNk4DCBM"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#cnnhistory=model.fit(x_traincnn, y_train, batch_size=16, epochs=700, validation_data=(x_testcnn, y_test))\n",
        "cnnhistory=model.fit(x_traincnn, y_train, batch_size=16, epochs=500 , validation_data=(X_valid, y_valid))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RI1v2AuADFhy",
        "outputId": "5353bb87-4516-4bc5-a38e-00ff8a957a01"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "104/104 [==============================] - 13s 8ms/step - loss: 5.2212 - accuracy: 0.1844 - val_loss: 2.2119 - val_accuracy: 0.2705\n",
            "Epoch 2/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 3.1409 - accuracy: 0.1941 - val_loss: 2.1076 - val_accuracy: 0.0725\n",
            "Epoch 3/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 2.4956 - accuracy: 0.1995 - val_loss: 1.8070 - val_accuracy: 0.1691\n",
            "Epoch 4/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 2.1985 - accuracy: 0.2158 - val_loss: 1.9906 - val_accuracy: 0.2029\n",
            "Epoch 5/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 2.0611 - accuracy: 0.2128 - val_loss: 2.0133 - val_accuracy: 0.0628\n",
            "Epoch 6/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.9938 - accuracy: 0.2116 - val_loss: 1.7838 - val_accuracy: 0.2705\n",
            "Epoch 7/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.8772 - accuracy: 0.2304 - val_loss: 1.7853 - val_accuracy: 0.2415\n",
            "Epoch 8/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.8598 - accuracy: 0.2394 - val_loss: 1.7707 - val_accuracy: 0.2271\n",
            "Epoch 9/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.8505 - accuracy: 0.2346 - val_loss: 1.7711 - val_accuracy: 0.1981\n",
            "Epoch 10/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.8176 - accuracy: 0.2461 - val_loss: 1.6581 - val_accuracy: 0.3092\n",
            "Epoch 11/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.7712 - accuracy: 0.2666 - val_loss: 1.6524 - val_accuracy: 0.3043\n",
            "Epoch 12/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.7374 - accuracy: 0.2642 - val_loss: 1.6977 - val_accuracy: 0.2705\n",
            "Epoch 13/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.7059 - accuracy: 0.2854 - val_loss: 1.5646 - val_accuracy: 0.4541\n",
            "Epoch 14/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.7085 - accuracy: 0.2896 - val_loss: 1.6527 - val_accuracy: 0.2947\n",
            "Epoch 15/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.6850 - accuracy: 0.3108 - val_loss: 1.6677 - val_accuracy: 0.2512\n",
            "Epoch 16/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.6771 - accuracy: 0.2848 - val_loss: 1.6205 - val_accuracy: 0.2995\n",
            "Epoch 17/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.6718 - accuracy: 0.3017 - val_loss: 1.5531 - val_accuracy: 0.3575\n",
            "Epoch 18/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.6292 - accuracy: 0.3241 - val_loss: 1.5425 - val_accuracy: 0.3333\n",
            "Epoch 19/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.6112 - accuracy: 0.3301 - val_loss: 1.5474 - val_accuracy: 0.3430\n",
            "Epoch 20/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.6046 - accuracy: 0.3253 - val_loss: 1.5929 - val_accuracy: 0.2802\n",
            "Epoch 21/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.5964 - accuracy: 0.3489 - val_loss: 1.5218 - val_accuracy: 0.3671\n",
            "Epoch 22/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.5717 - accuracy: 0.3319 - val_loss: 1.5697 - val_accuracy: 0.3237\n",
            "Epoch 23/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.5830 - accuracy: 0.3440 - val_loss: 1.4902 - val_accuracy: 0.4106\n",
            "Epoch 24/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.5294 - accuracy: 0.3652 - val_loss: 1.4502 - val_accuracy: 0.3671\n",
            "Epoch 25/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.5123 - accuracy: 0.3724 - val_loss: 1.4099 - val_accuracy: 0.4010\n",
            "Epoch 26/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.5155 - accuracy: 0.3724 - val_loss: 1.4276 - val_accuracy: 0.3865\n",
            "Epoch 27/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.4810 - accuracy: 0.3827 - val_loss: 1.4667 - val_accuracy: 0.3527\n",
            "Epoch 28/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.4775 - accuracy: 0.3948 - val_loss: 1.4481 - val_accuracy: 0.4493\n",
            "Epoch 29/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.4447 - accuracy: 0.4033 - val_loss: 1.5292 - val_accuracy: 0.4106\n",
            "Epoch 30/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.4479 - accuracy: 0.3942 - val_loss: 1.4652 - val_accuracy: 0.3913\n",
            "Epoch 31/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.4156 - accuracy: 0.4178 - val_loss: 1.4270 - val_accuracy: 0.4251\n",
            "Epoch 32/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.4090 - accuracy: 0.4553 - val_loss: 1.4622 - val_accuracy: 0.4106\n",
            "Epoch 33/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.4019 - accuracy: 0.4317 - val_loss: 1.3165 - val_accuracy: 0.4879\n",
            "Epoch 34/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.3858 - accuracy: 0.4353 - val_loss: 1.2909 - val_accuracy: 0.5121\n",
            "Epoch 35/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.3774 - accuracy: 0.4359 - val_loss: 1.3012 - val_accuracy: 0.5169\n",
            "Epoch 36/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.3573 - accuracy: 0.4510 - val_loss: 1.2660 - val_accuracy: 0.5266\n",
            "Epoch 37/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.3248 - accuracy: 0.4643 - val_loss: 1.2899 - val_accuracy: 0.4928\n",
            "Epoch 38/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.3079 - accuracy: 0.4698 - val_loss: 1.2457 - val_accuracy: 0.5217\n",
            "Epoch 39/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.3022 - accuracy: 0.4740 - val_loss: 1.2727 - val_accuracy: 0.4879\n",
            "Epoch 40/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.2811 - accuracy: 0.4770 - val_loss: 1.2101 - val_accuracy: 0.5507\n",
            "Epoch 41/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.2620 - accuracy: 0.4794 - val_loss: 1.2071 - val_accuracy: 0.5314\n",
            "Epoch 42/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.2409 - accuracy: 0.4867 - val_loss: 1.2894 - val_accuracy: 0.4686\n",
            "Epoch 43/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.2708 - accuracy: 0.4794 - val_loss: 1.2021 - val_accuracy: 0.4976\n",
            "Epoch 44/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.2239 - accuracy: 0.4946 - val_loss: 1.2003 - val_accuracy: 0.5266\n",
            "Epoch 45/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.2398 - accuracy: 0.4940 - val_loss: 1.1598 - val_accuracy: 0.5797\n",
            "Epoch 46/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.2160 - accuracy: 0.5085 - val_loss: 1.2527 - val_accuracy: 0.4058\n",
            "Epoch 47/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.2044 - accuracy: 0.5230 - val_loss: 1.1512 - val_accuracy: 0.5217\n",
            "Epoch 48/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.1910 - accuracy: 0.5121 - val_loss: 1.0853 - val_accuracy: 0.5845\n",
            "Epoch 49/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.1655 - accuracy: 0.5127 - val_loss: 1.1174 - val_accuracy: 0.5604\n",
            "Epoch 50/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.1730 - accuracy: 0.5103 - val_loss: 1.1197 - val_accuracy: 0.5652\n",
            "Epoch 51/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.1677 - accuracy: 0.5103 - val_loss: 1.0536 - val_accuracy: 0.5942\n",
            "Epoch 52/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.1403 - accuracy: 0.5526 - val_loss: 1.0615 - val_accuracy: 0.6329\n",
            "Epoch 53/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.1394 - accuracy: 0.5411 - val_loss: 1.0744 - val_accuracy: 0.5652\n",
            "Epoch 54/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.1503 - accuracy: 0.5284 - val_loss: 1.0560 - val_accuracy: 0.6135\n",
            "Epoch 55/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0926 - accuracy: 0.5478 - val_loss: 1.0481 - val_accuracy: 0.5990\n",
            "Epoch 56/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.1097 - accuracy: 0.5441 - val_loss: 1.0991 - val_accuracy: 0.5942\n",
            "Epoch 57/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.1025 - accuracy: 0.5447 - val_loss: 1.0830 - val_accuracy: 0.5459\n",
            "Epoch 58/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.1167 - accuracy: 0.5333 - val_loss: 1.0467 - val_accuracy: 0.5507\n",
            "Epoch 59/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0912 - accuracy: 0.5580 - val_loss: 1.0244 - val_accuracy: 0.6087\n",
            "Epoch 60/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0572 - accuracy: 0.5677 - val_loss: 1.0539 - val_accuracy: 0.5507\n",
            "Epoch 61/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0742 - accuracy: 0.5659 - val_loss: 1.0077 - val_accuracy: 0.6473\n",
            "Epoch 62/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0661 - accuracy: 0.5750 - val_loss: 1.0777 - val_accuracy: 0.5556\n",
            "Epoch 63/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0661 - accuracy: 0.5780 - val_loss: 1.0026 - val_accuracy: 0.6329\n",
            "Epoch 64/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0563 - accuracy: 0.5774 - val_loss: 1.0150 - val_accuracy: 0.6280\n",
            "Epoch 65/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0420 - accuracy: 0.5840 - val_loss: 1.0141 - val_accuracy: 0.6135\n",
            "Epoch 66/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0284 - accuracy: 0.5967 - val_loss: 1.0078 - val_accuracy: 0.6087\n",
            "Epoch 67/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0294 - accuracy: 0.5816 - val_loss: 0.9974 - val_accuracy: 0.5845\n",
            "Epoch 68/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9986 - accuracy: 0.6052 - val_loss: 0.9640 - val_accuracy: 0.6087\n",
            "Epoch 69/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0020 - accuracy: 0.6106 - val_loss: 1.0175 - val_accuracy: 0.6039\n",
            "Epoch 70/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9943 - accuracy: 0.5937 - val_loss: 1.0724 - val_accuracy: 0.5556\n",
            "Epoch 71/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9819 - accuracy: 0.6004 - val_loss: 0.9619 - val_accuracy: 0.5990\n",
            "Epoch 72/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9798 - accuracy: 0.5961 - val_loss: 0.9242 - val_accuracy: 0.6425\n",
            "Epoch 73/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9666 - accuracy: 0.6058 - val_loss: 0.9622 - val_accuracy: 0.6184\n",
            "Epoch 74/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9725 - accuracy: 0.6125 - val_loss: 0.9591 - val_accuracy: 0.5942\n",
            "Epoch 75/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9665 - accuracy: 0.6082 - val_loss: 0.9408 - val_accuracy: 0.6232\n",
            "Epoch 76/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9592 - accuracy: 0.6197 - val_loss: 0.9346 - val_accuracy: 0.6087\n",
            "Epoch 77/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9501 - accuracy: 0.6131 - val_loss: 0.9448 - val_accuracy: 0.6425\n",
            "Epoch 78/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9161 - accuracy: 0.6366 - val_loss: 0.9300 - val_accuracy: 0.6135\n",
            "Epoch 79/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9248 - accuracy: 0.6336 - val_loss: 0.9168 - val_accuracy: 0.6522\n",
            "Epoch 80/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9408 - accuracy: 0.6088 - val_loss: 0.9998 - val_accuracy: 0.6377\n",
            "Epoch 81/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9109 - accuracy: 0.6342 - val_loss: 0.9921 - val_accuracy: 0.5845\n",
            "Epoch 82/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9206 - accuracy: 0.6306 - val_loss: 0.9313 - val_accuracy: 0.6570\n",
            "Epoch 83/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9043 - accuracy: 0.6258 - val_loss: 0.9461 - val_accuracy: 0.6377\n",
            "Epoch 84/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9059 - accuracy: 0.6330 - val_loss: 0.8726 - val_accuracy: 0.6570\n",
            "Epoch 85/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8833 - accuracy: 0.6385 - val_loss: 0.9227 - val_accuracy: 0.6425\n",
            "Epoch 86/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8742 - accuracy: 0.6427 - val_loss: 0.9549 - val_accuracy: 0.6135\n",
            "Epoch 87/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8915 - accuracy: 0.6391 - val_loss: 0.9120 - val_accuracy: 0.6522\n",
            "Epoch 88/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8842 - accuracy: 0.6457 - val_loss: 0.8713 - val_accuracy: 0.6763\n",
            "Epoch 89/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8688 - accuracy: 0.6451 - val_loss: 0.9688 - val_accuracy: 0.6425\n",
            "Epoch 90/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8509 - accuracy: 0.6590 - val_loss: 0.9118 - val_accuracy: 0.6425\n",
            "Epoch 91/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8406 - accuracy: 0.6614 - val_loss: 0.9328 - val_accuracy: 0.6473\n",
            "Epoch 92/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8581 - accuracy: 0.6602 - val_loss: 0.9205 - val_accuracy: 0.6425\n",
            "Epoch 93/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8589 - accuracy: 0.6560 - val_loss: 0.9229 - val_accuracy: 0.6377\n",
            "Epoch 94/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8484 - accuracy: 0.6711 - val_loss: 0.8996 - val_accuracy: 0.6280\n",
            "Epoch 95/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8501 - accuracy: 0.6651 - val_loss: 0.9137 - val_accuracy: 0.6329\n",
            "Epoch 96/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8271 - accuracy: 0.6741 - val_loss: 0.8812 - val_accuracy: 0.6957\n",
            "Epoch 97/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8369 - accuracy: 0.6723 - val_loss: 0.8657 - val_accuracy: 0.6377\n",
            "Epoch 98/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8391 - accuracy: 0.6711 - val_loss: 0.8788 - val_accuracy: 0.6860\n",
            "Epoch 99/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8243 - accuracy: 0.6632 - val_loss: 0.8923 - val_accuracy: 0.6570\n",
            "Epoch 100/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8116 - accuracy: 0.6693 - val_loss: 0.9477 - val_accuracy: 0.5700\n",
            "Epoch 101/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8047 - accuracy: 0.6886 - val_loss: 0.9132 - val_accuracy: 0.6280\n",
            "Epoch 102/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8070 - accuracy: 0.6759 - val_loss: 0.8712 - val_accuracy: 0.6425\n",
            "Epoch 103/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8081 - accuracy: 0.6844 - val_loss: 0.8623 - val_accuracy: 0.6329\n",
            "Epoch 104/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8135 - accuracy: 0.6784 - val_loss: 0.8431 - val_accuracy: 0.6860\n",
            "Epoch 105/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8075 - accuracy: 0.6892 - val_loss: 0.8497 - val_accuracy: 0.6473\n",
            "Epoch 106/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7831 - accuracy: 0.6911 - val_loss: 0.8957 - val_accuracy: 0.6618\n",
            "Epoch 107/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7663 - accuracy: 0.6904 - val_loss: 0.8182 - val_accuracy: 0.6860\n",
            "Epoch 108/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7672 - accuracy: 0.6953 - val_loss: 0.8538 - val_accuracy: 0.6667\n",
            "Epoch 109/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7653 - accuracy: 0.6953 - val_loss: 0.8645 - val_accuracy: 0.6377\n",
            "Epoch 110/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7629 - accuracy: 0.6977 - val_loss: 0.8642 - val_accuracy: 0.6280\n",
            "Epoch 111/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7533 - accuracy: 0.7044 - val_loss: 0.8561 - val_accuracy: 0.6425\n",
            "Epoch 112/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7550 - accuracy: 0.6995 - val_loss: 0.8573 - val_accuracy: 0.6377\n",
            "Epoch 113/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7567 - accuracy: 0.6983 - val_loss: 0.8726 - val_accuracy: 0.6280\n",
            "Epoch 114/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7736 - accuracy: 0.6886 - val_loss: 0.8727 - val_accuracy: 0.6667\n",
            "Epoch 115/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7562 - accuracy: 0.6880 - val_loss: 0.8862 - val_accuracy: 0.6522\n",
            "Epoch 116/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7158 - accuracy: 0.7098 - val_loss: 0.8313 - val_accuracy: 0.6763\n",
            "Epoch 117/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7210 - accuracy: 0.7213 - val_loss: 0.8101 - val_accuracy: 0.6425\n",
            "Epoch 118/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7297 - accuracy: 0.7056 - val_loss: 0.8986 - val_accuracy: 0.6232\n",
            "Epoch 119/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7253 - accuracy: 0.7134 - val_loss: 0.8245 - val_accuracy: 0.6763\n",
            "Epoch 120/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7186 - accuracy: 0.7044 - val_loss: 0.8687 - val_accuracy: 0.6329\n",
            "Epoch 121/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7377 - accuracy: 0.7104 - val_loss: 0.8280 - val_accuracy: 0.6715\n",
            "Epoch 122/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7206 - accuracy: 0.7231 - val_loss: 0.8153 - val_accuracy: 0.6908\n",
            "Epoch 123/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7111 - accuracy: 0.7304 - val_loss: 0.7892 - val_accuracy: 0.6908\n",
            "Epoch 124/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7210 - accuracy: 0.7031 - val_loss: 0.7982 - val_accuracy: 0.6618\n",
            "Epoch 125/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6856 - accuracy: 0.7291 - val_loss: 0.7839 - val_accuracy: 0.7005\n",
            "Epoch 126/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7055 - accuracy: 0.7152 - val_loss: 0.8333 - val_accuracy: 0.6957\n",
            "Epoch 127/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7029 - accuracy: 0.7279 - val_loss: 0.7854 - val_accuracy: 0.6812\n",
            "Epoch 128/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7082 - accuracy: 0.7164 - val_loss: 0.7788 - val_accuracy: 0.7150\n",
            "Epoch 129/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6880 - accuracy: 0.7358 - val_loss: 0.7900 - val_accuracy: 0.6715\n",
            "Epoch 130/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6691 - accuracy: 0.7455 - val_loss: 0.7902 - val_accuracy: 0.6812\n",
            "Epoch 131/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6784 - accuracy: 0.7358 - val_loss: 0.7986 - val_accuracy: 0.6618\n",
            "Epoch 132/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6581 - accuracy: 0.7358 - val_loss: 0.7968 - val_accuracy: 0.6957\n",
            "Epoch 133/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6709 - accuracy: 0.7352 - val_loss: 0.8303 - val_accuracy: 0.6425\n",
            "Epoch 134/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6599 - accuracy: 0.7364 - val_loss: 0.7614 - val_accuracy: 0.7053\n",
            "Epoch 135/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6830 - accuracy: 0.7304 - val_loss: 0.7656 - val_accuracy: 0.7005\n",
            "Epoch 136/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6734 - accuracy: 0.7437 - val_loss: 0.7559 - val_accuracy: 0.6908\n",
            "Epoch 137/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6583 - accuracy: 0.7406 - val_loss: 0.7753 - val_accuracy: 0.6957\n",
            "Epoch 138/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6505 - accuracy: 0.7424 - val_loss: 0.7731 - val_accuracy: 0.6812\n",
            "Epoch 139/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6380 - accuracy: 0.7509 - val_loss: 0.7689 - val_accuracy: 0.7101\n",
            "Epoch 140/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6388 - accuracy: 0.7545 - val_loss: 0.8278 - val_accuracy: 0.6522\n",
            "Epoch 141/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6587 - accuracy: 0.7455 - val_loss: 0.7510 - val_accuracy: 0.7198\n",
            "Epoch 142/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6490 - accuracy: 0.7430 - val_loss: 0.7469 - val_accuracy: 0.7150\n",
            "Epoch 143/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6419 - accuracy: 0.7388 - val_loss: 0.7680 - val_accuracy: 0.7101\n",
            "Epoch 144/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6514 - accuracy: 0.7406 - val_loss: 0.7453 - val_accuracy: 0.7150\n",
            "Epoch 145/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6412 - accuracy: 0.7479 - val_loss: 0.7382 - val_accuracy: 0.7198\n",
            "Epoch 146/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6340 - accuracy: 0.7551 - val_loss: 0.7811 - val_accuracy: 0.6667\n",
            "Epoch 147/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6399 - accuracy: 0.7515 - val_loss: 0.7567 - val_accuracy: 0.7101\n",
            "Epoch 148/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6426 - accuracy: 0.7412 - val_loss: 0.7599 - val_accuracy: 0.7198\n",
            "Epoch 149/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6445 - accuracy: 0.7412 - val_loss: 0.7442 - val_accuracy: 0.7246\n",
            "Epoch 150/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6200 - accuracy: 0.7582 - val_loss: 0.7994 - val_accuracy: 0.6908\n",
            "Epoch 151/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6042 - accuracy: 0.7624 - val_loss: 0.7340 - val_accuracy: 0.7150\n",
            "Epoch 152/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6173 - accuracy: 0.7606 - val_loss: 0.7785 - val_accuracy: 0.6908\n",
            "Epoch 153/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6062 - accuracy: 0.7606 - val_loss: 0.7657 - val_accuracy: 0.7005\n",
            "Epoch 154/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6046 - accuracy: 0.7642 - val_loss: 0.7226 - val_accuracy: 0.6957\n",
            "Epoch 155/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6042 - accuracy: 0.7684 - val_loss: 0.7172 - val_accuracy: 0.7101\n",
            "Epoch 156/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5861 - accuracy: 0.7654 - val_loss: 0.7468 - val_accuracy: 0.6715\n",
            "Epoch 157/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5868 - accuracy: 0.7709 - val_loss: 0.7428 - val_accuracy: 0.7101\n",
            "Epoch 158/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5981 - accuracy: 0.7654 - val_loss: 0.7301 - val_accuracy: 0.7198\n",
            "Epoch 159/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5715 - accuracy: 0.7799 - val_loss: 0.7802 - val_accuracy: 0.7005\n",
            "Epoch 160/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6105 - accuracy: 0.7642 - val_loss: 0.7449 - val_accuracy: 0.7005\n",
            "Epoch 161/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5732 - accuracy: 0.7751 - val_loss: 0.7367 - val_accuracy: 0.7005\n",
            "Epoch 162/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5861 - accuracy: 0.7715 - val_loss: 0.7631 - val_accuracy: 0.6618\n",
            "Epoch 163/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5674 - accuracy: 0.7775 - val_loss: 0.7016 - val_accuracy: 0.7536\n",
            "Epoch 164/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5658 - accuracy: 0.7975 - val_loss: 0.7150 - val_accuracy: 0.7440\n",
            "Epoch 165/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5682 - accuracy: 0.7763 - val_loss: 0.7348 - val_accuracy: 0.7198\n",
            "Epoch 166/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5595 - accuracy: 0.7830 - val_loss: 0.7337 - val_accuracy: 0.6860\n",
            "Epoch 167/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5820 - accuracy: 0.7733 - val_loss: 0.7114 - val_accuracy: 0.7295\n",
            "Epoch 168/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5366 - accuracy: 0.7926 - val_loss: 0.7342 - val_accuracy: 0.7005\n",
            "Epoch 169/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5645 - accuracy: 0.7830 - val_loss: 0.7259 - val_accuracy: 0.7295\n",
            "Epoch 170/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5292 - accuracy: 0.7963 - val_loss: 0.7655 - val_accuracy: 0.7391\n",
            "Epoch 171/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5447 - accuracy: 0.7811 - val_loss: 0.7651 - val_accuracy: 0.7053\n",
            "Epoch 172/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5310 - accuracy: 0.7969 - val_loss: 0.7354 - val_accuracy: 0.7053\n",
            "Epoch 173/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5601 - accuracy: 0.7836 - val_loss: 0.7262 - val_accuracy: 0.7150\n",
            "Epoch 174/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5370 - accuracy: 0.7890 - val_loss: 0.7084 - val_accuracy: 0.7150\n",
            "Epoch 175/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5369 - accuracy: 0.7926 - val_loss: 0.7345 - val_accuracy: 0.7150\n",
            "Epoch 176/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5335 - accuracy: 0.7944 - val_loss: 0.7185 - val_accuracy: 0.7101\n",
            "Epoch 177/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5520 - accuracy: 0.7823 - val_loss: 0.7718 - val_accuracy: 0.7053\n",
            "Epoch 178/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5244 - accuracy: 0.8029 - val_loss: 0.7311 - val_accuracy: 0.6957\n",
            "Epoch 179/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5120 - accuracy: 0.7963 - val_loss: 0.7368 - val_accuracy: 0.7005\n",
            "Epoch 180/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5290 - accuracy: 0.7878 - val_loss: 0.6749 - val_accuracy: 0.7343\n",
            "Epoch 181/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5016 - accuracy: 0.8017 - val_loss: 0.7048 - val_accuracy: 0.7343\n",
            "Epoch 182/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5259 - accuracy: 0.7902 - val_loss: 0.7330 - val_accuracy: 0.7150\n",
            "Epoch 183/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5150 - accuracy: 0.8017 - val_loss: 0.6959 - val_accuracy: 0.7246\n",
            "Epoch 184/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5161 - accuracy: 0.8041 - val_loss: 0.7325 - val_accuracy: 0.7198\n",
            "Epoch 185/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5073 - accuracy: 0.8047 - val_loss: 0.7566 - val_accuracy: 0.7005\n",
            "Epoch 186/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4936 - accuracy: 0.8126 - val_loss: 0.7004 - val_accuracy: 0.7246\n",
            "Epoch 187/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4930 - accuracy: 0.8071 - val_loss: 0.7146 - val_accuracy: 0.7343\n",
            "Epoch 188/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4807 - accuracy: 0.8083 - val_loss: 0.6957 - val_accuracy: 0.7391\n",
            "Epoch 189/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5049 - accuracy: 0.8011 - val_loss: 0.6987 - val_accuracy: 0.7101\n",
            "Epoch 190/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4891 - accuracy: 0.8150 - val_loss: 0.7087 - val_accuracy: 0.7053\n",
            "Epoch 191/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4978 - accuracy: 0.8120 - val_loss: 0.7278 - val_accuracy: 0.7391\n",
            "Epoch 192/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5152 - accuracy: 0.8053 - val_loss: 0.7167 - val_accuracy: 0.7440\n",
            "Epoch 193/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5077 - accuracy: 0.8065 - val_loss: 0.7129 - val_accuracy: 0.7246\n",
            "Epoch 194/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.4896 - accuracy: 0.8168 - val_loss: 0.7233 - val_accuracy: 0.7198\n",
            "Epoch 195/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4917 - accuracy: 0.8071 - val_loss: 0.6789 - val_accuracy: 0.7440\n",
            "Epoch 196/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5059 - accuracy: 0.8017 - val_loss: 0.7040 - val_accuracy: 0.7246\n",
            "Epoch 197/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4854 - accuracy: 0.8089 - val_loss: 0.6679 - val_accuracy: 0.7343\n",
            "Epoch 198/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4788 - accuracy: 0.8108 - val_loss: 0.6767 - val_accuracy: 0.7198\n",
            "Epoch 199/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4678 - accuracy: 0.8247 - val_loss: 0.7225 - val_accuracy: 0.7440\n",
            "Epoch 200/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4719 - accuracy: 0.8259 - val_loss: 0.7783 - val_accuracy: 0.6860\n",
            "Epoch 201/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4804 - accuracy: 0.8144 - val_loss: 0.7071 - val_accuracy: 0.7391\n",
            "Epoch 202/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4638 - accuracy: 0.8289 - val_loss: 0.7210 - val_accuracy: 0.7488\n",
            "Epoch 203/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.4813 - accuracy: 0.8102 - val_loss: 0.6691 - val_accuracy: 0.7536\n",
            "Epoch 204/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4775 - accuracy: 0.8150 - val_loss: 0.7192 - val_accuracy: 0.7246\n",
            "Epoch 205/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4476 - accuracy: 0.8295 - val_loss: 0.6746 - val_accuracy: 0.7391\n",
            "Epoch 206/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4643 - accuracy: 0.8307 - val_loss: 0.6832 - val_accuracy: 0.7246\n",
            "Epoch 207/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4409 - accuracy: 0.8356 - val_loss: 0.6984 - val_accuracy: 0.7536\n",
            "Epoch 208/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.4502 - accuracy: 0.8204 - val_loss: 0.6707 - val_accuracy: 0.7536\n",
            "Epoch 209/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4511 - accuracy: 0.8229 - val_loss: 0.6677 - val_accuracy: 0.7440\n",
            "Epoch 210/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4588 - accuracy: 0.8150 - val_loss: 0.6886 - val_accuracy: 0.7198\n",
            "Epoch 211/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4491 - accuracy: 0.8186 - val_loss: 0.6725 - val_accuracy: 0.7391\n",
            "Epoch 212/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4566 - accuracy: 0.8295 - val_loss: 0.6578 - val_accuracy: 0.7488\n",
            "Epoch 213/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4443 - accuracy: 0.8277 - val_loss: 0.6807 - val_accuracy: 0.7536\n",
            "Epoch 214/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4265 - accuracy: 0.8271 - val_loss: 0.6406 - val_accuracy: 0.7778\n",
            "Epoch 215/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4370 - accuracy: 0.8374 - val_loss: 0.7076 - val_accuracy: 0.7053\n",
            "Epoch 216/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4413 - accuracy: 0.8362 - val_loss: 0.7173 - val_accuracy: 0.7150\n",
            "Epoch 217/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4521 - accuracy: 0.8374 - val_loss: 0.7049 - val_accuracy: 0.7246\n",
            "Epoch 218/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4164 - accuracy: 0.8349 - val_loss: 0.6438 - val_accuracy: 0.7488\n",
            "Epoch 219/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4380 - accuracy: 0.8307 - val_loss: 0.6611 - val_accuracy: 0.7585\n",
            "Epoch 220/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4429 - accuracy: 0.8307 - val_loss: 0.7154 - val_accuracy: 0.7488\n",
            "Epoch 221/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4287 - accuracy: 0.8307 - val_loss: 0.7554 - val_accuracy: 0.7150\n",
            "Epoch 222/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4422 - accuracy: 0.8380 - val_loss: 0.6647 - val_accuracy: 0.7536\n",
            "Epoch 223/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4473 - accuracy: 0.8277 - val_loss: 0.6801 - val_accuracy: 0.7536\n",
            "Epoch 224/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4088 - accuracy: 0.8325 - val_loss: 0.6661 - val_accuracy: 0.7681\n",
            "Epoch 225/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3950 - accuracy: 0.8482 - val_loss: 0.6310 - val_accuracy: 0.7681\n",
            "Epoch 226/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4404 - accuracy: 0.8470 - val_loss: 0.6938 - val_accuracy: 0.7005\n",
            "Epoch 227/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4277 - accuracy: 0.8428 - val_loss: 0.7401 - val_accuracy: 0.7005\n",
            "Epoch 228/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4045 - accuracy: 0.8428 - val_loss: 0.6474 - val_accuracy: 0.7681\n",
            "Epoch 229/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4237 - accuracy: 0.8325 - val_loss: 0.6984 - val_accuracy: 0.7391\n",
            "Epoch 230/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3936 - accuracy: 0.8555 - val_loss: 0.7835 - val_accuracy: 0.7295\n",
            "Epoch 231/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3936 - accuracy: 0.8567 - val_loss: 0.7052 - val_accuracy: 0.7295\n",
            "Epoch 232/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3854 - accuracy: 0.8573 - val_loss: 0.6852 - val_accuracy: 0.7633\n",
            "Epoch 233/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3984 - accuracy: 0.8392 - val_loss: 0.6979 - val_accuracy: 0.7198\n",
            "Epoch 234/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3781 - accuracy: 0.8622 - val_loss: 0.6774 - val_accuracy: 0.7633\n",
            "Epoch 235/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4032 - accuracy: 0.8519 - val_loss: 0.6618 - val_accuracy: 0.7681\n",
            "Epoch 236/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3955 - accuracy: 0.8470 - val_loss: 0.6252 - val_accuracy: 0.7681\n",
            "Epoch 237/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3912 - accuracy: 0.8615 - val_loss: 0.6808 - val_accuracy: 0.7440\n",
            "Epoch 238/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3762 - accuracy: 0.8543 - val_loss: 0.6858 - val_accuracy: 0.7633\n",
            "Epoch 239/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3731 - accuracy: 0.8603 - val_loss: 0.6594 - val_accuracy: 0.7488\n",
            "Epoch 240/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3753 - accuracy: 0.8561 - val_loss: 0.6767 - val_accuracy: 0.7295\n",
            "Epoch 241/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3768 - accuracy: 0.8603 - val_loss: 0.6580 - val_accuracy: 0.7681\n",
            "Epoch 242/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3902 - accuracy: 0.8537 - val_loss: 0.7109 - val_accuracy: 0.7295\n",
            "Epoch 243/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4131 - accuracy: 0.8452 - val_loss: 0.6929 - val_accuracy: 0.7343\n",
            "Epoch 244/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3587 - accuracy: 0.8706 - val_loss: 0.6643 - val_accuracy: 0.7536\n",
            "Epoch 245/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3601 - accuracy: 0.8609 - val_loss: 0.7157 - val_accuracy: 0.7101\n",
            "Epoch 246/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3686 - accuracy: 0.8537 - val_loss: 0.6868 - val_accuracy: 0.7536\n",
            "Epoch 247/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3830 - accuracy: 0.8609 - val_loss: 0.6798 - val_accuracy: 0.7391\n",
            "Epoch 248/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3279 - accuracy: 0.8688 - val_loss: 0.6778 - val_accuracy: 0.7488\n",
            "Epoch 249/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3759 - accuracy: 0.8622 - val_loss: 0.7052 - val_accuracy: 0.7150\n",
            "Epoch 250/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3495 - accuracy: 0.8634 - val_loss: 0.6914 - val_accuracy: 0.7633\n",
            "Epoch 251/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3545 - accuracy: 0.8670 - val_loss: 0.7015 - val_accuracy: 0.7536\n",
            "Epoch 252/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3702 - accuracy: 0.8525 - val_loss: 0.6634 - val_accuracy: 0.7536\n",
            "Epoch 253/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3482 - accuracy: 0.8628 - val_loss: 0.6562 - val_accuracy: 0.7536\n",
            "Epoch 254/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3339 - accuracy: 0.8706 - val_loss: 0.6492 - val_accuracy: 0.7874\n",
            "Epoch 255/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3490 - accuracy: 0.8664 - val_loss: 0.7137 - val_accuracy: 0.7488\n",
            "Epoch 256/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3337 - accuracy: 0.8791 - val_loss: 0.6721 - val_accuracy: 0.7681\n",
            "Epoch 257/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3578 - accuracy: 0.8658 - val_loss: 0.6039 - val_accuracy: 0.7681\n",
            "Epoch 258/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3499 - accuracy: 0.8676 - val_loss: 0.6580 - val_accuracy: 0.7681\n",
            "Epoch 259/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3314 - accuracy: 0.8779 - val_loss: 0.6817 - val_accuracy: 0.7536\n",
            "Epoch 260/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3328 - accuracy: 0.8706 - val_loss: 0.6703 - val_accuracy: 0.7343\n",
            "Epoch 261/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3481 - accuracy: 0.8603 - val_loss: 0.6488 - val_accuracy: 0.7826\n",
            "Epoch 262/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3319 - accuracy: 0.8742 - val_loss: 0.6964 - val_accuracy: 0.7391\n",
            "Epoch 263/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.3677 - accuracy: 0.8591 - val_loss: 0.6886 - val_accuracy: 0.7585\n",
            "Epoch 264/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.3526 - accuracy: 0.8615 - val_loss: 0.6467 - val_accuracy: 0.7729\n",
            "Epoch 265/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3373 - accuracy: 0.8700 - val_loss: 0.6468 - val_accuracy: 0.7826\n",
            "Epoch 266/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3278 - accuracy: 0.8833 - val_loss: 0.6919 - val_accuracy: 0.7633\n",
            "Epoch 267/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3361 - accuracy: 0.8767 - val_loss: 0.6502 - val_accuracy: 0.7488\n",
            "Epoch 268/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3289 - accuracy: 0.8797 - val_loss: 0.7160 - val_accuracy: 0.7391\n",
            "Epoch 269/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3429 - accuracy: 0.8664 - val_loss: 0.6882 - val_accuracy: 0.7391\n",
            "Epoch 270/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3607 - accuracy: 0.8658 - val_loss: 0.6714 - val_accuracy: 0.7729\n",
            "Epoch 271/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3150 - accuracy: 0.8748 - val_loss: 0.6593 - val_accuracy: 0.7874\n",
            "Epoch 272/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3537 - accuracy: 0.8724 - val_loss: 0.7216 - val_accuracy: 0.7536\n",
            "Epoch 273/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3393 - accuracy: 0.8682 - val_loss: 0.6767 - val_accuracy: 0.7585\n",
            "Epoch 274/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2999 - accuracy: 0.8803 - val_loss: 0.6967 - val_accuracy: 0.7778\n",
            "Epoch 275/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3039 - accuracy: 0.8821 - val_loss: 0.6746 - val_accuracy: 0.7778\n",
            "Epoch 276/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3156 - accuracy: 0.8851 - val_loss: 0.7462 - val_accuracy: 0.7585\n",
            "Epoch 277/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.3270 - accuracy: 0.8833 - val_loss: 0.6584 - val_accuracy: 0.7729\n",
            "Epoch 278/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.3060 - accuracy: 0.8918 - val_loss: 0.7416 - val_accuracy: 0.7536\n",
            "Epoch 279/500\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.2980 - accuracy: 0.8845 - val_loss: 0.7018 - val_accuracy: 0.7826\n",
            "Epoch 280/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.3060 - accuracy: 0.8869 - val_loss: 0.6528 - val_accuracy: 0.7778\n",
            "Epoch 281/500\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.3092 - accuracy: 0.8851 - val_loss: 0.6926 - val_accuracy: 0.7295\n",
            "Epoch 282/500\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.3025 - accuracy: 0.8863 - val_loss: 0.7232 - val_accuracy: 0.7343\n",
            "Epoch 283/500\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.3281 - accuracy: 0.8748 - val_loss: 0.6715 - val_accuracy: 0.7826\n",
            "Epoch 284/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2864 - accuracy: 0.8869 - val_loss: 0.6721 - val_accuracy: 0.7585\n",
            "Epoch 285/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3001 - accuracy: 0.8894 - val_loss: 0.6898 - val_accuracy: 0.7729\n",
            "Epoch 286/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3212 - accuracy: 0.8797 - val_loss: 0.7060 - val_accuracy: 0.7440\n",
            "Epoch 287/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3045 - accuracy: 0.8779 - val_loss: 0.6431 - val_accuracy: 0.7681\n",
            "Epoch 288/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3299 - accuracy: 0.8773 - val_loss: 0.7189 - val_accuracy: 0.7681\n",
            "Epoch 289/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2998 - accuracy: 0.8875 - val_loss: 0.6853 - val_accuracy: 0.7585\n",
            "Epoch 290/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2925 - accuracy: 0.8803 - val_loss: 0.6181 - val_accuracy: 0.7874\n",
            "Epoch 291/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2921 - accuracy: 0.8888 - val_loss: 0.6631 - val_accuracy: 0.7729\n",
            "Epoch 292/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2743 - accuracy: 0.8978 - val_loss: 0.6841 - val_accuracy: 0.7633\n",
            "Epoch 293/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3034 - accuracy: 0.8918 - val_loss: 0.7516 - val_accuracy: 0.7585\n",
            "Epoch 294/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3030 - accuracy: 0.8881 - val_loss: 0.6571 - val_accuracy: 0.7874\n",
            "Epoch 295/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2909 - accuracy: 0.8906 - val_loss: 0.6977 - val_accuracy: 0.7729\n",
            "Epoch 296/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3081 - accuracy: 0.8912 - val_loss: 0.6993 - val_accuracy: 0.7440\n",
            "Epoch 297/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2751 - accuracy: 0.8996 - val_loss: 0.6520 - val_accuracy: 0.7633\n",
            "Epoch 298/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2887 - accuracy: 0.8881 - val_loss: 0.7090 - val_accuracy: 0.7343\n",
            "Epoch 299/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2712 - accuracy: 0.8978 - val_loss: 0.7765 - val_accuracy: 0.7391\n",
            "Epoch 300/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2934 - accuracy: 0.8930 - val_loss: 0.6896 - val_accuracy: 0.7681\n",
            "Epoch 301/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2911 - accuracy: 0.8881 - val_loss: 0.6900 - val_accuracy: 0.7681\n",
            "Epoch 302/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2887 - accuracy: 0.8942 - val_loss: 0.6978 - val_accuracy: 0.7440\n",
            "Epoch 303/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2883 - accuracy: 0.8906 - val_loss: 0.6373 - val_accuracy: 0.7729\n",
            "Epoch 304/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2662 - accuracy: 0.8948 - val_loss: 0.6952 - val_accuracy: 0.7778\n",
            "Epoch 305/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2747 - accuracy: 0.9002 - val_loss: 0.6686 - val_accuracy: 0.8068\n",
            "Epoch 306/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2819 - accuracy: 0.8990 - val_loss: 0.6868 - val_accuracy: 0.7681\n",
            "Epoch 307/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2750 - accuracy: 0.8954 - val_loss: 0.7479 - val_accuracy: 0.7440\n",
            "Epoch 308/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2708 - accuracy: 0.8966 - val_loss: 0.6971 - val_accuracy: 0.7633\n",
            "Epoch 309/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2790 - accuracy: 0.8942 - val_loss: 0.7306 - val_accuracy: 0.7391\n",
            "Epoch 310/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2674 - accuracy: 0.9045 - val_loss: 0.7378 - val_accuracy: 0.7585\n",
            "Epoch 311/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2995 - accuracy: 0.8900 - val_loss: 0.6506 - val_accuracy: 0.7778\n",
            "Epoch 312/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2521 - accuracy: 0.9099 - val_loss: 0.7662 - val_accuracy: 0.7585\n",
            "Epoch 313/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2875 - accuracy: 0.8930 - val_loss: 0.7383 - val_accuracy: 0.7729\n",
            "Epoch 314/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2815 - accuracy: 0.8948 - val_loss: 0.7058 - val_accuracy: 0.7681\n",
            "Epoch 315/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2703 - accuracy: 0.9045 - val_loss: 0.7505 - val_accuracy: 0.7536\n",
            "Epoch 316/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2712 - accuracy: 0.9015 - val_loss: 0.7503 - val_accuracy: 0.7681\n",
            "Epoch 317/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2615 - accuracy: 0.9002 - val_loss: 0.6724 - val_accuracy: 0.7778\n",
            "Epoch 318/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2643 - accuracy: 0.8978 - val_loss: 0.7234 - val_accuracy: 0.7729\n",
            "Epoch 319/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2485 - accuracy: 0.9105 - val_loss: 0.7209 - val_accuracy: 0.7536\n",
            "Epoch 320/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2490 - accuracy: 0.9117 - val_loss: 0.7738 - val_accuracy: 0.7729\n",
            "Epoch 321/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2692 - accuracy: 0.8996 - val_loss: 0.7233 - val_accuracy: 0.7681\n",
            "Epoch 322/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2540 - accuracy: 0.9129 - val_loss: 0.6727 - val_accuracy: 0.7778\n",
            "Epoch 323/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2626 - accuracy: 0.9027 - val_loss: 0.7068 - val_accuracy: 0.7681\n",
            "Epoch 324/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2609 - accuracy: 0.9015 - val_loss: 0.6917 - val_accuracy: 0.8164\n",
            "Epoch 325/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2482 - accuracy: 0.9051 - val_loss: 0.7180 - val_accuracy: 0.7778\n",
            "Epoch 326/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2576 - accuracy: 0.9015 - val_loss: 0.7053 - val_accuracy: 0.7826\n",
            "Epoch 327/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2510 - accuracy: 0.9051 - val_loss: 0.6429 - val_accuracy: 0.7971\n",
            "Epoch 328/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2676 - accuracy: 0.8996 - val_loss: 0.6404 - val_accuracy: 0.7729\n",
            "Epoch 329/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2399 - accuracy: 0.9129 - val_loss: 0.7268 - val_accuracy: 0.7778\n",
            "Epoch 330/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2331 - accuracy: 0.9111 - val_loss: 0.6660 - val_accuracy: 0.7971\n",
            "Epoch 331/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2540 - accuracy: 0.9039 - val_loss: 0.6986 - val_accuracy: 0.8019\n",
            "Epoch 332/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2582 - accuracy: 0.9093 - val_loss: 0.7001 - val_accuracy: 0.7971\n",
            "Epoch 333/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2445 - accuracy: 0.9069 - val_loss: 0.6339 - val_accuracy: 0.8213\n",
            "Epoch 334/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2367 - accuracy: 0.9148 - val_loss: 0.7348 - val_accuracy: 0.7923\n",
            "Epoch 335/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2617 - accuracy: 0.9057 - val_loss: 0.6955 - val_accuracy: 0.7633\n",
            "Epoch 336/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2591 - accuracy: 0.9002 - val_loss: 0.7072 - val_accuracy: 0.7681\n",
            "Epoch 337/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2520 - accuracy: 0.9021 - val_loss: 0.8073 - val_accuracy: 0.7536\n",
            "Epoch 338/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2436 - accuracy: 0.9051 - val_loss: 0.6442 - val_accuracy: 0.7729\n",
            "Epoch 339/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2526 - accuracy: 0.9051 - val_loss: 0.6995 - val_accuracy: 0.7729\n",
            "Epoch 340/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2373 - accuracy: 0.9160 - val_loss: 0.6568 - val_accuracy: 0.7778\n",
            "Epoch 341/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2426 - accuracy: 0.9141 - val_loss: 0.6746 - val_accuracy: 0.7923\n",
            "Epoch 342/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2438 - accuracy: 0.9075 - val_loss: 0.7266 - val_accuracy: 0.7826\n",
            "Epoch 343/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2446 - accuracy: 0.9105 - val_loss: 0.7218 - val_accuracy: 0.7971\n",
            "Epoch 344/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2313 - accuracy: 0.9135 - val_loss: 0.7095 - val_accuracy: 0.7585\n",
            "Epoch 345/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2270 - accuracy: 0.9232 - val_loss: 0.6952 - val_accuracy: 0.7874\n",
            "Epoch 346/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2287 - accuracy: 0.9184 - val_loss: 0.7263 - val_accuracy: 0.8068\n",
            "Epoch 347/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2544 - accuracy: 0.9172 - val_loss: 0.7190 - val_accuracy: 0.7729\n",
            "Epoch 348/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2217 - accuracy: 0.9154 - val_loss: 0.6905 - val_accuracy: 0.7778\n",
            "Epoch 349/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2292 - accuracy: 0.9160 - val_loss: 0.6536 - val_accuracy: 0.7923\n",
            "Epoch 350/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2380 - accuracy: 0.9129 - val_loss: 0.6646 - val_accuracy: 0.7826\n",
            "Epoch 351/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2290 - accuracy: 0.9166 - val_loss: 0.7520 - val_accuracy: 0.7729\n",
            "Epoch 352/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2232 - accuracy: 0.9141 - val_loss: 0.7590 - val_accuracy: 0.7681\n",
            "Epoch 353/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2166 - accuracy: 0.9226 - val_loss: 0.6904 - val_accuracy: 0.7681\n",
            "Epoch 354/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2323 - accuracy: 0.9141 - val_loss: 0.6639 - val_accuracy: 0.7826\n",
            "Epoch 355/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2332 - accuracy: 0.9141 - val_loss: 0.7371 - val_accuracy: 0.7729\n",
            "Epoch 356/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2250 - accuracy: 0.9117 - val_loss: 0.7515 - val_accuracy: 0.7874\n",
            "Epoch 357/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2337 - accuracy: 0.9087 - val_loss: 0.6730 - val_accuracy: 0.7874\n",
            "Epoch 358/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2290 - accuracy: 0.9141 - val_loss: 0.7140 - val_accuracy: 0.8068\n",
            "Epoch 359/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2008 - accuracy: 0.9208 - val_loss: 0.6570 - val_accuracy: 0.8019\n",
            "Epoch 360/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1881 - accuracy: 0.9305 - val_loss: 0.6663 - val_accuracy: 0.7874\n",
            "Epoch 361/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2492 - accuracy: 0.9160 - val_loss: 0.6726 - val_accuracy: 0.7778\n",
            "Epoch 362/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2227 - accuracy: 0.9208 - val_loss: 0.8386 - val_accuracy: 0.7874\n",
            "Epoch 363/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2157 - accuracy: 0.9256 - val_loss: 0.6886 - val_accuracy: 0.7874\n",
            "Epoch 364/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2127 - accuracy: 0.9105 - val_loss: 0.7031 - val_accuracy: 0.7778\n",
            "Epoch 365/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2202 - accuracy: 0.9202 - val_loss: 0.8133 - val_accuracy: 0.7536\n",
            "Epoch 366/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2435 - accuracy: 0.9154 - val_loss: 0.7450 - val_accuracy: 0.7681\n",
            "Epoch 367/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2072 - accuracy: 0.9166 - val_loss: 0.7523 - val_accuracy: 0.7874\n",
            "Epoch 368/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2196 - accuracy: 0.9238 - val_loss: 0.6733 - val_accuracy: 0.7778\n",
            "Epoch 369/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2289 - accuracy: 0.9202 - val_loss: 0.6774 - val_accuracy: 0.7874\n",
            "Epoch 370/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2250 - accuracy: 0.9172 - val_loss: 0.6943 - val_accuracy: 0.7826\n",
            "Epoch 371/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2352 - accuracy: 0.9141 - val_loss: 0.6818 - val_accuracy: 0.7778\n",
            "Epoch 372/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2084 - accuracy: 0.9244 - val_loss: 0.6507 - val_accuracy: 0.8019\n",
            "Epoch 373/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1894 - accuracy: 0.9305 - val_loss: 0.6493 - val_accuracy: 0.8261\n",
            "Epoch 374/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2000 - accuracy: 0.9274 - val_loss: 0.6876 - val_accuracy: 0.8164\n",
            "Epoch 375/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2036 - accuracy: 0.9226 - val_loss: 0.7231 - val_accuracy: 0.7729\n",
            "Epoch 376/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2141 - accuracy: 0.9232 - val_loss: 0.6963 - val_accuracy: 0.7826\n",
            "Epoch 377/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1985 - accuracy: 0.9274 - val_loss: 0.8200 - val_accuracy: 0.7729\n",
            "Epoch 378/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2317 - accuracy: 0.9178 - val_loss: 0.7439 - val_accuracy: 0.8068\n",
            "Epoch 379/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2045 - accuracy: 0.9256 - val_loss: 0.7070 - val_accuracy: 0.7874\n",
            "Epoch 380/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1971 - accuracy: 0.9341 - val_loss: 0.8000 - val_accuracy: 0.7778\n",
            "Epoch 381/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2072 - accuracy: 0.9220 - val_loss: 0.6832 - val_accuracy: 0.7923\n",
            "Epoch 382/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1774 - accuracy: 0.9311 - val_loss: 0.7851 - val_accuracy: 0.7778\n",
            "Epoch 383/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1933 - accuracy: 0.9311 - val_loss: 0.7404 - val_accuracy: 0.7633\n",
            "Epoch 384/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1811 - accuracy: 0.9365 - val_loss: 0.7804 - val_accuracy: 0.7681\n",
            "Epoch 385/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1958 - accuracy: 0.9323 - val_loss: 0.7595 - val_accuracy: 0.7874\n",
            "Epoch 386/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2121 - accuracy: 0.9299 - val_loss: 0.6712 - val_accuracy: 0.8213\n",
            "Epoch 387/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2132 - accuracy: 0.9268 - val_loss: 0.6494 - val_accuracy: 0.7826\n",
            "Epoch 388/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1912 - accuracy: 0.9256 - val_loss: 0.7351 - val_accuracy: 0.7971\n",
            "Epoch 389/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2120 - accuracy: 0.9287 - val_loss: 0.8928 - val_accuracy: 0.7681\n",
            "Epoch 390/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2046 - accuracy: 0.9281 - val_loss: 0.7265 - val_accuracy: 0.8116\n",
            "Epoch 391/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2087 - accuracy: 0.9178 - val_loss: 0.6835 - val_accuracy: 0.7585\n",
            "Epoch 392/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2344 - accuracy: 0.9184 - val_loss: 0.7801 - val_accuracy: 0.7874\n",
            "Epoch 393/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1758 - accuracy: 0.9414 - val_loss: 0.7174 - val_accuracy: 0.7778\n",
            "Epoch 394/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1881 - accuracy: 0.9341 - val_loss: 0.7597 - val_accuracy: 0.8019\n",
            "Epoch 395/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1852 - accuracy: 0.9335 - val_loss: 0.7749 - val_accuracy: 0.7923\n",
            "Epoch 396/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1852 - accuracy: 0.9305 - val_loss: 0.7624 - val_accuracy: 0.7681\n",
            "Epoch 397/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2247 - accuracy: 0.9135 - val_loss: 0.7656 - val_accuracy: 0.7778\n",
            "Epoch 398/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1729 - accuracy: 0.9383 - val_loss: 0.7361 - val_accuracy: 0.8116\n",
            "Epoch 399/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2000 - accuracy: 0.9262 - val_loss: 0.7847 - val_accuracy: 0.7729\n",
            "Epoch 400/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1825 - accuracy: 0.9341 - val_loss: 0.7891 - val_accuracy: 0.7633\n",
            "Epoch 401/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2254 - accuracy: 0.9256 - val_loss: 0.7543 - val_accuracy: 0.7826\n",
            "Epoch 402/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1763 - accuracy: 0.9359 - val_loss: 0.8177 - val_accuracy: 0.7778\n",
            "Epoch 403/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1988 - accuracy: 0.9232 - val_loss: 0.7859 - val_accuracy: 0.7826\n",
            "Epoch 404/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1946 - accuracy: 0.9250 - val_loss: 0.7981 - val_accuracy: 0.7826\n",
            "Epoch 405/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1876 - accuracy: 0.9268 - val_loss: 0.7480 - val_accuracy: 0.7874\n",
            "Epoch 406/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1996 - accuracy: 0.9287 - val_loss: 0.8162 - val_accuracy: 0.7729\n",
            "Epoch 407/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1771 - accuracy: 0.9371 - val_loss: 0.7148 - val_accuracy: 0.7488\n",
            "Epoch 408/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1942 - accuracy: 0.9383 - val_loss: 0.7358 - val_accuracy: 0.7729\n",
            "Epoch 409/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2057 - accuracy: 0.9287 - val_loss: 0.7735 - val_accuracy: 0.7681\n",
            "Epoch 410/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2091 - accuracy: 0.9329 - val_loss: 0.7404 - val_accuracy: 0.7971\n",
            "Epoch 411/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2046 - accuracy: 0.9323 - val_loss: 0.7132 - val_accuracy: 0.7874\n",
            "Epoch 412/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1987 - accuracy: 0.9281 - val_loss: 0.7259 - val_accuracy: 0.7874\n",
            "Epoch 413/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2116 - accuracy: 0.9214 - val_loss: 0.7847 - val_accuracy: 0.7923\n",
            "Epoch 414/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1757 - accuracy: 0.9395 - val_loss: 0.7927 - val_accuracy: 0.7778\n",
            "Epoch 415/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1996 - accuracy: 0.9323 - val_loss: 0.7921 - val_accuracy: 0.8019\n",
            "Epoch 416/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1792 - accuracy: 0.9359 - val_loss: 0.7200 - val_accuracy: 0.7923\n",
            "Epoch 417/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2094 - accuracy: 0.9335 - val_loss: 0.7837 - val_accuracy: 0.7681\n",
            "Epoch 418/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1795 - accuracy: 0.9383 - val_loss: 0.7406 - val_accuracy: 0.7826\n",
            "Epoch 419/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1960 - accuracy: 0.9335 - val_loss: 0.7368 - val_accuracy: 0.7874\n",
            "Epoch 420/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1847 - accuracy: 0.9335 - val_loss: 0.7563 - val_accuracy: 0.7729\n",
            "Epoch 421/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1881 - accuracy: 0.9317 - val_loss: 0.7651 - val_accuracy: 0.7585\n",
            "Epoch 422/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1860 - accuracy: 0.9329 - val_loss: 0.7856 - val_accuracy: 0.7971\n",
            "Epoch 423/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1941 - accuracy: 0.9311 - val_loss: 0.7351 - val_accuracy: 0.7923\n",
            "Epoch 424/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1827 - accuracy: 0.9305 - val_loss: 0.7025 - val_accuracy: 0.7971\n",
            "Epoch 425/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1860 - accuracy: 0.9335 - val_loss: 0.7650 - val_accuracy: 0.7971\n",
            "Epoch 426/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2182 - accuracy: 0.9268 - val_loss: 0.7661 - val_accuracy: 0.7681\n",
            "Epoch 427/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1774 - accuracy: 0.9401 - val_loss: 0.7440 - val_accuracy: 0.7874\n",
            "Epoch 428/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1873 - accuracy: 0.9323 - val_loss: 0.7373 - val_accuracy: 0.7971\n",
            "Epoch 429/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1686 - accuracy: 0.9401 - val_loss: 0.8438 - val_accuracy: 0.7923\n",
            "Epoch 430/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1741 - accuracy: 0.9383 - val_loss: 0.7621 - val_accuracy: 0.7923\n",
            "Epoch 431/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1637 - accuracy: 0.9432 - val_loss: 0.7497 - val_accuracy: 0.7923\n",
            "Epoch 432/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1590 - accuracy: 0.9474 - val_loss: 0.7867 - val_accuracy: 0.7874\n",
            "Epoch 433/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1636 - accuracy: 0.9414 - val_loss: 0.6990 - val_accuracy: 0.8116\n",
            "Epoch 434/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1614 - accuracy: 0.9426 - val_loss: 0.7711 - val_accuracy: 0.8019\n",
            "Epoch 435/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2045 - accuracy: 0.9299 - val_loss: 0.7817 - val_accuracy: 0.7778\n",
            "Epoch 436/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1772 - accuracy: 0.9414 - val_loss: 0.8532 - val_accuracy: 0.7874\n",
            "Epoch 437/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1861 - accuracy: 0.9377 - val_loss: 0.7864 - val_accuracy: 0.8068\n",
            "Epoch 438/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1559 - accuracy: 0.9420 - val_loss: 0.7765 - val_accuracy: 0.7681\n",
            "Epoch 439/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1600 - accuracy: 0.9450 - val_loss: 0.8634 - val_accuracy: 0.7826\n",
            "Epoch 440/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1837 - accuracy: 0.9347 - val_loss: 0.7812 - val_accuracy: 0.7826\n",
            "Epoch 441/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1735 - accuracy: 0.9420 - val_loss: 0.8337 - val_accuracy: 0.7585\n",
            "Epoch 442/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1831 - accuracy: 0.9341 - val_loss: 0.7999 - val_accuracy: 0.8019\n",
            "Epoch 443/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1629 - accuracy: 0.9347 - val_loss: 0.8150 - val_accuracy: 0.7874\n",
            "Epoch 444/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1602 - accuracy: 0.9383 - val_loss: 0.8147 - val_accuracy: 0.7971\n",
            "Epoch 445/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1962 - accuracy: 0.9395 - val_loss: 0.7433 - val_accuracy: 0.7681\n",
            "Epoch 446/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1809 - accuracy: 0.9420 - val_loss: 0.7663 - val_accuracy: 0.7729\n",
            "Epoch 447/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1932 - accuracy: 0.9341 - val_loss: 0.8100 - val_accuracy: 0.7778\n",
            "Epoch 448/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1939 - accuracy: 0.9371 - val_loss: 0.6925 - val_accuracy: 0.8116\n",
            "Epoch 449/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1721 - accuracy: 0.9377 - val_loss: 0.7117 - val_accuracy: 0.8019\n",
            "Epoch 450/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1421 - accuracy: 0.9498 - val_loss: 0.8081 - val_accuracy: 0.8164\n",
            "Epoch 451/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1565 - accuracy: 0.9426 - val_loss: 0.7518 - val_accuracy: 0.8019\n",
            "Epoch 452/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1603 - accuracy: 0.9492 - val_loss: 0.7479 - val_accuracy: 0.7923\n",
            "Epoch 453/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1507 - accuracy: 0.9420 - val_loss: 0.7998 - val_accuracy: 0.7826\n",
            "Epoch 454/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1628 - accuracy: 0.9389 - val_loss: 0.8447 - val_accuracy: 0.7681\n",
            "Epoch 455/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1859 - accuracy: 0.9329 - val_loss: 0.7422 - val_accuracy: 0.7923\n",
            "Epoch 456/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1589 - accuracy: 0.9414 - val_loss: 0.7657 - val_accuracy: 0.7923\n",
            "Epoch 457/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1689 - accuracy: 0.9456 - val_loss: 0.7744 - val_accuracy: 0.7826\n",
            "Epoch 458/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1442 - accuracy: 0.9468 - val_loss: 0.7791 - val_accuracy: 0.7826\n",
            "Epoch 459/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1565 - accuracy: 0.9389 - val_loss: 0.7425 - val_accuracy: 0.7923\n",
            "Epoch 460/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1890 - accuracy: 0.9401 - val_loss: 0.7223 - val_accuracy: 0.7923\n",
            "Epoch 461/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1838 - accuracy: 0.9359 - val_loss: 0.6875 - val_accuracy: 0.7874\n",
            "Epoch 462/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1478 - accuracy: 0.9553 - val_loss: 0.8106 - val_accuracy: 0.7633\n",
            "Epoch 463/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1543 - accuracy: 0.9432 - val_loss: 0.8652 - val_accuracy: 0.7826\n",
            "Epoch 464/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1599 - accuracy: 0.9450 - val_loss: 0.7597 - val_accuracy: 0.7874\n",
            "Epoch 465/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1719 - accuracy: 0.9353 - val_loss: 0.7010 - val_accuracy: 0.7874\n",
            "Epoch 466/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1725 - accuracy: 0.9371 - val_loss: 0.8218 - val_accuracy: 0.7826\n",
            "Epoch 467/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1661 - accuracy: 0.9407 - val_loss: 0.8490 - val_accuracy: 0.7681\n",
            "Epoch 468/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1574 - accuracy: 0.9450 - val_loss: 0.7899 - val_accuracy: 0.7923\n",
            "Epoch 469/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1602 - accuracy: 0.9420 - val_loss: 0.7536 - val_accuracy: 0.7923\n",
            "Epoch 470/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1755 - accuracy: 0.9395 - val_loss: 0.7791 - val_accuracy: 0.8019\n",
            "Epoch 471/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1525 - accuracy: 0.9462 - val_loss: 0.8509 - val_accuracy: 0.8116\n",
            "Epoch 472/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1476 - accuracy: 0.9450 - val_loss: 0.7989 - val_accuracy: 0.7923\n",
            "Epoch 473/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1770 - accuracy: 0.9407 - val_loss: 0.8614 - val_accuracy: 0.8019\n",
            "Epoch 474/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1720 - accuracy: 0.9468 - val_loss: 0.7799 - val_accuracy: 0.8019\n",
            "Epoch 475/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1589 - accuracy: 0.9407 - val_loss: 0.7807 - val_accuracy: 0.8019\n",
            "Epoch 476/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1492 - accuracy: 0.9522 - val_loss: 0.8097 - val_accuracy: 0.7585\n",
            "Epoch 477/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1864 - accuracy: 0.9341 - val_loss: 0.8867 - val_accuracy: 0.7729\n",
            "Epoch 478/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1410 - accuracy: 0.9498 - val_loss: 0.8021 - val_accuracy: 0.8068\n",
            "Epoch 479/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1773 - accuracy: 0.9383 - val_loss: 0.8407 - val_accuracy: 0.7826\n",
            "Epoch 480/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1521 - accuracy: 0.9468 - val_loss: 0.7874 - val_accuracy: 0.7971\n",
            "Epoch 481/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1381 - accuracy: 0.9498 - val_loss: 0.8402 - val_accuracy: 0.8068\n",
            "Epoch 482/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1498 - accuracy: 0.9444 - val_loss: 0.7973 - val_accuracy: 0.7971\n",
            "Epoch 483/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1579 - accuracy: 0.9407 - val_loss: 0.8846 - val_accuracy: 0.7826\n",
            "Epoch 484/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1544 - accuracy: 0.9432 - val_loss: 0.8730 - val_accuracy: 0.7971\n",
            "Epoch 485/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1625 - accuracy: 0.9486 - val_loss: 0.7549 - val_accuracy: 0.8019\n",
            "Epoch 486/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1633 - accuracy: 0.9486 - val_loss: 0.9012 - val_accuracy: 0.7923\n",
            "Epoch 487/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1421 - accuracy: 0.9498 - val_loss: 0.9979 - val_accuracy: 0.7681\n",
            "Epoch 488/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1389 - accuracy: 0.9553 - val_loss: 0.8542 - val_accuracy: 0.7874\n",
            "Epoch 489/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1422 - accuracy: 0.9450 - val_loss: 0.8762 - val_accuracy: 0.8019\n",
            "Epoch 490/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1578 - accuracy: 0.9456 - val_loss: 0.8908 - val_accuracy: 0.7971\n",
            "Epoch 491/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1626 - accuracy: 0.9462 - val_loss: 0.8973 - val_accuracy: 0.8213\n",
            "Epoch 492/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1531 - accuracy: 0.9444 - val_loss: 0.8230 - val_accuracy: 0.7971\n",
            "Epoch 493/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1592 - accuracy: 0.9492 - val_loss: 0.9312 - val_accuracy: 0.7826\n",
            "Epoch 494/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1561 - accuracy: 0.9534 - val_loss: 0.8098 - val_accuracy: 0.7923\n",
            "Epoch 495/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1494 - accuracy: 0.9420 - val_loss: 0.7739 - val_accuracy: 0.8068\n",
            "Epoch 496/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1415 - accuracy: 0.9492 - val_loss: 0.8639 - val_accuracy: 0.7971\n",
            "Epoch 497/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1657 - accuracy: 0.9438 - val_loss: 0.7402 - val_accuracy: 0.7826\n",
            "Epoch 498/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1355 - accuracy: 0.9516 - val_loss: 0.7118 - val_accuracy: 0.8116\n",
            "Epoch 499/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1368 - accuracy: 0.9565 - val_loss: 0.8755 - val_accuracy: 0.7923\n",
            "Epoch 500/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1510 - accuracy: 0.9480 - val_loss: 0.9104 - val_accuracy: 0.7681\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(cnnhistory.history['loss'])\n",
        "plt.plot(cnnhistory.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train','test'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "oQYnuaCrDH_A",
        "outputId": "e90f2937-14d9-4d1a-dbaf-ec84e1e1bc46"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(cnnhistory.history['accuracy'])\n",
        "plt.plot(cnnhistory.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train','test'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "IFkTuO8nDNdq",
        "outputId": "91727e70-e385-40f7-b41f-72e50139d49d"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#predictions = model.predict_classes(x_testcnn)\n",
        "predictions = model.predict(x_testcnn)"
      ],
      "metadata": {
        "id": "A2xtrN5wDQgY"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_f_ohjXKDUpY",
        "outputId": "0c6e45e2-cdb9-4f73-bdf6-7f6e12cf8faf"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.0136834e-05, 2.0927798e-06, 8.9040622e-03, 2.3549544e-05,\n",
              "        4.5087668e-03, 9.8655140e-01],\n",
              "       [3.0898659e-03, 9.9339598e-01, 2.5124467e-04, 2.6822763e-03,\n",
              "        3.3905468e-04, 2.4159682e-04],\n",
              "       [1.4119157e-06, 4.2409007e-03, 9.7028089e-01, 1.8589884e-05,\n",
              "        4.2820289e-03, 2.1176113e-02],\n",
              "       ...,\n",
              "       [2.8554870e-05, 2.4094160e-07, 9.1542926e-04, 9.4812189e-05,\n",
              "        9.7582769e-01, 2.3133274e-02],\n",
              "       [2.4283538e-05, 7.3717638e-06, 1.7189834e-06, 9.7306424e-01,\n",
              "        3.4196141e-06, 2.6898898e-02],\n",
              "       [6.9082816e-05, 7.0382237e-05, 1.5990265e-06, 5.1990628e-05,\n",
              "        9.9980694e-01, 1.6510141e-08]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cmA2bFgsDW3D",
        "outputId": "26a6ae6f-9db9-441d-8a05-3e7a4921428b"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5, 1, 2, 5, 3, 4, 2, 0, 3, 1, 3, 2, 1, 4, 3, 0, 5, 0, 2, 5, 0, 0,\n",
              "       1, 3, 2, 3, 2, 5, 4, 2, 2, 3, 1, 2, 5, 5, 3, 5, 3, 3, 4, 1, 3, 2,\n",
              "       3, 1, 5, 3, 1, 2, 4, 4, 5, 5, 5, 1, 2, 3, 2, 5, 0, 2, 4, 2, 5, 4,\n",
              "       3, 0, 1, 2, 5, 2, 1, 2, 4, 5, 4, 1, 5, 5, 3, 1, 5, 3, 2, 4, 2, 5,\n",
              "       0, 5, 0, 5, 4, 0, 2, 4, 0, 2, 2, 0, 2, 3, 5, 3, 5, 5, 3, 1, 2, 2,\n",
              "       2, 1, 3, 2, 1, 3, 4, 4, 1, 1, 2, 4, 4, 1, 4, 2, 0, 4, 5, 5, 3, 1,\n",
              "       2, 1, 5, 5, 1, 2, 3, 3, 0, 3, 3, 0, 1, 0, 1, 2, 1, 5, 1, 2, 2, 0,\n",
              "       1, 1, 1, 1, 1, 4, 0, 1, 5, 1, 4, 5, 5, 4, 1, 0, 3, 5, 2, 3, 0, 4,\n",
              "       1, 3, 1, 0, 5, 5, 3, 5, 4, 5, 4, 0, 4, 1, 2, 1, 5, 0, 4, 3, 2, 1,\n",
              "       0, 3, 5, 0, 4, 5, 4, 5, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_Ytest = y_test.astype(int)"
      ],
      "metadata": {
        "id": "0PHDKWJWDY3g"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_Ytest"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k68v2i-pDbZE",
        "outputId": "39922254-7ae7-4076-cad8-483b7ebbf095"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5, 1, 2, 5, 3, 4, 2, 0, 3, 1, 3, 2, 1, 4, 3, 0, 5, 0, 2, 5, 0, 0,\n",
              "       1, 3, 2, 3, 2, 5, 4, 2, 2, 3, 1, 2, 5, 5, 3, 5, 3, 3, 4, 1, 3, 2,\n",
              "       3, 1, 5, 3, 1, 2, 4, 4, 5, 5, 5, 1, 2, 3, 2, 5, 0, 2, 4, 2, 5, 4,\n",
              "       3, 0, 1, 2, 5, 2, 1, 2, 4, 5, 4, 1, 5, 5, 3, 1, 5, 3, 2, 4, 2, 5,\n",
              "       0, 5, 0, 5, 4, 0, 2, 4, 0, 2, 2, 0, 2, 3, 5, 3, 5, 5, 3, 1, 2, 2,\n",
              "       2, 1, 3, 2, 1, 3, 4, 4, 1, 1, 2, 4, 4, 1, 4, 2, 0, 4, 5, 5, 3, 1,\n",
              "       2, 1, 5, 5, 1, 2, 3, 3, 0, 3, 3, 0, 1, 0, 1, 2, 1, 5, 1, 2, 2, 0,\n",
              "       1, 1, 1, 1, 1, 4, 0, 1, 5, 1, 4, 5, 5, 4, 1, 0, 3, 5, 2, 3, 0, 4,\n",
              "       1, 3, 1, 0, 5, 5, 3, 5, 4, 5, 4, 0, 4, 1, 2, 1, 5, 0, 4, 3, 2, 1,\n",
              "       0, 3, 5, 0, 4, 5, 4, 5, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds1=predictions.argmax(axis=1)\n",
        "preds1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4_cAI39VFhtp",
        "outputId": "ca4d2a85-f4a1-4695-e691-c8656383782d"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5, 1, 2, 5, 1, 4, 2, 0, 3, 0, 3, 2, 1, 4, 3, 0, 5, 3, 2, 5, 0, 0,\n",
              "       1, 3, 2, 5, 2, 5, 4, 2, 2, 3, 1, 2, 5, 5, 1, 5, 3, 3, 4, 1, 2, 2,\n",
              "       3, 1, 3, 3, 1, 0, 4, 4, 5, 5, 3, 1, 2, 3, 2, 5, 0, 2, 4, 4, 5, 4,\n",
              "       3, 0, 1, 2, 3, 2, 1, 2, 4, 5, 4, 1, 5, 5, 3, 1, 5, 3, 2, 4, 2, 3,\n",
              "       0, 2, 0, 5, 4, 0, 3, 4, 3, 4, 2, 0, 2, 3, 5, 3, 5, 2, 5, 1, 2, 2,\n",
              "       2, 1, 3, 2, 1, 3, 4, 4, 0, 1, 2, 4, 4, 1, 4, 2, 0, 4, 5, 5, 5, 1,\n",
              "       4, 1, 5, 5, 1, 3, 3, 3, 0, 3, 5, 0, 1, 0, 1, 2, 1, 2, 0, 1, 2, 0,\n",
              "       1, 1, 1, 1, 2, 4, 0, 1, 5, 1, 4, 5, 5, 4, 1, 0, 3, 1, 2, 2, 3, 4,\n",
              "       1, 3, 1, 0, 5, 2, 3, 5, 4, 4, 0, 0, 0, 3, 2, 1, 3, 0, 4, 1, 2, 0,\n",
              "       1, 3, 5, 0, 4, 5, 4, 3, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "abc = preds1.astype(int).flatten()"
      ],
      "metadata": {
        "id": "H4WEmM60NfQn"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "c = confusion_matrix(new_Ytest, abc) \n",
        "c"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bKEBeEBlFjB8",
        "outputId": "6fb2c2fa-3491-4a32-87db-5e572431de9a"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[21,  1,  0,  3,  0,  0],\n",
              "       [ 4, 33,  1,  1,  0,  0],\n",
              "       [ 1,  1, 31,  2,  3,  0],\n",
              "       [ 0,  3,  2, 24,  0,  4],\n",
              "       [ 2,  0,  0,  0, 28,  0],\n",
              "       [ 0,  1,  4,  6,  1, 30]])"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m4RjG7LWLSQx",
        "outputId": "a0c00bfa-0967-4cb9-8481-ff444cdf83db"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5, 1, 2, 5, 3, 4, 2, 0, 3, 1, 3, 2, 1, 4, 3, 0, 5, 0, 2, 5, 0, 0,\n",
              "       1, 3, 2, 3, 2, 5, 4, 2, 2, 3, 1, 2, 5, 5, 3, 5, 3, 3, 4, 1, 3, 2,\n",
              "       3, 1, 5, 3, 1, 2, 4, 4, 5, 5, 5, 1, 2, 3, 2, 5, 0, 2, 4, 2, 5, 4,\n",
              "       3, 0, 1, 2, 5, 2, 1, 2, 4, 5, 4, 1, 5, 5, 3, 1, 5, 3, 2, 4, 2, 5,\n",
              "       0, 5, 0, 5, 4, 0, 2, 4, 0, 2, 2, 0, 2, 3, 5, 3, 5, 5, 3, 1, 2, 2,\n",
              "       2, 1, 3, 2, 1, 3, 4, 4, 1, 1, 2, 4, 4, 1, 4, 2, 0, 4, 5, 5, 3, 1,\n",
              "       2, 1, 5, 5, 1, 2, 3, 3, 0, 3, 3, 0, 1, 0, 1, 2, 1, 5, 1, 2, 2, 0,\n",
              "       1, 1, 1, 1, 1, 4, 0, 1, 5, 1, 4, 5, 5, 4, 1, 0, 3, 5, 2, 3, 0, 4,\n",
              "       1, 3, 1, 0, 5, 5, 3, 5, 4, 5, 4, 0, 4, 1, 2, 1, 5, 0, 4, 3, 2, 1,\n",
              "       0, 3, 5, 0, 4, 5, 4, 5, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('/content/drive/My Drive/graduation project/audio/paper_code/mariam/original_500 epoch_with_valid_Adam2_3')\n",
        "print(\"MODEL SAVED\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lsJBNeMWDl6Z",
        "outputId": "089f4f99-6e4d-4997-f15e-ec97b726c657"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/graduation project/audio/paper_code/mariam/original_500 epoch_with_valid_Adam2_3/assets\n",
            "MODEL SAVED\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_model=keras.models.load_model('/content/drive/My Drive/graduation project/audio/paper_code/mariam/original_500 epoch_with_valid_Adam2_3')\n",
        "new_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q3KjaO9GDoNl",
        "outputId": "560b367d-6291-4fd9-ce4b-dbb43d3a8aac"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d (Conv1D)             (None, 40, 128)           1152      \n",
            "                                                                 \n",
            " activation (Activation)     (None, 40, 128)           0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 40, 128)           0         \n",
            "                                                                 \n",
            " max_pooling1d (MaxPooling1D  (None, 8, 128)           0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv1d_1 (Conv1D)           (None, 8, 256)            262400    \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 8, 256)            0         \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 8, 256)            0         \n",
            "                                                                 \n",
            " max_pooling1d_1 (MaxPooling  (None, 1, 256)           0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 256)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 256)               65792     \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 256)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 256)               65792     \n",
            "                                                                 \n",
            " activation_3 (Activation)   (None, 256)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 6)                 1542      \n",
            "                                                                 \n",
            " activation_4 (Activation)   (None, 6)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 396,678\n",
            "Trainable params: 396,678\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss, acc =model.evaluate(x_testcnn, y_test)\n",
        "print(\"Restored model, accuracy: {:5.2f}%\".format(100*acc))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n3kzoqPkDqqS",
        "outputId": "65eb0b0b-c625-4130-d74c-71d19e12a728"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7/7 [==============================] - 0s 3ms/step - loss: 0.7565 - accuracy: 0.8068\n",
            "Restored model, accuracy: 80.68%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss, acc =model.evaluate(X_train, y_train)\n",
        "print(\"Restored model train, accuracy: {:5.2f}%\".format(100*acc))"
      ],
      "metadata": {
        "id": "fJDTGH_OUX0z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f8041a5f-4ba6-4573-b4d1-b5a286ffd1df"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "52/52 [==============================] - 0s 4ms/step - loss: 0.0650 - accuracy: 0.9855\n",
            "Restored model train, accuracy: 98.55%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix,accuracy_score\n",
        "import seaborn as sn\n",
        "\n",
        "print(classification_report(new_Ytest,abc))\n",
        "\n",
        "acc = float(accuracy_score(new_Ytest,abc))*100\n",
        "print(\"----accuracy score %s ----\" % acc)\n",
        "\n",
        "cm = confusion_matrix(new_Ytest,abc)\n",
        "#df_cm = pd.DataFrame(cm)\n",
        "class_names = ['neutral','calm', 'happy','sad','angry', 'fearful' ]\n",
        "df_cm = pd.DataFrame(cm, index=class_names, columns=class_names,)\n",
        "sn.heatmap(df_cm, annot=True, fmt='')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 508
        },
        "id": "SfSC3El94LZg",
        "outputId": "3344d745-28b3-4459-803a-896a57206ce0"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.84      0.79        25\n",
            "           1       0.85      0.85      0.85        39\n",
            "           2       0.82      0.82      0.82        38\n",
            "           3       0.67      0.73      0.70        33\n",
            "           4       0.88      0.93      0.90        30\n",
            "           5       0.88      0.71      0.79        42\n",
            "\n",
            "    accuracy                           0.81       207\n",
            "   macro avg       0.81      0.81      0.81       207\n",
            "weighted avg       0.81      0.81      0.81       207\n",
            "\n",
            "----accuracy score 80.67632850241546 ----\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "LGpgwFQqkpyU"
      },
      "execution_count": 38,
      "outputs": []
    }
  ]
}