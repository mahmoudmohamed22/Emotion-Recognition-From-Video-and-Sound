{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "original_adam_0.00002_without decay_1000_2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9SRCO-a_AlH5",
        "outputId": "2a0ab84c-5dcf-4978-c726-fc3b6fc4c7a4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install librosa"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Lo4mUwG9RMd",
        "outputId": "c1afc7b3-c32e-4a48-8ad8-f2e4f43b1603"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.7/dist-packages (0.8.1)\n",
            "Requirement already satisfied: resampy>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from librosa) (0.2.2)\n",
            "Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.6.0)\n",
            "Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.0.2)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.21.6)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.4.1)\n",
            "Requirement already satisfied: decorator>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied: audioread>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (2.1.9)\n",
            "Requirement already satisfied: numba>=0.43.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (0.51.2)\n",
            "Requirement already satisfied: soundfile>=0.10.2 in /usr/local/lib/python3.7/dist-packages (from librosa) (0.10.3.post1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (21.3)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.1.0)\n",
            "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba>=0.43.0->librosa) (0.34.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba>=0.43.0->librosa) (57.4.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->librosa) (3.0.9)\n",
            "Requirement already satisfied: appdirs>=1.3.0 in /usr/local/lib/python3.7/dist-packages (from pooch>=1.0->librosa) (1.4.4)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from pooch>=1.0->librosa) (2.23.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2022.5.18.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2.10)\n",
            "Requirement already satisfied: six>=1.3 in /usr/local/lib/python3.7/dist-packages (from resampy>=0.2.2->librosa) (1.15.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn!=0.19.0,>=0.14.0->librosa) (3.1.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.7/dist-packages (from soundfile>=0.10.2->librosa) (1.15.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.0->soundfile>=0.10.2->librosa) (2.21)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HJjcbxwy46bG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "2784e5f6-0416-4b38-80ab-3e7541414b91"
      },
      "source": [
        "# Orignial Notebook: https://github.com/MITESHPUTHRANNEU/Speech-Emotion-Analyzer/blob/master/final_results_gender_test.ipynb\n",
        "# This notebook author: Reza Chu\n",
        "# Last Editing Date: 31st May 2019\n",
        "\n",
        "## Python\n",
        "import os\n",
        "import random\n",
        "import sys\n",
        "\n",
        "import IPython\n",
        "from IPython.display import Audio\n",
        "from IPython.display import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "## Package\n",
        "import glob \n",
        "import keras\n",
        "import IPython.display as ipd\n",
        "import librosa\n",
        "import librosa.display\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import plotly.graph_objs as go\n",
        "import plotly.offline as py\n",
        "import plotly.tools as tls\n",
        "import seaborn as sns\n",
        "import scipy.io.wavfile\n",
        "import tensorflow as tf\n",
        "py.init_notebook_mode(connected=True)\n",
        "\n",
        "## Keras\n",
        "from keras import regularizers\n",
        "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping\n",
        "from keras.callbacks import  History, ReduceLROnPlateau, CSVLogger\n",
        "from keras.models import Model, Sequential\n",
        "from keras.layers import Dense, Embedding, LSTM\n",
        "from keras.layers import Input, Flatten, Dropout, Activation, BatchNormalization\n",
        "from keras.layers import Conv1D, MaxPooling1D, AveragePooling1D\n",
        "from keras.preprocessing import sequence\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.utils import np_utils\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "## Sklearn\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "## Rest\n",
        "from scipy.fftpack import fft\n",
        "from scipy import signal\n",
        "from scipy.io import wavfile\n",
        "from tqdm import tqdm\n",
        "\n",
        "input_duration=3\n",
        "# % pylab inline"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "        <script type=\"text/javascript\">\n",
              "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
              "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
              "        if (typeof require !== 'undefined') {\n",
              "        require.undef(\"plotly\");\n",
              "        requirejs.config({\n",
              "            paths: {\n",
              "                'plotly': ['https://cdn.plot.ly/plotly-2.8.3.min']\n",
              "            }\n",
              "        });\n",
              "        require(['plotly'], function(Plotly) {\n",
              "            window._Plotly = Plotly;\n",
              "        });\n",
              "        }\n",
              "        </script>\n",
              "        "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Saving joblib files to not load them again with the loop above\n",
        "\n",
        "# import joblib\n",
        "\n",
        "# X_name = 'x.joblib'\n",
        "# y_name = 'y.joblib'\n",
        "# save_dir = '/content/drive/My Drive/graduation project/audio/paper_code/features'\n",
        "\n",
        "# savedX = joblib.dump(X, os.path.join(save_dir, X_name))\n",
        "# savedy = joblib.dump(y, os.path.join(save_dir, y_name))"
      ],
      "metadata": {
        "id": "UCzic8rlDcuk"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Loading saved models\n",
        "import joblib\n",
        "X = joblib.load('/content/drive/My Drive/graduation project/audio/paper_code/features/x.joblib')\n",
        "y = joblib.load('/content/drive/My Drive/graduation project/audio/paper_code/features/y.joblib')"
      ],
      "metadata": {
        "id": "Q35CN6zDrzg1"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7PSTurzjCo5K",
        "outputId": "df09e6c5-4e3c-4f63-e779-ac754cae621d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2068, 40)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.1 ,shuffle = True\n",
        "                                                    , random_state=42)\n",
        "X_train , X_valid, y_train, y_valid = train_test_split(X_train,y_train, test_size=0.1112305212 , shuffle = True \n",
        "                                                       , random_state=42)"
      ],
      "metadata": {
        "id": "Ai4Fy5cPCiq1"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "x_traincnn = np.expand_dims(X_train, axis=2)\n",
        "x_testcnn = np.expand_dims(X_test, axis=2)\n",
        "X_valid= np.expand_dims(X_valid, axis=2)"
      ],
      "metadata": {
        "id": "tp1Fm5K3CEXu"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_traincnn.shape, x_testcnn.shape , X_valid.shape\n",
        "#1861"
      ],
      "metadata": {
        "id": "RI0MxoIPBws5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d48b926-561d-41a2-925b-7ef6d1a3b8b2"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1654, 40, 1), (207, 40, 1), (207, 40, 1))"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oALhiMUd9G2Y",
        "outputId": "ca091ff4-1c21-4e04-e959-3f9b758c8c79"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (2.8.2+zzzcolab20220527125636)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.26.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.5.3)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.21.6)\n",
            "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.17.3)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.0.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.46.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow) (57.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (14.0.1)\n",
            "Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (4.2.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow) (1.5.2)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.23.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.6.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.4.6)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (3.3.7)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.35.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (4.11.4)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (3.8.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2022.5.18.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (3.2.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from keras.preprocessing import sequence\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from keras.layers import Input, Flatten, Dropout, Activation\n",
        "from keras.layers import Conv1D, MaxPooling1D\n",
        "from keras.models import Model\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras import optimizers\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv1D(128, 8,padding='same', #classifier.add(Convolution2D(64, (3, 3), padding = 'same', input_shape = (128, 128, 3), activation = 'relu'))\n",
        "                 input_shape=(40,1)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(MaxPooling1D(pool_size=(5)))\n",
        "\n",
        "\n",
        "model.add(Conv1D(256,8,padding='same',))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(MaxPooling1D(pool_size=(5)))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(256))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(256))\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "model.add(Dense(6))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "opt = tf.keras.optimizers.Adam(lr=0.00002 , decay=0.0)\n",
        "#opt = tf.keras.optimizers.RMSprop(lr=0.0001, rho=0.9, epsilon=1e-07, decay=0.0)\n",
        "#opt = tf.keras.optimizers.SGD(lr=0.001, momentum=0.0, decay=0.0, nesterov=False)"
      ],
      "metadata": {
        "id": "g74fXWVAC4Cr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9055e318-4e7e-4fa3-c8f0-cef1f6d72432"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning:\n",
            "\n",
            "The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H6ukOxAGC_I4",
        "outputId": "d85916e5-a736-4e0e-f5d1-fdf7d0b2216a"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d (Conv1D)             (None, 40, 128)           1152      \n",
            "                                                                 \n",
            " activation (Activation)     (None, 40, 128)           0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 40, 128)           0         \n",
            "                                                                 \n",
            " max_pooling1d (MaxPooling1D  (None, 8, 128)           0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv1d_1 (Conv1D)           (None, 8, 256)            262400    \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 8, 256)            0         \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 8, 256)            0         \n",
            "                                                                 \n",
            " max_pooling1d_1 (MaxPooling  (None, 1, 256)           0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 256)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 256)               65792     \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 256)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 256)               65792     \n",
            "                                                                 \n",
            " activation_3 (Activation)   (None, 256)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 6)                 1542      \n",
            "                                                                 \n",
            " activation_4 (Activation)   (None, 6)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 396,678\n",
            "Trainable params: 396,678\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='sparse_categorical_crossentropy',\n",
        "              optimizer=opt,\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "AbMlLNk4DCBM"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an Instance of Early Stopping Callback.\n",
        "early_stopping_callback = EarlyStopping(monitor = 'val_loss', patience = 25, mode = 'min', restore_best_weights = True)\n",
        "\n",
        "cnnhistory=model.fit(x_traincnn, y_train, batch_size=16, epochs=1000 , shuffle = True, \n",
        "                     validation_data=(X_valid, y_valid) \n",
        "                     , callbacks = [early_stopping_callback]\n",
        "                     )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RI1v2AuADFhy",
        "outputId": "ee774924-3a58-4b84-b571-af612fc2add5"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "104/104 [==============================] - 5s 12ms/step - loss: 5.6463 - accuracy: 0.1711 - val_loss: 2.3278 - val_accuracy: 0.2271\n",
            "Epoch 2/1000\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 4.4192 - accuracy: 0.1784 - val_loss: 2.2304 - val_accuracy: 0.2271\n",
            "Epoch 3/1000\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 3.7125 - accuracy: 0.1995 - val_loss: 1.9216 - val_accuracy: 0.2271\n",
            "Epoch 4/1000\n",
            "104/104 [==============================] - 1s 9ms/step - loss: 3.3357 - accuracy: 0.1723 - val_loss: 1.8945 - val_accuracy: 0.1981\n",
            "Epoch 5/1000\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 2.9948 - accuracy: 0.1753 - val_loss: 1.8012 - val_accuracy: 0.2222\n",
            "Epoch 6/1000\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 2.9020 - accuracy: 0.1898 - val_loss: 1.8215 - val_accuracy: 0.2077\n",
            "Epoch 7/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 2.7199 - accuracy: 0.1892 - val_loss: 1.7797 - val_accuracy: 0.2174\n",
            "Epoch 8/1000\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 2.6306 - accuracy: 0.1820 - val_loss: 1.7347 - val_accuracy: 0.2222\n",
            "Epoch 9/1000\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 2.4808 - accuracy: 0.1874 - val_loss: 1.7388 - val_accuracy: 0.2560\n",
            "Epoch 10/1000\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 2.4621 - accuracy: 0.1723 - val_loss: 1.7242 - val_accuracy: 0.2512\n",
            "Epoch 11/1000\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 2.3343 - accuracy: 0.1832 - val_loss: 1.7386 - val_accuracy: 0.2560\n",
            "Epoch 12/1000\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 2.2598 - accuracy: 0.2019 - val_loss: 1.7355 - val_accuracy: 0.2367\n",
            "Epoch 13/1000\n",
            "104/104 [==============================] - 1s 11ms/step - loss: 2.2638 - accuracy: 0.1941 - val_loss: 1.7211 - val_accuracy: 0.3188\n",
            "Epoch 14/1000\n",
            "104/104 [==============================] - 1s 9ms/step - loss: 2.1900 - accuracy: 0.2025 - val_loss: 1.7169 - val_accuracy: 0.2560\n",
            "Epoch 15/1000\n",
            "104/104 [==============================] - 1s 10ms/step - loss: 2.1235 - accuracy: 0.2098 - val_loss: 1.7421 - val_accuracy: 0.2609\n",
            "Epoch 16/1000\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 2.0941 - accuracy: 0.2019 - val_loss: 1.7552 - val_accuracy: 0.2464\n",
            "Epoch 17/1000\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 2.0561 - accuracy: 0.2201 - val_loss: 1.7241 - val_accuracy: 0.2560\n",
            "Epoch 18/1000\n",
            "104/104 [==============================] - 1s 9ms/step - loss: 2.0068 - accuracy: 0.2225 - val_loss: 1.7311 - val_accuracy: 0.2609\n",
            "Epoch 19/1000\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 1.9945 - accuracy: 0.2267 - val_loss: 1.7269 - val_accuracy: 0.2367\n",
            "Epoch 20/1000\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 2.0094 - accuracy: 0.2170 - val_loss: 1.7171 - val_accuracy: 0.2705\n",
            "Epoch 21/1000\n",
            "104/104 [==============================] - 1s 9ms/step - loss: 1.9441 - accuracy: 0.2164 - val_loss: 1.7166 - val_accuracy: 0.2995\n",
            "Epoch 22/1000\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 1.9627 - accuracy: 0.2140 - val_loss: 1.7064 - val_accuracy: 0.2754\n",
            "Epoch 23/1000\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 1.9451 - accuracy: 0.2170 - val_loss: 1.7157 - val_accuracy: 0.2705\n",
            "Epoch 24/1000\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 1.9174 - accuracy: 0.2225 - val_loss: 1.7253 - val_accuracy: 0.2126\n",
            "Epoch 25/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 1.8708 - accuracy: 0.2406 - val_loss: 1.7072 - val_accuracy: 0.2802\n",
            "Epoch 26/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 1.8779 - accuracy: 0.2328 - val_loss: 1.6982 - val_accuracy: 0.2802\n",
            "Epoch 27/1000\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 1.8751 - accuracy: 0.2328 - val_loss: 1.6961 - val_accuracy: 0.3092\n",
            "Epoch 28/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.8830 - accuracy: 0.2183 - val_loss: 1.6876 - val_accuracy: 0.3043\n",
            "Epoch 29/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.8261 - accuracy: 0.2297 - val_loss: 1.7074 - val_accuracy: 0.2754\n",
            "Epoch 30/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.8436 - accuracy: 0.2461 - val_loss: 1.6891 - val_accuracy: 0.2609\n",
            "Epoch 31/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.8172 - accuracy: 0.2485 - val_loss: 1.6869 - val_accuracy: 0.3092\n",
            "Epoch 32/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.8224 - accuracy: 0.2533 - val_loss: 1.6969 - val_accuracy: 0.2609\n",
            "Epoch 33/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.8461 - accuracy: 0.2249 - val_loss: 1.6965 - val_accuracy: 0.2802\n",
            "Epoch 34/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.7912 - accuracy: 0.2509 - val_loss: 1.6787 - val_accuracy: 0.3430\n",
            "Epoch 35/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.7832 - accuracy: 0.2467 - val_loss: 1.6777 - val_accuracy: 0.3140\n",
            "Epoch 36/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.7623 - accuracy: 0.2557 - val_loss: 1.6781 - val_accuracy: 0.3188\n",
            "Epoch 37/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.7907 - accuracy: 0.2539 - val_loss: 1.6796 - val_accuracy: 0.2754\n",
            "Epoch 38/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.7842 - accuracy: 0.2570 - val_loss: 1.6677 - val_accuracy: 0.3092\n",
            "Epoch 39/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.7635 - accuracy: 0.2557 - val_loss: 1.6564 - val_accuracy: 0.3816\n",
            "Epoch 40/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.7763 - accuracy: 0.2539 - val_loss: 1.6518 - val_accuracy: 0.3188\n",
            "Epoch 41/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.7525 - accuracy: 0.2582 - val_loss: 1.6651 - val_accuracy: 0.3768\n",
            "Epoch 42/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.7525 - accuracy: 0.2763 - val_loss: 1.6667 - val_accuracy: 0.2995\n",
            "Epoch 43/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.7265 - accuracy: 0.2739 - val_loss: 1.6464 - val_accuracy: 0.3575\n",
            "Epoch 44/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.7329 - accuracy: 0.2787 - val_loss: 1.6725 - val_accuracy: 0.3092\n",
            "Epoch 45/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.7368 - accuracy: 0.2805 - val_loss: 1.6544 - val_accuracy: 0.3092\n",
            "Epoch 46/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.7067 - accuracy: 0.2896 - val_loss: 1.6478 - val_accuracy: 0.3043\n",
            "Epoch 47/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.6959 - accuracy: 0.2884 - val_loss: 1.6577 - val_accuracy: 0.3043\n",
            "Epoch 48/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.7201 - accuracy: 0.2733 - val_loss: 1.6510 - val_accuracy: 0.3768\n",
            "Epoch 49/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.7435 - accuracy: 0.2624 - val_loss: 1.6348 - val_accuracy: 0.4155\n",
            "Epoch 50/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.6917 - accuracy: 0.2787 - val_loss: 1.6272 - val_accuracy: 0.3720\n",
            "Epoch 51/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.7033 - accuracy: 0.2890 - val_loss: 1.6318 - val_accuracy: 0.3865\n",
            "Epoch 52/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.6801 - accuracy: 0.2969 - val_loss: 1.6576 - val_accuracy: 0.3913\n",
            "Epoch 53/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.6934 - accuracy: 0.2860 - val_loss: 1.6313 - val_accuracy: 0.3430\n",
            "Epoch 54/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.6877 - accuracy: 0.2696 - val_loss: 1.6226 - val_accuracy: 0.3430\n",
            "Epoch 55/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.6573 - accuracy: 0.3005 - val_loss: 1.6144 - val_accuracy: 0.3671\n",
            "Epoch 56/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.6730 - accuracy: 0.2944 - val_loss: 1.6253 - val_accuracy: 0.3671\n",
            "Epoch 57/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.6516 - accuracy: 0.2866 - val_loss: 1.6159 - val_accuracy: 0.3623\n",
            "Epoch 58/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.6579 - accuracy: 0.3005 - val_loss: 1.6057 - val_accuracy: 0.3382\n",
            "Epoch 59/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.6482 - accuracy: 0.2932 - val_loss: 1.5982 - val_accuracy: 0.3865\n",
            "Epoch 60/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.6646 - accuracy: 0.2860 - val_loss: 1.5984 - val_accuracy: 0.4300\n",
            "Epoch 61/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.6317 - accuracy: 0.3138 - val_loss: 1.5957 - val_accuracy: 0.3623\n",
            "Epoch 62/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.6595 - accuracy: 0.3120 - val_loss: 1.5787 - val_accuracy: 0.3913\n",
            "Epoch 63/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.6179 - accuracy: 0.3053 - val_loss: 1.6006 - val_accuracy: 0.3188\n",
            "Epoch 64/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.6198 - accuracy: 0.3289 - val_loss: 1.5756 - val_accuracy: 0.3913\n",
            "Epoch 65/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.6186 - accuracy: 0.3277 - val_loss: 1.5743 - val_accuracy: 0.4010\n",
            "Epoch 66/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.6212 - accuracy: 0.3210 - val_loss: 1.5763 - val_accuracy: 0.3623\n",
            "Epoch 67/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.6091 - accuracy: 0.3253 - val_loss: 1.5883 - val_accuracy: 0.3285\n",
            "Epoch 68/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.5915 - accuracy: 0.3235 - val_loss: 1.5780 - val_accuracy: 0.3671\n",
            "Epoch 69/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.6019 - accuracy: 0.3343 - val_loss: 1.5608 - val_accuracy: 0.3671\n",
            "Epoch 70/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.6078 - accuracy: 0.3325 - val_loss: 1.5557 - val_accuracy: 0.3478\n",
            "Epoch 71/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.5854 - accuracy: 0.3283 - val_loss: 1.5795 - val_accuracy: 0.3478\n",
            "Epoch 72/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.5893 - accuracy: 0.3362 - val_loss: 1.5600 - val_accuracy: 0.3623\n",
            "Epoch 73/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.5748 - accuracy: 0.3458 - val_loss: 1.5664 - val_accuracy: 0.4058\n",
            "Epoch 74/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.5687 - accuracy: 0.3470 - val_loss: 1.5451 - val_accuracy: 0.4010\n",
            "Epoch 75/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.5675 - accuracy: 0.3446 - val_loss: 1.5391 - val_accuracy: 0.4444\n",
            "Epoch 76/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.5816 - accuracy: 0.3428 - val_loss: 1.5399 - val_accuracy: 0.3913\n",
            "Epoch 77/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.5704 - accuracy: 0.3501 - val_loss: 1.5431 - val_accuracy: 0.3961\n",
            "Epoch 78/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.5672 - accuracy: 0.3591 - val_loss: 1.5286 - val_accuracy: 0.4300\n",
            "Epoch 79/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.5638 - accuracy: 0.3495 - val_loss: 1.5180 - val_accuracy: 0.4493\n",
            "Epoch 80/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.5635 - accuracy: 0.3501 - val_loss: 1.5059 - val_accuracy: 0.4396\n",
            "Epoch 81/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.5494 - accuracy: 0.3555 - val_loss: 1.5014 - val_accuracy: 0.3768\n",
            "Epoch 82/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.5631 - accuracy: 0.3434 - val_loss: 1.5038 - val_accuracy: 0.3720\n",
            "Epoch 83/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.5509 - accuracy: 0.3482 - val_loss: 1.5080 - val_accuracy: 0.4396\n",
            "Epoch 84/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.5321 - accuracy: 0.3658 - val_loss: 1.5057 - val_accuracy: 0.4348\n",
            "Epoch 85/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.5285 - accuracy: 0.3513 - val_loss: 1.5005 - val_accuracy: 0.3961\n",
            "Epoch 86/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.5103 - accuracy: 0.3881 - val_loss: 1.4967 - val_accuracy: 0.4251\n",
            "Epoch 87/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.5158 - accuracy: 0.3640 - val_loss: 1.5087 - val_accuracy: 0.4010\n",
            "Epoch 88/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.5093 - accuracy: 0.3797 - val_loss: 1.4937 - val_accuracy: 0.4251\n",
            "Epoch 89/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.5163 - accuracy: 0.3742 - val_loss: 1.4855 - val_accuracy: 0.4444\n",
            "Epoch 90/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.4882 - accuracy: 0.3815 - val_loss: 1.5079 - val_accuracy: 0.3768\n",
            "Epoch 91/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.5031 - accuracy: 0.3900 - val_loss: 1.4866 - val_accuracy: 0.4444\n",
            "Epoch 92/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.5022 - accuracy: 0.3718 - val_loss: 1.4843 - val_accuracy: 0.3720\n",
            "Epoch 93/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.4889 - accuracy: 0.4075 - val_loss: 1.4671 - val_accuracy: 0.4589\n",
            "Epoch 94/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.5072 - accuracy: 0.3761 - val_loss: 1.4643 - val_accuracy: 0.4831\n",
            "Epoch 95/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.4901 - accuracy: 0.3906 - val_loss: 1.4527 - val_accuracy: 0.4686\n",
            "Epoch 96/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.4841 - accuracy: 0.3942 - val_loss: 1.4666 - val_accuracy: 0.4686\n",
            "Epoch 97/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.4750 - accuracy: 0.3942 - val_loss: 1.4528 - val_accuracy: 0.4300\n",
            "Epoch 98/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.4708 - accuracy: 0.3954 - val_loss: 1.4455 - val_accuracy: 0.4638\n",
            "Epoch 99/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.4610 - accuracy: 0.4105 - val_loss: 1.4397 - val_accuracy: 0.4928\n",
            "Epoch 100/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.4605 - accuracy: 0.3984 - val_loss: 1.4373 - val_accuracy: 0.4541\n",
            "Epoch 101/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.4634 - accuracy: 0.3960 - val_loss: 1.4209 - val_accuracy: 0.4783\n",
            "Epoch 102/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.4456 - accuracy: 0.4063 - val_loss: 1.4273 - val_accuracy: 0.4300\n",
            "Epoch 103/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.4384 - accuracy: 0.4045 - val_loss: 1.4147 - val_accuracy: 0.4783\n",
            "Epoch 104/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.4455 - accuracy: 0.4111 - val_loss: 1.4237 - val_accuracy: 0.4300\n",
            "Epoch 105/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.4505 - accuracy: 0.3930 - val_loss: 1.4221 - val_accuracy: 0.4686\n",
            "Epoch 106/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.4308 - accuracy: 0.4063 - val_loss: 1.4277 - val_accuracy: 0.4493\n",
            "Epoch 107/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.4489 - accuracy: 0.3984 - val_loss: 1.4233 - val_accuracy: 0.4444\n",
            "Epoch 108/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.4482 - accuracy: 0.4063 - val_loss: 1.4136 - val_accuracy: 0.4589\n",
            "Epoch 109/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.4110 - accuracy: 0.4214 - val_loss: 1.4001 - val_accuracy: 0.4879\n",
            "Epoch 110/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.4398 - accuracy: 0.4160 - val_loss: 1.3876 - val_accuracy: 0.5362\n",
            "Epoch 111/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.4079 - accuracy: 0.4154 - val_loss: 1.4023 - val_accuracy: 0.4831\n",
            "Epoch 112/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.4126 - accuracy: 0.4256 - val_loss: 1.3865 - val_accuracy: 0.4734\n",
            "Epoch 113/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.4354 - accuracy: 0.4129 - val_loss: 1.3821 - val_accuracy: 0.5266\n",
            "Epoch 114/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.4006 - accuracy: 0.4256 - val_loss: 1.3862 - val_accuracy: 0.5121\n",
            "Epoch 115/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.4070 - accuracy: 0.4196 - val_loss: 1.3779 - val_accuracy: 0.4783\n",
            "Epoch 116/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.3974 - accuracy: 0.4208 - val_loss: 1.3722 - val_accuracy: 0.5314\n",
            "Epoch 117/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.3770 - accuracy: 0.4559 - val_loss: 1.3655 - val_accuracy: 0.4783\n",
            "Epoch 118/1000\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 1.3968 - accuracy: 0.4323 - val_loss: 1.3680 - val_accuracy: 0.4879\n",
            "Epoch 119/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.3791 - accuracy: 0.4522 - val_loss: 1.3502 - val_accuracy: 0.5459\n",
            "Epoch 120/1000\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 1.3913 - accuracy: 0.4353 - val_loss: 1.3468 - val_accuracy: 0.5411\n",
            "Epoch 121/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.3706 - accuracy: 0.4371 - val_loss: 1.3465 - val_accuracy: 0.5024\n",
            "Epoch 122/1000\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 1.3558 - accuracy: 0.4601 - val_loss: 1.3415 - val_accuracy: 0.5121\n",
            "Epoch 123/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.3413 - accuracy: 0.4637 - val_loss: 1.3310 - val_accuracy: 0.5169\n",
            "Epoch 124/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.3591 - accuracy: 0.4401 - val_loss: 1.3441 - val_accuracy: 0.4879\n",
            "Epoch 125/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.3512 - accuracy: 0.4522 - val_loss: 1.3314 - val_accuracy: 0.4879\n",
            "Epoch 126/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.3590 - accuracy: 0.4353 - val_loss: 1.3389 - val_accuracy: 0.5072\n",
            "Epoch 127/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.3547 - accuracy: 0.4577 - val_loss: 1.3223 - val_accuracy: 0.4976\n",
            "Epoch 128/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.3453 - accuracy: 0.4534 - val_loss: 1.3160 - val_accuracy: 0.5217\n",
            "Epoch 129/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.3378 - accuracy: 0.4589 - val_loss: 1.3143 - val_accuracy: 0.5121\n",
            "Epoch 130/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.3352 - accuracy: 0.4667 - val_loss: 1.3159 - val_accuracy: 0.5024\n",
            "Epoch 131/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.3110 - accuracy: 0.4716 - val_loss: 1.3262 - val_accuracy: 0.5266\n",
            "Epoch 132/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.3141 - accuracy: 0.4667 - val_loss: 1.3007 - val_accuracy: 0.5314\n",
            "Epoch 133/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.3197 - accuracy: 0.4722 - val_loss: 1.3130 - val_accuracy: 0.5121\n",
            "Epoch 134/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.3038 - accuracy: 0.4752 - val_loss: 1.2952 - val_accuracy: 0.5217\n",
            "Epoch 135/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.3204 - accuracy: 0.4643 - val_loss: 1.2895 - val_accuracy: 0.5459\n",
            "Epoch 136/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.2911 - accuracy: 0.4692 - val_loss: 1.2888 - val_accuracy: 0.5362\n",
            "Epoch 137/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.2783 - accuracy: 0.4933 - val_loss: 1.2717 - val_accuracy: 0.5217\n",
            "Epoch 138/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.3132 - accuracy: 0.4655 - val_loss: 1.2822 - val_accuracy: 0.5266\n",
            "Epoch 139/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.3031 - accuracy: 0.4770 - val_loss: 1.2680 - val_accuracy: 0.5604\n",
            "Epoch 140/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.2892 - accuracy: 0.4909 - val_loss: 1.2666 - val_accuracy: 0.5411\n",
            "Epoch 141/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.2974 - accuracy: 0.4855 - val_loss: 1.2760 - val_accuracy: 0.5459\n",
            "Epoch 142/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.2918 - accuracy: 0.4728 - val_loss: 1.2672 - val_accuracy: 0.5652\n",
            "Epoch 143/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.2822 - accuracy: 0.4716 - val_loss: 1.2652 - val_accuracy: 0.5797\n",
            "Epoch 144/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.2827 - accuracy: 0.4885 - val_loss: 1.2576 - val_accuracy: 0.5604\n",
            "Epoch 145/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.2624 - accuracy: 0.4873 - val_loss: 1.2696 - val_accuracy: 0.5556\n",
            "Epoch 146/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.2654 - accuracy: 0.4855 - val_loss: 1.2514 - val_accuracy: 0.5604\n",
            "Epoch 147/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.2481 - accuracy: 0.4897 - val_loss: 1.2458 - val_accuracy: 0.5652\n",
            "Epoch 148/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.2715 - accuracy: 0.4740 - val_loss: 1.2495 - val_accuracy: 0.5314\n",
            "Epoch 149/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.2356 - accuracy: 0.4940 - val_loss: 1.2477 - val_accuracy: 0.5217\n",
            "Epoch 150/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.2513 - accuracy: 0.4885 - val_loss: 1.2314 - val_accuracy: 0.5749\n",
            "Epoch 151/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.2594 - accuracy: 0.4861 - val_loss: 1.2303 - val_accuracy: 0.5362\n",
            "Epoch 152/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.2454 - accuracy: 0.5109 - val_loss: 1.2281 - val_accuracy: 0.5797\n",
            "Epoch 153/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.2396 - accuracy: 0.4976 - val_loss: 1.2162 - val_accuracy: 0.5942\n",
            "Epoch 154/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.2333 - accuracy: 0.4915 - val_loss: 1.2206 - val_accuracy: 0.5604\n",
            "Epoch 155/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.2404 - accuracy: 0.4982 - val_loss: 1.2085 - val_accuracy: 0.5700\n",
            "Epoch 156/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.2249 - accuracy: 0.5218 - val_loss: 1.2198 - val_accuracy: 0.5604\n",
            "Epoch 157/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.2223 - accuracy: 0.5157 - val_loss: 1.2122 - val_accuracy: 0.5507\n",
            "Epoch 158/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.2252 - accuracy: 0.5175 - val_loss: 1.2045 - val_accuracy: 0.5797\n",
            "Epoch 159/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.2344 - accuracy: 0.4970 - val_loss: 1.2061 - val_accuracy: 0.5556\n",
            "Epoch 160/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.2162 - accuracy: 0.4964 - val_loss: 1.1999 - val_accuracy: 0.5894\n",
            "Epoch 161/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.2138 - accuracy: 0.5054 - val_loss: 1.2026 - val_accuracy: 0.5362\n",
            "Epoch 162/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.2182 - accuracy: 0.5145 - val_loss: 1.2066 - val_accuracy: 0.5362\n",
            "Epoch 163/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.2197 - accuracy: 0.5163 - val_loss: 1.1957 - val_accuracy: 0.5749\n",
            "Epoch 164/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.1890 - accuracy: 0.5218 - val_loss: 1.1767 - val_accuracy: 0.5990\n",
            "Epoch 165/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.1901 - accuracy: 0.5139 - val_loss: 1.1809 - val_accuracy: 0.5507\n",
            "Epoch 166/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.1865 - accuracy: 0.5187 - val_loss: 1.1780 - val_accuracy: 0.5556\n",
            "Epoch 167/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.1758 - accuracy: 0.5326 - val_loss: 1.1826 - val_accuracy: 0.5362\n",
            "Epoch 168/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.1707 - accuracy: 0.5272 - val_loss: 1.1992 - val_accuracy: 0.5121\n",
            "Epoch 169/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.1802 - accuracy: 0.5339 - val_loss: 1.1656 - val_accuracy: 0.5652\n",
            "Epoch 170/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.1842 - accuracy: 0.5145 - val_loss: 1.1755 - val_accuracy: 0.5894\n",
            "Epoch 171/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.1742 - accuracy: 0.5187 - val_loss: 1.1754 - val_accuracy: 0.5556\n",
            "Epoch 172/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.1809 - accuracy: 0.5290 - val_loss: 1.1686 - val_accuracy: 0.5700\n",
            "Epoch 173/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.1792 - accuracy: 0.5187 - val_loss: 1.1589 - val_accuracy: 0.5556\n",
            "Epoch 174/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.1615 - accuracy: 0.5345 - val_loss: 1.1468 - val_accuracy: 0.5749\n",
            "Epoch 175/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.1686 - accuracy: 0.5314 - val_loss: 1.1492 - val_accuracy: 0.5749\n",
            "Epoch 176/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.1538 - accuracy: 0.5393 - val_loss: 1.1409 - val_accuracy: 0.5652\n",
            "Epoch 177/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.1456 - accuracy: 0.5526 - val_loss: 1.1351 - val_accuracy: 0.6135\n",
            "Epoch 178/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.1491 - accuracy: 0.5375 - val_loss: 1.1363 - val_accuracy: 0.5749\n",
            "Epoch 179/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.1578 - accuracy: 0.5339 - val_loss: 1.1439 - val_accuracy: 0.5652\n",
            "Epoch 180/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.1412 - accuracy: 0.5357 - val_loss: 1.1318 - val_accuracy: 0.5894\n",
            "Epoch 181/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.1283 - accuracy: 0.5544 - val_loss: 1.1266 - val_accuracy: 0.5942\n",
            "Epoch 182/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.1175 - accuracy: 0.5508 - val_loss: 1.1224 - val_accuracy: 0.5749\n",
            "Epoch 183/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.1326 - accuracy: 0.5496 - val_loss: 1.1380 - val_accuracy: 0.5459\n",
            "Epoch 184/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.1356 - accuracy: 0.5435 - val_loss: 1.1204 - val_accuracy: 0.5797\n",
            "Epoch 185/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.1213 - accuracy: 0.5508 - val_loss: 1.1188 - val_accuracy: 0.5700\n",
            "Epoch 186/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.1352 - accuracy: 0.5453 - val_loss: 1.1180 - val_accuracy: 0.6184\n",
            "Epoch 187/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.1172 - accuracy: 0.5599 - val_loss: 1.1090 - val_accuracy: 0.5990\n",
            "Epoch 188/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.1122 - accuracy: 0.5532 - val_loss: 1.1164 - val_accuracy: 0.5797\n",
            "Epoch 189/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.1359 - accuracy: 0.5411 - val_loss: 1.1072 - val_accuracy: 0.5942\n",
            "Epoch 190/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.1047 - accuracy: 0.5647 - val_loss: 1.1078 - val_accuracy: 0.6184\n",
            "Epoch 191/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.1079 - accuracy: 0.5617 - val_loss: 1.1162 - val_accuracy: 0.5942\n",
            "Epoch 192/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.1217 - accuracy: 0.5490 - val_loss: 1.1140 - val_accuracy: 0.5942\n",
            "Epoch 193/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.1127 - accuracy: 0.5544 - val_loss: 1.1113 - val_accuracy: 0.5990\n",
            "Epoch 194/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.1144 - accuracy: 0.5502 - val_loss: 1.1045 - val_accuracy: 0.6135\n",
            "Epoch 195/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.1107 - accuracy: 0.5411 - val_loss: 1.1221 - val_accuracy: 0.5894\n",
            "Epoch 196/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0937 - accuracy: 0.5593 - val_loss: 1.1003 - val_accuracy: 0.6087\n",
            "Epoch 197/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.1021 - accuracy: 0.5453 - val_loss: 1.0998 - val_accuracy: 0.6087\n",
            "Epoch 198/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0847 - accuracy: 0.5550 - val_loss: 1.0895 - val_accuracy: 0.6087\n",
            "Epoch 199/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.1033 - accuracy: 0.5574 - val_loss: 1.0880 - val_accuracy: 0.6039\n",
            "Epoch 200/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0824 - accuracy: 0.5556 - val_loss: 1.0922 - val_accuracy: 0.5845\n",
            "Epoch 201/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0664 - accuracy: 0.5556 - val_loss: 1.0906 - val_accuracy: 0.6329\n",
            "Epoch 202/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0910 - accuracy: 0.5514 - val_loss: 1.0937 - val_accuracy: 0.5845\n",
            "Epoch 203/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0695 - accuracy: 0.5786 - val_loss: 1.0945 - val_accuracy: 0.5797\n",
            "Epoch 204/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.0569 - accuracy: 0.5792 - val_loss: 1.0910 - val_accuracy: 0.5652\n",
            "Epoch 205/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0848 - accuracy: 0.5562 - val_loss: 1.0703 - val_accuracy: 0.6087\n",
            "Epoch 206/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.0612 - accuracy: 0.5744 - val_loss: 1.0836 - val_accuracy: 0.5845\n",
            "Epoch 207/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.0553 - accuracy: 0.5701 - val_loss: 1.0728 - val_accuracy: 0.6232\n",
            "Epoch 208/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.0723 - accuracy: 0.5653 - val_loss: 1.0771 - val_accuracy: 0.5845\n",
            "Epoch 209/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0534 - accuracy: 0.5713 - val_loss: 1.0573 - val_accuracy: 0.6232\n",
            "Epoch 210/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.0771 - accuracy: 0.5774 - val_loss: 1.0608 - val_accuracy: 0.6280\n",
            "Epoch 211/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.0617 - accuracy: 0.5798 - val_loss: 1.0689 - val_accuracy: 0.6184\n",
            "Epoch 212/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.0518 - accuracy: 0.5719 - val_loss: 1.0475 - val_accuracy: 0.6377\n",
            "Epoch 213/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.0285 - accuracy: 0.5846 - val_loss: 1.0552 - val_accuracy: 0.6087\n",
            "Epoch 214/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.0574 - accuracy: 0.5786 - val_loss: 1.0582 - val_accuracy: 0.5990\n",
            "Epoch 215/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0505 - accuracy: 0.5701 - val_loss: 1.0450 - val_accuracy: 0.6377\n",
            "Epoch 216/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0512 - accuracy: 0.5762 - val_loss: 1.0564 - val_accuracy: 0.5894\n",
            "Epoch 217/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.0568 - accuracy: 0.5623 - val_loss: 1.0319 - val_accuracy: 0.6570\n",
            "Epoch 218/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.0587 - accuracy: 0.5774 - val_loss: 1.0411 - val_accuracy: 0.6184\n",
            "Epoch 219/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.0462 - accuracy: 0.5798 - val_loss: 1.0333 - val_accuracy: 0.6135\n",
            "Epoch 220/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0396 - accuracy: 0.5895 - val_loss: 1.0382 - val_accuracy: 0.6135\n",
            "Epoch 221/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0345 - accuracy: 0.5828 - val_loss: 1.0463 - val_accuracy: 0.6039\n",
            "Epoch 222/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.0077 - accuracy: 0.6034 - val_loss: 1.0227 - val_accuracy: 0.6280\n",
            "Epoch 223/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0393 - accuracy: 0.5907 - val_loss: 1.0357 - val_accuracy: 0.6039\n",
            "Epoch 224/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0217 - accuracy: 0.5955 - val_loss: 1.0220 - val_accuracy: 0.6329\n",
            "Epoch 225/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0277 - accuracy: 0.5889 - val_loss: 1.0152 - val_accuracy: 0.6039\n",
            "Epoch 226/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.0499 - accuracy: 0.5822 - val_loss: 1.0131 - val_accuracy: 0.6473\n",
            "Epoch 227/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.0260 - accuracy: 0.5834 - val_loss: 1.0098 - val_accuracy: 0.6280\n",
            "Epoch 228/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0248 - accuracy: 0.5992 - val_loss: 1.0177 - val_accuracy: 0.6329\n",
            "Epoch 229/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0149 - accuracy: 0.5907 - val_loss: 1.0168 - val_accuracy: 0.6473\n",
            "Epoch 230/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.0015 - accuracy: 0.6010 - val_loss: 1.0168 - val_accuracy: 0.6377\n",
            "Epoch 231/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.0223 - accuracy: 0.6076 - val_loss: 1.0141 - val_accuracy: 0.6184\n",
            "Epoch 232/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.0335 - accuracy: 0.5774 - val_loss: 0.9954 - val_accuracy: 0.6522\n",
            "Epoch 233/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0091 - accuracy: 0.6004 - val_loss: 1.0094 - val_accuracy: 0.6280\n",
            "Epoch 234/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0041 - accuracy: 0.5919 - val_loss: 0.9926 - val_accuracy: 0.6570\n",
            "Epoch 235/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0036 - accuracy: 0.5949 - val_loss: 0.9898 - val_accuracy: 0.6425\n",
            "Epoch 236/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.0026 - accuracy: 0.6052 - val_loss: 0.9977 - val_accuracy: 0.6715\n",
            "Epoch 237/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.9810 - accuracy: 0.5998 - val_loss: 1.0066 - val_accuracy: 0.6618\n",
            "Epoch 238/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.0050 - accuracy: 0.5979 - val_loss: 0.9978 - val_accuracy: 0.6425\n",
            "Epoch 239/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9883 - accuracy: 0.6052 - val_loss: 0.9902 - val_accuracy: 0.6135\n",
            "Epoch 240/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9876 - accuracy: 0.6100 - val_loss: 1.0082 - val_accuracy: 0.6280\n",
            "Epoch 241/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.9928 - accuracy: 0.6058 - val_loss: 0.9932 - val_accuracy: 0.6329\n",
            "Epoch 242/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0115 - accuracy: 0.5967 - val_loss: 0.9860 - val_accuracy: 0.6570\n",
            "Epoch 243/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9883 - accuracy: 0.6125 - val_loss: 0.9854 - val_accuracy: 0.6377\n",
            "Epoch 244/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.9888 - accuracy: 0.6040 - val_loss: 0.9943 - val_accuracy: 0.6280\n",
            "Epoch 245/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.9942 - accuracy: 0.5992 - val_loss: 0.9767 - val_accuracy: 0.6473\n",
            "Epoch 246/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.9729 - accuracy: 0.6052 - val_loss: 0.9755 - val_accuracy: 0.6618\n",
            "Epoch 247/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9841 - accuracy: 0.6185 - val_loss: 0.9752 - val_accuracy: 0.6715\n",
            "Epoch 248/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.9631 - accuracy: 0.5992 - val_loss: 0.9636 - val_accuracy: 0.6618\n",
            "Epoch 249/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.9779 - accuracy: 0.6016 - val_loss: 0.9882 - val_accuracy: 0.6280\n",
            "Epoch 250/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9707 - accuracy: 0.6082 - val_loss: 0.9656 - val_accuracy: 0.6860\n",
            "Epoch 251/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.9795 - accuracy: 0.6022 - val_loss: 0.9809 - val_accuracy: 0.6522\n",
            "Epoch 252/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9452 - accuracy: 0.6252 - val_loss: 0.9672 - val_accuracy: 0.6473\n",
            "Epoch 253/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9634 - accuracy: 0.6155 - val_loss: 0.9787 - val_accuracy: 0.6473\n",
            "Epoch 254/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9630 - accuracy: 0.6221 - val_loss: 0.9609 - val_accuracy: 0.6522\n",
            "Epoch 255/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.9664 - accuracy: 0.6125 - val_loss: 0.9687 - val_accuracy: 0.6377\n",
            "Epoch 256/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.9750 - accuracy: 0.6034 - val_loss: 0.9637 - val_accuracy: 0.6715\n",
            "Epoch 257/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9543 - accuracy: 0.6155 - val_loss: 0.9763 - val_accuracy: 0.6473\n",
            "Epoch 258/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.9596 - accuracy: 0.6161 - val_loss: 0.9525 - val_accuracy: 0.6618\n",
            "Epoch 259/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9249 - accuracy: 0.6312 - val_loss: 0.9724 - val_accuracy: 0.6329\n",
            "Epoch 260/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.9322 - accuracy: 0.6294 - val_loss: 0.9697 - val_accuracy: 0.6329\n",
            "Epoch 261/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9740 - accuracy: 0.6125 - val_loss: 0.9602 - val_accuracy: 0.6377\n",
            "Epoch 262/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9384 - accuracy: 0.6215 - val_loss: 0.9629 - val_accuracy: 0.6473\n",
            "Epoch 263/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9410 - accuracy: 0.6336 - val_loss: 0.9593 - val_accuracy: 0.6570\n",
            "Epoch 264/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9476 - accuracy: 0.6203 - val_loss: 0.9608 - val_accuracy: 0.6377\n",
            "Epoch 265/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9465 - accuracy: 0.6221 - val_loss: 0.9494 - val_accuracy: 0.6570\n",
            "Epoch 266/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9488 - accuracy: 0.6221 - val_loss: 0.9383 - val_accuracy: 0.6763\n",
            "Epoch 267/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.9590 - accuracy: 0.6112 - val_loss: 0.9497 - val_accuracy: 0.6570\n",
            "Epoch 268/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.9419 - accuracy: 0.6324 - val_loss: 0.9621 - val_accuracy: 0.6473\n",
            "Epoch 269/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9589 - accuracy: 0.5973 - val_loss: 0.9402 - val_accuracy: 0.6812\n",
            "Epoch 270/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.9617 - accuracy: 0.6179 - val_loss: 0.9467 - val_accuracy: 0.6522\n",
            "Epoch 271/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.9392 - accuracy: 0.6215 - val_loss: 0.9404 - val_accuracy: 0.6618\n",
            "Epoch 272/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.9156 - accuracy: 0.6354 - val_loss: 0.9502 - val_accuracy: 0.6473\n",
            "Epoch 273/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.9114 - accuracy: 0.6427 - val_loss: 0.9433 - val_accuracy: 0.6425\n",
            "Epoch 274/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.9264 - accuracy: 0.6306 - val_loss: 0.9568 - val_accuracy: 0.6329\n",
            "Epoch 275/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.9091 - accuracy: 0.6221 - val_loss: 0.9434 - val_accuracy: 0.6329\n",
            "Epoch 276/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9323 - accuracy: 0.6330 - val_loss: 0.9290 - val_accuracy: 0.6860\n",
            "Epoch 277/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9367 - accuracy: 0.6294 - val_loss: 0.9399 - val_accuracy: 0.6473\n",
            "Epoch 278/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9384 - accuracy: 0.6191 - val_loss: 0.9341 - val_accuracy: 0.6618\n",
            "Epoch 279/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9205 - accuracy: 0.6282 - val_loss: 0.9340 - val_accuracy: 0.6763\n",
            "Epoch 280/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9303 - accuracy: 0.6288 - val_loss: 0.9466 - val_accuracy: 0.6329\n",
            "Epoch 281/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9286 - accuracy: 0.6336 - val_loss: 0.9379 - val_accuracy: 0.6618\n",
            "Epoch 282/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9035 - accuracy: 0.6397 - val_loss: 0.9286 - val_accuracy: 0.6715\n",
            "Epoch 283/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9211 - accuracy: 0.6258 - val_loss: 0.9169 - val_accuracy: 0.6667\n",
            "Epoch 284/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9169 - accuracy: 0.6409 - val_loss: 0.9189 - val_accuracy: 0.6715\n",
            "Epoch 285/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8962 - accuracy: 0.6445 - val_loss: 0.9115 - val_accuracy: 0.6618\n",
            "Epoch 286/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.9042 - accuracy: 0.6421 - val_loss: 0.9171 - val_accuracy: 0.6667\n",
            "Epoch 287/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.9039 - accuracy: 0.6554 - val_loss: 0.9300 - val_accuracy: 0.6618\n",
            "Epoch 288/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9087 - accuracy: 0.6415 - val_loss: 0.9302 - val_accuracy: 0.6425\n",
            "Epoch 289/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.9078 - accuracy: 0.6469 - val_loss: 0.9013 - val_accuracy: 0.6763\n",
            "Epoch 290/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.9122 - accuracy: 0.6403 - val_loss: 0.9032 - val_accuracy: 0.6812\n",
            "Epoch 291/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9071 - accuracy: 0.6415 - val_loss: 0.9282 - val_accuracy: 0.6425\n",
            "Epoch 292/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9125 - accuracy: 0.6270 - val_loss: 0.9147 - val_accuracy: 0.6618\n",
            "Epoch 293/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8762 - accuracy: 0.6572 - val_loss: 0.9065 - val_accuracy: 0.6570\n",
            "Epoch 294/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.8816 - accuracy: 0.6554 - val_loss: 0.8992 - val_accuracy: 0.6715\n",
            "Epoch 295/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9048 - accuracy: 0.6457 - val_loss: 0.9012 - val_accuracy: 0.6715\n",
            "Epoch 296/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8987 - accuracy: 0.6487 - val_loss: 0.8985 - val_accuracy: 0.6763\n",
            "Epoch 297/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9043 - accuracy: 0.6378 - val_loss: 0.9078 - val_accuracy: 0.6570\n",
            "Epoch 298/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.8867 - accuracy: 0.6457 - val_loss: 0.9083 - val_accuracy: 0.6715\n",
            "Epoch 299/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8899 - accuracy: 0.6475 - val_loss: 0.8938 - val_accuracy: 0.6715\n",
            "Epoch 300/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.8859 - accuracy: 0.6518 - val_loss: 0.8902 - val_accuracy: 0.7005\n",
            "Epoch 301/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.8871 - accuracy: 0.6554 - val_loss: 0.8885 - val_accuracy: 0.7101\n",
            "Epoch 302/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.8918 - accuracy: 0.6524 - val_loss: 0.8844 - val_accuracy: 0.6763\n",
            "Epoch 303/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9001 - accuracy: 0.6421 - val_loss: 0.8977 - val_accuracy: 0.6570\n",
            "Epoch 304/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8754 - accuracy: 0.6433 - val_loss: 0.8914 - val_accuracy: 0.6763\n",
            "Epoch 305/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8868 - accuracy: 0.6566 - val_loss: 0.8958 - val_accuracy: 0.6618\n",
            "Epoch 306/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8881 - accuracy: 0.6469 - val_loss: 0.8975 - val_accuracy: 0.6522\n",
            "Epoch 307/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.8480 - accuracy: 0.6753 - val_loss: 0.8866 - val_accuracy: 0.6763\n",
            "Epoch 308/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.8764 - accuracy: 0.6578 - val_loss: 0.8916 - val_accuracy: 0.6667\n",
            "Epoch 309/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.8432 - accuracy: 0.6657 - val_loss: 0.8995 - val_accuracy: 0.6425\n",
            "Epoch 310/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.8617 - accuracy: 0.6505 - val_loss: 0.8877 - val_accuracy: 0.6570\n",
            "Epoch 311/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.8763 - accuracy: 0.6505 - val_loss: 0.8860 - val_accuracy: 0.6570\n",
            "Epoch 312/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.8777 - accuracy: 0.6469 - val_loss: 0.8894 - val_accuracy: 0.6473\n",
            "Epoch 313/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.8483 - accuracy: 0.6505 - val_loss: 0.9070 - val_accuracy: 0.6473\n",
            "Epoch 314/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8861 - accuracy: 0.6336 - val_loss: 0.8776 - val_accuracy: 0.6812\n",
            "Epoch 315/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8635 - accuracy: 0.6620 - val_loss: 0.8864 - val_accuracy: 0.6763\n",
            "Epoch 316/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.8773 - accuracy: 0.6548 - val_loss: 0.8860 - val_accuracy: 0.6570\n",
            "Epoch 317/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.8359 - accuracy: 0.6711 - val_loss: 0.8696 - val_accuracy: 0.7005\n",
            "Epoch 318/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8558 - accuracy: 0.6644 - val_loss: 0.8775 - val_accuracy: 0.6812\n",
            "Epoch 319/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8400 - accuracy: 0.6663 - val_loss: 0.8759 - val_accuracy: 0.6957\n",
            "Epoch 320/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8480 - accuracy: 0.6735 - val_loss: 0.8677 - val_accuracy: 0.6812\n",
            "Epoch 321/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.8504 - accuracy: 0.6693 - val_loss: 0.8765 - val_accuracy: 0.6618\n",
            "Epoch 322/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8527 - accuracy: 0.6524 - val_loss: 0.9055 - val_accuracy: 0.6618\n",
            "Epoch 323/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8602 - accuracy: 0.6741 - val_loss: 0.8785 - val_accuracy: 0.6618\n",
            "Epoch 324/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8496 - accuracy: 0.6560 - val_loss: 0.8820 - val_accuracy: 0.6522\n",
            "Epoch 325/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8302 - accuracy: 0.6790 - val_loss: 0.8594 - val_accuracy: 0.6908\n",
            "Epoch 326/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8425 - accuracy: 0.6651 - val_loss: 0.8703 - val_accuracy: 0.6957\n",
            "Epoch 327/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8194 - accuracy: 0.6747 - val_loss: 0.8488 - val_accuracy: 0.7150\n",
            "Epoch 328/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8490 - accuracy: 0.6511 - val_loss: 0.8505 - val_accuracy: 0.7198\n",
            "Epoch 329/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8418 - accuracy: 0.6693 - val_loss: 0.8716 - val_accuracy: 0.6667\n",
            "Epoch 330/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8563 - accuracy: 0.6620 - val_loss: 0.8676 - val_accuracy: 0.6667\n",
            "Epoch 331/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8426 - accuracy: 0.6699 - val_loss: 0.8825 - val_accuracy: 0.6473\n",
            "Epoch 332/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8383 - accuracy: 0.6717 - val_loss: 0.8667 - val_accuracy: 0.6618\n",
            "Epoch 333/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8376 - accuracy: 0.6705 - val_loss: 0.8540 - val_accuracy: 0.7150\n",
            "Epoch 334/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.8319 - accuracy: 0.6790 - val_loss: 0.8531 - val_accuracy: 0.6860\n",
            "Epoch 335/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8289 - accuracy: 0.6778 - val_loss: 0.8441 - val_accuracy: 0.6763\n",
            "Epoch 336/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8287 - accuracy: 0.6717 - val_loss: 0.8474 - val_accuracy: 0.7005\n",
            "Epoch 337/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8314 - accuracy: 0.6699 - val_loss: 0.8585 - val_accuracy: 0.6812\n",
            "Epoch 338/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.8348 - accuracy: 0.6687 - val_loss: 0.8499 - val_accuracy: 0.7005\n",
            "Epoch 339/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8487 - accuracy: 0.6705 - val_loss: 0.8456 - val_accuracy: 0.6957\n",
            "Epoch 340/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8280 - accuracy: 0.6693 - val_loss: 0.8673 - val_accuracy: 0.6667\n",
            "Epoch 341/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8340 - accuracy: 0.6753 - val_loss: 0.8527 - val_accuracy: 0.6908\n",
            "Epoch 342/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.8205 - accuracy: 0.6820 - val_loss: 0.8486 - val_accuracy: 0.6957\n",
            "Epoch 343/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.8184 - accuracy: 0.6826 - val_loss: 0.8400 - val_accuracy: 0.6957\n",
            "Epoch 344/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.8302 - accuracy: 0.6644 - val_loss: 0.8424 - val_accuracy: 0.7101\n",
            "Epoch 345/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8237 - accuracy: 0.6717 - val_loss: 0.8478 - val_accuracy: 0.6812\n",
            "Epoch 346/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8013 - accuracy: 0.6856 - val_loss: 0.8357 - val_accuracy: 0.7053\n",
            "Epoch 347/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8075 - accuracy: 0.6898 - val_loss: 0.8224 - val_accuracy: 0.7053\n",
            "Epoch 348/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.8203 - accuracy: 0.6808 - val_loss: 0.8309 - val_accuracy: 0.7053\n",
            "Epoch 349/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8319 - accuracy: 0.6747 - val_loss: 0.8270 - val_accuracy: 0.6908\n",
            "Epoch 350/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8189 - accuracy: 0.6880 - val_loss: 0.8457 - val_accuracy: 0.6812\n",
            "Epoch 351/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.8161 - accuracy: 0.6747 - val_loss: 0.8366 - val_accuracy: 0.6957\n",
            "Epoch 352/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.8160 - accuracy: 0.6874 - val_loss: 0.8249 - val_accuracy: 0.7198\n",
            "Epoch 353/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.8144 - accuracy: 0.6784 - val_loss: 0.8255 - val_accuracy: 0.7150\n",
            "Epoch 354/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8138 - accuracy: 0.6771 - val_loss: 0.8226 - val_accuracy: 0.7053\n",
            "Epoch 355/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7868 - accuracy: 0.6832 - val_loss: 0.8416 - val_accuracy: 0.6715\n",
            "Epoch 356/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7926 - accuracy: 0.6844 - val_loss: 0.8373 - val_accuracy: 0.6957\n",
            "Epoch 357/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7897 - accuracy: 0.6844 - val_loss: 0.8462 - val_accuracy: 0.6618\n",
            "Epoch 358/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7876 - accuracy: 0.6850 - val_loss: 0.8261 - val_accuracy: 0.6812\n",
            "Epoch 359/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7871 - accuracy: 0.6856 - val_loss: 0.8320 - val_accuracy: 0.6860\n",
            "Epoch 360/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8100 - accuracy: 0.6657 - val_loss: 0.8265 - val_accuracy: 0.7053\n",
            "Epoch 361/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.7899 - accuracy: 0.6886 - val_loss: 0.8224 - val_accuracy: 0.7053\n",
            "Epoch 362/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7860 - accuracy: 0.6844 - val_loss: 0.8189 - val_accuracy: 0.6908\n",
            "Epoch 363/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.7827 - accuracy: 0.6923 - val_loss: 0.8252 - val_accuracy: 0.6812\n",
            "Epoch 364/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7764 - accuracy: 0.7019 - val_loss: 0.8336 - val_accuracy: 0.6908\n",
            "Epoch 365/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.7998 - accuracy: 0.6862 - val_loss: 0.8254 - val_accuracy: 0.7005\n",
            "Epoch 366/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.8031 - accuracy: 0.6771 - val_loss: 0.8158 - val_accuracy: 0.7053\n",
            "Epoch 367/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7961 - accuracy: 0.6856 - val_loss: 0.8262 - val_accuracy: 0.7101\n",
            "Epoch 368/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7820 - accuracy: 0.6977 - val_loss: 0.8077 - val_accuracy: 0.6957\n",
            "Epoch 369/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7679 - accuracy: 0.7044 - val_loss: 0.8302 - val_accuracy: 0.6908\n",
            "Epoch 370/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7879 - accuracy: 0.6892 - val_loss: 0.8298 - val_accuracy: 0.7005\n",
            "Epoch 371/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7703 - accuracy: 0.6941 - val_loss: 0.8349 - val_accuracy: 0.6957\n",
            "Epoch 372/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7874 - accuracy: 0.6820 - val_loss: 0.8267 - val_accuracy: 0.6860\n",
            "Epoch 373/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.7873 - accuracy: 0.6959 - val_loss: 0.8195 - val_accuracy: 0.7053\n",
            "Epoch 374/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7823 - accuracy: 0.6820 - val_loss: 0.8164 - val_accuracy: 0.6908\n",
            "Epoch 375/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7807 - accuracy: 0.6953 - val_loss: 0.8202 - val_accuracy: 0.7053\n",
            "Epoch 376/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7944 - accuracy: 0.6904 - val_loss: 0.8099 - val_accuracy: 0.7053\n",
            "Epoch 377/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7761 - accuracy: 0.6886 - val_loss: 0.8195 - val_accuracy: 0.6908\n",
            "Epoch 378/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7655 - accuracy: 0.6959 - val_loss: 0.8256 - val_accuracy: 0.6957\n",
            "Epoch 379/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7720 - accuracy: 0.6886 - val_loss: 0.8257 - val_accuracy: 0.6763\n",
            "Epoch 380/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7358 - accuracy: 0.7007 - val_loss: 0.8054 - val_accuracy: 0.7198\n",
            "Epoch 381/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7570 - accuracy: 0.7019 - val_loss: 0.8103 - val_accuracy: 0.7053\n",
            "Epoch 382/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7578 - accuracy: 0.6917 - val_loss: 0.8190 - val_accuracy: 0.6908\n",
            "Epoch 383/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.7639 - accuracy: 0.7056 - val_loss: 0.8141 - val_accuracy: 0.7053\n",
            "Epoch 384/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7452 - accuracy: 0.7001 - val_loss: 0.8185 - val_accuracy: 0.7101\n",
            "Epoch 385/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7633 - accuracy: 0.6971 - val_loss: 0.8070 - val_accuracy: 0.6957\n",
            "Epoch 386/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.7834 - accuracy: 0.6953 - val_loss: 0.8115 - val_accuracy: 0.6812\n",
            "Epoch 387/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.7573 - accuracy: 0.7128 - val_loss: 0.8136 - val_accuracy: 0.6763\n",
            "Epoch 388/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7692 - accuracy: 0.7044 - val_loss: 0.8412 - val_accuracy: 0.6763\n",
            "Epoch 389/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7557 - accuracy: 0.7122 - val_loss: 0.8236 - val_accuracy: 0.6957\n",
            "Epoch 390/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.7485 - accuracy: 0.7001 - val_loss: 0.7993 - val_accuracy: 0.7246\n",
            "Epoch 391/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7415 - accuracy: 0.7140 - val_loss: 0.8228 - val_accuracy: 0.6812\n",
            "Epoch 392/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7700 - accuracy: 0.6886 - val_loss: 0.8079 - val_accuracy: 0.7053\n",
            "Epoch 393/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7465 - accuracy: 0.7098 - val_loss: 0.8057 - val_accuracy: 0.7053\n",
            "Epoch 394/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7470 - accuracy: 0.6947 - val_loss: 0.8059 - val_accuracy: 0.7150\n",
            "Epoch 395/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7498 - accuracy: 0.6965 - val_loss: 0.8062 - val_accuracy: 0.7150\n",
            "Epoch 396/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7601 - accuracy: 0.6929 - val_loss: 0.8163 - val_accuracy: 0.6957\n",
            "Epoch 397/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7232 - accuracy: 0.7195 - val_loss: 0.8090 - val_accuracy: 0.7150\n",
            "Epoch 398/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7658 - accuracy: 0.6898 - val_loss: 0.8042 - val_accuracy: 0.7005\n",
            "Epoch 399/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7432 - accuracy: 0.7068 - val_loss: 0.7866 - val_accuracy: 0.7005\n",
            "Epoch 400/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7515 - accuracy: 0.6983 - val_loss: 0.7988 - val_accuracy: 0.7101\n",
            "Epoch 401/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7329 - accuracy: 0.7189 - val_loss: 0.8193 - val_accuracy: 0.7005\n",
            "Epoch 402/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7494 - accuracy: 0.7080 - val_loss: 0.7900 - val_accuracy: 0.7101\n",
            "Epoch 403/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7429 - accuracy: 0.7128 - val_loss: 0.8068 - val_accuracy: 0.6957\n",
            "Epoch 404/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7476 - accuracy: 0.6850 - val_loss: 0.8011 - val_accuracy: 0.6812\n",
            "Epoch 405/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.7285 - accuracy: 0.7122 - val_loss: 0.7851 - val_accuracy: 0.6908\n",
            "Epoch 406/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.7349 - accuracy: 0.7122 - val_loss: 0.7810 - val_accuracy: 0.7343\n",
            "Epoch 407/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7546 - accuracy: 0.7098 - val_loss: 0.7946 - val_accuracy: 0.6908\n",
            "Epoch 408/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7384 - accuracy: 0.6929 - val_loss: 0.7898 - val_accuracy: 0.7198\n",
            "Epoch 409/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7313 - accuracy: 0.7183 - val_loss: 0.7800 - val_accuracy: 0.7150\n",
            "Epoch 410/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7524 - accuracy: 0.6953 - val_loss: 0.7907 - val_accuracy: 0.7005\n",
            "Epoch 411/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7349 - accuracy: 0.7050 - val_loss: 0.7944 - val_accuracy: 0.7053\n",
            "Epoch 412/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7175 - accuracy: 0.7170 - val_loss: 0.7721 - val_accuracy: 0.7295\n",
            "Epoch 413/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7299 - accuracy: 0.6983 - val_loss: 0.7951 - val_accuracy: 0.7005\n",
            "Epoch 414/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7328 - accuracy: 0.7019 - val_loss: 0.7821 - val_accuracy: 0.6860\n",
            "Epoch 415/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7196 - accuracy: 0.7164 - val_loss: 0.7836 - val_accuracy: 0.7246\n",
            "Epoch 416/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.7134 - accuracy: 0.7164 - val_loss: 0.8015 - val_accuracy: 0.7150\n",
            "Epoch 417/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7431 - accuracy: 0.7170 - val_loss: 0.7845 - val_accuracy: 0.7295\n",
            "Epoch 418/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7209 - accuracy: 0.7152 - val_loss: 0.7913 - val_accuracy: 0.6763\n",
            "Epoch 419/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7353 - accuracy: 0.7056 - val_loss: 0.7923 - val_accuracy: 0.6860\n",
            "Epoch 420/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7191 - accuracy: 0.7140 - val_loss: 0.7762 - val_accuracy: 0.7198\n",
            "Epoch 421/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7059 - accuracy: 0.7219 - val_loss: 0.7675 - val_accuracy: 0.7150\n",
            "Epoch 422/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.7297 - accuracy: 0.7110 - val_loss: 0.7720 - val_accuracy: 0.7198\n",
            "Epoch 423/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7150 - accuracy: 0.7164 - val_loss: 0.7572 - val_accuracy: 0.7150\n",
            "Epoch 424/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7254 - accuracy: 0.7007 - val_loss: 0.7930 - val_accuracy: 0.6957\n",
            "Epoch 425/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7238 - accuracy: 0.7098 - val_loss: 0.7733 - val_accuracy: 0.7295\n",
            "Epoch 426/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7290 - accuracy: 0.7110 - val_loss: 0.7858 - val_accuracy: 0.6908\n",
            "Epoch 427/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7373 - accuracy: 0.7031 - val_loss: 0.7747 - val_accuracy: 0.7343\n",
            "Epoch 428/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7228 - accuracy: 0.7080 - val_loss: 0.7701 - val_accuracy: 0.7343\n",
            "Epoch 429/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7198 - accuracy: 0.7110 - val_loss: 0.7739 - val_accuracy: 0.7295\n",
            "Epoch 430/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7189 - accuracy: 0.7098 - val_loss: 0.7640 - val_accuracy: 0.7391\n",
            "Epoch 431/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7145 - accuracy: 0.7086 - val_loss: 0.7757 - val_accuracy: 0.7343\n",
            "Epoch 432/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7228 - accuracy: 0.7110 - val_loss: 0.7899 - val_accuracy: 0.7198\n",
            "Epoch 433/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7201 - accuracy: 0.7231 - val_loss: 0.7715 - val_accuracy: 0.7150\n",
            "Epoch 434/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7012 - accuracy: 0.7219 - val_loss: 0.7747 - val_accuracy: 0.7053\n",
            "Epoch 435/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7155 - accuracy: 0.7255 - val_loss: 0.7756 - val_accuracy: 0.7005\n",
            "Epoch 436/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7199 - accuracy: 0.7013 - val_loss: 0.7782 - val_accuracy: 0.6957\n",
            "Epoch 437/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7029 - accuracy: 0.7164 - val_loss: 0.7754 - val_accuracy: 0.6908\n",
            "Epoch 438/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7103 - accuracy: 0.6977 - val_loss: 0.7733 - val_accuracy: 0.6957\n",
            "Epoch 439/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7050 - accuracy: 0.7237 - val_loss: 0.7619 - val_accuracy: 0.7295\n",
            "Epoch 440/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7103 - accuracy: 0.7164 - val_loss: 0.7665 - val_accuracy: 0.7246\n",
            "Epoch 441/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6980 - accuracy: 0.7297 - val_loss: 0.7591 - val_accuracy: 0.7343\n",
            "Epoch 442/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6934 - accuracy: 0.7273 - val_loss: 0.7665 - val_accuracy: 0.7246\n",
            "Epoch 443/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6904 - accuracy: 0.7255 - val_loss: 0.7548 - val_accuracy: 0.7295\n",
            "Epoch 444/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6986 - accuracy: 0.7297 - val_loss: 0.7634 - val_accuracy: 0.7198\n",
            "Epoch 445/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7024 - accuracy: 0.7255 - val_loss: 0.7622 - val_accuracy: 0.7101\n",
            "Epoch 446/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7100 - accuracy: 0.7177 - val_loss: 0.7707 - val_accuracy: 0.7295\n",
            "Epoch 447/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6928 - accuracy: 0.7249 - val_loss: 0.7539 - val_accuracy: 0.7343\n",
            "Epoch 448/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6873 - accuracy: 0.7189 - val_loss: 0.7540 - val_accuracy: 0.7391\n",
            "Epoch 449/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6953 - accuracy: 0.7328 - val_loss: 0.7693 - val_accuracy: 0.7150\n",
            "Epoch 450/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6886 - accuracy: 0.7304 - val_loss: 0.7633 - val_accuracy: 0.7198\n",
            "Epoch 451/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6762 - accuracy: 0.7285 - val_loss: 0.7788 - val_accuracy: 0.7053\n",
            "Epoch 452/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6818 - accuracy: 0.7195 - val_loss: 0.7607 - val_accuracy: 0.7343\n",
            "Epoch 453/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6937 - accuracy: 0.7310 - val_loss: 0.7694 - val_accuracy: 0.7150\n",
            "Epoch 454/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6900 - accuracy: 0.7322 - val_loss: 0.7618 - val_accuracy: 0.7053\n",
            "Epoch 455/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6853 - accuracy: 0.7285 - val_loss: 0.7550 - val_accuracy: 0.7198\n",
            "Epoch 456/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6963 - accuracy: 0.7328 - val_loss: 0.7652 - val_accuracy: 0.7246\n",
            "Epoch 457/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6733 - accuracy: 0.7382 - val_loss: 0.7508 - val_accuracy: 0.7295\n",
            "Epoch 458/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6733 - accuracy: 0.7388 - val_loss: 0.7556 - val_accuracy: 0.7150\n",
            "Epoch 459/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6751 - accuracy: 0.7310 - val_loss: 0.7780 - val_accuracy: 0.7053\n",
            "Epoch 460/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6678 - accuracy: 0.7443 - val_loss: 0.7838 - val_accuracy: 0.6908\n",
            "Epoch 461/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6666 - accuracy: 0.7310 - val_loss: 0.7526 - val_accuracy: 0.7198\n",
            "Epoch 462/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6900 - accuracy: 0.7195 - val_loss: 0.7382 - val_accuracy: 0.7198\n",
            "Epoch 463/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6543 - accuracy: 0.7424 - val_loss: 0.7346 - val_accuracy: 0.7295\n",
            "Epoch 464/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6720 - accuracy: 0.7285 - val_loss: 0.7431 - val_accuracy: 0.7198\n",
            "Epoch 465/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6739 - accuracy: 0.7412 - val_loss: 0.7559 - val_accuracy: 0.7246\n",
            "Epoch 466/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.7195 - val_loss: 0.7504 - val_accuracy: 0.7198\n",
            "Epoch 467/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6728 - accuracy: 0.7207 - val_loss: 0.7338 - val_accuracy: 0.7246\n",
            "Epoch 468/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6762 - accuracy: 0.7291 - val_loss: 0.7727 - val_accuracy: 0.7150\n",
            "Epoch 469/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6495 - accuracy: 0.7503 - val_loss: 0.7601 - val_accuracy: 0.7150\n",
            "Epoch 470/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6610 - accuracy: 0.7418 - val_loss: 0.7485 - val_accuracy: 0.7440\n",
            "Epoch 471/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6697 - accuracy: 0.7376 - val_loss: 0.7489 - val_accuracy: 0.7246\n",
            "Epoch 472/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6698 - accuracy: 0.7340 - val_loss: 0.7355 - val_accuracy: 0.7246\n",
            "Epoch 473/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6698 - accuracy: 0.7297 - val_loss: 0.7355 - val_accuracy: 0.7440\n",
            "Epoch 474/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6574 - accuracy: 0.7424 - val_loss: 0.7486 - val_accuracy: 0.7295\n",
            "Epoch 475/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6525 - accuracy: 0.7328 - val_loss: 0.7426 - val_accuracy: 0.7246\n",
            "Epoch 476/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6677 - accuracy: 0.7304 - val_loss: 0.7321 - val_accuracy: 0.7391\n",
            "Epoch 477/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6623 - accuracy: 0.7424 - val_loss: 0.7345 - val_accuracy: 0.7246\n",
            "Epoch 478/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6587 - accuracy: 0.7370 - val_loss: 0.7329 - val_accuracy: 0.7440\n",
            "Epoch 479/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6531 - accuracy: 0.7437 - val_loss: 0.7386 - val_accuracy: 0.7150\n",
            "Epoch 480/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6601 - accuracy: 0.7346 - val_loss: 0.7265 - val_accuracy: 0.7295\n",
            "Epoch 481/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.6320 - accuracy: 0.7527 - val_loss: 0.7324 - val_accuracy: 0.7440\n",
            "Epoch 482/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6509 - accuracy: 0.7473 - val_loss: 0.7430 - val_accuracy: 0.7005\n",
            "Epoch 483/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6749 - accuracy: 0.7297 - val_loss: 0.7403 - val_accuracy: 0.7343\n",
            "Epoch 484/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6459 - accuracy: 0.7424 - val_loss: 0.7279 - val_accuracy: 0.7295\n",
            "Epoch 485/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6671 - accuracy: 0.7352 - val_loss: 0.7259 - val_accuracy: 0.7343\n",
            "Epoch 486/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6501 - accuracy: 0.7340 - val_loss: 0.7361 - val_accuracy: 0.7536\n",
            "Epoch 487/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6586 - accuracy: 0.7328 - val_loss: 0.7465 - val_accuracy: 0.7246\n",
            "Epoch 488/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6472 - accuracy: 0.7527 - val_loss: 0.7460 - val_accuracy: 0.7295\n",
            "Epoch 489/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6440 - accuracy: 0.7521 - val_loss: 0.7283 - val_accuracy: 0.7391\n",
            "Epoch 490/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6395 - accuracy: 0.7588 - val_loss: 0.7299 - val_accuracy: 0.7343\n",
            "Epoch 491/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6557 - accuracy: 0.7382 - val_loss: 0.7313 - val_accuracy: 0.7246\n",
            "Epoch 492/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6293 - accuracy: 0.7576 - val_loss: 0.7232 - val_accuracy: 0.7488\n",
            "Epoch 493/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6568 - accuracy: 0.7394 - val_loss: 0.7259 - val_accuracy: 0.7246\n",
            "Epoch 494/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6454 - accuracy: 0.7455 - val_loss: 0.7239 - val_accuracy: 0.7488\n",
            "Epoch 495/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6368 - accuracy: 0.7515 - val_loss: 0.7319 - val_accuracy: 0.7391\n",
            "Epoch 496/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6552 - accuracy: 0.7461 - val_loss: 0.7345 - val_accuracy: 0.7536\n",
            "Epoch 497/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6344 - accuracy: 0.7455 - val_loss: 0.7353 - val_accuracy: 0.7440\n",
            "Epoch 498/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6359 - accuracy: 0.7551 - val_loss: 0.7233 - val_accuracy: 0.7488\n",
            "Epoch 499/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6404 - accuracy: 0.7340 - val_loss: 0.7238 - val_accuracy: 0.7343\n",
            "Epoch 500/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6194 - accuracy: 0.7551 - val_loss: 0.7227 - val_accuracy: 0.7391\n",
            "Epoch 501/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.6265 - accuracy: 0.7654 - val_loss: 0.7238 - val_accuracy: 0.7343\n",
            "Epoch 502/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6460 - accuracy: 0.7467 - val_loss: 0.7098 - val_accuracy: 0.7391\n",
            "Epoch 503/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6414 - accuracy: 0.7521 - val_loss: 0.7161 - val_accuracy: 0.7391\n",
            "Epoch 504/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6269 - accuracy: 0.7515 - val_loss: 0.7278 - val_accuracy: 0.7391\n",
            "Epoch 505/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6328 - accuracy: 0.7563 - val_loss: 0.7163 - val_accuracy: 0.7440\n",
            "Epoch 506/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6312 - accuracy: 0.7539 - val_loss: 0.7270 - val_accuracy: 0.7101\n",
            "Epoch 507/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.6216 - accuracy: 0.7491 - val_loss: 0.7195 - val_accuracy: 0.7343\n",
            "Epoch 508/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6280 - accuracy: 0.7394 - val_loss: 0.7108 - val_accuracy: 0.7440\n",
            "Epoch 509/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5949 - accuracy: 0.7666 - val_loss: 0.7233 - val_accuracy: 0.7536\n",
            "Epoch 510/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6343 - accuracy: 0.7539 - val_loss: 0.7083 - val_accuracy: 0.7488\n",
            "Epoch 511/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6273 - accuracy: 0.7563 - val_loss: 0.7118 - val_accuracy: 0.7536\n",
            "Epoch 512/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6414 - accuracy: 0.7467 - val_loss: 0.7110 - val_accuracy: 0.7488\n",
            "Epoch 513/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6052 - accuracy: 0.7636 - val_loss: 0.7134 - val_accuracy: 0.7343\n",
            "Epoch 514/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6223 - accuracy: 0.7539 - val_loss: 0.7148 - val_accuracy: 0.7246\n",
            "Epoch 515/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6193 - accuracy: 0.7612 - val_loss: 0.7156 - val_accuracy: 0.7343\n",
            "Epoch 516/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6121 - accuracy: 0.7545 - val_loss: 0.7140 - val_accuracy: 0.7343\n",
            "Epoch 517/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6325 - accuracy: 0.7316 - val_loss: 0.7094 - val_accuracy: 0.7440\n",
            "Epoch 518/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6006 - accuracy: 0.7690 - val_loss: 0.7173 - val_accuracy: 0.7633\n",
            "Epoch 519/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6194 - accuracy: 0.7527 - val_loss: 0.7169 - val_accuracy: 0.7440\n",
            "Epoch 520/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6059 - accuracy: 0.7690 - val_loss: 0.7139 - val_accuracy: 0.7391\n",
            "Epoch 521/1000\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.6003 - accuracy: 0.7497 - val_loss: 0.7128 - val_accuracy: 0.7488\n",
            "Epoch 522/1000\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.6068 - accuracy: 0.7624 - val_loss: 0.7011 - val_accuracy: 0.7391\n",
            "Epoch 523/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6058 - accuracy: 0.7594 - val_loss: 0.7022 - val_accuracy: 0.7536\n",
            "Epoch 524/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6047 - accuracy: 0.7630 - val_loss: 0.7040 - val_accuracy: 0.7391\n",
            "Epoch 525/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6084 - accuracy: 0.7612 - val_loss: 0.7254 - val_accuracy: 0.7295\n",
            "Epoch 526/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6148 - accuracy: 0.7443 - val_loss: 0.7135 - val_accuracy: 0.7295\n",
            "Epoch 527/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6169 - accuracy: 0.7533 - val_loss: 0.7359 - val_accuracy: 0.7150\n",
            "Epoch 528/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6099 - accuracy: 0.7594 - val_loss: 0.7104 - val_accuracy: 0.7391\n",
            "Epoch 529/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6006 - accuracy: 0.7703 - val_loss: 0.7238 - val_accuracy: 0.7440\n",
            "Epoch 530/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6279 - accuracy: 0.7509 - val_loss: 0.7100 - val_accuracy: 0.7295\n",
            "Epoch 531/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.5903 - accuracy: 0.7594 - val_loss: 0.7141 - val_accuracy: 0.7488\n",
            "Epoch 532/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6304 - accuracy: 0.7443 - val_loss: 0.7040 - val_accuracy: 0.7633\n",
            "Epoch 533/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6073 - accuracy: 0.7576 - val_loss: 0.7233 - val_accuracy: 0.7343\n",
            "Epoch 534/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.5905 - accuracy: 0.7654 - val_loss: 0.7126 - val_accuracy: 0.7391\n",
            "Epoch 535/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6136 - accuracy: 0.7479 - val_loss: 0.7101 - val_accuracy: 0.7585\n",
            "Epoch 536/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5961 - accuracy: 0.7612 - val_loss: 0.7248 - val_accuracy: 0.7488\n",
            "Epoch 537/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6044 - accuracy: 0.7660 - val_loss: 0.7167 - val_accuracy: 0.7391\n",
            "Epoch 538/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5965 - accuracy: 0.7539 - val_loss: 0.7034 - val_accuracy: 0.7633\n",
            "Epoch 539/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.5956 - accuracy: 0.7600 - val_loss: 0.7132 - val_accuracy: 0.7343\n",
            "Epoch 540/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6070 - accuracy: 0.7624 - val_loss: 0.6995 - val_accuracy: 0.7536\n",
            "Epoch 541/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5988 - accuracy: 0.7666 - val_loss: 0.7130 - val_accuracy: 0.7488\n",
            "Epoch 542/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5877 - accuracy: 0.7696 - val_loss: 0.7132 - val_accuracy: 0.7488\n",
            "Epoch 543/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6042 - accuracy: 0.7636 - val_loss: 0.7010 - val_accuracy: 0.7391\n",
            "Epoch 544/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5991 - accuracy: 0.7563 - val_loss: 0.7028 - val_accuracy: 0.7488\n",
            "Epoch 545/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5869 - accuracy: 0.7793 - val_loss: 0.7014 - val_accuracy: 0.7633\n",
            "Epoch 546/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5758 - accuracy: 0.7811 - val_loss: 0.6936 - val_accuracy: 0.7536\n",
            "Epoch 547/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5937 - accuracy: 0.7630 - val_loss: 0.7017 - val_accuracy: 0.7488\n",
            "Epoch 548/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5972 - accuracy: 0.7703 - val_loss: 0.7039 - val_accuracy: 0.7488\n",
            "Epoch 549/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5938 - accuracy: 0.7666 - val_loss: 0.7050 - val_accuracy: 0.7440\n",
            "Epoch 550/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.5829 - accuracy: 0.7793 - val_loss: 0.6986 - val_accuracy: 0.7488\n",
            "Epoch 551/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5974 - accuracy: 0.7576 - val_loss: 0.6941 - val_accuracy: 0.7488\n",
            "Epoch 552/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.5851 - accuracy: 0.7781 - val_loss: 0.6840 - val_accuracy: 0.7681\n",
            "Epoch 553/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.5961 - accuracy: 0.7576 - val_loss: 0.6973 - val_accuracy: 0.7633\n",
            "Epoch 554/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5821 - accuracy: 0.7727 - val_loss: 0.6954 - val_accuracy: 0.7440\n",
            "Epoch 555/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.5815 - accuracy: 0.7648 - val_loss: 0.6917 - val_accuracy: 0.7391\n",
            "Epoch 556/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.5902 - accuracy: 0.7696 - val_loss: 0.6948 - val_accuracy: 0.7440\n",
            "Epoch 557/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5722 - accuracy: 0.7836 - val_loss: 0.6862 - val_accuracy: 0.7585\n",
            "Epoch 558/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5746 - accuracy: 0.7793 - val_loss: 0.7093 - val_accuracy: 0.7488\n",
            "Epoch 559/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.5585 - accuracy: 0.7793 - val_loss: 0.6930 - val_accuracy: 0.7826\n",
            "Epoch 560/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5829 - accuracy: 0.7811 - val_loss: 0.6960 - val_accuracy: 0.7681\n",
            "Epoch 561/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5671 - accuracy: 0.7836 - val_loss: 0.6978 - val_accuracy: 0.7585\n",
            "Epoch 562/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5634 - accuracy: 0.7763 - val_loss: 0.7047 - val_accuracy: 0.7633\n",
            "Epoch 563/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.5833 - accuracy: 0.7733 - val_loss: 0.6954 - val_accuracy: 0.7585\n",
            "Epoch 564/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5702 - accuracy: 0.7763 - val_loss: 0.6744 - val_accuracy: 0.7440\n",
            "Epoch 565/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5800 - accuracy: 0.7690 - val_loss: 0.6805 - val_accuracy: 0.7585\n",
            "Epoch 566/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.5537 - accuracy: 0.7787 - val_loss: 0.6763 - val_accuracy: 0.7874\n",
            "Epoch 567/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.5593 - accuracy: 0.7799 - val_loss: 0.6899 - val_accuracy: 0.7826\n",
            "Epoch 568/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5765 - accuracy: 0.7727 - val_loss: 0.7307 - val_accuracy: 0.7440\n",
            "Epoch 569/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5893 - accuracy: 0.7654 - val_loss: 0.6946 - val_accuracy: 0.7681\n",
            "Epoch 570/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.5665 - accuracy: 0.7787 - val_loss: 0.6824 - val_accuracy: 0.7778\n",
            "Epoch 571/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5615 - accuracy: 0.7823 - val_loss: 0.6765 - val_accuracy: 0.7729\n",
            "Epoch 572/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.5562 - accuracy: 0.7920 - val_loss: 0.7266 - val_accuracy: 0.7101\n",
            "Epoch 573/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5665 - accuracy: 0.7793 - val_loss: 0.6791 - val_accuracy: 0.7585\n",
            "Epoch 574/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5506 - accuracy: 0.7842 - val_loss: 0.6906 - val_accuracy: 0.7585\n",
            "Epoch 575/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.5766 - accuracy: 0.7733 - val_loss: 0.6715 - val_accuracy: 0.7681\n",
            "Epoch 576/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5560 - accuracy: 0.7793 - val_loss: 0.6622 - val_accuracy: 0.7923\n",
            "Epoch 577/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5848 - accuracy: 0.7642 - val_loss: 0.6808 - val_accuracy: 0.7633\n",
            "Epoch 578/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5630 - accuracy: 0.7872 - val_loss: 0.6798 - val_accuracy: 0.7633\n",
            "Epoch 579/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.5714 - accuracy: 0.7769 - val_loss: 0.6792 - val_accuracy: 0.7391\n",
            "Epoch 580/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5694 - accuracy: 0.7781 - val_loss: 0.6816 - val_accuracy: 0.7633\n",
            "Epoch 581/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.5700 - accuracy: 0.7823 - val_loss: 0.6772 - val_accuracy: 0.7681\n",
            "Epoch 582/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5356 - accuracy: 0.7872 - val_loss: 0.6925 - val_accuracy: 0.7729\n",
            "Epoch 583/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.5730 - accuracy: 0.7781 - val_loss: 0.6627 - val_accuracy: 0.7681\n",
            "Epoch 584/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.5285 - accuracy: 0.7920 - val_loss: 0.6659 - val_accuracy: 0.7681\n",
            "Epoch 585/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5552 - accuracy: 0.7769 - val_loss: 0.6789 - val_accuracy: 0.7440\n",
            "Epoch 586/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5503 - accuracy: 0.7823 - val_loss: 0.6796 - val_accuracy: 0.7585\n",
            "Epoch 587/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5413 - accuracy: 0.7896 - val_loss: 0.6685 - val_accuracy: 0.7585\n",
            "Epoch 588/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5555 - accuracy: 0.7811 - val_loss: 0.6662 - val_accuracy: 0.7729\n",
            "Epoch 589/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.5273 - accuracy: 0.8005 - val_loss: 0.6697 - val_accuracy: 0.7585\n",
            "Epoch 590/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.5753 - accuracy: 0.7696 - val_loss: 0.6776 - val_accuracy: 0.7536\n",
            "Epoch 591/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.5445 - accuracy: 0.7848 - val_loss: 0.6768 - val_accuracy: 0.7440\n",
            "Epoch 592/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5440 - accuracy: 0.7902 - val_loss: 0.6684 - val_accuracy: 0.7440\n",
            "Epoch 593/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.5482 - accuracy: 0.7908 - val_loss: 0.6811 - val_accuracy: 0.7488\n",
            "Epoch 594/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5584 - accuracy: 0.7787 - val_loss: 0.6667 - val_accuracy: 0.7585\n",
            "Epoch 595/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5475 - accuracy: 0.7872 - val_loss: 0.6610 - val_accuracy: 0.7440\n",
            "Epoch 596/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5504 - accuracy: 0.7884 - val_loss: 0.6559 - val_accuracy: 0.7729\n",
            "Epoch 597/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5372 - accuracy: 0.7866 - val_loss: 0.6827 - val_accuracy: 0.7488\n",
            "Epoch 598/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5560 - accuracy: 0.7854 - val_loss: 0.6747 - val_accuracy: 0.7729\n",
            "Epoch 599/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5485 - accuracy: 0.7902 - val_loss: 0.6797 - val_accuracy: 0.7536\n",
            "Epoch 600/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.5524 - accuracy: 0.7890 - val_loss: 0.6770 - val_accuracy: 0.7488\n",
            "Epoch 601/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5453 - accuracy: 0.7854 - val_loss: 0.6657 - val_accuracy: 0.7440\n",
            "Epoch 602/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.5440 - accuracy: 0.7890 - val_loss: 0.6804 - val_accuracy: 0.7536\n",
            "Epoch 603/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5287 - accuracy: 0.7938 - val_loss: 0.6683 - val_accuracy: 0.7488\n",
            "Epoch 604/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5335 - accuracy: 0.8041 - val_loss: 0.6832 - val_accuracy: 0.7633\n",
            "Epoch 605/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5287 - accuracy: 0.7902 - val_loss: 0.6776 - val_accuracy: 0.7874\n",
            "Epoch 606/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5426 - accuracy: 0.7836 - val_loss: 0.6746 - val_accuracy: 0.7488\n",
            "Epoch 607/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5512 - accuracy: 0.7823 - val_loss: 0.6753 - val_accuracy: 0.7633\n",
            "Epoch 608/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5215 - accuracy: 0.7878 - val_loss: 0.6887 - val_accuracy: 0.7585\n",
            "Epoch 609/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5368 - accuracy: 0.7884 - val_loss: 0.6626 - val_accuracy: 0.7488\n",
            "Epoch 610/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5416 - accuracy: 0.7938 - val_loss: 0.6658 - val_accuracy: 0.7440\n",
            "Epoch 611/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.5365 - accuracy: 0.7866 - val_loss: 0.6615 - val_accuracy: 0.7536\n",
            "Epoch 612/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5304 - accuracy: 0.7866 - val_loss: 0.6718 - val_accuracy: 0.7585\n",
            "Epoch 613/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5178 - accuracy: 0.7920 - val_loss: 0.6668 - val_accuracy: 0.7488\n",
            "Epoch 614/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5162 - accuracy: 0.8089 - val_loss: 0.6708 - val_accuracy: 0.7681\n",
            "Epoch 615/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5356 - accuracy: 0.7823 - val_loss: 0.6703 - val_accuracy: 0.7536\n",
            "Epoch 616/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.5408 - accuracy: 0.7848 - val_loss: 0.6904 - val_accuracy: 0.7295\n",
            "Epoch 617/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.5290 - accuracy: 0.7993 - val_loss: 0.6703 - val_accuracy: 0.7440\n",
            "Epoch 618/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.5073 - accuracy: 0.8132 - val_loss: 0.6803 - val_accuracy: 0.7585\n",
            "Epoch 619/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.5116 - accuracy: 0.7981 - val_loss: 0.6685 - val_accuracy: 0.7440\n",
            "Epoch 620/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.5238 - accuracy: 0.8017 - val_loss: 0.6776 - val_accuracy: 0.7488\n",
            "Epoch 621/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5403 - accuracy: 0.7793 - val_loss: 0.6583 - val_accuracy: 0.7681\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(cnnhistory.history['loss'])\n",
        "plt.plot(cnnhistory.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train','test'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "oQYnuaCrDH_A",
        "outputId": "440a8268-6c33-4c20-b8b9-ba654ea0f0a8"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(cnnhistory.history['accuracy'])\n",
        "plt.plot(cnnhistory.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train','test'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "IFkTuO8nDNdq",
        "outputId": "55697425-c4e1-430b-f59d-c0431c41339e"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model.predict(x_testcnn)"
      ],
      "metadata": {
        "id": "A2xtrN5wDQgY"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_f_ohjXKDUpY",
        "outputId": "4793db3d-0b56-4c49-c05d-9723c3c9b1e5"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[2.1818702e-01, 7.8669511e-02, 1.7953475e-01, 2.6946294e-01,\n",
              "        1.5580177e-01, 9.8344050e-02],\n",
              "       [3.7255997e-04, 3.8784707e-05, 8.3061678e-07, 9.8232192e-01,\n",
              "        7.8445609e-04, 1.6481448e-02],\n",
              "       [1.5674442e-01, 5.7443257e-02, 7.5271294e-02, 3.7796527e-01,\n",
              "        4.0431395e-02, 2.9214439e-01],\n",
              "       ...,\n",
              "       [1.3181928e-04, 6.4311416e-06, 1.7188025e-03, 6.9455775e-03,\n",
              "        9.2665571e-01, 6.4541787e-02],\n",
              "       [8.1670978e-06, 6.5627587e-01, 3.2324538e-01, 7.4840132e-03,\n",
              "        2.7174714e-03, 1.0269200e-02],\n",
              "       [2.4612708e-04, 1.0172679e-03, 4.8812855e-02, 1.9227432e-03,\n",
              "        8.8975036e-01, 5.8250610e-02]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cmA2bFgsDW3D",
        "outputId": "915de0ca-e19b-44bd-efe5-cc143259331d"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([3, 3, 3, 0, 4, 4, 1, 2, 5, 0, 5, 3, 2, 2, 1, 4, 4, 5, 2, 4, 1, 2,\n",
              "       3, 5, 4, 2, 1, 2, 2, 2, 2, 5, 2, 5, 3, 1, 2, 0, 4, 5, 2, 3, 2, 2,\n",
              "       5, 2, 0, 1, 3, 4, 4, 5, 1, 1, 4, 4, 5, 1, 1, 1, 0, 1, 5, 0, 4, 1,\n",
              "       1, 0, 1, 4, 1, 0, 4, 1, 3, 1, 2, 2, 1, 2, 3, 0, 5, 3, 5, 5, 2, 4,\n",
              "       5, 1, 5, 1, 5, 3, 4, 1, 4, 1, 5, 4, 5, 1, 2, 1, 1, 5, 1, 3, 2, 5,\n",
              "       2, 1, 3, 5, 4, 4, 0, 0, 3, 1, 2, 2, 3, 5, 1, 5, 3, 4, 2, 2, 0, 2,\n",
              "       2, 5, 5, 0, 3, 3, 2, 2, 0, 3, 4, 0, 4, 2, 4, 5, 4, 1, 5, 3, 2, 2,\n",
              "       5, 4, 3, 3, 4, 3, 3, 4, 1, 5, 2, 3, 2, 2, 0, 2, 1, 3, 1, 2, 2, 5,\n",
              "       5, 1, 4, 2, 2, 1, 1, 3, 3, 5, 5, 2, 5, 1, 5, 0, 3, 3, 0, 5, 1, 4,\n",
              "       1, 4, 2, 5, 5, 1, 4, 2, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_Ytest = y_test.astype(int)"
      ],
      "metadata": {
        "id": "0PHDKWJWDY3g"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_Ytest"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k68v2i-pDbZE",
        "outputId": "cfc02788-5cee-45a4-b78d-317c5cc67258"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([3, 3, 3, 0, 4, 4, 1, 2, 5, 0, 5, 3, 2, 2, 1, 4, 4, 5, 2, 4, 1, 2,\n",
              "       3, 5, 4, 2, 1, 2, 2, 2, 2, 5, 2, 5, 3, 1, 2, 0, 4, 5, 2, 3, 2, 2,\n",
              "       5, 2, 0, 1, 3, 4, 4, 5, 1, 1, 4, 4, 5, 1, 1, 1, 0, 1, 5, 0, 4, 1,\n",
              "       1, 0, 1, 4, 1, 0, 4, 1, 3, 1, 2, 2, 1, 2, 3, 0, 5, 3, 5, 5, 2, 4,\n",
              "       5, 1, 5, 1, 5, 3, 4, 1, 4, 1, 5, 4, 5, 1, 2, 1, 1, 5, 1, 3, 2, 5,\n",
              "       2, 1, 3, 5, 4, 4, 0, 0, 3, 1, 2, 2, 3, 5, 1, 5, 3, 4, 2, 2, 0, 2,\n",
              "       2, 5, 5, 0, 3, 3, 2, 2, 0, 3, 4, 0, 4, 2, 4, 5, 4, 1, 5, 3, 2, 2,\n",
              "       5, 4, 3, 3, 4, 3, 3, 4, 1, 5, 2, 3, 2, 2, 0, 2, 1, 3, 1, 2, 2, 5,\n",
              "       5, 1, 4, 2, 2, 1, 1, 3, 3, 5, 5, 2, 5, 1, 5, 0, 3, 3, 0, 5, 1, 4,\n",
              "       1, 4, 2, 5, 5, 1, 4, 2, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds1=predictions.argmax(axis=1)\n",
        "preds1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4_cAI39VFhtp",
        "outputId": "a8c53603-7efa-4f34-a834-f1e44fdf69e0"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([3, 3, 3, 3, 4, 4, 1, 5, 5, 1, 4, 3, 2, 2, 1, 4, 4, 3, 3, 4, 2, 2,\n",
              "       3, 3, 5, 2, 1, 0, 2, 2, 2, 5, 3, 5, 3, 1, 2, 0, 4, 5, 2, 5, 2, 2,\n",
              "       5, 2, 1, 1, 3, 4, 4, 2, 1, 1, 4, 4, 5, 1, 1, 1, 3, 1, 2, 1, 4, 1,\n",
              "       1, 1, 1, 4, 1, 2, 4, 1, 5, 5, 2, 2, 0, 2, 1, 0, 5, 3, 5, 5, 2, 3,\n",
              "       3, 1, 5, 1, 5, 3, 2, 2, 4, 1, 5, 4, 5, 1, 5, 1, 1, 5, 1, 3, 2, 5,\n",
              "       5, 3, 3, 5, 4, 4, 3, 0, 3, 1, 1, 2, 1, 5, 1, 3, 5, 5, 2, 5, 1, 4,\n",
              "       2, 3, 3, 0, 3, 3, 2, 4, 0, 5, 4, 1, 4, 4, 4, 2, 4, 1, 5, 3, 2, 2,\n",
              "       5, 4, 2, 3, 4, 5, 3, 4, 1, 5, 2, 3, 2, 2, 0, 2, 1, 3, 1, 2, 4, 5,\n",
              "       5, 1, 4, 2, 4, 1, 1, 3, 3, 5, 5, 2, 5, 1, 4, 1, 3, 3, 3, 4, 1, 4,\n",
              "       1, 3, 5, 5, 5, 1, 4, 1, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "abc = preds1.astype(int).flatten()"
      ],
      "metadata": {
        "id": "H4WEmM60NfQn"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "c = confusion_matrix(new_Ytest, abc) \n",
        "c"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bKEBeEBlFjB8",
        "outputId": "853ed4ce-137f-40ae-a312-c74d3a0f036c"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 6,  7,  1,  4,  0,  0],\n",
              "       [ 1, 36,  2,  1,  0,  1],\n",
              "       [ 1,  2, 30,  2,  5,  5],\n",
              "       [ 0,  2,  1, 23,  0,  5],\n",
              "       [ 0,  0,  1,  2, 28,  2],\n",
              "       [ 0,  0,  3,  6,  3, 27]])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m4RjG7LWLSQx",
        "outputId": "f8ecb773-ff70-41b9-d359-474f488ee40b"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([3, 3, 3, 0, 4, 4, 1, 2, 5, 0, 5, 3, 2, 2, 1, 4, 4, 5, 2, 4, 1, 2,\n",
              "       3, 5, 4, 2, 1, 2, 2, 2, 2, 5, 2, 5, 3, 1, 2, 0, 4, 5, 2, 3, 2, 2,\n",
              "       5, 2, 0, 1, 3, 4, 4, 5, 1, 1, 4, 4, 5, 1, 1, 1, 0, 1, 5, 0, 4, 1,\n",
              "       1, 0, 1, 4, 1, 0, 4, 1, 3, 1, 2, 2, 1, 2, 3, 0, 5, 3, 5, 5, 2, 4,\n",
              "       5, 1, 5, 1, 5, 3, 4, 1, 4, 1, 5, 4, 5, 1, 2, 1, 1, 5, 1, 3, 2, 5,\n",
              "       2, 1, 3, 5, 4, 4, 0, 0, 3, 1, 2, 2, 3, 5, 1, 5, 3, 4, 2, 2, 0, 2,\n",
              "       2, 5, 5, 0, 3, 3, 2, 2, 0, 3, 4, 0, 4, 2, 4, 5, 4, 1, 5, 3, 2, 2,\n",
              "       5, 4, 3, 3, 4, 3, 3, 4, 1, 5, 2, 3, 2, 2, 0, 2, 1, 3, 1, 2, 2, 5,\n",
              "       5, 1, 4, 2, 2, 1, 1, 3, 3, 5, 5, 2, 5, 1, 5, 0, 3, 3, 0, 5, 1, 4,\n",
              "       1, 4, 2, 5, 5, 1, 4, 2, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss, acc =model.evaluate(x_testcnn, y_test)\n",
        "print(\"Restored model, accuracy: {:5.2f}%\".format(100*acc))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n3kzoqPkDqqS",
        "outputId": "b79f2511-27d6-4f9a-c6d0-f1e46c58c7eb"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7/7 [==============================] - 0s 3ms/step - loss: 0.6850 - accuracy: 0.7246\n",
            "Restored model, accuracy: 72.46%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss, acc =model.evaluate(X_train, y_train)\n",
        "print(\"Restored model train, accuracy: {:5.2f}%\".format(100*acc))"
      ],
      "metadata": {
        "id": "fJDTGH_OUX0z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74e648d1-1c82-4838-cdfa-4d0fd951fb1f"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "52/52 [==============================] - 0s 4ms/step - loss: 0.4678 - accuracy: 0.8724\n",
            "Restored model train, accuracy: 87.24%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix,accuracy_score\n",
        "import seaborn as sn\n",
        "\n",
        "print(classification_report(new_Ytest,abc))\n",
        "\n",
        "acc = float(accuracy_score(new_Ytest,abc))*100\n",
        "print(\"----accuracy score %s ----\" % acc)\n",
        "\n",
        "cm = confusion_matrix(new_Ytest,abc)\n",
        "#df_cm = pd.DataFrame(cm)\n",
        "class_names = ['neutral','calm', 'happy','sad','angry', 'fearful' ]\n",
        "df_cm = pd.DataFrame(cm, index=class_names, columns=class_names,)\n",
        "sn.heatmap(df_cm, annot=True, fmt='')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 508
        },
        "id": "SfSC3El94LZg",
        "outputId": "c1c07f7e-4154-4fec-fa02-cba1647a096c"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.33      0.46        18\n",
            "           1       0.77      0.88      0.82        41\n",
            "           2       0.79      0.67      0.72        45\n",
            "           3       0.61      0.74      0.67        31\n",
            "           4       0.78      0.85      0.81        33\n",
            "           5       0.68      0.69      0.68        39\n",
            "\n",
            "    accuracy                           0.72       207\n",
            "   macro avg       0.73      0.69      0.69       207\n",
            "weighted avg       0.73      0.72      0.72       207\n",
            "\n",
            "----accuracy score 72.46376811594203 ----\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "A6UOIsB2xKek"
      },
      "execution_count": 28,
      "outputs": []
    }
  ]
}