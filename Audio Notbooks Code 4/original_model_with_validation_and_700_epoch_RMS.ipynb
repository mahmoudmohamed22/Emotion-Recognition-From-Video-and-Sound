{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "original model with validation and 700 epoch_RMS.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9SRCO-a_AlH5",
        "outputId": "e77e2f3c-f734-4645-b50c-f88e830005d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install librosa"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oi8pWV3yBVjO",
        "outputId": "520c4a01-ff8d-41b0-ff3f-0a31c9012362"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: librosa in /usr/local/lib/python3.7/dist-packages (0.8.1)\n",
            "Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.6.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (21.3)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.21.5)\n",
            "Requirement already satisfied: audioread>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (2.1.9)\n",
            "Requirement already satisfied: numba>=0.43.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (0.51.2)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.0.2)\n",
            "Requirement already satisfied: soundfile>=0.10.2 in /usr/local/lib/python3.7/dist-packages (from librosa) (0.10.3.post1)\n",
            "Requirement already satisfied: decorator>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.1.0)\n",
            "Requirement already satisfied: resampy>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from librosa) (0.2.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba>=0.43.0->librosa) (57.4.0)\n",
            "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba>=0.43.0->librosa) (0.34.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->librosa) (3.0.7)\n",
            "Requirement already satisfied: appdirs>=1.3.0 in /usr/local/lib/python3.7/dist-packages (from pooch>=1.0->librosa) (1.4.4)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from pooch>=1.0->librosa) (2.23.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (3.0.4)\n",
            "Requirement already satisfied: six>=1.3 in /usr/local/lib/python3.7/dist-packages (from resampy>=0.2.2->librosa) (1.15.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn!=0.19.0,>=0.14.0->librosa) (3.1.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.7/dist-packages (from soundfile>=0.10.2->librosa) (1.15.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.0->soundfile>=0.10.2->librosa) (2.21)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "wsaoikiQGfqd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HJjcbxwy46bG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "8038fc49-bcf5-44a2-aee3-3390c0d21735"
      },
      "source": [
        "# Orignial Notebook: https://github.com/MITESHPUTHRANNEU/Speech-Emotion-Analyzer/blob/master/final_results_gender_test.ipynb\n",
        "# This notebook author: Reza Chu\n",
        "# Last Editing Date: 31st May 2019\n",
        "\n",
        "## Python\n",
        "import os\n",
        "import random\n",
        "import sys\n",
        "\n",
        "import IPython\n",
        "from IPython.display import Audio\n",
        "from IPython.display import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "## Package\n",
        "import glob \n",
        "import keras\n",
        "import IPython.display as ipd\n",
        "import librosa\n",
        "import librosa.display\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import plotly.graph_objs as go\n",
        "import plotly.offline as py\n",
        "import plotly.tools as tls\n",
        "import seaborn as sns\n",
        "import scipy.io.wavfile\n",
        "import tensorflow as tf\n",
        "py.init_notebook_mode(connected=True)\n",
        "\n",
        "## Keras\n",
        "from keras import regularizers\n",
        "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping\n",
        "from keras.callbacks import  History, ReduceLROnPlateau, CSVLogger\n",
        "from keras.models import Model, Sequential\n",
        "from keras.layers import Dense, Embedding, LSTM\n",
        "from keras.layers import Input, Flatten, Dropout, Activation, BatchNormalization\n",
        "from keras.layers import Conv1D, MaxPooling1D, AveragePooling1D\n",
        "from keras.preprocessing import sequence\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.utils import np_utils\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "## Sklearn\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "## Rest\n",
        "from scipy.fftpack import fft\n",
        "from scipy import signal\n",
        "from scipy.io import wavfile\n",
        "from tqdm import tqdm\n",
        "\n",
        "input_duration=3\n",
        "# % pylab inline"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "        <script type=\"text/javascript\">\n",
              "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
              "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
              "        if (typeof require !== 'undefined') {\n",
              "        require.undef(\"plotly\");\n",
              "        requirejs.config({\n",
              "            paths: {\n",
              "                'plotly': ['https://cdn.plot.ly/plotly-2.8.3.min']\n",
              "            }\n",
              "        });\n",
              "        require(['plotly'], function(Plotly) {\n",
              "            window._Plotly = Plotly;\n",
              "        });\n",
              "        }\n",
              "        </script>\n",
              "        "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#radvass speech and song\n",
        "import time\n",
        "import os\n",
        "import librosa\n",
        "from librosa import display\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "count=0\n",
        "path1 = '/content/drive/My Drive/data_set/RAVDESS_speech'\n",
        "path2 = '/content/drive/My Drive/data_set/RAVDESS_song'\n",
        "\n",
        "lst = []\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "for subdir, dirs, files in os.walk(path2):\n",
        "  print(dirs)\n",
        "  print(subdir)\n",
        "  #print(files)\n",
        "  for file in files:\n",
        "      try:\n",
        "        count +=1\n",
        "        #Load librosa array, obtain mfcss, store the file and the mcss information in a new array\n",
        "        X, sample_rate = librosa.load(os.path.join(subdir,file), res_type='kaiser_fast')\n",
        "        mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T,axis=0) \n",
        "        # The instruction below converts the labels (from 1 to 8) to a series from 0 to 7\n",
        "        # This is because our predictor needs to start from 0 otherwise it will try to predict also 0.\n",
        "        file = int(file[7:8]) - 1 \n",
        "        arr = mfccs, file\n",
        "        lst.append(arr)\n",
        "      # If the file is not valid, skip it\n",
        "      except ValueError:\n",
        "        continue\n",
        "\n",
        "for subdir, dirs, files in os.walk(path1):\n",
        "  print(dirs)\n",
        "  print(subdir)\n",
        " # print(files)\n",
        "  for file in files:\n",
        "      try:\n",
        "        #Load librosa array, obtain mfcss, store the file and the mcss information in a new array\n",
        "        X, sample_rate = librosa.load(os.path.join(subdir,file), res_type='kaiser_fast')\n",
        "        mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T,axis=0) \n",
        "        # The instruction below converts the labels (from 1 to 8) to a series from 0 to 7\n",
        "        # This is because our predictor needs to start from 0 otherwise it will try to predict also 0.\n",
        "        file = int(file[7:8]) - 1 \n",
        "        if(file ==6 or file==7):\n",
        "          continue\n",
        "        count +=1\n",
        "        arr = mfccs, file\n",
        "        lst.append(arr)\n",
        "      # If the file is not valid, skip it\n",
        "      except ValueError:\n",
        "        continue\n",
        "\n",
        "\n",
        "\n",
        "print(\"--- Data loaded. Loading time: %s seconds ---\" % (time.time() - start_time))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IfuyRZl42ccZ",
        "outputId": "34809b15-dd5c-4186-96e3-9172c769b373"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Actor_10', 'Actor_11', 'Actor_13', 'Actor_12', 'Actor_14', 'Actor_15', 'Actor_16', 'Actor_17', 'Actor_18', 'Actor_19', 'Actor_21', 'Actor_22', 'Actor_23', 'Actor_09', 'Actor_24', 'Actor_04', 'Actor_08', 'Actor_03', 'Actor_02', 'Actor_06', 'Actor_05', 'Actor_01', 'Actor_07', 'Actor_20']\n",
            "/content/drive/My Drive/data_set/RAVDESS_song\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_song/Actor_10\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_song/Actor_11\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_song/Actor_13\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_song/Actor_12\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_song/Actor_14\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_song/Actor_15\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_song/Actor_16\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_song/Actor_17\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_song/Actor_18\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_song/Actor_19\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_song/Actor_21\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_song/Actor_22\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_song/Actor_23\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_song/Actor_09\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_song/Actor_24\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_song/Actor_04\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_song/Actor_08\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_song/Actor_03\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_song/Actor_02\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_song/Actor_06\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_song/Actor_05\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_song/Actor_01\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_song/Actor_07\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_song/Actor_20\n",
            "['Actor_05', 'Actor_08', 'Actor_10', 'Actor_04', 'Actor_09', 'Actor_14', 'Actor_12', 'Actor_13', 'Actor_11', 'Actor_06', 'Actor_24', 'Actor_07', 'Actor_23', 'Actor_22', 'Actor_21', 'Actor_20', 'Actor_02', 'Actor_19', 'Actor_18', 'Actor_17', 'Actor_16', 'Actor_15', 'Actor_03', 'Actor_01']\n",
            "/content/drive/My Drive/data_set/RAVDESS_speech\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_speech/Actor_05\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_speech/Actor_08\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_speech/Actor_10\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_speech/Actor_04\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_speech/Actor_09\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_speech/Actor_14\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_speech/Actor_12\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_speech/Actor_13\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_speech/Actor_11\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_speech/Actor_06\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_speech/Actor_24\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_speech/Actor_07\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_speech/Actor_23\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_speech/Actor_22\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_speech/Actor_21\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_speech/Actor_20\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_speech/Actor_02\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_speech/Actor_19\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_speech/Actor_18\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_speech/Actor_17\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_speech/Actor_16\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_speech/Actor_15\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_speech/Actor_03\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_speech/Actor_01\n",
            "--- Data loaded. Loading time: 221.34846711158752 seconds ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "count"
      ],
      "metadata": {
        "id": "Ltlhi25L2AI5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1bb84b7-d08a-4432-af60-65565c47c441"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2068"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy.core.fromnumeric import size\n",
        "size(lst)"
      ],
      "metadata": {
        "id": "HMOH7d7mzHB7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27638de3-6cc2-43ba-8996-74baaa080d9b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/core/fromnumeric.py:3208: VisibleDeprecationWarning:\n",
            "\n",
            "Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4136"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating X and y: zip makes a list of all the first elements, and a list of all the second elements.\n",
        "X, y = zip(*lst)"
      ],
      "metadata": {
        "id": "ocdL7tSTBoMt"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "X = np.asarray(X)\n",
        "y = np.asarray(y)\n",
        "X.shape, y.shape"
      ],
      "metadata": {
        "id": "vHKwUGTbBtnF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a816bb4-b79d-4627-d390-d809e7b68f46"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((2068, 40), (2068,))"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "id": "2sUCtbfMztE5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "05de4f31-8e5b-49c4-90ab-7e46183d0572"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2068, 40)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Saving joblib files to not load them again with the loop above\n",
        "\n",
        "import joblib\n",
        "\n",
        "X_name = 'saveex5.joblib'\n",
        "y_name = 'saveey5.joblib'\n",
        "save_dir = '/content/drive/My Drive/graduation project/audio/improvement1/features'\n",
        "\n",
        "savedX = joblib.dump(X, os.path.join(save_dir, X_name))\n",
        "savedy = joblib.dump(y, os.path.join(save_dir, y_name))"
      ],
      "metadata": {
        "id": "UCzic8rlDcuk"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading saved models\n",
        "import joblib\n",
        "X = joblib.load('/content/drive/My Drive/models/CNN_2/last/features/speech&songx6.joblib')\n",
        "y = joblib.load('/content/drive/My Drive/models/CNN_2/last/features/speech&songy6.joblib')"
      ],
      "metadata": {
        "id": "Q35CN6zDrzg1"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2,train_size=0.8, random_state=42)\n",
        "X_valid, X_test, y_valid, y_test = train_test_split(X_test,y_test, test_size=0.5,train_size=0.5, random_state=42)"
      ],
      "metadata": {
        "id": "Ai4Fy5cPCiq1"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7PSTurzjCo5K",
        "outputId": "571f5d4c-4674-433f-cffa-bb9a7901b6c7"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2068, 40)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "x_traincnn = np.expand_dims(X_train, axis=2)\n",
        "x_testcnn = np.expand_dims(X_test, axis=2)\n",
        "X_valid= np.expand_dims(X_valid, axis=2)"
      ],
      "metadata": {
        "id": "tp1Fm5K3CEXu"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_traincnn.shape, x_testcnn.shape , X_valid.shape"
      ],
      "metadata": {
        "id": "RI0MxoIPBws5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "784fa859-2eb2-4645-e615-b085ec2e7170"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1654, 40, 1), (207, 40, 1), (207, 40, 1))"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow"
      ],
      "metadata": {
        "id": "goxL4Y3jKICC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1f815e8-0a50-47a4-c330-40404effac7a"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (2.8.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.44.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n",
            "Requirement already satisfied: tf-estimator-nightly==2.8.0.dev2021122109 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0.dev2021122109)\n",
            "Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.5.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow) (57.4.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.17.3)\n",
            "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.21.5)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.24.0)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (13.0.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.10.0.2)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.13.3)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.0.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow) (1.5.2)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.4.6)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.35.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.6.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (3.3.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.23.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.8)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.2.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (4.11.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (3.7.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (3.2.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keras"
      ],
      "metadata": {
        "id": "EkcmN9UrKSxj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d78873e5-3d0c-4a72-aaa1-efc4bdf30878"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: keras in /usr/local/lib/python3.7/dist-packages (2.8.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from keras.preprocessing import sequence\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from keras.layers import Input, Flatten, Dropout, Activation\n",
        "from keras.layers import Conv1D, MaxPooling1D\n",
        "from keras.models import Model\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras import optimizers\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv1D(128, 8,padding='same', #classifier.add(Convolution2D(64, (3, 3), padding = 'same', input_shape = (128, 128, 3), activation = 'relu'))\n",
        "                 input_shape=(40,1)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(MaxPooling1D(pool_size=(5)))\n",
        "\n",
        "\n",
        "model.add(Conv1D(256,8,padding='same',))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(MaxPooling1D(pool_size=(5)))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(256))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(256))\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "model.add(Dense(6))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "#opt = tf.keras.optimizers.Adam(lr=0.00002)\n",
        "opt = tf.keras.optimizers.RMSprop(lr=0.0001, rho=0.9, epsilon=1e-07, decay=0.0)\n",
        "#opt = tf.keras.optimizers.SGD(lr=0.001, momentum=0.0, decay=0.0, nesterov=False)"
      ],
      "metadata": {
        "id": "g74fXWVAC4Cr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6567886a-de1a-4f2d-e6ce-83250e72522e"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/rmsprop.py:130: UserWarning:\n",
            "\n",
            "The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H6ukOxAGC_I4",
        "outputId": "fef00bd2-c352-46df-ffa3-830b5cd33887"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d (Conv1D)             (None, 40, 128)           1152      \n",
            "                                                                 \n",
            " activation (Activation)     (None, 40, 128)           0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 40, 128)           0         \n",
            "                                                                 \n",
            " max_pooling1d (MaxPooling1D  (None, 8, 128)           0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv1d_1 (Conv1D)           (None, 8, 256)            262400    \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 8, 256)            0         \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 8, 256)            0         \n",
            "                                                                 \n",
            " max_pooling1d_1 (MaxPooling  (None, 1, 256)           0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 256)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 256)               65792     \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 256)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 256)               65792     \n",
            "                                                                 \n",
            " activation_3 (Activation)   (None, 256)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 6)                 1542      \n",
            "                                                                 \n",
            " activation_4 (Activation)   (None, 6)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 396,678\n",
            "Trainable params: 396,678\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='sparse_categorical_crossentropy',\n",
        "              optimizer=opt,\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "AbMlLNk4DCBM"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#cnnhistory=model.fit(x_traincnn, y_train, batch_size=16, epochs=700, validation_data=(x_testcnn, y_test))\n",
        "cnnhistory=model.fit(x_traincnn, y_train, batch_size=16, epochs=700 , validation_data=(X_valid, y_valid))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RI1v2AuADFhy",
        "outputId": "c82eb752-5401-4565-ccf4-2e84df5a3d83"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/700\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 1.9735 - accuracy: 0.2273 - val_loss: 1.8670 - val_accuracy: 0.1401\n",
            "Epoch 2/700\n",
            "104/104 [==============================] - 2s 19ms/step - loss: 1.8911 - accuracy: 0.2334 - val_loss: 1.7816 - val_accuracy: 0.2802\n",
            "Epoch 3/700\n",
            "104/104 [==============================] - 2s 19ms/step - loss: 1.8269 - accuracy: 0.2563 - val_loss: 1.6831 - val_accuracy: 0.2802\n",
            "Epoch 4/700\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 1.8236 - accuracy: 0.2497 - val_loss: 1.6469 - val_accuracy: 0.3140\n",
            "Epoch 5/700\n",
            "104/104 [==============================] - 2s 19ms/step - loss: 1.8055 - accuracy: 0.2491 - val_loss: 1.6517 - val_accuracy: 0.2802\n",
            "Epoch 6/700\n",
            "104/104 [==============================] - 2s 19ms/step - loss: 1.7574 - accuracy: 0.2739 - val_loss: 1.6521 - val_accuracy: 0.3043\n",
            "Epoch 7/700\n",
            "104/104 [==============================] - 2s 19ms/step - loss: 1.7302 - accuracy: 0.2703 - val_loss: 1.6244 - val_accuracy: 0.3092\n",
            "Epoch 8/700\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 1.7113 - accuracy: 0.2950 - val_loss: 1.7338 - val_accuracy: 0.2899\n",
            "Epoch 9/700\n",
            "104/104 [==============================] - 2s 19ms/step - loss: 1.6984 - accuracy: 0.2944 - val_loss: 1.6364 - val_accuracy: 0.3333\n",
            "Epoch 10/700\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 1.6750 - accuracy: 0.2950 - val_loss: 1.6116 - val_accuracy: 0.2850\n",
            "Epoch 11/700\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 1.6434 - accuracy: 0.3271 - val_loss: 1.5388 - val_accuracy: 0.3575\n",
            "Epoch 12/700\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 1.6316 - accuracy: 0.3229 - val_loss: 1.7021 - val_accuracy: 0.3043\n",
            "Epoch 13/700\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 1.5897 - accuracy: 0.3513 - val_loss: 1.4946 - val_accuracy: 0.3961\n",
            "Epoch 14/700\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 1.5984 - accuracy: 0.3386 - val_loss: 1.4803 - val_accuracy: 0.4396\n",
            "Epoch 15/700\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 1.5696 - accuracy: 0.3501 - val_loss: 1.6198 - val_accuracy: 0.2947\n",
            "Epoch 16/700\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 1.5610 - accuracy: 0.3458 - val_loss: 1.4335 - val_accuracy: 0.4058\n",
            "Epoch 17/700\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 1.5476 - accuracy: 0.3555 - val_loss: 1.4932 - val_accuracy: 0.3333\n",
            "Epoch 18/700\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 1.5165 - accuracy: 0.3827 - val_loss: 1.4421 - val_accuracy: 0.4300\n",
            "Epoch 19/700\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 1.5074 - accuracy: 0.3869 - val_loss: 1.4581 - val_accuracy: 0.4106\n",
            "Epoch 20/700\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 1.4672 - accuracy: 0.4015 - val_loss: 1.4792 - val_accuracy: 0.3768\n",
            "Epoch 21/700\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 1.4753 - accuracy: 0.3881 - val_loss: 1.3633 - val_accuracy: 0.5024\n",
            "Epoch 22/700\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 1.4374 - accuracy: 0.4311 - val_loss: 1.4665 - val_accuracy: 0.3816\n",
            "Epoch 23/700\n",
            "104/104 [==============================] - 2s 19ms/step - loss: 1.4447 - accuracy: 0.4027 - val_loss: 1.4473 - val_accuracy: 0.3720\n",
            "Epoch 24/700\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 1.4062 - accuracy: 0.4389 - val_loss: 1.3624 - val_accuracy: 0.4638\n",
            "Epoch 25/700\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 1.4002 - accuracy: 0.4353 - val_loss: 1.3134 - val_accuracy: 0.4734\n",
            "Epoch 26/700\n",
            "104/104 [==============================] - 2s 19ms/step - loss: 1.3958 - accuracy: 0.4262 - val_loss: 1.2863 - val_accuracy: 0.5024\n",
            "Epoch 27/700\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 1.3714 - accuracy: 0.4450 - val_loss: 1.3332 - val_accuracy: 0.4155\n",
            "Epoch 28/700\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 1.3315 - accuracy: 0.4516 - val_loss: 1.3123 - val_accuracy: 0.4783\n",
            "Epoch 29/700\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 1.3465 - accuracy: 0.4595 - val_loss: 1.2507 - val_accuracy: 0.4976\n",
            "Epoch 30/700\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 1.3317 - accuracy: 0.4625 - val_loss: 1.2774 - val_accuracy: 0.4831\n",
            "Epoch 31/700\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 1.3033 - accuracy: 0.4680 - val_loss: 1.3346 - val_accuracy: 0.4541\n",
            "Epoch 32/700\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 1.3074 - accuracy: 0.4752 - val_loss: 1.2617 - val_accuracy: 0.5314\n",
            "Epoch 33/700\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 1.2885 - accuracy: 0.4758 - val_loss: 1.3503 - val_accuracy: 0.4203\n",
            "Epoch 34/700\n",
            "104/104 [==============================] - 2s 19ms/step - loss: 1.2725 - accuracy: 0.4891 - val_loss: 1.2284 - val_accuracy: 0.5217\n",
            "Epoch 35/700\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 1.2614 - accuracy: 0.4903 - val_loss: 1.2251 - val_accuracy: 0.4976\n",
            "Epoch 36/700\n",
            "104/104 [==============================] - 3s 30ms/step - loss: 1.2374 - accuracy: 0.4897 - val_loss: 1.1513 - val_accuracy: 0.5266\n",
            "Epoch 37/700\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 1.2497 - accuracy: 0.4976 - val_loss: 1.1297 - val_accuracy: 0.5942\n",
            "Epoch 38/700\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 1.2319 - accuracy: 0.5054 - val_loss: 1.2303 - val_accuracy: 0.5121\n",
            "Epoch 39/700\n",
            "104/104 [==============================] - 2s 19ms/step - loss: 1.2003 - accuracy: 0.5054 - val_loss: 1.2150 - val_accuracy: 0.5024\n",
            "Epoch 40/700\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 1.2107 - accuracy: 0.5054 - val_loss: 1.1846 - val_accuracy: 0.5072\n",
            "Epoch 41/700\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 1.1963 - accuracy: 0.5206 - val_loss: 1.2261 - val_accuracy: 0.5217\n",
            "Epoch 42/700\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 1.1915 - accuracy: 0.5242 - val_loss: 1.1924 - val_accuracy: 0.5507\n",
            "Epoch 43/700\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 1.1622 - accuracy: 0.5308 - val_loss: 1.1330 - val_accuracy: 0.5121\n",
            "Epoch 44/700\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 1.1766 - accuracy: 0.5278 - val_loss: 1.0903 - val_accuracy: 0.5797\n",
            "Epoch 45/700\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 1.1284 - accuracy: 0.5472 - val_loss: 1.1139 - val_accuracy: 0.5749\n",
            "Epoch 46/700\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 1.1576 - accuracy: 0.5411 - val_loss: 1.1684 - val_accuracy: 0.5217\n",
            "Epoch 47/700\n",
            "104/104 [==============================] - 2s 19ms/step - loss: 1.1317 - accuracy: 0.5351 - val_loss: 1.0541 - val_accuracy: 0.5942\n",
            "Epoch 48/700\n",
            "104/104 [==============================] - 2s 19ms/step - loss: 1.1138 - accuracy: 0.5562 - val_loss: 1.0867 - val_accuracy: 0.5700\n",
            "Epoch 49/700\n",
            "104/104 [==============================] - 2s 19ms/step - loss: 1.0869 - accuracy: 0.5593 - val_loss: 1.0629 - val_accuracy: 0.5749\n",
            "Epoch 50/700\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 1.0777 - accuracy: 0.5629 - val_loss: 1.0842 - val_accuracy: 0.5459\n",
            "Epoch 51/700\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 1.0867 - accuracy: 0.5707 - val_loss: 1.0771 - val_accuracy: 0.5556\n",
            "Epoch 52/700\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 1.0847 - accuracy: 0.5689 - val_loss: 1.0261 - val_accuracy: 0.6087\n",
            "Epoch 53/700\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 1.0673 - accuracy: 0.5798 - val_loss: 1.1833 - val_accuracy: 0.5024\n",
            "Epoch 54/700\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 1.0505 - accuracy: 0.5653 - val_loss: 1.0578 - val_accuracy: 0.5604\n",
            "Epoch 55/700\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 1.0313 - accuracy: 0.6034 - val_loss: 1.0286 - val_accuracy: 0.5942\n",
            "Epoch 56/700\n",
            "104/104 [==============================] - 2s 19ms/step - loss: 1.0421 - accuracy: 0.5883 - val_loss: 1.1164 - val_accuracy: 0.5845\n",
            "Epoch 57/700\n",
            "104/104 [==============================] - 2s 19ms/step - loss: 1.0326 - accuracy: 0.5955 - val_loss: 1.0228 - val_accuracy: 0.6087\n",
            "Epoch 58/700\n",
            "104/104 [==============================] - 2s 19ms/step - loss: 1.0125 - accuracy: 0.5919 - val_loss: 1.0054 - val_accuracy: 0.6039\n",
            "Epoch 59/700\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 1.0083 - accuracy: 0.5913 - val_loss: 1.0143 - val_accuracy: 0.5797\n",
            "Epoch 60/700\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 1.0011 - accuracy: 0.6004 - val_loss: 0.9669 - val_accuracy: 0.5942\n",
            "Epoch 61/700\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 0.9984 - accuracy: 0.6058 - val_loss: 0.9880 - val_accuracy: 0.5894\n",
            "Epoch 62/700\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 0.9812 - accuracy: 0.6040 - val_loss: 0.9763 - val_accuracy: 0.5749\n",
            "Epoch 63/700\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 0.9954 - accuracy: 0.6034 - val_loss: 0.9809 - val_accuracy: 0.5990\n",
            "Epoch 64/700\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 0.9846 - accuracy: 0.6040 - val_loss: 0.9736 - val_accuracy: 0.6087\n",
            "Epoch 65/700\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 0.9747 - accuracy: 0.6276 - val_loss: 1.0492 - val_accuracy: 0.5604\n",
            "Epoch 66/700\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 0.9516 - accuracy: 0.6288 - val_loss: 0.9726 - val_accuracy: 0.6087\n",
            "Epoch 67/700\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 0.9602 - accuracy: 0.6245 - val_loss: 1.0078 - val_accuracy: 0.6135\n",
            "Epoch 68/700\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 0.9555 - accuracy: 0.6155 - val_loss: 0.9383 - val_accuracy: 0.6425\n",
            "Epoch 69/700\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 0.9488 - accuracy: 0.6366 - val_loss: 0.9998 - val_accuracy: 0.6087\n",
            "Epoch 70/700\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 0.9454 - accuracy: 0.6366 - val_loss: 0.9667 - val_accuracy: 0.6184\n",
            "Epoch 71/700\n",
            "104/104 [==============================] - 2s 19ms/step - loss: 0.9347 - accuracy: 0.6330 - val_loss: 0.9330 - val_accuracy: 0.6280\n",
            "Epoch 72/700\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 0.9194 - accuracy: 0.6270 - val_loss: 0.9190 - val_accuracy: 0.6522\n",
            "Epoch 73/700\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 0.9172 - accuracy: 0.6288 - val_loss: 0.8848 - val_accuracy: 0.6618\n",
            "Epoch 74/700\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 0.9141 - accuracy: 0.6421 - val_loss: 0.9149 - val_accuracy: 0.6473\n",
            "Epoch 75/700\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.8927 - accuracy: 0.6463 - val_loss: 0.9901 - val_accuracy: 0.6087\n",
            "Epoch 76/700\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 0.9049 - accuracy: 0.6409 - val_loss: 0.9046 - val_accuracy: 0.6425\n",
            "Epoch 77/700\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 0.8907 - accuracy: 0.6409 - val_loss: 0.9784 - val_accuracy: 0.5942\n",
            "Epoch 78/700\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 0.8700 - accuracy: 0.6451 - val_loss: 0.8931 - val_accuracy: 0.6425\n",
            "Epoch 79/700\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 0.8540 - accuracy: 0.6638 - val_loss: 0.8888 - val_accuracy: 0.6425\n",
            "Epoch 80/700\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 0.8600 - accuracy: 0.6518 - val_loss: 0.8635 - val_accuracy: 0.6715\n",
            "Epoch 81/700\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 0.8634 - accuracy: 0.6572 - val_loss: 0.8648 - val_accuracy: 0.6570\n",
            "Epoch 82/700\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 0.8604 - accuracy: 0.6644 - val_loss: 0.8794 - val_accuracy: 0.6812\n",
            "Epoch 83/700\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 0.8599 - accuracy: 0.6542 - val_loss: 0.8544 - val_accuracy: 0.6618\n",
            "Epoch 84/700\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 0.8701 - accuracy: 0.6433 - val_loss: 0.8998 - val_accuracy: 0.6280\n",
            "Epoch 85/700\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 0.8356 - accuracy: 0.6651 - val_loss: 0.8355 - val_accuracy: 0.6715\n",
            "Epoch 86/700\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 0.8326 - accuracy: 0.6796 - val_loss: 0.8559 - val_accuracy: 0.6715\n",
            "Epoch 87/700\n",
            "104/104 [==============================] - 3s 29ms/step - loss: 0.8029 - accuracy: 0.6868 - val_loss: 0.8451 - val_accuracy: 0.6763\n",
            "Epoch 88/700\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 0.8041 - accuracy: 0.6747 - val_loss: 0.8348 - val_accuracy: 0.6763\n",
            "Epoch 89/700\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 0.8310 - accuracy: 0.6711 - val_loss: 0.8748 - val_accuracy: 0.6570\n",
            "Epoch 90/700\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 0.8045 - accuracy: 0.6856 - val_loss: 0.8758 - val_accuracy: 0.6184\n",
            "Epoch 91/700\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 0.8081 - accuracy: 0.6832 - val_loss: 0.8266 - val_accuracy: 0.6618\n",
            "Epoch 92/700\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 0.7940 - accuracy: 0.6917 - val_loss: 0.8580 - val_accuracy: 0.6618\n",
            "Epoch 93/700\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 0.7977 - accuracy: 0.6808 - val_loss: 0.8246 - val_accuracy: 0.6618\n",
            "Epoch 94/700\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.7878 - accuracy: 0.6765 - val_loss: 0.8360 - val_accuracy: 0.6812\n",
            "Epoch 95/700\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 0.7996 - accuracy: 0.6923 - val_loss: 0.8748 - val_accuracy: 0.6715\n",
            "Epoch 96/700\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.7764 - accuracy: 0.6935 - val_loss: 0.8550 - val_accuracy: 0.6570\n",
            "Epoch 97/700\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 0.7606 - accuracy: 0.7013 - val_loss: 0.8609 - val_accuracy: 0.6812\n",
            "Epoch 98/700\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 0.7523 - accuracy: 0.7007 - val_loss: 0.8000 - val_accuracy: 0.6908\n",
            "Epoch 99/700\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 0.7373 - accuracy: 0.7207 - val_loss: 0.8082 - val_accuracy: 0.6618\n",
            "Epoch 100/700\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 0.7667 - accuracy: 0.6838 - val_loss: 0.8197 - val_accuracy: 0.6763\n",
            "Epoch 101/700\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 0.7592 - accuracy: 0.7001 - val_loss: 0.8016 - val_accuracy: 0.6522\n",
            "Epoch 102/700\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 0.7459 - accuracy: 0.7044 - val_loss: 0.7951 - val_accuracy: 0.6618\n",
            "Epoch 103/700\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.7417 - accuracy: 0.7062 - val_loss: 0.7938 - val_accuracy: 0.6957\n",
            "Epoch 104/700\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 0.7472 - accuracy: 0.7068 - val_loss: 0.8633 - val_accuracy: 0.6522\n",
            "Epoch 105/700\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 0.7625 - accuracy: 0.6892 - val_loss: 0.8426 - val_accuracy: 0.6522\n",
            "Epoch 106/700\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 0.7301 - accuracy: 0.7116 - val_loss: 0.8749 - val_accuracy: 0.6570\n",
            "Epoch 107/700\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 0.7138 - accuracy: 0.7225 - val_loss: 0.7757 - val_accuracy: 0.6908\n",
            "Epoch 108/700\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 0.7345 - accuracy: 0.7098 - val_loss: 0.7952 - val_accuracy: 0.6618\n",
            "Epoch 109/700\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 0.7250 - accuracy: 0.7177 - val_loss: 0.8168 - val_accuracy: 0.7005\n",
            "Epoch 110/700\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 0.7046 - accuracy: 0.7213 - val_loss: 0.7964 - val_accuracy: 0.6522\n",
            "Epoch 111/700\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 0.7037 - accuracy: 0.7195 - val_loss: 0.7789 - val_accuracy: 0.6618\n",
            "Epoch 112/700\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 0.7141 - accuracy: 0.7201 - val_loss: 0.8054 - val_accuracy: 0.6715\n",
            "Epoch 113/700\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 0.6865 - accuracy: 0.7261 - val_loss: 0.7790 - val_accuracy: 0.6908\n",
            "Epoch 114/700\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 0.7122 - accuracy: 0.7255 - val_loss: 0.8002 - val_accuracy: 0.6618\n",
            "Epoch 115/700\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 0.6902 - accuracy: 0.7273 - val_loss: 0.7929 - val_accuracy: 0.6812\n",
            "Epoch 116/700\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 0.6876 - accuracy: 0.7273 - val_loss: 0.8067 - val_accuracy: 0.6763\n",
            "Epoch 117/700\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 0.6695 - accuracy: 0.7304 - val_loss: 0.7936 - val_accuracy: 0.6812\n",
            "Epoch 118/700\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 0.6899 - accuracy: 0.7261 - val_loss: 0.7551 - val_accuracy: 0.6957\n",
            "Epoch 119/700\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 0.7015 - accuracy: 0.7340 - val_loss: 0.7820 - val_accuracy: 0.6957\n",
            "Epoch 120/700\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 0.6802 - accuracy: 0.7291 - val_loss: 0.7602 - val_accuracy: 0.6860\n",
            "Epoch 121/700\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 0.6627 - accuracy: 0.7424 - val_loss: 0.7775 - val_accuracy: 0.6860\n",
            "Epoch 122/700\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 0.6657 - accuracy: 0.7461 - val_loss: 0.7631 - val_accuracy: 0.6763\n",
            "Epoch 123/700\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 0.6717 - accuracy: 0.7406 - val_loss: 0.7724 - val_accuracy: 0.6957\n",
            "Epoch 124/700\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 0.6660 - accuracy: 0.7346 - val_loss: 0.7944 - val_accuracy: 0.6763\n",
            "Epoch 125/700\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 0.6543 - accuracy: 0.7400 - val_loss: 0.7700 - val_accuracy: 0.6860\n",
            "Epoch 126/700\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 0.6562 - accuracy: 0.7376 - val_loss: 0.7399 - val_accuracy: 0.7005\n",
            "Epoch 127/700\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 0.6327 - accuracy: 0.7515 - val_loss: 0.7757 - val_accuracy: 0.6908\n",
            "Epoch 128/700\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 0.6140 - accuracy: 0.7654 - val_loss: 0.7584 - val_accuracy: 0.7005\n",
            "Epoch 129/700\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 0.6206 - accuracy: 0.7582 - val_loss: 0.7279 - val_accuracy: 0.6957\n",
            "Epoch 130/700\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 0.6369 - accuracy: 0.7533 - val_loss: 0.8123 - val_accuracy: 0.6860\n",
            "Epoch 131/700\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 0.6170 - accuracy: 0.7563 - val_loss: 0.7179 - val_accuracy: 0.7295\n",
            "Epoch 132/700\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.6332 - accuracy: 0.7479 - val_loss: 0.7287 - val_accuracy: 0.7198\n",
            "Epoch 133/700\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 0.6431 - accuracy: 0.7418 - val_loss: 0.7229 - val_accuracy: 0.7150\n",
            "Epoch 134/700\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 0.6098 - accuracy: 0.7588 - val_loss: 0.7314 - val_accuracy: 0.6957\n",
            "Epoch 135/700\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 0.6180 - accuracy: 0.7551 - val_loss: 0.7268 - val_accuracy: 0.6425\n",
            "Epoch 136/700\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.6114 - accuracy: 0.7618 - val_loss: 0.7270 - val_accuracy: 0.7246\n",
            "Epoch 137/700\n",
            "104/104 [==============================] - 3s 24ms/step - loss: 0.6306 - accuracy: 0.7715 - val_loss: 0.7304 - val_accuracy: 0.7246\n",
            "Epoch 138/700\n",
            "104/104 [==============================] - 3s 25ms/step - loss: 0.6066 - accuracy: 0.7642 - val_loss: 0.7413 - val_accuracy: 0.6667\n",
            "Epoch 139/700\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 0.6137 - accuracy: 0.7642 - val_loss: 0.7435 - val_accuracy: 0.6860\n",
            "Epoch 140/700\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 0.5851 - accuracy: 0.7781 - val_loss: 0.7045 - val_accuracy: 0.7343\n",
            "Epoch 141/700\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 0.6152 - accuracy: 0.7545 - val_loss: 0.7199 - val_accuracy: 0.7198\n",
            "Epoch 142/700\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 0.6132 - accuracy: 0.7624 - val_loss: 0.7659 - val_accuracy: 0.7198\n",
            "Epoch 143/700\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 0.6052 - accuracy: 0.7672 - val_loss: 0.7714 - val_accuracy: 0.6522\n",
            "Epoch 144/700\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 0.5817 - accuracy: 0.7793 - val_loss: 0.7419 - val_accuracy: 0.7053\n",
            "Epoch 145/700\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 0.5846 - accuracy: 0.7793 - val_loss: 0.6945 - val_accuracy: 0.7343\n",
            "Epoch 146/700\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 0.5891 - accuracy: 0.7733 - val_loss: 0.7557 - val_accuracy: 0.6812\n",
            "Epoch 147/700\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 0.5856 - accuracy: 0.7690 - val_loss: 0.6862 - val_accuracy: 0.7585\n",
            "Epoch 148/700\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 0.5936 - accuracy: 0.7733 - val_loss: 0.7560 - val_accuracy: 0.7536\n",
            "Epoch 149/700\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.5598 - accuracy: 0.7739 - val_loss: 0.7175 - val_accuracy: 0.7295\n",
            "Epoch 150/700\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 0.5630 - accuracy: 0.7872 - val_loss: 0.6921 - val_accuracy: 0.7053\n",
            "Epoch 151/700\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 0.5523 - accuracy: 0.7944 - val_loss: 0.6974 - val_accuracy: 0.7005\n",
            "Epoch 152/700\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 0.5666 - accuracy: 0.7811 - val_loss: 0.6769 - val_accuracy: 0.7246\n",
            "Epoch 153/700\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 0.5539 - accuracy: 0.7775 - val_loss: 0.7544 - val_accuracy: 0.7053\n",
            "Epoch 154/700\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 0.5556 - accuracy: 0.7830 - val_loss: 0.7660 - val_accuracy: 0.7053\n",
            "Epoch 155/700\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 0.5380 - accuracy: 0.7890 - val_loss: 0.7166 - val_accuracy: 0.7005\n",
            "Epoch 156/700\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.5611 - accuracy: 0.7799 - val_loss: 0.7292 - val_accuracy: 0.7053\n",
            "Epoch 157/700\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 0.5423 - accuracy: 0.7908 - val_loss: 0.7266 - val_accuracy: 0.6812\n",
            "Epoch 158/700\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 0.5357 - accuracy: 0.7787 - val_loss: 0.6883 - val_accuracy: 0.7005\n",
            "Epoch 159/700\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 0.5608 - accuracy: 0.7908 - val_loss: 0.7169 - val_accuracy: 0.7488\n",
            "Epoch 160/700\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 0.5490 - accuracy: 0.7781 - val_loss: 0.6631 - val_accuracy: 0.7585\n",
            "Epoch 161/700\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.5266 - accuracy: 0.7993 - val_loss: 0.7912 - val_accuracy: 0.6957\n",
            "Epoch 162/700\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 0.5104 - accuracy: 0.7932 - val_loss: 0.6550 - val_accuracy: 0.7585\n",
            "Epoch 163/700\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 0.5243 - accuracy: 0.8023 - val_loss: 0.6897 - val_accuracy: 0.7198\n",
            "Epoch 164/700\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 0.5352 - accuracy: 0.7914 - val_loss: 0.6928 - val_accuracy: 0.7536\n",
            "Epoch 165/700\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 0.5275 - accuracy: 0.8029 - val_loss: 0.7323 - val_accuracy: 0.7198\n",
            "Epoch 166/700\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 0.5156 - accuracy: 0.7956 - val_loss: 0.6977 - val_accuracy: 0.7101\n",
            "Epoch 167/700\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 0.5063 - accuracy: 0.8108 - val_loss: 0.6503 - val_accuracy: 0.7681\n",
            "Epoch 168/700\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 0.5056 - accuracy: 0.8029 - val_loss: 0.6811 - val_accuracy: 0.7295\n",
            "Epoch 169/700\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 0.5146 - accuracy: 0.8029 - val_loss: 0.6665 - val_accuracy: 0.7681\n",
            "Epoch 170/700\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 0.5052 - accuracy: 0.7999 - val_loss: 0.6728 - val_accuracy: 0.7440\n",
            "Epoch 171/700\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 0.4903 - accuracy: 0.8132 - val_loss: 0.7189 - val_accuracy: 0.7101\n",
            "Epoch 172/700\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.5081 - accuracy: 0.8102 - val_loss: 0.6692 - val_accuracy: 0.7488\n",
            "Epoch 173/700\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 0.5060 - accuracy: 0.8017 - val_loss: 0.6507 - val_accuracy: 0.7440\n",
            "Epoch 174/700\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.4985 - accuracy: 0.8204 - val_loss: 0.6759 - val_accuracy: 0.7295\n",
            "Epoch 175/700\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 0.4877 - accuracy: 0.8156 - val_loss: 0.6616 - val_accuracy: 0.7295\n",
            "Epoch 176/700\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.4846 - accuracy: 0.8120 - val_loss: 0.6723 - val_accuracy: 0.7488\n",
            "Epoch 177/700\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 0.4977 - accuracy: 0.8108 - val_loss: 0.6798 - val_accuracy: 0.7391\n",
            "Epoch 178/700\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 0.4982 - accuracy: 0.8023 - val_loss: 0.6956 - val_accuracy: 0.7198\n",
            "Epoch 179/700\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 0.4923 - accuracy: 0.8096 - val_loss: 0.6503 - val_accuracy: 0.7681\n",
            "Epoch 180/700\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 0.4748 - accuracy: 0.8132 - val_loss: 0.6879 - val_accuracy: 0.7295\n",
            "Epoch 181/700\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 0.4815 - accuracy: 0.8114 - val_loss: 0.6922 - val_accuracy: 0.7536\n",
            "Epoch 182/700\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 0.4819 - accuracy: 0.8089 - val_loss: 0.6973 - val_accuracy: 0.7343\n",
            "Epoch 183/700\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 0.4644 - accuracy: 0.8235 - val_loss: 0.6824 - val_accuracy: 0.7295\n",
            "Epoch 184/700\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 0.4833 - accuracy: 0.8150 - val_loss: 0.7417 - val_accuracy: 0.7053\n",
            "Epoch 185/700\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.4567 - accuracy: 0.8253 - val_loss: 0.6549 - val_accuracy: 0.7681\n",
            "Epoch 186/700\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 0.4489 - accuracy: 0.8241 - val_loss: 0.6611 - val_accuracy: 0.7391\n",
            "Epoch 187/700\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 0.4402 - accuracy: 0.8356 - val_loss: 0.6784 - val_accuracy: 0.7246\n",
            "Epoch 188/700\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.4837 - accuracy: 0.8071 - val_loss: 0.7842 - val_accuracy: 0.6860\n",
            "Epoch 189/700\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.4803 - accuracy: 0.8144 - val_loss: 0.7304 - val_accuracy: 0.7343\n",
            "Epoch 190/700\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 0.4425 - accuracy: 0.8319 - val_loss: 0.6702 - val_accuracy: 0.7536\n",
            "Epoch 191/700\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 0.4739 - accuracy: 0.8241 - val_loss: 0.6489 - val_accuracy: 0.7536\n",
            "Epoch 192/700\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 0.4752 - accuracy: 0.8089 - val_loss: 0.7156 - val_accuracy: 0.7053\n",
            "Epoch 193/700\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.4473 - accuracy: 0.8337 - val_loss: 0.7087 - val_accuracy: 0.7150\n",
            "Epoch 194/700\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 0.4620 - accuracy: 0.8132 - val_loss: 0.6943 - val_accuracy: 0.7053\n",
            "Epoch 195/700\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 0.4680 - accuracy: 0.8138 - val_loss: 0.7269 - val_accuracy: 0.7488\n",
            "Epoch 196/700\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 0.4480 - accuracy: 0.8265 - val_loss: 0.6964 - val_accuracy: 0.6957\n",
            "Epoch 197/700\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 0.4448 - accuracy: 0.8343 - val_loss: 0.6519 - val_accuracy: 0.7585\n",
            "Epoch 198/700\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 0.4530 - accuracy: 0.8295 - val_loss: 0.6654 - val_accuracy: 0.7778\n",
            "Epoch 199/700\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 0.4162 - accuracy: 0.8410 - val_loss: 0.7001 - val_accuracy: 0.7343\n",
            "Epoch 200/700\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 0.4299 - accuracy: 0.8313 - val_loss: 0.7059 - val_accuracy: 0.7440\n",
            "Epoch 201/700\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 0.4445 - accuracy: 0.8271 - val_loss: 0.6535 - val_accuracy: 0.7729\n",
            "Epoch 202/700\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 0.4479 - accuracy: 0.8229 - val_loss: 0.6297 - val_accuracy: 0.7343\n",
            "Epoch 203/700\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 0.4296 - accuracy: 0.8362 - val_loss: 0.6680 - val_accuracy: 0.7295\n",
            "Epoch 204/700\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 0.4340 - accuracy: 0.8313 - val_loss: 0.6554 - val_accuracy: 0.7246\n",
            "Epoch 205/700\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 0.4223 - accuracy: 0.8356 - val_loss: 0.6523 - val_accuracy: 0.7150\n",
            "Epoch 206/700\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 0.4237 - accuracy: 0.8428 - val_loss: 0.6877 - val_accuracy: 0.7101\n",
            "Epoch 207/700\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 0.4213 - accuracy: 0.8416 - val_loss: 0.6962 - val_accuracy: 0.7150\n",
            "Epoch 208/700\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 0.4235 - accuracy: 0.8398 - val_loss: 0.7082 - val_accuracy: 0.7053\n",
            "Epoch 209/700\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 0.4223 - accuracy: 0.8489 - val_loss: 0.6453 - val_accuracy: 0.7440\n",
            "Epoch 210/700\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 0.4225 - accuracy: 0.8440 - val_loss: 0.6416 - val_accuracy: 0.7343\n",
            "Epoch 211/700\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 0.4077 - accuracy: 0.8519 - val_loss: 0.6641 - val_accuracy: 0.7198\n",
            "Epoch 212/700\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 0.4194 - accuracy: 0.8313 - val_loss: 0.6548 - val_accuracy: 0.7246\n",
            "Epoch 213/700\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.4334 - accuracy: 0.8392 - val_loss: 0.6725 - val_accuracy: 0.7585\n",
            "Epoch 214/700\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 0.4355 - accuracy: 0.8374 - val_loss: 0.6679 - val_accuracy: 0.7440\n",
            "Epoch 215/700\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 0.3894 - accuracy: 0.8464 - val_loss: 0.6258 - val_accuracy: 0.7826\n",
            "Epoch 216/700\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 0.4025 - accuracy: 0.8458 - val_loss: 0.6528 - val_accuracy: 0.7826\n",
            "Epoch 217/700\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.4100 - accuracy: 0.8452 - val_loss: 0.6598 - val_accuracy: 0.7633\n",
            "Epoch 218/700\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.4097 - accuracy: 0.8525 - val_loss: 0.7380 - val_accuracy: 0.7343\n",
            "Epoch 219/700\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.4031 - accuracy: 0.8519 - val_loss: 0.6879 - val_accuracy: 0.7488\n",
            "Epoch 220/700\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 0.4012 - accuracy: 0.8434 - val_loss: 0.6500 - val_accuracy: 0.7585\n",
            "Epoch 221/700\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.4041 - accuracy: 0.8507 - val_loss: 0.6703 - val_accuracy: 0.7150\n",
            "Epoch 222/700\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.3709 - accuracy: 0.8609 - val_loss: 0.6503 - val_accuracy: 0.7681\n",
            "Epoch 223/700\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.4067 - accuracy: 0.8434 - val_loss: 0.6289 - val_accuracy: 0.7585\n",
            "Epoch 224/700\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 0.3844 - accuracy: 0.8640 - val_loss: 0.6403 - val_accuracy: 0.7923\n",
            "Epoch 225/700\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 0.4064 - accuracy: 0.8482 - val_loss: 0.6842 - val_accuracy: 0.7343\n",
            "Epoch 226/700\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.3845 - accuracy: 0.8561 - val_loss: 0.6274 - val_accuracy: 0.7440\n",
            "Epoch 227/700\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.3649 - accuracy: 0.8646 - val_loss: 0.7227 - val_accuracy: 0.7391\n",
            "Epoch 228/700\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.4031 - accuracy: 0.8476 - val_loss: 0.6279 - val_accuracy: 0.7729\n",
            "Epoch 229/700\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.3691 - accuracy: 0.8640 - val_loss: 0.6504 - val_accuracy: 0.7681\n",
            "Epoch 230/700\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.3845 - accuracy: 0.8573 - val_loss: 0.6465 - val_accuracy: 0.7778\n",
            "Epoch 231/700\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.3625 - accuracy: 0.8640 - val_loss: 0.6307 - val_accuracy: 0.7536\n",
            "Epoch 232/700\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.3730 - accuracy: 0.8658 - val_loss: 0.6692 - val_accuracy: 0.7246\n",
            "Epoch 233/700\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.3563 - accuracy: 0.8658 - val_loss: 0.6829 - val_accuracy: 0.7440\n",
            "Epoch 234/700\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.3587 - accuracy: 0.8615 - val_loss: 0.6658 - val_accuracy: 0.7343\n",
            "Epoch 235/700\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.3737 - accuracy: 0.8597 - val_loss: 0.6529 - val_accuracy: 0.7488\n",
            "Epoch 236/700\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 0.3856 - accuracy: 0.8591 - val_loss: 0.6851 - val_accuracy: 0.7150\n",
            "Epoch 237/700\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 0.3397 - accuracy: 0.8724 - val_loss: 0.6621 - val_accuracy: 0.7585\n",
            "Epoch 238/700\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 0.3713 - accuracy: 0.8634 - val_loss: 0.6254 - val_accuracy: 0.7681\n",
            "Epoch 239/700\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 0.3535 - accuracy: 0.8664 - val_loss: 0.6970 - val_accuracy: 0.7198\n",
            "Epoch 240/700\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 0.3469 - accuracy: 0.8658 - val_loss: 0.6489 - val_accuracy: 0.7198\n",
            "Epoch 241/700\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.3462 - accuracy: 0.8700 - val_loss: 0.7142 - val_accuracy: 0.7295\n",
            "Epoch 242/700\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 0.3663 - accuracy: 0.8634 - val_loss: 0.6971 - val_accuracy: 0.7343\n",
            "Epoch 243/700\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.3439 - accuracy: 0.8670 - val_loss: 0.7169 - val_accuracy: 0.7005\n",
            "Epoch 244/700\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.3580 - accuracy: 0.8646 - val_loss: 0.6454 - val_accuracy: 0.7729\n",
            "Epoch 245/700\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 0.3693 - accuracy: 0.8543 - val_loss: 0.6738 - val_accuracy: 0.7198\n",
            "Epoch 246/700\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 0.3419 - accuracy: 0.8724 - val_loss: 0.6967 - val_accuracy: 0.7633\n",
            "Epoch 247/700\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.3370 - accuracy: 0.8646 - val_loss: 0.6341 - val_accuracy: 0.7585\n",
            "Epoch 248/700\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 0.3509 - accuracy: 0.8652 - val_loss: 0.6837 - val_accuracy: 0.7295\n",
            "Epoch 249/700\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 0.3421 - accuracy: 0.8730 - val_loss: 0.6228 - val_accuracy: 0.7681\n",
            "Epoch 250/700\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 0.3512 - accuracy: 0.8585 - val_loss: 0.6664 - val_accuracy: 0.7536\n",
            "Epoch 251/700\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.3208 - accuracy: 0.8809 - val_loss: 0.6531 - val_accuracy: 0.7343\n",
            "Epoch 252/700\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 0.3444 - accuracy: 0.8676 - val_loss: 0.6881 - val_accuracy: 0.7150\n",
            "Epoch 253/700\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 0.3381 - accuracy: 0.8755 - val_loss: 0.6779 - val_accuracy: 0.7246\n",
            "Epoch 254/700\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.3564 - accuracy: 0.8700 - val_loss: 0.7506 - val_accuracy: 0.6957\n",
            "Epoch 255/700\n",
            "104/104 [==============================] - 2s 20ms/step - loss: 0.3377 - accuracy: 0.8724 - val_loss: 0.6970 - val_accuracy: 0.7295\n",
            "Epoch 256/700\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.3327 - accuracy: 0.8736 - val_loss: 0.6972 - val_accuracy: 0.7295\n",
            "Epoch 257/700\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.3293 - accuracy: 0.8694 - val_loss: 0.6761 - val_accuracy: 0.7295\n",
            "Epoch 258/700\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.3073 - accuracy: 0.8797 - val_loss: 0.6949 - val_accuracy: 0.7198\n",
            "Epoch 259/700\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.3246 - accuracy: 0.8839 - val_loss: 0.6602 - val_accuracy: 0.7633\n",
            "Epoch 260/700\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.3356 - accuracy: 0.8767 - val_loss: 0.6612 - val_accuracy: 0.7729\n",
            "Epoch 261/700\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.3499 - accuracy: 0.8688 - val_loss: 0.7041 - val_accuracy: 0.7440\n",
            "Epoch 262/700\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.3327 - accuracy: 0.8815 - val_loss: 0.6663 - val_accuracy: 0.7440\n",
            "Epoch 263/700\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.3155 - accuracy: 0.8833 - val_loss: 0.5915 - val_accuracy: 0.7971\n",
            "Epoch 264/700\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.3452 - accuracy: 0.8797 - val_loss: 0.6883 - val_accuracy: 0.6957\n",
            "Epoch 265/700\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.3328 - accuracy: 0.8676 - val_loss: 0.6441 - val_accuracy: 0.7536\n",
            "Epoch 266/700\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.3047 - accuracy: 0.8894 - val_loss: 0.6584 - val_accuracy: 0.7295\n",
            "Epoch 267/700\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.3319 - accuracy: 0.8730 - val_loss: 0.5994 - val_accuracy: 0.7536\n",
            "Epoch 268/700\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.3050 - accuracy: 0.8863 - val_loss: 0.6925 - val_accuracy: 0.7295\n",
            "Epoch 269/700\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.3021 - accuracy: 0.8881 - val_loss: 0.6372 - val_accuracy: 0.7874\n",
            "Epoch 270/700\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.2997 - accuracy: 0.8954 - val_loss: 0.6669 - val_accuracy: 0.7440\n",
            "Epoch 271/700\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.3275 - accuracy: 0.8815 - val_loss: 0.6315 - val_accuracy: 0.7778\n",
            "Epoch 272/700\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.2993 - accuracy: 0.8845 - val_loss: 0.6204 - val_accuracy: 0.7585\n",
            "Epoch 273/700\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.3217 - accuracy: 0.8785 - val_loss: 0.6180 - val_accuracy: 0.7923\n",
            "Epoch 274/700\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.3018 - accuracy: 0.8912 - val_loss: 0.6218 - val_accuracy: 0.7778\n",
            "Epoch 275/700\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.3068 - accuracy: 0.8918 - val_loss: 0.6848 - val_accuracy: 0.7295\n",
            "Epoch 276/700\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.3280 - accuracy: 0.8736 - val_loss: 0.5985 - val_accuracy: 0.7778\n",
            "Epoch 277/700\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.2893 - accuracy: 0.8863 - val_loss: 0.6488 - val_accuracy: 0.7198\n",
            "Epoch 278/700\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.3003 - accuracy: 0.8875 - val_loss: 0.6198 - val_accuracy: 0.7633\n",
            "Epoch 279/700\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.3017 - accuracy: 0.8851 - val_loss: 0.6586 - val_accuracy: 0.7150\n",
            "Epoch 280/700\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.2762 - accuracy: 0.9027 - val_loss: 0.6343 - val_accuracy: 0.7633\n",
            "Epoch 281/700\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.2721 - accuracy: 0.8990 - val_loss: 0.6423 - val_accuracy: 0.7633\n",
            "Epoch 282/700\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.2992 - accuracy: 0.8881 - val_loss: 0.6463 - val_accuracy: 0.7536\n",
            "Epoch 283/700\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.3302 - accuracy: 0.8724 - val_loss: 0.6106 - val_accuracy: 0.7681\n",
            "Epoch 284/700\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.2875 - accuracy: 0.9002 - val_loss: 0.6247 - val_accuracy: 0.7585\n",
            "Epoch 285/700\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.3205 - accuracy: 0.8906 - val_loss: 0.7306 - val_accuracy: 0.7246\n",
            "Epoch 286/700\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.2881 - accuracy: 0.8924 - val_loss: 0.7255 - val_accuracy: 0.7150\n",
            "Epoch 287/700\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.2976 - accuracy: 0.8942 - val_loss: 0.7165 - val_accuracy: 0.7246\n",
            "Epoch 288/700\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.2768 - accuracy: 0.9039 - val_loss: 0.6875 - val_accuracy: 0.7585\n",
            "Epoch 289/700\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.2759 - accuracy: 0.8960 - val_loss: 0.6752 - val_accuracy: 0.7585\n",
            "Epoch 290/700\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.2855 - accuracy: 0.9027 - val_loss: 0.7368 - val_accuracy: 0.7295\n",
            "Epoch 291/700\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.2965 - accuracy: 0.8833 - val_loss: 0.6592 - val_accuracy: 0.7536\n",
            "Epoch 292/700\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.2758 - accuracy: 0.9008 - val_loss: 0.7712 - val_accuracy: 0.7101\n",
            "Epoch 293/700\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.2843 - accuracy: 0.8930 - val_loss: 0.6642 - val_accuracy: 0.7585\n",
            "Epoch 294/700\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.2900 - accuracy: 0.8924 - val_loss: 0.6869 - val_accuracy: 0.7198\n",
            "Epoch 295/700\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.2884 - accuracy: 0.8984 - val_loss: 0.6578 - val_accuracy: 0.7488\n",
            "Epoch 296/700\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.2730 - accuracy: 0.9045 - val_loss: 0.6886 - val_accuracy: 0.7681\n",
            "Epoch 297/700\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.2947 - accuracy: 0.8894 - val_loss: 0.6482 - val_accuracy: 0.7585\n",
            "Epoch 298/700\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.2789 - accuracy: 0.8918 - val_loss: 0.6767 - val_accuracy: 0.7585\n",
            "Epoch 299/700\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.3031 - accuracy: 0.8966 - val_loss: 0.6773 - val_accuracy: 0.7343\n",
            "Epoch 300/700\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.2592 - accuracy: 0.9093 - val_loss: 0.7034 - val_accuracy: 0.7729\n",
            "Epoch 301/700\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.2499 - accuracy: 0.9190 - val_loss: 0.7641 - val_accuracy: 0.7295\n",
            "Epoch 302/700\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.2574 - accuracy: 0.9051 - val_loss: 0.7623 - val_accuracy: 0.7053\n",
            "Epoch 303/700\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.2700 - accuracy: 0.9069 - val_loss: 0.6668 - val_accuracy: 0.7633\n",
            "Epoch 304/700\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.2463 - accuracy: 0.9141 - val_loss: 0.7114 - val_accuracy: 0.7391\n",
            "Epoch 305/700\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.2804 - accuracy: 0.9002 - val_loss: 0.6410 - val_accuracy: 0.7536\n",
            "Epoch 306/700\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.2788 - accuracy: 0.8900 - val_loss: 0.6231 - val_accuracy: 0.7633\n",
            "Epoch 307/700\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.2729 - accuracy: 0.9093 - val_loss: 0.5922 - val_accuracy: 0.7536\n",
            "Epoch 308/700\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.2833 - accuracy: 0.8948 - val_loss: 0.6603 - val_accuracy: 0.7585\n",
            "Epoch 309/700\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.2447 - accuracy: 0.9123 - val_loss: 0.6810 - val_accuracy: 0.7295\n",
            "Epoch 310/700\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.2839 - accuracy: 0.8869 - val_loss: 0.6946 - val_accuracy: 0.7295\n",
            "Epoch 311/700\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.2403 - accuracy: 0.9015 - val_loss: 0.6609 - val_accuracy: 0.7729\n",
            "Epoch 312/700\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.2466 - accuracy: 0.9075 - val_loss: 0.6804 - val_accuracy: 0.7053\n",
            "Epoch 313/700\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.2505 - accuracy: 0.9015 - val_loss: 0.6327 - val_accuracy: 0.8068\n",
            "Epoch 314/700\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.2913 - accuracy: 0.8918 - val_loss: 0.6231 - val_accuracy: 0.7681\n",
            "Epoch 315/700\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.2408 - accuracy: 0.9099 - val_loss: 0.6466 - val_accuracy: 0.7778\n",
            "Epoch 316/700\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.2887 - accuracy: 0.8966 - val_loss: 0.7032 - val_accuracy: 0.7681\n",
            "Epoch 317/700\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.2612 - accuracy: 0.9075 - val_loss: 0.7624 - val_accuracy: 0.7343\n",
            "Epoch 318/700\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.2594 - accuracy: 0.9129 - val_loss: 0.6016 - val_accuracy: 0.7923\n",
            "Epoch 319/700\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.2799 - accuracy: 0.8894 - val_loss: 0.6245 - val_accuracy: 0.7874\n",
            "Epoch 320/700\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.2644 - accuracy: 0.9021 - val_loss: 0.6136 - val_accuracy: 0.7971\n",
            "Epoch 321/700\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.2709 - accuracy: 0.8990 - val_loss: 0.5811 - val_accuracy: 0.7923\n",
            "Epoch 322/700\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.2460 - accuracy: 0.9045 - val_loss: 0.7454 - val_accuracy: 0.7246\n",
            "Epoch 323/700\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.2366 - accuracy: 0.9148 - val_loss: 0.6516 - val_accuracy: 0.7923\n",
            "Epoch 324/700\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.2364 - accuracy: 0.9087 - val_loss: 0.5841 - val_accuracy: 0.7923\n",
            "Epoch 325/700\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.2383 - accuracy: 0.9099 - val_loss: 0.6151 - val_accuracy: 0.7633\n",
            "Epoch 326/700\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.2219 - accuracy: 0.9141 - val_loss: 0.5933 - val_accuracy: 0.7778\n",
            "Epoch 327/700\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.2231 - accuracy: 0.9160 - val_loss: 0.6995 - val_accuracy: 0.7488\n",
            "Epoch 328/700\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.2417 - accuracy: 0.9117 - val_loss: 0.5896 - val_accuracy: 0.7633\n",
            "Epoch 329/700\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.2423 - accuracy: 0.9129 - val_loss: 0.7673 - val_accuracy: 0.7391\n",
            "Epoch 330/700\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.2527 - accuracy: 0.9099 - val_loss: 0.6284 - val_accuracy: 0.7633\n",
            "Epoch 331/700\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.2367 - accuracy: 0.9184 - val_loss: 0.6752 - val_accuracy: 0.7681\n",
            "Epoch 332/700\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.2389 - accuracy: 0.9045 - val_loss: 0.6002 - val_accuracy: 0.7874\n",
            "Epoch 333/700\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.2221 - accuracy: 0.9190 - val_loss: 0.5927 - val_accuracy: 0.7585\n",
            "Epoch 334/700\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.2705 - accuracy: 0.9033 - val_loss: 0.5908 - val_accuracy: 0.7826\n",
            "Epoch 335/700\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.2613 - accuracy: 0.9039 - val_loss: 0.6690 - val_accuracy: 0.7343\n",
            "Epoch 336/700\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.2104 - accuracy: 0.9190 - val_loss: 0.7373 - val_accuracy: 0.7391\n",
            "Epoch 337/700\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.2314 - accuracy: 0.9160 - val_loss: 0.7052 - val_accuracy: 0.7295\n",
            "Epoch 338/700\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.2106 - accuracy: 0.9250 - val_loss: 0.7123 - val_accuracy: 0.7729\n",
            "Epoch 339/700\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.2229 - accuracy: 0.9123 - val_loss: 0.6008 - val_accuracy: 0.7681\n",
            "Epoch 340/700\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.2232 - accuracy: 0.9154 - val_loss: 0.6324 - val_accuracy: 0.7923\n",
            "Epoch 341/700\n",
            "104/104 [==============================] - 4s 37ms/step - loss: 0.2345 - accuracy: 0.9172 - val_loss: 0.6305 - val_accuracy: 0.7923\n",
            "Epoch 342/700\n",
            "104/104 [==============================] - 4s 38ms/step - loss: 0.2479 - accuracy: 0.9166 - val_loss: 0.7167 - val_accuracy: 0.7343\n",
            "Epoch 343/700\n",
            "104/104 [==============================] - 3s 33ms/step - loss: 0.2362 - accuracy: 0.9141 - val_loss: 0.6089 - val_accuracy: 0.7923\n",
            "Epoch 344/700\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.2331 - accuracy: 0.9154 - val_loss: 0.6430 - val_accuracy: 0.7440\n",
            "Epoch 345/700\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.2219 - accuracy: 0.9190 - val_loss: 0.6371 - val_accuracy: 0.7874\n",
            "Epoch 346/700\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.2203 - accuracy: 0.9208 - val_loss: 0.6494 - val_accuracy: 0.7585\n",
            "Epoch 347/700\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.2104 - accuracy: 0.9160 - val_loss: 0.6794 - val_accuracy: 0.7585\n",
            "Epoch 348/700\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.2336 - accuracy: 0.9256 - val_loss: 0.7372 - val_accuracy: 0.7343\n",
            "Epoch 349/700\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.2113 - accuracy: 0.9214 - val_loss: 0.6661 - val_accuracy: 0.7826\n",
            "Epoch 350/700\n",
            "104/104 [==============================] - 3s 24ms/step - loss: 0.2101 - accuracy: 0.9190 - val_loss: 0.6353 - val_accuracy: 0.7729\n",
            "Epoch 351/700\n",
            "104/104 [==============================] - 4s 41ms/step - loss: 0.2343 - accuracy: 0.9184 - val_loss: 0.6437 - val_accuracy: 0.7826\n",
            "Epoch 352/700\n",
            "104/104 [==============================] - 3s 32ms/step - loss: 0.2127 - accuracy: 0.9274 - val_loss: 0.6779 - val_accuracy: 0.7778\n",
            "Epoch 353/700\n",
            "104/104 [==============================] - 3s 29ms/step - loss: 0.2108 - accuracy: 0.9238 - val_loss: 0.7236 - val_accuracy: 0.7585\n",
            "Epoch 354/700\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.2464 - accuracy: 0.9166 - val_loss: 0.7031 - val_accuracy: 0.7536\n",
            "Epoch 355/700\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.2188 - accuracy: 0.9311 - val_loss: 0.6126 - val_accuracy: 0.7874\n",
            "Epoch 356/700\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.2185 - accuracy: 0.9226 - val_loss: 0.7656 - val_accuracy: 0.7440\n",
            "Epoch 357/700\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.2181 - accuracy: 0.9196 - val_loss: 0.6145 - val_accuracy: 0.7971\n",
            "Epoch 358/700\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.2054 - accuracy: 0.9238 - val_loss: 0.6719 - val_accuracy: 0.7874\n",
            "Epoch 359/700\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.2320 - accuracy: 0.9214 - val_loss: 0.5701 - val_accuracy: 0.7826\n",
            "Epoch 360/700\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.2199 - accuracy: 0.9148 - val_loss: 0.5487 - val_accuracy: 0.8164\n",
            "Epoch 361/700\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.2143 - accuracy: 0.9208 - val_loss: 0.5418 - val_accuracy: 0.8213\n",
            "Epoch 362/700\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.2195 - accuracy: 0.9220 - val_loss: 0.6230 - val_accuracy: 0.8068\n",
            "Epoch 363/700\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.2152 - accuracy: 0.9208 - val_loss: 0.6828 - val_accuracy: 0.7391\n",
            "Epoch 364/700\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.2087 - accuracy: 0.9262 - val_loss: 0.6491 - val_accuracy: 0.7729\n",
            "Epoch 365/700\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.1995 - accuracy: 0.9244 - val_loss: 0.6488 - val_accuracy: 0.7729\n",
            "Epoch 366/700\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.2163 - accuracy: 0.9262 - val_loss: 0.6038 - val_accuracy: 0.7874\n",
            "Epoch 367/700\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.2185 - accuracy: 0.9256 - val_loss: 0.6641 - val_accuracy: 0.7826\n",
            "Epoch 368/700\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.2092 - accuracy: 0.9226 - val_loss: 0.6569 - val_accuracy: 0.7681\n",
            "Epoch 369/700\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.1850 - accuracy: 0.9341 - val_loss: 0.6583 - val_accuracy: 0.7681\n",
            "Epoch 370/700\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.1891 - accuracy: 0.9281 - val_loss: 0.6147 - val_accuracy: 0.7874\n",
            "Epoch 371/700\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.2221 - accuracy: 0.9154 - val_loss: 0.5996 - val_accuracy: 0.7874\n",
            "Epoch 372/700\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.2008 - accuracy: 0.9305 - val_loss: 0.6260 - val_accuracy: 0.7874\n",
            "Epoch 373/700\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.1952 - accuracy: 0.9299 - val_loss: 0.6477 - val_accuracy: 0.8068\n",
            "Epoch 374/700\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.2305 - accuracy: 0.9123 - val_loss: 0.6133 - val_accuracy: 0.7778\n",
            "Epoch 375/700\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.2049 - accuracy: 0.9220 - val_loss: 0.5984 - val_accuracy: 0.8068\n",
            "Epoch 376/700\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.1961 - accuracy: 0.9281 - val_loss: 0.6184 - val_accuracy: 0.7971\n",
            "Epoch 377/700\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.2017 - accuracy: 0.9329 - val_loss: 0.6462 - val_accuracy: 0.7729\n",
            "Epoch 378/700\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.1959 - accuracy: 0.9341 - val_loss: 0.6200 - val_accuracy: 0.7923\n",
            "Epoch 379/700\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.2283 - accuracy: 0.9184 - val_loss: 0.6080 - val_accuracy: 0.7826\n",
            "Epoch 380/700\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.2040 - accuracy: 0.9250 - val_loss: 0.6279 - val_accuracy: 0.7874\n",
            "Epoch 381/700\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.2027 - accuracy: 0.9274 - val_loss: 0.6334 - val_accuracy: 0.7874\n",
            "Epoch 382/700\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.1961 - accuracy: 0.9329 - val_loss: 0.6678 - val_accuracy: 0.7633\n",
            "Epoch 383/700\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.1923 - accuracy: 0.9317 - val_loss: 0.6260 - val_accuracy: 0.8019\n",
            "Epoch 384/700\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.2113 - accuracy: 0.9268 - val_loss: 0.6292 - val_accuracy: 0.8019\n",
            "Epoch 385/700\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.1878 - accuracy: 0.9268 - val_loss: 0.5943 - val_accuracy: 0.8068\n",
            "Epoch 386/700\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.1985 - accuracy: 0.9293 - val_loss: 0.6136 - val_accuracy: 0.7778\n",
            "Epoch 387/700\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.1803 - accuracy: 0.9347 - val_loss: 0.6298 - val_accuracy: 0.7778\n",
            "Epoch 388/700\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.2023 - accuracy: 0.9244 - val_loss: 0.6135 - val_accuracy: 0.7971\n",
            "Epoch 389/700\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.1816 - accuracy: 0.9281 - val_loss: 0.6185 - val_accuracy: 0.7874\n",
            "Epoch 390/700\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.2008 - accuracy: 0.9323 - val_loss: 0.6232 - val_accuracy: 0.8164\n",
            "Epoch 391/700\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.1821 - accuracy: 0.9353 - val_loss: 0.6859 - val_accuracy: 0.7923\n",
            "Epoch 392/700\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.1904 - accuracy: 0.9287 - val_loss: 0.6410 - val_accuracy: 0.7536\n",
            "Epoch 393/700\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.1830 - accuracy: 0.9353 - val_loss: 0.6370 - val_accuracy: 0.8019\n",
            "Epoch 394/700\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.1766 - accuracy: 0.9377 - val_loss: 0.6645 - val_accuracy: 0.7729\n",
            "Epoch 395/700\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.1962 - accuracy: 0.9256 - val_loss: 0.6850 - val_accuracy: 0.7633\n",
            "Epoch 396/700\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.1818 - accuracy: 0.9353 - val_loss: 0.6115 - val_accuracy: 0.7826\n",
            "Epoch 397/700\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.1892 - accuracy: 0.9311 - val_loss: 0.6028 - val_accuracy: 0.8068\n",
            "Epoch 398/700\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.2018 - accuracy: 0.9268 - val_loss: 0.6143 - val_accuracy: 0.7681\n",
            "Epoch 399/700\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.1758 - accuracy: 0.9359 - val_loss: 0.6663 - val_accuracy: 0.7729\n",
            "Epoch 400/700\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.2000 - accuracy: 0.9293 - val_loss: 0.6349 - val_accuracy: 0.8261\n",
            "Epoch 401/700\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.2008 - accuracy: 0.9238 - val_loss: 0.6136 - val_accuracy: 0.7826\n",
            "Epoch 402/700\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.2078 - accuracy: 0.9281 - val_loss: 0.6623 - val_accuracy: 0.7536\n",
            "Epoch 403/700\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.1927 - accuracy: 0.9329 - val_loss: 0.6791 - val_accuracy: 0.7681\n",
            "Epoch 404/700\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.1850 - accuracy: 0.9329 - val_loss: 0.7143 - val_accuracy: 0.7729\n",
            "Epoch 405/700\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.1869 - accuracy: 0.9323 - val_loss: 0.5880 - val_accuracy: 0.7874\n",
            "Epoch 406/700\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.1863 - accuracy: 0.9281 - val_loss: 0.7123 - val_accuracy: 0.7681\n",
            "Epoch 407/700\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.1888 - accuracy: 0.9305 - val_loss: 0.5996 - val_accuracy: 0.7923\n",
            "Epoch 408/700\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.1963 - accuracy: 0.9317 - val_loss: 0.6554 - val_accuracy: 0.7778\n",
            "Epoch 409/700\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.1847 - accuracy: 0.9305 - val_loss: 0.6877 - val_accuracy: 0.7874\n",
            "Epoch 410/700\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.1844 - accuracy: 0.9287 - val_loss: 0.6646 - val_accuracy: 0.7633\n",
            "Epoch 411/700\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.1697 - accuracy: 0.9432 - val_loss: 0.7044 - val_accuracy: 0.7585\n",
            "Epoch 412/700\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.1894 - accuracy: 0.9432 - val_loss: 0.6117 - val_accuracy: 0.7874\n",
            "Epoch 413/700\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.1915 - accuracy: 0.9317 - val_loss: 0.6952 - val_accuracy: 0.7874\n",
            "Epoch 414/700\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.2136 - accuracy: 0.9232 - val_loss: 0.6223 - val_accuracy: 0.7923\n",
            "Epoch 415/700\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.1930 - accuracy: 0.9353 - val_loss: 0.5792 - val_accuracy: 0.8068\n",
            "Epoch 416/700\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.1665 - accuracy: 0.9329 - val_loss: 0.6380 - val_accuracy: 0.7874\n",
            "Epoch 417/700\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.1970 - accuracy: 0.9341 - val_loss: 0.5711 - val_accuracy: 0.8068\n",
            "Epoch 418/700\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.1675 - accuracy: 0.9426 - val_loss: 0.5736 - val_accuracy: 0.7971\n",
            "Epoch 419/700\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.1731 - accuracy: 0.9341 - val_loss: 0.6309 - val_accuracy: 0.7971\n",
            "Epoch 420/700\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.2089 - accuracy: 0.9256 - val_loss: 0.6298 - val_accuracy: 0.7681\n",
            "Epoch 421/700\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.1939 - accuracy: 0.9341 - val_loss: 0.6141 - val_accuracy: 0.8116\n",
            "Epoch 422/700\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.1779 - accuracy: 0.9389 - val_loss: 0.6545 - val_accuracy: 0.7681\n",
            "Epoch 423/700\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.1644 - accuracy: 0.9432 - val_loss: 0.6519 - val_accuracy: 0.7874\n",
            "Epoch 424/700\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.1773 - accuracy: 0.9377 - val_loss: 0.6476 - val_accuracy: 0.8068\n",
            "Epoch 425/700\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.1658 - accuracy: 0.9329 - val_loss: 0.6779 - val_accuracy: 0.7681\n",
            "Epoch 426/700\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.1554 - accuracy: 0.9450 - val_loss: 0.7494 - val_accuracy: 0.7633\n",
            "Epoch 427/700\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.1806 - accuracy: 0.9329 - val_loss: 0.6701 - val_accuracy: 0.7874\n",
            "Epoch 428/700\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.1720 - accuracy: 0.9383 - val_loss: 0.5954 - val_accuracy: 0.7778\n",
            "Epoch 429/700\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.1746 - accuracy: 0.9341 - val_loss: 0.6917 - val_accuracy: 0.7681\n",
            "Epoch 430/700\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.1730 - accuracy: 0.9407 - val_loss: 0.6624 - val_accuracy: 0.7923\n",
            "Epoch 431/700\n",
            "104/104 [==============================] - 3s 24ms/step - loss: 0.1726 - accuracy: 0.9365 - val_loss: 0.7089 - val_accuracy: 0.7585\n",
            "Epoch 432/700\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.1984 - accuracy: 0.9365 - val_loss: 0.7130 - val_accuracy: 0.7585\n",
            "Epoch 433/700\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.1614 - accuracy: 0.9438 - val_loss: 0.6432 - val_accuracy: 0.7633\n",
            "Epoch 434/700\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.1607 - accuracy: 0.9407 - val_loss: 0.7103 - val_accuracy: 0.7536\n",
            "Epoch 435/700\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.1465 - accuracy: 0.9420 - val_loss: 0.7057 - val_accuracy: 0.8019\n",
            "Epoch 436/700\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.1968 - accuracy: 0.9335 - val_loss: 0.6550 - val_accuracy: 0.7874\n",
            "Epoch 437/700\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.1641 - accuracy: 0.9450 - val_loss: 0.6764 - val_accuracy: 0.7826\n",
            "Epoch 438/700\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.1559 - accuracy: 0.9450 - val_loss: 0.7010 - val_accuracy: 0.7585\n",
            "Epoch 439/700\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.1790 - accuracy: 0.9329 - val_loss: 0.6355 - val_accuracy: 0.7681\n",
            "Epoch 440/700\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.1811 - accuracy: 0.9359 - val_loss: 0.6197 - val_accuracy: 0.8116\n",
            "Epoch 441/700\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.1832 - accuracy: 0.9371 - val_loss: 0.7017 - val_accuracy: 0.7536\n",
            "Epoch 442/700\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.1706 - accuracy: 0.9389 - val_loss: 0.5981 - val_accuracy: 0.7923\n",
            "Epoch 443/700\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.1604 - accuracy: 0.9414 - val_loss: 0.6897 - val_accuracy: 0.7633\n",
            "Epoch 444/700\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.1511 - accuracy: 0.9468 - val_loss: 0.5655 - val_accuracy: 0.8116\n",
            "Epoch 445/700\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.1703 - accuracy: 0.9444 - val_loss: 0.5612 - val_accuracy: 0.8357\n",
            "Epoch 446/700\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.1625 - accuracy: 0.9432 - val_loss: 0.6745 - val_accuracy: 0.7536\n",
            "Epoch 447/700\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.1642 - accuracy: 0.9468 - val_loss: 0.5887 - val_accuracy: 0.7874\n",
            "Epoch 448/700\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.1663 - accuracy: 0.9383 - val_loss: 0.6287 - val_accuracy: 0.7923\n",
            "Epoch 449/700\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.1616 - accuracy: 0.9420 - val_loss: 0.6008 - val_accuracy: 0.8019\n",
            "Epoch 450/700\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.1655 - accuracy: 0.9365 - val_loss: 0.6167 - val_accuracy: 0.7874\n",
            "Epoch 451/700\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.1863 - accuracy: 0.9268 - val_loss: 0.5909 - val_accuracy: 0.8068\n",
            "Epoch 452/700\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.1478 - accuracy: 0.9516 - val_loss: 0.6621 - val_accuracy: 0.8261\n",
            "Epoch 453/700\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.1549 - accuracy: 0.9395 - val_loss: 0.5966 - val_accuracy: 0.8261\n",
            "Epoch 454/700\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.1801 - accuracy: 0.9335 - val_loss: 0.6392 - val_accuracy: 0.7633\n",
            "Epoch 455/700\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.1483 - accuracy: 0.9510 - val_loss: 0.5954 - val_accuracy: 0.8019\n",
            "Epoch 456/700\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.1426 - accuracy: 0.9468 - val_loss: 0.6973 - val_accuracy: 0.8068\n",
            "Epoch 457/700\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.1718 - accuracy: 0.9444 - val_loss: 0.5997 - val_accuracy: 0.8116\n",
            "Epoch 458/700\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.1376 - accuracy: 0.9492 - val_loss: 0.6377 - val_accuracy: 0.8116\n",
            "Epoch 459/700\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.1562 - accuracy: 0.9444 - val_loss: 0.6819 - val_accuracy: 0.7923\n",
            "Epoch 460/700\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.1375 - accuracy: 0.9534 - val_loss: 0.6126 - val_accuracy: 0.8019\n",
            "Epoch 461/700\n",
            "104/104 [==============================] - 2s 23ms/step - loss: 0.1818 - accuracy: 0.9365 - val_loss: 0.5939 - val_accuracy: 0.8019\n",
            "Epoch 462/700\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.1505 - accuracy: 0.9474 - val_loss: 0.6678 - val_accuracy: 0.7923\n",
            "Epoch 463/700\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.1590 - accuracy: 0.9438 - val_loss: 0.6278 - val_accuracy: 0.8213\n",
            "Epoch 464/700\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.1623 - accuracy: 0.9456 - val_loss: 0.7718 - val_accuracy: 0.7536\n",
            "Epoch 465/700\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.1639 - accuracy: 0.9401 - val_loss: 0.6387 - val_accuracy: 0.7874\n",
            "Epoch 466/700\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.1723 - accuracy: 0.9450 - val_loss: 0.6472 - val_accuracy: 0.8019\n",
            "Epoch 467/700\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.1626 - accuracy: 0.9407 - val_loss: 0.7653 - val_accuracy: 0.7874\n",
            "Epoch 468/700\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.1510 - accuracy: 0.9438 - val_loss: 0.6428 - val_accuracy: 0.8068\n",
            "Epoch 469/700\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.1423 - accuracy: 0.9462 - val_loss: 0.6986 - val_accuracy: 0.7778\n",
            "Epoch 470/700\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.1547 - accuracy: 0.9438 - val_loss: 0.7224 - val_accuracy: 0.7778\n",
            "Epoch 471/700\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.1534 - accuracy: 0.9474 - val_loss: 0.7041 - val_accuracy: 0.7778\n",
            "Epoch 472/700\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.1586 - accuracy: 0.9480 - val_loss: 0.6838 - val_accuracy: 0.8019\n",
            "Epoch 473/700\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.1611 - accuracy: 0.9504 - val_loss: 0.6509 - val_accuracy: 0.7971\n",
            "Epoch 474/700\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.1591 - accuracy: 0.9486 - val_loss: 0.6554 - val_accuracy: 0.7778\n",
            "Epoch 475/700\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.1509 - accuracy: 0.9504 - val_loss: 0.5889 - val_accuracy: 0.8019\n",
            "Epoch 476/700\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.1560 - accuracy: 0.9444 - val_loss: 0.6333 - val_accuracy: 0.7874\n",
            "Epoch 477/700\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.1762 - accuracy: 0.9492 - val_loss: 0.6611 - val_accuracy: 0.7681\n",
            "Epoch 478/700\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.1477 - accuracy: 0.9456 - val_loss: 0.5814 - val_accuracy: 0.8261\n",
            "Epoch 479/700\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.1555 - accuracy: 0.9468 - val_loss: 0.6337 - val_accuracy: 0.7923\n",
            "Epoch 480/700\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.1710 - accuracy: 0.9438 - val_loss: 0.6092 - val_accuracy: 0.7874\n",
            "Epoch 481/700\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.1539 - accuracy: 0.9498 - val_loss: 0.5586 - val_accuracy: 0.7971\n",
            "Epoch 482/700\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.1326 - accuracy: 0.9547 - val_loss: 0.5739 - val_accuracy: 0.7923\n",
            "Epoch 483/700\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.1455 - accuracy: 0.9450 - val_loss: 0.6283 - val_accuracy: 0.8261\n",
            "Epoch 484/700\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.1267 - accuracy: 0.9559 - val_loss: 0.6566 - val_accuracy: 0.7971\n",
            "Epoch 485/700\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.1477 - accuracy: 0.9498 - val_loss: 0.6063 - val_accuracy: 0.8068\n",
            "Epoch 486/700\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.1503 - accuracy: 0.9414 - val_loss: 0.6583 - val_accuracy: 0.7874\n",
            "Epoch 487/700\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.1541 - accuracy: 0.9432 - val_loss: 0.7203 - val_accuracy: 0.7826\n",
            "Epoch 488/700\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.1441 - accuracy: 0.9534 - val_loss: 0.6446 - val_accuracy: 0.7923\n",
            "Epoch 489/700\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.1411 - accuracy: 0.9486 - val_loss: 0.7375 - val_accuracy: 0.7923\n",
            "Epoch 490/700\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.1606 - accuracy: 0.9450 - val_loss: 0.7033 - val_accuracy: 0.8068\n",
            "Epoch 491/700\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.1330 - accuracy: 0.9553 - val_loss: 0.7306 - val_accuracy: 0.7488\n",
            "Epoch 492/700\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.1609 - accuracy: 0.9522 - val_loss: 0.7371 - val_accuracy: 0.7874\n",
            "Epoch 493/700\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.1970 - accuracy: 0.9299 - val_loss: 0.6864 - val_accuracy: 0.8164\n",
            "Epoch 494/700\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.1489 - accuracy: 0.9456 - val_loss: 0.6679 - val_accuracy: 0.7923\n",
            "Epoch 495/700\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.1575 - accuracy: 0.9480 - val_loss: 0.7365 - val_accuracy: 0.8068\n",
            "Epoch 496/700\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.1676 - accuracy: 0.9420 - val_loss: 0.6886 - val_accuracy: 0.7874\n",
            "Epoch 497/700\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.1571 - accuracy: 0.9438 - val_loss: 0.7582 - val_accuracy: 0.7729\n",
            "Epoch 498/700\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.1640 - accuracy: 0.9426 - val_loss: 0.6987 - val_accuracy: 0.7874\n",
            "Epoch 499/700\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.1511 - accuracy: 0.9456 - val_loss: 0.5697 - val_accuracy: 0.8068\n",
            "Epoch 500/700\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.1461 - accuracy: 0.9498 - val_loss: 0.6373 - val_accuracy: 0.7778\n",
            "Epoch 501/700\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.1444 - accuracy: 0.9541 - val_loss: 0.6725 - val_accuracy: 0.7874\n",
            "Epoch 502/700\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.1397 - accuracy: 0.9504 - val_loss: 0.6562 - val_accuracy: 0.7923\n",
            "Epoch 503/700\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.1457 - accuracy: 0.9492 - val_loss: 0.6304 - val_accuracy: 0.7923\n",
            "Epoch 504/700\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.1333 - accuracy: 0.9492 - val_loss: 0.6767 - val_accuracy: 0.7826\n",
            "Epoch 505/700\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.1461 - accuracy: 0.9498 - val_loss: 0.6570 - val_accuracy: 0.7778\n",
            "Epoch 506/700\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.1541 - accuracy: 0.9462 - val_loss: 0.6733 - val_accuracy: 0.7826\n",
            "Epoch 507/700\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.1469 - accuracy: 0.9480 - val_loss: 0.6021 - val_accuracy: 0.7923\n",
            "Epoch 508/700\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.1690 - accuracy: 0.9474 - val_loss: 0.6579 - val_accuracy: 0.8019\n",
            "Epoch 509/700\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.1299 - accuracy: 0.9534 - val_loss: 0.6696 - val_accuracy: 0.7923\n",
            "Epoch 510/700\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.1570 - accuracy: 0.9468 - val_loss: 0.5930 - val_accuracy: 0.8116\n",
            "Epoch 511/700\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.1337 - accuracy: 0.9553 - val_loss: 0.6268 - val_accuracy: 0.8261\n",
            "Epoch 512/700\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.1364 - accuracy: 0.9450 - val_loss: 0.6846 - val_accuracy: 0.8019\n",
            "Epoch 513/700\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.1498 - accuracy: 0.9450 - val_loss: 0.7983 - val_accuracy: 0.7440\n",
            "Epoch 514/700\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.1496 - accuracy: 0.9522 - val_loss: 0.7406 - val_accuracy: 0.7826\n",
            "Epoch 515/700\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.1279 - accuracy: 0.9541 - val_loss: 0.7000 - val_accuracy: 0.8068\n",
            "Epoch 516/700\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.1109 - accuracy: 0.9601 - val_loss: 0.6990 - val_accuracy: 0.8019\n",
            "Epoch 517/700\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.1534 - accuracy: 0.9432 - val_loss: 0.6914 - val_accuracy: 0.7778\n",
            "Epoch 518/700\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.1457 - accuracy: 0.9504 - val_loss: 0.6864 - val_accuracy: 0.8116\n",
            "Epoch 519/700\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.1265 - accuracy: 0.9565 - val_loss: 0.7186 - val_accuracy: 0.7826\n",
            "Epoch 520/700\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.1491 - accuracy: 0.9426 - val_loss: 0.7066 - val_accuracy: 0.8068\n",
            "Epoch 521/700\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.1532 - accuracy: 0.9504 - val_loss: 0.6670 - val_accuracy: 0.8116\n",
            "Epoch 522/700\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.1341 - accuracy: 0.9559 - val_loss: 0.7145 - val_accuracy: 0.8164\n",
            "Epoch 523/700\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.1378 - accuracy: 0.9547 - val_loss: 0.6551 - val_accuracy: 0.8213\n",
            "Epoch 524/700\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.1271 - accuracy: 0.9528 - val_loss: 0.6413 - val_accuracy: 0.7923\n",
            "Epoch 525/700\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.1505 - accuracy: 0.9474 - val_loss: 0.6587 - val_accuracy: 0.8068\n",
            "Epoch 526/700\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.1496 - accuracy: 0.9474 - val_loss: 0.6364 - val_accuracy: 0.8019\n",
            "Epoch 527/700\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.1541 - accuracy: 0.9462 - val_loss: 0.5628 - val_accuracy: 0.8068\n",
            "Epoch 528/700\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.1619 - accuracy: 0.9504 - val_loss: 0.6144 - val_accuracy: 0.8309\n",
            "Epoch 529/700\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.1447 - accuracy: 0.9498 - val_loss: 0.7153 - val_accuracy: 0.8068\n",
            "Epoch 530/700\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.1410 - accuracy: 0.9522 - val_loss: 0.6539 - val_accuracy: 0.8213\n",
            "Epoch 531/700\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.1196 - accuracy: 0.9553 - val_loss: 0.7273 - val_accuracy: 0.7778\n",
            "Epoch 532/700\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.1436 - accuracy: 0.9516 - val_loss: 0.6063 - val_accuracy: 0.8116\n",
            "Epoch 533/700\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.1357 - accuracy: 0.9534 - val_loss: 0.7935 - val_accuracy: 0.7874\n",
            "Epoch 534/700\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.1508 - accuracy: 0.9486 - val_loss: 0.6590 - val_accuracy: 0.7826\n",
            "Epoch 535/700\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.1318 - accuracy: 0.9565 - val_loss: 0.6185 - val_accuracy: 0.7874\n",
            "Epoch 536/700\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.1381 - accuracy: 0.9486 - val_loss: 0.6536 - val_accuracy: 0.8068\n",
            "Epoch 537/700\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.1310 - accuracy: 0.9559 - val_loss: 0.6102 - val_accuracy: 0.8019\n",
            "Epoch 538/700\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.1208 - accuracy: 0.9559 - val_loss: 0.6764 - val_accuracy: 0.7874\n",
            "Epoch 539/700\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.1468 - accuracy: 0.9559 - val_loss: 0.6610 - val_accuracy: 0.8019\n",
            "Epoch 540/700\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.1354 - accuracy: 0.9504 - val_loss: 0.6766 - val_accuracy: 0.7729\n",
            "Epoch 541/700\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.1196 - accuracy: 0.9522 - val_loss: 0.7996 - val_accuracy: 0.7923\n",
            "Epoch 542/700\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.1246 - accuracy: 0.9565 - val_loss: 0.6474 - val_accuracy: 0.8309\n",
            "Epoch 543/700\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.1181 - accuracy: 0.9571 - val_loss: 0.6017 - val_accuracy: 0.8164\n",
            "Epoch 544/700\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.1348 - accuracy: 0.9522 - val_loss: 0.6506 - val_accuracy: 0.8213\n",
            "Epoch 545/700\n",
            "104/104 [==============================] - 2s 23ms/step - loss: 0.1538 - accuracy: 0.9498 - val_loss: 0.6524 - val_accuracy: 0.7923\n",
            "Epoch 546/700\n",
            "104/104 [==============================] - 2s 21ms/step - loss: 0.1518 - accuracy: 0.9486 - val_loss: 0.6683 - val_accuracy: 0.8116\n",
            "Epoch 547/700\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.1193 - accuracy: 0.9522 - val_loss: 0.7870 - val_accuracy: 0.7729\n",
            "Epoch 548/700\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.1500 - accuracy: 0.9492 - val_loss: 0.6658 - val_accuracy: 0.8213\n",
            "Epoch 549/700\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.1132 - accuracy: 0.9492 - val_loss: 0.8145 - val_accuracy: 0.7923\n",
            "Epoch 550/700\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.1653 - accuracy: 0.9492 - val_loss: 0.7536 - val_accuracy: 0.7681\n",
            "Epoch 551/700\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.1369 - accuracy: 0.9553 - val_loss: 0.7381 - val_accuracy: 0.7874\n",
            "Epoch 552/700\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.1508 - accuracy: 0.9468 - val_loss: 0.7118 - val_accuracy: 0.8164\n",
            "Epoch 553/700\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.1403 - accuracy: 0.9474 - val_loss: 0.6653 - val_accuracy: 0.8116\n",
            "Epoch 554/700\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.1144 - accuracy: 0.9589 - val_loss: 0.7276 - val_accuracy: 0.8068\n",
            "Epoch 555/700\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.1114 - accuracy: 0.9661 - val_loss: 0.6396 - val_accuracy: 0.8019\n",
            "Epoch 556/700\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.1314 - accuracy: 0.9534 - val_loss: 0.7124 - val_accuracy: 0.7778\n",
            "Epoch 557/700\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.1124 - accuracy: 0.9571 - val_loss: 0.6481 - val_accuracy: 0.8261\n",
            "Epoch 558/700\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.1328 - accuracy: 0.9565 - val_loss: 0.6419 - val_accuracy: 0.8309\n",
            "Epoch 559/700\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.1483 - accuracy: 0.9480 - val_loss: 0.6318 - val_accuracy: 0.7874\n",
            "Epoch 560/700\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.1209 - accuracy: 0.9547 - val_loss: 0.6577 - val_accuracy: 0.8164\n",
            "Epoch 561/700\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.1334 - accuracy: 0.9559 - val_loss: 0.6321 - val_accuracy: 0.7971\n",
            "Epoch 562/700\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.1256 - accuracy: 0.9553 - val_loss: 0.6388 - val_accuracy: 0.8068\n",
            "Epoch 563/700\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.1323 - accuracy: 0.9577 - val_loss: 0.7143 - val_accuracy: 0.8116\n",
            "Epoch 564/700\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.1323 - accuracy: 0.9547 - val_loss: 0.7284 - val_accuracy: 0.8116\n",
            "Epoch 565/700\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.1258 - accuracy: 0.9510 - val_loss: 0.7303 - val_accuracy: 0.8116\n",
            "Epoch 566/700\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.1169 - accuracy: 0.9595 - val_loss: 0.6975 - val_accuracy: 0.8164\n",
            "Epoch 567/700\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.1573 - accuracy: 0.9510 - val_loss: 0.5962 - val_accuracy: 0.8213\n",
            "Epoch 568/700\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.1156 - accuracy: 0.9571 - val_loss: 0.7252 - val_accuracy: 0.8261\n",
            "Epoch 569/700\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.1181 - accuracy: 0.9625 - val_loss: 0.6683 - val_accuracy: 0.8309\n",
            "Epoch 570/700\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.1581 - accuracy: 0.9516 - val_loss: 0.6144 - val_accuracy: 0.8213\n",
            "Epoch 571/700\n",
            "104/104 [==============================] - 2s 23ms/step - loss: 0.1296 - accuracy: 0.9583 - val_loss: 0.6519 - val_accuracy: 0.8164\n",
            "Epoch 572/700\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.1250 - accuracy: 0.9565 - val_loss: 0.6349 - val_accuracy: 0.8164\n",
            "Epoch 573/700\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.1479 - accuracy: 0.9522 - val_loss: 0.7297 - val_accuracy: 0.8019\n",
            "Epoch 574/700\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.1352 - accuracy: 0.9510 - val_loss: 0.6135 - val_accuracy: 0.8261\n",
            "Epoch 575/700\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.1114 - accuracy: 0.9607 - val_loss: 0.6431 - val_accuracy: 0.8309\n",
            "Epoch 576/700\n",
            "104/104 [==============================] - 2s 23ms/step - loss: 0.1494 - accuracy: 0.9559 - val_loss: 0.6097 - val_accuracy: 0.8116\n",
            "Epoch 577/700\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.1014 - accuracy: 0.9619 - val_loss: 0.6729 - val_accuracy: 0.8261\n",
            "Epoch 578/700\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.1252 - accuracy: 0.9577 - val_loss: 0.9365 - val_accuracy: 0.7826\n",
            "Epoch 579/700\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.1387 - accuracy: 0.9595 - val_loss: 0.7146 - val_accuracy: 0.8261\n",
            "Epoch 580/700\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.1135 - accuracy: 0.9601 - val_loss: 0.7410 - val_accuracy: 0.8068\n",
            "Epoch 581/700\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.1162 - accuracy: 0.9607 - val_loss: 0.7080 - val_accuracy: 0.7971\n",
            "Epoch 582/700\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.1171 - accuracy: 0.9619 - val_loss: 0.7144 - val_accuracy: 0.8164\n",
            "Epoch 583/700\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.1162 - accuracy: 0.9637 - val_loss: 0.7016 - val_accuracy: 0.8261\n",
            "Epoch 584/700\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.1044 - accuracy: 0.9661 - val_loss: 0.7105 - val_accuracy: 0.7826\n",
            "Epoch 585/700\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.1257 - accuracy: 0.9583 - val_loss: 0.6890 - val_accuracy: 0.7923\n",
            "Epoch 586/700\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.1350 - accuracy: 0.9565 - val_loss: 0.6760 - val_accuracy: 0.8261\n",
            "Epoch 587/700\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.1340 - accuracy: 0.9559 - val_loss: 0.6396 - val_accuracy: 0.7923\n",
            "Epoch 588/700\n",
            "104/104 [==============================] - 2s 23ms/step - loss: 0.1483 - accuracy: 0.9553 - val_loss: 0.6967 - val_accuracy: 0.8213\n",
            "Epoch 589/700\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.1326 - accuracy: 0.9541 - val_loss: 0.6523 - val_accuracy: 0.8164\n",
            "Epoch 590/700\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.1110 - accuracy: 0.9637 - val_loss: 0.6746 - val_accuracy: 0.8164\n",
            "Epoch 591/700\n",
            "104/104 [==============================] - 2s 23ms/step - loss: 0.1112 - accuracy: 0.9601 - val_loss: 0.6928 - val_accuracy: 0.7488\n",
            "Epoch 592/700\n",
            "104/104 [==============================] - 2s 23ms/step - loss: 0.1377 - accuracy: 0.9534 - val_loss: 0.6484 - val_accuracy: 0.8019\n",
            "Epoch 593/700\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.1062 - accuracy: 0.9649 - val_loss: 0.6870 - val_accuracy: 0.8164\n",
            "Epoch 594/700\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.1384 - accuracy: 0.9643 - val_loss: 0.7183 - val_accuracy: 0.7826\n",
            "Epoch 595/700\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.1305 - accuracy: 0.9547 - val_loss: 0.6884 - val_accuracy: 0.7971\n",
            "Epoch 596/700\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.1457 - accuracy: 0.9480 - val_loss: 0.7222 - val_accuracy: 0.7874\n",
            "Epoch 597/700\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.1176 - accuracy: 0.9595 - val_loss: 0.7094 - val_accuracy: 0.8019\n",
            "Epoch 598/700\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.1280 - accuracy: 0.9577 - val_loss: 0.6741 - val_accuracy: 0.8019\n",
            "Epoch 599/700\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.1017 - accuracy: 0.9661 - val_loss: 0.7035 - val_accuracy: 0.8164\n",
            "Epoch 600/700\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.1255 - accuracy: 0.9619 - val_loss: 0.8690 - val_accuracy: 0.8261\n",
            "Epoch 601/700\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.1305 - accuracy: 0.9601 - val_loss: 0.8446 - val_accuracy: 0.7585\n",
            "Epoch 602/700\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.1091 - accuracy: 0.9680 - val_loss: 0.7674 - val_accuracy: 0.7826\n",
            "Epoch 603/700\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.1491 - accuracy: 0.9450 - val_loss: 0.7579 - val_accuracy: 0.8116\n",
            "Epoch 604/700\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.1182 - accuracy: 0.9553 - val_loss: 0.8705 - val_accuracy: 0.7971\n",
            "Epoch 605/700\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.1228 - accuracy: 0.9631 - val_loss: 0.7374 - val_accuracy: 0.8068\n",
            "Epoch 606/700\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.1413 - accuracy: 0.9547 - val_loss: 0.7690 - val_accuracy: 0.7923\n",
            "Epoch 607/700\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.1359 - accuracy: 0.9528 - val_loss: 0.6766 - val_accuracy: 0.7971\n",
            "Epoch 608/700\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.1207 - accuracy: 0.9661 - val_loss: 0.7978 - val_accuracy: 0.7874\n",
            "Epoch 609/700\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.1246 - accuracy: 0.9601 - val_loss: 0.7614 - val_accuracy: 0.8068\n",
            "Epoch 610/700\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.1086 - accuracy: 0.9643 - val_loss: 0.6034 - val_accuracy: 0.8164\n",
            "Epoch 611/700\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.1314 - accuracy: 0.9541 - val_loss: 0.7975 - val_accuracy: 0.7826\n",
            "Epoch 612/700\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.1169 - accuracy: 0.9619 - val_loss: 0.7647 - val_accuracy: 0.8116\n",
            "Epoch 613/700\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.1225 - accuracy: 0.9601 - val_loss: 0.8263 - val_accuracy: 0.7391\n",
            "Epoch 614/700\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.1076 - accuracy: 0.9643 - val_loss: 0.7944 - val_accuracy: 0.7633\n",
            "Epoch 615/700\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.1366 - accuracy: 0.9541 - val_loss: 0.9573 - val_accuracy: 0.7729\n",
            "Epoch 616/700\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.1085 - accuracy: 0.9619 - val_loss: 0.7777 - val_accuracy: 0.7778\n",
            "Epoch 617/700\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.1308 - accuracy: 0.9601 - val_loss: 0.8009 - val_accuracy: 0.8068\n",
            "Epoch 618/700\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.1379 - accuracy: 0.9589 - val_loss: 0.7910 - val_accuracy: 0.8019\n",
            "Epoch 619/700\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.1268 - accuracy: 0.9649 - val_loss: 0.7752 - val_accuracy: 0.8116\n",
            "Epoch 620/700\n",
            "104/104 [==============================] - 2s 23ms/step - loss: 0.1279 - accuracy: 0.9619 - val_loss: 0.8224 - val_accuracy: 0.7826\n",
            "Epoch 621/700\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.1130 - accuracy: 0.9643 - val_loss: 0.6381 - val_accuracy: 0.8261\n",
            "Epoch 622/700\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.1340 - accuracy: 0.9553 - val_loss: 0.7864 - val_accuracy: 0.7778\n",
            "Epoch 623/700\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.0890 - accuracy: 0.9710 - val_loss: 0.7730 - val_accuracy: 0.7971\n",
            "Epoch 624/700\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.1161 - accuracy: 0.9559 - val_loss: 0.7803 - val_accuracy: 0.7971\n",
            "Epoch 625/700\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.1183 - accuracy: 0.9607 - val_loss: 0.7799 - val_accuracy: 0.8164\n",
            "Epoch 626/700\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.1109 - accuracy: 0.9674 - val_loss: 0.8732 - val_accuracy: 0.7681\n",
            "Epoch 627/700\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.1557 - accuracy: 0.9559 - val_loss: 0.7264 - val_accuracy: 0.7826\n",
            "Epoch 628/700\n",
            "104/104 [==============================] - 2s 23ms/step - loss: 0.1125 - accuracy: 0.9674 - val_loss: 0.7954 - val_accuracy: 0.8116\n",
            "Epoch 629/700\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.1493 - accuracy: 0.9516 - val_loss: 0.7247 - val_accuracy: 0.8164\n",
            "Epoch 630/700\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.1253 - accuracy: 0.9571 - val_loss: 0.7016 - val_accuracy: 0.8261\n",
            "Epoch 631/700\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.1122 - accuracy: 0.9595 - val_loss: 0.7230 - val_accuracy: 0.7923\n",
            "Epoch 632/700\n",
            "104/104 [==============================] - 2s 23ms/step - loss: 0.1188 - accuracy: 0.9698 - val_loss: 0.6934 - val_accuracy: 0.8019\n",
            "Epoch 633/700\n",
            "104/104 [==============================] - 2s 23ms/step - loss: 0.1413 - accuracy: 0.9522 - val_loss: 0.6611 - val_accuracy: 0.8261\n",
            "Epoch 634/700\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.1098 - accuracy: 0.9655 - val_loss: 0.6771 - val_accuracy: 0.8357\n",
            "Epoch 635/700\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.1364 - accuracy: 0.9571 - val_loss: 0.7104 - val_accuracy: 0.8309\n",
            "Epoch 636/700\n",
            "104/104 [==============================] - 2s 23ms/step - loss: 0.1311 - accuracy: 0.9553 - val_loss: 0.7513 - val_accuracy: 0.7729\n",
            "Epoch 637/700\n",
            "104/104 [==============================] - 2s 23ms/step - loss: 0.1086 - accuracy: 0.9661 - val_loss: 0.7260 - val_accuracy: 0.8261\n",
            "Epoch 638/700\n",
            "104/104 [==============================] - 2s 23ms/step - loss: 0.1100 - accuracy: 0.9637 - val_loss: 0.7740 - val_accuracy: 0.8019\n",
            "Epoch 639/700\n",
            "104/104 [==============================] - 2s 23ms/step - loss: 0.1240 - accuracy: 0.9637 - val_loss: 0.7195 - val_accuracy: 0.8261\n",
            "Epoch 640/700\n",
            "104/104 [==============================] - 3s 26ms/step - loss: 0.1147 - accuracy: 0.9655 - val_loss: 0.6987 - val_accuracy: 0.8019\n",
            "Epoch 641/700\n",
            "104/104 [==============================] - 2s 23ms/step - loss: 0.1239 - accuracy: 0.9619 - val_loss: 0.8176 - val_accuracy: 0.7874\n",
            "Epoch 642/700\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.1311 - accuracy: 0.9565 - val_loss: 0.8205 - val_accuracy: 0.8261\n",
            "Epoch 643/700\n",
            "104/104 [==============================] - 2s 23ms/step - loss: 0.1146 - accuracy: 0.9625 - val_loss: 0.7172 - val_accuracy: 0.8213\n",
            "Epoch 644/700\n",
            "104/104 [==============================] - 2s 23ms/step - loss: 0.0951 - accuracy: 0.9625 - val_loss: 0.7699 - val_accuracy: 0.8019\n",
            "Epoch 645/700\n",
            "104/104 [==============================] - 2s 23ms/step - loss: 0.1194 - accuracy: 0.9649 - val_loss: 0.7060 - val_accuracy: 0.7778\n",
            "Epoch 646/700\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.1279 - accuracy: 0.9595 - val_loss: 0.9701 - val_accuracy: 0.7440\n",
            "Epoch 647/700\n",
            "104/104 [==============================] - 2s 23ms/step - loss: 0.1090 - accuracy: 0.9649 - val_loss: 0.7185 - val_accuracy: 0.8357\n",
            "Epoch 648/700\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.1408 - accuracy: 0.9655 - val_loss: 0.8305 - val_accuracy: 0.8164\n",
            "Epoch 649/700\n",
            "104/104 [==============================] - 2s 23ms/step - loss: 0.1174 - accuracy: 0.9577 - val_loss: 0.7412 - val_accuracy: 0.8213\n",
            "Epoch 650/700\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.1266 - accuracy: 0.9589 - val_loss: 0.7461 - val_accuracy: 0.7826\n",
            "Epoch 651/700\n",
            "104/104 [==============================] - 2s 23ms/step - loss: 0.1265 - accuracy: 0.9643 - val_loss: 0.8023 - val_accuracy: 0.8068\n",
            "Epoch 652/700\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.0981 - accuracy: 0.9704 - val_loss: 0.7833 - val_accuracy: 0.8068\n",
            "Epoch 653/700\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.1211 - accuracy: 0.9601 - val_loss: 0.7935 - val_accuracy: 0.8019\n",
            "Epoch 654/700\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.1283 - accuracy: 0.9534 - val_loss: 0.7264 - val_accuracy: 0.8164\n",
            "Epoch 655/700\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.0973 - accuracy: 0.9686 - val_loss: 0.7687 - val_accuracy: 0.7971\n",
            "Epoch 656/700\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.1224 - accuracy: 0.9565 - val_loss: 0.7407 - val_accuracy: 0.7971\n",
            "Epoch 657/700\n",
            "104/104 [==============================] - 2s 23ms/step - loss: 0.1016 - accuracy: 0.9680 - val_loss: 0.7290 - val_accuracy: 0.7874\n",
            "Epoch 658/700\n",
            "104/104 [==============================] - 2s 23ms/step - loss: 0.1208 - accuracy: 0.9649 - val_loss: 0.6168 - val_accuracy: 0.8261\n",
            "Epoch 659/700\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.0856 - accuracy: 0.9704 - val_loss: 0.7408 - val_accuracy: 0.8068\n",
            "Epoch 660/700\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.1242 - accuracy: 0.9607 - val_loss: 0.7607 - val_accuracy: 0.8116\n",
            "Epoch 661/700\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.1021 - accuracy: 0.9667 - val_loss: 0.7716 - val_accuracy: 0.7729\n",
            "Epoch 662/700\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.1241 - accuracy: 0.9607 - val_loss: 0.8086 - val_accuracy: 0.8019\n",
            "Epoch 663/700\n",
            "104/104 [==============================] - 2s 23ms/step - loss: 0.1326 - accuracy: 0.9583 - val_loss: 0.7263 - val_accuracy: 0.8068\n",
            "Epoch 664/700\n",
            "104/104 [==============================] - 2s 23ms/step - loss: 0.1067 - accuracy: 0.9607 - val_loss: 0.6891 - val_accuracy: 0.7874\n",
            "Epoch 665/700\n",
            "104/104 [==============================] - 2s 23ms/step - loss: 0.1200 - accuracy: 0.9619 - val_loss: 0.8069 - val_accuracy: 0.8068\n",
            "Epoch 666/700\n",
            "104/104 [==============================] - 2s 23ms/step - loss: 0.1074 - accuracy: 0.9661 - val_loss: 0.7940 - val_accuracy: 0.7778\n",
            "Epoch 667/700\n",
            "104/104 [==============================] - 2s 23ms/step - loss: 0.1188 - accuracy: 0.9571 - val_loss: 0.7342 - val_accuracy: 0.7971\n",
            "Epoch 668/700\n",
            "104/104 [==============================] - 2s 23ms/step - loss: 0.0986 - accuracy: 0.9674 - val_loss: 0.7192 - val_accuracy: 0.7923\n",
            "Epoch 669/700\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.1130 - accuracy: 0.9619 - val_loss: 0.7358 - val_accuracy: 0.8019\n",
            "Epoch 670/700\n",
            "104/104 [==============================] - 2s 23ms/step - loss: 0.1369 - accuracy: 0.9541 - val_loss: 0.7622 - val_accuracy: 0.7923\n",
            "Epoch 671/700\n",
            "104/104 [==============================] - 2s 23ms/step - loss: 0.1075 - accuracy: 0.9625 - val_loss: 0.7401 - val_accuracy: 0.7971\n",
            "Epoch 672/700\n",
            "104/104 [==============================] - 2s 23ms/step - loss: 0.1008 - accuracy: 0.9631 - val_loss: 0.7393 - val_accuracy: 0.8357\n",
            "Epoch 673/700\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.1323 - accuracy: 0.9522 - val_loss: 0.7042 - val_accuracy: 0.8068\n",
            "Epoch 674/700\n",
            "104/104 [==============================] - 2s 23ms/step - loss: 0.1098 - accuracy: 0.9637 - val_loss: 0.6719 - val_accuracy: 0.8309\n",
            "Epoch 675/700\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.1268 - accuracy: 0.9631 - val_loss: 0.6979 - val_accuracy: 0.8357\n",
            "Epoch 676/700\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.0992 - accuracy: 0.9716 - val_loss: 0.7994 - val_accuracy: 0.7778\n",
            "Epoch 677/700\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.1445 - accuracy: 0.9607 - val_loss: 0.8617 - val_accuracy: 0.7826\n",
            "Epoch 678/700\n",
            "104/104 [==============================] - 2s 23ms/step - loss: 0.0993 - accuracy: 0.9716 - val_loss: 0.8161 - val_accuracy: 0.8309\n",
            "Epoch 679/700\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.1339 - accuracy: 0.9559 - val_loss: 0.6821 - val_accuracy: 0.8116\n",
            "Epoch 680/700\n",
            "104/104 [==============================] - 2s 23ms/step - loss: 0.1080 - accuracy: 0.9583 - val_loss: 0.8171 - val_accuracy: 0.7874\n",
            "Epoch 681/700\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.1203 - accuracy: 0.9607 - val_loss: 0.8613 - val_accuracy: 0.7874\n",
            "Epoch 682/700\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.1201 - accuracy: 0.9613 - val_loss: 0.8061 - val_accuracy: 0.8116\n",
            "Epoch 683/700\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.1292 - accuracy: 0.9589 - val_loss: 0.7891 - val_accuracy: 0.8068\n",
            "Epoch 684/700\n",
            "104/104 [==============================] - 2s 23ms/step - loss: 0.1051 - accuracy: 0.9601 - val_loss: 0.8717 - val_accuracy: 0.7874\n",
            "Epoch 685/700\n",
            "104/104 [==============================] - 2s 23ms/step - loss: 0.1215 - accuracy: 0.9534 - val_loss: 0.8111 - val_accuracy: 0.7826\n",
            "Epoch 686/700\n",
            "104/104 [==============================] - 2s 23ms/step - loss: 0.0993 - accuracy: 0.9692 - val_loss: 0.7346 - val_accuracy: 0.8164\n",
            "Epoch 687/700\n",
            "104/104 [==============================] - 2s 23ms/step - loss: 0.1370 - accuracy: 0.9625 - val_loss: 0.8383 - val_accuracy: 0.7923\n",
            "Epoch 688/700\n",
            "104/104 [==============================] - 2s 23ms/step - loss: 0.0873 - accuracy: 0.9680 - val_loss: 0.7370 - val_accuracy: 0.8068\n",
            "Epoch 689/700\n",
            "104/104 [==============================] - 2s 23ms/step - loss: 0.0917 - accuracy: 0.9649 - val_loss: 0.7995 - val_accuracy: 0.8068\n",
            "Epoch 690/700\n",
            "104/104 [==============================] - 2s 23ms/step - loss: 0.1238 - accuracy: 0.9631 - val_loss: 0.7030 - val_accuracy: 0.8116\n",
            "Epoch 691/700\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.1413 - accuracy: 0.9541 - val_loss: 0.7501 - val_accuracy: 0.8213\n",
            "Epoch 692/700\n",
            "104/104 [==============================] - 2s 23ms/step - loss: 0.1065 - accuracy: 0.9655 - val_loss: 0.7720 - val_accuracy: 0.8357\n",
            "Epoch 693/700\n",
            "104/104 [==============================] - 2s 23ms/step - loss: 0.1131 - accuracy: 0.9595 - val_loss: 0.6403 - val_accuracy: 0.8068\n",
            "Epoch 694/700\n",
            "104/104 [==============================] - 2s 22ms/step - loss: 0.1283 - accuracy: 0.9589 - val_loss: 0.7267 - val_accuracy: 0.8019\n",
            "Epoch 695/700\n",
            "104/104 [==============================] - 2s 23ms/step - loss: 0.0945 - accuracy: 0.9661 - val_loss: 0.7480 - val_accuracy: 0.8164\n",
            "Epoch 696/700\n",
            "104/104 [==============================] - 2s 23ms/step - loss: 0.1248 - accuracy: 0.9607 - val_loss: 0.7120 - val_accuracy: 0.8309\n",
            "Epoch 697/700\n",
            "104/104 [==============================] - 2s 23ms/step - loss: 0.1340 - accuracy: 0.9637 - val_loss: 0.6500 - val_accuracy: 0.8357\n",
            "Epoch 698/700\n",
            "104/104 [==============================] - 2s 23ms/step - loss: 0.1180 - accuracy: 0.9601 - val_loss: 0.7503 - val_accuracy: 0.8213\n",
            "Epoch 699/700\n",
            "104/104 [==============================] - 2s 23ms/step - loss: 0.1165 - accuracy: 0.9625 - val_loss: 0.7280 - val_accuracy: 0.8164\n",
            "Epoch 700/700\n",
            "104/104 [==============================] - 2s 23ms/step - loss: 0.1304 - accuracy: 0.9547 - val_loss: 0.6663 - val_accuracy: 0.8213\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(cnnhistory.history['loss'])\n",
        "plt.plot(cnnhistory.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train','test'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "oQYnuaCrDH_A",
        "outputId": "694dc4d9-3613-4742-db75-245ba1081bd0"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "01otXNBSCLs9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(cnnhistory.history['accuracy'])\n",
        "plt.plot(cnnhistory.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train','test'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "IFkTuO8nDNdq",
        "outputId": "d411121e-c4c9-4ac2-f9f8-aee7bce6bcd0"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#predictions = model.predict_classes(x_testcnn)\n",
        "predictions = model.predict(x_testcnn)"
      ],
      "metadata": {
        "id": "A2xtrN5wDQgY"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_f_ohjXKDUpY",
        "outputId": "38258166-cc4a-4ba7-e413-7c172a0845db"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.62314813e-04, 1.12355491e-02, 9.52155665e-02, 1.52021395e-02,\n",
              "        2.66641397e-02, 8.51520240e-01],\n",
              "       [4.34502681e-07, 9.99997497e-01, 7.11856885e-08, 1.19566391e-06,\n",
              "        1.72264535e-07, 6.20534195e-07],\n",
              "       [1.26168572e-07, 8.20301193e-06, 9.99334395e-01, 1.99742908e-06,\n",
              "        9.96626932e-06, 6.45256601e-04],\n",
              "       ...,\n",
              "       [1.24917790e-06, 2.01567190e-08, 1.70999207e-04, 1.92200259e-05,\n",
              "        9.93346810e-01, 6.46172883e-03],\n",
              "       [1.13871100e-03, 9.43165651e-05, 1.25074503e-05, 2.02114165e-01,\n",
              "        2.82697351e-06, 7.96637475e-01],\n",
              "       [5.80462197e-12, 7.02290032e-11, 1.41063402e-11, 8.56368244e-01,\n",
              "        2.88439858e-14, 1.43631831e-01]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cmA2bFgsDW3D",
        "outputId": "de855b6d-cfc0-4f7a-d818-6a4fa463a745"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5, 1, 2, 5, 4, 3, 2, 0, 3, 0, 3, 2, 0, 3, 3, 0, 5, 0, 2, 4, 0, 0,\n",
              "       1, 3, 2, 3, 2, 5, 3, 1, 2, 4, 2, 2, 5, 5, 3, 5, 3, 3, 4, 1, 2, 2,\n",
              "       3, 1, 5, 3, 1, 0, 4, 5, 5, 5, 5, 1, 2, 3, 2, 5, 0, 2, 4, 2, 5, 4,\n",
              "       2, 0, 2, 3, 5, 2, 0, 3, 4, 4, 4, 0, 5, 5, 3, 4, 5, 3, 2, 4, 1, 5,\n",
              "       0, 5, 0, 5, 4, 0, 1, 4, 0, 2, 2, 0, 2, 4, 5, 3, 4, 5, 3, 1, 2, 2,\n",
              "       2, 1, 3, 2, 1, 2, 4, 4, 2, 1, 2, 4, 5, 1, 4, 2, 0, 4, 5, 5, 3, 1,\n",
              "       2, 1, 5, 5, 1, 2, 3, 3, 0, 3, 3, 0, 1, 0, 1, 2, 2, 5, 2, 2, 2, 1,\n",
              "       1, 0, 1, 1, 1, 4, 0, 1, 5, 1, 5, 5, 5, 4, 1, 0, 3, 5, 2, 4, 1, 4,\n",
              "       1, 3, 2, 0, 5, 5, 3, 5, 4, 5, 4, 0, 4, 1, 2, 1, 4, 0, 4, 3, 2, 1,\n",
              "       0, 3, 5, 0, 4, 5, 4, 5, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_Ytest = y_test.astype(int)"
      ],
      "metadata": {
        "id": "0PHDKWJWDY3g"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_Ytest"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k68v2i-pDbZE",
        "outputId": "9591aa31-7b8c-441d-eb54-10418e68f79c"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5, 1, 2, 5, 4, 3, 2, 0, 3, 0, 3, 2, 0, 3, 3, 0, 5, 0, 2, 4, 0, 0,\n",
              "       1, 3, 2, 3, 2, 5, 3, 1, 2, 4, 2, 2, 5, 5, 3, 5, 3, 3, 4, 1, 2, 2,\n",
              "       3, 1, 5, 3, 1, 0, 4, 5, 5, 5, 5, 1, 2, 3, 2, 5, 0, 2, 4, 2, 5, 4,\n",
              "       2, 0, 2, 3, 5, 2, 0, 3, 4, 4, 4, 0, 5, 5, 3, 4, 5, 3, 2, 4, 1, 5,\n",
              "       0, 5, 0, 5, 4, 0, 1, 4, 0, 2, 2, 0, 2, 4, 5, 3, 4, 5, 3, 1, 2, 2,\n",
              "       2, 1, 3, 2, 1, 2, 4, 4, 2, 1, 2, 4, 5, 1, 4, 2, 0, 4, 5, 5, 3, 1,\n",
              "       2, 1, 5, 5, 1, 2, 3, 3, 0, 3, 3, 0, 1, 0, 1, 2, 2, 5, 2, 2, 2, 1,\n",
              "       1, 0, 1, 1, 1, 4, 0, 1, 5, 1, 5, 5, 5, 4, 1, 0, 3, 5, 2, 4, 1, 4,\n",
              "       1, 3, 2, 0, 5, 5, 3, 5, 4, 5, 4, 0, 4, 1, 2, 1, 4, 0, 4, 3, 2, 1,\n",
              "       0, 3, 5, 0, 4, 5, 4, 5, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds1=predictions.argmax(axis=1)\n",
        "preds1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4_cAI39VFhtp",
        "outputId": "6031dcfd-79f6-4afd-c516-a79467673a23"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5, 1, 2, 5, 0, 1, 2, 0, 3, 0, 3, 2, 1, 3, 3, 0, 5, 3, 2, 5, 0, 1,\n",
              "       1, 3, 1, 5, 2, 5, 3, 1, 2, 5, 2, 3, 5, 5, 1, 2, 3, 3, 5, 1, 4, 2,\n",
              "       3, 1, 5, 3, 1, 1, 4, 5, 2, 2, 5, 1, 1, 3, 2, 5, 0, 2, 4, 2, 5, 4,\n",
              "       2, 0, 2, 4, 5, 2, 0, 0, 4, 4, 4, 3, 5, 5, 3, 5, 5, 3, 2, 4, 1, 5,\n",
              "       1, 5, 0, 5, 4, 0, 1, 4, 3, 1, 2, 4, 2, 1, 5, 3, 4, 5, 5, 1, 2, 2,\n",
              "       2, 1, 3, 2, 1, 2, 2, 4, 4, 1, 5, 4, 0, 1, 4, 5, 0, 2, 4, 5, 5, 1,\n",
              "       4, 1, 5, 5, 1, 3, 3, 3, 0, 3, 3, 0, 1, 0, 1, 2, 2, 5, 2, 2, 2, 1,\n",
              "       1, 0, 1, 1, 0, 3, 0, 1, 5, 1, 5, 5, 5, 4, 1, 0, 3, 5, 2, 4, 1, 4,\n",
              "       1, 5, 1, 5, 5, 2, 3, 5, 4, 5, 0, 1, 4, 1, 2, 1, 5, 0, 4, 1, 2, 0,\n",
              "       0, 4, 5, 3, 4, 2, 4, 5, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "abc = preds1.astype(int).flatten()"
      ],
      "metadata": {
        "id": "H4WEmM60NfQn"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "c = confusion_matrix(new_Ytest, abc) \n",
        "c"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bKEBeEBlFjB8",
        "outputId": "99d500d4-daa4-413e-990b-219e95df8248"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[18,  5,  0,  4,  1,  1],\n",
              "       [ 2, 30,  0,  0,  0,  0],\n",
              "       [ 0,  4, 30,  2,  3,  2],\n",
              "       [ 1,  3,  0, 22,  2,  4],\n",
              "       [ 2,  1,  2,  1, 21,  5],\n",
              "       [ 1,  0,  5,  0,  1, 34]])"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m4RjG7LWLSQx",
        "outputId": "3aed3144-3c9e-45f2-864d-88483ad5da16"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5, 1, 2, 5, 4, 3, 2, 0, 3, 0, 3, 2, 0, 3, 3, 0, 5, 0, 2, 4, 0, 0,\n",
              "       1, 3, 2, 3, 2, 5, 3, 1, 2, 4, 2, 2, 5, 5, 3, 5, 3, 3, 4, 1, 2, 2,\n",
              "       3, 1, 5, 3, 1, 0, 4, 5, 5, 5, 5, 1, 2, 3, 2, 5, 0, 2, 4, 2, 5, 4,\n",
              "       2, 0, 2, 3, 5, 2, 0, 3, 4, 4, 4, 0, 5, 5, 3, 4, 5, 3, 2, 4, 1, 5,\n",
              "       0, 5, 0, 5, 4, 0, 1, 4, 0, 2, 2, 0, 2, 4, 5, 3, 4, 5, 3, 1, 2, 2,\n",
              "       2, 1, 3, 2, 1, 2, 4, 4, 2, 1, 2, 4, 5, 1, 4, 2, 0, 4, 5, 5, 3, 1,\n",
              "       2, 1, 5, 5, 1, 2, 3, 3, 0, 3, 3, 0, 1, 0, 1, 2, 2, 5, 2, 2, 2, 1,\n",
              "       1, 0, 1, 1, 1, 4, 0, 1, 5, 1, 5, 5, 5, 4, 1, 0, 3, 5, 2, 4, 1, 4,\n",
              "       1, 3, 2, 0, 5, 5, 3, 5, 4, 5, 4, 0, 4, 1, 2, 1, 4, 0, 4, 3, 2, 1,\n",
              "       0, 3, 5, 0, 4, 5, 4, 5, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('/content/drive/My Drive/graduation project/audio/paper_code/mariam/original_700 epoch_with_valid_RMS2')\n",
        "print(\"MODEL SAVED\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lsJBNeMWDl6Z",
        "outputId": "fee0546a-df71-4f07-a268-b7a8b563b022"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/graduation project/audio/paper_code/mariam/original_700 epoch_with_valid_RMS2/assets\n",
            "MODEL SAVED\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_model=keras.models.load_model('/content/drive/My Drive/graduation project/audio/paper_code/mariam/original_700 epoch_with_valid_RMS2')\n",
        "new_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q3KjaO9GDoNl",
        "outputId": "0e26367e-7369-43ff-eb37-028a93ad19a5"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d (Conv1D)             (None, 40, 128)           1152      \n",
            "                                                                 \n",
            " activation (Activation)     (None, 40, 128)           0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 40, 128)           0         \n",
            "                                                                 \n",
            " max_pooling1d (MaxPooling1D  (None, 8, 128)           0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv1d_1 (Conv1D)           (None, 8, 256)            262400    \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 8, 256)            0         \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 8, 256)            0         \n",
            "                                                                 \n",
            " max_pooling1d_1 (MaxPooling  (None, 1, 256)           0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 256)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 256)               65792     \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 256)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 256)               65792     \n",
            "                                                                 \n",
            " activation_3 (Activation)   (None, 256)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 6)                 1542      \n",
            "                                                                 \n",
            " activation_4 (Activation)   (None, 6)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 396,678\n",
            "Trainable params: 396,678\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = new_model.predict(x_testcnn)"
      ],
      "metadata": {
        "id": "WOKeSzc7T-MZ"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3RjQxa2RUBKQ",
        "outputId": "1079603b-8aac-4d2c-bf9a-4d546cde4dd2"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.62314813e-04, 1.12355491e-02, 9.52155665e-02, 1.52021395e-02,\n",
              "        2.66641397e-02, 8.51520240e-01],\n",
              "       [4.34502681e-07, 9.99997497e-01, 7.11856885e-08, 1.19566391e-06,\n",
              "        1.72264535e-07, 6.20534195e-07],\n",
              "       [1.26168572e-07, 8.20301193e-06, 9.99334395e-01, 1.99742908e-06,\n",
              "        9.96626932e-06, 6.45256601e-04],\n",
              "       ...,\n",
              "       [1.24917790e-06, 2.01567190e-08, 1.70999207e-04, 1.92200259e-05,\n",
              "        9.93346810e-01, 6.46172883e-03],\n",
              "       [1.13871100e-03, 9.43165651e-05, 1.25074503e-05, 2.02114165e-01,\n",
              "        2.82697351e-06, 7.96637475e-01],\n",
              "       [5.80462197e-12, 7.02290032e-11, 1.41063402e-11, 8.56368244e-01,\n",
              "        2.88439858e-14, 1.43631831e-01]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss, acc =new_model.evaluate(x_testcnn, y_test)\n",
        "print(\"Restored model, accuracy: {:5.2f}%\".format(100*acc))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n3kzoqPkDqqS",
        "outputId": "25e3edfd-c2a4-47ac-87e3-2503ec17480b"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7/7 [==============================] - 0s 5ms/step - loss: 0.9414 - accuracy: 0.7488\n",
            "Restored model, accuracy: 74.88%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss, acc =new_model.evaluate(X_train, y_train)\n",
        "print(\"Restored model train, accuracy: {:5.2f}%\".format(100*acc))"
      ],
      "metadata": {
        "id": "fJDTGH_OUX0z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b5afede7-4aaf-4f6f-bf68-7886e0591f13"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "52/52 [==============================] - 0s 5ms/step - loss: 0.1562 - accuracy: 0.9746\n",
            "Restored model train, accuracy: 97.46%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix,accuracy_score\n",
        "import seaborn as sn\n",
        "\n",
        "print(classification_report(new_Ytest,abc))\n",
        "\n",
        "acc = float(accuracy_score(new_Ytest,abc))*100\n",
        "print(\"----accuracy score %s ----\" % acc)\n",
        "\n",
        "cm = confusion_matrix(new_Ytest,abc)\n",
        "#df_cm = pd.DataFrame(cm)\n",
        "class_names = ['neutral','calm', 'happy','sad','angry', 'fearful' ]\n",
        "df_cm = pd.DataFrame(cm, index=class_names, columns=class_names,)\n",
        "sn.heatmap(df_cm, annot=True, fmt='')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 512
        },
        "id": "SfSC3El94LZg",
        "outputId": "4f61925f-9187-446f-a6cc-3d38631a4bdb"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.66      0.66      0.66        29\n",
            "           1       0.69      0.78      0.74        32\n",
            "           2       0.73      0.73      0.73        41\n",
            "           3       0.61      0.78      0.68        32\n",
            "           4       0.78      0.66      0.71        32\n",
            "           5       0.79      0.63      0.70        41\n",
            "\n",
            "    accuracy                           0.71       207\n",
            "   macro avg       0.71      0.71      0.70       207\n",
            "weighted avg       0.71      0.71      0.71       207\n",
            "\n",
            "----accuracy score 70.53140096618358 ----\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "y5OoGgupF7kU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}