{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN_2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9SRCO-a_AlH5",
        "outputId": "dab0c6d6-8f34-49cc-fedb-7ae635f65472"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install librosa"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oi8pWV3yBVjO",
        "outputId": "c25ad025-a260-4f9a-dc57-6a1e9fe3f730"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: librosa in /usr/local/lib/python3.7/dist-packages (0.8.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.19.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (21.3)\n",
            "Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.5.2)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.1.0)\n",
            "Requirement already satisfied: resampy>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from librosa) (0.2.2)\n",
            "Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.0.1)\n",
            "Requirement already satisfied: numba>=0.43.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (0.51.2)\n",
            "Requirement already satisfied: soundfile>=0.10.2 in /usr/local/lib/python3.7/dist-packages (from librosa) (0.10.3.post1)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.4.1)\n",
            "Requirement already satisfied: decorator>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied: audioread>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (2.1.9)\n",
            "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba>=0.43.0->librosa) (0.34.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba>=0.43.0->librosa) (57.4.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->librosa) (3.0.6)\n",
            "Requirement already satisfied: appdirs in /usr/local/lib/python3.7/dist-packages (from pooch>=1.0->librosa) (1.4.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from pooch>=1.0->librosa) (2.23.0)\n",
            "Requirement already satisfied: six>=1.3 in /usr/local/lib/python3.7/dist-packages (from resampy>=0.2.2->librosa) (1.15.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn!=0.19.0,>=0.14.0->librosa) (3.0.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.7/dist-packages (from soundfile>=0.10.2->librosa) (1.15.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.0->soundfile>=0.10.2->librosa) (2.21)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->pooch>=1.0->librosa) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->pooch>=1.0->librosa) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->pooch>=1.0->librosa) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->pooch>=1.0->librosa) (2021.10.8)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "wsaoikiQGfqd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HJjcbxwy46bG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "83f6d0e3-1d98-4d34-a9c6-a2a7a65e0a16"
      },
      "source": [
        "# Orignial Notebook: https://github.com/MITESHPUTHRANNEU/Speech-Emotion-Analyzer/blob/master/final_results_gender_test.ipynb\n",
        "# This notebook author: Reza Chu\n",
        "# Last Editing Date: 31st May 2019\n",
        "\n",
        "## Python\n",
        "import os\n",
        "import random\n",
        "import sys\n",
        "\n",
        "import IPython\n",
        "from IPython.display import Audio\n",
        "from IPython.display import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "## Package\n",
        "import glob \n",
        "import keras\n",
        "import IPython.display as ipd\n",
        "import librosa\n",
        "import librosa.display\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import plotly.graph_objs as go\n",
        "import plotly.offline as py\n",
        "import plotly.tools as tls\n",
        "import seaborn as sns\n",
        "import scipy.io.wavfile\n",
        "import tensorflow as tf\n",
        "py.init_notebook_mode(connected=True)\n",
        "\n",
        "## Keras\n",
        "from keras import regularizers\n",
        "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping\n",
        "from keras.callbacks import  History, ReduceLROnPlateau, CSVLogger\n",
        "from keras.models import Model, Sequential\n",
        "from keras.layers import Dense, Embedding, LSTM\n",
        "from keras.layers import Input, Flatten, Dropout, Activation, BatchNormalization\n",
        "from keras.layers import Conv1D, MaxPooling1D, AveragePooling1D\n",
        "from keras.preprocessing import sequence\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.utils import np_utils\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "## Sklearn\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "## Rest\n",
        "from scipy.fftpack import fft\n",
        "from scipy import signal\n",
        "from scipy.io import wavfile\n",
        "from tqdm import tqdm\n",
        "\n",
        "input_duration=3\n",
        "# % pylab inline"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "        <script type=\"text/javascript\">\n",
              "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
              "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
              "        if (typeof require !== 'undefined') {\n",
              "        require.undef(\"plotly\");\n",
              "        requirejs.config({\n",
              "            paths: {\n",
              "                'plotly': ['https://cdn.plot.ly/plotly-2.8.3.min']\n",
              "            }\n",
              "        });\n",
              "        require(['plotly'], function(Plotly) {\n",
              "            window._Plotly = Plotly;\n",
              "        });\n",
              "        }\n",
              "        </script>\n",
              "        "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#only SAVEE data set\n",
        "import time\n",
        "import os\n",
        "import librosa\n",
        "from librosa import display\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "lst = []\n",
        "count=0\n",
        "start_time = time.time()\n",
        "\n",
        "path3 = '/content/drive/My Drive/data_set/SAVEE'\n",
        "for subdir, dirs, files in os.walk(path3):\n",
        "  for file in files:\n",
        "      try:\n",
        "        #0 = neutral,  1 = fearful, 2 = happy, 3 = sad, 4 = angry\n",
        "        if file.startswith('a'):\n",
        "            emotion=4\n",
        "        elif file.startswith('d'):\n",
        "            continue\n",
        "        elif file.startswith('f'):\n",
        "            emotion=1\n",
        "        elif file.startswith('h'):\n",
        "            emotion=2\n",
        "        elif file.startswith('n'):\n",
        "            emotion=0\n",
        "        elif file.startswith('sa'):\n",
        "            emotion=3\n",
        "        elif file.startswith('su'):\n",
        "            continue\n",
        "        else:\n",
        "            continue\n",
        "        #Load librosa array, obtain mfcss, store the file and the mcss information in a new array\n",
        "        X, sample_rate = librosa.load(os.path.join(subdir,file), res_type='kaiser_fast')\n",
        "        mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T,axis=0) \n",
        "        count +=1\n",
        "        # The instruction below converts the labels (from 1 to 8) to a series from 0 to 7\n",
        "        # This is because our predictor needs to start from 0 otherwise it will try to predict also 0.\n",
        "        #file = int(file[7:8]) - 1 \n",
        "        #0 = neutral, 1 = calm, 2 = happy, 3 = sad, 4 = angry, 5 = fearful, 6 = disgust, 7 = surprised\n",
        "        arr = mfccs, emotion\n",
        "        lst.append(arr)\n",
        "      # If the file is not valid, skip it\n",
        "      except ValueError:\n",
        "        continue\n",
        "\n",
        "print(\"--- Data loaded. Loading time: %s seconds ---\" % (time.time() - start_time))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JNAdK9M2TJP_",
        "outputId": "8faf9b53-dea7-434b-9dbb-8b8a50fd3ec4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Data loaded. Loading time: 29.2397620677948 seconds ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "count"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QyZbhkDOzA-P",
        "outputId": "551fa57f-5e16-4c60-e2e4-b7aaccc77d13"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "360"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#radvass speech and song\n",
        "import time\n",
        "import os\n",
        "import librosa\n",
        "from librosa import display\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "count=0\n",
        "path1 = '/content/drive/My Drive/data_set/RAVDESS_speech'\n",
        "path2 = '/content/drive/My Drive/data_set/RAVDESS_song'\n",
        "\n",
        "lst = []\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "for subdir, dirs, files in os.walk(path2):\n",
        "  print(dirs)\n",
        "  print(subdir)\n",
        "  #print(files)\n",
        "  for file in files:\n",
        "      try:\n",
        "        count +=1\n",
        "        #Load librosa array, obtain mfcss, store the file and the mcss information in a new array\n",
        "        X, sample_rate = librosa.load(os.path.join(subdir,file), res_type='kaiser_fast')\n",
        "        mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T,axis=0) \n",
        "        # The instruction below converts the labels (from 1 to 8) to a series from 0 to 7\n",
        "        # This is because our predictor needs to start from 0 otherwise it will try to predict also 0.\n",
        "        file = int(file[7:8]) - 1 \n",
        "        arr = mfccs, file\n",
        "        lst.append(arr)\n",
        "      # If the file is not valid, skip it\n",
        "      except ValueError:\n",
        "        continue\n",
        "\n",
        "for subdir, dirs, files in os.walk(path1):\n",
        "  print(dirs)\n",
        "  print(subdir)\n",
        " # print(files)\n",
        "  for file in files:\n",
        "      try:\n",
        "        #Load librosa array, obtain mfcss, store the file and the mcss information in a new array\n",
        "        X, sample_rate = librosa.load(os.path.join(subdir,file), res_type='kaiser_fast')\n",
        "        mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T,axis=0) \n",
        "        # The instruction below converts the labels (from 1 to 8) to a series from 0 to 7\n",
        "        # This is because our predictor needs to start from 0 otherwise it will try to predict also 0.\n",
        "        file = int(file[7:8]) - 1 \n",
        "        if(file==6 or file==7):\n",
        "          continue\n",
        "        count +=1\n",
        "        arr = mfccs, file\n",
        "        lst.append(arr)\n",
        "      # If the file is not valid, skip it\n",
        "      except ValueError:\n",
        "        continue\n",
        "\n",
        "\n",
        "\n",
        "print(\"--- Data loaded. Loading time: %s seconds ---\" % (time.time() - start_time))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IfuyRZl42ccZ",
        "outputId": "eda2fee2-2577-41d4-8308-7e6b8ce97733"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Actor_10', 'Actor_11', 'Actor_13', 'Actor_12', 'Actor_14', 'Actor_15', 'Actor_16', 'Actor_17', 'Actor_18', 'Actor_19', 'Actor_21', 'Actor_22', 'Actor_23', 'Actor_09', 'Actor_24', 'Actor_04', 'Actor_08', 'Actor_03', 'Actor_02', 'Actor_06', 'Actor_05', 'Actor_01', 'Actor_07', 'Actor_20']\n",
            "/content/drive/My Drive/data_set/RAVDESS_song\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_song/Actor_10\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_song/Actor_11\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_song/Actor_13\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_song/Actor_12\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_song/Actor_14\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_song/Actor_15\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_song/Actor_16\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_song/Actor_17\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_song/Actor_18\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_song/Actor_19\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_song/Actor_21\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_song/Actor_22\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_song/Actor_23\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_song/Actor_09\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_song/Actor_24\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_song/Actor_04\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_song/Actor_08\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_song/Actor_03\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_song/Actor_02\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_song/Actor_06\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_song/Actor_05\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_song/Actor_01\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_song/Actor_07\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_song/Actor_20\n",
            "['Actor_05', 'Actor_08', 'Actor_10', 'Actor_04', 'Actor_09', 'Actor_14', 'Actor_12', 'Actor_13', 'Actor_11', 'Actor_06', 'Actor_24', 'Actor_07', 'Actor_23', 'Actor_22', 'Actor_21', 'Actor_20', 'Actor_02', 'Actor_19', 'Actor_18', 'Actor_17', 'Actor_16', 'Actor_15', 'Actor_03', 'Actor_01']\n",
            "/content/drive/My Drive/data_set/RAVDESS_speech\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_speech/Actor_05\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_speech/Actor_08\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_speech/Actor_10\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_speech/Actor_04\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_speech/Actor_09\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_speech/Actor_14\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_speech/Actor_12\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_speech/Actor_13\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_speech/Actor_11\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_speech/Actor_06\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_speech/Actor_24\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_speech/Actor_07\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_speech/Actor_23\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_speech/Actor_22\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_speech/Actor_21\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_speech/Actor_20\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_speech/Actor_02\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_speech/Actor_19\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_speech/Actor_18\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_speech/Actor_17\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_speech/Actor_16\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_speech/Actor_15\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_speech/Actor_03\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_speech/Actor_01\n",
            "--- Data loaded. Loading time: 230.8708372116089 seconds ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#radvass speech \n",
        "import time\n",
        "import os\n",
        "import librosa\n",
        "from librosa import display\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "count=0\n",
        "path1 = '/content/drive/My Drive/data_set/RAVDESS_speech'\n",
        "\n",
        "\n",
        "lst = []\n",
        "\n",
        "start_time = time.time()\n",
        "for subdir, dirs, files in os.walk(path1):\n",
        "  print(dirs)\n",
        "  print(subdir)\n",
        "  #print(files)\n",
        "  for file in files:\n",
        "      try:\n",
        "        count +=1\n",
        "        #Load librosa array, obtain mfcss, store the file and the mcss information in a new array\n",
        "        X, sample_rate = librosa.load(os.path.join(subdir,file), res_type='kaiser_fast')\n",
        "        mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T,axis=0) \n",
        "        # The instruction below converts the labels (from 1 to 8) to a series from 0 to 7\n",
        "        # This is because our predictor needs to start from 0 otherwise it will try to predict also 0.\n",
        "        file = int(file[7:8]) - 1 \n",
        "        arr = mfccs, file\n",
        "        lst.append(arr)\n",
        "      # If the file is not valid, skip it\n",
        "      except ValueError:\n",
        "        continue\n",
        "\n",
        "\n",
        "\n",
        "print(\"--- Data loaded. Loading time: %s seconds ---\" % (time.time() - start_time))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e4xkgct25hAx",
        "outputId": "9cbdbb0c-78c4-4cb7-899b-9d80ab551b00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Actor_05', 'Actor_08', 'Actor_10', 'Actor_04', 'Actor_09', 'Actor_14', 'Actor_12', 'Actor_13', 'Actor_11', 'Actor_06', 'Actor_24', 'Actor_07', 'Actor_23', 'Actor_22', 'Actor_21', 'Actor_20', 'Actor_02', 'Actor_19', 'Actor_18', 'Actor_17', 'Actor_16', 'Actor_15', 'Actor_03', 'Actor_01']\n",
            "/content/drive/My Drive/data_set/RAVDESS_speech\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_speech/Actor_05\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_speech/Actor_08\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_speech/Actor_10\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_speech/Actor_04\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_speech/Actor_09\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_speech/Actor_14\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_speech/Actor_12\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_speech/Actor_13\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_speech/Actor_11\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_speech/Actor_06\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_speech/Actor_24\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_speech/Actor_07\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_speech/Actor_23\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_speech/Actor_22\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_speech/Actor_21\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_speech/Actor_20\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_speech/Actor_02\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_speech/Actor_19\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_speech/Actor_18\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_speech/Actor_17\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_speech/Actor_16\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_speech/Actor_15\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_speech/Actor_03\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_speech/Actor_01\n",
            "--- Data loaded. Loading time: 209.09052848815918 seconds ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import os\n",
        "import librosa\n",
        "from librosa import display\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "path1 = '/content/drive/My Drive/data_set/RAVDESS_speech'\n",
        "path2 = '/content/drive/My Drive/data_set/RAVDESS_song'\n",
        "path3 = '/content/drive/My Drive/data_set/SAVEE'\n",
        "lst = []\n",
        "count=0\n",
        "start_time = time.time()\n",
        "\n",
        "for subdir, dirs, files in os.walk(path1):\n",
        "  for file in files:\n",
        "      try:\n",
        "        count +=1\n",
        "        #Load librosa array, obtain mfcss, store the file and the mcss information in a new array\n",
        "        X, sample_rate = librosa.load(os.path.join(subdir,file), res_type='kaiser_fast')\n",
        "        mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T,axis=0) \n",
        "        # The instruction below converts the labels (from 1 to 8) to a series from 0 to 7\n",
        "        # This is because our predictor needs to start from 0 otherwise it will try to predict also 0.\n",
        "        file = int(file[7:8]) - 1 \n",
        "        arr = mfccs, file\n",
        "        lst.append(arr)\n",
        "      # If the file is not valid, skip it\n",
        "      except ValueError:\n",
        "        continue\n",
        "\n",
        "for subdir, dirs, files in os.walk(path2):\n",
        "  for file in files:\n",
        "      try:\n",
        "        count +=1\n",
        "        #Load librosa array, obtain mfcss, store the file and the mcss information in a new array\n",
        "        X, sample_rate = librosa.load(os.path.join(subdir,file), res_type='kaiser_fast')\n",
        "        mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T,axis=0) \n",
        "        # The instruction below converts the labels (from 1 to 8) to a series from 0 to 7\n",
        "        # This is because our predictor needs to start from 0 otherwise it will try to predict also 0.\n",
        "        file = int(file[7:8]) - 1 \n",
        "        arr = mfccs, file\n",
        "        lst.append(arr)\n",
        "      # If the file is not valid, skip it\n",
        "      except ValueError:\n",
        "        continue\n",
        "\n",
        "for subdir, dirs, files in os.walk(path3):\n",
        "  for file in files:\n",
        "      try:\n",
        "        #Load librosa array, obtain mfcss, store the file and the mcss information in a new array\n",
        "        X, sample_rate = librosa.load(os.path.join(subdir,file), res_type='kaiser_fast')\n",
        "        mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T,axis=0) \n",
        "        count +=1\n",
        "        # The instruction below converts the labels (from 1 to 8) to a series from 0 to 7\n",
        "        # This is because our predictor needs to start from 0 otherwise it will try to predict also 0.\n",
        "        #file = int(file[7:8]) - 1 \n",
        "        #0 = neutral, 1 = calm, 2 = happy, 3 = sad, 4 = angry, 5 = fearful, 6 = disgust, 7 = surprised\n",
        "        if file.startswith('a'):\n",
        "            emotion=4\n",
        "        elif file.startswith('d'):\n",
        "            emotion=6\n",
        "        elif file.startswith('f'):\n",
        "            emotion=5\n",
        "        elif file.startswith('h'):\n",
        "            emotion=2\n",
        "        elif file.startswith('n'):\n",
        "            emotion=0\n",
        "        elif file.startswith('sa'):\n",
        "            emotion=3\n",
        "        elif file.startswith('su'):\n",
        "            emotion=7\n",
        "        else:\n",
        "            emotion=8\n",
        "        arr = mfccs, emotion\n",
        "        lst.append(arr)\n",
        "      # If the file is not valid, skip it\n",
        "      except ValueError:\n",
        "        continue\n",
        "\n",
        "print(\"--- Data loaded. Loading time: %s seconds ---\" % (time.time() - start_time))"
      ],
      "metadata": {
        "id": "-1eNUEyyPzeb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "cgQgIZNjXs9D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#song only\n",
        "#lst=[]\n",
        "count=0\n",
        "path2 = '/content/drive/My Drive/data_set/RAVDESS_song'\n",
        "for subdir, dirs, files in os.walk(path2):\n",
        "  print(dirs)\n",
        "  print(subdir)\n",
        "  for file in files:\n",
        "      try:\n",
        "        count +=1\n",
        "        #Load librosa array, obtain mfcss, store the file and the mcss information in a new array\n",
        "        X, sample_rate = librosa.load(os.path.join(subdir,file), res_type='kaiser_fast')\n",
        "        mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T,axis=0) \n",
        "        # The instruction below converts the labels (from 1 to 8) to a series from 0 to 7\n",
        "        # This is because our predictor needs to start from 0 otherwise it will try to predict also 0.\n",
        "        file = int(file[7:8]) - 1 \n",
        "        arr = mfccs, file\n",
        "        lst.append(arr)\n",
        "      # If the file is not valid, skip it\n",
        "      except ValueError:\n",
        "        print(\"error\")\n",
        "        continue\n",
        "\n",
        "#print(\"--- Data loaded. Loading time: %s seconds ---\" % (time.time() - start_time))"
      ],
      "metadata": {
        "id": "ulx43CTEXtGc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a22b1851-e29f-4b81-e4aa-9d62a25276fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Actor_10', 'Actor_11', 'Actor_13', 'Actor_12', 'Actor_14', 'Actor_15', 'Actor_16', 'Actor_17', 'Actor_18', 'Actor_19', 'Actor_21', 'Actor_22', 'Actor_23', 'Actor_09', 'Actor_24', 'Actor_04', 'Actor_08', 'Actor_03', 'Actor_02', 'Actor_06', 'Actor_05', 'Actor_01', 'Actor_07', 'Actor_20']\n",
            "/content/drive/My Drive/data_set/RAVDESS_song\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_song/Actor_10\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_song/Actor_11\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_song/Actor_13\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_song/Actor_12\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_song/Actor_14\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_song/Actor_15\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_song/Actor_16\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_song/Actor_17\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_song/Actor_18\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_song/Actor_19\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_song/Actor_21\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_song/Actor_22\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_song/Actor_23\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_song/Actor_09\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_song/Actor_24\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_song/Actor_04\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_song/Actor_08\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_song/Actor_03\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_song/Actor_02\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_song/Actor_06\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_song/Actor_05\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_song/Actor_01\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_song/Actor_07\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_song/Actor_20\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "count"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ltlhi25L2AI5",
        "outputId": "f9f75cc8-9a58-4004-d858-82c711a634ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2068"
            ]
          },
          "metadata": {},
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy.core.fromnumeric import size\n",
        "size(lst)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HMOH7d7mzHB7",
        "outputId": "10688416-8b03-4518-b7fc-fe4ff5edd4d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/core/fromnumeric.py:3208: VisibleDeprecationWarning:\n",
            "\n",
            "Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "720"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating X and y: zip makes a list of all the first elements, and a list of all the second elements.\n",
        "X, y = zip(*lst)"
      ],
      "metadata": {
        "id": "ocdL7tSTBoMt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "X = np.asarray(X)\n",
        "y = np.asarray(y)\n",
        "X.shape, y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vHKwUGTbBtnF",
        "outputId": "54829d79-a98c-4e8e-83fb-3a79fc5c0b8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((360, 40), (360,))"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Saving joblib files to not load them again with the loop above\n",
        "\n",
        "import joblib\n",
        "\n",
        "X_name = 'saveex5.joblib'\n",
        "y_name = 'saveey5.joblib'\n",
        "save_dir = '/content/drive/My Drive/graduation project/audio/improvement1/features'\n",
        "\n",
        "savedX = joblib.dump(X, os.path.join(save_dir, X_name))\n",
        "savedy = joblib.dump(y, os.path.join(save_dir, y_name))"
      ],
      "metadata": {
        "id": "gprL_ZgHB8hJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading saved models\n",
        "import joblib\n",
        "X = joblib.load('/content/drive/My Drive/graduation project/audio/improvement1/features/speech&songx6.joblib')\n",
        "y = joblib.load('/content/drive/My Drive/graduation project/audio/improvement1/features/speech&songy6.joblib')"
      ],
      "metadata": {
        "id": "X8uI92luB9wW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2sUCtbfMztE5",
        "outputId": "f15482d0-5e85-4b70-bde4-2d0bb947ff84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1880, 40)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.20, random_state=42)"
      ],
      "metadata": {
        "id": "Ai4Fy5cPCiq1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "x_traincnn = np.expand_dims(X_train, axis=2)\n",
        "x_testcnn = np.expand_dims(X_test, axis=2)"
      ],
      "metadata": {
        "id": "tp1Fm5K3CEXu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_traincnn.shape, x_testcnn.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RI0MxoIPBws5",
        "outputId": "fc73371d-daf9-462e-b04e-e195efa331aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1654, 40, 1), (414, 40, 1))"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "goxL4Y3jKICC",
        "outputId": "43412655-928a-455f-f02e-2e8aa9253a8c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (2.8.0)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.21.5)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.24.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.10.0.2)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.17.3)\n",
            "Collecting tf-estimator-nightly==2.8.0.dev2021122109\n",
            "  Downloading tf_estimator_nightly-2.8.0.dev2021122109-py2.py3-none-any.whl (462 kB)\n",
            "\u001b[K     |████████████████████████████████| 462 kB 23.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.43.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow) (57.4.0)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.0.0)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (13.0.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.13.3)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.5.3)\n",
            "Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow) (1.5.2)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.4.6)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.35.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (3.3.6)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.8.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.23.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.6.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.2.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (4.11.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (3.7.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2021.10.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (3.2.0)\n",
            "Installing collected packages: tf-estimator-nightly\n",
            "Successfully installed tf-estimator-nightly-2.8.0.dev2021122109\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keras"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EkcmN9UrKSxj",
        "outputId": "5cba7adc-a0df-4ec6-d24c-7d779cd3221b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: keras in /usr/local/lib/python3.7/dist-packages (2.7.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from keras.preprocessing import sequence\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from keras.layers import Input, Flatten, Dropout, Activation\n",
        "from keras.layers import Conv1D, MaxPooling1D\n",
        "from keras.models import Model\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras import optimizers\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv1D(64, 5,padding='same', #classifier.add(Convolution2D(64, (3, 3), padding = 'same', input_shape = (128, 128, 3), activation = 'relu'))\n",
        "                 input_shape=(40,1)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.1))\n",
        "model.add(MaxPooling1D(pool_size=(4)))\n",
        "model.add(Conv1D(128, 5,padding='same',))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.1))\n",
        "model.add(MaxPooling1D(pool_size=(4)))\n",
        "model.add(Conv1D(256, 5,padding='same',))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.1))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(6))\n",
        "model.add(Activation('softmax'))\n",
        "opt = tf.keras.optimizers.RMSprop(lr=0.0001, rho=0.9, epsilon=1e-07, decay=0.0)\n",
        "#opt = tf.keras.optimizers.SGD(lr=0.001, momentum=0.0, decay=0.0, nesterov=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g74fXWVAC4Cr",
        "outputId": "7cb416d2-ac05-4ebe-ea6f-d1e8cb31cb9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/rmsprop.py:130: UserWarning:\n",
            "\n",
            "The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H6ukOxAGC_I4",
        "outputId": "eb94ea24-1169-48c2-bda9-8701411f92b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d (Conv1D)             (None, 40, 64)            384       \n",
            "                                                                 \n",
            " activation (Activation)     (None, 40, 64)            0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 40, 64)            0         \n",
            "                                                                 \n",
            " max_pooling1d (MaxPooling1D  (None, 10, 64)           0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv1d_1 (Conv1D)           (None, 10, 128)           41088     \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 10, 128)           0         \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 10, 128)           0         \n",
            "                                                                 \n",
            " max_pooling1d_1 (MaxPooling  (None, 2, 128)           0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " conv1d_2 (Conv1D)           (None, 2, 256)            164096    \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 2, 256)            0         \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 2, 256)            0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 512)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 6)                 3078      \n",
            "                                                                 \n",
            " activation_3 (Activation)   (None, 6)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 208,646\n",
            "Trainable params: 208,646\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='sparse_categorical_crossentropy',\n",
        "              optimizer=opt,\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "AbMlLNk4DCBM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#cnnhistory=model.fit(x_traincnn, y_train, batch_size=16, epochs=700, validation_data=(x_testcnn, y_test))\n",
        "cnnhistory=model.fit(x_traincnn, y_train, batch_size=16, epochs=700,validation_split=0.1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RI1v2AuADFhy",
        "outputId": "ce5a5e5e-fb2b-44dc-bc2c-d412a51bdfe2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/700\n",
            "93/93 [==============================] - 1s 14ms/step - loss: 1.7020 - accuracy: 0.2984 - val_loss: 1.5564 - val_accuracy: 0.4157\n",
            "Epoch 2/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 1.7024 - accuracy: 0.2910 - val_loss: 1.5296 - val_accuracy: 0.4337\n",
            "Epoch 3/700\n",
            "93/93 [==============================] - 1s 14ms/step - loss: 1.6161 - accuracy: 0.3320 - val_loss: 1.5111 - val_accuracy: 0.4458\n",
            "Epoch 4/700\n",
            "93/93 [==============================] - 1s 14ms/step - loss: 1.6192 - accuracy: 0.3407 - val_loss: 1.4846 - val_accuracy: 0.4337\n",
            "Epoch 5/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 1.5786 - accuracy: 0.3595 - val_loss: 1.4516 - val_accuracy: 0.4699\n",
            "Epoch 6/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 1.5537 - accuracy: 0.3777 - val_loss: 1.4600 - val_accuracy: 0.4277\n",
            "Epoch 7/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 1.4882 - accuracy: 0.4005 - val_loss: 1.3805 - val_accuracy: 0.5181\n",
            "Epoch 8/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 1.4776 - accuracy: 0.3925 - val_loss: 1.3532 - val_accuracy: 0.4699\n",
            "Epoch 9/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 1.4515 - accuracy: 0.4147 - val_loss: 1.3249 - val_accuracy: 0.5120\n",
            "Epoch 10/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 1.4252 - accuracy: 0.4348 - val_loss: 1.3187 - val_accuracy: 0.4759\n",
            "Epoch 11/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 1.3877 - accuracy: 0.4509 - val_loss: 1.3404 - val_accuracy: 0.4578\n",
            "Epoch 12/700\n",
            "93/93 [==============================] - 1s 14ms/step - loss: 1.3841 - accuracy: 0.4429 - val_loss: 1.2654 - val_accuracy: 0.5120\n",
            "Epoch 13/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 1.3307 - accuracy: 0.4630 - val_loss: 1.2187 - val_accuracy: 0.5241\n",
            "Epoch 14/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 1.3313 - accuracy: 0.4651 - val_loss: 1.2125 - val_accuracy: 0.5843\n",
            "Epoch 15/700\n",
            "93/93 [==============================] - 1s 14ms/step - loss: 1.2891 - accuracy: 0.4745 - val_loss: 1.2061 - val_accuracy: 0.5422\n",
            "Epoch 16/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 1.2617 - accuracy: 0.5161 - val_loss: 1.1736 - val_accuracy: 0.5542\n",
            "Epoch 17/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 1.2802 - accuracy: 0.5054 - val_loss: 1.2273 - val_accuracy: 0.5120\n",
            "Epoch 18/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 1.2444 - accuracy: 0.5007 - val_loss: 1.1182 - val_accuracy: 0.6024\n",
            "Epoch 19/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 1.2225 - accuracy: 0.5054 - val_loss: 1.1525 - val_accuracy: 0.5602\n",
            "Epoch 20/700\n",
            "93/93 [==============================] - 3s 28ms/step - loss: 1.2059 - accuracy: 0.5141 - val_loss: 1.1261 - val_accuracy: 0.5602\n",
            "Epoch 21/700\n",
            "93/93 [==============================] - 2s 21ms/step - loss: 1.1815 - accuracy: 0.5249 - val_loss: 1.1451 - val_accuracy: 0.5482\n",
            "Epoch 22/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 1.1673 - accuracy: 0.5363 - val_loss: 1.1243 - val_accuracy: 0.5783\n",
            "Epoch 23/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 1.1637 - accuracy: 0.5249 - val_loss: 1.1461 - val_accuracy: 0.5301\n",
            "Epoch 24/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 1.1287 - accuracy: 0.5618 - val_loss: 1.0415 - val_accuracy: 0.6265\n",
            "Epoch 25/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 1.1250 - accuracy: 0.5565 - val_loss: 1.0307 - val_accuracy: 0.6265\n",
            "Epoch 26/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 1.1058 - accuracy: 0.5672 - val_loss: 1.0400 - val_accuracy: 0.6145\n",
            "Epoch 27/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 1.0952 - accuracy: 0.5679 - val_loss: 1.0303 - val_accuracy: 0.6084\n",
            "Epoch 28/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 1.0921 - accuracy: 0.5773 - val_loss: 1.0432 - val_accuracy: 0.5723\n",
            "Epoch 29/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 1.0644 - accuracy: 0.5793 - val_loss: 1.0439 - val_accuracy: 0.6145\n",
            "Epoch 30/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 1.0352 - accuracy: 0.5934 - val_loss: 1.0074 - val_accuracy: 0.6205\n",
            "Epoch 31/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 1.0501 - accuracy: 0.5793 - val_loss: 1.0117 - val_accuracy: 0.6265\n",
            "Epoch 32/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 1.0066 - accuracy: 0.5927 - val_loss: 0.9933 - val_accuracy: 0.6446\n",
            "Epoch 33/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 1.0149 - accuracy: 0.6089 - val_loss: 1.0007 - val_accuracy: 0.6205\n",
            "Epoch 34/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 1.0080 - accuracy: 0.5961 - val_loss: 0.9654 - val_accuracy: 0.6566\n",
            "Epoch 35/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 0.9952 - accuracy: 0.6069 - val_loss: 0.9470 - val_accuracy: 0.6627\n",
            "Epoch 36/700\n",
            "93/93 [==============================] - 1s 14ms/step - loss: 1.0001 - accuracy: 0.5907 - val_loss: 0.9613 - val_accuracy: 0.6024\n",
            "Epoch 37/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 0.9613 - accuracy: 0.6243 - val_loss: 0.9566 - val_accuracy: 0.6325\n",
            "Epoch 38/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 0.9584 - accuracy: 0.6210 - val_loss: 0.9782 - val_accuracy: 0.6506\n",
            "Epoch 39/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 0.9563 - accuracy: 0.6351 - val_loss: 0.9441 - val_accuracy: 0.6747\n",
            "Epoch 40/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 0.9376 - accuracy: 0.6317 - val_loss: 0.9145 - val_accuracy: 0.6988\n",
            "Epoch 41/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 0.9392 - accuracy: 0.6203 - val_loss: 0.9680 - val_accuracy: 0.6506\n",
            "Epoch 42/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 0.9295 - accuracy: 0.6364 - val_loss: 0.9909 - val_accuracy: 0.5964\n",
            "Epoch 43/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 0.9276 - accuracy: 0.6378 - val_loss: 0.9278 - val_accuracy: 0.6807\n",
            "Epoch 44/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 0.9144 - accuracy: 0.6546 - val_loss: 0.8773 - val_accuracy: 0.6687\n",
            "Epoch 45/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 0.8968 - accuracy: 0.6472 - val_loss: 0.9119 - val_accuracy: 0.6747\n",
            "Epoch 46/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 0.8763 - accuracy: 0.6620 - val_loss: 0.8958 - val_accuracy: 0.6867\n",
            "Epoch 47/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 0.8961 - accuracy: 0.6526 - val_loss: 0.8857 - val_accuracy: 0.6988\n",
            "Epoch 48/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 0.8795 - accuracy: 0.6505 - val_loss: 0.8784 - val_accuracy: 0.6807\n",
            "Epoch 49/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 0.8646 - accuracy: 0.6694 - val_loss: 0.9060 - val_accuracy: 0.6566\n",
            "Epoch 50/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 0.8555 - accuracy: 0.6754 - val_loss: 0.8793 - val_accuracy: 0.6446\n",
            "Epoch 51/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 0.8371 - accuracy: 0.6694 - val_loss: 0.8917 - val_accuracy: 0.6747\n",
            "Epoch 52/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 0.8240 - accuracy: 0.6734 - val_loss: 0.8437 - val_accuracy: 0.7169\n",
            "Epoch 53/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 0.8270 - accuracy: 0.6720 - val_loss: 0.8344 - val_accuracy: 0.7169\n",
            "Epoch 54/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 0.8184 - accuracy: 0.6848 - val_loss: 0.8479 - val_accuracy: 0.6928\n",
            "Epoch 55/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 0.8097 - accuracy: 0.6915 - val_loss: 0.8804 - val_accuracy: 0.6627\n",
            "Epoch 56/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 0.7980 - accuracy: 0.6895 - val_loss: 0.8144 - val_accuracy: 0.7048\n",
            "Epoch 57/700\n",
            "93/93 [==============================] - 1s 14ms/step - loss: 0.8129 - accuracy: 0.6895 - val_loss: 0.8153 - val_accuracy: 0.6988\n",
            "Epoch 58/700\n",
            "93/93 [==============================] - 1s 14ms/step - loss: 0.7695 - accuracy: 0.7070 - val_loss: 0.8604 - val_accuracy: 0.6566\n",
            "Epoch 59/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 0.7930 - accuracy: 0.6909 - val_loss: 0.8255 - val_accuracy: 0.6867\n",
            "Epoch 60/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 0.7685 - accuracy: 0.7036 - val_loss: 0.7991 - val_accuracy: 0.6988\n",
            "Epoch 61/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 0.7629 - accuracy: 0.6996 - val_loss: 0.8002 - val_accuracy: 0.7108\n",
            "Epoch 62/700\n",
            "93/93 [==============================] - 1s 14ms/step - loss: 0.7569 - accuracy: 0.7056 - val_loss: 0.8447 - val_accuracy: 0.6807\n",
            "Epoch 63/700\n",
            "93/93 [==============================] - 1s 14ms/step - loss: 0.7713 - accuracy: 0.6956 - val_loss: 0.7869 - val_accuracy: 0.7108\n",
            "Epoch 64/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 0.7573 - accuracy: 0.7030 - val_loss: 0.8331 - val_accuracy: 0.6928\n",
            "Epoch 65/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 0.7624 - accuracy: 0.7023 - val_loss: 0.7973 - val_accuracy: 0.7169\n",
            "Epoch 66/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 0.7326 - accuracy: 0.7070 - val_loss: 0.7896 - val_accuracy: 0.6988\n",
            "Epoch 67/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 0.7400 - accuracy: 0.7164 - val_loss: 0.7877 - val_accuracy: 0.7289\n",
            "Epoch 68/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 0.7207 - accuracy: 0.7177 - val_loss: 0.7776 - val_accuracy: 0.7470\n",
            "Epoch 69/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 0.7376 - accuracy: 0.7157 - val_loss: 0.7916 - val_accuracy: 0.7349\n",
            "Epoch 70/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 0.6886 - accuracy: 0.7379 - val_loss: 0.7986 - val_accuracy: 0.7349\n",
            "Epoch 71/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 0.7131 - accuracy: 0.7251 - val_loss: 0.7444 - val_accuracy: 0.7530\n",
            "Epoch 72/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 0.6930 - accuracy: 0.7345 - val_loss: 0.7884 - val_accuracy: 0.7470\n",
            "Epoch 73/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 0.6719 - accuracy: 0.7352 - val_loss: 0.7601 - val_accuracy: 0.7229\n",
            "Epoch 74/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 0.6899 - accuracy: 0.7379 - val_loss: 0.7903 - val_accuracy: 0.7108\n",
            "Epoch 75/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 0.6826 - accuracy: 0.7312 - val_loss: 0.8199 - val_accuracy: 0.6807\n",
            "Epoch 76/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 0.6837 - accuracy: 0.7339 - val_loss: 0.7643 - val_accuracy: 0.7470\n",
            "Epoch 77/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 0.6714 - accuracy: 0.7433 - val_loss: 0.7407 - val_accuracy: 0.7349\n",
            "Epoch 78/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 0.6581 - accuracy: 0.7560 - val_loss: 0.7399 - val_accuracy: 0.7470\n",
            "Epoch 79/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 0.6740 - accuracy: 0.7433 - val_loss: 0.7727 - val_accuracy: 0.7349\n",
            "Epoch 80/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 0.6669 - accuracy: 0.7426 - val_loss: 0.7339 - val_accuracy: 0.7229\n",
            "Epoch 81/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 0.6419 - accuracy: 0.7621 - val_loss: 0.7467 - val_accuracy: 0.7229\n",
            "Epoch 82/700\n",
            "93/93 [==============================] - 1s 14ms/step - loss: 0.6543 - accuracy: 0.7560 - val_loss: 0.7716 - val_accuracy: 0.7470\n",
            "Epoch 83/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 0.6594 - accuracy: 0.7473 - val_loss: 0.7098 - val_accuracy: 0.7651\n",
            "Epoch 84/700\n",
            "93/93 [==============================] - 1s 14ms/step - loss: 0.6173 - accuracy: 0.7648 - val_loss: 0.7455 - val_accuracy: 0.7410\n",
            "Epoch 85/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 0.6263 - accuracy: 0.7534 - val_loss: 0.7159 - val_accuracy: 0.7530\n",
            "Epoch 86/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 0.6138 - accuracy: 0.7527 - val_loss: 0.7263 - val_accuracy: 0.7410\n",
            "Epoch 87/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 0.6116 - accuracy: 0.7547 - val_loss: 0.7197 - val_accuracy: 0.7771\n",
            "Epoch 88/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 0.5949 - accuracy: 0.7809 - val_loss: 0.7304 - val_accuracy: 0.7410\n",
            "Epoch 89/700\n",
            "93/93 [==============================] - 1s 14ms/step - loss: 0.6137 - accuracy: 0.7661 - val_loss: 0.7703 - val_accuracy: 0.7048\n",
            "Epoch 90/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 0.6125 - accuracy: 0.7621 - val_loss: 0.7042 - val_accuracy: 0.7651\n",
            "Epoch 91/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 0.6001 - accuracy: 0.7681 - val_loss: 0.7293 - val_accuracy: 0.7530\n",
            "Epoch 92/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 0.5998 - accuracy: 0.7715 - val_loss: 0.7147 - val_accuracy: 0.7470\n",
            "Epoch 93/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 0.5690 - accuracy: 0.7769 - val_loss: 0.7061 - val_accuracy: 0.7651\n",
            "Epoch 94/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 0.5655 - accuracy: 0.7823 - val_loss: 0.6995 - val_accuracy: 0.7711\n",
            "Epoch 95/700\n",
            "93/93 [==============================] - 1s 14ms/step - loss: 0.5719 - accuracy: 0.7769 - val_loss: 0.7038 - val_accuracy: 0.7530\n",
            "Epoch 96/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 0.5630 - accuracy: 0.7802 - val_loss: 0.7177 - val_accuracy: 0.7771\n",
            "Epoch 97/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 0.5419 - accuracy: 0.7829 - val_loss: 0.7409 - val_accuracy: 0.7349\n",
            "Epoch 98/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 0.5591 - accuracy: 0.7876 - val_loss: 0.7337 - val_accuracy: 0.7530\n",
            "Epoch 99/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 0.5579 - accuracy: 0.7843 - val_loss: 0.7075 - val_accuracy: 0.7771\n",
            "Epoch 100/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 0.5714 - accuracy: 0.7802 - val_loss: 0.7274 - val_accuracy: 0.7169\n",
            "Epoch 101/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 0.5484 - accuracy: 0.7944 - val_loss: 0.6991 - val_accuracy: 0.7590\n",
            "Epoch 102/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 0.5332 - accuracy: 0.7890 - val_loss: 0.6528 - val_accuracy: 0.7711\n",
            "Epoch 103/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 0.5210 - accuracy: 0.8038 - val_loss: 0.6716 - val_accuracy: 0.7651\n",
            "Epoch 104/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 0.5653 - accuracy: 0.7876 - val_loss: 0.7027 - val_accuracy: 0.7289\n",
            "Epoch 105/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 0.5085 - accuracy: 0.8165 - val_loss: 0.6639 - val_accuracy: 0.7771\n",
            "Epoch 106/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 0.5442 - accuracy: 0.7890 - val_loss: 0.6703 - val_accuracy: 0.7711\n",
            "Epoch 107/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 0.5208 - accuracy: 0.7950 - val_loss: 0.6844 - val_accuracy: 0.7711\n",
            "Epoch 108/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 0.5200 - accuracy: 0.7964 - val_loss: 0.6764 - val_accuracy: 0.7590\n",
            "Epoch 109/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 0.5288 - accuracy: 0.8038 - val_loss: 0.6856 - val_accuracy: 0.7590\n",
            "Epoch 110/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 0.4999 - accuracy: 0.8017 - val_loss: 0.6856 - val_accuracy: 0.7711\n",
            "Epoch 111/700\n",
            "93/93 [==============================] - 1s 14ms/step - loss: 0.4917 - accuracy: 0.8125 - val_loss: 0.6627 - val_accuracy: 0.8072\n",
            "Epoch 112/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 0.4891 - accuracy: 0.8138 - val_loss: 0.6798 - val_accuracy: 0.7771\n",
            "Epoch 113/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 0.4933 - accuracy: 0.8138 - val_loss: 0.6814 - val_accuracy: 0.7470\n",
            "Epoch 114/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 0.4822 - accuracy: 0.8138 - val_loss: 0.6416 - val_accuracy: 0.7651\n",
            "Epoch 115/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 0.4876 - accuracy: 0.8098 - val_loss: 0.6936 - val_accuracy: 0.7651\n",
            "Epoch 116/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 0.4797 - accuracy: 0.8138 - val_loss: 0.7029 - val_accuracy: 0.7651\n",
            "Epoch 117/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 0.4905 - accuracy: 0.8058 - val_loss: 0.6664 - val_accuracy: 0.7952\n",
            "Epoch 118/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 0.4582 - accuracy: 0.8165 - val_loss: 0.6621 - val_accuracy: 0.7771\n",
            "Epoch 119/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 0.4700 - accuracy: 0.8273 - val_loss: 0.6514 - val_accuracy: 0.7651\n",
            "Epoch 120/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 0.4624 - accuracy: 0.8165 - val_loss: 0.7554 - val_accuracy: 0.7349\n",
            "Epoch 121/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 0.4603 - accuracy: 0.8401 - val_loss: 0.6990 - val_accuracy: 0.7711\n",
            "Epoch 122/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 0.4630 - accuracy: 0.8172 - val_loss: 0.6635 - val_accuracy: 0.7530\n",
            "Epoch 123/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 0.4378 - accuracy: 0.8259 - val_loss: 0.6540 - val_accuracy: 0.7771\n",
            "Epoch 124/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 0.4293 - accuracy: 0.8380 - val_loss: 0.6496 - val_accuracy: 0.7831\n",
            "Epoch 125/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 0.4567 - accuracy: 0.8280 - val_loss: 0.6591 - val_accuracy: 0.7771\n",
            "Epoch 126/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 0.4296 - accuracy: 0.8360 - val_loss: 0.6703 - val_accuracy: 0.7711\n",
            "Epoch 127/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 0.4331 - accuracy: 0.8327 - val_loss: 0.6483 - val_accuracy: 0.7651\n",
            "Epoch 128/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 0.4382 - accuracy: 0.8280 - val_loss: 0.6540 - val_accuracy: 0.7892\n",
            "Epoch 129/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 0.4194 - accuracy: 0.8380 - val_loss: 0.6616 - val_accuracy: 0.7651\n",
            "Epoch 130/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 0.4318 - accuracy: 0.8320 - val_loss: 0.6211 - val_accuracy: 0.7831\n",
            "Epoch 131/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 0.4238 - accuracy: 0.8414 - val_loss: 0.6427 - val_accuracy: 0.7711\n",
            "Epoch 132/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 0.4103 - accuracy: 0.8569 - val_loss: 0.6679 - val_accuracy: 0.7831\n",
            "Epoch 133/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 0.4334 - accuracy: 0.8468 - val_loss: 0.6411 - val_accuracy: 0.7952\n",
            "Epoch 134/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 0.4054 - accuracy: 0.8542 - val_loss: 0.6439 - val_accuracy: 0.7831\n",
            "Epoch 135/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 0.3863 - accuracy: 0.8575 - val_loss: 0.6712 - val_accuracy: 0.7289\n",
            "Epoch 136/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 0.4375 - accuracy: 0.8306 - val_loss: 0.6465 - val_accuracy: 0.7831\n",
            "Epoch 137/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 0.4117 - accuracy: 0.8474 - val_loss: 0.6752 - val_accuracy: 0.7530\n",
            "Epoch 138/700\n",
            "93/93 [==============================] - 1s 16ms/step - loss: 0.3890 - accuracy: 0.8562 - val_loss: 0.6203 - val_accuracy: 0.7831\n",
            "Epoch 139/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 0.3886 - accuracy: 0.8528 - val_loss: 0.6636 - val_accuracy: 0.7590\n",
            "Epoch 140/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 0.3814 - accuracy: 0.8542 - val_loss: 0.6524 - val_accuracy: 0.7590\n",
            "Epoch 141/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 0.4011 - accuracy: 0.8575 - val_loss: 0.6087 - val_accuracy: 0.7892\n",
            "Epoch 142/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 0.3964 - accuracy: 0.8535 - val_loss: 0.6253 - val_accuracy: 0.7590\n",
            "Epoch 143/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 0.3816 - accuracy: 0.8548 - val_loss: 0.6297 - val_accuracy: 0.7651\n",
            "Epoch 144/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 0.3796 - accuracy: 0.8548 - val_loss: 0.6650 - val_accuracy: 0.7590\n",
            "Epoch 145/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 0.3628 - accuracy: 0.8629 - val_loss: 0.6360 - val_accuracy: 0.7771\n",
            "Epoch 146/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 0.3581 - accuracy: 0.8737 - val_loss: 0.6290 - val_accuracy: 0.7892\n",
            "Epoch 147/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 0.3744 - accuracy: 0.8609 - val_loss: 0.6343 - val_accuracy: 0.7711\n",
            "Epoch 148/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 0.3661 - accuracy: 0.8616 - val_loss: 0.6719 - val_accuracy: 0.7651\n",
            "Epoch 149/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 0.3484 - accuracy: 0.8743 - val_loss: 0.6527 - val_accuracy: 0.7892\n",
            "Epoch 150/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 0.3670 - accuracy: 0.8528 - val_loss: 0.5919 - val_accuracy: 0.7892\n",
            "Epoch 151/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 0.3654 - accuracy: 0.8656 - val_loss: 0.6434 - val_accuracy: 0.7711\n",
            "Epoch 152/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 0.3545 - accuracy: 0.8703 - val_loss: 0.6309 - val_accuracy: 0.7831\n",
            "Epoch 153/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 0.3495 - accuracy: 0.8669 - val_loss: 0.7010 - val_accuracy: 0.7410\n",
            "Epoch 154/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 0.3559 - accuracy: 0.8690 - val_loss: 0.6073 - val_accuracy: 0.7771\n",
            "Epoch 155/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 0.3616 - accuracy: 0.8629 - val_loss: 0.5960 - val_accuracy: 0.8012\n",
            "Epoch 156/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 0.3279 - accuracy: 0.8884 - val_loss: 0.7311 - val_accuracy: 0.6928\n",
            "Epoch 157/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 0.3447 - accuracy: 0.8730 - val_loss: 0.6228 - val_accuracy: 0.8012\n",
            "Epoch 158/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 0.3351 - accuracy: 0.8710 - val_loss: 0.6243 - val_accuracy: 0.7892\n",
            "Epoch 159/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 0.3356 - accuracy: 0.8757 - val_loss: 0.6333 - val_accuracy: 0.7952\n",
            "Epoch 160/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 0.3380 - accuracy: 0.8669 - val_loss: 0.6410 - val_accuracy: 0.7711\n",
            "Epoch 161/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 0.3355 - accuracy: 0.8710 - val_loss: 0.5989 - val_accuracy: 0.8012\n",
            "Epoch 162/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 0.3270 - accuracy: 0.8763 - val_loss: 0.6190 - val_accuracy: 0.7952\n",
            "Epoch 163/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 0.3280 - accuracy: 0.8810 - val_loss: 0.7018 - val_accuracy: 0.7108\n",
            "Epoch 164/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 0.3240 - accuracy: 0.8804 - val_loss: 0.6037 - val_accuracy: 0.7952\n",
            "Epoch 165/700\n",
            "93/93 [==============================] - 1s 16ms/step - loss: 0.3516 - accuracy: 0.8696 - val_loss: 0.6571 - val_accuracy: 0.7831\n",
            "Epoch 166/700\n",
            "93/93 [==============================] - 1s 16ms/step - loss: 0.3088 - accuracy: 0.8878 - val_loss: 0.6391 - val_accuracy: 0.7771\n",
            "Epoch 167/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 0.3113 - accuracy: 0.8898 - val_loss: 0.6178 - val_accuracy: 0.7711\n",
            "Epoch 168/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 0.3093 - accuracy: 0.8824 - val_loss: 0.6228 - val_accuracy: 0.7952\n",
            "Epoch 169/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 0.3068 - accuracy: 0.8858 - val_loss: 0.6021 - val_accuracy: 0.8133\n",
            "Epoch 170/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 0.3008 - accuracy: 0.8918 - val_loss: 0.7162 - val_accuracy: 0.7651\n",
            "Epoch 171/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 0.3083 - accuracy: 0.8763 - val_loss: 0.6237 - val_accuracy: 0.7831\n",
            "Epoch 172/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 0.3110 - accuracy: 0.8763 - val_loss: 0.6265 - val_accuracy: 0.8072\n",
            "Epoch 173/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 0.2895 - accuracy: 0.8992 - val_loss: 0.5996 - val_accuracy: 0.7892\n",
            "Epoch 174/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 0.3034 - accuracy: 0.8884 - val_loss: 0.6124 - val_accuracy: 0.7952\n",
            "Epoch 175/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 0.2764 - accuracy: 0.9019 - val_loss: 0.6373 - val_accuracy: 0.7892\n",
            "Epoch 176/700\n",
            "93/93 [==============================] - 1s 16ms/step - loss: 0.3066 - accuracy: 0.8898 - val_loss: 0.6316 - val_accuracy: 0.7952\n",
            "Epoch 177/700\n",
            "93/93 [==============================] - 1s 16ms/step - loss: 0.2998 - accuracy: 0.8878 - val_loss: 0.6160 - val_accuracy: 0.8133\n",
            "Epoch 178/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 0.2923 - accuracy: 0.8864 - val_loss: 0.6434 - val_accuracy: 0.7952\n",
            "Epoch 179/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 0.2965 - accuracy: 0.8965 - val_loss: 0.6609 - val_accuracy: 0.7711\n",
            "Epoch 180/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 0.2954 - accuracy: 0.8864 - val_loss: 0.6542 - val_accuracy: 0.7771\n",
            "Epoch 181/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 0.2824 - accuracy: 0.9012 - val_loss: 0.7352 - val_accuracy: 0.7410\n",
            "Epoch 182/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 0.2950 - accuracy: 0.8938 - val_loss: 0.6435 - val_accuracy: 0.7952\n",
            "Epoch 183/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 0.2674 - accuracy: 0.9140 - val_loss: 0.6127 - val_accuracy: 0.8012\n",
            "Epoch 184/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 0.2853 - accuracy: 0.8864 - val_loss: 0.6276 - val_accuracy: 0.7892\n",
            "Epoch 185/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 0.2813 - accuracy: 0.8958 - val_loss: 0.6469 - val_accuracy: 0.7952\n",
            "Epoch 186/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 0.2637 - accuracy: 0.9099 - val_loss: 0.6128 - val_accuracy: 0.7952\n",
            "Epoch 187/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 0.2667 - accuracy: 0.8972 - val_loss: 0.6560 - val_accuracy: 0.7831\n",
            "Epoch 188/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 0.2782 - accuracy: 0.8952 - val_loss: 0.6281 - val_accuracy: 0.8133\n",
            "Epoch 189/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 0.2647 - accuracy: 0.9059 - val_loss: 0.6847 - val_accuracy: 0.7349\n",
            "Epoch 190/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 0.2625 - accuracy: 0.9133 - val_loss: 0.6241 - val_accuracy: 0.7892\n",
            "Epoch 191/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 0.2666 - accuracy: 0.9032 - val_loss: 0.6404 - val_accuracy: 0.7952\n",
            "Epoch 192/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 0.2526 - accuracy: 0.9086 - val_loss: 0.6997 - val_accuracy: 0.7590\n",
            "Epoch 193/700\n",
            "93/93 [==============================] - 1s 16ms/step - loss: 0.2515 - accuracy: 0.9126 - val_loss: 0.6939 - val_accuracy: 0.7952\n",
            "Epoch 194/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 0.2591 - accuracy: 0.9005 - val_loss: 0.6490 - val_accuracy: 0.7952\n",
            "Epoch 195/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 0.2438 - accuracy: 0.9173 - val_loss: 0.6200 - val_accuracy: 0.7892\n",
            "Epoch 196/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 0.2515 - accuracy: 0.9120 - val_loss: 0.5988 - val_accuracy: 0.8012\n",
            "Epoch 197/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 0.2447 - accuracy: 0.9106 - val_loss: 0.6735 - val_accuracy: 0.7651\n",
            "Epoch 198/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 0.2531 - accuracy: 0.9120 - val_loss: 0.6329 - val_accuracy: 0.7831\n",
            "Epoch 199/700\n",
            "93/93 [==============================] - 1s 16ms/step - loss: 0.2738 - accuracy: 0.8978 - val_loss: 0.6628 - val_accuracy: 0.7771\n",
            "Epoch 200/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 0.2310 - accuracy: 0.9133 - val_loss: 0.6761 - val_accuracy: 0.7771\n",
            "Epoch 201/700\n",
            "93/93 [==============================] - 1s 16ms/step - loss: 0.2415 - accuracy: 0.9147 - val_loss: 0.6366 - val_accuracy: 0.7892\n",
            "Epoch 202/700\n",
            "93/93 [==============================] - 1s 16ms/step - loss: 0.2231 - accuracy: 0.9180 - val_loss: 0.6515 - val_accuracy: 0.7892\n",
            "Epoch 203/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 0.2418 - accuracy: 0.9106 - val_loss: 0.6168 - val_accuracy: 0.8072\n",
            "Epoch 204/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 0.2436 - accuracy: 0.9086 - val_loss: 0.7252 - val_accuracy: 0.7711\n",
            "Epoch 205/700\n",
            "93/93 [==============================] - 1s 16ms/step - loss: 0.2336 - accuracy: 0.9147 - val_loss: 0.6805 - val_accuracy: 0.7831\n",
            "Epoch 206/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 0.2204 - accuracy: 0.9207 - val_loss: 0.7083 - val_accuracy: 0.7771\n",
            "Epoch 207/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 0.2265 - accuracy: 0.9200 - val_loss: 0.6463 - val_accuracy: 0.8012\n",
            "Epoch 208/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 0.2270 - accuracy: 0.9120 - val_loss: 0.6419 - val_accuracy: 0.7952\n",
            "Epoch 209/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 0.2367 - accuracy: 0.9220 - val_loss: 0.6288 - val_accuracy: 0.7892\n",
            "Epoch 210/700\n",
            "93/93 [==============================] - 1s 16ms/step - loss: 0.2237 - accuracy: 0.9234 - val_loss: 0.6275 - val_accuracy: 0.8133\n",
            "Epoch 211/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 0.2139 - accuracy: 0.9267 - val_loss: 0.6336 - val_accuracy: 0.8072\n",
            "Epoch 212/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 0.2128 - accuracy: 0.9227 - val_loss: 0.6646 - val_accuracy: 0.8012\n",
            "Epoch 213/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 0.2215 - accuracy: 0.9140 - val_loss: 0.6808 - val_accuracy: 0.8012\n",
            "Epoch 214/700\n",
            "93/93 [==============================] - 1s 16ms/step - loss: 0.2280 - accuracy: 0.9220 - val_loss: 0.6598 - val_accuracy: 0.7892\n",
            "Epoch 215/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 0.2109 - accuracy: 0.9200 - val_loss: 0.6363 - val_accuracy: 0.7952\n",
            "Epoch 216/700\n",
            "93/93 [==============================] - 1s 16ms/step - loss: 0.1998 - accuracy: 0.9328 - val_loss: 0.6805 - val_accuracy: 0.7711\n",
            "Epoch 217/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 0.2227 - accuracy: 0.9113 - val_loss: 0.6241 - val_accuracy: 0.8133\n",
            "Epoch 218/700\n",
            "93/93 [==============================] - 1s 16ms/step - loss: 0.2029 - accuracy: 0.9267 - val_loss: 0.6548 - val_accuracy: 0.7892\n",
            "Epoch 219/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 0.2029 - accuracy: 0.9281 - val_loss: 0.6925 - val_accuracy: 0.7952\n",
            "Epoch 220/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 0.2385 - accuracy: 0.9086 - val_loss: 0.6531 - val_accuracy: 0.7952\n",
            "Epoch 221/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 0.1969 - accuracy: 0.9267 - val_loss: 0.6934 - val_accuracy: 0.8012\n",
            "Epoch 222/700\n",
            "93/93 [==============================] - 1s 16ms/step - loss: 0.2075 - accuracy: 0.9267 - val_loss: 0.7079 - val_accuracy: 0.8012\n",
            "Epoch 223/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 0.2068 - accuracy: 0.9274 - val_loss: 0.6404 - val_accuracy: 0.7711\n",
            "Epoch 224/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 0.2257 - accuracy: 0.9207 - val_loss: 0.6527 - val_accuracy: 0.7952\n",
            "Epoch 225/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 0.1951 - accuracy: 0.9308 - val_loss: 0.6672 - val_accuracy: 0.7831\n",
            "Epoch 226/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 0.1957 - accuracy: 0.9274 - val_loss: 0.6628 - val_accuracy: 0.8012\n",
            "Epoch 227/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 0.2013 - accuracy: 0.9194 - val_loss: 0.6999 - val_accuracy: 0.7892\n",
            "Epoch 228/700\n",
            "93/93 [==============================] - 1s 16ms/step - loss: 0.1930 - accuracy: 0.9321 - val_loss: 0.6529 - val_accuracy: 0.8012\n",
            "Epoch 229/700\n",
            "93/93 [==============================] - 1s 16ms/step - loss: 0.2361 - accuracy: 0.9147 - val_loss: 0.6664 - val_accuracy: 0.7952\n",
            "Epoch 230/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 0.1920 - accuracy: 0.9294 - val_loss: 0.6552 - val_accuracy: 0.7892\n",
            "Epoch 231/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 0.1990 - accuracy: 0.9267 - val_loss: 0.6875 - val_accuracy: 0.7892\n",
            "Epoch 232/700\n",
            "93/93 [==============================] - 1s 16ms/step - loss: 0.2018 - accuracy: 0.9335 - val_loss: 0.6978 - val_accuracy: 0.7771\n",
            "Epoch 233/700\n",
            "93/93 [==============================] - 1s 16ms/step - loss: 0.2041 - accuracy: 0.9301 - val_loss: 0.6632 - val_accuracy: 0.7892\n",
            "Epoch 234/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 0.1873 - accuracy: 0.9382 - val_loss: 0.6581 - val_accuracy: 0.8012\n",
            "Epoch 235/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 0.1765 - accuracy: 0.9341 - val_loss: 0.6852 - val_accuracy: 0.7892\n",
            "Epoch 236/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 0.1789 - accuracy: 0.9409 - val_loss: 0.6604 - val_accuracy: 0.7892\n",
            "Epoch 237/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 0.1642 - accuracy: 0.9449 - val_loss: 0.6951 - val_accuracy: 0.8072\n",
            "Epoch 238/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 0.1994 - accuracy: 0.9261 - val_loss: 0.6895 - val_accuracy: 0.8072\n",
            "Epoch 239/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 0.1952 - accuracy: 0.9328 - val_loss: 0.6493 - val_accuracy: 0.8133\n",
            "Epoch 240/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 0.1773 - accuracy: 0.9321 - val_loss: 0.6348 - val_accuracy: 0.8072\n",
            "Epoch 241/700\n",
            "93/93 [==============================] - 1s 16ms/step - loss: 0.1753 - accuracy: 0.9375 - val_loss: 0.6734 - val_accuracy: 0.8072\n",
            "Epoch 242/700\n",
            "93/93 [==============================] - 1s 16ms/step - loss: 0.1647 - accuracy: 0.9469 - val_loss: 0.7407 - val_accuracy: 0.7892\n",
            "Epoch 243/700\n",
            "93/93 [==============================] - 1s 16ms/step - loss: 0.1753 - accuracy: 0.9348 - val_loss: 0.6668 - val_accuracy: 0.7952\n",
            "Epoch 244/700\n",
            "93/93 [==============================] - 1s 16ms/step - loss: 0.1718 - accuracy: 0.9362 - val_loss: 0.7544 - val_accuracy: 0.7771\n",
            "Epoch 245/700\n",
            "93/93 [==============================] - 1s 16ms/step - loss: 0.1874 - accuracy: 0.9274 - val_loss: 0.6693 - val_accuracy: 0.7952\n",
            "Epoch 246/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 0.1570 - accuracy: 0.9476 - val_loss: 0.7304 - val_accuracy: 0.7590\n",
            "Epoch 247/700\n",
            "93/93 [==============================] - 1s 16ms/step - loss: 0.1720 - accuracy: 0.9442 - val_loss: 0.6613 - val_accuracy: 0.8012\n",
            "Epoch 248/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 0.1686 - accuracy: 0.9409 - val_loss: 0.6805 - val_accuracy: 0.8012\n",
            "Epoch 249/700\n",
            "93/93 [==============================] - 1s 16ms/step - loss: 0.1792 - accuracy: 0.9395 - val_loss: 0.6523 - val_accuracy: 0.8133\n",
            "Epoch 250/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 0.1776 - accuracy: 0.9355 - val_loss: 0.6609 - val_accuracy: 0.8193\n",
            "Epoch 251/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 0.1722 - accuracy: 0.9395 - val_loss: 0.7112 - val_accuracy: 0.7831\n",
            "Epoch 252/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 0.1743 - accuracy: 0.9388 - val_loss: 0.7457 - val_accuracy: 0.7952\n",
            "Epoch 253/700\n",
            "93/93 [==============================] - 1s 16ms/step - loss: 0.1759 - accuracy: 0.9348 - val_loss: 0.7881 - val_accuracy: 0.7530\n",
            "Epoch 254/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 0.1665 - accuracy: 0.9368 - val_loss: 0.7988 - val_accuracy: 0.7651\n",
            "Epoch 255/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 0.1872 - accuracy: 0.9234 - val_loss: 0.7211 - val_accuracy: 0.7711\n",
            "Epoch 256/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 0.1786 - accuracy: 0.9402 - val_loss: 0.7204 - val_accuracy: 0.7892\n",
            "Epoch 257/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 0.1622 - accuracy: 0.9435 - val_loss: 0.6996 - val_accuracy: 0.7892\n",
            "Epoch 258/700\n",
            "93/93 [==============================] - 1s 16ms/step - loss: 0.1652 - accuracy: 0.9328 - val_loss: 0.6770 - val_accuracy: 0.8012\n",
            "Epoch 259/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 0.1535 - accuracy: 0.9476 - val_loss: 0.7133 - val_accuracy: 0.8072\n",
            "Epoch 260/700\n",
            "93/93 [==============================] - 1s 16ms/step - loss: 0.1657 - accuracy: 0.9382 - val_loss: 0.7161 - val_accuracy: 0.7711\n",
            "Epoch 261/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 0.1419 - accuracy: 0.9489 - val_loss: 0.7479 - val_accuracy: 0.7711\n",
            "Epoch 262/700\n",
            "93/93 [==============================] - 1s 16ms/step - loss: 0.1628 - accuracy: 0.9409 - val_loss: 0.7188 - val_accuracy: 0.8072\n",
            "Epoch 263/700\n",
            "93/93 [==============================] - 1s 16ms/step - loss: 0.1742 - accuracy: 0.9388 - val_loss: 0.7850 - val_accuracy: 0.7711\n",
            "Epoch 264/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 0.1588 - accuracy: 0.9442 - val_loss: 0.7888 - val_accuracy: 0.7470\n",
            "Epoch 265/700\n",
            "93/93 [==============================] - 1s 16ms/step - loss: 0.1351 - accuracy: 0.9503 - val_loss: 0.6880 - val_accuracy: 0.7952\n",
            "Epoch 266/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 0.1543 - accuracy: 0.9429 - val_loss: 0.7136 - val_accuracy: 0.7771\n",
            "Epoch 267/700\n",
            "93/93 [==============================] - 1s 16ms/step - loss: 0.1587 - accuracy: 0.9409 - val_loss: 0.7392 - val_accuracy: 0.7771\n",
            "Epoch 268/700\n",
            "93/93 [==============================] - 1s 16ms/step - loss: 0.1504 - accuracy: 0.9469 - val_loss: 0.7254 - val_accuracy: 0.8012\n",
            "Epoch 269/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 0.1593 - accuracy: 0.9442 - val_loss: 0.7408 - val_accuracy: 0.7831\n",
            "Epoch 270/700\n",
            "93/93 [==============================] - 1s 16ms/step - loss: 0.1566 - accuracy: 0.9375 - val_loss: 0.7797 - val_accuracy: 0.7590\n",
            "Epoch 271/700\n",
            "93/93 [==============================] - 1s 16ms/step - loss: 0.1517 - accuracy: 0.9469 - val_loss: 0.7435 - val_accuracy: 0.7952\n",
            "Epoch 272/700\n",
            "93/93 [==============================] - 1s 16ms/step - loss: 0.1587 - accuracy: 0.9409 - val_loss: 0.7331 - val_accuracy: 0.8313\n",
            "Epoch 273/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 0.1619 - accuracy: 0.9415 - val_loss: 0.6991 - val_accuracy: 0.7892\n",
            "Epoch 274/700\n",
            "93/93 [==============================] - 1s 16ms/step - loss: 0.1422 - accuracy: 0.9516 - val_loss: 0.6783 - val_accuracy: 0.8072\n",
            "Epoch 275/700\n",
            "93/93 [==============================] - 1s 16ms/step - loss: 0.1533 - accuracy: 0.9476 - val_loss: 0.7723 - val_accuracy: 0.7530\n",
            "Epoch 276/700\n",
            "93/93 [==============================] - 1s 16ms/step - loss: 0.1542 - accuracy: 0.9442 - val_loss: 0.7422 - val_accuracy: 0.7771\n",
            "Epoch 277/700\n",
            "93/93 [==============================] - 1s 16ms/step - loss: 0.1417 - accuracy: 0.9462 - val_loss: 0.7169 - val_accuracy: 0.7952\n",
            "Epoch 278/700\n",
            "93/93 [==============================] - 1s 16ms/step - loss: 0.1287 - accuracy: 0.9624 - val_loss: 0.7027 - val_accuracy: 0.8012\n",
            "Epoch 279/700\n",
            "93/93 [==============================] - 1s 16ms/step - loss: 0.1535 - accuracy: 0.9469 - val_loss: 0.7494 - val_accuracy: 0.7892\n",
            "Epoch 280/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 0.1601 - accuracy: 0.9388 - val_loss: 0.6667 - val_accuracy: 0.8133\n",
            "Epoch 281/700\n",
            "93/93 [==============================] - 1s 16ms/step - loss: 0.1259 - accuracy: 0.9550 - val_loss: 0.6723 - val_accuracy: 0.8253\n",
            "Epoch 282/700\n",
            "93/93 [==============================] - 1s 16ms/step - loss: 0.1567 - accuracy: 0.9429 - val_loss: 0.6793 - val_accuracy: 0.8012\n",
            "Epoch 283/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 0.1375 - accuracy: 0.9509 - val_loss: 0.6930 - val_accuracy: 0.8253\n",
            "Epoch 284/700\n",
            "93/93 [==============================] - 1s 16ms/step - loss: 0.1236 - accuracy: 0.9550 - val_loss: 0.6590 - val_accuracy: 0.7952\n",
            "Epoch 285/700\n",
            "93/93 [==============================] - 1s 16ms/step - loss: 0.1382 - accuracy: 0.9456 - val_loss: 0.7298 - val_accuracy: 0.8133\n",
            "Epoch 286/700\n",
            "93/93 [==============================] - 1s 16ms/step - loss: 0.1479 - accuracy: 0.9456 - val_loss: 0.6571 - val_accuracy: 0.8133\n",
            "Epoch 287/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 0.1376 - accuracy: 0.9536 - val_loss: 0.7005 - val_accuracy: 0.8072\n",
            "Epoch 288/700\n",
            "93/93 [==============================] - 1s 16ms/step - loss: 0.1227 - accuracy: 0.9489 - val_loss: 0.7525 - val_accuracy: 0.8072\n",
            "Epoch 289/700\n",
            "93/93 [==============================] - 1s 16ms/step - loss: 0.1408 - accuracy: 0.9483 - val_loss: 0.7105 - val_accuracy: 0.8133\n",
            "Epoch 290/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 0.1318 - accuracy: 0.9530 - val_loss: 0.7364 - val_accuracy: 0.7892\n",
            "Epoch 291/700\n",
            "93/93 [==============================] - 1s 16ms/step - loss: 0.1494 - accuracy: 0.9456 - val_loss: 0.7394 - val_accuracy: 0.7892\n",
            "Epoch 292/700\n",
            "93/93 [==============================] - 2s 16ms/step - loss: 0.1264 - accuracy: 0.9570 - val_loss: 0.7390 - val_accuracy: 0.7892\n",
            "Epoch 293/700\n",
            "93/93 [==============================] - 1s 16ms/step - loss: 0.1293 - accuracy: 0.9543 - val_loss: 0.7559 - val_accuracy: 0.7892\n",
            "Epoch 294/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 0.1368 - accuracy: 0.9563 - val_loss: 0.7490 - val_accuracy: 0.7892\n",
            "Epoch 295/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 0.1360 - accuracy: 0.9556 - val_loss: 0.7258 - val_accuracy: 0.7771\n",
            "Epoch 296/700\n",
            "93/93 [==============================] - 1s 16ms/step - loss: 0.1342 - accuracy: 0.9536 - val_loss: 0.7387 - val_accuracy: 0.7892\n",
            "Epoch 297/700\n",
            "93/93 [==============================] - 1s 16ms/step - loss: 0.1261 - accuracy: 0.9536 - val_loss: 0.7201 - val_accuracy: 0.7892\n",
            "Epoch 298/700\n",
            "93/93 [==============================] - 1s 16ms/step - loss: 0.1331 - accuracy: 0.9530 - val_loss: 0.7153 - val_accuracy: 0.8133\n",
            "Epoch 299/700\n",
            "93/93 [==============================] - 1s 16ms/step - loss: 0.1209 - accuracy: 0.9590 - val_loss: 0.7231 - val_accuracy: 0.8072\n",
            "Epoch 300/700\n",
            "93/93 [==============================] - 1s 16ms/step - loss: 0.1456 - accuracy: 0.9550 - val_loss: 0.7423 - val_accuracy: 0.8072\n",
            "Epoch 301/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 0.1242 - accuracy: 0.9617 - val_loss: 0.7132 - val_accuracy: 0.8133\n",
            "Epoch 302/700\n",
            "93/93 [==============================] - 2s 16ms/step - loss: 0.1344 - accuracy: 0.9550 - val_loss: 0.7767 - val_accuracy: 0.8133\n",
            "Epoch 303/700\n",
            "93/93 [==============================] - 1s 16ms/step - loss: 0.1242 - accuracy: 0.9543 - val_loss: 0.7282 - val_accuracy: 0.8133\n",
            "Epoch 304/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 0.1302 - accuracy: 0.9590 - val_loss: 0.8215 - val_accuracy: 0.7831\n",
            "Epoch 305/700\n",
            "93/93 [==============================] - 1s 16ms/step - loss: 0.1291 - accuracy: 0.9530 - val_loss: 0.7459 - val_accuracy: 0.8193\n",
            "Epoch 306/700\n",
            "93/93 [==============================] - 2s 16ms/step - loss: 0.1388 - accuracy: 0.9496 - val_loss: 0.7614 - val_accuracy: 0.8072\n",
            "Epoch 307/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 0.1124 - accuracy: 0.9570 - val_loss: 0.7662 - val_accuracy: 0.7831\n",
            "Epoch 308/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 0.1275 - accuracy: 0.9597 - val_loss: 0.7368 - val_accuracy: 0.8072\n",
            "Epoch 309/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 0.1170 - accuracy: 0.9563 - val_loss: 0.7208 - val_accuracy: 0.8253\n",
            "Epoch 310/700\n",
            "93/93 [==============================] - 1s 16ms/step - loss: 0.1098 - accuracy: 0.9630 - val_loss: 0.7595 - val_accuracy: 0.8133\n",
            "Epoch 311/700\n",
            "93/93 [==============================] - 1s 16ms/step - loss: 0.1172 - accuracy: 0.9577 - val_loss: 0.7790 - val_accuracy: 0.8012\n",
            "Epoch 312/700\n",
            "93/93 [==============================] - 1s 16ms/step - loss: 0.1210 - accuracy: 0.9583 - val_loss: 0.8004 - val_accuracy: 0.8012\n",
            "Epoch 313/700\n",
            "93/93 [==============================] - 1s 16ms/step - loss: 0.1054 - accuracy: 0.9637 - val_loss: 0.6928 - val_accuracy: 0.8434\n",
            "Epoch 314/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 0.1313 - accuracy: 0.9570 - val_loss: 0.6951 - val_accuracy: 0.8253\n",
            "Epoch 315/700\n",
            "93/93 [==============================] - 1s 16ms/step - loss: 0.1245 - accuracy: 0.9583 - val_loss: 0.7670 - val_accuracy: 0.7952\n",
            "Epoch 316/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 0.1163 - accuracy: 0.9610 - val_loss: 0.7551 - val_accuracy: 0.8133\n",
            "Epoch 317/700\n",
            "93/93 [==============================] - 1s 16ms/step - loss: 0.1152 - accuracy: 0.9577 - val_loss: 0.6854 - val_accuracy: 0.8072\n",
            "Epoch 318/700\n",
            "93/93 [==============================] - 2s 16ms/step - loss: 0.1159 - accuracy: 0.9637 - val_loss: 0.7311 - val_accuracy: 0.8072\n",
            "Epoch 319/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 0.1332 - accuracy: 0.9536 - val_loss: 0.7211 - val_accuracy: 0.8253\n",
            "Epoch 320/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 0.1318 - accuracy: 0.9516 - val_loss: 0.7974 - val_accuracy: 0.7892\n",
            "Epoch 321/700\n",
            "93/93 [==============================] - 1s 16ms/step - loss: 0.1275 - accuracy: 0.9516 - val_loss: 0.7078 - val_accuracy: 0.8133\n",
            "Epoch 322/700\n",
            "93/93 [==============================] - 1s 16ms/step - loss: 0.1161 - accuracy: 0.9583 - val_loss: 0.7381 - val_accuracy: 0.7892\n",
            "Epoch 323/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 0.1037 - accuracy: 0.9577 - val_loss: 0.7615 - val_accuracy: 0.8072\n",
            "Epoch 324/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 0.1291 - accuracy: 0.9523 - val_loss: 0.7651 - val_accuracy: 0.8253\n",
            "Epoch 325/700\n",
            "93/93 [==============================] - 1s 16ms/step - loss: 0.1112 - accuracy: 0.9563 - val_loss: 0.6988 - val_accuracy: 0.8193\n",
            "Epoch 326/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 0.1187 - accuracy: 0.9556 - val_loss: 0.8221 - val_accuracy: 0.7952\n",
            "Epoch 327/700\n",
            "93/93 [==============================] - 1s 16ms/step - loss: 0.1072 - accuracy: 0.9637 - val_loss: 0.8292 - val_accuracy: 0.7831\n",
            "Epoch 328/700\n",
            "93/93 [==============================] - 2s 16ms/step - loss: 0.1129 - accuracy: 0.9603 - val_loss: 0.7650 - val_accuracy: 0.7892\n",
            "Epoch 329/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 0.1058 - accuracy: 0.9657 - val_loss: 0.8692 - val_accuracy: 0.7892\n",
            "Epoch 330/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 0.1162 - accuracy: 0.9583 - val_loss: 0.8173 - val_accuracy: 0.8072\n",
            "Epoch 331/700\n",
            "93/93 [==============================] - 1s 16ms/step - loss: 0.0936 - accuracy: 0.9677 - val_loss: 0.7519 - val_accuracy: 0.8253\n",
            "Epoch 332/700\n",
            "93/93 [==============================] - 2s 16ms/step - loss: 0.1013 - accuracy: 0.9671 - val_loss: 0.8381 - val_accuracy: 0.8193\n",
            "Epoch 333/700\n",
            "93/93 [==============================] - 1s 16ms/step - loss: 0.1040 - accuracy: 0.9664 - val_loss: 0.7615 - val_accuracy: 0.8133\n",
            "Epoch 334/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 0.1030 - accuracy: 0.9644 - val_loss: 0.8046 - val_accuracy: 0.7831\n",
            "Epoch 335/700\n",
            "93/93 [==============================] - 1s 16ms/step - loss: 0.0949 - accuracy: 0.9664 - val_loss: 0.7612 - val_accuracy: 0.7711\n",
            "Epoch 336/700\n",
            "93/93 [==============================] - 1s 16ms/step - loss: 0.1185 - accuracy: 0.9644 - val_loss: 0.7659 - val_accuracy: 0.8133\n",
            "Epoch 337/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 0.1060 - accuracy: 0.9657 - val_loss: 0.7612 - val_accuracy: 0.8133\n",
            "Epoch 338/700\n",
            "93/93 [==============================] - 1s 16ms/step - loss: 0.1149 - accuracy: 0.9583 - val_loss: 0.8204 - val_accuracy: 0.8133\n",
            "Epoch 339/700\n",
            "93/93 [==============================] - 1s 16ms/step - loss: 0.0904 - accuracy: 0.9698 - val_loss: 0.7894 - val_accuracy: 0.7771\n",
            "Epoch 340/700\n",
            "93/93 [==============================] - 1s 16ms/step - loss: 0.1158 - accuracy: 0.9597 - val_loss: 0.7471 - val_accuracy: 0.8253\n",
            "Epoch 341/700\n",
            "93/93 [==============================] - 1s 16ms/step - loss: 0.1136 - accuracy: 0.9624 - val_loss: 0.7198 - val_accuracy: 0.8072\n",
            "Epoch 342/700\n",
            "93/93 [==============================] - 2s 16ms/step - loss: 0.0960 - accuracy: 0.9745 - val_loss: 0.7787 - val_accuracy: 0.8133\n",
            "Epoch 343/700\n",
            "93/93 [==============================] - 1s 16ms/step - loss: 0.1002 - accuracy: 0.9630 - val_loss: 0.7942 - val_accuracy: 0.8253\n",
            "Epoch 344/700\n",
            "93/93 [==============================] - 1s 16ms/step - loss: 0.1043 - accuracy: 0.9630 - val_loss: 0.8409 - val_accuracy: 0.8193\n",
            "Epoch 345/700\n",
            "93/93 [==============================] - 1s 16ms/step - loss: 0.1103 - accuracy: 0.9637 - val_loss: 0.7480 - val_accuracy: 0.7892\n",
            "Epoch 346/700\n",
            "93/93 [==============================] - 2s 16ms/step - loss: 0.0884 - accuracy: 0.9704 - val_loss: 0.7212 - val_accuracy: 0.8072\n",
            "Epoch 347/700\n",
            "93/93 [==============================] - 1s 16ms/step - loss: 0.0908 - accuracy: 0.9704 - val_loss: 0.7252 - val_accuracy: 0.8133\n",
            "Epoch 348/700\n",
            "93/93 [==============================] - 1s 16ms/step - loss: 0.1273 - accuracy: 0.9556 - val_loss: 0.7766 - val_accuracy: 0.8253\n",
            "Epoch 349/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 0.0923 - accuracy: 0.9664 - val_loss: 0.7926 - val_accuracy: 0.8313\n",
            "Epoch 350/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 0.1203 - accuracy: 0.9550 - val_loss: 0.7937 - val_accuracy: 0.7892\n",
            "Epoch 351/700\n",
            "93/93 [==============================] - 1s 16ms/step - loss: 0.0907 - accuracy: 0.9724 - val_loss: 0.7983 - val_accuracy: 0.7831\n",
            "Epoch 352/700\n",
            "93/93 [==============================] - 1s 16ms/step - loss: 0.1001 - accuracy: 0.9651 - val_loss: 0.7506 - val_accuracy: 0.8133\n",
            "Epoch 353/700\n",
            "93/93 [==============================] - 1s 16ms/step - loss: 0.0848 - accuracy: 0.9657 - val_loss: 0.7256 - val_accuracy: 0.8614\n",
            "Epoch 354/700\n",
            "93/93 [==============================] - 1s 16ms/step - loss: 0.1076 - accuracy: 0.9644 - val_loss: 0.7219 - val_accuracy: 0.8253\n",
            "Epoch 355/700\n",
            "93/93 [==============================] - 1s 16ms/step - loss: 0.1065 - accuracy: 0.9657 - val_loss: 0.7371 - val_accuracy: 0.8193\n",
            "Epoch 356/700\n",
            "93/93 [==============================] - 1s 16ms/step - loss: 0.1049 - accuracy: 0.9617 - val_loss: 0.7575 - val_accuracy: 0.8193\n",
            "Epoch 357/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 0.0913 - accuracy: 0.9711 - val_loss: 0.8199 - val_accuracy: 0.7590\n",
            "Epoch 358/700\n",
            "93/93 [==============================] - 1s 16ms/step - loss: 0.0889 - accuracy: 0.9684 - val_loss: 0.7692 - val_accuracy: 0.7831\n",
            "Epoch 359/700\n",
            "93/93 [==============================] - 2s 16ms/step - loss: 0.0975 - accuracy: 0.9677 - val_loss: 0.7875 - val_accuracy: 0.7892\n",
            "Epoch 360/700\n",
            "93/93 [==============================] - 1s 16ms/step - loss: 0.0743 - accuracy: 0.9765 - val_loss: 0.7536 - val_accuracy: 0.8133\n",
            "Epoch 361/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 0.1027 - accuracy: 0.9664 - val_loss: 0.7652 - val_accuracy: 0.8012\n",
            "Epoch 362/700\n",
            "93/93 [==============================] - 1s 16ms/step - loss: 0.0996 - accuracy: 0.9691 - val_loss: 0.7495 - val_accuracy: 0.8072\n",
            "Epoch 363/700\n",
            "93/93 [==============================] - 1s 16ms/step - loss: 0.0947 - accuracy: 0.9718 - val_loss: 0.7813 - val_accuracy: 0.8072\n",
            "Epoch 364/700\n",
            "93/93 [==============================] - 1s 16ms/step - loss: 0.0942 - accuracy: 0.9704 - val_loss: 0.7965 - val_accuracy: 0.8133\n",
            "Epoch 365/700\n",
            "93/93 [==============================] - 1s 16ms/step - loss: 0.1018 - accuracy: 0.9664 - val_loss: 0.7676 - val_accuracy: 0.8253\n",
            "Epoch 366/700\n",
            "93/93 [==============================] - 1s 16ms/step - loss: 0.0909 - accuracy: 0.9711 - val_loss: 0.7705 - val_accuracy: 0.8012\n",
            "Epoch 367/700\n",
            "93/93 [==============================] - 1s 16ms/step - loss: 0.0923 - accuracy: 0.9677 - val_loss: 0.7606 - val_accuracy: 0.8133\n",
            "Epoch 368/700\n",
            "93/93 [==============================] - 2s 16ms/step - loss: 0.1011 - accuracy: 0.9597 - val_loss: 0.7344 - val_accuracy: 0.8434\n",
            "Epoch 369/700\n",
            "93/93 [==============================] - 2s 16ms/step - loss: 0.0927 - accuracy: 0.9731 - val_loss: 0.7882 - val_accuracy: 0.8133\n",
            "Epoch 370/700\n",
            "93/93 [==============================] - 1s 16ms/step - loss: 0.0842 - accuracy: 0.9671 - val_loss: 0.8798 - val_accuracy: 0.8133\n",
            "Epoch 371/700\n",
            "93/93 [==============================] - 1s 16ms/step - loss: 0.0720 - accuracy: 0.9731 - val_loss: 0.8159 - val_accuracy: 0.8133\n",
            "Epoch 372/700\n",
            "93/93 [==============================] - 2s 16ms/step - loss: 0.0985 - accuracy: 0.9677 - val_loss: 0.7436 - val_accuracy: 0.8253\n",
            "Epoch 373/700\n",
            "93/93 [==============================] - 1s 16ms/step - loss: 0.1050 - accuracy: 0.9664 - val_loss: 0.8465 - val_accuracy: 0.8072\n",
            "Epoch 374/700\n",
            "93/93 [==============================] - 1s 16ms/step - loss: 0.0934 - accuracy: 0.9711 - val_loss: 0.7963 - val_accuracy: 0.8253\n",
            "Epoch 375/700\n",
            "93/93 [==============================] - 1s 16ms/step - loss: 0.0969 - accuracy: 0.9671 - val_loss: 0.7498 - val_accuracy: 0.8072\n",
            "Epoch 376/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 0.0850 - accuracy: 0.9698 - val_loss: 0.7957 - val_accuracy: 0.8133\n",
            "Epoch 377/700\n",
            "93/93 [==============================] - 1s 16ms/step - loss: 0.0798 - accuracy: 0.9691 - val_loss: 0.8692 - val_accuracy: 0.8012\n",
            "Epoch 378/700\n",
            "93/93 [==============================] - 2s 16ms/step - loss: 0.0886 - accuracy: 0.9731 - val_loss: 0.8631 - val_accuracy: 0.8012\n",
            "Epoch 379/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 0.0853 - accuracy: 0.9745 - val_loss: 0.7937 - val_accuracy: 0.8072\n",
            "Epoch 380/700\n",
            "93/93 [==============================] - 2s 16ms/step - loss: 0.0685 - accuracy: 0.9772 - val_loss: 0.8719 - val_accuracy: 0.8012\n",
            "Epoch 381/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 0.0814 - accuracy: 0.9698 - val_loss: 0.8010 - val_accuracy: 0.8012\n",
            "Epoch 382/700\n",
            "93/93 [==============================] - 1s 16ms/step - loss: 0.0896 - accuracy: 0.9644 - val_loss: 0.8304 - val_accuracy: 0.8253\n",
            "Epoch 383/700\n",
            "93/93 [==============================] - 2s 16ms/step - loss: 0.0817 - accuracy: 0.9698 - val_loss: 0.7977 - val_accuracy: 0.8012\n",
            "Epoch 384/700\n",
            "93/93 [==============================] - 1s 16ms/step - loss: 0.0997 - accuracy: 0.9617 - val_loss: 0.8150 - val_accuracy: 0.7952\n",
            "Epoch 385/700\n",
            "93/93 [==============================] - 1s 16ms/step - loss: 0.0946 - accuracy: 0.9651 - val_loss: 0.7885 - val_accuracy: 0.8012\n",
            "Epoch 386/700\n",
            "93/93 [==============================] - 2s 16ms/step - loss: 0.0827 - accuracy: 0.9718 - val_loss: 0.7860 - val_accuracy: 0.7952\n",
            "Epoch 387/700\n",
            "93/93 [==============================] - 2s 16ms/step - loss: 0.0768 - accuracy: 0.9758 - val_loss: 0.7959 - val_accuracy: 0.8253\n",
            "Epoch 388/700\n",
            "93/93 [==============================] - 1s 16ms/step - loss: 0.0808 - accuracy: 0.9745 - val_loss: 0.8378 - val_accuracy: 0.8072\n",
            "Epoch 389/700\n",
            "93/93 [==============================] - 1s 16ms/step - loss: 0.0838 - accuracy: 0.9684 - val_loss: 0.7718 - val_accuracy: 0.8133\n",
            "Epoch 390/700\n",
            "93/93 [==============================] - 2s 16ms/step - loss: 0.0746 - accuracy: 0.9751 - val_loss: 0.7225 - val_accuracy: 0.8373\n",
            "Epoch 391/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 0.0835 - accuracy: 0.9758 - val_loss: 0.7740 - val_accuracy: 0.8193\n",
            "Epoch 392/700\n",
            "93/93 [==============================] - 1s 16ms/step - loss: 0.0872 - accuracy: 0.9711 - val_loss: 0.8749 - val_accuracy: 0.7952\n",
            "Epoch 393/700\n",
            "93/93 [==============================] - 2s 16ms/step - loss: 0.0940 - accuracy: 0.9657 - val_loss: 0.8529 - val_accuracy: 0.8193\n",
            "Epoch 394/700\n",
            "93/93 [==============================] - 2s 17ms/step - loss: 0.0830 - accuracy: 0.9718 - val_loss: 0.8257 - val_accuracy: 0.8072\n",
            "Epoch 395/700\n",
            "93/93 [==============================] - 1s 16ms/step - loss: 0.0798 - accuracy: 0.9765 - val_loss: 0.8140 - val_accuracy: 0.8012\n",
            "Epoch 396/700\n",
            "93/93 [==============================] - 2s 16ms/step - loss: 0.0834 - accuracy: 0.9724 - val_loss: 0.8485 - val_accuracy: 0.7771\n",
            "Epoch 397/700\n",
            "93/93 [==============================] - 1s 16ms/step - loss: 0.0934 - accuracy: 0.9684 - val_loss: 0.8728 - val_accuracy: 0.8193\n",
            "Epoch 398/700\n",
            "93/93 [==============================] - 2s 16ms/step - loss: 0.0725 - accuracy: 0.9751 - val_loss: 0.8282 - val_accuracy: 0.8373\n",
            "Epoch 399/700\n",
            "93/93 [==============================] - 1s 16ms/step - loss: 0.0868 - accuracy: 0.9684 - val_loss: 0.7790 - val_accuracy: 0.8012\n",
            "Epoch 400/700\n",
            "93/93 [==============================] - 1s 16ms/step - loss: 0.0625 - accuracy: 0.9798 - val_loss: 0.8302 - val_accuracy: 0.7952\n",
            "Epoch 401/700\n",
            "93/93 [==============================] - 1s 16ms/step - loss: 0.0779 - accuracy: 0.9738 - val_loss: 0.7858 - val_accuracy: 0.8253\n",
            "Epoch 402/700\n",
            "93/93 [==============================] - 1s 16ms/step - loss: 0.0657 - accuracy: 0.9785 - val_loss: 0.9027 - val_accuracy: 0.7771\n",
            "Epoch 403/700\n",
            "93/93 [==============================] - 2s 16ms/step - loss: 0.0815 - accuracy: 0.9724 - val_loss: 0.9518 - val_accuracy: 0.7831\n",
            "Epoch 404/700\n",
            "93/93 [==============================] - 1s 16ms/step - loss: 0.0866 - accuracy: 0.9704 - val_loss: 0.8128 - val_accuracy: 0.7831\n",
            "Epoch 405/700\n",
            "93/93 [==============================] - 2s 16ms/step - loss: 0.0824 - accuracy: 0.9758 - val_loss: 0.8436 - val_accuracy: 0.8253\n",
            "Epoch 406/700\n",
            "93/93 [==============================] - 1s 16ms/step - loss: 0.0796 - accuracy: 0.9704 - val_loss: 0.8376 - val_accuracy: 0.8133\n",
            "Epoch 407/700\n",
            "93/93 [==============================] - 1s 16ms/step - loss: 0.0694 - accuracy: 0.9745 - val_loss: 0.8491 - val_accuracy: 0.8072\n",
            "Epoch 408/700\n",
            "93/93 [==============================] - 1s 16ms/step - loss: 0.0765 - accuracy: 0.9778 - val_loss: 0.8631 - val_accuracy: 0.8253\n",
            "Epoch 409/700\n",
            "93/93 [==============================] - 1s 16ms/step - loss: 0.0791 - accuracy: 0.9698 - val_loss: 0.7552 - val_accuracy: 0.8253\n",
            "Epoch 410/700\n",
            "93/93 [==============================] - 2s 16ms/step - loss: 0.0806 - accuracy: 0.9745 - val_loss: 0.8443 - val_accuracy: 0.8133\n",
            "Epoch 411/700\n",
            "93/93 [==============================] - 1s 16ms/step - loss: 0.0809 - accuracy: 0.9671 - val_loss: 0.8377 - val_accuracy: 0.7892\n",
            "Epoch 412/700\n",
            "93/93 [==============================] - 2s 16ms/step - loss: 0.0757 - accuracy: 0.9758 - val_loss: 0.8175 - val_accuracy: 0.8012\n",
            "Epoch 413/700\n",
            "93/93 [==============================] - 1s 16ms/step - loss: 0.0686 - accuracy: 0.9792 - val_loss: 0.8732 - val_accuracy: 0.8133\n",
            "Epoch 414/700\n",
            "93/93 [==============================] - 2s 16ms/step - loss: 0.0945 - accuracy: 0.9644 - val_loss: 0.8178 - val_accuracy: 0.8012\n",
            "Epoch 415/700\n",
            "93/93 [==============================] - 2s 16ms/step - loss: 0.0691 - accuracy: 0.9778 - val_loss: 0.8809 - val_accuracy: 0.7952\n",
            "Epoch 416/700\n",
            "93/93 [==============================] - 1s 16ms/step - loss: 0.0823 - accuracy: 0.9751 - val_loss: 0.8895 - val_accuracy: 0.8313\n",
            "Epoch 417/700\n",
            "93/93 [==============================] - 1s 16ms/step - loss: 0.0655 - accuracy: 0.9778 - val_loss: 0.8102 - val_accuracy: 0.8313\n",
            "Epoch 418/700\n",
            "93/93 [==============================] - 1s 16ms/step - loss: 0.0851 - accuracy: 0.9738 - val_loss: 0.7489 - val_accuracy: 0.8434\n",
            "Epoch 419/700\n",
            "93/93 [==============================] - 1s 16ms/step - loss: 0.0599 - accuracy: 0.9798 - val_loss: 0.8334 - val_accuracy: 0.8193\n",
            "Epoch 420/700\n",
            "93/93 [==============================] - 1s 16ms/step - loss: 0.0835 - accuracy: 0.9731 - val_loss: 0.8185 - val_accuracy: 0.8072\n",
            "Epoch 421/700\n",
            "93/93 [==============================] - 1s 16ms/step - loss: 0.0706 - accuracy: 0.9751 - val_loss: 0.8645 - val_accuracy: 0.8012\n",
            "Epoch 422/700\n",
            "93/93 [==============================] - 1s 16ms/step - loss: 0.0980 - accuracy: 0.9677 - val_loss: 0.9507 - val_accuracy: 0.7831\n",
            "Epoch 423/700\n",
            "93/93 [==============================] - 1s 16ms/step - loss: 0.0727 - accuracy: 0.9731 - val_loss: 0.7916 - val_accuracy: 0.8072\n",
            "Epoch 424/700\n",
            "93/93 [==============================] - 2s 16ms/step - loss: 0.0640 - accuracy: 0.9798 - val_loss: 0.8532 - val_accuracy: 0.8072\n",
            "Epoch 425/700\n",
            "93/93 [==============================] - 1s 16ms/step - loss: 0.0737 - accuracy: 0.9765 - val_loss: 0.9211 - val_accuracy: 0.8133\n",
            "Epoch 426/700\n",
            "93/93 [==============================] - 2s 16ms/step - loss: 0.0675 - accuracy: 0.9731 - val_loss: 0.8508 - val_accuracy: 0.8193\n",
            "Epoch 427/700\n",
            "93/93 [==============================] - 1s 16ms/step - loss: 0.0760 - accuracy: 0.9745 - val_loss: 0.8869 - val_accuracy: 0.8012\n",
            "Epoch 428/700\n",
            "93/93 [==============================] - 2s 16ms/step - loss: 0.0669 - accuracy: 0.9724 - val_loss: 0.9019 - val_accuracy: 0.7952\n",
            "Epoch 429/700\n",
            "93/93 [==============================] - 2s 16ms/step - loss: 0.0697 - accuracy: 0.9745 - val_loss: 0.8768 - val_accuracy: 0.7952\n",
            "Epoch 430/700\n",
            "93/93 [==============================] - 1s 16ms/step - loss: 0.0817 - accuracy: 0.9745 - val_loss: 0.8418 - val_accuracy: 0.8494\n",
            "Epoch 431/700\n",
            "93/93 [==============================] - 2s 16ms/step - loss: 0.0884 - accuracy: 0.9704 - val_loss: 0.9190 - val_accuracy: 0.8253\n",
            "Epoch 432/700\n",
            "93/93 [==============================] - 1s 16ms/step - loss: 0.0879 - accuracy: 0.9664 - val_loss: 0.8355 - val_accuracy: 0.8133\n",
            "Epoch 433/700\n",
            "93/93 [==============================] - 2s 16ms/step - loss: 0.0766 - accuracy: 0.9724 - val_loss: 0.8750 - val_accuracy: 0.8373\n",
            "Epoch 434/700\n",
            "93/93 [==============================] - 1s 16ms/step - loss: 0.0805 - accuracy: 0.9724 - val_loss: 0.9963 - val_accuracy: 0.7711\n",
            "Epoch 435/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 0.0781 - accuracy: 0.9724 - val_loss: 0.8673 - val_accuracy: 0.8133\n",
            "Epoch 436/700\n",
            "93/93 [==============================] - 1s 16ms/step - loss: 0.0756 - accuracy: 0.9731 - val_loss: 1.0134 - val_accuracy: 0.7892\n",
            "Epoch 437/700\n",
            "93/93 [==============================] - 1s 16ms/step - loss: 0.0762 - accuracy: 0.9778 - val_loss: 0.8623 - val_accuracy: 0.8072\n",
            "Epoch 438/700\n",
            "93/93 [==============================] - 1s 16ms/step - loss: 0.0747 - accuracy: 0.9718 - val_loss: 0.8266 - val_accuracy: 0.7952\n",
            "Epoch 439/700\n",
            "93/93 [==============================] - 1s 16ms/step - loss: 0.0726 - accuracy: 0.9765 - val_loss: 0.8161 - val_accuracy: 0.8133\n",
            "Epoch 440/700\n",
            "93/93 [==============================] - 2s 16ms/step - loss: 0.0760 - accuracy: 0.9745 - val_loss: 0.7532 - val_accuracy: 0.8373\n",
            "Epoch 441/700\n",
            "93/93 [==============================] - 1s 16ms/step - loss: 0.0699 - accuracy: 0.9778 - val_loss: 0.7647 - val_accuracy: 0.8012\n",
            "Epoch 442/700\n",
            "93/93 [==============================] - 1s 16ms/step - loss: 0.0680 - accuracy: 0.9772 - val_loss: 0.8881 - val_accuracy: 0.8072\n",
            "Epoch 443/700\n",
            "93/93 [==============================] - 1s 16ms/step - loss: 0.0740 - accuracy: 0.9758 - val_loss: 0.8449 - val_accuracy: 0.7892\n",
            "Epoch 444/700\n",
            "93/93 [==============================] - 2s 17ms/step - loss: 0.0610 - accuracy: 0.9778 - val_loss: 0.8126 - val_accuracy: 0.8133\n",
            "Epoch 445/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 0.0767 - accuracy: 0.9738 - val_loss: 0.7914 - val_accuracy: 0.8133\n",
            "Epoch 446/700\n",
            "93/93 [==============================] - 1s 16ms/step - loss: 0.0679 - accuracy: 0.9751 - val_loss: 0.8284 - val_accuracy: 0.8072\n",
            "Epoch 447/700\n",
            "93/93 [==============================] - 1s 16ms/step - loss: 0.0716 - accuracy: 0.9758 - val_loss: 0.9057 - val_accuracy: 0.7952\n",
            "Epoch 448/700\n",
            "93/93 [==============================] - 2s 16ms/step - loss: 0.0702 - accuracy: 0.9745 - val_loss: 0.8202 - val_accuracy: 0.8373\n",
            "Epoch 449/700\n",
            "93/93 [==============================] - 2s 16ms/step - loss: 0.0631 - accuracy: 0.9778 - val_loss: 0.8598 - val_accuracy: 0.8434\n",
            "Epoch 450/700\n",
            "93/93 [==============================] - 2s 16ms/step - loss: 0.0796 - accuracy: 0.9731 - val_loss: 0.8387 - val_accuracy: 0.8434\n",
            "Epoch 451/700\n",
            "93/93 [==============================] - 1s 16ms/step - loss: 0.0642 - accuracy: 0.9785 - val_loss: 0.9044 - val_accuracy: 0.8434\n",
            "Epoch 452/700\n",
            "93/93 [==============================] - 1s 16ms/step - loss: 0.0828 - accuracy: 0.9731 - val_loss: 0.7772 - val_accuracy: 0.8313\n",
            "Epoch 453/700\n",
            "93/93 [==============================] - 1s 16ms/step - loss: 0.0589 - accuracy: 0.9785 - val_loss: 0.8850 - val_accuracy: 0.8253\n",
            "Epoch 454/700\n",
            "93/93 [==============================] - 1s 16ms/step - loss: 0.0895 - accuracy: 0.9704 - val_loss: 0.7933 - val_accuracy: 0.8434\n",
            "Epoch 455/700\n",
            "93/93 [==============================] - 2s 16ms/step - loss: 0.0676 - accuracy: 0.9738 - val_loss: 0.9936 - val_accuracy: 0.7892\n",
            "Epoch 456/700\n",
            "93/93 [==============================] - 1s 16ms/step - loss: 0.0622 - accuracy: 0.9785 - val_loss: 0.8560 - val_accuracy: 0.8072\n",
            "Epoch 457/700\n",
            "93/93 [==============================] - 1s 16ms/step - loss: 0.0706 - accuracy: 0.9785 - val_loss: 0.9261 - val_accuracy: 0.8434\n",
            "Epoch 458/700\n",
            "93/93 [==============================] - 1s 16ms/step - loss: 0.0734 - accuracy: 0.9731 - val_loss: 0.9125 - val_accuracy: 0.8133\n",
            "Epoch 459/700\n",
            "93/93 [==============================] - 2s 16ms/step - loss: 0.0547 - accuracy: 0.9832 - val_loss: 0.9699 - val_accuracy: 0.7892\n",
            "Epoch 460/700\n",
            "93/93 [==============================] - 1s 16ms/step - loss: 0.0892 - accuracy: 0.9711 - val_loss: 0.8244 - val_accuracy: 0.8253\n",
            "Epoch 461/700\n",
            "93/93 [==============================] - 2s 16ms/step - loss: 0.0581 - accuracy: 0.9765 - val_loss: 0.8205 - val_accuracy: 0.8133\n",
            "Epoch 462/700\n",
            "93/93 [==============================] - 2s 16ms/step - loss: 0.0634 - accuracy: 0.9758 - val_loss: 0.8574 - val_accuracy: 0.8072\n",
            "Epoch 463/700\n",
            "93/93 [==============================] - 2s 16ms/step - loss: 0.0573 - accuracy: 0.9792 - val_loss: 0.8831 - val_accuracy: 0.8373\n",
            "Epoch 464/700\n",
            "93/93 [==============================] - 2s 17ms/step - loss: 0.0549 - accuracy: 0.9798 - val_loss: 0.9033 - val_accuracy: 0.8072\n",
            "Epoch 465/700\n",
            "93/93 [==============================] - 1s 16ms/step - loss: 0.0619 - accuracy: 0.9798 - val_loss: 0.8565 - val_accuracy: 0.8133\n",
            "Epoch 466/700\n",
            "93/93 [==============================] - 2s 16ms/step - loss: 0.0706 - accuracy: 0.9758 - val_loss: 0.9653 - val_accuracy: 0.8253\n",
            "Epoch 467/700\n",
            "93/93 [==============================] - 2s 16ms/step - loss: 0.0673 - accuracy: 0.9772 - val_loss: 0.9136 - val_accuracy: 0.8012\n",
            "Epoch 468/700\n",
            "93/93 [==============================] - 1s 16ms/step - loss: 0.0579 - accuracy: 0.9819 - val_loss: 0.9541 - val_accuracy: 0.8012\n",
            "Epoch 469/700\n",
            "93/93 [==============================] - 1s 16ms/step - loss: 0.0642 - accuracy: 0.9805 - val_loss: 0.9643 - val_accuracy: 0.7771\n",
            "Epoch 470/700\n",
            "93/93 [==============================] - 1s 16ms/step - loss: 0.0756 - accuracy: 0.9805 - val_loss: 0.8886 - val_accuracy: 0.8193\n",
            "Epoch 471/700\n",
            "93/93 [==============================] - 2s 16ms/step - loss: 0.0611 - accuracy: 0.9772 - val_loss: 0.9477 - val_accuracy: 0.8193\n",
            "Epoch 472/700\n",
            "93/93 [==============================] - 2s 16ms/step - loss: 0.0745 - accuracy: 0.9745 - val_loss: 0.9007 - val_accuracy: 0.7952\n",
            "Epoch 473/700\n",
            "93/93 [==============================] - 1s 16ms/step - loss: 0.0547 - accuracy: 0.9798 - val_loss: 0.8886 - val_accuracy: 0.8072\n",
            "Epoch 474/700\n",
            "93/93 [==============================] - 2s 17ms/step - loss: 0.0556 - accuracy: 0.9798 - val_loss: 0.9800 - val_accuracy: 0.8133\n",
            "Epoch 475/700\n",
            "93/93 [==============================] - 2s 18ms/step - loss: 0.0722 - accuracy: 0.9731 - val_loss: 0.8719 - val_accuracy: 0.8193\n",
            "Epoch 476/700\n",
            "93/93 [==============================] - 2s 17ms/step - loss: 0.0724 - accuracy: 0.9758 - val_loss: 0.9453 - val_accuracy: 0.8373\n",
            "Epoch 477/700\n",
            "93/93 [==============================] - 2s 16ms/step - loss: 0.0714 - accuracy: 0.9792 - val_loss: 0.9577 - val_accuracy: 0.8012\n",
            "Epoch 478/700\n",
            "93/93 [==============================] - 2s 16ms/step - loss: 0.0662 - accuracy: 0.9751 - val_loss: 0.8969 - val_accuracy: 0.8133\n",
            "Epoch 479/700\n",
            "93/93 [==============================] - 2s 17ms/step - loss: 0.0633 - accuracy: 0.9785 - val_loss: 1.0775 - val_accuracy: 0.7952\n",
            "Epoch 480/700\n",
            "93/93 [==============================] - 2s 17ms/step - loss: 0.0542 - accuracy: 0.9792 - val_loss: 0.9566 - val_accuracy: 0.8133\n",
            "Epoch 481/700\n",
            "93/93 [==============================] - 1s 16ms/step - loss: 0.0755 - accuracy: 0.9751 - val_loss: 0.9529 - val_accuracy: 0.8012\n",
            "Epoch 482/700\n",
            "93/93 [==============================] - 2s 17ms/step - loss: 0.0571 - accuracy: 0.9792 - val_loss: 0.9546 - val_accuracy: 0.8012\n",
            "Epoch 483/700\n",
            "93/93 [==============================] - 2s 18ms/step - loss: 0.0679 - accuracy: 0.9758 - val_loss: 0.8770 - val_accuracy: 0.8133\n",
            "Epoch 484/700\n",
            "93/93 [==============================] - 2s 17ms/step - loss: 0.0507 - accuracy: 0.9845 - val_loss: 0.9198 - val_accuracy: 0.8253\n",
            "Epoch 485/700\n",
            "93/93 [==============================] - 1s 16ms/step - loss: 0.0523 - accuracy: 0.9839 - val_loss: 0.9507 - val_accuracy: 0.8012\n",
            "Epoch 486/700\n",
            "93/93 [==============================] - 2s 18ms/step - loss: 0.0553 - accuracy: 0.9792 - val_loss: 0.9161 - val_accuracy: 0.8253\n",
            "Epoch 487/700\n",
            "93/93 [==============================] - 2s 18ms/step - loss: 0.0528 - accuracy: 0.9839 - val_loss: 1.0181 - val_accuracy: 0.8253\n",
            "Epoch 488/700\n",
            "93/93 [==============================] - 2s 18ms/step - loss: 0.0533 - accuracy: 0.9758 - val_loss: 0.9708 - val_accuracy: 0.7771\n",
            "Epoch 489/700\n",
            "93/93 [==============================] - 2s 18ms/step - loss: 0.0680 - accuracy: 0.9724 - val_loss: 1.0012 - val_accuracy: 0.8253\n",
            "Epoch 490/700\n",
            "93/93 [==============================] - 2s 18ms/step - loss: 0.0505 - accuracy: 0.9819 - val_loss: 0.9447 - val_accuracy: 0.8434\n",
            "Epoch 491/700\n",
            "93/93 [==============================] - 2s 17ms/step - loss: 0.0579 - accuracy: 0.9785 - val_loss: 0.9485 - val_accuracy: 0.8193\n",
            "Epoch 492/700\n",
            "93/93 [==============================] - 2s 17ms/step - loss: 0.0581 - accuracy: 0.9792 - val_loss: 1.0086 - val_accuracy: 0.8133\n",
            "Epoch 493/700\n",
            "93/93 [==============================] - 2s 16ms/step - loss: 0.0669 - accuracy: 0.9765 - val_loss: 0.9812 - val_accuracy: 0.8133\n",
            "Epoch 494/700\n",
            "93/93 [==============================] - 1s 16ms/step - loss: 0.0575 - accuracy: 0.9805 - val_loss: 0.9491 - val_accuracy: 0.8193\n",
            "Epoch 495/700\n",
            "93/93 [==============================] - 1s 16ms/step - loss: 0.0624 - accuracy: 0.9812 - val_loss: 0.9815 - val_accuracy: 0.8072\n",
            "Epoch 496/700\n",
            "93/93 [==============================] - 2s 17ms/step - loss: 0.0517 - accuracy: 0.9852 - val_loss: 1.0306 - val_accuracy: 0.8133\n",
            "Epoch 497/700\n",
            "93/93 [==============================] - 1s 16ms/step - loss: 0.0585 - accuracy: 0.9798 - val_loss: 0.9259 - val_accuracy: 0.8072\n",
            "Epoch 498/700\n",
            "93/93 [==============================] - 2s 18ms/step - loss: 0.0630 - accuracy: 0.9798 - val_loss: 0.9291 - val_accuracy: 0.7952\n",
            "Epoch 499/700\n",
            "93/93 [==============================] - 2s 17ms/step - loss: 0.0601 - accuracy: 0.9785 - val_loss: 0.9006 - val_accuracy: 0.8133\n",
            "Epoch 500/700\n",
            "93/93 [==============================] - 2s 18ms/step - loss: 0.0620 - accuracy: 0.9758 - val_loss: 0.9437 - val_accuracy: 0.8313\n",
            "Epoch 501/700\n",
            "93/93 [==============================] - 2s 17ms/step - loss: 0.0575 - accuracy: 0.9792 - val_loss: 1.0677 - val_accuracy: 0.7892\n",
            "Epoch 502/700\n",
            "93/93 [==============================] - 2s 17ms/step - loss: 0.0655 - accuracy: 0.9772 - val_loss: 1.0814 - val_accuracy: 0.8012\n",
            "Epoch 503/700\n",
            "93/93 [==============================] - 2s 18ms/step - loss: 0.0914 - accuracy: 0.9751 - val_loss: 0.9744 - val_accuracy: 0.8133\n",
            "Epoch 504/700\n",
            "93/93 [==============================] - 1s 16ms/step - loss: 0.0562 - accuracy: 0.9785 - val_loss: 1.0529 - val_accuracy: 0.8253\n",
            "Epoch 505/700\n",
            "93/93 [==============================] - 2s 17ms/step - loss: 0.0541 - accuracy: 0.9778 - val_loss: 1.1256 - val_accuracy: 0.8193\n",
            "Epoch 506/700\n",
            "93/93 [==============================] - 2s 17ms/step - loss: 0.0456 - accuracy: 0.9832 - val_loss: 1.1401 - val_accuracy: 0.8133\n",
            "Epoch 507/700\n",
            "93/93 [==============================] - 1s 15ms/step - loss: 0.0688 - accuracy: 0.9778 - val_loss: 1.0482 - val_accuracy: 0.8072\n",
            "Epoch 508/700\n",
            "93/93 [==============================] - 2s 17ms/step - loss: 0.0817 - accuracy: 0.9758 - val_loss: 1.0473 - val_accuracy: 0.8072\n",
            "Epoch 509/700\n",
            "93/93 [==============================] - 2s 17ms/step - loss: 0.0529 - accuracy: 0.9839 - val_loss: 1.0098 - val_accuracy: 0.8253\n",
            "Epoch 510/700\n",
            "93/93 [==============================] - 2s 18ms/step - loss: 0.0617 - accuracy: 0.9785 - val_loss: 0.9268 - val_accuracy: 0.8313\n",
            "Epoch 511/700\n",
            "93/93 [==============================] - 1s 16ms/step - loss: 0.0574 - accuracy: 0.9812 - val_loss: 0.9628 - val_accuracy: 0.8193\n",
            "Epoch 512/700\n",
            "93/93 [==============================] - 2s 17ms/step - loss: 0.0453 - accuracy: 0.9839 - val_loss: 0.9770 - val_accuracy: 0.8253\n",
            "Epoch 513/700\n",
            "93/93 [==============================] - 2s 16ms/step - loss: 0.0393 - accuracy: 0.9892 - val_loss: 0.9890 - val_accuracy: 0.8133\n",
            "Epoch 514/700\n",
            "93/93 [==============================] - 2s 17ms/step - loss: 0.0680 - accuracy: 0.9778 - val_loss: 1.1036 - val_accuracy: 0.7651\n",
            "Epoch 515/700\n",
            "93/93 [==============================] - 2s 18ms/step - loss: 0.0674 - accuracy: 0.9825 - val_loss: 1.0124 - val_accuracy: 0.8133\n",
            "Epoch 516/700\n",
            "93/93 [==============================] - 1s 16ms/step - loss: 0.0552 - accuracy: 0.9772 - val_loss: 1.0176 - val_accuracy: 0.8012\n",
            "Epoch 517/700\n",
            "93/93 [==============================] - 2s 17ms/step - loss: 0.0708 - accuracy: 0.9772 - val_loss: 1.0167 - val_accuracy: 0.8133\n",
            "Epoch 518/700\n",
            "93/93 [==============================] - 2s 17ms/step - loss: 0.0600 - accuracy: 0.9812 - val_loss: 0.9664 - val_accuracy: 0.8313\n",
            "Epoch 519/700\n",
            "93/93 [==============================] - 2s 17ms/step - loss: 0.0611 - accuracy: 0.9785 - val_loss: 0.9847 - val_accuracy: 0.8012\n",
            "Epoch 520/700\n",
            "93/93 [==============================] - 2s 18ms/step - loss: 0.0505 - accuracy: 0.9839 - val_loss: 1.0631 - val_accuracy: 0.8133\n",
            "Epoch 521/700\n",
            "93/93 [==============================] - 2s 17ms/step - loss: 0.0628 - accuracy: 0.9798 - val_loss: 0.9543 - val_accuracy: 0.8253\n",
            "Epoch 522/700\n",
            "93/93 [==============================] - 2s 17ms/step - loss: 0.0500 - accuracy: 0.9812 - val_loss: 1.0636 - val_accuracy: 0.8133\n",
            "Epoch 523/700\n",
            "93/93 [==============================] - 2s 18ms/step - loss: 0.0646 - accuracy: 0.9792 - val_loss: 0.9964 - val_accuracy: 0.8373\n",
            "Epoch 524/700\n",
            "93/93 [==============================] - 2s 18ms/step - loss: 0.0525 - accuracy: 0.9792 - val_loss: 0.9946 - val_accuracy: 0.8313\n",
            "Epoch 525/700\n",
            "93/93 [==============================] - 2s 17ms/step - loss: 0.0586 - accuracy: 0.9785 - val_loss: 0.9992 - val_accuracy: 0.8133\n",
            "Epoch 526/700\n",
            "93/93 [==============================] - 2s 16ms/step - loss: 0.0805 - accuracy: 0.9738 - val_loss: 0.9577 - val_accuracy: 0.8313\n",
            "Epoch 527/700\n",
            "93/93 [==============================] - 2s 18ms/step - loss: 0.0575 - accuracy: 0.9798 - val_loss: 1.0961 - val_accuracy: 0.8012\n",
            "Epoch 528/700\n",
            "93/93 [==============================] - 2s 17ms/step - loss: 0.0557 - accuracy: 0.9758 - val_loss: 1.0646 - val_accuracy: 0.8072\n",
            "Epoch 529/700\n",
            "93/93 [==============================] - 2s 16ms/step - loss: 0.0559 - accuracy: 0.9832 - val_loss: 1.0512 - val_accuracy: 0.8193\n",
            "Epoch 530/700\n",
            "93/93 [==============================] - 2s 16ms/step - loss: 0.0527 - accuracy: 0.9812 - val_loss: 1.0443 - val_accuracy: 0.8193\n",
            "Epoch 531/700\n",
            "93/93 [==============================] - 2s 18ms/step - loss: 0.0582 - accuracy: 0.9825 - val_loss: 1.0711 - val_accuracy: 0.7892\n",
            "Epoch 532/700\n",
            "93/93 [==============================] - 2s 17ms/step - loss: 0.0446 - accuracy: 0.9845 - val_loss: 0.9971 - val_accuracy: 0.8072\n",
            "Epoch 533/700\n",
            "93/93 [==============================] - 2s 18ms/step - loss: 0.0577 - accuracy: 0.9792 - val_loss: 1.1002 - val_accuracy: 0.8193\n",
            "Epoch 534/700\n",
            "93/93 [==============================] - 2s 17ms/step - loss: 0.0567 - accuracy: 0.9819 - val_loss: 1.0254 - val_accuracy: 0.8072\n",
            "Epoch 535/700\n",
            "93/93 [==============================] - 2s 18ms/step - loss: 0.0474 - accuracy: 0.9859 - val_loss: 0.9527 - val_accuracy: 0.8012\n",
            "Epoch 536/700\n",
            "93/93 [==============================] - 2s 17ms/step - loss: 0.0577 - accuracy: 0.9832 - val_loss: 1.0576 - val_accuracy: 0.7892\n",
            "Epoch 537/700\n",
            "93/93 [==============================] - 2s 17ms/step - loss: 0.0603 - accuracy: 0.9839 - val_loss: 1.0304 - val_accuracy: 0.8373\n",
            "Epoch 538/700\n",
            "93/93 [==============================] - 2s 17ms/step - loss: 0.0663 - accuracy: 0.9772 - val_loss: 0.9229 - val_accuracy: 0.8072\n",
            "Epoch 539/700\n",
            "93/93 [==============================] - 2s 17ms/step - loss: 0.0524 - accuracy: 0.9832 - val_loss: 0.9717 - val_accuracy: 0.7952\n",
            "Epoch 540/700\n",
            "93/93 [==============================] - 2s 17ms/step - loss: 0.0596 - accuracy: 0.9819 - val_loss: 1.0317 - val_accuracy: 0.8253\n",
            "Epoch 541/700\n",
            "93/93 [==============================] - 2s 18ms/step - loss: 0.0634 - accuracy: 0.9758 - val_loss: 1.0561 - val_accuracy: 0.8012\n",
            "Epoch 542/700\n",
            "93/93 [==============================] - 2s 16ms/step - loss: 0.0602 - accuracy: 0.9751 - val_loss: 1.0211 - val_accuracy: 0.8072\n",
            "Epoch 543/700\n",
            "93/93 [==============================] - 1s 16ms/step - loss: 0.0679 - accuracy: 0.9819 - val_loss: 0.9862 - val_accuracy: 0.8434\n",
            "Epoch 544/700\n",
            "93/93 [==============================] - 2s 17ms/step - loss: 0.0663 - accuracy: 0.9792 - val_loss: 1.1322 - val_accuracy: 0.8012\n",
            "Epoch 545/700\n",
            "93/93 [==============================] - 2s 18ms/step - loss: 0.0554 - accuracy: 0.9819 - val_loss: 0.9650 - val_accuracy: 0.8373\n",
            "Epoch 546/700\n",
            "93/93 [==============================] - 2s 19ms/step - loss: 0.0483 - accuracy: 0.9839 - val_loss: 1.0217 - val_accuracy: 0.8193\n",
            "Epoch 547/700\n",
            "93/93 [==============================] - 2s 18ms/step - loss: 0.0693 - accuracy: 0.9778 - val_loss: 1.0103 - val_accuracy: 0.8494\n",
            "Epoch 548/700\n",
            "93/93 [==============================] - 2s 18ms/step - loss: 0.0545 - accuracy: 0.9845 - val_loss: 0.9449 - val_accuracy: 0.8313\n",
            "Epoch 549/700\n",
            "93/93 [==============================] - 2s 17ms/step - loss: 0.0530 - accuracy: 0.9839 - val_loss: 0.9949 - val_accuracy: 0.7952\n",
            "Epoch 550/700\n",
            "93/93 [==============================] - 2s 19ms/step - loss: 0.0575 - accuracy: 0.9765 - val_loss: 0.9138 - val_accuracy: 0.8193\n",
            "Epoch 551/700\n",
            "93/93 [==============================] - 2s 17ms/step - loss: 0.0624 - accuracy: 0.9772 - val_loss: 1.0048 - val_accuracy: 0.8373\n",
            "Epoch 552/700\n",
            "93/93 [==============================] - 2s 18ms/step - loss: 0.0378 - accuracy: 0.9899 - val_loss: 1.0509 - val_accuracy: 0.7952\n",
            "Epoch 553/700\n",
            "93/93 [==============================] - 2s 17ms/step - loss: 0.0474 - accuracy: 0.9866 - val_loss: 1.1329 - val_accuracy: 0.8133\n",
            "Epoch 554/700\n",
            "93/93 [==============================] - 2s 16ms/step - loss: 0.0522 - accuracy: 0.9825 - val_loss: 1.0448 - val_accuracy: 0.8012\n",
            "Epoch 555/700\n",
            "93/93 [==============================] - 2s 17ms/step - loss: 0.0323 - accuracy: 0.9899 - val_loss: 0.9510 - val_accuracy: 0.8072\n",
            "Epoch 556/700\n",
            "93/93 [==============================] - 2s 16ms/step - loss: 0.0571 - accuracy: 0.9785 - val_loss: 0.9055 - val_accuracy: 0.8313\n",
            "Epoch 557/700\n",
            "93/93 [==============================] - 1s 16ms/step - loss: 0.0532 - accuracy: 0.9832 - val_loss: 0.9613 - val_accuracy: 0.8133\n",
            "Epoch 558/700\n",
            "93/93 [==============================] - 2s 16ms/step - loss: 0.0588 - accuracy: 0.9819 - val_loss: 0.9328 - val_accuracy: 0.8133\n",
            "Epoch 559/700\n",
            "93/93 [==============================] - 2s 16ms/step - loss: 0.0497 - accuracy: 0.9845 - val_loss: 0.9619 - val_accuracy: 0.8434\n",
            "Epoch 560/700\n",
            "93/93 [==============================] - 2s 17ms/step - loss: 0.0612 - accuracy: 0.9792 - val_loss: 0.9243 - val_accuracy: 0.8072\n",
            "Epoch 561/700\n",
            "93/93 [==============================] - 2s 17ms/step - loss: 0.0540 - accuracy: 0.9832 - val_loss: 1.0079 - val_accuracy: 0.8193\n",
            "Epoch 562/700\n",
            "93/93 [==============================] - 2s 17ms/step - loss: 0.0519 - accuracy: 0.9839 - val_loss: 0.9375 - val_accuracy: 0.8133\n",
            "Epoch 563/700\n",
            "93/93 [==============================] - 2s 17ms/step - loss: 0.0498 - accuracy: 0.9792 - val_loss: 0.9437 - val_accuracy: 0.8313\n",
            "Epoch 564/700\n",
            "93/93 [==============================] - 2s 18ms/step - loss: 0.0462 - accuracy: 0.9845 - val_loss: 0.9704 - val_accuracy: 0.8313\n",
            "Epoch 565/700\n",
            "93/93 [==============================] - 2s 17ms/step - loss: 0.0649 - accuracy: 0.9819 - val_loss: 0.9258 - val_accuracy: 0.8494\n",
            "Epoch 566/700\n",
            "93/93 [==============================] - 2s 17ms/step - loss: 0.0510 - accuracy: 0.9785 - val_loss: 0.9750 - val_accuracy: 0.7952\n",
            "Epoch 567/700\n",
            "93/93 [==============================] - 2s 16ms/step - loss: 0.0511 - accuracy: 0.9832 - val_loss: 1.0140 - val_accuracy: 0.8193\n",
            "Epoch 568/700\n",
            "93/93 [==============================] - 2s 17ms/step - loss: 0.0503 - accuracy: 0.9825 - val_loss: 1.0033 - val_accuracy: 0.8133\n",
            "Epoch 569/700\n",
            "93/93 [==============================] - 2s 18ms/step - loss: 0.0507 - accuracy: 0.9819 - val_loss: 0.9771 - val_accuracy: 0.8313\n",
            "Epoch 570/700\n",
            "93/93 [==============================] - 2s 18ms/step - loss: 0.0444 - accuracy: 0.9839 - val_loss: 1.0707 - val_accuracy: 0.7952\n",
            "Epoch 571/700\n",
            "93/93 [==============================] - 2s 17ms/step - loss: 0.0653 - accuracy: 0.9751 - val_loss: 0.9444 - val_accuracy: 0.8193\n",
            "Epoch 572/700\n",
            "93/93 [==============================] - 2s 17ms/step - loss: 0.0420 - accuracy: 0.9872 - val_loss: 0.9607 - val_accuracy: 0.8253\n",
            "Epoch 573/700\n",
            "93/93 [==============================] - 2s 16ms/step - loss: 0.0396 - accuracy: 0.9825 - val_loss: 1.0489 - val_accuracy: 0.7952\n",
            "Epoch 574/700\n",
            "93/93 [==============================] - 2s 17ms/step - loss: 0.0457 - accuracy: 0.9839 - val_loss: 0.9749 - val_accuracy: 0.8072\n",
            "Epoch 575/700\n",
            "93/93 [==============================] - 2s 17ms/step - loss: 0.0628 - accuracy: 0.9812 - val_loss: 1.0768 - val_accuracy: 0.7892\n",
            "Epoch 576/700\n",
            "93/93 [==============================] - 2s 17ms/step - loss: 0.0479 - accuracy: 0.9832 - val_loss: 0.9452 - val_accuracy: 0.8193\n",
            "Epoch 577/700\n",
            "93/93 [==============================] - 2s 18ms/step - loss: 0.0745 - accuracy: 0.9758 - val_loss: 0.9221 - val_accuracy: 0.8373\n",
            "Epoch 578/700\n",
            "93/93 [==============================] - 2s 18ms/step - loss: 0.0399 - accuracy: 0.9866 - val_loss: 1.0763 - val_accuracy: 0.7771\n",
            "Epoch 579/700\n",
            "93/93 [==============================] - 2s 18ms/step - loss: 0.0480 - accuracy: 0.9859 - val_loss: 1.0561 - val_accuracy: 0.8012\n",
            "Epoch 580/700\n",
            "93/93 [==============================] - 2s 16ms/step - loss: 0.0491 - accuracy: 0.9839 - val_loss: 1.0763 - val_accuracy: 0.7952\n",
            "Epoch 581/700\n",
            "93/93 [==============================] - 1s 16ms/step - loss: 0.0493 - accuracy: 0.9825 - val_loss: 1.1082 - val_accuracy: 0.8012\n",
            "Epoch 582/700\n",
            "93/93 [==============================] - 2s 17ms/step - loss: 0.0474 - accuracy: 0.9839 - val_loss: 1.1523 - val_accuracy: 0.8072\n",
            "Epoch 583/700\n",
            "93/93 [==============================] - 2s 17ms/step - loss: 0.0458 - accuracy: 0.9845 - val_loss: 1.1066 - val_accuracy: 0.7952\n",
            "Epoch 584/700\n",
            "93/93 [==============================] - 2s 18ms/step - loss: 0.0443 - accuracy: 0.9886 - val_loss: 0.9617 - val_accuracy: 0.8313\n",
            "Epoch 585/700\n",
            "93/93 [==============================] - 2s 17ms/step - loss: 0.0555 - accuracy: 0.9872 - val_loss: 1.1070 - val_accuracy: 0.8253\n",
            "Epoch 586/700\n",
            "93/93 [==============================] - 2s 18ms/step - loss: 0.0481 - accuracy: 0.9832 - val_loss: 1.0483 - val_accuracy: 0.8012\n",
            "Epoch 587/700\n",
            "93/93 [==============================] - 2s 18ms/step - loss: 0.0479 - accuracy: 0.9832 - val_loss: 1.0006 - val_accuracy: 0.8253\n",
            "Epoch 588/700\n",
            "93/93 [==============================] - 2s 17ms/step - loss: 0.0423 - accuracy: 0.9859 - val_loss: 1.1231 - val_accuracy: 0.8253\n",
            "Epoch 589/700\n",
            "93/93 [==============================] - 2s 18ms/step - loss: 0.0464 - accuracy: 0.9825 - val_loss: 0.9960 - val_accuracy: 0.8133\n",
            "Epoch 590/700\n",
            "93/93 [==============================] - 1s 16ms/step - loss: 0.0490 - accuracy: 0.9852 - val_loss: 1.0468 - val_accuracy: 0.8193\n",
            "Epoch 591/700\n",
            "93/93 [==============================] - 2s 16ms/step - loss: 0.0505 - accuracy: 0.9859 - val_loss: 1.0233 - val_accuracy: 0.8313\n",
            "Epoch 592/700\n",
            "93/93 [==============================] - 2s 18ms/step - loss: 0.0295 - accuracy: 0.9892 - val_loss: 1.0099 - val_accuracy: 0.8253\n",
            "Epoch 593/700\n",
            "93/93 [==============================] - 2s 17ms/step - loss: 0.0388 - accuracy: 0.9852 - val_loss: 1.0932 - val_accuracy: 0.8072\n",
            "Epoch 594/700\n",
            "93/93 [==============================] - 2s 16ms/step - loss: 0.0537 - accuracy: 0.9805 - val_loss: 1.1492 - val_accuracy: 0.8012\n",
            "Epoch 595/700\n",
            "93/93 [==============================] - 2s 17ms/step - loss: 0.0503 - accuracy: 0.9805 - val_loss: 1.1207 - val_accuracy: 0.8313\n",
            "Epoch 596/700\n",
            "93/93 [==============================] - 2s 17ms/step - loss: 0.0370 - accuracy: 0.9886 - val_loss: 1.1366 - val_accuracy: 0.7892\n",
            "Epoch 597/700\n",
            "93/93 [==============================] - 2s 18ms/step - loss: 0.0473 - accuracy: 0.9819 - val_loss: 0.9900 - val_accuracy: 0.8193\n",
            "Epoch 598/700\n",
            "93/93 [==============================] - 2s 18ms/step - loss: 0.0550 - accuracy: 0.9805 - val_loss: 1.0679 - val_accuracy: 0.8253\n",
            "Epoch 599/700\n",
            "93/93 [==============================] - 2s 16ms/step - loss: 0.0460 - accuracy: 0.9845 - val_loss: 1.1697 - val_accuracy: 0.7952\n",
            "Epoch 600/700\n",
            "93/93 [==============================] - 2s 18ms/step - loss: 0.0419 - accuracy: 0.9832 - val_loss: 1.0154 - val_accuracy: 0.8193\n",
            "Epoch 601/700\n",
            "93/93 [==============================] - 2s 18ms/step - loss: 0.0469 - accuracy: 0.9832 - val_loss: 0.9551 - val_accuracy: 0.8434\n",
            "Epoch 602/700\n",
            "93/93 [==============================] - 2s 16ms/step - loss: 0.0554 - accuracy: 0.9825 - val_loss: 1.0569 - val_accuracy: 0.8193\n",
            "Epoch 603/700\n",
            "93/93 [==============================] - 2s 17ms/step - loss: 0.0589 - accuracy: 0.9778 - val_loss: 1.0176 - val_accuracy: 0.8373\n",
            "Epoch 604/700\n",
            "93/93 [==============================] - 2s 18ms/step - loss: 0.0407 - accuracy: 0.9879 - val_loss: 1.0107 - val_accuracy: 0.8133\n",
            "Epoch 605/700\n",
            "93/93 [==============================] - 2s 18ms/step - loss: 0.0439 - accuracy: 0.9852 - val_loss: 1.1393 - val_accuracy: 0.8012\n",
            "Epoch 606/700\n",
            "93/93 [==============================] - 1s 16ms/step - loss: 0.0432 - accuracy: 0.9839 - val_loss: 1.0797 - val_accuracy: 0.7952\n",
            "Epoch 607/700\n",
            "93/93 [==============================] - 2s 19ms/step - loss: 0.0520 - accuracy: 0.9839 - val_loss: 0.9709 - val_accuracy: 0.8313\n",
            "Epoch 608/700\n",
            "93/93 [==============================] - 2s 18ms/step - loss: 0.0528 - accuracy: 0.9832 - val_loss: 0.9758 - val_accuracy: 0.8373\n",
            "Epoch 609/700\n",
            "93/93 [==============================] - 2s 17ms/step - loss: 0.0434 - accuracy: 0.9872 - val_loss: 1.0817 - val_accuracy: 0.8193\n",
            "Epoch 610/700\n",
            "93/93 [==============================] - 2s 18ms/step - loss: 0.0630 - accuracy: 0.9792 - val_loss: 1.0831 - val_accuracy: 0.8133\n",
            "Epoch 611/700\n",
            "93/93 [==============================] - 2s 17ms/step - loss: 0.0430 - accuracy: 0.9852 - val_loss: 1.1845 - val_accuracy: 0.8012\n",
            "Epoch 612/700\n",
            "93/93 [==============================] - 2s 16ms/step - loss: 0.0445 - accuracy: 0.9866 - val_loss: 1.0840 - val_accuracy: 0.7952\n",
            "Epoch 613/700\n",
            "93/93 [==============================] - 2s 18ms/step - loss: 0.0384 - accuracy: 0.9866 - val_loss: 1.1688 - val_accuracy: 0.8133\n",
            "Epoch 614/700\n",
            "93/93 [==============================] - 2s 18ms/step - loss: 0.0517 - accuracy: 0.9845 - val_loss: 1.1677 - val_accuracy: 0.8313\n",
            "Epoch 615/700\n",
            "93/93 [==============================] - 2s 17ms/step - loss: 0.0448 - accuracy: 0.9852 - val_loss: 1.0144 - val_accuracy: 0.8133\n",
            "Epoch 616/700\n",
            "93/93 [==============================] - 2s 17ms/step - loss: 0.0570 - accuracy: 0.9805 - val_loss: 0.9677 - val_accuracy: 0.8253\n",
            "Epoch 617/700\n",
            "93/93 [==============================] - 2s 17ms/step - loss: 0.0431 - accuracy: 0.9832 - val_loss: 1.0186 - val_accuracy: 0.8133\n",
            "Epoch 618/700\n",
            "93/93 [==============================] - 2s 16ms/step - loss: 0.0664 - accuracy: 0.9765 - val_loss: 0.9884 - val_accuracy: 0.8313\n",
            "Epoch 619/700\n",
            "93/93 [==============================] - 2s 17ms/step - loss: 0.0487 - accuracy: 0.9825 - val_loss: 1.1744 - val_accuracy: 0.8012\n",
            "Epoch 620/700\n",
            "93/93 [==============================] - 2s 18ms/step - loss: 0.0700 - accuracy: 0.9798 - val_loss: 0.9930 - val_accuracy: 0.8133\n",
            "Epoch 621/700\n",
            "93/93 [==============================] - 2s 18ms/step - loss: 0.0479 - accuracy: 0.9805 - val_loss: 0.9875 - val_accuracy: 0.8253\n",
            "Epoch 622/700\n",
            "93/93 [==============================] - 2s 19ms/step - loss: 0.0497 - accuracy: 0.9859 - val_loss: 1.1076 - val_accuracy: 0.8133\n",
            "Epoch 623/700\n",
            "93/93 [==============================] - 2s 16ms/step - loss: 0.0423 - accuracy: 0.9852 - val_loss: 1.0825 - val_accuracy: 0.7952\n",
            "Epoch 624/700\n",
            "93/93 [==============================] - 2s 16ms/step - loss: 0.0340 - accuracy: 0.9886 - val_loss: 1.0456 - val_accuracy: 0.8373\n",
            "Epoch 625/700\n",
            "93/93 [==============================] - 1s 16ms/step - loss: 0.0504 - accuracy: 0.9852 - val_loss: 1.0248 - val_accuracy: 0.8133\n",
            "Epoch 626/700\n",
            "93/93 [==============================] - 2s 18ms/step - loss: 0.0461 - accuracy: 0.9866 - val_loss: 1.0449 - val_accuracy: 0.8313\n",
            "Epoch 627/700\n",
            "93/93 [==============================] - 2s 18ms/step - loss: 0.0432 - accuracy: 0.9839 - val_loss: 1.0914 - val_accuracy: 0.7952\n",
            "Epoch 628/700\n",
            "93/93 [==============================] - 2s 18ms/step - loss: 0.0423 - accuracy: 0.9852 - val_loss: 1.0840 - val_accuracy: 0.8253\n",
            "Epoch 629/700\n",
            "93/93 [==============================] - 2s 19ms/step - loss: 0.0446 - accuracy: 0.9832 - val_loss: 1.1524 - val_accuracy: 0.8253\n",
            "Epoch 630/700\n",
            "93/93 [==============================] - 2s 18ms/step - loss: 0.0448 - accuracy: 0.9852 - val_loss: 1.0362 - val_accuracy: 0.8494\n",
            "Epoch 631/700\n",
            "93/93 [==============================] - 2s 18ms/step - loss: 0.0490 - accuracy: 0.9845 - val_loss: 1.0623 - val_accuracy: 0.8313\n",
            "Epoch 632/700\n",
            "93/93 [==============================] - 2s 17ms/step - loss: 0.0509 - accuracy: 0.9859 - val_loss: 1.0102 - val_accuracy: 0.8313\n",
            "Epoch 633/700\n",
            "93/93 [==============================] - 1s 16ms/step - loss: 0.0678 - accuracy: 0.9792 - val_loss: 0.9692 - val_accuracy: 0.8313\n",
            "Epoch 634/700\n",
            "93/93 [==============================] - 2s 17ms/step - loss: 0.0499 - accuracy: 0.9819 - val_loss: 0.9360 - val_accuracy: 0.8313\n",
            "Epoch 635/700\n",
            "93/93 [==============================] - 2s 18ms/step - loss: 0.0259 - accuracy: 0.9892 - val_loss: 1.0546 - val_accuracy: 0.8554\n",
            "Epoch 636/700\n",
            "93/93 [==============================] - 2s 17ms/step - loss: 0.0490 - accuracy: 0.9886 - val_loss: 0.9899 - val_accuracy: 0.8253\n",
            "Epoch 637/700\n",
            "93/93 [==============================] - 2s 17ms/step - loss: 0.0344 - accuracy: 0.9866 - val_loss: 1.0065 - val_accuracy: 0.8253\n",
            "Epoch 638/700\n",
            "93/93 [==============================] - 2s 17ms/step - loss: 0.0510 - accuracy: 0.9819 - val_loss: 1.0224 - val_accuracy: 0.8072\n",
            "Epoch 639/700\n",
            "93/93 [==============================] - 2s 16ms/step - loss: 0.0416 - accuracy: 0.9859 - val_loss: 1.0434 - val_accuracy: 0.8313\n",
            "Epoch 640/700\n",
            "93/93 [==============================] - 2s 18ms/step - loss: 0.0575 - accuracy: 0.9812 - val_loss: 1.1522 - val_accuracy: 0.8434\n",
            "Epoch 641/700\n",
            "93/93 [==============================] - 2s 19ms/step - loss: 0.0474 - accuracy: 0.9819 - val_loss: 1.0237 - val_accuracy: 0.8253\n",
            "Epoch 642/700\n",
            "93/93 [==============================] - 2s 17ms/step - loss: 0.0474 - accuracy: 0.9798 - val_loss: 1.0469 - val_accuracy: 0.7831\n",
            "Epoch 643/700\n",
            "93/93 [==============================] - 2s 18ms/step - loss: 0.0371 - accuracy: 0.9872 - val_loss: 0.9751 - val_accuracy: 0.8072\n",
            "Epoch 644/700\n",
            "93/93 [==============================] - 2s 19ms/step - loss: 0.0513 - accuracy: 0.9839 - val_loss: 1.0144 - val_accuracy: 0.8012\n",
            "Epoch 645/700\n",
            "93/93 [==============================] - 2s 16ms/step - loss: 0.0606 - accuracy: 0.9805 - val_loss: 0.9995 - val_accuracy: 0.8133\n",
            "Epoch 646/700\n",
            "93/93 [==============================] - 2s 18ms/step - loss: 0.0317 - accuracy: 0.9913 - val_loss: 0.9731 - val_accuracy: 0.8373\n",
            "Epoch 647/700\n",
            "93/93 [==============================] - 2s 18ms/step - loss: 0.0400 - accuracy: 0.9859 - val_loss: 1.0667 - val_accuracy: 0.8133\n",
            "Epoch 648/700\n",
            "93/93 [==============================] - 2s 18ms/step - loss: 0.0552 - accuracy: 0.9825 - val_loss: 1.0680 - val_accuracy: 0.8253\n",
            "Epoch 649/700\n",
            "93/93 [==============================] - 2s 18ms/step - loss: 0.0530 - accuracy: 0.9839 - val_loss: 1.0733 - val_accuracy: 0.8072\n",
            "Epoch 650/700\n",
            "93/93 [==============================] - 2s 18ms/step - loss: 0.0479 - accuracy: 0.9792 - val_loss: 1.0194 - val_accuracy: 0.8133\n",
            "Epoch 651/700\n",
            "93/93 [==============================] - 2s 18ms/step - loss: 0.0516 - accuracy: 0.9839 - val_loss: 1.0158 - val_accuracy: 0.8313\n",
            "Epoch 652/700\n",
            "93/93 [==============================] - 2s 18ms/step - loss: 0.0404 - accuracy: 0.9845 - val_loss: 1.1945 - val_accuracy: 0.8253\n",
            "Epoch 653/700\n",
            "93/93 [==============================] - 2s 18ms/step - loss: 0.0507 - accuracy: 0.9839 - val_loss: 0.9934 - val_accuracy: 0.8253\n",
            "Epoch 654/700\n",
            "93/93 [==============================] - 2s 18ms/step - loss: 0.0524 - accuracy: 0.9812 - val_loss: 0.9652 - val_accuracy: 0.8133\n",
            "Epoch 655/700\n",
            "93/93 [==============================] - 2s 16ms/step - loss: 0.0345 - accuracy: 0.9859 - val_loss: 1.0121 - val_accuracy: 0.8193\n",
            "Epoch 656/700\n",
            "93/93 [==============================] - 2s 17ms/step - loss: 0.0313 - accuracy: 0.9919 - val_loss: 1.0819 - val_accuracy: 0.8253\n",
            "Epoch 657/700\n",
            "93/93 [==============================] - 2s 18ms/step - loss: 0.0510 - accuracy: 0.9825 - val_loss: 1.0683 - val_accuracy: 0.8193\n",
            "Epoch 658/700\n",
            "93/93 [==============================] - 2s 18ms/step - loss: 0.0387 - accuracy: 0.9886 - val_loss: 0.9289 - val_accuracy: 0.8133\n",
            "Epoch 659/700\n",
            "93/93 [==============================] - 2s 19ms/step - loss: 0.0578 - accuracy: 0.9798 - val_loss: 0.9974 - val_accuracy: 0.8313\n",
            "Epoch 660/700\n",
            "93/93 [==============================] - 2s 19ms/step - loss: 0.0430 - accuracy: 0.9892 - val_loss: 1.0674 - val_accuracy: 0.8434\n",
            "Epoch 661/700\n",
            "93/93 [==============================] - 2s 18ms/step - loss: 0.0602 - accuracy: 0.9832 - val_loss: 0.9153 - val_accuracy: 0.8434\n",
            "Epoch 662/700\n",
            "93/93 [==============================] - 2s 18ms/step - loss: 0.0591 - accuracy: 0.9812 - val_loss: 0.9732 - val_accuracy: 0.8193\n",
            "Epoch 663/700\n",
            "93/93 [==============================] - 2s 17ms/step - loss: 0.0439 - accuracy: 0.9852 - val_loss: 1.1333 - val_accuracy: 0.8253\n",
            "Epoch 664/700\n",
            "93/93 [==============================] - 2s 17ms/step - loss: 0.0381 - accuracy: 0.9872 - val_loss: 1.0997 - val_accuracy: 0.8313\n",
            "Epoch 665/700\n",
            "93/93 [==============================] - 2s 18ms/step - loss: 0.0363 - accuracy: 0.9919 - val_loss: 1.1553 - val_accuracy: 0.8373\n",
            "Epoch 666/700\n",
            "93/93 [==============================] - 2s 17ms/step - loss: 0.0401 - accuracy: 0.9859 - val_loss: 1.3023 - val_accuracy: 0.7892\n",
            "Epoch 667/700\n",
            "93/93 [==============================] - 2s 16ms/step - loss: 0.0420 - accuracy: 0.9832 - val_loss: 1.1837 - val_accuracy: 0.7831\n",
            "Epoch 668/700\n",
            "93/93 [==============================] - 2s 17ms/step - loss: 0.0423 - accuracy: 0.9886 - val_loss: 1.1706 - val_accuracy: 0.8193\n",
            "Epoch 669/700\n",
            "93/93 [==============================] - 2s 16ms/step - loss: 0.0364 - accuracy: 0.9886 - val_loss: 1.1841 - val_accuracy: 0.8012\n",
            "Epoch 670/700\n",
            "93/93 [==============================] - 2s 17ms/step - loss: 0.0543 - accuracy: 0.9825 - val_loss: 1.1951 - val_accuracy: 0.8072\n",
            "Epoch 671/700\n",
            "93/93 [==============================] - 2s 18ms/step - loss: 0.0353 - accuracy: 0.9866 - val_loss: 1.0856 - val_accuracy: 0.8193\n",
            "Epoch 672/700\n",
            "93/93 [==============================] - 2s 17ms/step - loss: 0.0367 - accuracy: 0.9906 - val_loss: 1.1065 - val_accuracy: 0.8072\n",
            "Epoch 673/700\n",
            "93/93 [==============================] - 2s 17ms/step - loss: 0.0527 - accuracy: 0.9832 - val_loss: 1.0818 - val_accuracy: 0.8434\n",
            "Epoch 674/700\n",
            "93/93 [==============================] - 2s 18ms/step - loss: 0.0282 - accuracy: 0.9906 - val_loss: 1.1365 - val_accuracy: 0.8193\n",
            "Epoch 675/700\n",
            "93/93 [==============================] - 2s 17ms/step - loss: 0.0404 - accuracy: 0.9839 - val_loss: 1.2045 - val_accuracy: 0.8193\n",
            "Epoch 676/700\n",
            "93/93 [==============================] - 2s 17ms/step - loss: 0.0381 - accuracy: 0.9866 - val_loss: 1.2161 - val_accuracy: 0.8133\n",
            "Epoch 677/700\n",
            "93/93 [==============================] - 2s 18ms/step - loss: 0.0428 - accuracy: 0.9845 - val_loss: 1.0079 - val_accuracy: 0.8133\n",
            "Epoch 678/700\n",
            "93/93 [==============================] - 2s 19ms/step - loss: 0.0420 - accuracy: 0.9852 - val_loss: 1.0973 - val_accuracy: 0.8133\n",
            "Epoch 679/700\n",
            "93/93 [==============================] - 2s 18ms/step - loss: 0.0316 - accuracy: 0.9926 - val_loss: 1.1539 - val_accuracy: 0.8072\n",
            "Epoch 680/700\n",
            "93/93 [==============================] - 2s 19ms/step - loss: 0.0332 - accuracy: 0.9866 - val_loss: 1.1447 - val_accuracy: 0.8193\n",
            "Epoch 681/700\n",
            "93/93 [==============================] - 2s 17ms/step - loss: 0.0334 - accuracy: 0.9899 - val_loss: 1.2044 - val_accuracy: 0.8012\n",
            "Epoch 682/700\n",
            "93/93 [==============================] - 2s 18ms/step - loss: 0.0438 - accuracy: 0.9832 - val_loss: 1.1051 - val_accuracy: 0.8253\n",
            "Epoch 683/700\n",
            "93/93 [==============================] - 2s 18ms/step - loss: 0.0413 - accuracy: 0.9866 - val_loss: 1.2333 - val_accuracy: 0.8012\n",
            "Epoch 684/700\n",
            "93/93 [==============================] - 2s 19ms/step - loss: 0.0483 - accuracy: 0.9879 - val_loss: 1.3569 - val_accuracy: 0.7831\n",
            "Epoch 685/700\n",
            "93/93 [==============================] - 2s 18ms/step - loss: 0.0474 - accuracy: 0.9845 - val_loss: 1.0732 - val_accuracy: 0.8313\n",
            "Epoch 686/700\n",
            "93/93 [==============================] - 2s 16ms/step - loss: 0.0461 - accuracy: 0.9845 - val_loss: 1.1003 - val_accuracy: 0.8313\n",
            "Epoch 687/700\n",
            "93/93 [==============================] - 2s 18ms/step - loss: 0.0462 - accuracy: 0.9839 - val_loss: 1.2169 - val_accuracy: 0.8193\n",
            "Epoch 688/700\n",
            "93/93 [==============================] - 2s 17ms/step - loss: 0.0424 - accuracy: 0.9859 - val_loss: 1.0874 - val_accuracy: 0.8313\n",
            "Epoch 689/700\n",
            "93/93 [==============================] - 2s 17ms/step - loss: 0.0337 - accuracy: 0.9906 - val_loss: 1.0197 - val_accuracy: 0.8554\n",
            "Epoch 690/700\n",
            "93/93 [==============================] - 2s 17ms/step - loss: 0.0477 - accuracy: 0.9825 - val_loss: 1.1471 - val_accuracy: 0.8193\n",
            "Epoch 691/700\n",
            "93/93 [==============================] - 2s 17ms/step - loss: 0.0351 - accuracy: 0.9845 - val_loss: 1.1198 - val_accuracy: 0.8434\n",
            "Epoch 692/700\n",
            "93/93 [==============================] - 2s 18ms/step - loss: 0.0489 - accuracy: 0.9825 - val_loss: 1.1258 - val_accuracy: 0.8193\n",
            "Epoch 693/700\n",
            "93/93 [==============================] - 2s 19ms/step - loss: 0.0317 - accuracy: 0.9892 - val_loss: 1.2743 - val_accuracy: 0.8373\n",
            "Epoch 694/700\n",
            "93/93 [==============================] - 2s 19ms/step - loss: 0.0355 - accuracy: 0.9899 - val_loss: 1.1206 - val_accuracy: 0.8133\n",
            "Epoch 695/700\n",
            "93/93 [==============================] - 2s 19ms/step - loss: 0.0505 - accuracy: 0.9832 - val_loss: 1.0104 - val_accuracy: 0.8072\n",
            "Epoch 696/700\n",
            "93/93 [==============================] - 2s 18ms/step - loss: 0.0403 - accuracy: 0.9845 - val_loss: 1.0983 - val_accuracy: 0.7892\n",
            "Epoch 697/700\n",
            "93/93 [==============================] - 2s 19ms/step - loss: 0.0326 - accuracy: 0.9919 - val_loss: 1.1920 - val_accuracy: 0.8193\n",
            "Epoch 698/700\n",
            "93/93 [==============================] - 2s 18ms/step - loss: 0.0500 - accuracy: 0.9832 - val_loss: 1.1764 - val_accuracy: 0.8193\n",
            "Epoch 699/700\n",
            "93/93 [==============================] - 2s 17ms/step - loss: 0.0522 - accuracy: 0.9852 - val_loss: 1.1036 - val_accuracy: 0.8253\n",
            "Epoch 700/700\n",
            "93/93 [==============================] - 2s 17ms/step - loss: 0.0341 - accuracy: 0.9906 - val_loss: 1.1095 - val_accuracy: 0.8133\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#cnnhistory=model.fit(x_traincnn, y_train, batch_size=16, epochs=700, validation_data=(x_testcnn, y_test))\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "kfold = StratifiedKFold(n_splits=5, shuffle=True)\n",
        "cvscores = []\n",
        "for train, test in kfold.split(X, y):\n",
        "  #create model\n",
        "\n",
        "  model = Sequential()\n",
        "\n",
        "  model.add(Conv1D(64, 5,padding='same', #classifier.add(Convolution2D(64, (3, 3), padding = 'same', input_shape = (128, 128, 3), activation = 'relu'))\n",
        "                 input_shape=(40,1)))\n",
        "  model.add(Activation('sigmoid'))\n",
        "  model.add(Dropout(0.1))\n",
        "  model.add(MaxPooling1D(pool_size=(4)))\n",
        "  model.add(Conv1D(128, 5,padding='same',))\n",
        "  model.add(Activation('sigmoid'))\n",
        "  model.add(Dropout(0.1))\n",
        "  model.add(MaxPooling1D(pool_size=(4)))\n",
        "  model.add(Conv1D(256, 5,padding='same',))\n",
        "  model.add(Activation('sigmoid'))\n",
        "  model.add(Dropout(0.1))\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(6))\n",
        "  model.add(Activation('softmax'))\n",
        "  opt = tf.keras.optimizers.RMSprop(lr=0.0001, rho=0.9, epsilon=1e-07, decay=0.0)\n",
        "\n",
        "  model.compile(loss='sparse_categorical_crossentropy',\n",
        "              optimizer=opt,\n",
        "              metrics=['accuracy'])\n",
        "  \n",
        "  cnnhistory=model.fit(X[train], y[train], batch_size=16, epochs=700,validation_split=0.1)\n",
        "   \n",
        "  # evaluate the model\n",
        "  training_acc=np.mean(cnnhistory.history['accuracy']) # numpy assumed imported as np\n",
        "  print(training_acc)\n",
        "  scores = model.evaluate(X[test], y[test], verbose=0)\n",
        "  print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
        "  cvscores.append(scores[1] * 100)\n",
        "  \n",
        "print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(cvscores), np.std(cvscores)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fxJ42-klSls6",
        "outputId": "967dddd7-dbc4-4290-aa36-f9e8c6ff7ad7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/700\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/rmsprop.py:130: UserWarning:\n",
            "\n",
            "The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.6737 - accuracy: 0.7310 - val_loss: 1.4059 - val_accuracy: 0.4305\n",
            "Epoch 306/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.6837 - accuracy: 0.7199 - val_loss: 1.3884 - val_accuracy: 0.4437\n",
            "Epoch 307/700\n",
            "85/85 [==============================] - 2s 19ms/step - loss: 0.6722 - accuracy: 0.7347 - val_loss: 1.4188 - val_accuracy: 0.4305\n",
            "Epoch 308/700\n",
            "85/85 [==============================] - 2s 19ms/step - loss: 0.6916 - accuracy: 0.7206 - val_loss: 1.3862 - val_accuracy: 0.4503\n",
            "Epoch 309/700\n",
            "85/85 [==============================] - 2s 18ms/step - loss: 0.6696 - accuracy: 0.7369 - val_loss: 1.3759 - val_accuracy: 0.4238\n",
            "Epoch 310/700\n",
            "85/85 [==============================] - 2s 19ms/step - loss: 0.6654 - accuracy: 0.7406 - val_loss: 1.4103 - val_accuracy: 0.4040\n",
            "Epoch 311/700\n",
            "85/85 [==============================] - 2s 19ms/step - loss: 0.6503 - accuracy: 0.7458 - val_loss: 1.4645 - val_accuracy: 0.4040\n",
            "Epoch 312/700\n",
            "85/85 [==============================] - 2s 19ms/step - loss: 0.6587 - accuracy: 0.7332 - val_loss: 1.3974 - val_accuracy: 0.4238\n",
            "Epoch 313/700\n",
            "85/85 [==============================] - 2s 19ms/step - loss: 0.6509 - accuracy: 0.7361 - val_loss: 1.4165 - val_accuracy: 0.4040\n",
            "Epoch 314/700\n",
            "85/85 [==============================] - 2s 19ms/step - loss: 0.6641 - accuracy: 0.7435 - val_loss: 1.4364 - val_accuracy: 0.4238\n",
            "Epoch 315/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.6670 - accuracy: 0.7265 - val_loss: 1.4060 - val_accuracy: 0.4437\n",
            "Epoch 316/700\n",
            "85/85 [==============================] - 2s 19ms/step - loss: 0.6571 - accuracy: 0.7384 - val_loss: 1.4091 - val_accuracy: 0.4503\n",
            "Epoch 317/700\n",
            "85/85 [==============================] - 2s 19ms/step - loss: 0.6592 - accuracy: 0.7391 - val_loss: 1.4280 - val_accuracy: 0.3841\n",
            "Epoch 318/700\n",
            "85/85 [==============================] - 2s 19ms/step - loss: 0.6467 - accuracy: 0.7613 - val_loss: 1.3810 - val_accuracy: 0.4371\n",
            "Epoch 319/700\n",
            "85/85 [==============================] - 2s 19ms/step - loss: 0.6654 - accuracy: 0.7354 - val_loss: 1.4024 - val_accuracy: 0.4371\n",
            "Epoch 320/700\n",
            "85/85 [==============================] - 2s 19ms/step - loss: 0.6611 - accuracy: 0.7398 - val_loss: 1.3879 - val_accuracy: 0.4702\n",
            "Epoch 321/700\n",
            "85/85 [==============================] - 2s 19ms/step - loss: 0.6422 - accuracy: 0.7598 - val_loss: 1.4297 - val_accuracy: 0.4437\n",
            "Epoch 322/700\n",
            "85/85 [==============================] - 2s 19ms/step - loss: 0.6580 - accuracy: 0.7443 - val_loss: 1.4162 - val_accuracy: 0.4106\n",
            "Epoch 323/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.6477 - accuracy: 0.7435 - val_loss: 1.4811 - val_accuracy: 0.4305\n",
            "Epoch 324/700\n",
            "85/85 [==============================] - 2s 19ms/step - loss: 0.6590 - accuracy: 0.7324 - val_loss: 1.3953 - val_accuracy: 0.4967\n",
            "Epoch 325/700\n",
            "85/85 [==============================] - 2s 19ms/step - loss: 0.6625 - accuracy: 0.7398 - val_loss: 1.3684 - val_accuracy: 0.4834\n",
            "Epoch 326/700\n",
            "85/85 [==============================] - 2s 19ms/step - loss: 0.6565 - accuracy: 0.7487 - val_loss: 1.4017 - val_accuracy: 0.4570\n",
            "Epoch 327/700\n",
            "85/85 [==============================] - 2s 19ms/step - loss: 0.6633 - accuracy: 0.7310 - val_loss: 1.4259 - val_accuracy: 0.4238\n",
            "Epoch 328/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.6435 - accuracy: 0.7494 - val_loss: 1.4020 - val_accuracy: 0.4702\n",
            "Epoch 329/700\n",
            "85/85 [==============================] - 2s 19ms/step - loss: 0.6455 - accuracy: 0.7524 - val_loss: 1.4067 - val_accuracy: 0.4106\n",
            "Epoch 330/700\n",
            "85/85 [==============================] - 2s 18ms/step - loss: 0.6380 - accuracy: 0.7450 - val_loss: 1.3791 - val_accuracy: 0.4636\n",
            "Epoch 331/700\n",
            "85/85 [==============================] - 2s 19ms/step - loss: 0.6610 - accuracy: 0.7361 - val_loss: 1.4060 - val_accuracy: 0.4238\n",
            "Epoch 332/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.6325 - accuracy: 0.7576 - val_loss: 1.4515 - val_accuracy: 0.4238\n",
            "Epoch 333/700\n",
            "85/85 [==============================] - 2s 19ms/step - loss: 0.6154 - accuracy: 0.7642 - val_loss: 1.3651 - val_accuracy: 0.4437\n",
            "Epoch 334/700\n",
            "85/85 [==============================] - 2s 19ms/step - loss: 0.6309 - accuracy: 0.7598 - val_loss: 1.3956 - val_accuracy: 0.4702\n",
            "Epoch 335/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.6340 - accuracy: 0.7480 - val_loss: 1.4684 - val_accuracy: 0.4437\n",
            "Epoch 336/700\n",
            "85/85 [==============================] - 2s 19ms/step - loss: 0.6478 - accuracy: 0.7398 - val_loss: 1.4122 - val_accuracy: 0.4305\n",
            "Epoch 337/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.6274 - accuracy: 0.7642 - val_loss: 1.4722 - val_accuracy: 0.4238\n",
            "Epoch 338/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.6374 - accuracy: 0.7465 - val_loss: 1.3981 - val_accuracy: 0.4503\n",
            "Epoch 339/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.6315 - accuracy: 0.7502 - val_loss: 1.4400 - val_accuracy: 0.4172\n",
            "Epoch 340/700\n",
            "85/85 [==============================] - 2s 19ms/step - loss: 0.6334 - accuracy: 0.7635 - val_loss: 1.3973 - val_accuracy: 0.4967\n",
            "Epoch 341/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.6106 - accuracy: 0.7598 - val_loss: 1.3964 - val_accuracy: 0.4702\n",
            "Epoch 342/700\n",
            "85/85 [==============================] - 2s 19ms/step - loss: 0.6293 - accuracy: 0.7531 - val_loss: 1.4851 - val_accuracy: 0.4106\n",
            "Epoch 343/700\n",
            "85/85 [==============================] - 2s 19ms/step - loss: 0.6175 - accuracy: 0.7627 - val_loss: 1.4357 - val_accuracy: 0.4172\n",
            "Epoch 344/700\n",
            "85/85 [==============================] - 2s 19ms/step - loss: 0.6218 - accuracy: 0.7509 - val_loss: 1.4196 - val_accuracy: 0.4371\n",
            "Epoch 345/700\n",
            "85/85 [==============================] - 2s 19ms/step - loss: 0.6170 - accuracy: 0.7642 - val_loss: 1.4061 - val_accuracy: 0.4636\n",
            "Epoch 346/700\n",
            "85/85 [==============================] - 2s 19ms/step - loss: 0.6135 - accuracy: 0.7642 - val_loss: 1.4138 - val_accuracy: 0.4570\n",
            "Epoch 347/700\n",
            "85/85 [==============================] - 2s 19ms/step - loss: 0.6215 - accuracy: 0.7509 - val_loss: 1.4130 - val_accuracy: 0.4503\n",
            "Epoch 348/700\n",
            "85/85 [==============================] - 2s 19ms/step - loss: 0.6204 - accuracy: 0.7583 - val_loss: 1.4464 - val_accuracy: 0.4305\n",
            "Epoch 349/700\n",
            "85/85 [==============================] - 2s 19ms/step - loss: 0.6320 - accuracy: 0.7494 - val_loss: 1.3984 - val_accuracy: 0.4503\n",
            "Epoch 350/700\n",
            "85/85 [==============================] - 2s 19ms/step - loss: 0.6205 - accuracy: 0.7531 - val_loss: 1.4539 - val_accuracy: 0.4371\n",
            "Epoch 351/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.6087 - accuracy: 0.7568 - val_loss: 1.4054 - val_accuracy: 0.4702\n",
            "Epoch 352/700\n",
            "85/85 [==============================] - 2s 19ms/step - loss: 0.6160 - accuracy: 0.7539 - val_loss: 1.3952 - val_accuracy: 0.4702\n",
            "Epoch 353/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.6214 - accuracy: 0.7627 - val_loss: 1.4080 - val_accuracy: 0.4371\n",
            "Epoch 354/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.5946 - accuracy: 0.7613 - val_loss: 1.5036 - val_accuracy: 0.4371\n",
            "Epoch 355/700\n",
            "85/85 [==============================] - 2s 19ms/step - loss: 0.6131 - accuracy: 0.7679 - val_loss: 1.4036 - val_accuracy: 0.4636\n",
            "Epoch 356/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.6087 - accuracy: 0.7724 - val_loss: 1.4064 - val_accuracy: 0.4503\n",
            "Epoch 357/700\n",
            "85/85 [==============================] - 2s 19ms/step - loss: 0.6053 - accuracy: 0.7687 - val_loss: 1.4105 - val_accuracy: 0.4636\n",
            "Epoch 358/700\n",
            "85/85 [==============================] - 2s 19ms/step - loss: 0.6049 - accuracy: 0.7679 - val_loss: 1.4141 - val_accuracy: 0.4768\n",
            "Epoch 359/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.5988 - accuracy: 0.7709 - val_loss: 1.4008 - val_accuracy: 0.4570\n",
            "Epoch 360/700\n",
            "85/85 [==============================] - 2s 19ms/step - loss: 0.6096 - accuracy: 0.7650 - val_loss: 1.4442 - val_accuracy: 0.4305\n",
            "Epoch 361/700\n",
            "85/85 [==============================] - 2s 19ms/step - loss: 0.6014 - accuracy: 0.7620 - val_loss: 1.4420 - val_accuracy: 0.4106\n",
            "Epoch 362/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.6132 - accuracy: 0.7672 - val_loss: 1.4263 - val_accuracy: 0.4305\n",
            "Epoch 363/700\n",
            "85/85 [==============================] - 2s 19ms/step - loss: 0.6033 - accuracy: 0.7620 - val_loss: 1.4648 - val_accuracy: 0.4172\n",
            "Epoch 364/700\n",
            "85/85 [==============================] - 2s 19ms/step - loss: 0.6071 - accuracy: 0.7620 - val_loss: 1.4208 - val_accuracy: 0.4437\n",
            "Epoch 365/700\n",
            "85/85 [==============================] - 2s 19ms/step - loss: 0.6226 - accuracy: 0.7664 - val_loss: 1.4244 - val_accuracy: 0.4437\n",
            "Epoch 366/700\n",
            "85/85 [==============================] - 2s 18ms/step - loss: 0.6025 - accuracy: 0.7716 - val_loss: 1.4104 - val_accuracy: 0.4437\n",
            "Epoch 367/700\n",
            "85/85 [==============================] - 2s 18ms/step - loss: 0.6046 - accuracy: 0.7731 - val_loss: 1.4039 - val_accuracy: 0.4238\n",
            "Epoch 368/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.5827 - accuracy: 0.7701 - val_loss: 1.4116 - val_accuracy: 0.4702\n",
            "Epoch 369/700\n",
            "85/85 [==============================] - 2s 19ms/step - loss: 0.6082 - accuracy: 0.7591 - val_loss: 1.4106 - val_accuracy: 0.4636\n",
            "Epoch 370/700\n",
            "85/85 [==============================] - 2s 19ms/step - loss: 0.5778 - accuracy: 0.7805 - val_loss: 1.4175 - val_accuracy: 0.4371\n",
            "Epoch 371/700\n",
            "85/85 [==============================] - 2s 19ms/step - loss: 0.6053 - accuracy: 0.7605 - val_loss: 1.4082 - val_accuracy: 0.4305\n",
            "Epoch 372/700\n",
            "85/85 [==============================] - 2s 19ms/step - loss: 0.5749 - accuracy: 0.7834 - val_loss: 1.4694 - val_accuracy: 0.4238\n",
            "Epoch 373/700\n",
            "85/85 [==============================] - 2s 19ms/step - loss: 0.5839 - accuracy: 0.7664 - val_loss: 1.4362 - val_accuracy: 0.4437\n",
            "Epoch 374/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.5938 - accuracy: 0.7620 - val_loss: 1.4322 - val_accuracy: 0.4238\n",
            "Epoch 375/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.5773 - accuracy: 0.7753 - val_loss: 1.4754 - val_accuracy: 0.3907\n",
            "Epoch 376/700\n",
            "85/85 [==============================] - 2s 19ms/step - loss: 0.5694 - accuracy: 0.7834 - val_loss: 1.4573 - val_accuracy: 0.4702\n",
            "Epoch 377/700\n",
            "85/85 [==============================] - 2s 19ms/step - loss: 0.5717 - accuracy: 0.7797 - val_loss: 1.4321 - val_accuracy: 0.4238\n",
            "Epoch 378/700\n",
            "85/85 [==============================] - 2s 19ms/step - loss: 0.5897 - accuracy: 0.7753 - val_loss: 1.4105 - val_accuracy: 0.4768\n",
            "Epoch 379/700\n",
            "85/85 [==============================] - 2s 19ms/step - loss: 0.6043 - accuracy: 0.7664 - val_loss: 1.4085 - val_accuracy: 0.4503\n",
            "Epoch 380/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.5855 - accuracy: 0.7738 - val_loss: 1.4449 - val_accuracy: 0.4172\n",
            "Epoch 381/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.5998 - accuracy: 0.7627 - val_loss: 1.4143 - val_accuracy: 0.4503\n",
            "Epoch 382/700\n",
            "85/85 [==============================] - 2s 19ms/step - loss: 0.5559 - accuracy: 0.7931 - val_loss: 1.5094 - val_accuracy: 0.4238\n",
            "Epoch 383/700\n",
            "85/85 [==============================] - 2s 18ms/step - loss: 0.5776 - accuracy: 0.7879 - val_loss: 1.4140 - val_accuracy: 0.4636\n",
            "Epoch 384/700\n",
            "85/85 [==============================] - 2s 19ms/step - loss: 0.6003 - accuracy: 0.7554 - val_loss: 1.4293 - val_accuracy: 0.4702\n",
            "Epoch 385/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.5557 - accuracy: 0.7827 - val_loss: 1.4101 - val_accuracy: 0.4901\n",
            "Epoch 386/700\n",
            "85/85 [==============================] - 2s 19ms/step - loss: 0.5934 - accuracy: 0.7657 - val_loss: 1.4926 - val_accuracy: 0.4040\n",
            "Epoch 387/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.5871 - accuracy: 0.7827 - val_loss: 1.4655 - val_accuracy: 0.4238\n",
            "Epoch 388/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.5710 - accuracy: 0.7790 - val_loss: 1.4353 - val_accuracy: 0.4570\n",
            "Epoch 389/700\n",
            "85/85 [==============================] - 2s 19ms/step - loss: 0.5532 - accuracy: 0.7923 - val_loss: 1.4400 - val_accuracy: 0.4503\n",
            "Epoch 390/700\n",
            "85/85 [==============================] - 2s 19ms/step - loss: 0.5727 - accuracy: 0.7790 - val_loss: 1.4211 - val_accuracy: 0.4636\n",
            "Epoch 391/700\n",
            "85/85 [==============================] - 2s 19ms/step - loss: 0.5836 - accuracy: 0.7761 - val_loss: 1.4193 - val_accuracy: 0.4437\n",
            "Epoch 392/700\n",
            "85/85 [==============================] - 2s 19ms/step - loss: 0.5782 - accuracy: 0.7797 - val_loss: 1.4180 - val_accuracy: 0.4437\n",
            "Epoch 393/700\n",
            "85/85 [==============================] - 2s 19ms/step - loss: 0.5936 - accuracy: 0.7694 - val_loss: 1.4236 - val_accuracy: 0.4437\n",
            "Epoch 394/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.5718 - accuracy: 0.7790 - val_loss: 1.4231 - val_accuracy: 0.4570\n",
            "Epoch 395/700\n",
            "85/85 [==============================] - 2s 19ms/step - loss: 0.5686 - accuracy: 0.7694 - val_loss: 1.4197 - val_accuracy: 0.4305\n",
            "Epoch 396/700\n",
            "85/85 [==============================] - 2s 19ms/step - loss: 0.5650 - accuracy: 0.7857 - val_loss: 1.4194 - val_accuracy: 0.4371\n",
            "Epoch 397/700\n",
            "85/85 [==============================] - 2s 19ms/step - loss: 0.5581 - accuracy: 0.7849 - val_loss: 1.4463 - val_accuracy: 0.4106\n",
            "Epoch 398/700\n",
            "85/85 [==============================] - 2s 19ms/step - loss: 0.5496 - accuracy: 0.7812 - val_loss: 1.4130 - val_accuracy: 0.4238\n",
            "Epoch 399/700\n",
            "85/85 [==============================] - 2s 19ms/step - loss: 0.5704 - accuracy: 0.7849 - val_loss: 1.4138 - val_accuracy: 0.4702\n",
            "Epoch 400/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.5578 - accuracy: 0.7783 - val_loss: 1.4296 - val_accuracy: 0.4437\n",
            "Epoch 401/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.5594 - accuracy: 0.7849 - val_loss: 1.4362 - val_accuracy: 0.4371\n",
            "Epoch 402/700\n",
            "85/85 [==============================] - 2s 19ms/step - loss: 0.5753 - accuracy: 0.7679 - val_loss: 1.4373 - val_accuracy: 0.4238\n",
            "Epoch 403/700\n",
            "85/85 [==============================] - 2s 19ms/step - loss: 0.5597 - accuracy: 0.7761 - val_loss: 1.4336 - val_accuracy: 0.4371\n",
            "Epoch 404/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.5562 - accuracy: 0.7797 - val_loss: 1.4913 - val_accuracy: 0.4371\n",
            "Epoch 405/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.5363 - accuracy: 0.7842 - val_loss: 1.4608 - val_accuracy: 0.4040\n",
            "Epoch 406/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.5669 - accuracy: 0.7827 - val_loss: 1.4861 - val_accuracy: 0.4503\n",
            "Epoch 407/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.5578 - accuracy: 0.7768 - val_loss: 1.4450 - val_accuracy: 0.4503\n",
            "Epoch 408/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.5532 - accuracy: 0.7790 - val_loss: 1.4135 - val_accuracy: 0.4702\n",
            "Epoch 409/700\n",
            "85/85 [==============================] - 2s 19ms/step - loss: 0.5502 - accuracy: 0.7812 - val_loss: 1.4397 - val_accuracy: 0.4437\n",
            "Epoch 410/700\n",
            "85/85 [==============================] - 2s 19ms/step - loss: 0.5464 - accuracy: 0.7945 - val_loss: 1.4390 - val_accuracy: 0.4305\n",
            "Epoch 411/700\n",
            "85/85 [==============================] - 2s 19ms/step - loss: 0.5382 - accuracy: 0.7849 - val_loss: 1.4855 - val_accuracy: 0.4040\n",
            "Epoch 412/700\n",
            "85/85 [==============================] - 2s 19ms/step - loss: 0.5421 - accuracy: 0.7916 - val_loss: 1.4437 - val_accuracy: 0.4437\n",
            "Epoch 413/700\n",
            "85/85 [==============================] - 2s 19ms/step - loss: 0.5538 - accuracy: 0.7908 - val_loss: 1.4325 - val_accuracy: 0.4371\n",
            "Epoch 414/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.5490 - accuracy: 0.7783 - val_loss: 1.4172 - val_accuracy: 0.4967\n",
            "Epoch 415/700\n",
            "85/85 [==============================] - 2s 19ms/step - loss: 0.5504 - accuracy: 0.7886 - val_loss: 1.4359 - val_accuracy: 0.4503\n",
            "Epoch 416/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.5315 - accuracy: 0.8027 - val_loss: 1.4218 - val_accuracy: 0.4305\n",
            "Epoch 417/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.5355 - accuracy: 0.7864 - val_loss: 1.4354 - val_accuracy: 0.4503\n",
            "Epoch 418/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.5344 - accuracy: 0.7967 - val_loss: 1.5160 - val_accuracy: 0.4106\n",
            "Epoch 419/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.5506 - accuracy: 0.7975 - val_loss: 1.4423 - val_accuracy: 0.4503\n",
            "Epoch 420/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.5449 - accuracy: 0.7834 - val_loss: 1.4707 - val_accuracy: 0.4967\n",
            "Epoch 421/700\n",
            "85/85 [==============================] - 2s 19ms/step - loss: 0.5540 - accuracy: 0.7967 - val_loss: 1.4296 - val_accuracy: 0.4834\n",
            "Epoch 422/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.5323 - accuracy: 0.7923 - val_loss: 1.4297 - val_accuracy: 0.4305\n",
            "Epoch 423/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.5411 - accuracy: 0.7901 - val_loss: 1.4661 - val_accuracy: 0.4238\n",
            "Epoch 424/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.5495 - accuracy: 0.7834 - val_loss: 1.5262 - val_accuracy: 0.4305\n",
            "Epoch 425/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.5366 - accuracy: 0.7982 - val_loss: 1.4746 - val_accuracy: 0.4305\n",
            "Epoch 426/700\n",
            "85/85 [==============================] - 2s 19ms/step - loss: 0.5389 - accuracy: 0.7886 - val_loss: 1.4438 - val_accuracy: 0.4437\n",
            "Epoch 427/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.5421 - accuracy: 0.7879 - val_loss: 1.5168 - val_accuracy: 0.4570\n",
            "Epoch 428/700\n",
            "85/85 [==============================] - 2s 19ms/step - loss: 0.5329 - accuracy: 0.7975 - val_loss: 1.4437 - val_accuracy: 0.4967\n",
            "Epoch 429/700\n",
            "85/85 [==============================] - 2s 19ms/step - loss: 0.5386 - accuracy: 0.7842 - val_loss: 1.4516 - val_accuracy: 0.4503\n",
            "Epoch 430/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.5245 - accuracy: 0.7982 - val_loss: 1.4756 - val_accuracy: 0.4305\n",
            "Epoch 431/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.5436 - accuracy: 0.7879 - val_loss: 1.4816 - val_accuracy: 0.4172\n",
            "Epoch 432/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.5272 - accuracy: 0.7894 - val_loss: 1.4667 - val_accuracy: 0.3907\n",
            "Epoch 433/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.5149 - accuracy: 0.7953 - val_loss: 1.4089 - val_accuracy: 0.4570\n",
            "Epoch 434/700\n",
            "85/85 [==============================] - 2s 19ms/step - loss: 0.5286 - accuracy: 0.7960 - val_loss: 1.4296 - val_accuracy: 0.4437\n",
            "Epoch 435/700\n",
            "85/85 [==============================] - 2s 19ms/step - loss: 0.5319 - accuracy: 0.7953 - val_loss: 1.4608 - val_accuracy: 0.4570\n",
            "Epoch 436/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.5384 - accuracy: 0.7967 - val_loss: 1.4525 - val_accuracy: 0.4305\n",
            "Epoch 437/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.5169 - accuracy: 0.8056 - val_loss: 1.5077 - val_accuracy: 0.4238\n",
            "Epoch 438/700\n",
            "85/85 [==============================] - 2s 19ms/step - loss: 0.5224 - accuracy: 0.7916 - val_loss: 1.4529 - val_accuracy: 0.4636\n",
            "Epoch 439/700\n",
            "85/85 [==============================] - 2s 19ms/step - loss: 0.5124 - accuracy: 0.8012 - val_loss: 1.4841 - val_accuracy: 0.4040\n",
            "Epoch 440/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.5338 - accuracy: 0.7967 - val_loss: 1.4840 - val_accuracy: 0.4371\n",
            "Epoch 441/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.5090 - accuracy: 0.7990 - val_loss: 1.4589 - val_accuracy: 0.4238\n",
            "Epoch 442/700\n",
            "85/85 [==============================] - 2s 19ms/step - loss: 0.5220 - accuracy: 0.8012 - val_loss: 1.4879 - val_accuracy: 0.4305\n",
            "Epoch 443/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.5194 - accuracy: 0.8071 - val_loss: 1.4909 - val_accuracy: 0.4437\n",
            "Epoch 444/700\n",
            "85/85 [==============================] - 2s 19ms/step - loss: 0.5070 - accuracy: 0.8160 - val_loss: 1.4333 - val_accuracy: 0.4503\n",
            "Epoch 445/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.5278 - accuracy: 0.7997 - val_loss: 1.4557 - val_accuracy: 0.4305\n",
            "Epoch 446/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.4973 - accuracy: 0.8034 - val_loss: 1.4246 - val_accuracy: 0.4768\n",
            "Epoch 447/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.5075 - accuracy: 0.8027 - val_loss: 1.4683 - val_accuracy: 0.4503\n",
            "Epoch 448/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.5028 - accuracy: 0.8019 - val_loss: 1.4755 - val_accuracy: 0.4437\n",
            "Epoch 449/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.5090 - accuracy: 0.8027 - val_loss: 1.4420 - val_accuracy: 0.4636\n",
            "Epoch 450/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.5069 - accuracy: 0.7967 - val_loss: 1.5120 - val_accuracy: 0.4238\n",
            "Epoch 451/700\n",
            "85/85 [==============================] - 2s 19ms/step - loss: 0.5037 - accuracy: 0.8130 - val_loss: 1.5046 - val_accuracy: 0.4106\n",
            "Epoch 452/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.4967 - accuracy: 0.8152 - val_loss: 1.4540 - val_accuracy: 0.4570\n",
            "Epoch 453/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.5332 - accuracy: 0.8012 - val_loss: 1.4827 - val_accuracy: 0.4636\n",
            "Epoch 454/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.4872 - accuracy: 0.8093 - val_loss: 1.4581 - val_accuracy: 0.4238\n",
            "Epoch 455/700\n",
            "85/85 [==============================] - 2s 19ms/step - loss: 0.4991 - accuracy: 0.8019 - val_loss: 1.4506 - val_accuracy: 0.4238\n",
            "Epoch 456/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.5017 - accuracy: 0.8197 - val_loss: 1.4401 - val_accuracy: 0.4768\n",
            "Epoch 457/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.5114 - accuracy: 0.8012 - val_loss: 1.4398 - val_accuracy: 0.4503\n",
            "Epoch 458/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.5043 - accuracy: 0.8115 - val_loss: 1.4952 - val_accuracy: 0.4172\n",
            "Epoch 459/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.5000 - accuracy: 0.8123 - val_loss: 1.4915 - val_accuracy: 0.4106\n",
            "Epoch 460/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.4894 - accuracy: 0.8197 - val_loss: 1.4968 - val_accuracy: 0.4305\n",
            "Epoch 461/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.5037 - accuracy: 0.7990 - val_loss: 1.4472 - val_accuracy: 0.4636\n",
            "Epoch 462/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.4997 - accuracy: 0.7997 - val_loss: 1.4662 - val_accuracy: 0.4305\n",
            "Epoch 463/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.4991 - accuracy: 0.8086 - val_loss: 1.4602 - val_accuracy: 0.4570\n",
            "Epoch 464/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.4935 - accuracy: 0.8101 - val_loss: 1.4897 - val_accuracy: 0.4305\n",
            "Epoch 465/700\n",
            "85/85 [==============================] - 2s 19ms/step - loss: 0.4959 - accuracy: 0.8123 - val_loss: 1.4826 - val_accuracy: 0.4238\n",
            "Epoch 466/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.5033 - accuracy: 0.7975 - val_loss: 1.4442 - val_accuracy: 0.4702\n",
            "Epoch 467/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.4885 - accuracy: 0.8152 - val_loss: 1.4480 - val_accuracy: 0.4636\n",
            "Epoch 468/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.4965 - accuracy: 0.8041 - val_loss: 1.4454 - val_accuracy: 0.4371\n",
            "Epoch 469/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.4843 - accuracy: 0.8123 - val_loss: 1.4532 - val_accuracy: 0.4702\n",
            "Epoch 470/700\n",
            "85/85 [==============================] - 2s 19ms/step - loss: 0.5026 - accuracy: 0.8027 - val_loss: 1.4528 - val_accuracy: 0.4570\n",
            "Epoch 471/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.4963 - accuracy: 0.8152 - val_loss: 1.4876 - val_accuracy: 0.4371\n",
            "Epoch 472/700\n",
            "85/85 [==============================] - 2s 19ms/step - loss: 0.4773 - accuracy: 0.8197 - val_loss: 1.4638 - val_accuracy: 0.4636\n",
            "Epoch 473/700\n",
            "85/85 [==============================] - 2s 19ms/step - loss: 0.4883 - accuracy: 0.8101 - val_loss: 1.4596 - val_accuracy: 0.4437\n",
            "Epoch 474/700\n",
            "85/85 [==============================] - 2s 19ms/step - loss: 0.4873 - accuracy: 0.8064 - val_loss: 1.5171 - val_accuracy: 0.4172\n",
            "Epoch 475/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.4832 - accuracy: 0.8152 - val_loss: 1.5046 - val_accuracy: 0.4238\n",
            "Epoch 476/700\n",
            "85/85 [==============================] - 2s 19ms/step - loss: 0.4920 - accuracy: 0.8137 - val_loss: 1.4722 - val_accuracy: 0.4967\n",
            "Epoch 477/700\n",
            "85/85 [==============================] - 2s 19ms/step - loss: 0.4746 - accuracy: 0.8174 - val_loss: 1.4841 - val_accuracy: 0.4570\n",
            "Epoch 478/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.4879 - accuracy: 0.8056 - val_loss: 1.4555 - val_accuracy: 0.4901\n",
            "Epoch 479/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.4768 - accuracy: 0.8197 - val_loss: 1.4957 - val_accuracy: 0.4570\n",
            "Epoch 480/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.4749 - accuracy: 0.8152 - val_loss: 1.4796 - val_accuracy: 0.4702\n",
            "Epoch 481/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.4827 - accuracy: 0.8123 - val_loss: 1.5175 - val_accuracy: 0.4570\n",
            "Epoch 482/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.4938 - accuracy: 0.8123 - val_loss: 1.5226 - val_accuracy: 0.4901\n",
            "Epoch 483/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.4617 - accuracy: 0.8271 - val_loss: 1.5137 - val_accuracy: 0.4636\n",
            "Epoch 484/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.4877 - accuracy: 0.8152 - val_loss: 1.5267 - val_accuracy: 0.4371\n",
            "Epoch 485/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.4722 - accuracy: 0.8115 - val_loss: 1.5108 - val_accuracy: 0.4106\n",
            "Epoch 486/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.4809 - accuracy: 0.8101 - val_loss: 1.5141 - val_accuracy: 0.4106\n",
            "Epoch 487/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.4715 - accuracy: 0.8145 - val_loss: 1.4728 - val_accuracy: 0.4636\n",
            "Epoch 488/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.4947 - accuracy: 0.8160 - val_loss: 1.5049 - val_accuracy: 0.4305\n",
            "Epoch 489/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.4705 - accuracy: 0.8174 - val_loss: 1.5224 - val_accuracy: 0.4437\n",
            "Epoch 490/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.4878 - accuracy: 0.8086 - val_loss: 1.5361 - val_accuracy: 0.4172\n",
            "Epoch 491/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.4728 - accuracy: 0.8101 - val_loss: 1.4917 - val_accuracy: 0.4238\n",
            "Epoch 492/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.4516 - accuracy: 0.8322 - val_loss: 1.5295 - val_accuracy: 0.4503\n",
            "Epoch 493/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.4692 - accuracy: 0.8381 - val_loss: 1.4782 - val_accuracy: 0.4503\n",
            "Epoch 494/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.4635 - accuracy: 0.8271 - val_loss: 1.5687 - val_accuracy: 0.4570\n",
            "Epoch 495/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.4737 - accuracy: 0.8130 - val_loss: 1.4764 - val_accuracy: 0.4768\n",
            "Epoch 496/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.4625 - accuracy: 0.8123 - val_loss: 1.5706 - val_accuracy: 0.4437\n",
            "Epoch 497/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.4700 - accuracy: 0.8248 - val_loss: 1.5859 - val_accuracy: 0.4437\n",
            "Epoch 498/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.4838 - accuracy: 0.8101 - val_loss: 1.4819 - val_accuracy: 0.4768\n",
            "Epoch 499/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.4532 - accuracy: 0.8337 - val_loss: 1.4857 - val_accuracy: 0.4238\n",
            "Epoch 500/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.4729 - accuracy: 0.8137 - val_loss: 1.4984 - val_accuracy: 0.4305\n",
            "Epoch 501/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.4474 - accuracy: 0.8234 - val_loss: 1.4939 - val_accuracy: 0.4570\n",
            "Epoch 502/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.4775 - accuracy: 0.8101 - val_loss: 1.4688 - val_accuracy: 0.4768\n",
            "Epoch 503/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.4680 - accuracy: 0.8256 - val_loss: 1.4747 - val_accuracy: 0.4702\n",
            "Epoch 504/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.4634 - accuracy: 0.8226 - val_loss: 1.5122 - val_accuracy: 0.4901\n",
            "Epoch 505/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.4595 - accuracy: 0.8256 - val_loss: 1.5044 - val_accuracy: 0.4371\n",
            "Epoch 506/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.4568 - accuracy: 0.8182 - val_loss: 1.5439 - val_accuracy: 0.4172\n",
            "Epoch 507/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.4676 - accuracy: 0.8204 - val_loss: 1.4766 - val_accuracy: 0.4768\n",
            "Epoch 508/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.4555 - accuracy: 0.8137 - val_loss: 1.4730 - val_accuracy: 0.4570\n",
            "Epoch 509/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.4717 - accuracy: 0.8130 - val_loss: 1.5063 - val_accuracy: 0.4768\n",
            "Epoch 510/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.4602 - accuracy: 0.8204 - val_loss: 1.5740 - val_accuracy: 0.4371\n",
            "Epoch 511/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.4634 - accuracy: 0.8130 - val_loss: 1.5311 - val_accuracy: 0.4238\n",
            "Epoch 512/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.4415 - accuracy: 0.8248 - val_loss: 1.5410 - val_accuracy: 0.4305\n",
            "Epoch 513/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.4578 - accuracy: 0.8152 - val_loss: 1.4990 - val_accuracy: 0.4371\n",
            "Epoch 514/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.4600 - accuracy: 0.8234 - val_loss: 1.5159 - val_accuracy: 0.4702\n",
            "Epoch 515/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.4623 - accuracy: 0.8145 - val_loss: 1.4855 - val_accuracy: 0.4305\n",
            "Epoch 516/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.4630 - accuracy: 0.8197 - val_loss: 1.4944 - val_accuracy: 0.4437\n",
            "Epoch 517/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.4651 - accuracy: 0.8174 - val_loss: 1.4994 - val_accuracy: 0.4238\n",
            "Epoch 518/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.4550 - accuracy: 0.8256 - val_loss: 1.5118 - val_accuracy: 0.4437\n",
            "Epoch 519/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.4537 - accuracy: 0.8189 - val_loss: 1.5110 - val_accuracy: 0.4570\n",
            "Epoch 520/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.4254 - accuracy: 0.8448 - val_loss: 1.5897 - val_accuracy: 0.4238\n",
            "Epoch 521/700\n",
            "85/85 [==============================] - 2s 19ms/step - loss: 0.4504 - accuracy: 0.8278 - val_loss: 1.4980 - val_accuracy: 0.4768\n",
            "Epoch 522/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.4419 - accuracy: 0.8234 - val_loss: 1.5328 - val_accuracy: 0.4570\n",
            "Epoch 523/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.4571 - accuracy: 0.8160 - val_loss: 1.4995 - val_accuracy: 0.4570\n",
            "Epoch 524/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.4458 - accuracy: 0.8300 - val_loss: 1.5244 - val_accuracy: 0.4503\n",
            "Epoch 525/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.4298 - accuracy: 0.8441 - val_loss: 1.6113 - val_accuracy: 0.4371\n",
            "Epoch 526/700\n",
            "85/85 [==============================] - 2s 19ms/step - loss: 0.4561 - accuracy: 0.8219 - val_loss: 1.5862 - val_accuracy: 0.4371\n",
            "Epoch 527/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.4488 - accuracy: 0.8219 - val_loss: 1.5128 - val_accuracy: 0.4305\n",
            "Epoch 528/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.4155 - accuracy: 0.8433 - val_loss: 1.5355 - val_accuracy: 0.4503\n",
            "Epoch 529/700\n",
            "85/85 [==============================] - 2s 19ms/step - loss: 0.4137 - accuracy: 0.8418 - val_loss: 1.5697 - val_accuracy: 0.4305\n",
            "Epoch 530/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.4326 - accuracy: 0.8344 - val_loss: 1.5328 - val_accuracy: 0.4636\n",
            "Epoch 531/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.4270 - accuracy: 0.8374 - val_loss: 1.5603 - val_accuracy: 0.4702\n",
            "Epoch 532/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.4200 - accuracy: 0.8433 - val_loss: 1.5573 - val_accuracy: 0.4967\n",
            "Epoch 533/700\n",
            "85/85 [==============================] - 2s 19ms/step - loss: 0.4569 - accuracy: 0.8182 - val_loss: 1.5361 - val_accuracy: 0.4834\n",
            "Epoch 534/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.4432 - accuracy: 0.8367 - val_loss: 1.6434 - val_accuracy: 0.4040\n",
            "Epoch 535/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.4637 - accuracy: 0.8086 - val_loss: 1.5459 - val_accuracy: 0.4305\n",
            "Epoch 536/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.4422 - accuracy: 0.8322 - val_loss: 1.5499 - val_accuracy: 0.4172\n",
            "Epoch 537/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.4513 - accuracy: 0.8197 - val_loss: 1.5481 - val_accuracy: 0.4768\n",
            "Epoch 538/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.4174 - accuracy: 0.8374 - val_loss: 1.5487 - val_accuracy: 0.4503\n",
            "Epoch 539/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.4338 - accuracy: 0.8389 - val_loss: 1.6561 - val_accuracy: 0.4106\n",
            "Epoch 540/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.4348 - accuracy: 0.8374 - val_loss: 1.6142 - val_accuracy: 0.4305\n",
            "Epoch 541/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.4275 - accuracy: 0.8367 - val_loss: 1.5439 - val_accuracy: 0.4305\n",
            "Epoch 542/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.4409 - accuracy: 0.8330 - val_loss: 1.5819 - val_accuracy: 0.4106\n",
            "Epoch 543/700\n",
            "85/85 [==============================] - 2s 19ms/step - loss: 0.4126 - accuracy: 0.8507 - val_loss: 1.5815 - val_accuracy: 0.4437\n",
            "Epoch 544/700\n",
            "85/85 [==============================] - 2s 19ms/step - loss: 0.4270 - accuracy: 0.8396 - val_loss: 1.5409 - val_accuracy: 0.4503\n",
            "Epoch 545/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.4337 - accuracy: 0.8285 - val_loss: 1.5253 - val_accuracy: 0.4371\n",
            "Epoch 546/700\n",
            "85/85 [==============================] - 2s 19ms/step - loss: 0.4252 - accuracy: 0.8241 - val_loss: 1.6212 - val_accuracy: 0.4305\n",
            "Epoch 547/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.4203 - accuracy: 0.8381 - val_loss: 1.5804 - val_accuracy: 0.4172\n",
            "Epoch 548/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.4356 - accuracy: 0.8300 - val_loss: 1.6275 - val_accuracy: 0.4238\n",
            "Epoch 549/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.4089 - accuracy: 0.8426 - val_loss: 1.5456 - val_accuracy: 0.4437\n",
            "Epoch 550/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.4165 - accuracy: 0.8463 - val_loss: 1.6361 - val_accuracy: 0.4503\n",
            "Epoch 551/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.4084 - accuracy: 0.8500 - val_loss: 1.5704 - val_accuracy: 0.4503\n",
            "Epoch 552/700\n",
            "85/85 [==============================] - 2s 19ms/step - loss: 0.4207 - accuracy: 0.8463 - val_loss: 1.6769 - val_accuracy: 0.4305\n",
            "Epoch 553/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.4172 - accuracy: 0.8477 - val_loss: 1.5858 - val_accuracy: 0.4371\n",
            "Epoch 554/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.4192 - accuracy: 0.8470 - val_loss: 1.6045 - val_accuracy: 0.4768\n",
            "Epoch 555/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.4245 - accuracy: 0.8307 - val_loss: 1.5682 - val_accuracy: 0.4503\n",
            "Epoch 556/700\n",
            "85/85 [==============================] - 2s 19ms/step - loss: 0.4181 - accuracy: 0.8433 - val_loss: 1.5438 - val_accuracy: 0.4570\n",
            "Epoch 557/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.4188 - accuracy: 0.8470 - val_loss: 1.5425 - val_accuracy: 0.4305\n",
            "Epoch 558/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.4048 - accuracy: 0.8485 - val_loss: 1.5208 - val_accuracy: 0.4503\n",
            "Epoch 559/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.4344 - accuracy: 0.8307 - val_loss: 1.6336 - val_accuracy: 0.4040\n",
            "Epoch 560/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.4102 - accuracy: 0.8507 - val_loss: 1.5706 - val_accuracy: 0.4768\n",
            "Epoch 561/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.4176 - accuracy: 0.8418 - val_loss: 1.6383 - val_accuracy: 0.4371\n",
            "Epoch 562/700\n",
            "85/85 [==============================] - 2s 19ms/step - loss: 0.3946 - accuracy: 0.8574 - val_loss: 1.5675 - val_accuracy: 0.4371\n",
            "Epoch 563/700\n",
            "85/85 [==============================] - 2s 19ms/step - loss: 0.4477 - accuracy: 0.8219 - val_loss: 1.5233 - val_accuracy: 0.4437\n",
            "Epoch 564/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.4125 - accuracy: 0.8396 - val_loss: 1.5409 - val_accuracy: 0.4636\n",
            "Epoch 565/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.3985 - accuracy: 0.8551 - val_loss: 1.5269 - val_accuracy: 0.4437\n",
            "Epoch 566/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.4351 - accuracy: 0.8293 - val_loss: 1.5560 - val_accuracy: 0.4371\n",
            "Epoch 567/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.4065 - accuracy: 0.8426 - val_loss: 1.5577 - val_accuracy: 0.4768\n",
            "Epoch 568/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.4129 - accuracy: 0.8411 - val_loss: 1.6013 - val_accuracy: 0.4040\n",
            "Epoch 569/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.4041 - accuracy: 0.8374 - val_loss: 1.5890 - val_accuracy: 0.4503\n",
            "Epoch 570/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.4050 - accuracy: 0.8537 - val_loss: 1.5964 - val_accuracy: 0.4172\n",
            "Epoch 571/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.3949 - accuracy: 0.8559 - val_loss: 1.5558 - val_accuracy: 0.4570\n",
            "Epoch 572/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.3943 - accuracy: 0.8551 - val_loss: 1.5946 - val_accuracy: 0.4901\n",
            "Epoch 573/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.3942 - accuracy: 0.8441 - val_loss: 1.5583 - val_accuracy: 0.4570\n",
            "Epoch 574/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.4103 - accuracy: 0.8396 - val_loss: 1.6410 - val_accuracy: 0.4503\n",
            "Epoch 575/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.4040 - accuracy: 0.8522 - val_loss: 1.5902 - val_accuracy: 0.4238\n",
            "Epoch 576/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.4184 - accuracy: 0.8352 - val_loss: 1.5954 - val_accuracy: 0.4172\n",
            "Epoch 577/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.3952 - accuracy: 0.8514 - val_loss: 1.5462 - val_accuracy: 0.4636\n",
            "Epoch 578/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.3865 - accuracy: 0.8581 - val_loss: 1.5329 - val_accuracy: 0.4570\n",
            "Epoch 579/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.4071 - accuracy: 0.8337 - val_loss: 1.5616 - val_accuracy: 0.4106\n",
            "Epoch 580/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.3920 - accuracy: 0.8500 - val_loss: 1.5925 - val_accuracy: 0.4702\n",
            "Epoch 581/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.3915 - accuracy: 0.8596 - val_loss: 1.6275 - val_accuracy: 0.4305\n",
            "Epoch 582/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.3821 - accuracy: 0.8500 - val_loss: 1.6065 - val_accuracy: 0.4636\n",
            "Epoch 583/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.4090 - accuracy: 0.8448 - val_loss: 1.5698 - val_accuracy: 0.4503\n",
            "Epoch 584/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.3773 - accuracy: 0.8500 - val_loss: 1.5844 - val_accuracy: 0.4371\n",
            "Epoch 585/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.3808 - accuracy: 0.8551 - val_loss: 1.6313 - val_accuracy: 0.4238\n",
            "Epoch 586/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.3974 - accuracy: 0.8470 - val_loss: 1.5955 - val_accuracy: 0.4371\n",
            "Epoch 587/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.3962 - accuracy: 0.8574 - val_loss: 1.5931 - val_accuracy: 0.4437\n",
            "Epoch 588/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.3979 - accuracy: 0.8507 - val_loss: 1.5690 - val_accuracy: 0.4305\n",
            "Epoch 589/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.3899 - accuracy: 0.8522 - val_loss: 1.5857 - val_accuracy: 0.4437\n",
            "Epoch 590/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.4092 - accuracy: 0.8293 - val_loss: 1.5883 - val_accuracy: 0.4305\n",
            "Epoch 591/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.4053 - accuracy: 0.8455 - val_loss: 1.5629 - val_accuracy: 0.4437\n",
            "Epoch 592/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.4142 - accuracy: 0.8433 - val_loss: 1.5800 - val_accuracy: 0.4636\n",
            "Epoch 593/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.4056 - accuracy: 0.8426 - val_loss: 1.6003 - val_accuracy: 0.4305\n",
            "Epoch 594/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.3763 - accuracy: 0.8707 - val_loss: 1.5980 - val_accuracy: 0.4371\n",
            "Epoch 595/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.3969 - accuracy: 0.8492 - val_loss: 1.6330 - val_accuracy: 0.4172\n",
            "Epoch 596/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.3751 - accuracy: 0.8566 - val_loss: 1.5748 - val_accuracy: 0.4702\n",
            "Epoch 597/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.3850 - accuracy: 0.8522 - val_loss: 1.5813 - val_accuracy: 0.4570\n",
            "Epoch 598/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.3985 - accuracy: 0.8529 - val_loss: 1.5750 - val_accuracy: 0.4371\n",
            "Epoch 599/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.4039 - accuracy: 0.8455 - val_loss: 1.5793 - val_accuracy: 0.4570\n",
            "Epoch 600/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.3796 - accuracy: 0.8618 - val_loss: 1.5520 - val_accuracy: 0.4768\n",
            "Epoch 601/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.4000 - accuracy: 0.8418 - val_loss: 1.6021 - val_accuracy: 0.4702\n",
            "Epoch 602/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.3746 - accuracy: 0.8588 - val_loss: 1.5670 - val_accuracy: 0.4437\n",
            "Epoch 603/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.3911 - accuracy: 0.8522 - val_loss: 1.6168 - val_accuracy: 0.4570\n",
            "Epoch 604/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.3723 - accuracy: 0.8655 - val_loss: 1.5620 - val_accuracy: 0.4503\n",
            "Epoch 605/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.3924 - accuracy: 0.8514 - val_loss: 1.6019 - val_accuracy: 0.4503\n",
            "Epoch 606/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.3680 - accuracy: 0.8625 - val_loss: 1.5801 - val_accuracy: 0.4305\n",
            "Epoch 607/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.3915 - accuracy: 0.8566 - val_loss: 1.5776 - val_accuracy: 0.4636\n",
            "Epoch 608/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.3854 - accuracy: 0.8529 - val_loss: 1.6165 - val_accuracy: 0.4238\n",
            "Epoch 609/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.3524 - accuracy: 0.8625 - val_loss: 1.6334 - val_accuracy: 0.4570\n",
            "Epoch 610/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.3762 - accuracy: 0.8662 - val_loss: 1.5767 - val_accuracy: 0.4702\n",
            "Epoch 611/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.3654 - accuracy: 0.8610 - val_loss: 1.5997 - val_accuracy: 0.4503\n",
            "Epoch 612/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.3900 - accuracy: 0.8603 - val_loss: 1.6124 - val_accuracy: 0.4636\n",
            "Epoch 613/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.3693 - accuracy: 0.8588 - val_loss: 1.5591 - val_accuracy: 0.4570\n",
            "Epoch 614/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.3726 - accuracy: 0.8588 - val_loss: 1.5788 - val_accuracy: 0.4636\n",
            "Epoch 615/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.3788 - accuracy: 0.8559 - val_loss: 1.5978 - val_accuracy: 0.4172\n",
            "Epoch 616/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.3891 - accuracy: 0.8492 - val_loss: 1.6417 - val_accuracy: 0.4570\n",
            "Epoch 617/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.3839 - accuracy: 0.8574 - val_loss: 1.5982 - val_accuracy: 0.4503\n",
            "Epoch 618/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.3846 - accuracy: 0.8559 - val_loss: 1.5899 - val_accuracy: 0.4834\n",
            "Epoch 619/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.3680 - accuracy: 0.8559 - val_loss: 1.6109 - val_accuracy: 0.4503\n",
            "Epoch 620/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.3585 - accuracy: 0.8566 - val_loss: 1.6069 - val_accuracy: 0.4570\n",
            "Epoch 621/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.3568 - accuracy: 0.8610 - val_loss: 1.6357 - val_accuracy: 0.4901\n",
            "Epoch 622/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.3615 - accuracy: 0.8537 - val_loss: 1.6030 - val_accuracy: 0.4503\n",
            "Epoch 623/700\n",
            "85/85 [==============================] - 2s 25ms/step - loss: 0.3703 - accuracy: 0.8610 - val_loss: 1.6978 - val_accuracy: 0.4305\n",
            "Epoch 624/700\n",
            "85/85 [==============================] - 3s 31ms/step - loss: 0.3629 - accuracy: 0.8640 - val_loss: 1.6416 - val_accuracy: 0.4768\n",
            "Epoch 625/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.3480 - accuracy: 0.8714 - val_loss: 1.6296 - val_accuracy: 0.4437\n",
            "Epoch 626/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.3637 - accuracy: 0.8633 - val_loss: 1.6008 - val_accuracy: 0.4768\n",
            "Epoch 627/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.3518 - accuracy: 0.8596 - val_loss: 1.6842 - val_accuracy: 0.4437\n",
            "Epoch 628/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.3700 - accuracy: 0.8655 - val_loss: 1.5940 - val_accuracy: 0.4106\n",
            "Epoch 629/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.3498 - accuracy: 0.8647 - val_loss: 1.6904 - val_accuracy: 0.4503\n",
            "Epoch 630/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.3557 - accuracy: 0.8707 - val_loss: 1.6220 - val_accuracy: 0.4702\n",
            "Epoch 631/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.3479 - accuracy: 0.8633 - val_loss: 1.6097 - val_accuracy: 0.4702\n",
            "Epoch 632/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.3654 - accuracy: 0.8662 - val_loss: 1.6929 - val_accuracy: 0.4106\n",
            "Epoch 633/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.3621 - accuracy: 0.8581 - val_loss: 1.6967 - val_accuracy: 0.4106\n",
            "Epoch 634/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.3476 - accuracy: 0.8655 - val_loss: 1.6459 - val_accuracy: 0.4702\n",
            "Epoch 635/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.3703 - accuracy: 0.8670 - val_loss: 1.6674 - val_accuracy: 0.4437\n",
            "Epoch 636/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.3539 - accuracy: 0.8647 - val_loss: 1.6245 - val_accuracy: 0.4503\n",
            "Epoch 637/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.3626 - accuracy: 0.8707 - val_loss: 1.6983 - val_accuracy: 0.3907\n",
            "Epoch 638/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.3743 - accuracy: 0.8544 - val_loss: 1.6907 - val_accuracy: 0.4570\n",
            "Epoch 639/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.3483 - accuracy: 0.8633 - val_loss: 1.6124 - val_accuracy: 0.4570\n",
            "Epoch 640/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.3669 - accuracy: 0.8647 - val_loss: 1.6107 - val_accuracy: 0.4437\n",
            "Epoch 641/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.3645 - accuracy: 0.8514 - val_loss: 1.8199 - val_accuracy: 0.4238\n",
            "Epoch 642/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.3455 - accuracy: 0.8729 - val_loss: 1.6213 - val_accuracy: 0.4106\n",
            "Epoch 643/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.3488 - accuracy: 0.8692 - val_loss: 1.6168 - val_accuracy: 0.4503\n",
            "Epoch 644/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.3542 - accuracy: 0.8751 - val_loss: 1.7364 - val_accuracy: 0.4172\n",
            "Epoch 645/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.3636 - accuracy: 0.8633 - val_loss: 1.6573 - val_accuracy: 0.4570\n",
            "Epoch 646/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.3612 - accuracy: 0.8603 - val_loss: 1.6582 - val_accuracy: 0.4503\n",
            "Epoch 647/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.3729 - accuracy: 0.8610 - val_loss: 1.6315 - val_accuracy: 0.4437\n",
            "Epoch 648/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.3469 - accuracy: 0.8736 - val_loss: 1.6158 - val_accuracy: 0.4503\n",
            "Epoch 649/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.3510 - accuracy: 0.8684 - val_loss: 1.6761 - val_accuracy: 0.4437\n",
            "Epoch 650/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.3361 - accuracy: 0.8699 - val_loss: 1.6417 - val_accuracy: 0.4967\n",
            "Epoch 651/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.3291 - accuracy: 0.8714 - val_loss: 1.6294 - val_accuracy: 0.4371\n",
            "Epoch 652/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.3491 - accuracy: 0.8633 - val_loss: 1.6380 - val_accuracy: 0.4371\n",
            "Epoch 653/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.3575 - accuracy: 0.8647 - val_loss: 1.6548 - val_accuracy: 0.4768\n",
            "Epoch 654/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.3572 - accuracy: 0.8618 - val_loss: 1.6913 - val_accuracy: 0.4570\n",
            "Epoch 655/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.3346 - accuracy: 0.8714 - val_loss: 1.6636 - val_accuracy: 0.4570\n",
            "Epoch 656/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.3570 - accuracy: 0.8670 - val_loss: 1.7236 - val_accuracy: 0.4503\n",
            "Epoch 657/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.3608 - accuracy: 0.8551 - val_loss: 1.6915 - val_accuracy: 0.4371\n",
            "Epoch 658/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.3415 - accuracy: 0.8699 - val_loss: 1.7304 - val_accuracy: 0.4503\n",
            "Epoch 659/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.3473 - accuracy: 0.8692 - val_loss: 1.6888 - val_accuracy: 0.4106\n",
            "Epoch 660/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.3367 - accuracy: 0.8707 - val_loss: 1.7969 - val_accuracy: 0.4305\n",
            "Epoch 661/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.3387 - accuracy: 0.8677 - val_loss: 1.7576 - val_accuracy: 0.4106\n",
            "Epoch 662/700\n",
            "85/85 [==============================] - 2s 19ms/step - loss: 0.3515 - accuracy: 0.8566 - val_loss: 1.7248 - val_accuracy: 0.4570\n",
            "Epoch 663/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.3600 - accuracy: 0.8625 - val_loss: 1.6131 - val_accuracy: 0.4636\n",
            "Epoch 664/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.3387 - accuracy: 0.8714 - val_loss: 1.6861 - val_accuracy: 0.4172\n",
            "Epoch 665/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.3564 - accuracy: 0.8625 - val_loss: 1.6992 - val_accuracy: 0.4238\n",
            "Epoch 666/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.3489 - accuracy: 0.8655 - val_loss: 1.6680 - val_accuracy: 0.4503\n",
            "Epoch 667/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.3229 - accuracy: 0.8810 - val_loss: 1.6771 - val_accuracy: 0.3974\n",
            "Epoch 668/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.3661 - accuracy: 0.8544 - val_loss: 1.6511 - val_accuracy: 0.4570\n",
            "Epoch 669/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.3525 - accuracy: 0.8736 - val_loss: 1.6776 - val_accuracy: 0.4172\n",
            "Epoch 670/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.3466 - accuracy: 0.8699 - val_loss: 1.7700 - val_accuracy: 0.4437\n",
            "Epoch 671/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.3503 - accuracy: 0.8707 - val_loss: 1.6812 - val_accuracy: 0.4636\n",
            "Epoch 672/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.3294 - accuracy: 0.8773 - val_loss: 1.6949 - val_accuracy: 0.4371\n",
            "Epoch 673/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.3365 - accuracy: 0.8736 - val_loss: 1.7123 - val_accuracy: 0.4437\n",
            "Epoch 674/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.3466 - accuracy: 0.8655 - val_loss: 1.7851 - val_accuracy: 0.4371\n",
            "Epoch 675/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.3454 - accuracy: 0.8633 - val_loss: 1.7895 - val_accuracy: 0.4636\n",
            "Epoch 676/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.3127 - accuracy: 0.8869 - val_loss: 1.6545 - val_accuracy: 0.4636\n",
            "Epoch 677/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.3303 - accuracy: 0.8699 - val_loss: 1.6856 - val_accuracy: 0.4238\n",
            "Epoch 678/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.3217 - accuracy: 0.8862 - val_loss: 1.6916 - val_accuracy: 0.4503\n",
            "Epoch 679/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.3402 - accuracy: 0.8803 - val_loss: 1.7041 - val_accuracy: 0.4305\n",
            "Epoch 680/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.3229 - accuracy: 0.8795 - val_loss: 1.6892 - val_accuracy: 0.4702\n",
            "Epoch 681/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.3205 - accuracy: 0.8840 - val_loss: 1.7025 - val_accuracy: 0.4172\n",
            "Epoch 682/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.3362 - accuracy: 0.8810 - val_loss: 1.7128 - val_accuracy: 0.4305\n",
            "Epoch 683/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.3436 - accuracy: 0.8721 - val_loss: 1.6758 - val_accuracy: 0.4371\n",
            "Epoch 684/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.3086 - accuracy: 0.8899 - val_loss: 1.6904 - val_accuracy: 0.4371\n",
            "Epoch 685/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.3563 - accuracy: 0.8633 - val_loss: 1.7405 - val_accuracy: 0.4437\n",
            "Epoch 686/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.3233 - accuracy: 0.8729 - val_loss: 1.6602 - val_accuracy: 0.4570\n",
            "Epoch 687/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.3177 - accuracy: 0.8795 - val_loss: 1.6885 - val_accuracy: 0.4636\n",
            "Epoch 688/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.3275 - accuracy: 0.8832 - val_loss: 1.7010 - val_accuracy: 0.4636\n",
            "Epoch 689/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.3292 - accuracy: 0.8744 - val_loss: 1.7230 - val_accuracy: 0.4503\n",
            "Epoch 690/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.3391 - accuracy: 0.8744 - val_loss: 1.7712 - val_accuracy: 0.4834\n",
            "Epoch 691/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.3187 - accuracy: 0.8914 - val_loss: 1.7045 - val_accuracy: 0.4371\n",
            "Epoch 692/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.3227 - accuracy: 0.8729 - val_loss: 1.7081 - val_accuracy: 0.4503\n",
            "Epoch 693/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.3211 - accuracy: 0.8877 - val_loss: 1.7232 - val_accuracy: 0.4636\n",
            "Epoch 694/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.3143 - accuracy: 0.8936 - val_loss: 1.6686 - val_accuracy: 0.4636\n",
            "Epoch 695/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.3355 - accuracy: 0.8655 - val_loss: 1.8033 - val_accuracy: 0.4570\n",
            "Epoch 696/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.3258 - accuracy: 0.8810 - val_loss: 1.7458 - val_accuracy: 0.4503\n",
            "Epoch 697/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.3307 - accuracy: 0.8817 - val_loss: 1.7157 - val_accuracy: 0.4570\n",
            "Epoch 698/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.3289 - accuracy: 0.8729 - val_loss: 1.6885 - val_accuracy: 0.4570\n",
            "Epoch 699/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.3265 - accuracy: 0.8758 - val_loss: 1.7069 - val_accuracy: 0.4570\n",
            "Epoch 700/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.3148 - accuracy: 0.8788 - val_loss: 1.6821 - val_accuracy: 0.4636\n",
            "0.717471229412726\n",
            "accuracy: 71.81%\n",
            "Epoch 1/700\n",
            "85/85 [==============================] - 3s 23ms/step - loss: 1.7404 - accuracy: 0.1803 - val_loss: 1.6375 - val_accuracy: 0.1788\n",
            "Epoch 2/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 1.6415 - accuracy: 0.2069 - val_loss: 1.6273 - val_accuracy: 0.2119\n",
            "Epoch 3/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 1.6345 - accuracy: 0.2025 - val_loss: 1.6114 - val_accuracy: 0.2119\n",
            "Epoch 4/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 1.6302 - accuracy: 0.2084 - val_loss: 1.6075 - val_accuracy: 0.2119\n",
            "Epoch 5/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 1.6351 - accuracy: 0.2106 - val_loss: 1.6171 - val_accuracy: 0.1788\n",
            "Epoch 6/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 1.6286 - accuracy: 0.2173 - val_loss: 1.6179 - val_accuracy: 0.1921\n",
            "Epoch 7/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 1.6319 - accuracy: 0.2062 - val_loss: 1.6087 - val_accuracy: 0.2119\n",
            "Epoch 8/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 1.6182 - accuracy: 0.2299 - val_loss: 1.6085 - val_accuracy: 0.1788\n",
            "Epoch 9/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 1.6230 - accuracy: 0.2077 - val_loss: 1.6049 - val_accuracy: 0.1788\n",
            "Epoch 10/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 1.6195 - accuracy: 0.2084 - val_loss: 1.5951 - val_accuracy: 0.2185\n",
            "Epoch 11/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 1.6112 - accuracy: 0.2188 - val_loss: 1.5909 - val_accuracy: 0.3245\n",
            "Epoch 12/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 1.6067 - accuracy: 0.2506 - val_loss: 1.5837 - val_accuracy: 0.2781\n",
            "Epoch 13/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 1.6065 - accuracy: 0.2225 - val_loss: 1.5802 - val_accuracy: 0.3245\n",
            "Epoch 14/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 1.5954 - accuracy: 0.2520 - val_loss: 1.5699 - val_accuracy: 0.2517\n",
            "Epoch 15/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 1.6041 - accuracy: 0.2528 - val_loss: 1.5661 - val_accuracy: 0.2649\n",
            "Epoch 16/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 1.5897 - accuracy: 0.2542 - val_loss: 1.5598 - val_accuracy: 0.3046\n",
            "Epoch 17/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 1.5798 - accuracy: 0.2676 - val_loss: 1.5575 - val_accuracy: 0.2252\n",
            "Epoch 18/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 1.5801 - accuracy: 0.2579 - val_loss: 1.5377 - val_accuracy: 0.3907\n",
            "Epoch 19/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 1.5676 - accuracy: 0.2949 - val_loss: 1.5352 - val_accuracy: 0.3444\n",
            "Epoch 20/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 1.5659 - accuracy: 0.2882 - val_loss: 1.5243 - val_accuracy: 0.3510\n",
            "Epoch 21/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 1.5592 - accuracy: 0.2853 - val_loss: 1.5336 - val_accuracy: 0.3046\n",
            "Epoch 22/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 1.5476 - accuracy: 0.2860 - val_loss: 1.5136 - val_accuracy: 0.3576\n",
            "Epoch 23/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 1.5409 - accuracy: 0.3038 - val_loss: 1.5004 - val_accuracy: 0.4040\n",
            "Epoch 24/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 1.5309 - accuracy: 0.3082 - val_loss: 1.5031 - val_accuracy: 0.3444\n",
            "Epoch 25/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 1.5245 - accuracy: 0.3274 - val_loss: 1.4877 - val_accuracy: 0.3841\n",
            "Epoch 26/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 1.5147 - accuracy: 0.3171 - val_loss: 1.5054 - val_accuracy: 0.3046\n",
            "Epoch 27/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 1.5115 - accuracy: 0.3245 - val_loss: 1.4750 - val_accuracy: 0.3974\n",
            "Epoch 28/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 1.5138 - accuracy: 0.3075 - val_loss: 1.4957 - val_accuracy: 0.3377\n",
            "Epoch 29/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 1.5033 - accuracy: 0.3230 - val_loss: 1.4782 - val_accuracy: 0.3907\n",
            "Epoch 30/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 1.5003 - accuracy: 0.3296 - val_loss: 1.4708 - val_accuracy: 0.3907\n",
            "Epoch 31/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 1.4826 - accuracy: 0.3452 - val_loss: 1.4546 - val_accuracy: 0.4238\n",
            "Epoch 32/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 1.4714 - accuracy: 0.3489 - val_loss: 1.4461 - val_accuracy: 0.4106\n",
            "Epoch 33/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 1.4663 - accuracy: 0.3607 - val_loss: 1.4501 - val_accuracy: 0.3907\n",
            "Epoch 34/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 1.4580 - accuracy: 0.3548 - val_loss: 1.4506 - val_accuracy: 0.3907\n",
            "Epoch 35/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 1.4430 - accuracy: 0.3762 - val_loss: 1.4350 - val_accuracy: 0.4106\n",
            "Epoch 36/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 1.4491 - accuracy: 0.3548 - val_loss: 1.4361 - val_accuracy: 0.4570\n",
            "Epoch 37/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 1.4404 - accuracy: 0.3725 - val_loss: 1.4322 - val_accuracy: 0.4172\n",
            "Epoch 38/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 1.4258 - accuracy: 0.3821 - val_loss: 1.4496 - val_accuracy: 0.3775\n",
            "Epoch 39/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 1.4219 - accuracy: 0.3843 - val_loss: 1.4375 - val_accuracy: 0.4106\n",
            "Epoch 40/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 1.4120 - accuracy: 0.4028 - val_loss: 1.4291 - val_accuracy: 0.4305\n",
            "Epoch 41/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 1.4082 - accuracy: 0.3858 - val_loss: 1.4099 - val_accuracy: 0.4371\n",
            "Epoch 42/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 1.3987 - accuracy: 0.3939 - val_loss: 1.4388 - val_accuracy: 0.4040\n",
            "Epoch 43/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 1.3850 - accuracy: 0.3976 - val_loss: 1.4111 - val_accuracy: 0.4305\n",
            "Epoch 44/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 1.3858 - accuracy: 0.4043 - val_loss: 1.3966 - val_accuracy: 0.4503\n",
            "Epoch 45/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 1.3812 - accuracy: 0.4080 - val_loss: 1.4107 - val_accuracy: 0.4305\n",
            "Epoch 46/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 1.3588 - accuracy: 0.4339 - val_loss: 1.3935 - val_accuracy: 0.4570\n",
            "Epoch 47/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 1.3611 - accuracy: 0.4257 - val_loss: 1.4539 - val_accuracy: 0.4040\n",
            "Epoch 48/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 1.3518 - accuracy: 0.4087 - val_loss: 1.3952 - val_accuracy: 0.4238\n",
            "Epoch 49/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 1.3532 - accuracy: 0.4242 - val_loss: 1.4082 - val_accuracy: 0.3709\n",
            "Epoch 50/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 1.3381 - accuracy: 0.4309 - val_loss: 1.3792 - val_accuracy: 0.4371\n",
            "Epoch 51/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 1.3258 - accuracy: 0.4390 - val_loss: 1.4002 - val_accuracy: 0.4238\n",
            "Epoch 52/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 1.3192 - accuracy: 0.4516 - val_loss: 1.3756 - val_accuracy: 0.4768\n",
            "Epoch 53/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 1.3174 - accuracy: 0.4531 - val_loss: 1.4008 - val_accuracy: 0.4238\n",
            "Epoch 54/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 1.3130 - accuracy: 0.4627 - val_loss: 1.3689 - val_accuracy: 0.4636\n",
            "Epoch 55/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 1.3004 - accuracy: 0.4664 - val_loss: 1.3946 - val_accuracy: 0.4901\n",
            "Epoch 56/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 1.2966 - accuracy: 0.4649 - val_loss: 1.3819 - val_accuracy: 0.4305\n",
            "Epoch 57/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 1.2817 - accuracy: 0.4863 - val_loss: 1.4040 - val_accuracy: 0.4305\n",
            "Epoch 58/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 1.2829 - accuracy: 0.4760 - val_loss: 1.4050 - val_accuracy: 0.4901\n",
            "Epoch 59/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 1.2742 - accuracy: 0.4930 - val_loss: 1.3801 - val_accuracy: 0.4901\n",
            "Epoch 60/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 1.2579 - accuracy: 0.4885 - val_loss: 1.3721 - val_accuracy: 0.4503\n",
            "Epoch 61/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 1.2647 - accuracy: 0.4745 - val_loss: 1.3834 - val_accuracy: 0.4834\n",
            "Epoch 62/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 1.2531 - accuracy: 0.4797 - val_loss: 1.3876 - val_accuracy: 0.4371\n",
            "Epoch 63/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 1.2490 - accuracy: 0.4686 - val_loss: 1.4141 - val_accuracy: 0.3907\n",
            "Epoch 64/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 1.2416 - accuracy: 0.4952 - val_loss: 1.3580 - val_accuracy: 0.4834\n",
            "Epoch 65/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 1.2240 - accuracy: 0.4959 - val_loss: 1.3748 - val_accuracy: 0.4901\n",
            "Epoch 66/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 1.2192 - accuracy: 0.5129 - val_loss: 1.3799 - val_accuracy: 0.4503\n",
            "Epoch 67/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 1.2260 - accuracy: 0.5063 - val_loss: 1.3822 - val_accuracy: 0.4437\n",
            "Epoch 68/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 1.2146 - accuracy: 0.5026 - val_loss: 1.3904 - val_accuracy: 0.4238\n",
            "Epoch 69/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 1.2091 - accuracy: 0.5322 - val_loss: 1.3603 - val_accuracy: 0.4636\n",
            "Epoch 70/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 1.1938 - accuracy: 0.5322 - val_loss: 1.3672 - val_accuracy: 0.4702\n",
            "Epoch 71/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 1.1918 - accuracy: 0.5174 - val_loss: 1.3828 - val_accuracy: 0.4238\n",
            "Epoch 72/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 1.1824 - accuracy: 0.5262 - val_loss: 1.3708 - val_accuracy: 0.4636\n",
            "Epoch 73/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 1.1865 - accuracy: 0.5233 - val_loss: 1.3678 - val_accuracy: 0.4702\n",
            "Epoch 74/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 1.1767 - accuracy: 0.5233 - val_loss: 1.3719 - val_accuracy: 0.4702\n",
            "Epoch 75/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 1.1738 - accuracy: 0.5196 - val_loss: 1.3584 - val_accuracy: 0.4636\n",
            "Epoch 76/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 1.1655 - accuracy: 0.5285 - val_loss: 1.3731 - val_accuracy: 0.4238\n",
            "Epoch 77/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 1.1548 - accuracy: 0.5322 - val_loss: 1.3691 - val_accuracy: 0.4106\n",
            "Epoch 78/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 1.1491 - accuracy: 0.5329 - val_loss: 1.3558 - val_accuracy: 0.4371\n",
            "Epoch 79/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 1.1480 - accuracy: 0.5432 - val_loss: 1.3602 - val_accuracy: 0.4503\n",
            "Epoch 80/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 1.1402 - accuracy: 0.5595 - val_loss: 1.3621 - val_accuracy: 0.4503\n",
            "Epoch 81/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 1.1350 - accuracy: 0.5492 - val_loss: 1.3526 - val_accuracy: 0.4570\n",
            "Epoch 82/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 1.1305 - accuracy: 0.5440 - val_loss: 1.3697 - val_accuracy: 0.4570\n",
            "Epoch 83/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 1.1331 - accuracy: 0.5418 - val_loss: 1.3640 - val_accuracy: 0.4570\n",
            "Epoch 84/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 1.1182 - accuracy: 0.5610 - val_loss: 1.3722 - val_accuracy: 0.4040\n",
            "Epoch 85/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 1.1175 - accuracy: 0.5536 - val_loss: 1.3411 - val_accuracy: 0.4437\n",
            "Epoch 86/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 1.1124 - accuracy: 0.5543 - val_loss: 1.3599 - val_accuracy: 0.4636\n",
            "Epoch 87/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 1.1053 - accuracy: 0.5654 - val_loss: 1.3587 - val_accuracy: 0.4437\n",
            "Epoch 88/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 1.0949 - accuracy: 0.5647 - val_loss: 1.3231 - val_accuracy: 0.4702\n",
            "Epoch 89/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 1.0858 - accuracy: 0.5676 - val_loss: 1.3233 - val_accuracy: 0.4371\n",
            "Epoch 90/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 1.0934 - accuracy: 0.5536 - val_loss: 1.3691 - val_accuracy: 0.4305\n",
            "Epoch 91/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 1.0854 - accuracy: 0.5610 - val_loss: 1.3378 - val_accuracy: 0.4636\n",
            "Epoch 92/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 1.0815 - accuracy: 0.5765 - val_loss: 1.3336 - val_accuracy: 0.4834\n",
            "Epoch 93/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 1.0721 - accuracy: 0.5654 - val_loss: 1.3380 - val_accuracy: 0.4305\n",
            "Epoch 94/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 1.0677 - accuracy: 0.5750 - val_loss: 1.3334 - val_accuracy: 0.4437\n",
            "Epoch 95/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 1.0695 - accuracy: 0.5795 - val_loss: 1.3309 - val_accuracy: 0.3974\n",
            "Epoch 96/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 1.0709 - accuracy: 0.5802 - val_loss: 1.3365 - val_accuracy: 0.4238\n",
            "Epoch 97/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 1.0414 - accuracy: 0.5861 - val_loss: 1.3271 - val_accuracy: 0.4437\n",
            "Epoch 98/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 1.0568 - accuracy: 0.5780 - val_loss: 1.3673 - val_accuracy: 0.4570\n",
            "Epoch 99/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 1.0578 - accuracy: 0.5839 - val_loss: 1.3545 - val_accuracy: 0.4371\n",
            "Epoch 100/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 1.0465 - accuracy: 0.5802 - val_loss: 1.3396 - val_accuracy: 0.4636\n",
            "Epoch 101/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 1.0563 - accuracy: 0.5839 - val_loss: 1.3717 - val_accuracy: 0.3642\n",
            "Epoch 102/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 1.0500 - accuracy: 0.5706 - val_loss: 1.3465 - val_accuracy: 0.4371\n",
            "Epoch 103/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 1.0293 - accuracy: 0.5898 - val_loss: 1.3595 - val_accuracy: 0.4503\n",
            "Epoch 104/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 1.0495 - accuracy: 0.5809 - val_loss: 1.3455 - val_accuracy: 0.3974\n",
            "Epoch 105/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 1.0292 - accuracy: 0.5957 - val_loss: 1.3501 - val_accuracy: 0.4305\n",
            "Epoch 106/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 1.0424 - accuracy: 0.5854 - val_loss: 1.3955 - val_accuracy: 0.4305\n",
            "Epoch 107/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 1.0258 - accuracy: 0.5824 - val_loss: 1.3249 - val_accuracy: 0.4305\n",
            "Epoch 108/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 1.0290 - accuracy: 0.5935 - val_loss: 1.3351 - val_accuracy: 0.4238\n",
            "Epoch 109/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 1.0132 - accuracy: 0.5994 - val_loss: 1.3630 - val_accuracy: 0.4570\n",
            "Epoch 110/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 1.0290 - accuracy: 0.5772 - val_loss: 1.3424 - val_accuracy: 0.4040\n",
            "Epoch 111/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 1.0137 - accuracy: 0.5920 - val_loss: 1.3445 - val_accuracy: 0.4172\n",
            "Epoch 112/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 1.0208 - accuracy: 0.5898 - val_loss: 1.3518 - val_accuracy: 0.3974\n",
            "Epoch 113/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 1.0067 - accuracy: 0.5950 - val_loss: 1.3658 - val_accuracy: 0.4305\n",
            "Epoch 114/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.9973 - accuracy: 0.5898 - val_loss: 1.3817 - val_accuracy: 0.3974\n",
            "Epoch 115/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 1.0025 - accuracy: 0.5928 - val_loss: 1.3487 - val_accuracy: 0.4040\n",
            "Epoch 116/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.9949 - accuracy: 0.6061 - val_loss: 1.3464 - val_accuracy: 0.4106\n",
            "Epoch 117/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.9950 - accuracy: 0.5913 - val_loss: 1.3215 - val_accuracy: 0.3974\n",
            "Epoch 118/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 1.0033 - accuracy: 0.5965 - val_loss: 1.3191 - val_accuracy: 0.4437\n",
            "Epoch 119/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.9930 - accuracy: 0.6053 - val_loss: 1.3158 - val_accuracy: 0.4437\n",
            "Epoch 120/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.9957 - accuracy: 0.5743 - val_loss: 1.3393 - val_accuracy: 0.4040\n",
            "Epoch 121/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.9921 - accuracy: 0.5987 - val_loss: 1.3401 - val_accuracy: 0.3841\n",
            "Epoch 122/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.9779 - accuracy: 0.6061 - val_loss: 1.4160 - val_accuracy: 0.3510\n",
            "Epoch 123/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.9629 - accuracy: 0.6157 - val_loss: 1.3351 - val_accuracy: 0.3907\n",
            "Epoch 124/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.9842 - accuracy: 0.5979 - val_loss: 1.3221 - val_accuracy: 0.4106\n",
            "Epoch 125/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.9757 - accuracy: 0.6016 - val_loss: 1.3361 - val_accuracy: 0.4503\n",
            "Epoch 126/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.9630 - accuracy: 0.6135 - val_loss: 1.3343 - val_accuracy: 0.4437\n",
            "Epoch 127/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.9792 - accuracy: 0.6009 - val_loss: 1.3434 - val_accuracy: 0.3974\n",
            "Epoch 128/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.9649 - accuracy: 0.6090 - val_loss: 1.3425 - val_accuracy: 0.4040\n",
            "Epoch 129/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.9626 - accuracy: 0.6171 - val_loss: 1.3195 - val_accuracy: 0.4305\n",
            "Epoch 130/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.9703 - accuracy: 0.6135 - val_loss: 1.3142 - val_accuracy: 0.4238\n",
            "Epoch 131/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.9665 - accuracy: 0.6024 - val_loss: 1.3205 - val_accuracy: 0.4238\n",
            "Epoch 132/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.9551 - accuracy: 0.6186 - val_loss: 1.3307 - val_accuracy: 0.4305\n",
            "Epoch 133/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.9497 - accuracy: 0.6186 - val_loss: 1.3421 - val_accuracy: 0.3841\n",
            "Epoch 134/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.9697 - accuracy: 0.6083 - val_loss: 1.3018 - val_accuracy: 0.4437\n",
            "Epoch 135/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.9447 - accuracy: 0.6253 - val_loss: 1.3091 - val_accuracy: 0.4768\n",
            "Epoch 136/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.9536 - accuracy: 0.6149 - val_loss: 1.3215 - val_accuracy: 0.4106\n",
            "Epoch 137/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.9433 - accuracy: 0.6297 - val_loss: 1.3185 - val_accuracy: 0.4172\n",
            "Epoch 138/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.9580 - accuracy: 0.6149 - val_loss: 1.3300 - val_accuracy: 0.4106\n",
            "Epoch 139/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.9564 - accuracy: 0.6149 - val_loss: 1.3218 - val_accuracy: 0.4040\n",
            "Epoch 140/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.9482 - accuracy: 0.6223 - val_loss: 1.3362 - val_accuracy: 0.3841\n",
            "Epoch 141/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.9342 - accuracy: 0.6194 - val_loss: 1.3372 - val_accuracy: 0.4238\n",
            "Epoch 142/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.9429 - accuracy: 0.6231 - val_loss: 1.3266 - val_accuracy: 0.4106\n",
            "Epoch 143/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.9445 - accuracy: 0.6186 - val_loss: 1.3317 - val_accuracy: 0.4238\n",
            "Epoch 144/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.9382 - accuracy: 0.6201 - val_loss: 1.3035 - val_accuracy: 0.4371\n",
            "Epoch 145/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.9328 - accuracy: 0.6157 - val_loss: 1.3405 - val_accuracy: 0.4238\n",
            "Epoch 146/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.9251 - accuracy: 0.6268 - val_loss: 1.3169 - val_accuracy: 0.4040\n",
            "Epoch 147/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.9384 - accuracy: 0.6046 - val_loss: 1.3464 - val_accuracy: 0.4305\n",
            "Epoch 148/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.9204 - accuracy: 0.6460 - val_loss: 1.3440 - val_accuracy: 0.3841\n",
            "Epoch 149/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.9183 - accuracy: 0.6356 - val_loss: 1.3272 - val_accuracy: 0.4768\n",
            "Epoch 150/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.9191 - accuracy: 0.6415 - val_loss: 1.3389 - val_accuracy: 0.3974\n",
            "Epoch 151/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.9135 - accuracy: 0.6386 - val_loss: 1.3302 - val_accuracy: 0.4040\n",
            "Epoch 152/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.9202 - accuracy: 0.6378 - val_loss: 1.3083 - val_accuracy: 0.4040\n",
            "Epoch 153/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.9068 - accuracy: 0.6371 - val_loss: 1.3252 - val_accuracy: 0.4305\n",
            "Epoch 154/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.9098 - accuracy: 0.6238 - val_loss: 1.3011 - val_accuracy: 0.4371\n",
            "Epoch 155/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.9141 - accuracy: 0.6341 - val_loss: 1.3094 - val_accuracy: 0.4106\n",
            "Epoch 156/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.9097 - accuracy: 0.6349 - val_loss: 1.3343 - val_accuracy: 0.3974\n",
            "Epoch 157/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.9036 - accuracy: 0.6378 - val_loss: 1.3160 - val_accuracy: 0.4570\n",
            "Epoch 158/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.9212 - accuracy: 0.6260 - val_loss: 1.2964 - val_accuracy: 0.4305\n",
            "Epoch 159/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.9070 - accuracy: 0.6415 - val_loss: 1.3233 - val_accuracy: 0.4371\n",
            "Epoch 160/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.8956 - accuracy: 0.6179 - val_loss: 1.2937 - val_accuracy: 0.4371\n",
            "Epoch 161/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.9030 - accuracy: 0.6349 - val_loss: 1.3223 - val_accuracy: 0.4040\n",
            "Epoch 162/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.8958 - accuracy: 0.6408 - val_loss: 1.2910 - val_accuracy: 0.4437\n",
            "Epoch 163/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.9084 - accuracy: 0.6171 - val_loss: 1.2882 - val_accuracy: 0.4172\n",
            "Epoch 164/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.8858 - accuracy: 0.6475 - val_loss: 1.3103 - val_accuracy: 0.3907\n",
            "Epoch 165/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.9104 - accuracy: 0.6319 - val_loss: 1.3135 - val_accuracy: 0.4371\n",
            "Epoch 166/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.8802 - accuracy: 0.6548 - val_loss: 1.3354 - val_accuracy: 0.4901\n",
            "Epoch 167/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.8947 - accuracy: 0.6386 - val_loss: 1.3256 - val_accuracy: 0.4172\n",
            "Epoch 168/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.8945 - accuracy: 0.6475 - val_loss: 1.3124 - val_accuracy: 0.3907\n",
            "Epoch 169/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.8776 - accuracy: 0.6541 - val_loss: 1.3505 - val_accuracy: 0.3775\n",
            "Epoch 170/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.8717 - accuracy: 0.6504 - val_loss: 1.2889 - val_accuracy: 0.4570\n",
            "Epoch 171/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.8807 - accuracy: 0.6460 - val_loss: 1.2855 - val_accuracy: 0.4238\n",
            "Epoch 172/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.8783 - accuracy: 0.6526 - val_loss: 1.3161 - val_accuracy: 0.4305\n",
            "Epoch 173/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.8573 - accuracy: 0.6763 - val_loss: 1.3476 - val_accuracy: 0.4702\n",
            "Epoch 174/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.8740 - accuracy: 0.6430 - val_loss: 1.2942 - val_accuracy: 0.4834\n",
            "Epoch 175/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.8784 - accuracy: 0.6445 - val_loss: 1.3261 - val_accuracy: 0.4172\n",
            "Epoch 176/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.8691 - accuracy: 0.6630 - val_loss: 1.3156 - val_accuracy: 0.4437\n",
            "Epoch 177/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.8632 - accuracy: 0.6526 - val_loss: 1.3111 - val_accuracy: 0.4172\n",
            "Epoch 178/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.8620 - accuracy: 0.6534 - val_loss: 1.2898 - val_accuracy: 0.4768\n",
            "Epoch 179/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.8680 - accuracy: 0.6341 - val_loss: 1.2966 - val_accuracy: 0.4238\n",
            "Epoch 180/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.8684 - accuracy: 0.6497 - val_loss: 1.3139 - val_accuracy: 0.4371\n",
            "Epoch 181/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.8581 - accuracy: 0.6652 - val_loss: 1.3316 - val_accuracy: 0.3377\n",
            "Epoch 182/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.8541 - accuracy: 0.6511 - val_loss: 1.3086 - val_accuracy: 0.3841\n",
            "Epoch 183/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.8623 - accuracy: 0.6423 - val_loss: 1.3063 - val_accuracy: 0.4238\n",
            "Epoch 184/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.8600 - accuracy: 0.6541 - val_loss: 1.3224 - val_accuracy: 0.4305\n",
            "Epoch 185/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.8701 - accuracy: 0.6585 - val_loss: 1.3219 - val_accuracy: 0.4305\n",
            "Epoch 186/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.8481 - accuracy: 0.6630 - val_loss: 1.3037 - val_accuracy: 0.4371\n",
            "Epoch 187/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.8600 - accuracy: 0.6681 - val_loss: 1.3221 - val_accuracy: 0.4305\n",
            "Epoch 188/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.8638 - accuracy: 0.6541 - val_loss: 1.2905 - val_accuracy: 0.4238\n",
            "Epoch 189/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.8340 - accuracy: 0.6674 - val_loss: 1.2997 - val_accuracy: 0.4834\n",
            "Epoch 190/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.8473 - accuracy: 0.6556 - val_loss: 1.2816 - val_accuracy: 0.4570\n",
            "Epoch 191/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.8610 - accuracy: 0.6600 - val_loss: 1.2900 - val_accuracy: 0.4238\n",
            "Epoch 192/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.8238 - accuracy: 0.6741 - val_loss: 1.2979 - val_accuracy: 0.4172\n",
            "Epoch 193/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.8318 - accuracy: 0.6681 - val_loss: 1.2886 - val_accuracy: 0.4305\n",
            "Epoch 194/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.8293 - accuracy: 0.6644 - val_loss: 1.3327 - val_accuracy: 0.3974\n",
            "Epoch 195/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.8361 - accuracy: 0.6497 - val_loss: 1.2990 - val_accuracy: 0.4238\n",
            "Epoch 196/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.8311 - accuracy: 0.6681 - val_loss: 1.2913 - val_accuracy: 0.4702\n",
            "Epoch 197/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.8389 - accuracy: 0.6822 - val_loss: 1.3067 - val_accuracy: 0.4106\n",
            "Epoch 198/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.8269 - accuracy: 0.6689 - val_loss: 1.2748 - val_accuracy: 0.4636\n",
            "Epoch 199/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.8381 - accuracy: 0.6674 - val_loss: 1.2876 - val_accuracy: 0.4106\n",
            "Epoch 200/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.8315 - accuracy: 0.6748 - val_loss: 1.2705 - val_accuracy: 0.4172\n",
            "Epoch 201/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.8196 - accuracy: 0.6667 - val_loss: 1.2815 - val_accuracy: 0.4238\n",
            "Epoch 202/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.8229 - accuracy: 0.6593 - val_loss: 1.2803 - val_accuracy: 0.4172\n",
            "Epoch 203/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.8315 - accuracy: 0.6778 - val_loss: 1.3218 - val_accuracy: 0.4172\n",
            "Epoch 204/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.8106 - accuracy: 0.6674 - val_loss: 1.2839 - val_accuracy: 0.4636\n",
            "Epoch 205/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.8190 - accuracy: 0.6704 - val_loss: 1.2699 - val_accuracy: 0.4305\n",
            "Epoch 206/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.8100 - accuracy: 0.6837 - val_loss: 1.2726 - val_accuracy: 0.4305\n",
            "Epoch 207/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.8146 - accuracy: 0.6763 - val_loss: 1.2727 - val_accuracy: 0.5033\n",
            "Epoch 208/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.8253 - accuracy: 0.6748 - val_loss: 1.2774 - val_accuracy: 0.4305\n",
            "Epoch 209/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.8129 - accuracy: 0.6896 - val_loss: 1.3285 - val_accuracy: 0.3974\n",
            "Epoch 210/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.7911 - accuracy: 0.6822 - val_loss: 1.3074 - val_accuracy: 0.4238\n",
            "Epoch 211/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.7984 - accuracy: 0.6829 - val_loss: 1.2719 - val_accuracy: 0.4437\n",
            "Epoch 212/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.8138 - accuracy: 0.6689 - val_loss: 1.3094 - val_accuracy: 0.4172\n",
            "Epoch 213/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.8074 - accuracy: 0.6844 - val_loss: 1.2942 - val_accuracy: 0.4172\n",
            "Epoch 214/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.8086 - accuracy: 0.6822 - val_loss: 1.3074 - val_accuracy: 0.4172\n",
            "Epoch 215/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.7929 - accuracy: 0.6859 - val_loss: 1.2833 - val_accuracy: 0.4636\n",
            "Epoch 216/700\n",
            "85/85 [==============================] - 2s 20ms/step - loss: 0.8094 - accuracy: 0.6918 - val_loss: 1.2889 - val_accuracy: 0.4172\n",
            "Epoch 217/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.8018 - accuracy: 0.6925 - val_loss: 1.3050 - val_accuracy: 0.4238\n",
            "Epoch 218/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.7961 - accuracy: 0.6955 - val_loss: 1.3172 - val_accuracy: 0.3974\n",
            "Epoch 219/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.7919 - accuracy: 0.7021 - val_loss: 1.2785 - val_accuracy: 0.4371\n",
            "Epoch 220/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.7879 - accuracy: 0.6770 - val_loss: 1.3044 - val_accuracy: 0.4305\n",
            "Epoch 221/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.7957 - accuracy: 0.6940 - val_loss: 1.2764 - val_accuracy: 0.4768\n",
            "Epoch 222/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.7980 - accuracy: 0.6814 - val_loss: 1.2846 - val_accuracy: 0.4106\n",
            "Epoch 223/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.7861 - accuracy: 0.6918 - val_loss: 1.2762 - val_accuracy: 0.4503\n",
            "Epoch 224/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.7841 - accuracy: 0.6814 - val_loss: 1.2787 - val_accuracy: 0.4172\n",
            "Epoch 225/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.7849 - accuracy: 0.6866 - val_loss: 1.2811 - val_accuracy: 0.4371\n",
            "Epoch 226/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.8027 - accuracy: 0.6859 - val_loss: 1.2748 - val_accuracy: 0.4834\n",
            "Epoch 227/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.7806 - accuracy: 0.6918 - val_loss: 1.3105 - val_accuracy: 0.4106\n",
            "Epoch 228/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.7843 - accuracy: 0.6874 - val_loss: 1.3129 - val_accuracy: 0.4106\n",
            "Epoch 229/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.7733 - accuracy: 0.6962 - val_loss: 1.2454 - val_accuracy: 0.4901\n",
            "Epoch 230/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.7733 - accuracy: 0.6814 - val_loss: 1.2723 - val_accuracy: 0.4371\n",
            "Epoch 231/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.7814 - accuracy: 0.6822 - val_loss: 1.2866 - val_accuracy: 0.4437\n",
            "Epoch 232/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.7835 - accuracy: 0.6785 - val_loss: 1.2585 - val_accuracy: 0.4834\n",
            "Epoch 233/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.7742 - accuracy: 0.6866 - val_loss: 1.2495 - val_accuracy: 0.4437\n",
            "Epoch 234/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.7827 - accuracy: 0.6807 - val_loss: 1.2783 - val_accuracy: 0.4570\n",
            "Epoch 235/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.7716 - accuracy: 0.6948 - val_loss: 1.3147 - val_accuracy: 0.4106\n",
            "Epoch 236/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.7602 - accuracy: 0.6970 - val_loss: 1.3206 - val_accuracy: 0.3775\n",
            "Epoch 237/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.7786 - accuracy: 0.6970 - val_loss: 1.2784 - val_accuracy: 0.4503\n",
            "Epoch 238/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.7757 - accuracy: 0.6955 - val_loss: 1.2774 - val_accuracy: 0.4437\n",
            "Epoch 239/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.7554 - accuracy: 0.6992 - val_loss: 1.2888 - val_accuracy: 0.4238\n",
            "Epoch 240/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.7534 - accuracy: 0.7014 - val_loss: 1.2928 - val_accuracy: 0.4503\n",
            "Epoch 241/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.7758 - accuracy: 0.6999 - val_loss: 1.2739 - val_accuracy: 0.5033\n",
            "Epoch 242/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.7736 - accuracy: 0.6874 - val_loss: 1.3063 - val_accuracy: 0.4305\n",
            "Epoch 243/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.7522 - accuracy: 0.7007 - val_loss: 1.2885 - val_accuracy: 0.4967\n",
            "Epoch 244/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.7545 - accuracy: 0.6984 - val_loss: 1.2540 - val_accuracy: 0.4503\n",
            "Epoch 245/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.7482 - accuracy: 0.7140 - val_loss: 1.2766 - val_accuracy: 0.4172\n",
            "Epoch 246/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.7481 - accuracy: 0.7066 - val_loss: 1.2760 - val_accuracy: 0.4503\n",
            "Epoch 247/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.7524 - accuracy: 0.7044 - val_loss: 1.2849 - val_accuracy: 0.4371\n",
            "Epoch 248/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.7600 - accuracy: 0.7029 - val_loss: 1.2738 - val_accuracy: 0.4305\n",
            "Epoch 249/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.7332 - accuracy: 0.7221 - val_loss: 1.2602 - val_accuracy: 0.4570\n",
            "Epoch 250/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.7452 - accuracy: 0.7132 - val_loss: 1.2941 - val_accuracy: 0.4238\n",
            "Epoch 251/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.7364 - accuracy: 0.7081 - val_loss: 1.2869 - val_accuracy: 0.4172\n",
            "Epoch 252/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.7407 - accuracy: 0.7236 - val_loss: 1.2512 - val_accuracy: 0.4636\n",
            "Epoch 253/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.7429 - accuracy: 0.6940 - val_loss: 1.2439 - val_accuracy: 0.4570\n",
            "Epoch 254/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.7333 - accuracy: 0.7132 - val_loss: 1.2660 - val_accuracy: 0.4768\n",
            "Epoch 255/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.7353 - accuracy: 0.7110 - val_loss: 1.2633 - val_accuracy: 0.4570\n",
            "Epoch 256/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.7535 - accuracy: 0.7073 - val_loss: 1.3079 - val_accuracy: 0.5099\n",
            "Epoch 257/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.7229 - accuracy: 0.7288 - val_loss: 1.2785 - val_accuracy: 0.4503\n",
            "Epoch 258/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.7382 - accuracy: 0.7125 - val_loss: 1.2875 - val_accuracy: 0.4570\n",
            "Epoch 259/700\n",
            "85/85 [==============================] - 2s 27ms/step - loss: 0.7455 - accuracy: 0.7051 - val_loss: 1.2640 - val_accuracy: 0.4437\n",
            "Epoch 260/700\n",
            "85/85 [==============================] - 2s 27ms/step - loss: 0.7370 - accuracy: 0.7132 - val_loss: 1.2972 - val_accuracy: 0.4503\n",
            "Epoch 261/700\n",
            "85/85 [==============================] - 3s 32ms/step - loss: 0.7324 - accuracy: 0.7162 - val_loss: 1.2476 - val_accuracy: 0.4768\n",
            "Epoch 262/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.7247 - accuracy: 0.7125 - val_loss: 1.2519 - val_accuracy: 0.4437\n",
            "Epoch 263/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.7281 - accuracy: 0.7221 - val_loss: 1.2420 - val_accuracy: 0.4570\n",
            "Epoch 264/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.7324 - accuracy: 0.7081 - val_loss: 1.2620 - val_accuracy: 0.4305\n",
            "Epoch 265/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.7207 - accuracy: 0.7221 - val_loss: 1.2653 - val_accuracy: 0.4636\n",
            "Epoch 266/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.7238 - accuracy: 0.7058 - val_loss: 1.2713 - val_accuracy: 0.4437\n",
            "Epoch 267/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.7183 - accuracy: 0.7118 - val_loss: 1.2775 - val_accuracy: 0.4172\n",
            "Epoch 268/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.7176 - accuracy: 0.7221 - val_loss: 1.3038 - val_accuracy: 0.4238\n",
            "Epoch 269/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.7244 - accuracy: 0.7088 - val_loss: 1.2465 - val_accuracy: 0.4702\n",
            "Epoch 270/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.7143 - accuracy: 0.7140 - val_loss: 1.2568 - val_accuracy: 0.4503\n",
            "Epoch 271/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.7030 - accuracy: 0.7339 - val_loss: 1.2495 - val_accuracy: 0.4636\n",
            "Epoch 272/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.7157 - accuracy: 0.7191 - val_loss: 1.2454 - val_accuracy: 0.4437\n",
            "Epoch 273/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.7273 - accuracy: 0.7125 - val_loss: 1.2855 - val_accuracy: 0.4371\n",
            "Epoch 274/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.7122 - accuracy: 0.7251 - val_loss: 1.2737 - val_accuracy: 0.4503\n",
            "Epoch 275/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.7057 - accuracy: 0.7169 - val_loss: 1.2632 - val_accuracy: 0.4371\n",
            "Epoch 276/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.7108 - accuracy: 0.7118 - val_loss: 1.2750 - val_accuracy: 0.4305\n",
            "Epoch 277/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.7190 - accuracy: 0.7243 - val_loss: 1.2593 - val_accuracy: 0.4437\n",
            "Epoch 278/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.6930 - accuracy: 0.7354 - val_loss: 1.2558 - val_accuracy: 0.4305\n",
            "Epoch 279/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.7144 - accuracy: 0.7132 - val_loss: 1.2592 - val_accuracy: 0.4570\n",
            "Epoch 280/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.6909 - accuracy: 0.7310 - val_loss: 1.2627 - val_accuracy: 0.4437\n",
            "Epoch 281/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.6976 - accuracy: 0.7302 - val_loss: 1.2540 - val_accuracy: 0.4702\n",
            "Epoch 282/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.7163 - accuracy: 0.7081 - val_loss: 1.2465 - val_accuracy: 0.4503\n",
            "Epoch 283/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.7022 - accuracy: 0.7273 - val_loss: 1.2483 - val_accuracy: 0.4570\n",
            "Epoch 284/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.7033 - accuracy: 0.7288 - val_loss: 1.2944 - val_accuracy: 0.4437\n",
            "Epoch 285/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.6915 - accuracy: 0.7228 - val_loss: 1.2389 - val_accuracy: 0.4768\n",
            "Epoch 286/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.7122 - accuracy: 0.7132 - val_loss: 1.2676 - val_accuracy: 0.4238\n",
            "Epoch 287/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.7004 - accuracy: 0.7280 - val_loss: 1.2351 - val_accuracy: 0.4768\n",
            "Epoch 288/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.6918 - accuracy: 0.7376 - val_loss: 1.2330 - val_accuracy: 0.4636\n",
            "Epoch 289/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.6838 - accuracy: 0.7354 - val_loss: 1.3058 - val_accuracy: 0.4503\n",
            "Epoch 290/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.6779 - accuracy: 0.7332 - val_loss: 1.2493 - val_accuracy: 0.4503\n",
            "Epoch 291/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.6935 - accuracy: 0.7317 - val_loss: 1.2422 - val_accuracy: 0.4503\n",
            "Epoch 292/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.6981 - accuracy: 0.7191 - val_loss: 1.2667 - val_accuracy: 0.4768\n",
            "Epoch 293/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.6833 - accuracy: 0.7243 - val_loss: 1.2788 - val_accuracy: 0.4437\n",
            "Epoch 294/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.6857 - accuracy: 0.7376 - val_loss: 1.2466 - val_accuracy: 0.4503\n",
            "Epoch 295/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.6856 - accuracy: 0.7428 - val_loss: 1.2135 - val_accuracy: 0.4901\n",
            "Epoch 296/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.6692 - accuracy: 0.7369 - val_loss: 1.2495 - val_accuracy: 0.4636\n",
            "Epoch 297/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.7053 - accuracy: 0.7376 - val_loss: 1.2286 - val_accuracy: 0.4768\n",
            "Epoch 298/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.6779 - accuracy: 0.7384 - val_loss: 1.2283 - val_accuracy: 0.4768\n",
            "Epoch 299/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.6812 - accuracy: 0.7347 - val_loss: 1.2603 - val_accuracy: 0.4437\n",
            "Epoch 300/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.7004 - accuracy: 0.7251 - val_loss: 1.2461 - val_accuracy: 0.4371\n",
            "Epoch 301/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.6741 - accuracy: 0.7517 - val_loss: 1.2539 - val_accuracy: 0.4570\n",
            "Epoch 302/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.6717 - accuracy: 0.7391 - val_loss: 1.2802 - val_accuracy: 0.4238\n",
            "Epoch 303/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.6762 - accuracy: 0.7265 - val_loss: 1.2501 - val_accuracy: 0.4702\n",
            "Epoch 304/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.6808 - accuracy: 0.7214 - val_loss: 1.2459 - val_accuracy: 0.4371\n",
            "Epoch 305/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.6824 - accuracy: 0.7354 - val_loss: 1.2326 - val_accuracy: 0.4636\n",
            "Epoch 306/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.6724 - accuracy: 0.7472 - val_loss: 1.2296 - val_accuracy: 0.4768\n",
            "Epoch 307/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.6599 - accuracy: 0.7494 - val_loss: 1.2209 - val_accuracy: 0.4503\n",
            "Epoch 308/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.6648 - accuracy: 0.7421 - val_loss: 1.2407 - val_accuracy: 0.4437\n",
            "Epoch 309/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.6585 - accuracy: 0.7509 - val_loss: 1.2073 - val_accuracy: 0.4901\n",
            "Epoch 310/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.6586 - accuracy: 0.7509 - val_loss: 1.2634 - val_accuracy: 0.4570\n",
            "Epoch 311/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.6676 - accuracy: 0.7398 - val_loss: 1.2689 - val_accuracy: 0.4305\n",
            "Epoch 312/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.6618 - accuracy: 0.7384 - val_loss: 1.2208 - val_accuracy: 0.4503\n",
            "Epoch 313/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.6518 - accuracy: 0.7480 - val_loss: 1.2605 - val_accuracy: 0.4834\n",
            "Epoch 314/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.6603 - accuracy: 0.7376 - val_loss: 1.2341 - val_accuracy: 0.4702\n",
            "Epoch 315/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.6627 - accuracy: 0.7391 - val_loss: 1.2122 - val_accuracy: 0.4834\n",
            "Epoch 316/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.6432 - accuracy: 0.7509 - val_loss: 1.2495 - val_accuracy: 0.4570\n",
            "Epoch 317/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.6573 - accuracy: 0.7472 - val_loss: 1.2573 - val_accuracy: 0.4570\n",
            "Epoch 318/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.6492 - accuracy: 0.7458 - val_loss: 1.2856 - val_accuracy: 0.4437\n",
            "Epoch 319/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.6532 - accuracy: 0.7450 - val_loss: 1.2518 - val_accuracy: 0.4834\n",
            "Epoch 320/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.6609 - accuracy: 0.7472 - val_loss: 1.2340 - val_accuracy: 0.4503\n",
            "Epoch 321/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.6436 - accuracy: 0.7480 - val_loss: 1.2376 - val_accuracy: 0.4834\n",
            "Epoch 322/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.6484 - accuracy: 0.7406 - val_loss: 1.2559 - val_accuracy: 0.4570\n",
            "Epoch 323/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.6477 - accuracy: 0.7450 - val_loss: 1.2633 - val_accuracy: 0.4503\n",
            "Epoch 324/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.6496 - accuracy: 0.7487 - val_loss: 1.2539 - val_accuracy: 0.4570\n",
            "Epoch 325/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.6501 - accuracy: 0.7421 - val_loss: 1.2170 - val_accuracy: 0.4967\n",
            "Epoch 326/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.6368 - accuracy: 0.7613 - val_loss: 1.2263 - val_accuracy: 0.4371\n",
            "Epoch 327/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.6380 - accuracy: 0.7517 - val_loss: 1.2243 - val_accuracy: 0.5099\n",
            "Epoch 328/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.6380 - accuracy: 0.7635 - val_loss: 1.2520 - val_accuracy: 0.4570\n",
            "Epoch 329/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.6455 - accuracy: 0.7428 - val_loss: 1.2235 - val_accuracy: 0.4570\n",
            "Epoch 330/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.6597 - accuracy: 0.7332 - val_loss: 1.2575 - val_accuracy: 0.4437\n",
            "Epoch 331/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.6505 - accuracy: 0.7494 - val_loss: 1.2448 - val_accuracy: 0.4371\n",
            "Epoch 332/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.6320 - accuracy: 0.7605 - val_loss: 1.2596 - val_accuracy: 0.4702\n",
            "Epoch 333/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.6205 - accuracy: 0.7605 - val_loss: 1.2510 - val_accuracy: 0.4437\n",
            "Epoch 334/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.6371 - accuracy: 0.7502 - val_loss: 1.2418 - val_accuracy: 0.4636\n",
            "Epoch 335/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.6334 - accuracy: 0.7443 - val_loss: 1.2396 - val_accuracy: 0.4702\n",
            "Epoch 336/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.6218 - accuracy: 0.7650 - val_loss: 1.2607 - val_accuracy: 0.4437\n",
            "Epoch 337/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.6250 - accuracy: 0.7701 - val_loss: 1.2705 - val_accuracy: 0.4570\n",
            "Epoch 338/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.6413 - accuracy: 0.7465 - val_loss: 1.2978 - val_accuracy: 0.4437\n",
            "Epoch 339/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.6253 - accuracy: 0.7591 - val_loss: 1.2322 - val_accuracy: 0.4437\n",
            "Epoch 340/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.6225 - accuracy: 0.7605 - val_loss: 1.2434 - val_accuracy: 0.4503\n",
            "Epoch 341/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.6143 - accuracy: 0.7627 - val_loss: 1.2295 - val_accuracy: 0.4967\n",
            "Epoch 342/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.6272 - accuracy: 0.7546 - val_loss: 1.2506 - val_accuracy: 0.4371\n",
            "Epoch 343/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.6176 - accuracy: 0.7576 - val_loss: 1.2522 - val_accuracy: 0.4570\n",
            "Epoch 344/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.6332 - accuracy: 0.7472 - val_loss: 1.2673 - val_accuracy: 0.4371\n",
            "Epoch 345/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.6300 - accuracy: 0.7598 - val_loss: 1.2742 - val_accuracy: 0.4371\n",
            "Epoch 346/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.6208 - accuracy: 0.7635 - val_loss: 1.2004 - val_accuracy: 0.4901\n",
            "Epoch 347/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.6309 - accuracy: 0.7642 - val_loss: 1.2364 - val_accuracy: 0.4437\n",
            "Epoch 348/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.6150 - accuracy: 0.7627 - val_loss: 1.2190 - val_accuracy: 0.4967\n",
            "Epoch 349/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.5988 - accuracy: 0.7775 - val_loss: 1.2030 - val_accuracy: 0.4768\n",
            "Epoch 350/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.5967 - accuracy: 0.7687 - val_loss: 1.2269 - val_accuracy: 0.4570\n",
            "Epoch 351/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.6137 - accuracy: 0.7657 - val_loss: 1.2507 - val_accuracy: 0.4834\n",
            "Epoch 352/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.6137 - accuracy: 0.7627 - val_loss: 1.2417 - val_accuracy: 0.4305\n",
            "Epoch 353/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.5996 - accuracy: 0.7598 - val_loss: 1.2456 - val_accuracy: 0.4503\n",
            "Epoch 354/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.6026 - accuracy: 0.7753 - val_loss: 1.2303 - val_accuracy: 0.4437\n",
            "Epoch 355/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.6076 - accuracy: 0.7724 - val_loss: 1.2237 - val_accuracy: 0.4834\n",
            "Epoch 356/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.6038 - accuracy: 0.7524 - val_loss: 1.2373 - val_accuracy: 0.4834\n",
            "Epoch 357/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.6059 - accuracy: 0.7650 - val_loss: 1.2232 - val_accuracy: 0.4636\n",
            "Epoch 358/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.5944 - accuracy: 0.7709 - val_loss: 1.2026 - val_accuracy: 0.5033\n",
            "Epoch 359/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.6119 - accuracy: 0.7546 - val_loss: 1.2256 - val_accuracy: 0.4503\n",
            "Epoch 360/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.5852 - accuracy: 0.7768 - val_loss: 1.2788 - val_accuracy: 0.4570\n",
            "Epoch 361/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.6146 - accuracy: 0.7591 - val_loss: 1.2340 - val_accuracy: 0.4570\n",
            "Epoch 362/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.5992 - accuracy: 0.7768 - val_loss: 1.2917 - val_accuracy: 0.4437\n",
            "Epoch 363/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.5899 - accuracy: 0.7812 - val_loss: 1.2490 - val_accuracy: 0.4570\n",
            "Epoch 364/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.6087 - accuracy: 0.7672 - val_loss: 1.2497 - val_accuracy: 0.4371\n",
            "Epoch 365/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.5969 - accuracy: 0.7716 - val_loss: 1.2465 - val_accuracy: 0.4570\n",
            "Epoch 366/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.6084 - accuracy: 0.7731 - val_loss: 1.2215 - val_accuracy: 0.4437\n",
            "Epoch 367/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.6000 - accuracy: 0.7598 - val_loss: 1.2478 - val_accuracy: 0.4768\n",
            "Epoch 368/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.5848 - accuracy: 0.7664 - val_loss: 1.2241 - val_accuracy: 0.4636\n",
            "Epoch 369/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.5876 - accuracy: 0.7746 - val_loss: 1.2433 - val_accuracy: 0.4371\n",
            "Epoch 370/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.6019 - accuracy: 0.7834 - val_loss: 1.2558 - val_accuracy: 0.4503\n",
            "Epoch 371/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.5950 - accuracy: 0.7731 - val_loss: 1.2262 - val_accuracy: 0.4702\n",
            "Epoch 372/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.5763 - accuracy: 0.7775 - val_loss: 1.2679 - val_accuracy: 0.4636\n",
            "Epoch 373/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.5904 - accuracy: 0.7687 - val_loss: 1.2683 - val_accuracy: 0.4503\n",
            "Epoch 374/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.5979 - accuracy: 0.7642 - val_loss: 1.2319 - val_accuracy: 0.5033\n",
            "Epoch 375/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.6018 - accuracy: 0.7738 - val_loss: 1.2151 - val_accuracy: 0.4636\n",
            "Epoch 376/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.5872 - accuracy: 0.7761 - val_loss: 1.2354 - val_accuracy: 0.4702\n",
            "Epoch 377/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.5858 - accuracy: 0.7679 - val_loss: 1.2885 - val_accuracy: 0.4172\n",
            "Epoch 378/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.5772 - accuracy: 0.7901 - val_loss: 1.2290 - val_accuracy: 0.4636\n",
            "Epoch 379/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.5753 - accuracy: 0.7857 - val_loss: 1.2563 - val_accuracy: 0.4503\n",
            "Epoch 380/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.5832 - accuracy: 0.7731 - val_loss: 1.2241 - val_accuracy: 0.4503\n",
            "Epoch 381/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.5765 - accuracy: 0.7768 - val_loss: 1.2364 - val_accuracy: 0.4305\n",
            "Epoch 382/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.5799 - accuracy: 0.7687 - val_loss: 1.2251 - val_accuracy: 0.4901\n",
            "Epoch 383/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.5995 - accuracy: 0.7642 - val_loss: 1.2588 - val_accuracy: 0.4437\n",
            "Epoch 384/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.5684 - accuracy: 0.7864 - val_loss: 1.2169 - val_accuracy: 0.4768\n",
            "Epoch 385/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.5653 - accuracy: 0.7820 - val_loss: 1.2099 - val_accuracy: 0.4437\n",
            "Epoch 386/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.5815 - accuracy: 0.7812 - val_loss: 1.2279 - val_accuracy: 0.4834\n",
            "Epoch 387/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.5711 - accuracy: 0.7753 - val_loss: 1.2884 - val_accuracy: 0.4371\n",
            "Epoch 388/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.5730 - accuracy: 0.7805 - val_loss: 1.2429 - val_accuracy: 0.4702\n",
            "Epoch 389/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.5850 - accuracy: 0.7738 - val_loss: 1.2312 - val_accuracy: 0.4636\n",
            "Epoch 390/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.5789 - accuracy: 0.7761 - val_loss: 1.2243 - val_accuracy: 0.4636\n",
            "Epoch 391/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.5544 - accuracy: 0.7953 - val_loss: 1.2374 - val_accuracy: 0.4702\n",
            "Epoch 392/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.5601 - accuracy: 0.7842 - val_loss: 1.2225 - val_accuracy: 0.5033\n",
            "Epoch 393/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.5579 - accuracy: 0.7975 - val_loss: 1.2685 - val_accuracy: 0.4570\n",
            "Epoch 394/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.5729 - accuracy: 0.7857 - val_loss: 1.2568 - val_accuracy: 0.4437\n",
            "Epoch 395/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.5830 - accuracy: 0.7864 - val_loss: 1.2117 - val_accuracy: 0.4636\n",
            "Epoch 396/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.5754 - accuracy: 0.7820 - val_loss: 1.1890 - val_accuracy: 0.5033\n",
            "Epoch 397/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.5470 - accuracy: 0.7879 - val_loss: 1.2626 - val_accuracy: 0.4570\n",
            "Epoch 398/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.5552 - accuracy: 0.7864 - val_loss: 1.2072 - val_accuracy: 0.4768\n",
            "Epoch 399/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.5471 - accuracy: 0.7886 - val_loss: 1.2557 - val_accuracy: 0.4437\n",
            "Epoch 400/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.5575 - accuracy: 0.7768 - val_loss: 1.3021 - val_accuracy: 0.4570\n",
            "Epoch 401/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.5528 - accuracy: 0.7931 - val_loss: 1.2362 - val_accuracy: 0.4768\n",
            "Epoch 402/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.5483 - accuracy: 0.8012 - val_loss: 1.2349 - val_accuracy: 0.4702\n",
            "Epoch 403/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.5670 - accuracy: 0.7886 - val_loss: 1.2520 - val_accuracy: 0.4503\n",
            "Epoch 404/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.5572 - accuracy: 0.7820 - val_loss: 1.2234 - val_accuracy: 0.4834\n",
            "Epoch 405/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.5541 - accuracy: 0.7790 - val_loss: 1.2085 - val_accuracy: 0.4503\n",
            "Epoch 406/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.5458 - accuracy: 0.8004 - val_loss: 1.2088 - val_accuracy: 0.4834\n",
            "Epoch 407/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.5631 - accuracy: 0.7827 - val_loss: 1.3162 - val_accuracy: 0.4437\n",
            "Epoch 408/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.5591 - accuracy: 0.7598 - val_loss: 1.2698 - val_accuracy: 0.4702\n",
            "Epoch 409/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.5737 - accuracy: 0.7738 - val_loss: 1.1943 - val_accuracy: 0.4967\n",
            "Epoch 410/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.5535 - accuracy: 0.7879 - val_loss: 1.2861 - val_accuracy: 0.4636\n",
            "Epoch 411/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.5448 - accuracy: 0.7857 - val_loss: 1.2045 - val_accuracy: 0.4901\n",
            "Epoch 412/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.5514 - accuracy: 0.7871 - val_loss: 1.2784 - val_accuracy: 0.4437\n",
            "Epoch 413/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.5342 - accuracy: 0.7990 - val_loss: 1.2312 - val_accuracy: 0.4636\n",
            "Epoch 414/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.5461 - accuracy: 0.8012 - val_loss: 1.2301 - val_accuracy: 0.4834\n",
            "Epoch 415/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.5601 - accuracy: 0.7931 - val_loss: 1.1878 - val_accuracy: 0.4901\n",
            "Epoch 416/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.5388 - accuracy: 0.7960 - val_loss: 1.2444 - val_accuracy: 0.4371\n",
            "Epoch 417/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.5331 - accuracy: 0.8071 - val_loss: 1.3078 - val_accuracy: 0.4371\n",
            "Epoch 418/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.5206 - accuracy: 0.8108 - val_loss: 1.1842 - val_accuracy: 0.5033\n",
            "Epoch 419/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.5373 - accuracy: 0.7931 - val_loss: 1.2081 - val_accuracy: 0.4901\n",
            "Epoch 420/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.5486 - accuracy: 0.7960 - val_loss: 1.2572 - val_accuracy: 0.4371\n",
            "Epoch 421/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.5293 - accuracy: 0.8019 - val_loss: 1.2367 - val_accuracy: 0.4570\n",
            "Epoch 422/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.5177 - accuracy: 0.7901 - val_loss: 1.2777 - val_accuracy: 0.3974\n",
            "Epoch 423/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.5274 - accuracy: 0.7997 - val_loss: 1.2417 - val_accuracy: 0.4901\n",
            "Epoch 424/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.5156 - accuracy: 0.7990 - val_loss: 1.2482 - val_accuracy: 0.4503\n",
            "Epoch 425/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.5236 - accuracy: 0.8027 - val_loss: 1.2260 - val_accuracy: 0.5033\n",
            "Epoch 426/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.5228 - accuracy: 0.7938 - val_loss: 1.1875 - val_accuracy: 0.5166\n",
            "Epoch 427/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.5308 - accuracy: 0.7990 - val_loss: 1.2266 - val_accuracy: 0.4371\n",
            "Epoch 428/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.5314 - accuracy: 0.7982 - val_loss: 1.2291 - val_accuracy: 0.4967\n",
            "Epoch 429/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.5251 - accuracy: 0.8056 - val_loss: 1.2416 - val_accuracy: 0.4702\n",
            "Epoch 430/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.5341 - accuracy: 0.7931 - val_loss: 1.2245 - val_accuracy: 0.5099\n",
            "Epoch 431/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.5158 - accuracy: 0.8174 - val_loss: 1.1979 - val_accuracy: 0.5166\n",
            "Epoch 432/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.5095 - accuracy: 0.8101 - val_loss: 1.2075 - val_accuracy: 0.5099\n",
            "Epoch 433/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.5414 - accuracy: 0.7931 - val_loss: 1.2381 - val_accuracy: 0.4768\n",
            "Epoch 434/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.5065 - accuracy: 0.8064 - val_loss: 1.2339 - val_accuracy: 0.4967\n",
            "Epoch 435/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.5339 - accuracy: 0.8093 - val_loss: 1.2033 - val_accuracy: 0.4901\n",
            "Epoch 436/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.5305 - accuracy: 0.7975 - val_loss: 1.2384 - val_accuracy: 0.4768\n",
            "Epoch 437/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.5184 - accuracy: 0.8064 - val_loss: 1.2271 - val_accuracy: 0.4768\n",
            "Epoch 438/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.5259 - accuracy: 0.7975 - val_loss: 1.1962 - val_accuracy: 0.4834\n",
            "Epoch 439/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.5134 - accuracy: 0.8174 - val_loss: 1.3060 - val_accuracy: 0.4570\n",
            "Epoch 440/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.5291 - accuracy: 0.7967 - val_loss: 1.2003 - val_accuracy: 0.5033\n",
            "Epoch 441/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.5270 - accuracy: 0.8056 - val_loss: 1.2563 - val_accuracy: 0.4636\n",
            "Epoch 442/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.4989 - accuracy: 0.8123 - val_loss: 1.2105 - val_accuracy: 0.4768\n",
            "Epoch 443/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.4949 - accuracy: 0.8234 - val_loss: 1.2948 - val_accuracy: 0.4768\n",
            "Epoch 444/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.5231 - accuracy: 0.7923 - val_loss: 1.1945 - val_accuracy: 0.5166\n",
            "Epoch 445/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.5138 - accuracy: 0.8004 - val_loss: 1.2217 - val_accuracy: 0.4702\n",
            "Epoch 446/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.5125 - accuracy: 0.8078 - val_loss: 1.1949 - val_accuracy: 0.5298\n",
            "Epoch 447/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.5075 - accuracy: 0.7967 - val_loss: 1.2056 - val_accuracy: 0.5033\n",
            "Epoch 448/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.4978 - accuracy: 0.8234 - val_loss: 1.2077 - val_accuracy: 0.4636\n",
            "Epoch 449/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.5293 - accuracy: 0.7864 - val_loss: 1.2205 - val_accuracy: 0.4636\n",
            "Epoch 450/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.5231 - accuracy: 0.7923 - val_loss: 1.1976 - val_accuracy: 0.4768\n",
            "Epoch 451/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.5018 - accuracy: 0.8167 - val_loss: 1.2748 - val_accuracy: 0.4570\n",
            "Epoch 452/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.4997 - accuracy: 0.8123 - val_loss: 1.3319 - val_accuracy: 0.4172\n",
            "Epoch 453/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.5085 - accuracy: 0.8115 - val_loss: 1.2737 - val_accuracy: 0.4570\n",
            "Epoch 454/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.4870 - accuracy: 0.8064 - val_loss: 1.2445 - val_accuracy: 0.4305\n",
            "Epoch 455/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.4893 - accuracy: 0.8137 - val_loss: 1.2220 - val_accuracy: 0.4636\n",
            "Epoch 456/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.4842 - accuracy: 0.8189 - val_loss: 1.2679 - val_accuracy: 0.4834\n",
            "Epoch 457/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.5096 - accuracy: 0.8041 - val_loss: 1.2884 - val_accuracy: 0.4834\n",
            "Epoch 458/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.5105 - accuracy: 0.8056 - val_loss: 1.2633 - val_accuracy: 0.4834\n",
            "Epoch 459/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.5217 - accuracy: 0.7923 - val_loss: 1.2093 - val_accuracy: 0.5232\n",
            "Epoch 460/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.4836 - accuracy: 0.8219 - val_loss: 1.2087 - val_accuracy: 0.4967\n",
            "Epoch 461/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.5178 - accuracy: 0.7982 - val_loss: 1.2485 - val_accuracy: 0.4570\n",
            "Epoch 462/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.4913 - accuracy: 0.8152 - val_loss: 1.2080 - val_accuracy: 0.5166\n",
            "Epoch 463/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.5053 - accuracy: 0.8152 - val_loss: 1.2359 - val_accuracy: 0.4702\n",
            "Epoch 464/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.5140 - accuracy: 0.8034 - val_loss: 1.2394 - val_accuracy: 0.4636\n",
            "Epoch 465/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.4925 - accuracy: 0.8226 - val_loss: 1.2112 - val_accuracy: 0.4768\n",
            "Epoch 466/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.5019 - accuracy: 0.8078 - val_loss: 1.2295 - val_accuracy: 0.4768\n",
            "Epoch 467/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.4991 - accuracy: 0.8204 - val_loss: 1.2264 - val_accuracy: 0.4967\n",
            "Epoch 468/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.5004 - accuracy: 0.8204 - val_loss: 1.3049 - val_accuracy: 0.4503\n",
            "Epoch 469/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.4971 - accuracy: 0.8145 - val_loss: 1.1931 - val_accuracy: 0.4901\n",
            "Epoch 470/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.4821 - accuracy: 0.8204 - val_loss: 1.2503 - val_accuracy: 0.4901\n",
            "Epoch 471/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.4818 - accuracy: 0.8115 - val_loss: 1.2730 - val_accuracy: 0.4834\n",
            "Epoch 472/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.4848 - accuracy: 0.8093 - val_loss: 1.2282 - val_accuracy: 0.4768\n",
            "Epoch 473/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.4853 - accuracy: 0.8130 - val_loss: 1.1834 - val_accuracy: 0.4834\n",
            "Epoch 474/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.5150 - accuracy: 0.7982 - val_loss: 1.2179 - val_accuracy: 0.4570\n",
            "Epoch 475/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.4890 - accuracy: 0.8130 - val_loss: 1.2750 - val_accuracy: 0.4834\n",
            "Epoch 476/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.4759 - accuracy: 0.8197 - val_loss: 1.2226 - val_accuracy: 0.4768\n",
            "Epoch 477/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.4852 - accuracy: 0.8204 - val_loss: 1.2286 - val_accuracy: 0.4901\n",
            "Epoch 478/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.4992 - accuracy: 0.8241 - val_loss: 1.2538 - val_accuracy: 0.4901\n",
            "Epoch 479/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.4720 - accuracy: 0.8204 - val_loss: 1.2994 - val_accuracy: 0.5033\n",
            "Epoch 480/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.4742 - accuracy: 0.8219 - val_loss: 1.3394 - val_accuracy: 0.4702\n",
            "Epoch 481/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.4676 - accuracy: 0.8396 - val_loss: 1.2577 - val_accuracy: 0.5099\n",
            "Epoch 482/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.4785 - accuracy: 0.8241 - val_loss: 1.2249 - val_accuracy: 0.4768\n",
            "Epoch 483/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.4848 - accuracy: 0.8093 - val_loss: 1.2768 - val_accuracy: 0.4702\n",
            "Epoch 484/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.4814 - accuracy: 0.8160 - val_loss: 1.2215 - val_accuracy: 0.4967\n",
            "Epoch 485/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.4666 - accuracy: 0.8285 - val_loss: 1.3114 - val_accuracy: 0.4437\n",
            "Epoch 486/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.4878 - accuracy: 0.8137 - val_loss: 1.2408 - val_accuracy: 0.4636\n",
            "Epoch 487/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.4703 - accuracy: 0.8241 - val_loss: 1.2609 - val_accuracy: 0.5166\n",
            "Epoch 488/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.4631 - accuracy: 0.8278 - val_loss: 1.2491 - val_accuracy: 0.4901\n",
            "Epoch 489/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.4701 - accuracy: 0.8248 - val_loss: 1.2845 - val_accuracy: 0.4305\n",
            "Epoch 490/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.4630 - accuracy: 0.8248 - val_loss: 1.2645 - val_accuracy: 0.5033\n",
            "Epoch 491/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.4896 - accuracy: 0.8027 - val_loss: 1.2646 - val_accuracy: 0.4570\n",
            "Epoch 492/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.4762 - accuracy: 0.8145 - val_loss: 1.2424 - val_accuracy: 0.4702\n",
            "Epoch 493/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.4807 - accuracy: 0.8248 - val_loss: 1.2914 - val_accuracy: 0.4503\n",
            "Epoch 494/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.4747 - accuracy: 0.8367 - val_loss: 1.2842 - val_accuracy: 0.4636\n",
            "Epoch 495/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.4823 - accuracy: 0.8197 - val_loss: 1.2571 - val_accuracy: 0.4371\n",
            "Epoch 496/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.4405 - accuracy: 0.8500 - val_loss: 1.1945 - val_accuracy: 0.4901\n",
            "Epoch 497/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.4646 - accuracy: 0.8234 - val_loss: 1.2266 - val_accuracy: 0.4768\n",
            "Epoch 498/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.4766 - accuracy: 0.8234 - val_loss: 1.2380 - val_accuracy: 0.5099\n",
            "Epoch 499/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.4693 - accuracy: 0.8278 - val_loss: 1.2838 - val_accuracy: 0.4967\n",
            "Epoch 500/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.4278 - accuracy: 0.8389 - val_loss: 1.2899 - val_accuracy: 0.4967\n",
            "Epoch 501/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.4670 - accuracy: 0.8167 - val_loss: 1.2452 - val_accuracy: 0.4768\n",
            "Epoch 502/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.4470 - accuracy: 0.8389 - val_loss: 1.2274 - val_accuracy: 0.5033\n",
            "Epoch 503/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.4612 - accuracy: 0.8315 - val_loss: 1.2130 - val_accuracy: 0.5099\n",
            "Epoch 504/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.4512 - accuracy: 0.8256 - val_loss: 1.2556 - val_accuracy: 0.4834\n",
            "Epoch 505/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.4323 - accuracy: 0.8367 - val_loss: 1.2684 - val_accuracy: 0.4172\n",
            "Epoch 506/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.4516 - accuracy: 0.8411 - val_loss: 1.2228 - val_accuracy: 0.4834\n",
            "Epoch 507/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.4512 - accuracy: 0.8248 - val_loss: 1.2634 - val_accuracy: 0.4636\n",
            "Epoch 508/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.4741 - accuracy: 0.8204 - val_loss: 1.2482 - val_accuracy: 0.4967\n",
            "Epoch 509/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.4515 - accuracy: 0.8322 - val_loss: 1.2609 - val_accuracy: 0.4901\n",
            "Epoch 510/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.4481 - accuracy: 0.8352 - val_loss: 1.2154 - val_accuracy: 0.5166\n",
            "Epoch 511/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.4461 - accuracy: 0.8374 - val_loss: 1.2791 - val_accuracy: 0.4768\n",
            "Epoch 512/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.4408 - accuracy: 0.8367 - val_loss: 1.2510 - val_accuracy: 0.4702\n",
            "Epoch 513/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.4458 - accuracy: 0.8278 - val_loss: 1.2158 - val_accuracy: 0.5364\n",
            "Epoch 514/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.4375 - accuracy: 0.8300 - val_loss: 1.2737 - val_accuracy: 0.5033\n",
            "Epoch 515/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.4606 - accuracy: 0.8211 - val_loss: 1.2453 - val_accuracy: 0.5099\n",
            "Epoch 516/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.4691 - accuracy: 0.8219 - val_loss: 1.2820 - val_accuracy: 0.5099\n",
            "Epoch 517/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.4507 - accuracy: 0.8285 - val_loss: 1.2336 - val_accuracy: 0.4901\n",
            "Epoch 518/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.4519 - accuracy: 0.8285 - val_loss: 1.2788 - val_accuracy: 0.5099\n",
            "Epoch 519/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.4319 - accuracy: 0.8396 - val_loss: 1.2904 - val_accuracy: 0.4901\n",
            "Epoch 520/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.4571 - accuracy: 0.8234 - val_loss: 1.3115 - val_accuracy: 0.4570\n",
            "Epoch 521/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.4241 - accuracy: 0.8367 - val_loss: 1.2771 - val_accuracy: 0.4901\n",
            "Epoch 522/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.4253 - accuracy: 0.8426 - val_loss: 1.2282 - val_accuracy: 0.5099\n",
            "Epoch 523/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.4405 - accuracy: 0.8381 - val_loss: 1.2217 - val_accuracy: 0.5099\n",
            "Epoch 524/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.4283 - accuracy: 0.8374 - val_loss: 1.2385 - val_accuracy: 0.5166\n",
            "Epoch 525/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.4516 - accuracy: 0.8248 - val_loss: 1.2730 - val_accuracy: 0.4702\n",
            "Epoch 526/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.4397 - accuracy: 0.8322 - val_loss: 1.3509 - val_accuracy: 0.4371\n",
            "Epoch 527/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.4298 - accuracy: 0.8359 - val_loss: 1.2222 - val_accuracy: 0.5232\n",
            "Epoch 528/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.4492 - accuracy: 0.8315 - val_loss: 1.2288 - val_accuracy: 0.4768\n",
            "Epoch 529/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.4401 - accuracy: 0.8374 - val_loss: 1.2278 - val_accuracy: 0.5033\n",
            "Epoch 530/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.4491 - accuracy: 0.8241 - val_loss: 1.2995 - val_accuracy: 0.4967\n",
            "Epoch 531/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.4448 - accuracy: 0.8263 - val_loss: 1.2810 - val_accuracy: 0.4901\n",
            "Epoch 532/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.4582 - accuracy: 0.8115 - val_loss: 1.2308 - val_accuracy: 0.4636\n",
            "Epoch 533/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.4406 - accuracy: 0.8426 - val_loss: 1.2773 - val_accuracy: 0.4834\n",
            "Epoch 534/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.4270 - accuracy: 0.8426 - val_loss: 1.1912 - val_accuracy: 0.5033\n",
            "Epoch 535/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.4285 - accuracy: 0.8389 - val_loss: 1.2351 - val_accuracy: 0.4768\n",
            "Epoch 536/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.4220 - accuracy: 0.8337 - val_loss: 1.2862 - val_accuracy: 0.4901\n",
            "Epoch 537/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.4164 - accuracy: 0.8374 - val_loss: 1.2996 - val_accuracy: 0.4636\n",
            "Epoch 538/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.4519 - accuracy: 0.8211 - val_loss: 1.2566 - val_accuracy: 0.4901\n",
            "Epoch 539/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.4330 - accuracy: 0.8477 - val_loss: 1.2670 - val_accuracy: 0.5033\n",
            "Epoch 540/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.4241 - accuracy: 0.8404 - val_loss: 1.3313 - val_accuracy: 0.5033\n",
            "Epoch 541/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.4137 - accuracy: 0.8470 - val_loss: 1.2894 - val_accuracy: 0.5099\n",
            "Epoch 542/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.4257 - accuracy: 0.8500 - val_loss: 1.2061 - val_accuracy: 0.5232\n",
            "Epoch 543/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.4197 - accuracy: 0.8330 - val_loss: 1.2147 - val_accuracy: 0.5099\n",
            "Epoch 544/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.4185 - accuracy: 0.8448 - val_loss: 1.2533 - val_accuracy: 0.4636\n",
            "Epoch 545/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.4221 - accuracy: 0.8315 - val_loss: 1.2285 - val_accuracy: 0.4834\n",
            "Epoch 546/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.4351 - accuracy: 0.8315 - val_loss: 1.2269 - val_accuracy: 0.5099\n",
            "Epoch 547/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.4375 - accuracy: 0.8315 - val_loss: 1.2500 - val_accuracy: 0.4503\n",
            "Epoch 548/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.4370 - accuracy: 0.8433 - val_loss: 1.2982 - val_accuracy: 0.4834\n",
            "Epoch 549/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.4202 - accuracy: 0.8418 - val_loss: 1.2869 - val_accuracy: 0.4768\n",
            "Epoch 550/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.4417 - accuracy: 0.8285 - val_loss: 1.3184 - val_accuracy: 0.4967\n",
            "Epoch 551/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.4264 - accuracy: 0.8426 - val_loss: 1.3842 - val_accuracy: 0.4305\n",
            "Epoch 552/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.4187 - accuracy: 0.8463 - val_loss: 1.2088 - val_accuracy: 0.4768\n",
            "Epoch 553/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.4278 - accuracy: 0.8418 - val_loss: 1.1914 - val_accuracy: 0.5232\n",
            "Epoch 554/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.4271 - accuracy: 0.8374 - val_loss: 1.2343 - val_accuracy: 0.5099\n",
            "Epoch 555/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.4042 - accuracy: 0.8485 - val_loss: 1.3042 - val_accuracy: 0.4437\n",
            "Epoch 556/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.4369 - accuracy: 0.8315 - val_loss: 1.2755 - val_accuracy: 0.4834\n",
            "Epoch 557/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.4248 - accuracy: 0.8381 - val_loss: 1.2443 - val_accuracy: 0.4901\n",
            "Epoch 558/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.4194 - accuracy: 0.8426 - val_loss: 1.2398 - val_accuracy: 0.5099\n",
            "Epoch 559/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.4207 - accuracy: 0.8411 - val_loss: 1.2727 - val_accuracy: 0.5033\n",
            "Epoch 560/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.4150 - accuracy: 0.8463 - val_loss: 1.2273 - val_accuracy: 0.5166\n",
            "Epoch 561/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.4212 - accuracy: 0.8404 - val_loss: 1.2291 - val_accuracy: 0.5099\n",
            "Epoch 562/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.4274 - accuracy: 0.8315 - val_loss: 1.2824 - val_accuracy: 0.4834\n",
            "Epoch 563/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.4202 - accuracy: 0.8300 - val_loss: 1.2278 - val_accuracy: 0.4901\n",
            "Epoch 564/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.4215 - accuracy: 0.8322 - val_loss: 1.2960 - val_accuracy: 0.4834\n",
            "Epoch 565/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.4222 - accuracy: 0.8455 - val_loss: 1.3671 - val_accuracy: 0.4371\n",
            "Epoch 566/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.4019 - accuracy: 0.8396 - val_loss: 1.4095 - val_accuracy: 0.4702\n",
            "Epoch 567/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.4107 - accuracy: 0.8477 - val_loss: 1.3395 - val_accuracy: 0.4834\n",
            "Epoch 568/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.4125 - accuracy: 0.8448 - val_loss: 1.2491 - val_accuracy: 0.5033\n",
            "Epoch 569/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.4093 - accuracy: 0.8418 - val_loss: 1.2650 - val_accuracy: 0.5033\n",
            "Epoch 570/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.4389 - accuracy: 0.8285 - val_loss: 1.2953 - val_accuracy: 0.5099\n",
            "Epoch 571/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.4171 - accuracy: 0.8455 - val_loss: 1.2602 - val_accuracy: 0.4834\n",
            "Epoch 572/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.4004 - accuracy: 0.8507 - val_loss: 1.2528 - val_accuracy: 0.4702\n",
            "Epoch 573/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.4035 - accuracy: 0.8492 - val_loss: 1.3348 - val_accuracy: 0.4702\n",
            "Epoch 574/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.3863 - accuracy: 0.8477 - val_loss: 1.2894 - val_accuracy: 0.4901\n",
            "Epoch 575/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.4123 - accuracy: 0.8374 - val_loss: 1.2690 - val_accuracy: 0.5232\n",
            "Epoch 576/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.4056 - accuracy: 0.8566 - val_loss: 1.3106 - val_accuracy: 0.4768\n",
            "Epoch 577/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.4042 - accuracy: 0.8367 - val_loss: 1.2679 - val_accuracy: 0.4901\n",
            "Epoch 578/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.4241 - accuracy: 0.8315 - val_loss: 1.3059 - val_accuracy: 0.4901\n",
            "Epoch 579/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.3952 - accuracy: 0.8522 - val_loss: 1.2230 - val_accuracy: 0.5232\n",
            "Epoch 580/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.3806 - accuracy: 0.8581 - val_loss: 1.2582 - val_accuracy: 0.5033\n",
            "Epoch 581/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.4060 - accuracy: 0.8396 - val_loss: 1.3536 - val_accuracy: 0.5166\n",
            "Epoch 582/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.4017 - accuracy: 0.8448 - val_loss: 1.3098 - val_accuracy: 0.4768\n",
            "Epoch 583/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.4067 - accuracy: 0.8507 - val_loss: 1.2878 - val_accuracy: 0.4768\n",
            "Epoch 584/700\n",
            "85/85 [==============================] - 2s 25ms/step - loss: 0.3834 - accuracy: 0.8610 - val_loss: 1.2829 - val_accuracy: 0.4768\n",
            "Epoch 585/700\n",
            "85/85 [==============================] - 3s 32ms/step - loss: 0.3956 - accuracy: 0.8389 - val_loss: 1.2307 - val_accuracy: 0.5099\n",
            "Epoch 586/700\n",
            "85/85 [==============================] - 3s 30ms/step - loss: 0.3978 - accuracy: 0.8411 - val_loss: 1.3515 - val_accuracy: 0.4305\n",
            "Epoch 587/700\n",
            "85/85 [==============================] - 3s 35ms/step - loss: 0.3824 - accuracy: 0.8721 - val_loss: 1.2446 - val_accuracy: 0.5033\n",
            "Epoch 588/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.4008 - accuracy: 0.8411 - val_loss: 1.3580 - val_accuracy: 0.4834\n",
            "Epoch 589/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.4034 - accuracy: 0.8433 - val_loss: 1.2530 - val_accuracy: 0.5033\n",
            "Epoch 590/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.3744 - accuracy: 0.8581 - val_loss: 1.3692 - val_accuracy: 0.4901\n",
            "Epoch 591/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.3668 - accuracy: 0.8662 - val_loss: 1.2613 - val_accuracy: 0.4570\n",
            "Epoch 592/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.4039 - accuracy: 0.8448 - val_loss: 1.2586 - val_accuracy: 0.5033\n",
            "Epoch 593/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.3795 - accuracy: 0.8677 - val_loss: 1.3527 - val_accuracy: 0.4636\n",
            "Epoch 594/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.3804 - accuracy: 0.8640 - val_loss: 1.2927 - val_accuracy: 0.5033\n",
            "Epoch 595/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.3809 - accuracy: 0.8537 - val_loss: 1.3717 - val_accuracy: 0.3974\n",
            "Epoch 596/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.3893 - accuracy: 0.8537 - val_loss: 1.3262 - val_accuracy: 0.4834\n",
            "Epoch 597/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.3847 - accuracy: 0.8492 - val_loss: 1.3284 - val_accuracy: 0.4768\n",
            "Epoch 598/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.3868 - accuracy: 0.8596 - val_loss: 1.2684 - val_accuracy: 0.4967\n",
            "Epoch 599/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.3672 - accuracy: 0.8640 - val_loss: 1.2554 - val_accuracy: 0.4702\n",
            "Epoch 600/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.3788 - accuracy: 0.8566 - val_loss: 1.2833 - val_accuracy: 0.4636\n",
            "Epoch 601/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.3754 - accuracy: 0.8640 - val_loss: 1.2480 - val_accuracy: 0.4967\n",
            "Epoch 602/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.3934 - accuracy: 0.8492 - val_loss: 1.3371 - val_accuracy: 0.5166\n",
            "Epoch 603/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.3808 - accuracy: 0.8581 - val_loss: 1.2518 - val_accuracy: 0.5033\n",
            "Epoch 604/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.3960 - accuracy: 0.8537 - val_loss: 1.3196 - val_accuracy: 0.4834\n",
            "Epoch 605/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.3941 - accuracy: 0.8455 - val_loss: 1.3260 - val_accuracy: 0.4702\n",
            "Epoch 606/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.3959 - accuracy: 0.8566 - val_loss: 1.3069 - val_accuracy: 0.4503\n",
            "Epoch 607/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.3756 - accuracy: 0.8566 - val_loss: 1.2302 - val_accuracy: 0.5099\n",
            "Epoch 608/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.3842 - accuracy: 0.8463 - val_loss: 1.3068 - val_accuracy: 0.4768\n",
            "Epoch 609/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.3948 - accuracy: 0.8529 - val_loss: 1.3037 - val_accuracy: 0.4901\n",
            "Epoch 610/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.3707 - accuracy: 0.8588 - val_loss: 1.3209 - val_accuracy: 0.4834\n",
            "Epoch 611/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.4044 - accuracy: 0.8529 - val_loss: 1.2707 - val_accuracy: 0.5033\n",
            "Epoch 612/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.3816 - accuracy: 0.8559 - val_loss: 1.2259 - val_accuracy: 0.5232\n",
            "Epoch 613/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.3837 - accuracy: 0.8588 - val_loss: 1.2929 - val_accuracy: 0.4570\n",
            "Epoch 614/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.3927 - accuracy: 0.8411 - val_loss: 1.4046 - val_accuracy: 0.4636\n",
            "Epoch 615/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.3642 - accuracy: 0.8610 - val_loss: 1.2891 - val_accuracy: 0.4768\n",
            "Epoch 616/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.3840 - accuracy: 0.8544 - val_loss: 1.2522 - val_accuracy: 0.5232\n",
            "Epoch 617/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.3943 - accuracy: 0.8492 - val_loss: 1.3555 - val_accuracy: 0.4570\n",
            "Epoch 618/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.3745 - accuracy: 0.8647 - val_loss: 1.3074 - val_accuracy: 0.4371\n",
            "Epoch 619/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.3876 - accuracy: 0.8522 - val_loss: 1.3550 - val_accuracy: 0.4768\n",
            "Epoch 620/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.3661 - accuracy: 0.8707 - val_loss: 1.3327 - val_accuracy: 0.5232\n",
            "Epoch 621/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.3674 - accuracy: 0.8714 - val_loss: 1.3406 - val_accuracy: 0.5033\n",
            "Epoch 622/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.3777 - accuracy: 0.8522 - val_loss: 1.3416 - val_accuracy: 0.4834\n",
            "Epoch 623/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.3775 - accuracy: 0.8618 - val_loss: 1.2819 - val_accuracy: 0.4702\n",
            "Epoch 624/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.3825 - accuracy: 0.8492 - val_loss: 1.3251 - val_accuracy: 0.4702\n",
            "Epoch 625/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.3875 - accuracy: 0.8522 - val_loss: 1.2887 - val_accuracy: 0.4967\n",
            "Epoch 626/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.3653 - accuracy: 0.8707 - val_loss: 1.2680 - val_accuracy: 0.4901\n",
            "Epoch 627/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.3767 - accuracy: 0.8544 - val_loss: 1.2839 - val_accuracy: 0.4636\n",
            "Epoch 628/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.3884 - accuracy: 0.8500 - val_loss: 1.3132 - val_accuracy: 0.4503\n",
            "Epoch 629/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.3820 - accuracy: 0.8477 - val_loss: 1.3684 - val_accuracy: 0.5033\n",
            "Epoch 630/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.3838 - accuracy: 0.8640 - val_loss: 1.2850 - val_accuracy: 0.4901\n",
            "Epoch 631/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.3753 - accuracy: 0.8566 - val_loss: 1.2522 - val_accuracy: 0.5033\n",
            "Epoch 632/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.3946 - accuracy: 0.8455 - val_loss: 1.2321 - val_accuracy: 0.5232\n",
            "Epoch 633/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.4014 - accuracy: 0.8492 - val_loss: 1.3134 - val_accuracy: 0.4834\n",
            "Epoch 634/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.3578 - accuracy: 0.8684 - val_loss: 1.3347 - val_accuracy: 0.4768\n",
            "Epoch 635/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.3499 - accuracy: 0.8832 - val_loss: 1.4239 - val_accuracy: 0.4371\n",
            "Epoch 636/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.3638 - accuracy: 0.8596 - val_loss: 1.2894 - val_accuracy: 0.4967\n",
            "Epoch 637/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.3490 - accuracy: 0.8751 - val_loss: 1.4033 - val_accuracy: 0.4901\n",
            "Epoch 638/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.3756 - accuracy: 0.8581 - val_loss: 1.2930 - val_accuracy: 0.5033\n",
            "Epoch 639/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.3675 - accuracy: 0.8574 - val_loss: 1.2243 - val_accuracy: 0.4967\n",
            "Epoch 640/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.3884 - accuracy: 0.8544 - val_loss: 1.3461 - val_accuracy: 0.4967\n",
            "Epoch 641/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.3579 - accuracy: 0.8633 - val_loss: 1.2913 - val_accuracy: 0.5033\n",
            "Epoch 642/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.3606 - accuracy: 0.8692 - val_loss: 1.2731 - val_accuracy: 0.4834\n",
            "Epoch 643/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.3680 - accuracy: 0.8603 - val_loss: 1.3322 - val_accuracy: 0.4967\n",
            "Epoch 644/700\n",
            "85/85 [==============================] - 2s 21ms/step - loss: 0.3604 - accuracy: 0.8699 - val_loss: 1.3368 - val_accuracy: 0.4702\n",
            "Epoch 645/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.3625 - accuracy: 0.8640 - val_loss: 1.2781 - val_accuracy: 0.5099\n",
            "Epoch 646/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.3671 - accuracy: 0.8618 - val_loss: 1.3231 - val_accuracy: 0.4901\n",
            "Epoch 647/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.3396 - accuracy: 0.8721 - val_loss: 1.3355 - val_accuracy: 0.4768\n",
            "Epoch 648/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.3499 - accuracy: 0.8744 - val_loss: 1.3623 - val_accuracy: 0.4834\n",
            "Epoch 649/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.3560 - accuracy: 0.8647 - val_loss: 1.3412 - val_accuracy: 0.4834\n",
            "Epoch 650/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.3511 - accuracy: 0.8647 - val_loss: 1.3183 - val_accuracy: 0.4901\n",
            "Epoch 651/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.3619 - accuracy: 0.8633 - val_loss: 1.3532 - val_accuracy: 0.4503\n",
            "Epoch 652/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.3430 - accuracy: 0.8736 - val_loss: 1.3227 - val_accuracy: 0.4503\n",
            "Epoch 653/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.3696 - accuracy: 0.8633 - val_loss: 1.3671 - val_accuracy: 0.4834\n",
            "Epoch 654/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.3518 - accuracy: 0.8729 - val_loss: 1.4281 - val_accuracy: 0.4570\n",
            "Epoch 655/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.3294 - accuracy: 0.8803 - val_loss: 1.2747 - val_accuracy: 0.4901\n",
            "Epoch 656/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.3636 - accuracy: 0.8603 - val_loss: 1.3340 - val_accuracy: 0.4702\n",
            "Epoch 657/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.3555 - accuracy: 0.8662 - val_loss: 1.2880 - val_accuracy: 0.4768\n",
            "Epoch 658/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.3483 - accuracy: 0.8714 - val_loss: 1.3583 - val_accuracy: 0.4702\n",
            "Epoch 659/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.3494 - accuracy: 0.8758 - val_loss: 1.3811 - val_accuracy: 0.4503\n",
            "Epoch 660/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.3578 - accuracy: 0.8596 - val_loss: 1.3560 - val_accuracy: 0.4834\n",
            "Epoch 661/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.3296 - accuracy: 0.8810 - val_loss: 1.3086 - val_accuracy: 0.4503\n",
            "Epoch 662/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.3450 - accuracy: 0.8670 - val_loss: 1.3538 - val_accuracy: 0.4305\n",
            "Epoch 663/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.3331 - accuracy: 0.8780 - val_loss: 1.3503 - val_accuracy: 0.4768\n",
            "Epoch 664/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.3550 - accuracy: 0.8751 - val_loss: 1.4032 - val_accuracy: 0.4768\n",
            "Epoch 665/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.3436 - accuracy: 0.8647 - val_loss: 1.3581 - val_accuracy: 0.4768\n",
            "Epoch 666/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.3495 - accuracy: 0.8699 - val_loss: 1.3426 - val_accuracy: 0.4570\n",
            "Epoch 667/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.3299 - accuracy: 0.8744 - val_loss: 1.3066 - val_accuracy: 0.4967\n",
            "Epoch 668/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.3411 - accuracy: 0.8803 - val_loss: 1.3510 - val_accuracy: 0.4768\n",
            "Epoch 669/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.3416 - accuracy: 0.8751 - val_loss: 1.2991 - val_accuracy: 0.5033\n",
            "Epoch 670/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.3201 - accuracy: 0.8773 - val_loss: 1.3299 - val_accuracy: 0.4768\n",
            "Epoch 671/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.3375 - accuracy: 0.8795 - val_loss: 1.4240 - val_accuracy: 0.4636\n",
            "Epoch 672/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.3443 - accuracy: 0.8662 - val_loss: 1.3098 - val_accuracy: 0.4834\n",
            "Epoch 673/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.3368 - accuracy: 0.8810 - val_loss: 1.3038 - val_accuracy: 0.4834\n",
            "Epoch 674/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.3336 - accuracy: 0.8729 - val_loss: 1.3324 - val_accuracy: 0.4702\n",
            "Epoch 675/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.3400 - accuracy: 0.8677 - val_loss: 1.3636 - val_accuracy: 0.4702\n",
            "Epoch 676/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.3166 - accuracy: 0.8832 - val_loss: 1.3580 - val_accuracy: 0.4636\n",
            "Epoch 677/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.3527 - accuracy: 0.8618 - val_loss: 1.3581 - val_accuracy: 0.4901\n",
            "Epoch 678/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.3490 - accuracy: 0.8744 - val_loss: 1.2937 - val_accuracy: 0.5232\n",
            "Epoch 679/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.3257 - accuracy: 0.8840 - val_loss: 1.3348 - val_accuracy: 0.4901\n",
            "Epoch 680/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.3294 - accuracy: 0.8847 - val_loss: 1.4611 - val_accuracy: 0.4834\n",
            "Epoch 681/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.3525 - accuracy: 0.8647 - val_loss: 1.3081 - val_accuracy: 0.4702\n",
            "Epoch 682/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.3221 - accuracy: 0.8803 - val_loss: 1.5402 - val_accuracy: 0.4503\n",
            "Epoch 683/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.3162 - accuracy: 0.8869 - val_loss: 1.4344 - val_accuracy: 0.4768\n",
            "Epoch 684/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.3367 - accuracy: 0.8773 - val_loss: 1.3419 - val_accuracy: 0.4570\n",
            "Epoch 685/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.3191 - accuracy: 0.8891 - val_loss: 1.3434 - val_accuracy: 0.4901\n",
            "Epoch 686/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.3393 - accuracy: 0.8655 - val_loss: 1.4544 - val_accuracy: 0.4636\n",
            "Epoch 687/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.3167 - accuracy: 0.8832 - val_loss: 1.3312 - val_accuracy: 0.4901\n",
            "Epoch 688/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.3439 - accuracy: 0.8655 - val_loss: 1.3669 - val_accuracy: 0.4901\n",
            "Epoch 689/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.3126 - accuracy: 0.8914 - val_loss: 1.3383 - val_accuracy: 0.4768\n",
            "Epoch 690/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.3432 - accuracy: 0.8825 - val_loss: 1.3870 - val_accuracy: 0.4702\n",
            "Epoch 691/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.3261 - accuracy: 0.8744 - val_loss: 1.3573 - val_accuracy: 0.4702\n",
            "Epoch 692/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.3430 - accuracy: 0.8692 - val_loss: 1.3244 - val_accuracy: 0.4636\n",
            "Epoch 693/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.3394 - accuracy: 0.8699 - val_loss: 1.3642 - val_accuracy: 0.4570\n",
            "Epoch 694/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.3187 - accuracy: 0.8817 - val_loss: 1.3412 - val_accuracy: 0.4570\n",
            "Epoch 695/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.3227 - accuracy: 0.8729 - val_loss: 1.4042 - val_accuracy: 0.4901\n",
            "Epoch 696/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.3364 - accuracy: 0.8736 - val_loss: 1.3332 - val_accuracy: 0.4834\n",
            "Epoch 697/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.3245 - accuracy: 0.8795 - val_loss: 1.4008 - val_accuracy: 0.4570\n",
            "Epoch 698/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.3346 - accuracy: 0.8633 - val_loss: 1.3170 - val_accuracy: 0.4967\n",
            "Epoch 699/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.3288 - accuracy: 0.8854 - val_loss: 1.4011 - val_accuracy: 0.4834\n",
            "Epoch 700/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.3205 - accuracy: 0.8825 - val_loss: 1.3470 - val_accuracy: 0.4901\n",
            "0.7184394463896752\n",
            "accuracy: 77.66%\n",
            "Epoch 1/700\n",
            "85/85 [==============================] - 3s 24ms/step - loss: 1.6729 - accuracy: 0.1848 - val_loss: 1.6172 - val_accuracy: 0.1921\n",
            "Epoch 2/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 1.6394 - accuracy: 0.2018 - val_loss: 1.6137 - val_accuracy: 0.1854\n",
            "Epoch 3/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 1.6451 - accuracy: 0.1729 - val_loss: 1.6082 - val_accuracy: 0.1921\n",
            "Epoch 4/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 1.6392 - accuracy: 0.1885 - val_loss: 1.6112 - val_accuracy: 0.2318\n",
            "Epoch 5/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 1.6345 - accuracy: 0.2158 - val_loss: 1.6039 - val_accuracy: 0.1921\n",
            "Epoch 6/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 1.6260 - accuracy: 0.2069 - val_loss: 1.6247 - val_accuracy: 0.2053\n",
            "Epoch 7/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 1.6347 - accuracy: 0.1944 - val_loss: 1.6007 - val_accuracy: 0.1921\n",
            "Epoch 8/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 1.6200 - accuracy: 0.2225 - val_loss: 1.5988 - val_accuracy: 0.2583\n",
            "Epoch 9/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 1.6268 - accuracy: 0.2084 - val_loss: 1.5932 - val_accuracy: 0.3046\n",
            "Epoch 10/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 1.6211 - accuracy: 0.2003 - val_loss: 1.5897 - val_accuracy: 0.2450\n",
            "Epoch 11/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 1.6197 - accuracy: 0.2269 - val_loss: 1.5889 - val_accuracy: 0.2649\n",
            "Epoch 12/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 1.6102 - accuracy: 0.2262 - val_loss: 1.5791 - val_accuracy: 0.3046\n",
            "Epoch 13/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 1.6140 - accuracy: 0.2306 - val_loss: 1.5793 - val_accuracy: 0.3245\n",
            "Epoch 14/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 1.6030 - accuracy: 0.2417 - val_loss: 1.5769 - val_accuracy: 0.3046\n",
            "Epoch 15/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 1.5952 - accuracy: 0.2387 - val_loss: 1.5769 - val_accuracy: 0.2583\n",
            "Epoch 16/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 1.6003 - accuracy: 0.2461 - val_loss: 1.5581 - val_accuracy: 0.3245\n",
            "Epoch 17/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 1.5816 - accuracy: 0.2668 - val_loss: 1.5695 - val_accuracy: 0.2318\n",
            "Epoch 18/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 1.5816 - accuracy: 0.2653 - val_loss: 1.5657 - val_accuracy: 0.2781\n",
            "Epoch 19/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 1.5833 - accuracy: 0.2469 - val_loss: 1.5524 - val_accuracy: 0.3179\n",
            "Epoch 20/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 1.5655 - accuracy: 0.2764 - val_loss: 1.5407 - val_accuracy: 0.2980\n",
            "Epoch 21/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 1.5727 - accuracy: 0.2690 - val_loss: 1.5388 - val_accuracy: 0.3576\n",
            "Epoch 22/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 1.5519 - accuracy: 0.2964 - val_loss: 1.5509 - val_accuracy: 0.2781\n",
            "Epoch 23/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 1.5571 - accuracy: 0.2868 - val_loss: 1.5339 - val_accuracy: 0.3642\n",
            "Epoch 24/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 1.5397 - accuracy: 0.3008 - val_loss: 1.5350 - val_accuracy: 0.3444\n",
            "Epoch 25/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 1.5422 - accuracy: 0.2942 - val_loss: 1.5153 - val_accuracy: 0.4106\n",
            "Epoch 26/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 1.5369 - accuracy: 0.3038 - val_loss: 1.5150 - val_accuracy: 0.3841\n",
            "Epoch 27/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 1.5192 - accuracy: 0.3082 - val_loss: 1.5279 - val_accuracy: 0.3775\n",
            "Epoch 28/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 1.5245 - accuracy: 0.3186 - val_loss: 1.5090 - val_accuracy: 0.3179\n",
            "Epoch 29/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 1.5146 - accuracy: 0.3385 - val_loss: 1.4895 - val_accuracy: 0.3576\n",
            "Epoch 30/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 1.5058 - accuracy: 0.3296 - val_loss: 1.4946 - val_accuracy: 0.3642\n",
            "Epoch 31/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 1.4959 - accuracy: 0.3208 - val_loss: 1.5042 - val_accuracy: 0.3444\n",
            "Epoch 32/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 1.4937 - accuracy: 0.3319 - val_loss: 1.4811 - val_accuracy: 0.4040\n",
            "Epoch 33/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 1.4815 - accuracy: 0.3540 - val_loss: 1.4565 - val_accuracy: 0.4172\n",
            "Epoch 34/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 1.4747 - accuracy: 0.3614 - val_loss: 1.4936 - val_accuracy: 0.4106\n",
            "Epoch 35/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 1.4620 - accuracy: 0.3673 - val_loss: 1.4893 - val_accuracy: 0.4238\n",
            "Epoch 36/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 1.4569 - accuracy: 0.3673 - val_loss: 1.4757 - val_accuracy: 0.4040\n",
            "Epoch 37/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 1.4568 - accuracy: 0.3622 - val_loss: 1.4668 - val_accuracy: 0.4437\n",
            "Epoch 38/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 1.4501 - accuracy: 0.3740 - val_loss: 1.4710 - val_accuracy: 0.4238\n",
            "Epoch 39/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 1.4297 - accuracy: 0.3954 - val_loss: 1.4711 - val_accuracy: 0.4040\n",
            "Epoch 40/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 1.4264 - accuracy: 0.3777 - val_loss: 1.4552 - val_accuracy: 0.4437\n",
            "Epoch 41/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 1.4160 - accuracy: 0.3880 - val_loss: 1.4669 - val_accuracy: 0.4172\n",
            "Epoch 42/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 1.4185 - accuracy: 0.3925 - val_loss: 1.4613 - val_accuracy: 0.4238\n",
            "Epoch 43/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 1.3980 - accuracy: 0.4021 - val_loss: 1.5250 - val_accuracy: 0.3510\n",
            "Epoch 44/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 1.3978 - accuracy: 0.3851 - val_loss: 1.4285 - val_accuracy: 0.4040\n",
            "Epoch 45/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 1.3894 - accuracy: 0.4006 - val_loss: 1.4373 - val_accuracy: 0.4437\n",
            "Epoch 46/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 1.3781 - accuracy: 0.4072 - val_loss: 1.4790 - val_accuracy: 0.4238\n",
            "Epoch 47/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 1.3689 - accuracy: 0.4420 - val_loss: 1.4235 - val_accuracy: 0.4437\n",
            "Epoch 48/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 1.3633 - accuracy: 0.4346 - val_loss: 1.4230 - val_accuracy: 0.4437\n",
            "Epoch 49/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 1.3562 - accuracy: 0.4427 - val_loss: 1.4331 - val_accuracy: 0.4570\n",
            "Epoch 50/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 1.3495 - accuracy: 0.4294 - val_loss: 1.4529 - val_accuracy: 0.4636\n",
            "Epoch 51/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 1.3337 - accuracy: 0.4619 - val_loss: 1.4315 - val_accuracy: 0.4437\n",
            "Epoch 52/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 1.3269 - accuracy: 0.4531 - val_loss: 1.4675 - val_accuracy: 0.4503\n",
            "Epoch 53/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 1.3174 - accuracy: 0.4516 - val_loss: 1.4797 - val_accuracy: 0.3841\n",
            "Epoch 54/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 1.3106 - accuracy: 0.4841 - val_loss: 1.4545 - val_accuracy: 0.4040\n",
            "Epoch 55/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 1.3041 - accuracy: 0.4797 - val_loss: 1.4244 - val_accuracy: 0.4371\n",
            "Epoch 56/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 1.2976 - accuracy: 0.4760 - val_loss: 1.4346 - val_accuracy: 0.4768\n",
            "Epoch 57/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 1.2865 - accuracy: 0.4848 - val_loss: 1.4216 - val_accuracy: 0.4834\n",
            "Epoch 58/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 1.2908 - accuracy: 0.4664 - val_loss: 1.3969 - val_accuracy: 0.4702\n",
            "Epoch 59/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 1.2698 - accuracy: 0.4826 - val_loss: 1.3994 - val_accuracy: 0.4636\n",
            "Epoch 60/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 1.2621 - accuracy: 0.5011 - val_loss: 1.3982 - val_accuracy: 0.4636\n",
            "Epoch 61/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 1.2565 - accuracy: 0.5011 - val_loss: 1.4185 - val_accuracy: 0.4967\n",
            "Epoch 62/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 1.2479 - accuracy: 0.4982 - val_loss: 1.4165 - val_accuracy: 0.4702\n",
            "Epoch 63/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 1.2472 - accuracy: 0.4937 - val_loss: 1.4345 - val_accuracy: 0.4503\n",
            "Epoch 64/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 1.2342 - accuracy: 0.5011 - val_loss: 1.4113 - val_accuracy: 0.4834\n",
            "Epoch 65/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 1.2192 - accuracy: 0.5129 - val_loss: 1.4256 - val_accuracy: 0.4238\n",
            "Epoch 66/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 1.2148 - accuracy: 0.5225 - val_loss: 1.4144 - val_accuracy: 0.4570\n",
            "Epoch 67/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 1.2077 - accuracy: 0.5233 - val_loss: 1.4379 - val_accuracy: 0.4636\n",
            "Epoch 68/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 1.2028 - accuracy: 0.5218 - val_loss: 1.4020 - val_accuracy: 0.4901\n",
            "Epoch 69/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 1.1957 - accuracy: 0.5137 - val_loss: 1.4070 - val_accuracy: 0.4570\n",
            "Epoch 70/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 1.1947 - accuracy: 0.5255 - val_loss: 1.4020 - val_accuracy: 0.4636\n",
            "Epoch 71/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 1.1818 - accuracy: 0.5225 - val_loss: 1.4008 - val_accuracy: 0.4636\n",
            "Epoch 72/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 1.1747 - accuracy: 0.5373 - val_loss: 1.4301 - val_accuracy: 0.4702\n",
            "Epoch 73/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 1.1814 - accuracy: 0.5255 - val_loss: 1.4177 - val_accuracy: 0.4437\n",
            "Epoch 74/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 1.1642 - accuracy: 0.5307 - val_loss: 1.4108 - val_accuracy: 0.4901\n",
            "Epoch 75/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 1.1698 - accuracy: 0.5270 - val_loss: 1.3951 - val_accuracy: 0.4503\n",
            "Epoch 76/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 1.1713 - accuracy: 0.5240 - val_loss: 1.4362 - val_accuracy: 0.3974\n",
            "Epoch 77/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 1.1524 - accuracy: 0.5329 - val_loss: 1.3966 - val_accuracy: 0.4702\n",
            "Epoch 78/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 1.1400 - accuracy: 0.5462 - val_loss: 1.4275 - val_accuracy: 0.4305\n",
            "Epoch 79/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 1.1328 - accuracy: 0.5506 - val_loss: 1.3953 - val_accuracy: 0.4570\n",
            "Epoch 80/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 1.1306 - accuracy: 0.5373 - val_loss: 1.4116 - val_accuracy: 0.4570\n",
            "Epoch 81/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 1.1343 - accuracy: 0.5455 - val_loss: 1.4046 - val_accuracy: 0.4503\n",
            "Epoch 82/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 1.1266 - accuracy: 0.5543 - val_loss: 1.3833 - val_accuracy: 0.5166\n",
            "Epoch 83/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 1.1049 - accuracy: 0.5743 - val_loss: 1.3972 - val_accuracy: 0.4636\n",
            "Epoch 84/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 1.1181 - accuracy: 0.5573 - val_loss: 1.3848 - val_accuracy: 0.5033\n",
            "Epoch 85/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 1.1184 - accuracy: 0.5484 - val_loss: 1.3963 - val_accuracy: 0.4768\n",
            "Epoch 86/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 1.1125 - accuracy: 0.5573 - val_loss: 1.3936 - val_accuracy: 0.4967\n",
            "Epoch 87/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 1.1076 - accuracy: 0.5632 - val_loss: 1.3728 - val_accuracy: 0.4901\n",
            "Epoch 88/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 1.1043 - accuracy: 0.5625 - val_loss: 1.3784 - val_accuracy: 0.4901\n",
            "Epoch 89/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 1.1045 - accuracy: 0.5418 - val_loss: 1.4262 - val_accuracy: 0.4636\n",
            "Epoch 90/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 1.0880 - accuracy: 0.5676 - val_loss: 1.4150 - val_accuracy: 0.4834\n",
            "Epoch 91/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 1.0818 - accuracy: 0.5706 - val_loss: 1.3712 - val_accuracy: 0.5166\n",
            "Epoch 92/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 1.0674 - accuracy: 0.5676 - val_loss: 1.4009 - val_accuracy: 0.4503\n",
            "Epoch 93/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 1.0890 - accuracy: 0.5661 - val_loss: 1.4400 - val_accuracy: 0.4040\n",
            "Epoch 94/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 1.0732 - accuracy: 0.5698 - val_loss: 1.4458 - val_accuracy: 0.3841\n",
            "Epoch 95/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 1.0774 - accuracy: 0.5743 - val_loss: 1.3831 - val_accuracy: 0.4768\n",
            "Epoch 96/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 1.0617 - accuracy: 0.5728 - val_loss: 1.4096 - val_accuracy: 0.4702\n",
            "Epoch 97/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 1.0599 - accuracy: 0.5743 - val_loss: 1.3840 - val_accuracy: 0.4503\n",
            "Epoch 98/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 1.0535 - accuracy: 0.5758 - val_loss: 1.4143 - val_accuracy: 0.4305\n",
            "Epoch 99/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 1.0635 - accuracy: 0.5617 - val_loss: 1.3745 - val_accuracy: 0.4967\n",
            "Epoch 100/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 1.0554 - accuracy: 0.5772 - val_loss: 1.4011 - val_accuracy: 0.4702\n",
            "Epoch 101/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 1.0456 - accuracy: 0.5787 - val_loss: 1.3984 - val_accuracy: 0.4172\n",
            "Epoch 102/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 1.0460 - accuracy: 0.5868 - val_loss: 1.4023 - val_accuracy: 0.4503\n",
            "Epoch 103/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 1.0398 - accuracy: 0.5868 - val_loss: 1.3919 - val_accuracy: 0.4172\n",
            "Epoch 104/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 1.0354 - accuracy: 0.5979 - val_loss: 1.4068 - val_accuracy: 0.4768\n",
            "Epoch 105/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 1.0415 - accuracy: 0.5846 - val_loss: 1.3827 - val_accuracy: 0.4570\n",
            "Epoch 106/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 1.0384 - accuracy: 0.5876 - val_loss: 1.3902 - val_accuracy: 0.5099\n",
            "Epoch 107/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 1.0271 - accuracy: 0.5987 - val_loss: 1.3964 - val_accuracy: 0.4437\n",
            "Epoch 108/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 1.0219 - accuracy: 0.5802 - val_loss: 1.3983 - val_accuracy: 0.4106\n",
            "Epoch 109/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 1.0374 - accuracy: 0.5831 - val_loss: 1.3849 - val_accuracy: 0.4437\n",
            "Epoch 110/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 1.0179 - accuracy: 0.5920 - val_loss: 1.4189 - val_accuracy: 0.4106\n",
            "Epoch 111/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 1.0295 - accuracy: 0.5861 - val_loss: 1.3942 - val_accuracy: 0.4636\n",
            "Epoch 112/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 1.0214 - accuracy: 0.5979 - val_loss: 1.4204 - val_accuracy: 0.4238\n",
            "Epoch 113/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 1.0147 - accuracy: 0.5795 - val_loss: 1.4385 - val_accuracy: 0.3974\n",
            "Epoch 114/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 1.0141 - accuracy: 0.6001 - val_loss: 1.3740 - val_accuracy: 0.4437\n",
            "Epoch 115/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 1.0172 - accuracy: 0.5994 - val_loss: 1.3668 - val_accuracy: 0.4305\n",
            "Epoch 116/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 1.0043 - accuracy: 0.5935 - val_loss: 1.3972 - val_accuracy: 0.4238\n",
            "Epoch 117/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.9976 - accuracy: 0.6024 - val_loss: 1.3643 - val_accuracy: 0.4702\n",
            "Epoch 118/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 1.0018 - accuracy: 0.5994 - val_loss: 1.3872 - val_accuracy: 0.4371\n",
            "Epoch 119/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.9776 - accuracy: 0.6024 - val_loss: 1.3943 - val_accuracy: 0.4305\n",
            "Epoch 120/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.9925 - accuracy: 0.5965 - val_loss: 1.4352 - val_accuracy: 0.3642\n",
            "Epoch 121/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.9980 - accuracy: 0.5965 - val_loss: 1.3956 - val_accuracy: 0.3907\n",
            "Epoch 122/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.9916 - accuracy: 0.6068 - val_loss: 1.3993 - val_accuracy: 0.4305\n",
            "Epoch 123/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.9907 - accuracy: 0.6038 - val_loss: 1.3875 - val_accuracy: 0.4768\n",
            "Epoch 124/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.9786 - accuracy: 0.6112 - val_loss: 1.4152 - val_accuracy: 0.4503\n",
            "Epoch 125/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.9634 - accuracy: 0.6260 - val_loss: 1.3625 - val_accuracy: 0.4305\n",
            "Epoch 126/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.9688 - accuracy: 0.6149 - val_loss: 1.4310 - val_accuracy: 0.4106\n",
            "Epoch 127/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.9816 - accuracy: 0.5979 - val_loss: 1.3992 - val_accuracy: 0.4238\n",
            "Epoch 128/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.9643 - accuracy: 0.6105 - val_loss: 1.4343 - val_accuracy: 0.4040\n",
            "Epoch 129/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.9659 - accuracy: 0.6001 - val_loss: 1.4265 - val_accuracy: 0.4106\n",
            "Epoch 130/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.9614 - accuracy: 0.6238 - val_loss: 1.4070 - val_accuracy: 0.4636\n",
            "Epoch 131/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.9700 - accuracy: 0.6238 - val_loss: 1.3713 - val_accuracy: 0.4702\n",
            "Epoch 132/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.9550 - accuracy: 0.6238 - val_loss: 1.3897 - val_accuracy: 0.4437\n",
            "Epoch 133/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.9583 - accuracy: 0.6216 - val_loss: 1.4437 - val_accuracy: 0.3841\n",
            "Epoch 134/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.9590 - accuracy: 0.6164 - val_loss: 1.3945 - val_accuracy: 0.4305\n",
            "Epoch 135/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.9682 - accuracy: 0.6208 - val_loss: 1.3824 - val_accuracy: 0.4238\n",
            "Epoch 136/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.9560 - accuracy: 0.6253 - val_loss: 1.3670 - val_accuracy: 0.4371\n",
            "Epoch 137/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.9495 - accuracy: 0.6319 - val_loss: 1.3838 - val_accuracy: 0.4172\n",
            "Epoch 138/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.9454 - accuracy: 0.6231 - val_loss: 1.3784 - val_accuracy: 0.4040\n",
            "Epoch 139/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.9518 - accuracy: 0.6216 - val_loss: 1.4189 - val_accuracy: 0.3841\n",
            "Epoch 140/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.9283 - accuracy: 0.6334 - val_loss: 1.3849 - val_accuracy: 0.4437\n",
            "Epoch 141/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.9397 - accuracy: 0.6201 - val_loss: 1.4077 - val_accuracy: 0.4238\n",
            "Epoch 142/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.9330 - accuracy: 0.6297 - val_loss: 1.4392 - val_accuracy: 0.3974\n",
            "Epoch 143/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.9350 - accuracy: 0.6223 - val_loss: 1.3857 - val_accuracy: 0.4967\n",
            "Epoch 144/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.9418 - accuracy: 0.6223 - val_loss: 1.4123 - val_accuracy: 0.4040\n",
            "Epoch 145/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.9229 - accuracy: 0.6386 - val_loss: 1.3941 - val_accuracy: 0.3907\n",
            "Epoch 146/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.9429 - accuracy: 0.6208 - val_loss: 1.3984 - val_accuracy: 0.4371\n",
            "Epoch 147/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.9239 - accuracy: 0.6393 - val_loss: 1.4094 - val_accuracy: 0.3841\n",
            "Epoch 148/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.9356 - accuracy: 0.6223 - val_loss: 1.4029 - val_accuracy: 0.3974\n",
            "Epoch 149/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.9283 - accuracy: 0.6282 - val_loss: 1.3955 - val_accuracy: 0.4172\n",
            "Epoch 150/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.9237 - accuracy: 0.6386 - val_loss: 1.3720 - val_accuracy: 0.4570\n",
            "Epoch 151/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.9252 - accuracy: 0.6401 - val_loss: 1.3828 - val_accuracy: 0.3974\n",
            "Epoch 152/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.9278 - accuracy: 0.6282 - val_loss: 1.4170 - val_accuracy: 0.3642\n",
            "Epoch 153/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.9338 - accuracy: 0.6231 - val_loss: 1.3853 - val_accuracy: 0.4305\n",
            "Epoch 154/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.9123 - accuracy: 0.6349 - val_loss: 1.3839 - val_accuracy: 0.4371\n",
            "Epoch 155/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.9174 - accuracy: 0.6327 - val_loss: 1.4124 - val_accuracy: 0.4172\n",
            "Epoch 156/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.9141 - accuracy: 0.6497 - val_loss: 1.4102 - val_accuracy: 0.4106\n",
            "Epoch 157/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.8974 - accuracy: 0.6415 - val_loss: 1.3890 - val_accuracy: 0.4371\n",
            "Epoch 158/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.9023 - accuracy: 0.6401 - val_loss: 1.4029 - val_accuracy: 0.4305\n",
            "Epoch 159/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.9000 - accuracy: 0.6393 - val_loss: 1.3770 - val_accuracy: 0.4371\n",
            "Epoch 160/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.9040 - accuracy: 0.6438 - val_loss: 1.4172 - val_accuracy: 0.4172\n",
            "Epoch 161/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.9057 - accuracy: 0.6415 - val_loss: 1.3846 - val_accuracy: 0.4040\n",
            "Epoch 162/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.8818 - accuracy: 0.6615 - val_loss: 1.4205 - val_accuracy: 0.4238\n",
            "Epoch 163/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.9115 - accuracy: 0.6393 - val_loss: 1.3967 - val_accuracy: 0.4437\n",
            "Epoch 164/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.8877 - accuracy: 0.6548 - val_loss: 1.3900 - val_accuracy: 0.4106\n",
            "Epoch 165/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.9096 - accuracy: 0.6378 - val_loss: 1.4025 - val_accuracy: 0.4636\n",
            "Epoch 166/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.8886 - accuracy: 0.6548 - val_loss: 1.4003 - val_accuracy: 0.4238\n",
            "Epoch 167/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.8804 - accuracy: 0.6526 - val_loss: 1.3999 - val_accuracy: 0.3907\n",
            "Epoch 168/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.8868 - accuracy: 0.6541 - val_loss: 1.4116 - val_accuracy: 0.4040\n",
            "Epoch 169/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.8742 - accuracy: 0.6519 - val_loss: 1.3791 - val_accuracy: 0.4040\n",
            "Epoch 170/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.8691 - accuracy: 0.6630 - val_loss: 1.3871 - val_accuracy: 0.4636\n",
            "Epoch 171/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.8983 - accuracy: 0.6467 - val_loss: 1.3968 - val_accuracy: 0.4371\n",
            "Epoch 172/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.8776 - accuracy: 0.6467 - val_loss: 1.4364 - val_accuracy: 0.3907\n",
            "Epoch 173/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.8780 - accuracy: 0.6563 - val_loss: 1.3735 - val_accuracy: 0.4106\n",
            "Epoch 174/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.8631 - accuracy: 0.6534 - val_loss: 1.3934 - val_accuracy: 0.3841\n",
            "Epoch 175/700\n",
            "85/85 [==============================] - 2s 28ms/step - loss: 0.8723 - accuracy: 0.6423 - val_loss: 1.3826 - val_accuracy: 0.4371\n",
            "Epoch 176/700\n",
            "85/85 [==============================] - 3s 30ms/step - loss: 0.8712 - accuracy: 0.6541 - val_loss: 1.4001 - val_accuracy: 0.4503\n",
            "Epoch 177/700\n",
            "85/85 [==============================] - 2s 27ms/step - loss: 0.8673 - accuracy: 0.6415 - val_loss: 1.4078 - val_accuracy: 0.4437\n",
            "Epoch 178/700\n",
            "85/85 [==============================] - 2s 29ms/step - loss: 0.8541 - accuracy: 0.6711 - val_loss: 1.3862 - val_accuracy: 0.4040\n",
            "Epoch 179/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.8717 - accuracy: 0.6519 - val_loss: 1.4137 - val_accuracy: 0.4106\n",
            "Epoch 180/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.8754 - accuracy: 0.6630 - val_loss: 1.3857 - val_accuracy: 0.3974\n",
            "Epoch 181/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.8713 - accuracy: 0.6637 - val_loss: 1.3725 - val_accuracy: 0.4503\n",
            "Epoch 182/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.8579 - accuracy: 0.6585 - val_loss: 1.3873 - val_accuracy: 0.4040\n",
            "Epoch 183/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.8453 - accuracy: 0.6748 - val_loss: 1.4086 - val_accuracy: 0.3709\n",
            "Epoch 184/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.8558 - accuracy: 0.6571 - val_loss: 1.4322 - val_accuracy: 0.4040\n",
            "Epoch 185/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.8489 - accuracy: 0.6770 - val_loss: 1.4059 - val_accuracy: 0.4238\n",
            "Epoch 186/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.8509 - accuracy: 0.6689 - val_loss: 1.4233 - val_accuracy: 0.4040\n",
            "Epoch 187/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.8442 - accuracy: 0.6667 - val_loss: 1.3659 - val_accuracy: 0.4437\n",
            "Epoch 188/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.8364 - accuracy: 0.6711 - val_loss: 1.3764 - val_accuracy: 0.4106\n",
            "Epoch 189/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.8310 - accuracy: 0.6844 - val_loss: 1.3878 - val_accuracy: 0.4172\n",
            "Epoch 190/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.8576 - accuracy: 0.6704 - val_loss: 1.3955 - val_accuracy: 0.4238\n",
            "Epoch 191/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.8394 - accuracy: 0.6615 - val_loss: 1.4217 - val_accuracy: 0.4106\n",
            "Epoch 192/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.8466 - accuracy: 0.6726 - val_loss: 1.3913 - val_accuracy: 0.4172\n",
            "Epoch 193/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.8271 - accuracy: 0.6718 - val_loss: 1.3953 - val_accuracy: 0.4172\n",
            "Epoch 194/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.8363 - accuracy: 0.6704 - val_loss: 1.3809 - val_accuracy: 0.4305\n",
            "Epoch 195/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.8309 - accuracy: 0.6644 - val_loss: 1.3844 - val_accuracy: 0.4238\n",
            "Epoch 196/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.8259 - accuracy: 0.6644 - val_loss: 1.4201 - val_accuracy: 0.3907\n",
            "Epoch 197/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.8127 - accuracy: 0.6696 - val_loss: 1.3986 - val_accuracy: 0.4172\n",
            "Epoch 198/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.8211 - accuracy: 0.6851 - val_loss: 1.4235 - val_accuracy: 0.4172\n",
            "Epoch 199/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.8317 - accuracy: 0.6763 - val_loss: 1.3772 - val_accuracy: 0.4570\n",
            "Epoch 200/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.8431 - accuracy: 0.6718 - val_loss: 1.4259 - val_accuracy: 0.4040\n",
            "Epoch 201/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.8321 - accuracy: 0.6608 - val_loss: 1.3992 - val_accuracy: 0.3974\n",
            "Epoch 202/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.8148 - accuracy: 0.6704 - val_loss: 1.4224 - val_accuracy: 0.4040\n",
            "Epoch 203/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.8121 - accuracy: 0.6696 - val_loss: 1.3868 - val_accuracy: 0.4040\n",
            "Epoch 204/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.8219 - accuracy: 0.6770 - val_loss: 1.4123 - val_accuracy: 0.3709\n",
            "Epoch 205/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.8116 - accuracy: 0.6822 - val_loss: 1.3626 - val_accuracy: 0.4305\n",
            "Epoch 206/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.8172 - accuracy: 0.6874 - val_loss: 1.3731 - val_accuracy: 0.4305\n",
            "Epoch 207/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.8102 - accuracy: 0.6681 - val_loss: 1.4001 - val_accuracy: 0.4040\n",
            "Epoch 208/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.8036 - accuracy: 0.6896 - val_loss: 1.4465 - val_accuracy: 0.3974\n",
            "Epoch 209/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.8069 - accuracy: 0.6778 - val_loss: 1.4079 - val_accuracy: 0.4238\n",
            "Epoch 210/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.8144 - accuracy: 0.6630 - val_loss: 1.3819 - val_accuracy: 0.4371\n",
            "Epoch 211/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.7962 - accuracy: 0.6822 - val_loss: 1.3989 - val_accuracy: 0.4106\n",
            "Epoch 212/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.7961 - accuracy: 0.6822 - val_loss: 1.4126 - val_accuracy: 0.3775\n",
            "Epoch 213/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.8058 - accuracy: 0.6778 - val_loss: 1.4100 - val_accuracy: 0.4106\n",
            "Epoch 214/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.8138 - accuracy: 0.6866 - val_loss: 1.3942 - val_accuracy: 0.3974\n",
            "Epoch 215/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.8175 - accuracy: 0.6851 - val_loss: 1.3796 - val_accuracy: 0.4172\n",
            "Epoch 216/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.7893 - accuracy: 0.6874 - val_loss: 1.3911 - val_accuracy: 0.4238\n",
            "Epoch 217/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.7901 - accuracy: 0.6896 - val_loss: 1.4022 - val_accuracy: 0.4172\n",
            "Epoch 218/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.8084 - accuracy: 0.6822 - val_loss: 1.4070 - val_accuracy: 0.4106\n",
            "Epoch 219/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.8026 - accuracy: 0.6837 - val_loss: 1.3974 - val_accuracy: 0.4371\n",
            "Epoch 220/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.8020 - accuracy: 0.6874 - val_loss: 1.4470 - val_accuracy: 0.4040\n",
            "Epoch 221/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.7942 - accuracy: 0.6741 - val_loss: 1.4204 - val_accuracy: 0.3974\n",
            "Epoch 222/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.8007 - accuracy: 0.6903 - val_loss: 1.4354 - val_accuracy: 0.3974\n",
            "Epoch 223/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.8018 - accuracy: 0.6829 - val_loss: 1.4136 - val_accuracy: 0.4238\n",
            "Epoch 224/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.7792 - accuracy: 0.6925 - val_loss: 1.3780 - val_accuracy: 0.4172\n",
            "Epoch 225/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.7739 - accuracy: 0.6851 - val_loss: 1.4079 - val_accuracy: 0.4172\n",
            "Epoch 226/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.7904 - accuracy: 0.6748 - val_loss: 1.3977 - val_accuracy: 0.4172\n",
            "Epoch 227/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.7835 - accuracy: 0.6933 - val_loss: 1.3928 - val_accuracy: 0.4172\n",
            "Epoch 228/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.7707 - accuracy: 0.7081 - val_loss: 1.4163 - val_accuracy: 0.4305\n",
            "Epoch 229/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.7766 - accuracy: 0.6800 - val_loss: 1.3841 - val_accuracy: 0.4371\n",
            "Epoch 230/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.7830 - accuracy: 0.6667 - val_loss: 1.4398 - val_accuracy: 0.3907\n",
            "Epoch 231/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.7730 - accuracy: 0.6977 - val_loss: 1.3860 - val_accuracy: 0.4371\n",
            "Epoch 232/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.7749 - accuracy: 0.7051 - val_loss: 1.4031 - val_accuracy: 0.4106\n",
            "Epoch 233/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.7760 - accuracy: 0.6970 - val_loss: 1.4179 - val_accuracy: 0.3907\n",
            "Epoch 234/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.7747 - accuracy: 0.6948 - val_loss: 1.4117 - val_accuracy: 0.4371\n",
            "Epoch 235/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.7732 - accuracy: 0.7095 - val_loss: 1.4179 - val_accuracy: 0.4238\n",
            "Epoch 236/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.7718 - accuracy: 0.6970 - val_loss: 1.3874 - val_accuracy: 0.4305\n",
            "Epoch 237/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.7631 - accuracy: 0.7007 - val_loss: 1.4297 - val_accuracy: 0.4371\n",
            "Epoch 238/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.7763 - accuracy: 0.6896 - val_loss: 1.4078 - val_accuracy: 0.4238\n",
            "Epoch 239/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.7691 - accuracy: 0.7066 - val_loss: 1.4142 - val_accuracy: 0.3974\n",
            "Epoch 240/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.7658 - accuracy: 0.7029 - val_loss: 1.4369 - val_accuracy: 0.3775\n",
            "Epoch 241/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.7504 - accuracy: 0.7066 - val_loss: 1.4181 - val_accuracy: 0.3907\n",
            "Epoch 242/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.7900 - accuracy: 0.6851 - val_loss: 1.4273 - val_accuracy: 0.3974\n",
            "Epoch 243/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.7761 - accuracy: 0.6874 - val_loss: 1.4128 - val_accuracy: 0.4172\n",
            "Epoch 244/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.7584 - accuracy: 0.7044 - val_loss: 1.4797 - val_accuracy: 0.3974\n",
            "Epoch 245/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.7739 - accuracy: 0.6955 - val_loss: 1.4140 - val_accuracy: 0.3841\n",
            "Epoch 246/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.7616 - accuracy: 0.6992 - val_loss: 1.4092 - val_accuracy: 0.4040\n",
            "Epoch 247/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.7584 - accuracy: 0.6940 - val_loss: 1.4065 - val_accuracy: 0.4040\n",
            "Epoch 248/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.7503 - accuracy: 0.7125 - val_loss: 1.3830 - val_accuracy: 0.4172\n",
            "Epoch 249/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.7518 - accuracy: 0.7029 - val_loss: 1.4146 - val_accuracy: 0.4106\n",
            "Epoch 250/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.7479 - accuracy: 0.7154 - val_loss: 1.4287 - val_accuracy: 0.3775\n",
            "Epoch 251/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.7490 - accuracy: 0.7125 - val_loss: 1.4272 - val_accuracy: 0.4238\n",
            "Epoch 252/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.7397 - accuracy: 0.7007 - val_loss: 1.4008 - val_accuracy: 0.4238\n",
            "Epoch 253/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.7314 - accuracy: 0.7095 - val_loss: 1.4035 - val_accuracy: 0.4106\n",
            "Epoch 254/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.7505 - accuracy: 0.7125 - val_loss: 1.4126 - val_accuracy: 0.4040\n",
            "Epoch 255/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.7193 - accuracy: 0.7265 - val_loss: 1.3991 - val_accuracy: 0.4238\n",
            "Epoch 256/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.7509 - accuracy: 0.7169 - val_loss: 1.4273 - val_accuracy: 0.4371\n",
            "Epoch 257/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.7390 - accuracy: 0.7066 - val_loss: 1.3988 - val_accuracy: 0.4437\n",
            "Epoch 258/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.7261 - accuracy: 0.7162 - val_loss: 1.4071 - val_accuracy: 0.3974\n",
            "Epoch 259/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.7443 - accuracy: 0.7058 - val_loss: 1.4072 - val_accuracy: 0.4040\n",
            "Epoch 260/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.7359 - accuracy: 0.7051 - val_loss: 1.4219 - val_accuracy: 0.4106\n",
            "Epoch 261/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.7386 - accuracy: 0.7014 - val_loss: 1.4404 - val_accuracy: 0.4106\n",
            "Epoch 262/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.7326 - accuracy: 0.7191 - val_loss: 1.4661 - val_accuracy: 0.4106\n",
            "Epoch 263/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.7234 - accuracy: 0.7044 - val_loss: 1.4195 - val_accuracy: 0.4106\n",
            "Epoch 264/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.7260 - accuracy: 0.7162 - val_loss: 1.4176 - val_accuracy: 0.4040\n",
            "Epoch 265/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.7284 - accuracy: 0.7288 - val_loss: 1.3891 - val_accuracy: 0.4106\n",
            "Epoch 266/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.7458 - accuracy: 0.6948 - val_loss: 1.4136 - val_accuracy: 0.3974\n",
            "Epoch 267/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.7178 - accuracy: 0.7236 - val_loss: 1.3978 - val_accuracy: 0.4172\n",
            "Epoch 268/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.7284 - accuracy: 0.7103 - val_loss: 1.4204 - val_accuracy: 0.3974\n",
            "Epoch 269/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.7156 - accuracy: 0.7280 - val_loss: 1.4204 - val_accuracy: 0.4172\n",
            "Epoch 270/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.7288 - accuracy: 0.7088 - val_loss: 1.3787 - val_accuracy: 0.4305\n",
            "Epoch 271/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.7273 - accuracy: 0.7125 - val_loss: 1.4612 - val_accuracy: 0.3841\n",
            "Epoch 272/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.7163 - accuracy: 0.7199 - val_loss: 1.3942 - val_accuracy: 0.4305\n",
            "Epoch 273/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.7217 - accuracy: 0.7184 - val_loss: 1.4513 - val_accuracy: 0.3907\n",
            "Epoch 274/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.7248 - accuracy: 0.7214 - val_loss: 1.3982 - val_accuracy: 0.4040\n",
            "Epoch 275/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.7137 - accuracy: 0.7177 - val_loss: 1.4069 - val_accuracy: 0.4172\n",
            "Epoch 276/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.7107 - accuracy: 0.7214 - val_loss: 1.4176 - val_accuracy: 0.4238\n",
            "Epoch 277/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.7273 - accuracy: 0.7169 - val_loss: 1.4037 - val_accuracy: 0.4305\n",
            "Epoch 278/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.7192 - accuracy: 0.7265 - val_loss: 1.3996 - val_accuracy: 0.4570\n",
            "Epoch 279/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.7133 - accuracy: 0.7236 - val_loss: 1.4492 - val_accuracy: 0.4238\n",
            "Epoch 280/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.7088 - accuracy: 0.7339 - val_loss: 1.4390 - val_accuracy: 0.3974\n",
            "Epoch 281/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.7082 - accuracy: 0.7214 - val_loss: 1.4434 - val_accuracy: 0.3974\n",
            "Epoch 282/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.6971 - accuracy: 0.7221 - val_loss: 1.4104 - val_accuracy: 0.3974\n",
            "Epoch 283/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.7070 - accuracy: 0.7243 - val_loss: 1.4498 - val_accuracy: 0.3974\n",
            "Epoch 284/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.7033 - accuracy: 0.7265 - val_loss: 1.3803 - val_accuracy: 0.4503\n",
            "Epoch 285/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.6958 - accuracy: 0.7332 - val_loss: 1.4496 - val_accuracy: 0.3974\n",
            "Epoch 286/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.6918 - accuracy: 0.7413 - val_loss: 1.4077 - val_accuracy: 0.4040\n",
            "Epoch 287/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.6936 - accuracy: 0.7302 - val_loss: 1.4212 - val_accuracy: 0.3974\n",
            "Epoch 288/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.6998 - accuracy: 0.7184 - val_loss: 1.3876 - val_accuracy: 0.4437\n",
            "Epoch 289/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.6871 - accuracy: 0.7361 - val_loss: 1.4060 - val_accuracy: 0.4172\n",
            "Epoch 290/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.7016 - accuracy: 0.7280 - val_loss: 1.4145 - val_accuracy: 0.4106\n",
            "Epoch 291/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.7001 - accuracy: 0.7280 - val_loss: 1.4346 - val_accuracy: 0.4040\n",
            "Epoch 292/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.6971 - accuracy: 0.7184 - val_loss: 1.4314 - val_accuracy: 0.4040\n",
            "Epoch 293/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.6823 - accuracy: 0.7354 - val_loss: 1.4305 - val_accuracy: 0.3907\n",
            "Epoch 294/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.6959 - accuracy: 0.7236 - val_loss: 1.4179 - val_accuracy: 0.3974\n",
            "Epoch 295/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.6854 - accuracy: 0.7221 - val_loss: 1.4008 - val_accuracy: 0.4238\n",
            "Epoch 296/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.6810 - accuracy: 0.7347 - val_loss: 1.4523 - val_accuracy: 0.4040\n",
            "Epoch 297/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.6731 - accuracy: 0.7524 - val_loss: 1.4566 - val_accuracy: 0.3841\n",
            "Epoch 298/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.6866 - accuracy: 0.7361 - val_loss: 1.4686 - val_accuracy: 0.4106\n",
            "Epoch 299/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.6818 - accuracy: 0.7435 - val_loss: 1.4322 - val_accuracy: 0.3974\n",
            "Epoch 300/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.6818 - accuracy: 0.7391 - val_loss: 1.4663 - val_accuracy: 0.4040\n",
            "Epoch 301/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.6923 - accuracy: 0.7280 - val_loss: 1.3956 - val_accuracy: 0.4570\n",
            "Epoch 302/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.6705 - accuracy: 0.7384 - val_loss: 1.4078 - val_accuracy: 0.4305\n",
            "Epoch 303/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.6731 - accuracy: 0.7450 - val_loss: 1.4688 - val_accuracy: 0.3907\n",
            "Epoch 304/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.6784 - accuracy: 0.7317 - val_loss: 1.4456 - val_accuracy: 0.3841\n",
            "Epoch 305/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.6645 - accuracy: 0.7458 - val_loss: 1.4636 - val_accuracy: 0.3775\n",
            "Epoch 306/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.6784 - accuracy: 0.7509 - val_loss: 1.4858 - val_accuracy: 0.3841\n",
            "Epoch 307/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.6530 - accuracy: 0.7472 - val_loss: 1.4709 - val_accuracy: 0.3974\n",
            "Epoch 308/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.6610 - accuracy: 0.7524 - val_loss: 1.4175 - val_accuracy: 0.4172\n",
            "Epoch 309/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.6587 - accuracy: 0.7465 - val_loss: 1.4157 - val_accuracy: 0.4172\n",
            "Epoch 310/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.6660 - accuracy: 0.7376 - val_loss: 1.4520 - val_accuracy: 0.4172\n",
            "Epoch 311/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.6701 - accuracy: 0.7413 - val_loss: 1.4451 - val_accuracy: 0.4503\n",
            "Epoch 312/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.6607 - accuracy: 0.7413 - val_loss: 1.4409 - val_accuracy: 0.4371\n",
            "Epoch 313/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.6748 - accuracy: 0.7376 - val_loss: 1.4931 - val_accuracy: 0.3974\n",
            "Epoch 314/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.6837 - accuracy: 0.7310 - val_loss: 1.4416 - val_accuracy: 0.4172\n",
            "Epoch 315/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.6628 - accuracy: 0.7421 - val_loss: 1.4275 - val_accuracy: 0.4040\n",
            "Epoch 316/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.6574 - accuracy: 0.7487 - val_loss: 1.4678 - val_accuracy: 0.3974\n",
            "Epoch 317/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.6521 - accuracy: 0.7413 - val_loss: 1.5232 - val_accuracy: 0.3709\n",
            "Epoch 318/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.6506 - accuracy: 0.7354 - val_loss: 1.4436 - val_accuracy: 0.3907\n",
            "Epoch 319/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.6588 - accuracy: 0.7369 - val_loss: 1.4702 - val_accuracy: 0.3974\n",
            "Epoch 320/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.6588 - accuracy: 0.7480 - val_loss: 1.4613 - val_accuracy: 0.4172\n",
            "Epoch 321/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.6554 - accuracy: 0.7531 - val_loss: 1.4891 - val_accuracy: 0.4238\n",
            "Epoch 322/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.6567 - accuracy: 0.7465 - val_loss: 1.4444 - val_accuracy: 0.4040\n",
            "Epoch 323/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.6473 - accuracy: 0.7487 - val_loss: 1.4444 - val_accuracy: 0.3974\n",
            "Epoch 324/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.6499 - accuracy: 0.7421 - val_loss: 1.4426 - val_accuracy: 0.3974\n",
            "Epoch 325/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.6413 - accuracy: 0.7502 - val_loss: 1.4207 - val_accuracy: 0.4172\n",
            "Epoch 326/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.6414 - accuracy: 0.7583 - val_loss: 1.4423 - val_accuracy: 0.4040\n",
            "Epoch 327/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.6635 - accuracy: 0.7480 - val_loss: 1.4278 - val_accuracy: 0.4106\n",
            "Epoch 328/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.6387 - accuracy: 0.7546 - val_loss: 1.4526 - val_accuracy: 0.4106\n",
            "Epoch 329/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.6469 - accuracy: 0.7568 - val_loss: 1.4405 - val_accuracy: 0.4371\n",
            "Epoch 330/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.6288 - accuracy: 0.7494 - val_loss: 1.5350 - val_accuracy: 0.4106\n",
            "Epoch 331/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.6324 - accuracy: 0.7583 - val_loss: 1.4645 - val_accuracy: 0.3974\n",
            "Epoch 332/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.6315 - accuracy: 0.7568 - val_loss: 1.4178 - val_accuracy: 0.4371\n",
            "Epoch 333/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.6395 - accuracy: 0.7517 - val_loss: 1.4346 - val_accuracy: 0.4040\n",
            "Epoch 334/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.6383 - accuracy: 0.7450 - val_loss: 1.4706 - val_accuracy: 0.4106\n",
            "Epoch 335/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.6371 - accuracy: 0.7487 - val_loss: 1.4562 - val_accuracy: 0.4040\n",
            "Epoch 336/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.6496 - accuracy: 0.7458 - val_loss: 1.4518 - val_accuracy: 0.4106\n",
            "Epoch 337/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.6242 - accuracy: 0.7605 - val_loss: 1.4742 - val_accuracy: 0.3907\n",
            "Epoch 338/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.6481 - accuracy: 0.7465 - val_loss: 1.5129 - val_accuracy: 0.3974\n",
            "Epoch 339/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.6317 - accuracy: 0.7450 - val_loss: 1.5014 - val_accuracy: 0.4172\n",
            "Epoch 340/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.6424 - accuracy: 0.7568 - val_loss: 1.4813 - val_accuracy: 0.4172\n",
            "Epoch 341/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.6388 - accuracy: 0.7443 - val_loss: 1.4610 - val_accuracy: 0.4371\n",
            "Epoch 342/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.6317 - accuracy: 0.7546 - val_loss: 1.4616 - val_accuracy: 0.4172\n",
            "Epoch 343/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.6280 - accuracy: 0.7613 - val_loss: 1.4645 - val_accuracy: 0.3974\n",
            "Epoch 344/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.6067 - accuracy: 0.7664 - val_loss: 1.4768 - val_accuracy: 0.4040\n",
            "Epoch 345/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.6423 - accuracy: 0.7554 - val_loss: 1.4732 - val_accuracy: 0.4172\n",
            "Epoch 346/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.6233 - accuracy: 0.7664 - val_loss: 1.4563 - val_accuracy: 0.4172\n",
            "Epoch 347/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.6069 - accuracy: 0.7576 - val_loss: 1.4659 - val_accuracy: 0.4371\n",
            "Epoch 348/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.6211 - accuracy: 0.7664 - val_loss: 1.4819 - val_accuracy: 0.3974\n",
            "Epoch 349/700\n",
            "85/85 [==============================] - 2s 25ms/step - loss: 0.6233 - accuracy: 0.7694 - val_loss: 1.4729 - val_accuracy: 0.4106\n",
            "Epoch 350/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.6351 - accuracy: 0.7561 - val_loss: 1.5499 - val_accuracy: 0.3841\n",
            "Epoch 351/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.6141 - accuracy: 0.7568 - val_loss: 1.4688 - val_accuracy: 0.4040\n",
            "Epoch 352/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.6161 - accuracy: 0.7598 - val_loss: 1.4847 - val_accuracy: 0.4106\n",
            "Epoch 353/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.6050 - accuracy: 0.7716 - val_loss: 1.4779 - val_accuracy: 0.4040\n",
            "Epoch 354/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.6084 - accuracy: 0.7672 - val_loss: 1.4702 - val_accuracy: 0.3974\n",
            "Epoch 355/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.6159 - accuracy: 0.7820 - val_loss: 1.5254 - val_accuracy: 0.3841\n",
            "Epoch 356/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.6075 - accuracy: 0.7576 - val_loss: 1.4627 - val_accuracy: 0.4305\n",
            "Epoch 357/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.6037 - accuracy: 0.7657 - val_loss: 1.4980 - val_accuracy: 0.4040\n",
            "Epoch 358/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.5986 - accuracy: 0.7716 - val_loss: 1.4676 - val_accuracy: 0.4040\n",
            "Epoch 359/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.5924 - accuracy: 0.7724 - val_loss: 1.4868 - val_accuracy: 0.4106\n",
            "Epoch 360/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.6136 - accuracy: 0.7605 - val_loss: 1.4694 - val_accuracy: 0.4305\n",
            "Epoch 361/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.5981 - accuracy: 0.7724 - val_loss: 1.4766 - val_accuracy: 0.3974\n",
            "Epoch 362/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.5983 - accuracy: 0.7738 - val_loss: 1.4661 - val_accuracy: 0.3974\n",
            "Epoch 363/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.6149 - accuracy: 0.7627 - val_loss: 1.4465 - val_accuracy: 0.4305\n",
            "Epoch 364/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.5892 - accuracy: 0.7746 - val_loss: 1.4584 - val_accuracy: 0.4636\n",
            "Epoch 365/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.6029 - accuracy: 0.7761 - val_loss: 1.4592 - val_accuracy: 0.4106\n",
            "Epoch 366/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.6010 - accuracy: 0.7664 - val_loss: 1.4809 - val_accuracy: 0.4040\n",
            "Epoch 367/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.6159 - accuracy: 0.7480 - val_loss: 1.5392 - val_accuracy: 0.3775\n",
            "Epoch 368/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.5921 - accuracy: 0.7783 - val_loss: 1.5070 - val_accuracy: 0.3907\n",
            "Epoch 369/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.6124 - accuracy: 0.7576 - val_loss: 1.4909 - val_accuracy: 0.3974\n",
            "Epoch 370/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.6035 - accuracy: 0.7701 - val_loss: 1.4358 - val_accuracy: 0.4238\n",
            "Epoch 371/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.5881 - accuracy: 0.7775 - val_loss: 1.5095 - val_accuracy: 0.4106\n",
            "Epoch 372/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.6127 - accuracy: 0.7701 - val_loss: 1.5136 - val_accuracy: 0.4172\n",
            "Epoch 373/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.5710 - accuracy: 0.7783 - val_loss: 1.5204 - val_accuracy: 0.4172\n",
            "Epoch 374/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.5934 - accuracy: 0.7672 - val_loss: 1.5024 - val_accuracy: 0.4040\n",
            "Epoch 375/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.5891 - accuracy: 0.7583 - val_loss: 1.5283 - val_accuracy: 0.3907\n",
            "Epoch 376/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.5857 - accuracy: 0.7716 - val_loss: 1.4721 - val_accuracy: 0.4238\n",
            "Epoch 377/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.5889 - accuracy: 0.7724 - val_loss: 1.4800 - val_accuracy: 0.4106\n",
            "Epoch 378/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.5829 - accuracy: 0.7687 - val_loss: 1.5055 - val_accuracy: 0.4172\n",
            "Epoch 379/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.5805 - accuracy: 0.7805 - val_loss: 1.4901 - val_accuracy: 0.4106\n",
            "Epoch 380/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.5950 - accuracy: 0.7672 - val_loss: 1.5249 - val_accuracy: 0.4040\n",
            "Epoch 381/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.5773 - accuracy: 0.7797 - val_loss: 1.4741 - val_accuracy: 0.4106\n",
            "Epoch 382/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.5772 - accuracy: 0.7827 - val_loss: 1.4434 - val_accuracy: 0.4238\n",
            "Epoch 383/700\n",
            "85/85 [==============================] - 2s 25ms/step - loss: 0.5820 - accuracy: 0.7783 - val_loss: 1.4927 - val_accuracy: 0.4238\n",
            "Epoch 384/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.5745 - accuracy: 0.7701 - val_loss: 1.5092 - val_accuracy: 0.4040\n",
            "Epoch 385/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.5669 - accuracy: 0.7797 - val_loss: 1.5114 - val_accuracy: 0.4040\n",
            "Epoch 386/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.5708 - accuracy: 0.7827 - val_loss: 1.5418 - val_accuracy: 0.3974\n",
            "Epoch 387/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.5706 - accuracy: 0.7820 - val_loss: 1.4808 - val_accuracy: 0.4238\n",
            "Epoch 388/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.5892 - accuracy: 0.7709 - val_loss: 1.5028 - val_accuracy: 0.4040\n",
            "Epoch 389/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.5812 - accuracy: 0.7694 - val_loss: 1.4974 - val_accuracy: 0.4040\n",
            "Epoch 390/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.5670 - accuracy: 0.7901 - val_loss: 1.5025 - val_accuracy: 0.4238\n",
            "Epoch 391/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.5792 - accuracy: 0.7679 - val_loss: 1.5087 - val_accuracy: 0.4106\n",
            "Epoch 392/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.5713 - accuracy: 0.7790 - val_loss: 1.4788 - val_accuracy: 0.4238\n",
            "Epoch 393/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.5605 - accuracy: 0.7894 - val_loss: 1.5067 - val_accuracy: 0.4238\n",
            "Epoch 394/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.5750 - accuracy: 0.7812 - val_loss: 1.4949 - val_accuracy: 0.4172\n",
            "Epoch 395/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.5677 - accuracy: 0.7738 - val_loss: 1.5379 - val_accuracy: 0.4106\n",
            "Epoch 396/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.5693 - accuracy: 0.7746 - val_loss: 1.5239 - val_accuracy: 0.4437\n",
            "Epoch 397/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.5592 - accuracy: 0.7812 - val_loss: 1.5300 - val_accuracy: 0.4238\n",
            "Epoch 398/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.5708 - accuracy: 0.7775 - val_loss: 1.4752 - val_accuracy: 0.4106\n",
            "Epoch 399/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.5795 - accuracy: 0.7679 - val_loss: 1.5216 - val_accuracy: 0.4106\n",
            "Epoch 400/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.5608 - accuracy: 0.7857 - val_loss: 1.5496 - val_accuracy: 0.4106\n",
            "Epoch 401/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.5669 - accuracy: 0.7864 - val_loss: 1.5105 - val_accuracy: 0.4040\n",
            "Epoch 402/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.5799 - accuracy: 0.7753 - val_loss: 1.5393 - val_accuracy: 0.4238\n",
            "Epoch 403/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.5487 - accuracy: 0.7857 - val_loss: 1.5113 - val_accuracy: 0.4106\n",
            "Epoch 404/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.5412 - accuracy: 0.7953 - val_loss: 1.5406 - val_accuracy: 0.4106\n",
            "Epoch 405/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.5643 - accuracy: 0.7716 - val_loss: 1.5154 - val_accuracy: 0.4040\n",
            "Epoch 406/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.5687 - accuracy: 0.7938 - val_loss: 1.5875 - val_accuracy: 0.4040\n",
            "Epoch 407/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.5610 - accuracy: 0.7709 - val_loss: 1.5087 - val_accuracy: 0.4172\n",
            "Epoch 408/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.5465 - accuracy: 0.7931 - val_loss: 1.5509 - val_accuracy: 0.3974\n",
            "Epoch 409/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.5460 - accuracy: 0.7982 - val_loss: 1.5363 - val_accuracy: 0.4305\n",
            "Epoch 410/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.5381 - accuracy: 0.7908 - val_loss: 1.4879 - val_accuracy: 0.4172\n",
            "Epoch 411/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.5693 - accuracy: 0.7731 - val_loss: 1.5438 - val_accuracy: 0.4172\n",
            "Epoch 412/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.5754 - accuracy: 0.7857 - val_loss: 1.5150 - val_accuracy: 0.4371\n",
            "Epoch 413/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.5471 - accuracy: 0.7886 - val_loss: 1.5249 - val_accuracy: 0.4040\n",
            "Epoch 414/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.5339 - accuracy: 0.8012 - val_loss: 1.5423 - val_accuracy: 0.4305\n",
            "Epoch 415/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.5568 - accuracy: 0.7820 - val_loss: 1.4904 - val_accuracy: 0.4106\n",
            "Epoch 416/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.5517 - accuracy: 0.7871 - val_loss: 1.5569 - val_accuracy: 0.4106\n",
            "Epoch 417/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.5502 - accuracy: 0.7901 - val_loss: 1.5718 - val_accuracy: 0.4106\n",
            "Epoch 418/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.5467 - accuracy: 0.7879 - val_loss: 1.5127 - val_accuracy: 0.4106\n",
            "Epoch 419/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.5400 - accuracy: 0.7997 - val_loss: 1.4966 - val_accuracy: 0.4172\n",
            "Epoch 420/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.5491 - accuracy: 0.7901 - val_loss: 1.5027 - val_accuracy: 0.4437\n",
            "Epoch 421/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.5534 - accuracy: 0.7857 - val_loss: 1.5446 - val_accuracy: 0.4238\n",
            "Epoch 422/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.5420 - accuracy: 0.7953 - val_loss: 1.5272 - val_accuracy: 0.4106\n",
            "Epoch 423/700\n",
            "85/85 [==============================] - 2s 25ms/step - loss: 0.5432 - accuracy: 0.7871 - val_loss: 1.5490 - val_accuracy: 0.4172\n",
            "Epoch 424/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.5391 - accuracy: 0.8041 - val_loss: 1.5632 - val_accuracy: 0.4238\n",
            "Epoch 425/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.5413 - accuracy: 0.7871 - val_loss: 1.5305 - val_accuracy: 0.4106\n",
            "Epoch 426/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.5363 - accuracy: 0.7834 - val_loss: 1.5264 - val_accuracy: 0.4371\n",
            "Epoch 427/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.5562 - accuracy: 0.7849 - val_loss: 1.5542 - val_accuracy: 0.4238\n",
            "Epoch 428/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.5493 - accuracy: 0.7701 - val_loss: 1.5757 - val_accuracy: 0.4040\n",
            "Epoch 429/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.5381 - accuracy: 0.8027 - val_loss: 1.5305 - val_accuracy: 0.4305\n",
            "Epoch 430/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.5365 - accuracy: 0.7931 - val_loss: 1.6289 - val_accuracy: 0.3974\n",
            "Epoch 431/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.5269 - accuracy: 0.8019 - val_loss: 1.5537 - val_accuracy: 0.4305\n",
            "Epoch 432/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.5280 - accuracy: 0.7938 - val_loss: 1.5282 - val_accuracy: 0.4503\n",
            "Epoch 433/700\n",
            "85/85 [==============================] - 2s 25ms/step - loss: 0.5283 - accuracy: 0.8101 - val_loss: 1.5043 - val_accuracy: 0.4570\n",
            "Epoch 434/700\n",
            "85/85 [==============================] - 2s 25ms/step - loss: 0.5217 - accuracy: 0.7901 - val_loss: 1.5266 - val_accuracy: 0.4238\n",
            "Epoch 435/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.5217 - accuracy: 0.7923 - val_loss: 1.5256 - val_accuracy: 0.4238\n",
            "Epoch 436/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.5384 - accuracy: 0.7864 - val_loss: 1.5357 - val_accuracy: 0.4238\n",
            "Epoch 437/700\n",
            "85/85 [==============================] - 2s 25ms/step - loss: 0.5390 - accuracy: 0.7894 - val_loss: 1.5172 - val_accuracy: 0.4172\n",
            "Epoch 438/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.5221 - accuracy: 0.7975 - val_loss: 1.5101 - val_accuracy: 0.4238\n",
            "Epoch 439/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.5286 - accuracy: 0.7960 - val_loss: 1.6477 - val_accuracy: 0.4172\n",
            "Epoch 440/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.5083 - accuracy: 0.8174 - val_loss: 1.6137 - val_accuracy: 0.3974\n",
            "Epoch 441/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.5238 - accuracy: 0.7945 - val_loss: 1.6050 - val_accuracy: 0.4172\n",
            "Epoch 442/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.5117 - accuracy: 0.8034 - val_loss: 1.5202 - val_accuracy: 0.4305\n",
            "Epoch 443/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.5272 - accuracy: 0.8012 - val_loss: 1.5790 - val_accuracy: 0.4172\n",
            "Epoch 444/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.5338 - accuracy: 0.7960 - val_loss: 1.5393 - val_accuracy: 0.4437\n",
            "Epoch 445/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.5316 - accuracy: 0.7945 - val_loss: 1.5906 - val_accuracy: 0.4238\n",
            "Epoch 446/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.5238 - accuracy: 0.7997 - val_loss: 1.5601 - val_accuracy: 0.4371\n",
            "Epoch 447/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.5402 - accuracy: 0.7931 - val_loss: 1.5621 - val_accuracy: 0.4503\n",
            "Epoch 448/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.5075 - accuracy: 0.8086 - val_loss: 1.5470 - val_accuracy: 0.4106\n",
            "Epoch 449/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.5072 - accuracy: 0.7960 - val_loss: 1.5995 - val_accuracy: 0.4106\n",
            "Epoch 450/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.5120 - accuracy: 0.8012 - val_loss: 1.4825 - val_accuracy: 0.4503\n",
            "Epoch 451/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.5133 - accuracy: 0.8041 - val_loss: 1.5208 - val_accuracy: 0.4305\n",
            "Epoch 452/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.5350 - accuracy: 0.7871 - val_loss: 1.5229 - val_accuracy: 0.4172\n",
            "Epoch 453/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.5229 - accuracy: 0.7967 - val_loss: 1.5376 - val_accuracy: 0.4305\n",
            "Epoch 454/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.5173 - accuracy: 0.8004 - val_loss: 1.5185 - val_accuracy: 0.4238\n",
            "Epoch 455/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.5153 - accuracy: 0.8041 - val_loss: 1.5295 - val_accuracy: 0.4238\n",
            "Epoch 456/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.5282 - accuracy: 0.7923 - val_loss: 1.6205 - val_accuracy: 0.3907\n",
            "Epoch 457/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.5040 - accuracy: 0.8056 - val_loss: 1.6031 - val_accuracy: 0.4106\n",
            "Epoch 458/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.5193 - accuracy: 0.7916 - val_loss: 1.5611 - val_accuracy: 0.4172\n",
            "Epoch 459/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.5191 - accuracy: 0.7982 - val_loss: 1.6388 - val_accuracy: 0.3841\n",
            "Epoch 460/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.5297 - accuracy: 0.7990 - val_loss: 1.5980 - val_accuracy: 0.4172\n",
            "Epoch 461/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.4963 - accuracy: 0.8071 - val_loss: 1.6566 - val_accuracy: 0.4172\n",
            "Epoch 462/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.5042 - accuracy: 0.8093 - val_loss: 1.5199 - val_accuracy: 0.4172\n",
            "Epoch 463/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.5112 - accuracy: 0.8012 - val_loss: 1.5655 - val_accuracy: 0.4305\n",
            "Epoch 464/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.4882 - accuracy: 0.8145 - val_loss: 1.5534 - val_accuracy: 0.4040\n",
            "Epoch 465/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.4941 - accuracy: 0.8123 - val_loss: 1.5584 - val_accuracy: 0.4172\n",
            "Epoch 466/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.5095 - accuracy: 0.8056 - val_loss: 1.5574 - val_accuracy: 0.3974\n",
            "Epoch 467/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.5109 - accuracy: 0.7982 - val_loss: 1.6414 - val_accuracy: 0.4106\n",
            "Epoch 468/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.4755 - accuracy: 0.8234 - val_loss: 1.6304 - val_accuracy: 0.4040\n",
            "Epoch 469/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.5121 - accuracy: 0.8012 - val_loss: 1.5861 - val_accuracy: 0.4437\n",
            "Epoch 470/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.4990 - accuracy: 0.7945 - val_loss: 1.6050 - val_accuracy: 0.4040\n",
            "Epoch 471/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.4930 - accuracy: 0.8167 - val_loss: 1.6477 - val_accuracy: 0.4305\n",
            "Epoch 472/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.4909 - accuracy: 0.8093 - val_loss: 1.6204 - val_accuracy: 0.4040\n",
            "Epoch 473/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.5136 - accuracy: 0.8034 - val_loss: 1.5685 - val_accuracy: 0.4172\n",
            "Epoch 474/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.4931 - accuracy: 0.7975 - val_loss: 1.5703 - val_accuracy: 0.4172\n",
            "Epoch 475/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.4896 - accuracy: 0.8086 - val_loss: 1.5552 - val_accuracy: 0.4238\n",
            "Epoch 476/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.4984 - accuracy: 0.8004 - val_loss: 1.6000 - val_accuracy: 0.4503\n",
            "Epoch 477/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.4938 - accuracy: 0.8071 - val_loss: 1.5148 - val_accuracy: 0.4437\n",
            "Epoch 478/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.4804 - accuracy: 0.8189 - val_loss: 1.5445 - val_accuracy: 0.4437\n",
            "Epoch 479/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.4917 - accuracy: 0.8056 - val_loss: 1.6310 - val_accuracy: 0.3907\n",
            "Epoch 480/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.4936 - accuracy: 0.8071 - val_loss: 1.4975 - val_accuracy: 0.4305\n",
            "Epoch 481/700\n",
            "85/85 [==============================] - 2s 25ms/step - loss: 0.4923 - accuracy: 0.8115 - val_loss: 1.5667 - val_accuracy: 0.4238\n",
            "Epoch 482/700\n",
            "85/85 [==============================] - 2s 26ms/step - loss: 0.4877 - accuracy: 0.8211 - val_loss: 1.5670 - val_accuracy: 0.4238\n",
            "Epoch 483/700\n",
            "85/85 [==============================] - 2s 29ms/step - loss: 0.4759 - accuracy: 0.8137 - val_loss: 1.5374 - val_accuracy: 0.4305\n",
            "Epoch 484/700\n",
            "85/85 [==============================] - 2s 28ms/step - loss: 0.4692 - accuracy: 0.8145 - val_loss: 1.5821 - val_accuracy: 0.4437\n",
            "Epoch 485/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.4882 - accuracy: 0.8004 - val_loss: 1.5437 - val_accuracy: 0.4437\n",
            "Epoch 486/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.4890 - accuracy: 0.8130 - val_loss: 1.6717 - val_accuracy: 0.3841\n",
            "Epoch 487/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.4979 - accuracy: 0.8219 - val_loss: 1.5343 - val_accuracy: 0.4172\n",
            "Epoch 488/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.4905 - accuracy: 0.8130 - val_loss: 1.5450 - val_accuracy: 0.4503\n",
            "Epoch 489/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.4843 - accuracy: 0.8093 - val_loss: 1.5877 - val_accuracy: 0.4040\n",
            "Epoch 490/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.4764 - accuracy: 0.8167 - val_loss: 1.5584 - val_accuracy: 0.4371\n",
            "Epoch 491/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.5065 - accuracy: 0.7908 - val_loss: 1.5443 - val_accuracy: 0.4106\n",
            "Epoch 492/700\n",
            "85/85 [==============================] - 2s 25ms/step - loss: 0.4604 - accuracy: 0.8322 - val_loss: 1.5204 - val_accuracy: 0.4437\n",
            "Epoch 493/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.4652 - accuracy: 0.8307 - val_loss: 1.5392 - val_accuracy: 0.4371\n",
            "Epoch 494/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.4814 - accuracy: 0.8078 - val_loss: 1.5515 - val_accuracy: 0.4305\n",
            "Epoch 495/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.4760 - accuracy: 0.8078 - val_loss: 1.5913 - val_accuracy: 0.4238\n",
            "Epoch 496/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.4794 - accuracy: 0.8115 - val_loss: 1.6742 - val_accuracy: 0.4305\n",
            "Epoch 497/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.4933 - accuracy: 0.8027 - val_loss: 1.5978 - val_accuracy: 0.4437\n",
            "Epoch 498/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.4560 - accuracy: 0.8226 - val_loss: 1.6371 - val_accuracy: 0.4040\n",
            "Epoch 499/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.4896 - accuracy: 0.8108 - val_loss: 1.5892 - val_accuracy: 0.4238\n",
            "Epoch 500/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.4610 - accuracy: 0.8204 - val_loss: 1.6228 - val_accuracy: 0.4305\n",
            "Epoch 501/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.4616 - accuracy: 0.8300 - val_loss: 1.6538 - val_accuracy: 0.3974\n",
            "Epoch 502/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.4771 - accuracy: 0.8049 - val_loss: 1.5402 - val_accuracy: 0.4437\n",
            "Epoch 503/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.4952 - accuracy: 0.8078 - val_loss: 1.5385 - val_accuracy: 0.4437\n",
            "Epoch 504/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.4750 - accuracy: 0.8115 - val_loss: 1.5910 - val_accuracy: 0.4371\n",
            "Epoch 505/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.4619 - accuracy: 0.8248 - val_loss: 1.5846 - val_accuracy: 0.4106\n",
            "Epoch 506/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.4672 - accuracy: 0.8263 - val_loss: 1.5997 - val_accuracy: 0.4172\n",
            "Epoch 507/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.4626 - accuracy: 0.8123 - val_loss: 1.5417 - val_accuracy: 0.4437\n",
            "Epoch 508/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.4712 - accuracy: 0.8167 - val_loss: 1.6042 - val_accuracy: 0.4172\n",
            "Epoch 509/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.4755 - accuracy: 0.8145 - val_loss: 1.5185 - val_accuracy: 0.4437\n",
            "Epoch 510/700\n",
            "85/85 [==============================] - 2s 25ms/step - loss: 0.4716 - accuracy: 0.8174 - val_loss: 1.6336 - val_accuracy: 0.4371\n",
            "Epoch 511/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.4572 - accuracy: 0.8278 - val_loss: 1.5327 - val_accuracy: 0.4238\n",
            "Epoch 512/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.4701 - accuracy: 0.8182 - val_loss: 1.5394 - val_accuracy: 0.4172\n",
            "Epoch 513/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.4608 - accuracy: 0.8189 - val_loss: 1.5842 - val_accuracy: 0.4305\n",
            "Epoch 514/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.4545 - accuracy: 0.8197 - val_loss: 1.5709 - val_accuracy: 0.4238\n",
            "Epoch 515/700\n",
            "85/85 [==============================] - 2s 25ms/step - loss: 0.4646 - accuracy: 0.8226 - val_loss: 1.6074 - val_accuracy: 0.4172\n",
            "Epoch 516/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.4765 - accuracy: 0.8160 - val_loss: 1.5983 - val_accuracy: 0.4305\n",
            "Epoch 517/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.4544 - accuracy: 0.8300 - val_loss: 1.6327 - val_accuracy: 0.4305\n",
            "Epoch 518/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.4684 - accuracy: 0.8145 - val_loss: 1.5590 - val_accuracy: 0.4238\n",
            "Epoch 519/700\n",
            "85/85 [==============================] - 2s 25ms/step - loss: 0.4615 - accuracy: 0.8389 - val_loss: 1.5958 - val_accuracy: 0.4503\n",
            "Epoch 520/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.4718 - accuracy: 0.8197 - val_loss: 1.6083 - val_accuracy: 0.4238\n",
            "Epoch 521/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.4660 - accuracy: 0.8256 - val_loss: 1.5792 - val_accuracy: 0.4238\n",
            "Epoch 522/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.4331 - accuracy: 0.8367 - val_loss: 1.6573 - val_accuracy: 0.4437\n",
            "Epoch 523/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.4679 - accuracy: 0.8293 - val_loss: 1.5829 - val_accuracy: 0.4570\n",
            "Epoch 524/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.4474 - accuracy: 0.8263 - val_loss: 1.6043 - val_accuracy: 0.4238\n",
            "Epoch 525/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.4448 - accuracy: 0.8315 - val_loss: 1.5673 - val_accuracy: 0.4636\n",
            "Epoch 526/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.4530 - accuracy: 0.8248 - val_loss: 1.5699 - val_accuracy: 0.4503\n",
            "Epoch 527/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.4449 - accuracy: 0.8330 - val_loss: 1.6080 - val_accuracy: 0.4305\n",
            "Epoch 528/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.4340 - accuracy: 0.8307 - val_loss: 1.6058 - val_accuracy: 0.4172\n",
            "Epoch 529/700\n",
            "85/85 [==============================] - 2s 25ms/step - loss: 0.4457 - accuracy: 0.8315 - val_loss: 1.6105 - val_accuracy: 0.4305\n",
            "Epoch 530/700\n",
            "85/85 [==============================] - 2s 25ms/step - loss: 0.4574 - accuracy: 0.8293 - val_loss: 1.6106 - val_accuracy: 0.4106\n",
            "Epoch 531/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.4598 - accuracy: 0.8189 - val_loss: 1.6562 - val_accuracy: 0.4172\n",
            "Epoch 532/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.4394 - accuracy: 0.8367 - val_loss: 1.6199 - val_accuracy: 0.4106\n",
            "Epoch 533/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.4463 - accuracy: 0.8307 - val_loss: 1.5426 - val_accuracy: 0.4305\n",
            "Epoch 534/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.4346 - accuracy: 0.8389 - val_loss: 1.6341 - val_accuracy: 0.4238\n",
            "Epoch 535/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.4484 - accuracy: 0.8271 - val_loss: 1.6240 - val_accuracy: 0.4371\n",
            "Epoch 536/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.4265 - accuracy: 0.8337 - val_loss: 1.5782 - val_accuracy: 0.4040\n",
            "Epoch 537/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.4493 - accuracy: 0.8271 - val_loss: 1.6461 - val_accuracy: 0.4238\n",
            "Epoch 538/700\n",
            "85/85 [==============================] - 2s 25ms/step - loss: 0.4380 - accuracy: 0.8330 - val_loss: 1.6538 - val_accuracy: 0.4238\n",
            "Epoch 539/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.4342 - accuracy: 0.8300 - val_loss: 1.6160 - val_accuracy: 0.4172\n",
            "Epoch 540/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.4520 - accuracy: 0.8293 - val_loss: 1.5951 - val_accuracy: 0.4437\n",
            "Epoch 541/700\n",
            "85/85 [==============================] - 2s 25ms/step - loss: 0.4487 - accuracy: 0.8389 - val_loss: 1.6021 - val_accuracy: 0.4238\n",
            "Epoch 542/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.4099 - accuracy: 0.8500 - val_loss: 1.6385 - val_accuracy: 0.4570\n",
            "Epoch 543/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.4478 - accuracy: 0.8263 - val_loss: 1.6616 - val_accuracy: 0.4238\n",
            "Epoch 544/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.4556 - accuracy: 0.8189 - val_loss: 1.6639 - val_accuracy: 0.4371\n",
            "Epoch 545/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.4517 - accuracy: 0.8263 - val_loss: 1.5851 - val_accuracy: 0.4106\n",
            "Epoch 546/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.4449 - accuracy: 0.8337 - val_loss: 1.6319 - val_accuracy: 0.4238\n",
            "Epoch 547/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.4160 - accuracy: 0.8367 - val_loss: 1.6027 - val_accuracy: 0.4371\n",
            "Epoch 548/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.4157 - accuracy: 0.8389 - val_loss: 1.6745 - val_accuracy: 0.4106\n",
            "Epoch 549/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.4254 - accuracy: 0.8381 - val_loss: 1.6358 - val_accuracy: 0.4305\n",
            "Epoch 550/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.4308 - accuracy: 0.8374 - val_loss: 1.6202 - val_accuracy: 0.4503\n",
            "Epoch 551/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.4399 - accuracy: 0.8271 - val_loss: 1.5765 - val_accuracy: 0.4305\n",
            "Epoch 552/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.4189 - accuracy: 0.8463 - val_loss: 1.6351 - val_accuracy: 0.4437\n",
            "Epoch 553/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.4234 - accuracy: 0.8411 - val_loss: 1.5952 - val_accuracy: 0.4238\n",
            "Epoch 554/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.4305 - accuracy: 0.8381 - val_loss: 1.6290 - val_accuracy: 0.4172\n",
            "Epoch 555/700\n",
            "85/85 [==============================] - 2s 25ms/step - loss: 0.4412 - accuracy: 0.8248 - val_loss: 1.6299 - val_accuracy: 0.4371\n",
            "Epoch 556/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.4135 - accuracy: 0.8477 - val_loss: 1.6462 - val_accuracy: 0.4371\n",
            "Epoch 557/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.4718 - accuracy: 0.8226 - val_loss: 1.6471 - val_accuracy: 0.4371\n",
            "Epoch 558/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.4308 - accuracy: 0.8411 - val_loss: 1.5903 - val_accuracy: 0.4437\n",
            "Epoch 559/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.4262 - accuracy: 0.8300 - val_loss: 1.5898 - val_accuracy: 0.4570\n",
            "Epoch 560/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.4201 - accuracy: 0.8337 - val_loss: 1.6193 - val_accuracy: 0.4503\n",
            "Epoch 561/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.4334 - accuracy: 0.8418 - val_loss: 1.6091 - val_accuracy: 0.4172\n",
            "Epoch 562/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.4237 - accuracy: 0.8448 - val_loss: 1.6125 - val_accuracy: 0.4503\n",
            "Epoch 563/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.4118 - accuracy: 0.8492 - val_loss: 1.6020 - val_accuracy: 0.4503\n",
            "Epoch 564/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.4258 - accuracy: 0.8463 - val_loss: 1.5995 - val_accuracy: 0.4305\n",
            "Epoch 565/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.4213 - accuracy: 0.8389 - val_loss: 1.6030 - val_accuracy: 0.4371\n",
            "Epoch 566/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.4240 - accuracy: 0.8344 - val_loss: 1.6233 - val_accuracy: 0.4503\n",
            "Epoch 567/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.4286 - accuracy: 0.8500 - val_loss: 1.6185 - val_accuracy: 0.4437\n",
            "Epoch 568/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.4380 - accuracy: 0.8315 - val_loss: 1.7101 - val_accuracy: 0.3974\n",
            "Epoch 569/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.4157 - accuracy: 0.8374 - val_loss: 1.6760 - val_accuracy: 0.4305\n",
            "Epoch 570/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.4242 - accuracy: 0.8344 - val_loss: 1.6604 - val_accuracy: 0.4172\n",
            "Epoch 571/700\n",
            "85/85 [==============================] - 2s 25ms/step - loss: 0.4137 - accuracy: 0.8433 - val_loss: 1.6644 - val_accuracy: 0.4305\n",
            "Epoch 572/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.4204 - accuracy: 0.8381 - val_loss: 1.6015 - val_accuracy: 0.4371\n",
            "Epoch 573/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.4041 - accuracy: 0.8566 - val_loss: 1.6272 - val_accuracy: 0.4371\n",
            "Epoch 574/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.4173 - accuracy: 0.8529 - val_loss: 1.6368 - val_accuracy: 0.4238\n",
            "Epoch 575/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.3956 - accuracy: 0.8492 - val_loss: 1.5641 - val_accuracy: 0.4371\n",
            "Epoch 576/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.4339 - accuracy: 0.8381 - val_loss: 1.6178 - val_accuracy: 0.4371\n",
            "Epoch 577/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.4190 - accuracy: 0.8381 - val_loss: 1.6513 - val_accuracy: 0.4172\n",
            "Epoch 578/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.4164 - accuracy: 0.8418 - val_loss: 1.6162 - val_accuracy: 0.4636\n",
            "Epoch 579/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.4043 - accuracy: 0.8367 - val_loss: 1.5997 - val_accuracy: 0.4238\n",
            "Epoch 580/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.4075 - accuracy: 0.8463 - val_loss: 1.5924 - val_accuracy: 0.4305\n",
            "Epoch 581/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.4111 - accuracy: 0.8426 - val_loss: 1.6331 - val_accuracy: 0.4503\n",
            "Epoch 582/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.4310 - accuracy: 0.8322 - val_loss: 1.5898 - val_accuracy: 0.4172\n",
            "Epoch 583/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.4198 - accuracy: 0.8352 - val_loss: 1.6216 - val_accuracy: 0.4305\n",
            "Epoch 584/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.4012 - accuracy: 0.8551 - val_loss: 1.6496 - val_accuracy: 0.4305\n",
            "Epoch 585/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.4072 - accuracy: 0.8455 - val_loss: 1.6442 - val_accuracy: 0.4238\n",
            "Epoch 586/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.4222 - accuracy: 0.8381 - val_loss: 1.6209 - val_accuracy: 0.4172\n",
            "Epoch 587/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.4011 - accuracy: 0.8448 - val_loss: 1.6303 - val_accuracy: 0.4172\n",
            "Epoch 588/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.4065 - accuracy: 0.8381 - val_loss: 1.6544 - val_accuracy: 0.4305\n",
            "Epoch 589/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.3996 - accuracy: 0.8477 - val_loss: 1.6352 - val_accuracy: 0.4305\n",
            "Epoch 590/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.3965 - accuracy: 0.8551 - val_loss: 1.6349 - val_accuracy: 0.4503\n",
            "Epoch 591/700\n",
            "85/85 [==============================] - 2s 25ms/step - loss: 0.4177 - accuracy: 0.8315 - val_loss: 1.6556 - val_accuracy: 0.4503\n",
            "Epoch 592/700\n",
            "85/85 [==============================] - 2s 25ms/step - loss: 0.4099 - accuracy: 0.8418 - val_loss: 1.7011 - val_accuracy: 0.4106\n",
            "Epoch 593/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.4079 - accuracy: 0.8492 - val_loss: 1.5981 - val_accuracy: 0.4636\n",
            "Epoch 594/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.3942 - accuracy: 0.8574 - val_loss: 1.6856 - val_accuracy: 0.4437\n",
            "Epoch 595/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.3937 - accuracy: 0.8507 - val_loss: 1.6784 - val_accuracy: 0.4305\n",
            "Epoch 596/700\n",
            "85/85 [==============================] - 2s 25ms/step - loss: 0.4040 - accuracy: 0.8433 - val_loss: 1.6553 - val_accuracy: 0.4305\n",
            "Epoch 597/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.3865 - accuracy: 0.8581 - val_loss: 1.7297 - val_accuracy: 0.4371\n",
            "Epoch 598/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.4099 - accuracy: 0.8463 - val_loss: 1.6212 - val_accuracy: 0.4570\n",
            "Epoch 599/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.4183 - accuracy: 0.8344 - val_loss: 1.6011 - val_accuracy: 0.4437\n",
            "Epoch 600/700\n",
            "85/85 [==============================] - 2s 25ms/step - loss: 0.3908 - accuracy: 0.8470 - val_loss: 1.6528 - val_accuracy: 0.4503\n",
            "Epoch 601/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.4152 - accuracy: 0.8426 - val_loss: 1.6365 - val_accuracy: 0.4305\n",
            "Epoch 602/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.3957 - accuracy: 0.8448 - val_loss: 1.7350 - val_accuracy: 0.4305\n",
            "Epoch 603/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.3766 - accuracy: 0.8714 - val_loss: 1.7260 - val_accuracy: 0.4371\n",
            "Epoch 604/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.3981 - accuracy: 0.8374 - val_loss: 1.6276 - val_accuracy: 0.4437\n",
            "Epoch 605/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.3992 - accuracy: 0.8463 - val_loss: 1.6434 - val_accuracy: 0.4305\n",
            "Epoch 606/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.3843 - accuracy: 0.8455 - val_loss: 1.6627 - val_accuracy: 0.4305\n",
            "Epoch 607/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.4016 - accuracy: 0.8500 - val_loss: 1.6158 - val_accuracy: 0.4503\n",
            "Epoch 608/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.3910 - accuracy: 0.8588 - val_loss: 1.6857 - val_accuracy: 0.4503\n",
            "Epoch 609/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.3904 - accuracy: 0.8463 - val_loss: 1.6521 - val_accuracy: 0.4305\n",
            "Epoch 610/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.3726 - accuracy: 0.8588 - val_loss: 1.6147 - val_accuracy: 0.4371\n",
            "Epoch 611/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.3754 - accuracy: 0.8581 - val_loss: 1.6765 - val_accuracy: 0.4238\n",
            "Epoch 612/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.3866 - accuracy: 0.8647 - val_loss: 1.6348 - val_accuracy: 0.4238\n",
            "Epoch 613/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.3927 - accuracy: 0.8559 - val_loss: 1.7129 - val_accuracy: 0.4238\n",
            "Epoch 614/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.3985 - accuracy: 0.8441 - val_loss: 1.6691 - val_accuracy: 0.4371\n",
            "Epoch 615/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.3938 - accuracy: 0.8507 - val_loss: 1.6320 - val_accuracy: 0.4305\n",
            "Epoch 616/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.3822 - accuracy: 0.8477 - val_loss: 1.6604 - val_accuracy: 0.4437\n",
            "Epoch 617/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.3660 - accuracy: 0.8692 - val_loss: 1.6286 - val_accuracy: 0.4570\n",
            "Epoch 618/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.3693 - accuracy: 0.8588 - val_loss: 1.7511 - val_accuracy: 0.4437\n",
            "Epoch 619/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.3862 - accuracy: 0.8477 - val_loss: 1.6688 - val_accuracy: 0.4305\n",
            "Epoch 620/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.3745 - accuracy: 0.8581 - val_loss: 1.6060 - val_accuracy: 0.4570\n",
            "Epoch 621/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.3739 - accuracy: 0.8610 - val_loss: 1.6176 - val_accuracy: 0.4702\n",
            "Epoch 622/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.4083 - accuracy: 0.8448 - val_loss: 1.6807 - val_accuracy: 0.4371\n",
            "Epoch 623/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.3928 - accuracy: 0.8559 - val_loss: 1.6876 - val_accuracy: 0.4238\n",
            "Epoch 624/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.3985 - accuracy: 0.8492 - val_loss: 1.6092 - val_accuracy: 0.4437\n",
            "Epoch 625/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.3665 - accuracy: 0.8581 - val_loss: 1.6682 - val_accuracy: 0.4570\n",
            "Epoch 626/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.3762 - accuracy: 0.8714 - val_loss: 1.6567 - val_accuracy: 0.4503\n",
            "Epoch 627/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.3720 - accuracy: 0.8647 - val_loss: 1.6144 - val_accuracy: 0.4570\n",
            "Epoch 628/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.3773 - accuracy: 0.8574 - val_loss: 1.5902 - val_accuracy: 0.4570\n",
            "Epoch 629/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.3766 - accuracy: 0.8529 - val_loss: 1.6811 - val_accuracy: 0.4503\n",
            "Epoch 630/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.3791 - accuracy: 0.8603 - val_loss: 1.6359 - val_accuracy: 0.4305\n",
            "Epoch 631/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.3790 - accuracy: 0.8514 - val_loss: 1.6897 - val_accuracy: 0.4371\n",
            "Epoch 632/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.4054 - accuracy: 0.8448 - val_loss: 1.7547 - val_accuracy: 0.4305\n",
            "Epoch 633/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.3815 - accuracy: 0.8574 - val_loss: 1.7360 - val_accuracy: 0.4371\n",
            "Epoch 634/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.3614 - accuracy: 0.8618 - val_loss: 1.6402 - val_accuracy: 0.4305\n",
            "Epoch 635/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.3805 - accuracy: 0.8596 - val_loss: 1.6917 - val_accuracy: 0.4238\n",
            "Epoch 636/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.3642 - accuracy: 0.8670 - val_loss: 1.6397 - val_accuracy: 0.4238\n",
            "Epoch 637/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.3586 - accuracy: 0.8596 - val_loss: 1.7228 - val_accuracy: 0.4503\n",
            "Epoch 638/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.3693 - accuracy: 0.8603 - val_loss: 1.6982 - val_accuracy: 0.4371\n",
            "Epoch 639/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.3789 - accuracy: 0.8603 - val_loss: 1.7835 - val_accuracy: 0.4305\n",
            "Epoch 640/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.3681 - accuracy: 0.8670 - val_loss: 1.7689 - val_accuracy: 0.4371\n",
            "Epoch 641/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.3683 - accuracy: 0.8618 - val_loss: 1.7521 - val_accuracy: 0.4238\n",
            "Epoch 642/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.3681 - accuracy: 0.8633 - val_loss: 1.6781 - val_accuracy: 0.4437\n",
            "Epoch 643/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.3828 - accuracy: 0.8647 - val_loss: 1.6873 - val_accuracy: 0.4570\n",
            "Epoch 644/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.3844 - accuracy: 0.8507 - val_loss: 1.7043 - val_accuracy: 0.4106\n",
            "Epoch 645/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.3589 - accuracy: 0.8610 - val_loss: 1.7110 - val_accuracy: 0.4636\n",
            "Epoch 646/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.3930 - accuracy: 0.8544 - val_loss: 1.6890 - val_accuracy: 0.4371\n",
            "Epoch 647/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.3570 - accuracy: 0.8581 - val_loss: 1.6811 - val_accuracy: 0.4570\n",
            "Epoch 648/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.3795 - accuracy: 0.8463 - val_loss: 1.6413 - val_accuracy: 0.4503\n",
            "Epoch 649/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.3544 - accuracy: 0.8588 - val_loss: 1.6547 - val_accuracy: 0.4702\n",
            "Epoch 650/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.3570 - accuracy: 0.8588 - val_loss: 1.6945 - val_accuracy: 0.4503\n",
            "Epoch 651/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.3720 - accuracy: 0.8610 - val_loss: 1.6180 - val_accuracy: 0.4371\n",
            "Epoch 652/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.3794 - accuracy: 0.8551 - val_loss: 1.6412 - val_accuracy: 0.4570\n",
            "Epoch 653/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.3636 - accuracy: 0.8707 - val_loss: 1.7028 - val_accuracy: 0.4636\n",
            "Epoch 654/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.3636 - accuracy: 0.8514 - val_loss: 1.6831 - val_accuracy: 0.4570\n",
            "Epoch 655/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.3597 - accuracy: 0.8500 - val_loss: 1.7330 - val_accuracy: 0.4172\n",
            "Epoch 656/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.3652 - accuracy: 0.8537 - val_loss: 1.7532 - val_accuracy: 0.4371\n",
            "Epoch 657/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.3641 - accuracy: 0.8640 - val_loss: 1.8304 - val_accuracy: 0.4106\n",
            "Epoch 658/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.3651 - accuracy: 0.8551 - val_loss: 1.6676 - val_accuracy: 0.4570\n",
            "Epoch 659/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.3508 - accuracy: 0.8684 - val_loss: 1.6930 - val_accuracy: 0.4371\n",
            "Epoch 660/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.3566 - accuracy: 0.8721 - val_loss: 1.6467 - val_accuracy: 0.4305\n",
            "Epoch 661/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.3566 - accuracy: 0.8744 - val_loss: 1.7764 - val_accuracy: 0.4305\n",
            "Epoch 662/700\n",
            "85/85 [==============================] - 2s 25ms/step - loss: 0.3736 - accuracy: 0.8522 - val_loss: 1.6938 - val_accuracy: 0.4238\n",
            "Epoch 663/700\n",
            "85/85 [==============================] - 2s 25ms/step - loss: 0.3353 - accuracy: 0.8766 - val_loss: 1.7103 - val_accuracy: 0.4437\n",
            "Epoch 664/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.3582 - accuracy: 0.8529 - val_loss: 1.7136 - val_accuracy: 0.4371\n",
            "Epoch 665/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.3488 - accuracy: 0.8640 - val_loss: 1.7236 - val_accuracy: 0.4437\n",
            "Epoch 666/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.3580 - accuracy: 0.8537 - val_loss: 1.6570 - val_accuracy: 0.4636\n",
            "Epoch 667/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.3659 - accuracy: 0.8581 - val_loss: 1.6944 - val_accuracy: 0.4305\n",
            "Epoch 668/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.3591 - accuracy: 0.8699 - val_loss: 1.7064 - val_accuracy: 0.4437\n",
            "Epoch 669/700\n",
            "85/85 [==============================] - 2s 25ms/step - loss: 0.3627 - accuracy: 0.8574 - val_loss: 1.6794 - val_accuracy: 0.4570\n",
            "Epoch 670/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.3508 - accuracy: 0.8655 - val_loss: 1.7123 - val_accuracy: 0.4636\n",
            "Epoch 671/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.3740 - accuracy: 0.8647 - val_loss: 1.6915 - val_accuracy: 0.4371\n",
            "Epoch 672/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.3497 - accuracy: 0.8640 - val_loss: 1.7955 - val_accuracy: 0.4305\n",
            "Epoch 673/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.3587 - accuracy: 0.8692 - val_loss: 1.7731 - val_accuracy: 0.4238\n",
            "Epoch 674/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.3639 - accuracy: 0.8574 - val_loss: 1.7439 - val_accuracy: 0.4437\n",
            "Epoch 675/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.3485 - accuracy: 0.8625 - val_loss: 1.7994 - val_accuracy: 0.4106\n",
            "Epoch 676/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.3492 - accuracy: 0.8655 - val_loss: 1.6839 - val_accuracy: 0.4371\n",
            "Epoch 677/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.3411 - accuracy: 0.8633 - val_loss: 1.6689 - val_accuracy: 0.4503\n",
            "Epoch 678/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.3627 - accuracy: 0.8647 - val_loss: 1.6635 - val_accuracy: 0.4371\n",
            "Epoch 679/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.3665 - accuracy: 0.8537 - val_loss: 1.7882 - val_accuracy: 0.4172\n",
            "Epoch 680/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.3454 - accuracy: 0.8670 - val_loss: 1.7730 - val_accuracy: 0.4238\n",
            "Epoch 681/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.3551 - accuracy: 0.8581 - val_loss: 1.7277 - val_accuracy: 0.4238\n",
            "Epoch 682/700\n",
            "85/85 [==============================] - 2s 25ms/step - loss: 0.3478 - accuracy: 0.8662 - val_loss: 1.6986 - val_accuracy: 0.4371\n",
            "Epoch 683/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.3717 - accuracy: 0.8647 - val_loss: 1.6740 - val_accuracy: 0.4570\n",
            "Epoch 684/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.3423 - accuracy: 0.8729 - val_loss: 1.7501 - val_accuracy: 0.4305\n",
            "Epoch 685/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.3478 - accuracy: 0.8544 - val_loss: 1.6637 - val_accuracy: 0.4305\n",
            "Epoch 686/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.3401 - accuracy: 0.8736 - val_loss: 1.7414 - val_accuracy: 0.4305\n",
            "Epoch 687/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.3448 - accuracy: 0.8692 - val_loss: 1.8476 - val_accuracy: 0.4106\n",
            "Epoch 688/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.3460 - accuracy: 0.8670 - val_loss: 1.7836 - val_accuracy: 0.4238\n",
            "Epoch 689/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.3496 - accuracy: 0.8707 - val_loss: 1.7054 - val_accuracy: 0.4371\n",
            "Epoch 690/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.3330 - accuracy: 0.8699 - val_loss: 1.7622 - val_accuracy: 0.4238\n",
            "Epoch 691/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.3360 - accuracy: 0.8780 - val_loss: 1.6503 - val_accuracy: 0.4371\n",
            "Epoch 692/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.3401 - accuracy: 0.8736 - val_loss: 1.7788 - val_accuracy: 0.4503\n",
            "Epoch 693/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.3365 - accuracy: 0.8788 - val_loss: 1.8174 - val_accuracy: 0.4371\n",
            "Epoch 694/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.3289 - accuracy: 0.8847 - val_loss: 1.7450 - val_accuracy: 0.4570\n",
            "Epoch 695/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.3219 - accuracy: 0.8773 - val_loss: 1.7960 - val_accuracy: 0.4371\n",
            "Epoch 696/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.3445 - accuracy: 0.8662 - val_loss: 1.6993 - val_accuracy: 0.4437\n",
            "Epoch 697/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.3530 - accuracy: 0.8647 - val_loss: 1.7478 - val_accuracy: 0.4305\n",
            "Epoch 698/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.3561 - accuracy: 0.8677 - val_loss: 1.6863 - val_accuracy: 0.4570\n",
            "Epoch 699/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.3212 - accuracy: 0.8670 - val_loss: 1.7767 - val_accuracy: 0.4305\n",
            "Epoch 700/700\n",
            "85/85 [==============================] - 2s 25ms/step - loss: 0.3340 - accuracy: 0.8788 - val_loss: 1.7874 - val_accuracy: 0.4172\n",
            "0.7157976993279798\n",
            "accuracy: 71.81%\n",
            "Epoch 1/700\n",
            "85/85 [==============================] - 3s 26ms/step - loss: 1.7280 - accuracy: 0.1885 - val_loss: 1.6225 - val_accuracy: 0.1987\n",
            "Epoch 2/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 1.6485 - accuracy: 0.1899 - val_loss: 1.6186 - val_accuracy: 0.2185\n",
            "Epoch 3/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 1.6389 - accuracy: 0.1907 - val_loss: 1.6116 - val_accuracy: 0.2185\n",
            "Epoch 4/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 1.6373 - accuracy: 0.2062 - val_loss: 1.6197 - val_accuracy: 0.2053\n",
            "Epoch 5/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 1.6329 - accuracy: 0.1959 - val_loss: 1.6192 - val_accuracy: 0.2914\n",
            "Epoch 6/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 1.6415 - accuracy: 0.1899 - val_loss: 1.6115 - val_accuracy: 0.1987\n",
            "Epoch 7/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 1.6223 - accuracy: 0.2180 - val_loss: 1.6225 - val_accuracy: 0.1722\n",
            "Epoch 8/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 1.6205 - accuracy: 0.2114 - val_loss: 1.6175 - val_accuracy: 0.1987\n",
            "Epoch 9/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 1.6314 - accuracy: 0.1988 - val_loss: 1.6060 - val_accuracy: 0.2185\n",
            "Epoch 10/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 1.6246 - accuracy: 0.2158 - val_loss: 1.5978 - val_accuracy: 0.2583\n",
            "Epoch 11/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 1.6138 - accuracy: 0.2299 - val_loss: 1.6221 - val_accuracy: 0.2715\n",
            "Epoch 12/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 1.6231 - accuracy: 0.2180 - val_loss: 1.6054 - val_accuracy: 0.2119\n",
            "Epoch 13/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 1.6223 - accuracy: 0.2151 - val_loss: 1.6191 - val_accuracy: 0.1921\n",
            "Epoch 14/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 1.6044 - accuracy: 0.2306 - val_loss: 1.5846 - val_accuracy: 0.2053\n",
            "Epoch 15/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 1.6063 - accuracy: 0.2321 - val_loss: 1.5842 - val_accuracy: 0.3245\n",
            "Epoch 16/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 1.5995 - accuracy: 0.2409 - val_loss: 1.5809 - val_accuracy: 0.2384\n",
            "Epoch 17/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 1.5958 - accuracy: 0.2550 - val_loss: 1.5826 - val_accuracy: 0.2517\n",
            "Epoch 18/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 1.5884 - accuracy: 0.2594 - val_loss: 1.5733 - val_accuracy: 0.3179\n",
            "Epoch 19/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 1.5852 - accuracy: 0.2513 - val_loss: 1.5707 - val_accuracy: 0.2318\n",
            "Epoch 20/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 1.5697 - accuracy: 0.2860 - val_loss: 1.5621 - val_accuracy: 0.2583\n",
            "Epoch 21/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 1.5721 - accuracy: 0.2897 - val_loss: 1.5394 - val_accuracy: 0.3245\n",
            "Epoch 22/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 1.5676 - accuracy: 0.3089 - val_loss: 1.5652 - val_accuracy: 0.2848\n",
            "Epoch 23/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 1.5561 - accuracy: 0.3023 - val_loss: 1.5315 - val_accuracy: 0.3576\n",
            "Epoch 24/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 1.5501 - accuracy: 0.2927 - val_loss: 1.5789 - val_accuracy: 0.2252\n",
            "Epoch 25/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 1.5511 - accuracy: 0.2934 - val_loss: 1.5475 - val_accuracy: 0.3245\n",
            "Epoch 26/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 1.5427 - accuracy: 0.3112 - val_loss: 1.5624 - val_accuracy: 0.2583\n",
            "Epoch 27/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 1.5362 - accuracy: 0.3186 - val_loss: 1.5192 - val_accuracy: 0.3444\n",
            "Epoch 28/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 1.5263 - accuracy: 0.3193 - val_loss: 1.5192 - val_accuracy: 0.2980\n",
            "Epoch 29/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 1.5226 - accuracy: 0.3126 - val_loss: 1.5095 - val_accuracy: 0.3311\n",
            "Epoch 30/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 1.5075 - accuracy: 0.3178 - val_loss: 1.5113 - val_accuracy: 0.3510\n",
            "Epoch 31/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 1.5071 - accuracy: 0.3237 - val_loss: 1.5135 - val_accuracy: 0.3311\n",
            "Epoch 32/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 1.4920 - accuracy: 0.3466 - val_loss: 1.5441 - val_accuracy: 0.2715\n",
            "Epoch 33/700\n",
            "85/85 [==============================] - 2s 25ms/step - loss: 1.4812 - accuracy: 0.3422 - val_loss: 1.5193 - val_accuracy: 0.2848\n",
            "Epoch 34/700\n",
            "85/85 [==============================] - 2s 25ms/step - loss: 1.4773 - accuracy: 0.3548 - val_loss: 1.5159 - val_accuracy: 0.3444\n",
            "Epoch 35/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 1.4679 - accuracy: 0.3503 - val_loss: 1.5169 - val_accuracy: 0.3576\n",
            "Epoch 36/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 1.4601 - accuracy: 0.3644 - val_loss: 1.4778 - val_accuracy: 0.3775\n",
            "Epoch 37/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 1.4466 - accuracy: 0.3792 - val_loss: 1.4709 - val_accuracy: 0.3576\n",
            "Epoch 38/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 1.4501 - accuracy: 0.3622 - val_loss: 1.4707 - val_accuracy: 0.4040\n",
            "Epoch 39/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 1.4313 - accuracy: 0.3880 - val_loss: 1.5056 - val_accuracy: 0.3444\n",
            "Epoch 40/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 1.4151 - accuracy: 0.3829 - val_loss: 1.4781 - val_accuracy: 0.3642\n",
            "Epoch 41/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 1.4092 - accuracy: 0.3932 - val_loss: 1.5002 - val_accuracy: 0.3444\n",
            "Epoch 42/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 1.4116 - accuracy: 0.3932 - val_loss: 1.4723 - val_accuracy: 0.3841\n",
            "Epoch 43/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 1.3964 - accuracy: 0.4124 - val_loss: 1.5005 - val_accuracy: 0.3510\n",
            "Epoch 44/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 1.3915 - accuracy: 0.3984 - val_loss: 1.5121 - val_accuracy: 0.3311\n",
            "Epoch 45/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 1.3720 - accuracy: 0.4139 - val_loss: 1.4417 - val_accuracy: 0.3642\n",
            "Epoch 46/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 1.3686 - accuracy: 0.4169 - val_loss: 1.4842 - val_accuracy: 0.3775\n",
            "Epoch 47/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 1.3533 - accuracy: 0.4257 - val_loss: 1.4544 - val_accuracy: 0.4106\n",
            "Epoch 48/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 1.3515 - accuracy: 0.4457 - val_loss: 1.4565 - val_accuracy: 0.3444\n",
            "Epoch 49/700\n",
            "85/85 [==============================] - 2s 25ms/step - loss: 1.3468 - accuracy: 0.4375 - val_loss: 1.4286 - val_accuracy: 0.3974\n",
            "Epoch 50/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 1.3405 - accuracy: 0.4375 - val_loss: 1.4429 - val_accuracy: 0.3709\n",
            "Epoch 51/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 1.3204 - accuracy: 0.4398 - val_loss: 1.4566 - val_accuracy: 0.3576\n",
            "Epoch 52/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 1.3122 - accuracy: 0.4597 - val_loss: 1.4615 - val_accuracy: 0.3841\n",
            "Epoch 53/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 1.3086 - accuracy: 0.4545 - val_loss: 1.4611 - val_accuracy: 0.3510\n",
            "Epoch 54/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 1.3013 - accuracy: 0.4582 - val_loss: 1.4791 - val_accuracy: 0.3974\n",
            "Epoch 55/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 1.2850 - accuracy: 0.4678 - val_loss: 1.4104 - val_accuracy: 0.4371\n",
            "Epoch 56/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 1.2823 - accuracy: 0.4908 - val_loss: 1.4197 - val_accuracy: 0.3974\n",
            "Epoch 57/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 1.2850 - accuracy: 0.4553 - val_loss: 1.4129 - val_accuracy: 0.4238\n",
            "Epoch 58/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 1.2653 - accuracy: 0.4656 - val_loss: 1.3972 - val_accuracy: 0.4570\n",
            "Epoch 59/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 1.2609 - accuracy: 0.4693 - val_loss: 1.4370 - val_accuracy: 0.4106\n",
            "Epoch 60/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 1.2526 - accuracy: 0.4841 - val_loss: 1.4584 - val_accuracy: 0.3510\n",
            "Epoch 61/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 1.2576 - accuracy: 0.4885 - val_loss: 1.4134 - val_accuracy: 0.4305\n",
            "Epoch 62/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 1.2263 - accuracy: 0.5122 - val_loss: 1.3999 - val_accuracy: 0.4503\n",
            "Epoch 63/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 1.2411 - accuracy: 0.4967 - val_loss: 1.3971 - val_accuracy: 0.4503\n",
            "Epoch 64/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 1.2211 - accuracy: 0.5041 - val_loss: 1.4145 - val_accuracy: 0.4437\n",
            "Epoch 65/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 1.2252 - accuracy: 0.4959 - val_loss: 1.4246 - val_accuracy: 0.4305\n",
            "Epoch 66/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 1.2129 - accuracy: 0.5078 - val_loss: 1.4000 - val_accuracy: 0.4172\n",
            "Epoch 67/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 1.2104 - accuracy: 0.5152 - val_loss: 1.4316 - val_accuracy: 0.4040\n",
            "Epoch 68/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 1.2025 - accuracy: 0.5196 - val_loss: 1.3818 - val_accuracy: 0.4371\n",
            "Epoch 69/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 1.1956 - accuracy: 0.5115 - val_loss: 1.4331 - val_accuracy: 0.3841\n",
            "Epoch 70/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 1.1895 - accuracy: 0.5277 - val_loss: 1.3887 - val_accuracy: 0.4503\n",
            "Epoch 71/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 1.1854 - accuracy: 0.5203 - val_loss: 1.4693 - val_accuracy: 0.3576\n",
            "Epoch 72/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 1.1867 - accuracy: 0.5159 - val_loss: 1.4097 - val_accuracy: 0.3775\n",
            "Epoch 73/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 1.1670 - accuracy: 0.5418 - val_loss: 1.4022 - val_accuracy: 0.4305\n",
            "Epoch 74/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 1.1711 - accuracy: 0.5240 - val_loss: 1.4076 - val_accuracy: 0.3841\n",
            "Epoch 75/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 1.1541 - accuracy: 0.5277 - val_loss: 1.4017 - val_accuracy: 0.3974\n",
            "Epoch 76/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 1.1557 - accuracy: 0.5358 - val_loss: 1.4132 - val_accuracy: 0.4238\n",
            "Epoch 77/700\n",
            "85/85 [==============================] - 2s 26ms/step - loss: 1.1482 - accuracy: 0.5299 - val_loss: 1.4238 - val_accuracy: 0.4238\n",
            "Epoch 78/700\n",
            "85/85 [==============================] - 2s 28ms/step - loss: 1.1452 - accuracy: 0.5351 - val_loss: 1.4434 - val_accuracy: 0.3841\n",
            "Epoch 79/700\n",
            "85/85 [==============================] - 2s 28ms/step - loss: 1.1396 - accuracy: 0.5307 - val_loss: 1.4450 - val_accuracy: 0.4172\n",
            "Epoch 80/700\n",
            "85/85 [==============================] - 3s 38ms/step - loss: 1.1355 - accuracy: 0.5484 - val_loss: 1.4078 - val_accuracy: 0.4040\n",
            "Epoch 81/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 1.1273 - accuracy: 0.5462 - val_loss: 1.3875 - val_accuracy: 0.4238\n",
            "Epoch 82/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 1.1152 - accuracy: 0.5455 - val_loss: 1.4547 - val_accuracy: 0.3642\n",
            "Epoch 83/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 1.1172 - accuracy: 0.5499 - val_loss: 1.4634 - val_accuracy: 0.4040\n",
            "Epoch 84/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 1.1236 - accuracy: 0.5528 - val_loss: 1.3982 - val_accuracy: 0.4437\n",
            "Epoch 85/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 1.1094 - accuracy: 0.5514 - val_loss: 1.4221 - val_accuracy: 0.3841\n",
            "Epoch 86/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 1.0985 - accuracy: 0.5536 - val_loss: 1.4490 - val_accuracy: 0.3974\n",
            "Epoch 87/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 1.0966 - accuracy: 0.5580 - val_loss: 1.4266 - val_accuracy: 0.3907\n",
            "Epoch 88/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 1.0922 - accuracy: 0.5588 - val_loss: 1.4970 - val_accuracy: 0.3510\n",
            "Epoch 89/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 1.0919 - accuracy: 0.5625 - val_loss: 1.4257 - val_accuracy: 0.4570\n",
            "Epoch 90/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 1.0832 - accuracy: 0.5920 - val_loss: 1.4616 - val_accuracy: 0.3709\n",
            "Epoch 91/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 1.0785 - accuracy: 0.5661 - val_loss: 1.4102 - val_accuracy: 0.4106\n",
            "Epoch 92/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 1.0805 - accuracy: 0.5654 - val_loss: 1.4110 - val_accuracy: 0.4371\n",
            "Epoch 93/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 1.0873 - accuracy: 0.5647 - val_loss: 1.4046 - val_accuracy: 0.4437\n",
            "Epoch 94/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 1.0812 - accuracy: 0.5580 - val_loss: 1.4570 - val_accuracy: 0.3974\n",
            "Epoch 95/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 1.0635 - accuracy: 0.5780 - val_loss: 1.3992 - val_accuracy: 0.4570\n",
            "Epoch 96/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 1.0757 - accuracy: 0.5728 - val_loss: 1.4432 - val_accuracy: 0.4238\n",
            "Epoch 97/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 1.0618 - accuracy: 0.5772 - val_loss: 1.3859 - val_accuracy: 0.4768\n",
            "Epoch 98/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 1.0582 - accuracy: 0.5750 - val_loss: 1.4144 - val_accuracy: 0.4570\n",
            "Epoch 99/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 1.0587 - accuracy: 0.5691 - val_loss: 1.4005 - val_accuracy: 0.4371\n",
            "Epoch 100/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 1.0518 - accuracy: 0.5817 - val_loss: 1.3823 - val_accuracy: 0.4172\n",
            "Epoch 101/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 1.0448 - accuracy: 0.5750 - val_loss: 1.4105 - val_accuracy: 0.4305\n",
            "Epoch 102/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 1.0358 - accuracy: 0.5861 - val_loss: 1.3908 - val_accuracy: 0.4040\n",
            "Epoch 103/700\n",
            "85/85 [==============================] - 2s 25ms/step - loss: 1.0382 - accuracy: 0.5698 - val_loss: 1.4015 - val_accuracy: 0.4172\n",
            "Epoch 104/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 1.0370 - accuracy: 0.5684 - val_loss: 1.4389 - val_accuracy: 0.4305\n",
            "Epoch 105/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 1.0359 - accuracy: 0.5905 - val_loss: 1.4128 - val_accuracy: 0.4305\n",
            "Epoch 106/700\n",
            "85/85 [==============================] - 2s 25ms/step - loss: 1.0201 - accuracy: 0.5891 - val_loss: 1.4140 - val_accuracy: 0.4106\n",
            "Epoch 107/700\n",
            "85/85 [==============================] - 2s 25ms/step - loss: 1.0275 - accuracy: 0.5935 - val_loss: 1.4370 - val_accuracy: 0.4305\n",
            "Epoch 108/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 1.0218 - accuracy: 0.5876 - val_loss: 1.4587 - val_accuracy: 0.4172\n",
            "Epoch 109/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 1.0238 - accuracy: 0.5831 - val_loss: 1.3977 - val_accuracy: 0.4305\n",
            "Epoch 110/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 1.0324 - accuracy: 0.5772 - val_loss: 1.3867 - val_accuracy: 0.4040\n",
            "Epoch 111/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 1.0259 - accuracy: 0.5676 - val_loss: 1.4130 - val_accuracy: 0.4172\n",
            "Epoch 112/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 1.0051 - accuracy: 0.5942 - val_loss: 1.4180 - val_accuracy: 0.3907\n",
            "Epoch 113/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 1.0252 - accuracy: 0.5876 - val_loss: 1.4217 - val_accuracy: 0.4305\n",
            "Epoch 114/700\n",
            "85/85 [==============================] - 2s 25ms/step - loss: 1.0075 - accuracy: 0.5905 - val_loss: 1.4189 - val_accuracy: 0.4305\n",
            "Epoch 115/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.9941 - accuracy: 0.5942 - val_loss: 1.4010 - val_accuracy: 0.4172\n",
            "Epoch 116/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.9901 - accuracy: 0.5957 - val_loss: 1.3988 - val_accuracy: 0.4172\n",
            "Epoch 117/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 1.0014 - accuracy: 0.6009 - val_loss: 1.4474 - val_accuracy: 0.4106\n",
            "Epoch 118/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.9953 - accuracy: 0.5994 - val_loss: 1.4058 - val_accuracy: 0.4238\n",
            "Epoch 119/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 1.0061 - accuracy: 0.5935 - val_loss: 1.4207 - val_accuracy: 0.3907\n",
            "Epoch 120/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.9865 - accuracy: 0.6053 - val_loss: 1.3929 - val_accuracy: 0.3974\n",
            "Epoch 121/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.9934 - accuracy: 0.5950 - val_loss: 1.3974 - val_accuracy: 0.4238\n",
            "Epoch 122/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.9679 - accuracy: 0.6179 - val_loss: 1.4147 - val_accuracy: 0.4172\n",
            "Epoch 123/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.9900 - accuracy: 0.6127 - val_loss: 1.4047 - val_accuracy: 0.3974\n",
            "Epoch 124/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.9790 - accuracy: 0.6001 - val_loss: 1.4002 - val_accuracy: 0.4437\n",
            "Epoch 125/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.9905 - accuracy: 0.5920 - val_loss: 1.4171 - val_accuracy: 0.4040\n",
            "Epoch 126/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.9744 - accuracy: 0.6009 - val_loss: 1.4365 - val_accuracy: 0.4040\n",
            "Epoch 127/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.9935 - accuracy: 0.5905 - val_loss: 1.4469 - val_accuracy: 0.3974\n",
            "Epoch 128/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.9691 - accuracy: 0.5935 - val_loss: 1.4049 - val_accuracy: 0.4305\n",
            "Epoch 129/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.9701 - accuracy: 0.6009 - val_loss: 1.4346 - val_accuracy: 0.3974\n",
            "Epoch 130/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.9702 - accuracy: 0.6024 - val_loss: 1.4128 - val_accuracy: 0.4040\n",
            "Epoch 131/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.9697 - accuracy: 0.6105 - val_loss: 1.4143 - val_accuracy: 0.3974\n",
            "Epoch 132/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.9620 - accuracy: 0.6201 - val_loss: 1.4239 - val_accuracy: 0.4172\n",
            "Epoch 133/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.9702 - accuracy: 0.6083 - val_loss: 1.4502 - val_accuracy: 0.4106\n",
            "Epoch 134/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.9671 - accuracy: 0.6053 - val_loss: 1.4193 - val_accuracy: 0.4040\n",
            "Epoch 135/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.9566 - accuracy: 0.6112 - val_loss: 1.4851 - val_accuracy: 0.4106\n",
            "Epoch 136/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.9463 - accuracy: 0.6223 - val_loss: 1.4732 - val_accuracy: 0.3841\n",
            "Epoch 137/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.9526 - accuracy: 0.6194 - val_loss: 1.4649 - val_accuracy: 0.4238\n",
            "Epoch 138/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.9476 - accuracy: 0.6098 - val_loss: 1.4339 - val_accuracy: 0.4040\n",
            "Epoch 139/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.9338 - accuracy: 0.6305 - val_loss: 1.4170 - val_accuracy: 0.4040\n",
            "Epoch 140/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.9435 - accuracy: 0.5920 - val_loss: 1.4691 - val_accuracy: 0.3642\n",
            "Epoch 141/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.9521 - accuracy: 0.6171 - val_loss: 1.4120 - val_accuracy: 0.4371\n",
            "Epoch 142/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.9276 - accuracy: 0.6164 - val_loss: 1.4374 - val_accuracy: 0.4305\n",
            "Epoch 143/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.9479 - accuracy: 0.6142 - val_loss: 1.4129 - val_accuracy: 0.3775\n",
            "Epoch 144/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.9267 - accuracy: 0.6364 - val_loss: 1.4546 - val_accuracy: 0.3642\n",
            "Epoch 145/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.9328 - accuracy: 0.6164 - val_loss: 1.4159 - val_accuracy: 0.4040\n",
            "Epoch 146/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.9256 - accuracy: 0.6327 - val_loss: 1.4118 - val_accuracy: 0.4040\n",
            "Epoch 147/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.9322 - accuracy: 0.6231 - val_loss: 1.4052 - val_accuracy: 0.3974\n",
            "Epoch 148/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.9119 - accuracy: 0.6186 - val_loss: 1.4578 - val_accuracy: 0.3907\n",
            "Epoch 149/700\n",
            "85/85 [==============================] - 2s 22ms/step - loss: 0.9246 - accuracy: 0.6245 - val_loss: 1.4730 - val_accuracy: 0.4238\n",
            "Epoch 150/700\n",
            "85/85 [==============================] - 2s 25ms/step - loss: 0.9191 - accuracy: 0.6223 - val_loss: 1.4563 - val_accuracy: 0.3775\n",
            "Epoch 151/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.9114 - accuracy: 0.6356 - val_loss: 1.4166 - val_accuracy: 0.3841\n",
            "Epoch 152/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.9218 - accuracy: 0.6371 - val_loss: 1.4871 - val_accuracy: 0.3841\n",
            "Epoch 153/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.9177 - accuracy: 0.6364 - val_loss: 1.4182 - val_accuracy: 0.3907\n",
            "Epoch 154/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.9147 - accuracy: 0.6467 - val_loss: 1.4082 - val_accuracy: 0.4238\n",
            "Epoch 155/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.9078 - accuracy: 0.6341 - val_loss: 1.4348 - val_accuracy: 0.4106\n",
            "Epoch 156/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.9096 - accuracy: 0.6327 - val_loss: 1.4553 - val_accuracy: 0.4238\n",
            "Epoch 157/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.9086 - accuracy: 0.6305 - val_loss: 1.4068 - val_accuracy: 0.4305\n",
            "Epoch 158/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.8985 - accuracy: 0.6268 - val_loss: 1.4343 - val_accuracy: 0.4305\n",
            "Epoch 159/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.8990 - accuracy: 0.6438 - val_loss: 1.4291 - val_accuracy: 0.4238\n",
            "Epoch 160/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.9071 - accuracy: 0.6327 - val_loss: 1.4268 - val_accuracy: 0.3775\n",
            "Epoch 161/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.8962 - accuracy: 0.6356 - val_loss: 1.4341 - val_accuracy: 0.3907\n",
            "Epoch 162/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.8990 - accuracy: 0.6245 - val_loss: 1.4142 - val_accuracy: 0.3841\n",
            "Epoch 163/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.8907 - accuracy: 0.6423 - val_loss: 1.4332 - val_accuracy: 0.4172\n",
            "Epoch 164/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.8892 - accuracy: 0.6415 - val_loss: 1.4176 - val_accuracy: 0.3907\n",
            "Epoch 165/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.8911 - accuracy: 0.6519 - val_loss: 1.4386 - val_accuracy: 0.3974\n",
            "Epoch 166/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.8779 - accuracy: 0.6526 - val_loss: 1.4379 - val_accuracy: 0.3974\n",
            "Epoch 167/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.8849 - accuracy: 0.6467 - val_loss: 1.4158 - val_accuracy: 0.3974\n",
            "Epoch 168/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.8855 - accuracy: 0.6445 - val_loss: 1.4174 - val_accuracy: 0.4106\n",
            "Epoch 169/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.8843 - accuracy: 0.6408 - val_loss: 1.4568 - val_accuracy: 0.3907\n",
            "Epoch 170/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.8941 - accuracy: 0.6238 - val_loss: 1.4203 - val_accuracy: 0.3907\n",
            "Epoch 171/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.8611 - accuracy: 0.6608 - val_loss: 1.4587 - val_accuracy: 0.4172\n",
            "Epoch 172/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.8634 - accuracy: 0.6600 - val_loss: 1.4134 - val_accuracy: 0.4371\n",
            "Epoch 173/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.8665 - accuracy: 0.6556 - val_loss: 1.4163 - val_accuracy: 0.4040\n",
            "Epoch 174/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.8641 - accuracy: 0.6652 - val_loss: 1.4697 - val_accuracy: 0.4040\n",
            "Epoch 175/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.8675 - accuracy: 0.6548 - val_loss: 1.4215 - val_accuracy: 0.4040\n",
            "Epoch 176/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.8714 - accuracy: 0.6585 - val_loss: 1.4593 - val_accuracy: 0.4106\n",
            "Epoch 177/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.8640 - accuracy: 0.6519 - val_loss: 1.4302 - val_accuracy: 0.4040\n",
            "Epoch 178/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.8571 - accuracy: 0.6526 - val_loss: 1.4273 - val_accuracy: 0.4040\n",
            "Epoch 179/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.8628 - accuracy: 0.6615 - val_loss: 1.4378 - val_accuracy: 0.4238\n",
            "Epoch 180/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.8447 - accuracy: 0.6563 - val_loss: 1.4240 - val_accuracy: 0.4040\n",
            "Epoch 181/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.8572 - accuracy: 0.6681 - val_loss: 1.4271 - val_accuracy: 0.4040\n",
            "Epoch 182/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.8596 - accuracy: 0.6534 - val_loss: 1.4257 - val_accuracy: 0.3974\n",
            "Epoch 183/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.8498 - accuracy: 0.6585 - val_loss: 1.4194 - val_accuracy: 0.4238\n",
            "Epoch 184/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.8491 - accuracy: 0.6511 - val_loss: 1.4125 - val_accuracy: 0.4437\n",
            "Epoch 185/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.8719 - accuracy: 0.6386 - val_loss: 1.4444 - val_accuracy: 0.3841\n",
            "Epoch 186/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.8409 - accuracy: 0.6652 - val_loss: 1.4698 - val_accuracy: 0.3907\n",
            "Epoch 187/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.8515 - accuracy: 0.6593 - val_loss: 1.4443 - val_accuracy: 0.4371\n",
            "Epoch 188/700\n",
            "85/85 [==============================] - 2s 25ms/step - loss: 0.8409 - accuracy: 0.6541 - val_loss: 1.4163 - val_accuracy: 0.3841\n",
            "Epoch 189/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.8441 - accuracy: 0.6548 - val_loss: 1.4409 - val_accuracy: 0.3974\n",
            "Epoch 190/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.8385 - accuracy: 0.6637 - val_loss: 1.4253 - val_accuracy: 0.3974\n",
            "Epoch 191/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.8319 - accuracy: 0.6748 - val_loss: 1.4443 - val_accuracy: 0.4106\n",
            "Epoch 192/700\n",
            "85/85 [==============================] - 2s 25ms/step - loss: 0.8367 - accuracy: 0.6644 - val_loss: 1.4394 - val_accuracy: 0.4172\n",
            "Epoch 193/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.8358 - accuracy: 0.6526 - val_loss: 1.4381 - val_accuracy: 0.4305\n",
            "Epoch 194/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.8422 - accuracy: 0.6637 - val_loss: 1.4406 - val_accuracy: 0.4172\n",
            "Epoch 195/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.8359 - accuracy: 0.6667 - val_loss: 1.4510 - val_accuracy: 0.4106\n",
            "Epoch 196/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.8383 - accuracy: 0.6644 - val_loss: 1.4230 - val_accuracy: 0.4305\n",
            "Epoch 197/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.8266 - accuracy: 0.6837 - val_loss: 1.4031 - val_accuracy: 0.4040\n",
            "Epoch 198/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.8320 - accuracy: 0.6652 - val_loss: 1.4241 - val_accuracy: 0.3841\n",
            "Epoch 199/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.8285 - accuracy: 0.6571 - val_loss: 1.4293 - val_accuracy: 0.4371\n",
            "Epoch 200/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.8259 - accuracy: 0.6681 - val_loss: 1.4267 - val_accuracy: 0.4371\n",
            "Epoch 201/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.8109 - accuracy: 0.6800 - val_loss: 1.4342 - val_accuracy: 0.4106\n",
            "Epoch 202/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.8196 - accuracy: 0.6755 - val_loss: 1.4344 - val_accuracy: 0.3907\n",
            "Epoch 203/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.8013 - accuracy: 0.6778 - val_loss: 1.4575 - val_accuracy: 0.4238\n",
            "Epoch 204/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.8191 - accuracy: 0.6778 - val_loss: 1.4464 - val_accuracy: 0.4503\n",
            "Epoch 205/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.8233 - accuracy: 0.6770 - val_loss: 1.4194 - val_accuracy: 0.3907\n",
            "Epoch 206/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.8183 - accuracy: 0.6822 - val_loss: 1.4182 - val_accuracy: 0.4371\n",
            "Epoch 207/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.8071 - accuracy: 0.6711 - val_loss: 1.4251 - val_accuracy: 0.4172\n",
            "Epoch 208/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.8136 - accuracy: 0.6652 - val_loss: 1.4371 - val_accuracy: 0.4040\n",
            "Epoch 209/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.7965 - accuracy: 0.6859 - val_loss: 1.4473 - val_accuracy: 0.3907\n",
            "Epoch 210/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.8175 - accuracy: 0.6652 - val_loss: 1.4336 - val_accuracy: 0.4570\n",
            "Epoch 211/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.8136 - accuracy: 0.6681 - val_loss: 1.4238 - val_accuracy: 0.4238\n",
            "Epoch 212/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.8069 - accuracy: 0.6755 - val_loss: 1.5258 - val_accuracy: 0.3775\n",
            "Epoch 213/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.8221 - accuracy: 0.6578 - val_loss: 1.4236 - val_accuracy: 0.4172\n",
            "Epoch 214/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.7962 - accuracy: 0.6888 - val_loss: 1.4467 - val_accuracy: 0.4503\n",
            "Epoch 215/700\n",
            "85/85 [==============================] - 2s 25ms/step - loss: 0.7928 - accuracy: 0.6859 - val_loss: 1.4316 - val_accuracy: 0.4238\n",
            "Epoch 216/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.8026 - accuracy: 0.6748 - val_loss: 1.4060 - val_accuracy: 0.4106\n",
            "Epoch 217/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.8012 - accuracy: 0.6851 - val_loss: 1.4473 - val_accuracy: 0.4371\n",
            "Epoch 218/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.7965 - accuracy: 0.6822 - val_loss: 1.4647 - val_accuracy: 0.3775\n",
            "Epoch 219/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.7980 - accuracy: 0.6763 - val_loss: 1.4723 - val_accuracy: 0.4437\n",
            "Epoch 220/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.8054 - accuracy: 0.6800 - val_loss: 1.4328 - val_accuracy: 0.4702\n",
            "Epoch 221/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.7927 - accuracy: 0.6792 - val_loss: 1.4286 - val_accuracy: 0.4040\n",
            "Epoch 222/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.7967 - accuracy: 0.6792 - val_loss: 1.4356 - val_accuracy: 0.4305\n",
            "Epoch 223/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.7857 - accuracy: 0.6903 - val_loss: 1.4316 - val_accuracy: 0.4636\n",
            "Epoch 224/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.7929 - accuracy: 0.6866 - val_loss: 1.4100 - val_accuracy: 0.4305\n",
            "Epoch 225/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.7907 - accuracy: 0.6896 - val_loss: 1.4236 - val_accuracy: 0.3974\n",
            "Epoch 226/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.7813 - accuracy: 0.6962 - val_loss: 1.4337 - val_accuracy: 0.4238\n",
            "Epoch 227/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.7738 - accuracy: 0.6844 - val_loss: 1.4294 - val_accuracy: 0.4437\n",
            "Epoch 228/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.7671 - accuracy: 0.6933 - val_loss: 1.4219 - val_accuracy: 0.3907\n",
            "Epoch 229/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.7745 - accuracy: 0.6962 - val_loss: 1.4289 - val_accuracy: 0.4305\n",
            "Epoch 230/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.7712 - accuracy: 0.6903 - val_loss: 1.4334 - val_accuracy: 0.4106\n",
            "Epoch 231/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.7697 - accuracy: 0.6933 - val_loss: 1.4755 - val_accuracy: 0.4040\n",
            "Epoch 232/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.7818 - accuracy: 0.6829 - val_loss: 1.4198 - val_accuracy: 0.4040\n",
            "Epoch 233/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.7465 - accuracy: 0.7154 - val_loss: 1.4809 - val_accuracy: 0.4106\n",
            "Epoch 234/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.7630 - accuracy: 0.6948 - val_loss: 1.4489 - val_accuracy: 0.4040\n",
            "Epoch 235/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.7684 - accuracy: 0.6866 - val_loss: 1.4336 - val_accuracy: 0.4040\n",
            "Epoch 236/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.7808 - accuracy: 0.6970 - val_loss: 1.4063 - val_accuracy: 0.4238\n",
            "Epoch 237/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.7623 - accuracy: 0.7066 - val_loss: 1.4196 - val_accuracy: 0.4172\n",
            "Epoch 238/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.7631 - accuracy: 0.6792 - val_loss: 1.4368 - val_accuracy: 0.4172\n",
            "Epoch 239/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.7572 - accuracy: 0.6984 - val_loss: 1.4355 - val_accuracy: 0.3974\n",
            "Epoch 240/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.7895 - accuracy: 0.6814 - val_loss: 1.4044 - val_accuracy: 0.4238\n",
            "Epoch 241/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.7537 - accuracy: 0.6999 - val_loss: 1.4770 - val_accuracy: 0.4503\n",
            "Epoch 242/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.7502 - accuracy: 0.6999 - val_loss: 1.4396 - val_accuracy: 0.4172\n",
            "Epoch 243/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.7630 - accuracy: 0.6970 - val_loss: 1.4079 - val_accuracy: 0.4636\n",
            "Epoch 244/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.7623 - accuracy: 0.7051 - val_loss: 1.4397 - val_accuracy: 0.4437\n",
            "Epoch 245/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.7510 - accuracy: 0.6859 - val_loss: 1.4291 - val_accuracy: 0.4172\n",
            "Epoch 246/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.7490 - accuracy: 0.7073 - val_loss: 1.4502 - val_accuracy: 0.4305\n",
            "Epoch 247/700\n",
            "85/85 [==============================] - 2s 25ms/step - loss: 0.7450 - accuracy: 0.7088 - val_loss: 1.4229 - val_accuracy: 0.4172\n",
            "Epoch 248/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.7524 - accuracy: 0.7103 - val_loss: 1.4238 - val_accuracy: 0.4636\n",
            "Epoch 249/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.7477 - accuracy: 0.7147 - val_loss: 1.4233 - val_accuracy: 0.4371\n",
            "Epoch 250/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.7393 - accuracy: 0.7029 - val_loss: 1.4080 - val_accuracy: 0.4371\n",
            "Epoch 251/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.7539 - accuracy: 0.7132 - val_loss: 1.4166 - val_accuracy: 0.4040\n",
            "Epoch 252/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.7258 - accuracy: 0.7154 - val_loss: 1.4181 - val_accuracy: 0.4106\n",
            "Epoch 253/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.7492 - accuracy: 0.6933 - val_loss: 1.4132 - val_accuracy: 0.4371\n",
            "Epoch 254/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.7376 - accuracy: 0.7036 - val_loss: 1.4208 - val_accuracy: 0.4238\n",
            "Epoch 255/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.7389 - accuracy: 0.7162 - val_loss: 1.4353 - val_accuracy: 0.4371\n",
            "Epoch 256/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.7265 - accuracy: 0.7081 - val_loss: 1.4365 - val_accuracy: 0.4305\n",
            "Epoch 257/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.7390 - accuracy: 0.7162 - val_loss: 1.4486 - val_accuracy: 0.4106\n",
            "Epoch 258/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.7433 - accuracy: 0.7088 - val_loss: 1.4669 - val_accuracy: 0.4570\n",
            "Epoch 259/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.7319 - accuracy: 0.7044 - val_loss: 1.4346 - val_accuracy: 0.4437\n",
            "Epoch 260/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.7263 - accuracy: 0.7058 - val_loss: 1.4325 - val_accuracy: 0.4437\n",
            "Epoch 261/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.7332 - accuracy: 0.7036 - val_loss: 1.4348 - val_accuracy: 0.4636\n",
            "Epoch 262/700\n",
            "85/85 [==============================] - 2s 25ms/step - loss: 0.7318 - accuracy: 0.7191 - val_loss: 1.4460 - val_accuracy: 0.4636\n",
            "Epoch 263/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.7261 - accuracy: 0.7029 - val_loss: 1.4260 - val_accuracy: 0.4172\n",
            "Epoch 264/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.7127 - accuracy: 0.7110 - val_loss: 1.4182 - val_accuracy: 0.4570\n",
            "Epoch 265/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.7193 - accuracy: 0.7228 - val_loss: 1.4045 - val_accuracy: 0.4503\n",
            "Epoch 266/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.7315 - accuracy: 0.7051 - val_loss: 1.4399 - val_accuracy: 0.4040\n",
            "Epoch 267/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.7026 - accuracy: 0.7265 - val_loss: 1.4313 - val_accuracy: 0.4172\n",
            "Epoch 268/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.7107 - accuracy: 0.7214 - val_loss: 1.4260 - val_accuracy: 0.4040\n",
            "Epoch 269/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.6971 - accuracy: 0.7347 - val_loss: 1.4043 - val_accuracy: 0.4371\n",
            "Epoch 270/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.7324 - accuracy: 0.6962 - val_loss: 1.4369 - val_accuracy: 0.4503\n",
            "Epoch 271/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.7053 - accuracy: 0.7154 - val_loss: 1.4382 - val_accuracy: 0.4172\n",
            "Epoch 272/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.7028 - accuracy: 0.7184 - val_loss: 1.4200 - val_accuracy: 0.4106\n",
            "Epoch 273/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.7171 - accuracy: 0.7073 - val_loss: 1.4090 - val_accuracy: 0.4437\n",
            "Epoch 274/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.7186 - accuracy: 0.7199 - val_loss: 1.4667 - val_accuracy: 0.3841\n",
            "Epoch 275/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.7301 - accuracy: 0.7058 - val_loss: 1.4715 - val_accuracy: 0.3841\n",
            "Epoch 276/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.6934 - accuracy: 0.7103 - val_loss: 1.4812 - val_accuracy: 0.4106\n",
            "Epoch 277/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.6947 - accuracy: 0.7265 - val_loss: 1.4349 - val_accuracy: 0.4106\n",
            "Epoch 278/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.7135 - accuracy: 0.7103 - val_loss: 1.4261 - val_accuracy: 0.4503\n",
            "Epoch 279/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.7050 - accuracy: 0.7140 - val_loss: 1.4129 - val_accuracy: 0.4238\n",
            "Epoch 280/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.6936 - accuracy: 0.7184 - val_loss: 1.4419 - val_accuracy: 0.4570\n",
            "Epoch 281/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.6807 - accuracy: 0.7361 - val_loss: 1.4497 - val_accuracy: 0.4371\n",
            "Epoch 282/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.6852 - accuracy: 0.7310 - val_loss: 1.4202 - val_accuracy: 0.5099\n",
            "Epoch 283/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.7046 - accuracy: 0.7214 - val_loss: 1.4271 - val_accuracy: 0.4702\n",
            "Epoch 284/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.6908 - accuracy: 0.7214 - val_loss: 1.4257 - val_accuracy: 0.4834\n",
            "Epoch 285/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.6936 - accuracy: 0.7243 - val_loss: 1.4224 - val_accuracy: 0.4437\n",
            "Epoch 286/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.6853 - accuracy: 0.7258 - val_loss: 1.4240 - val_accuracy: 0.4106\n",
            "Epoch 287/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.6855 - accuracy: 0.7413 - val_loss: 1.4477 - val_accuracy: 0.3907\n",
            "Epoch 288/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.6823 - accuracy: 0.7191 - val_loss: 1.4078 - val_accuracy: 0.4503\n",
            "Epoch 289/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.6926 - accuracy: 0.7206 - val_loss: 1.4388 - val_accuracy: 0.4503\n",
            "Epoch 290/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.7020 - accuracy: 0.7273 - val_loss: 1.5088 - val_accuracy: 0.4371\n",
            "Epoch 291/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.6996 - accuracy: 0.7228 - val_loss: 1.4304 - val_accuracy: 0.4238\n",
            "Epoch 292/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.6774 - accuracy: 0.7265 - val_loss: 1.4799 - val_accuracy: 0.4106\n",
            "Epoch 293/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.6871 - accuracy: 0.7273 - val_loss: 1.4365 - val_accuracy: 0.4238\n",
            "Epoch 294/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.6886 - accuracy: 0.7406 - val_loss: 1.4433 - val_accuracy: 0.4106\n",
            "Epoch 295/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.6618 - accuracy: 0.7310 - val_loss: 1.4538 - val_accuracy: 0.3974\n",
            "Epoch 296/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.6844 - accuracy: 0.7243 - val_loss: 1.4936 - val_accuracy: 0.4834\n",
            "Epoch 297/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.6749 - accuracy: 0.7361 - val_loss: 1.4350 - val_accuracy: 0.4768\n",
            "Epoch 298/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.6645 - accuracy: 0.7310 - val_loss: 1.4473 - val_accuracy: 0.4503\n",
            "Epoch 299/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.6792 - accuracy: 0.7184 - val_loss: 1.4478 - val_accuracy: 0.4305\n",
            "Epoch 300/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.6739 - accuracy: 0.7413 - val_loss: 1.4309 - val_accuracy: 0.4238\n",
            "Epoch 301/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.6736 - accuracy: 0.7324 - val_loss: 1.4454 - val_accuracy: 0.4238\n",
            "Epoch 302/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.6866 - accuracy: 0.7243 - val_loss: 1.4687 - val_accuracy: 0.4040\n",
            "Epoch 303/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.6679 - accuracy: 0.7265 - val_loss: 1.4661 - val_accuracy: 0.4106\n",
            "Epoch 304/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.6545 - accuracy: 0.7465 - val_loss: 1.4811 - val_accuracy: 0.4238\n",
            "Epoch 305/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.6707 - accuracy: 0.7317 - val_loss: 1.4863 - val_accuracy: 0.4305\n",
            "Epoch 306/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.6766 - accuracy: 0.7258 - val_loss: 1.4453 - val_accuracy: 0.4570\n",
            "Epoch 307/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.6728 - accuracy: 0.7376 - val_loss: 1.4288 - val_accuracy: 0.4305\n",
            "Epoch 308/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.6609 - accuracy: 0.7369 - val_loss: 1.4173 - val_accuracy: 0.4503\n",
            "Epoch 309/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.6810 - accuracy: 0.7206 - val_loss: 1.4431 - val_accuracy: 0.4636\n",
            "Epoch 310/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.6554 - accuracy: 0.7391 - val_loss: 1.4445 - val_accuracy: 0.4371\n",
            "Epoch 311/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.6834 - accuracy: 0.7310 - val_loss: 1.4865 - val_accuracy: 0.4305\n",
            "Epoch 312/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.6503 - accuracy: 0.7214 - val_loss: 1.4306 - val_accuracy: 0.4106\n",
            "Epoch 313/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.6480 - accuracy: 0.7524 - val_loss: 1.4543 - val_accuracy: 0.4305\n",
            "Epoch 314/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.6434 - accuracy: 0.7472 - val_loss: 1.4140 - val_accuracy: 0.4238\n",
            "Epoch 315/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.6545 - accuracy: 0.7465 - val_loss: 1.4739 - val_accuracy: 0.3841\n",
            "Epoch 316/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.6707 - accuracy: 0.7361 - val_loss: 1.4090 - val_accuracy: 0.4172\n",
            "Epoch 317/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.6580 - accuracy: 0.7369 - val_loss: 1.4158 - val_accuracy: 0.4437\n",
            "Epoch 318/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.6623 - accuracy: 0.7339 - val_loss: 1.4411 - val_accuracy: 0.4106\n",
            "Epoch 319/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.6555 - accuracy: 0.7332 - val_loss: 1.4653 - val_accuracy: 0.3974\n",
            "Epoch 320/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.6587 - accuracy: 0.7591 - val_loss: 1.4395 - val_accuracy: 0.4172\n",
            "Epoch 321/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.6311 - accuracy: 0.7502 - val_loss: 1.4585 - val_accuracy: 0.4040\n",
            "Epoch 322/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.6487 - accuracy: 0.7546 - val_loss: 1.4101 - val_accuracy: 0.4238\n",
            "Epoch 323/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.6536 - accuracy: 0.7561 - val_loss: 1.4288 - val_accuracy: 0.4238\n",
            "Epoch 324/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.6395 - accuracy: 0.7465 - val_loss: 1.4470 - val_accuracy: 0.4570\n",
            "Epoch 325/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.6510 - accuracy: 0.7317 - val_loss: 1.4781 - val_accuracy: 0.4371\n",
            "Epoch 326/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.6396 - accuracy: 0.7517 - val_loss: 1.4513 - val_accuracy: 0.4570\n",
            "Epoch 327/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.6404 - accuracy: 0.7465 - val_loss: 1.4611 - val_accuracy: 0.4437\n",
            "Epoch 328/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.6487 - accuracy: 0.7435 - val_loss: 1.4609 - val_accuracy: 0.4503\n",
            "Epoch 329/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.6318 - accuracy: 0.7531 - val_loss: 1.4435 - val_accuracy: 0.4238\n",
            "Epoch 330/700\n",
            "85/85 [==============================] - 2s 25ms/step - loss: 0.6315 - accuracy: 0.7480 - val_loss: 1.4264 - val_accuracy: 0.4702\n",
            "Epoch 331/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.6099 - accuracy: 0.7650 - val_loss: 1.4441 - val_accuracy: 0.4040\n",
            "Epoch 332/700\n",
            "85/85 [==============================] - 2s 25ms/step - loss: 0.6408 - accuracy: 0.7354 - val_loss: 1.4194 - val_accuracy: 0.4437\n",
            "Epoch 333/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.6404 - accuracy: 0.7480 - val_loss: 1.4706 - val_accuracy: 0.4238\n",
            "Epoch 334/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.6269 - accuracy: 0.7664 - val_loss: 1.4227 - val_accuracy: 0.4371\n",
            "Epoch 335/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.6118 - accuracy: 0.7591 - val_loss: 1.4481 - val_accuracy: 0.4238\n",
            "Epoch 336/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.6143 - accuracy: 0.7657 - val_loss: 1.4835 - val_accuracy: 0.4371\n",
            "Epoch 337/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.6119 - accuracy: 0.7539 - val_loss: 1.4354 - val_accuracy: 0.4238\n",
            "Epoch 338/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.6332 - accuracy: 0.7354 - val_loss: 1.5199 - val_accuracy: 0.4172\n",
            "Epoch 339/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.6321 - accuracy: 0.7450 - val_loss: 1.4609 - val_accuracy: 0.4636\n",
            "Epoch 340/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.6299 - accuracy: 0.7546 - val_loss: 1.4467 - val_accuracy: 0.4172\n",
            "Epoch 341/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.6276 - accuracy: 0.7591 - val_loss: 1.4266 - val_accuracy: 0.4305\n",
            "Epoch 342/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.6176 - accuracy: 0.7605 - val_loss: 1.4708 - val_accuracy: 0.4238\n",
            "Epoch 343/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.6148 - accuracy: 0.7509 - val_loss: 1.4277 - val_accuracy: 0.4238\n",
            "Epoch 344/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.6341 - accuracy: 0.7524 - val_loss: 1.4508 - val_accuracy: 0.4172\n",
            "Epoch 345/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.6413 - accuracy: 0.7369 - val_loss: 1.4656 - val_accuracy: 0.4437\n",
            "Epoch 346/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.6269 - accuracy: 0.7531 - val_loss: 1.4428 - val_accuracy: 0.4040\n",
            "Epoch 347/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.6271 - accuracy: 0.7524 - val_loss: 1.4525 - val_accuracy: 0.4305\n",
            "Epoch 348/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.6086 - accuracy: 0.7568 - val_loss: 1.4115 - val_accuracy: 0.4238\n",
            "Epoch 349/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.6231 - accuracy: 0.7605 - val_loss: 1.4632 - val_accuracy: 0.4437\n",
            "Epoch 350/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.6109 - accuracy: 0.7605 - val_loss: 1.4980 - val_accuracy: 0.4106\n",
            "Epoch 351/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.6035 - accuracy: 0.7635 - val_loss: 1.4560 - val_accuracy: 0.4305\n",
            "Epoch 352/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.6101 - accuracy: 0.7517 - val_loss: 1.4351 - val_accuracy: 0.4305\n",
            "Epoch 353/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.6122 - accuracy: 0.7517 - val_loss: 1.4721 - val_accuracy: 0.4636\n",
            "Epoch 354/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.6193 - accuracy: 0.7539 - val_loss: 1.4773 - val_accuracy: 0.4437\n",
            "Epoch 355/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.6027 - accuracy: 0.7724 - val_loss: 1.4439 - val_accuracy: 0.4172\n",
            "Epoch 356/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.6118 - accuracy: 0.7554 - val_loss: 1.4960 - val_accuracy: 0.4834\n",
            "Epoch 357/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.6167 - accuracy: 0.7480 - val_loss: 1.4552 - val_accuracy: 0.4238\n",
            "Epoch 358/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.6094 - accuracy: 0.7613 - val_loss: 1.4284 - val_accuracy: 0.4238\n",
            "Epoch 359/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.5894 - accuracy: 0.7716 - val_loss: 1.4595 - val_accuracy: 0.4503\n",
            "Epoch 360/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.5989 - accuracy: 0.7701 - val_loss: 1.4411 - val_accuracy: 0.4305\n",
            "Epoch 361/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.5839 - accuracy: 0.7687 - val_loss: 1.4465 - val_accuracy: 0.4305\n",
            "Epoch 362/700\n",
            "85/85 [==============================] - 2s 25ms/step - loss: 0.5919 - accuracy: 0.7709 - val_loss: 1.4413 - val_accuracy: 0.4437\n",
            "Epoch 363/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.5950 - accuracy: 0.7724 - val_loss: 1.4833 - val_accuracy: 0.4172\n",
            "Epoch 364/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.5915 - accuracy: 0.7679 - val_loss: 1.4501 - val_accuracy: 0.4636\n",
            "Epoch 365/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.5701 - accuracy: 0.7768 - val_loss: 1.4486 - val_accuracy: 0.4305\n",
            "Epoch 366/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.5995 - accuracy: 0.7591 - val_loss: 1.5489 - val_accuracy: 0.4106\n",
            "Epoch 367/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.6137 - accuracy: 0.7613 - val_loss: 1.4849 - val_accuracy: 0.4238\n",
            "Epoch 368/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.5840 - accuracy: 0.7568 - val_loss: 1.4559 - val_accuracy: 0.4636\n",
            "Epoch 369/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.6031 - accuracy: 0.7561 - val_loss: 1.4416 - val_accuracy: 0.4437\n",
            "Epoch 370/700\n",
            "85/85 [==============================] - 2s 25ms/step - loss: 0.6106 - accuracy: 0.7539 - val_loss: 1.4742 - val_accuracy: 0.4305\n",
            "Epoch 371/700\n",
            "85/85 [==============================] - 2s 25ms/step - loss: 0.5927 - accuracy: 0.7664 - val_loss: 1.4276 - val_accuracy: 0.4437\n",
            "Epoch 372/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.5918 - accuracy: 0.7761 - val_loss: 1.4608 - val_accuracy: 0.4371\n",
            "Epoch 373/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.5922 - accuracy: 0.7598 - val_loss: 1.4674 - val_accuracy: 0.4570\n",
            "Epoch 374/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.6002 - accuracy: 0.7679 - val_loss: 1.4577 - val_accuracy: 0.4570\n",
            "Epoch 375/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.5891 - accuracy: 0.7613 - val_loss: 1.4556 - val_accuracy: 0.4702\n",
            "Epoch 376/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.5847 - accuracy: 0.7812 - val_loss: 1.5371 - val_accuracy: 0.4636\n",
            "Epoch 377/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.5847 - accuracy: 0.7842 - val_loss: 1.4571 - val_accuracy: 0.4702\n",
            "Epoch 378/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.5805 - accuracy: 0.7679 - val_loss: 1.4402 - val_accuracy: 0.4570\n",
            "Epoch 379/700\n",
            "85/85 [==============================] - 2s 26ms/step - loss: 0.5779 - accuracy: 0.7797 - val_loss: 1.5031 - val_accuracy: 0.3974\n",
            "Epoch 380/700\n",
            "85/85 [==============================] - 2s 29ms/step - loss: 0.5756 - accuracy: 0.7775 - val_loss: 1.4761 - val_accuracy: 0.4636\n",
            "Epoch 381/700\n",
            "85/85 [==============================] - 3s 34ms/step - loss: 0.5883 - accuracy: 0.7805 - val_loss: 1.4569 - val_accuracy: 0.4305\n",
            "Epoch 382/700\n",
            "85/85 [==============================] - 2s 27ms/step - loss: 0.5835 - accuracy: 0.7694 - val_loss: 1.4931 - val_accuracy: 0.4305\n",
            "Epoch 383/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.5842 - accuracy: 0.7679 - val_loss: 1.4644 - val_accuracy: 0.4305\n",
            "Epoch 384/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.5742 - accuracy: 0.7783 - val_loss: 1.4615 - val_accuracy: 0.4768\n",
            "Epoch 385/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.5733 - accuracy: 0.7783 - val_loss: 1.4799 - val_accuracy: 0.4371\n",
            "Epoch 386/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.5554 - accuracy: 0.7746 - val_loss: 1.4648 - val_accuracy: 0.4437\n",
            "Epoch 387/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.5927 - accuracy: 0.7716 - val_loss: 1.4552 - val_accuracy: 0.4172\n",
            "Epoch 388/700\n",
            "85/85 [==============================] - 2s 25ms/step - loss: 0.5824 - accuracy: 0.7687 - val_loss: 1.4332 - val_accuracy: 0.4503\n",
            "Epoch 389/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.5773 - accuracy: 0.7583 - val_loss: 1.4503 - val_accuracy: 0.4106\n",
            "Epoch 390/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.5690 - accuracy: 0.7908 - val_loss: 1.4613 - val_accuracy: 0.4238\n",
            "Epoch 391/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.5597 - accuracy: 0.7761 - val_loss: 1.5213 - val_accuracy: 0.4172\n",
            "Epoch 392/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.5899 - accuracy: 0.7657 - val_loss: 1.4817 - val_accuracy: 0.4238\n",
            "Epoch 393/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.5643 - accuracy: 0.7694 - val_loss: 1.4755 - val_accuracy: 0.4305\n",
            "Epoch 394/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.5626 - accuracy: 0.7916 - val_loss: 1.4500 - val_accuracy: 0.4570\n",
            "Epoch 395/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.5747 - accuracy: 0.7716 - val_loss: 1.4581 - val_accuracy: 0.4371\n",
            "Epoch 396/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.5548 - accuracy: 0.7901 - val_loss: 1.4362 - val_accuracy: 0.4636\n",
            "Epoch 397/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.5563 - accuracy: 0.7931 - val_loss: 1.4646 - val_accuracy: 0.4371\n",
            "Epoch 398/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.5762 - accuracy: 0.7797 - val_loss: 1.4696 - val_accuracy: 0.4371\n",
            "Epoch 399/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.5618 - accuracy: 0.7768 - val_loss: 1.4601 - val_accuracy: 0.4305\n",
            "Epoch 400/700\n",
            "85/85 [==============================] - 2s 25ms/step - loss: 0.5619 - accuracy: 0.7783 - val_loss: 1.5079 - val_accuracy: 0.4305\n",
            "Epoch 401/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.5471 - accuracy: 0.7871 - val_loss: 1.4846 - val_accuracy: 0.4040\n",
            "Epoch 402/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.5623 - accuracy: 0.7797 - val_loss: 1.4716 - val_accuracy: 0.4238\n",
            "Epoch 403/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.5554 - accuracy: 0.7827 - val_loss: 1.4616 - val_accuracy: 0.4238\n",
            "Epoch 404/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.5530 - accuracy: 0.7931 - val_loss: 1.4931 - val_accuracy: 0.4636\n",
            "Epoch 405/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.5504 - accuracy: 0.7849 - val_loss: 1.4532 - val_accuracy: 0.4702\n",
            "Epoch 406/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.5356 - accuracy: 0.7901 - val_loss: 1.4764 - val_accuracy: 0.4106\n",
            "Epoch 407/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.5296 - accuracy: 0.7975 - val_loss: 1.4909 - val_accuracy: 0.4238\n",
            "Epoch 408/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.5495 - accuracy: 0.7812 - val_loss: 1.4694 - val_accuracy: 0.4172\n",
            "Epoch 409/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.5464 - accuracy: 0.7842 - val_loss: 1.4541 - val_accuracy: 0.4437\n",
            "Epoch 410/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.5463 - accuracy: 0.7923 - val_loss: 1.4810 - val_accuracy: 0.4636\n",
            "Epoch 411/700\n",
            "85/85 [==============================] - 2s 25ms/step - loss: 0.5489 - accuracy: 0.7894 - val_loss: 1.4824 - val_accuracy: 0.4371\n",
            "Epoch 412/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.5296 - accuracy: 0.7945 - val_loss: 1.4692 - val_accuracy: 0.4305\n",
            "Epoch 413/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.5308 - accuracy: 0.7908 - val_loss: 1.4758 - val_accuracy: 0.4503\n",
            "Epoch 414/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.5468 - accuracy: 0.7834 - val_loss: 1.4802 - val_accuracy: 0.4305\n",
            "Epoch 415/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.5427 - accuracy: 0.7738 - val_loss: 1.5699 - val_accuracy: 0.3974\n",
            "Epoch 416/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.5402 - accuracy: 0.7857 - val_loss: 1.4596 - val_accuracy: 0.4570\n",
            "Epoch 417/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.5538 - accuracy: 0.7761 - val_loss: 1.5262 - val_accuracy: 0.4702\n",
            "Epoch 418/700\n",
            "85/85 [==============================] - 2s 25ms/step - loss: 0.5550 - accuracy: 0.7827 - val_loss: 1.4890 - val_accuracy: 0.4570\n",
            "Epoch 419/700\n",
            "85/85 [==============================] - 2s 25ms/step - loss: 0.5258 - accuracy: 0.7990 - val_loss: 1.5129 - val_accuracy: 0.4437\n",
            "Epoch 420/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.5276 - accuracy: 0.7990 - val_loss: 1.5134 - val_accuracy: 0.4570\n",
            "Epoch 421/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.5208 - accuracy: 0.8012 - val_loss: 1.4426 - val_accuracy: 0.4636\n",
            "Epoch 422/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.5254 - accuracy: 0.7975 - val_loss: 1.4637 - val_accuracy: 0.4371\n",
            "Epoch 423/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.5103 - accuracy: 0.7997 - val_loss: 1.4938 - val_accuracy: 0.4305\n",
            "Epoch 424/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.5393 - accuracy: 0.8012 - val_loss: 1.4758 - val_accuracy: 0.4371\n",
            "Epoch 425/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.5139 - accuracy: 0.8071 - val_loss: 1.4764 - val_accuracy: 0.4636\n",
            "Epoch 426/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.5365 - accuracy: 0.7990 - val_loss: 1.4954 - val_accuracy: 0.4371\n",
            "Epoch 427/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.5329 - accuracy: 0.7908 - val_loss: 1.4604 - val_accuracy: 0.4503\n",
            "Epoch 428/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.5227 - accuracy: 0.8004 - val_loss: 1.4513 - val_accuracy: 0.4570\n",
            "Epoch 429/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.5386 - accuracy: 0.7864 - val_loss: 1.4923 - val_accuracy: 0.4570\n",
            "Epoch 430/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.5193 - accuracy: 0.7975 - val_loss: 1.4702 - val_accuracy: 0.4437\n",
            "Epoch 431/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.5270 - accuracy: 0.8041 - val_loss: 1.4796 - val_accuracy: 0.4570\n",
            "Epoch 432/700\n",
            "85/85 [==============================] - 2s 26ms/step - loss: 0.5298 - accuracy: 0.7820 - val_loss: 1.4742 - val_accuracy: 0.4437\n",
            "Epoch 433/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.5215 - accuracy: 0.8004 - val_loss: 1.4565 - val_accuracy: 0.4371\n",
            "Epoch 434/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.5244 - accuracy: 0.7857 - val_loss: 1.5089 - val_accuracy: 0.4570\n",
            "Epoch 435/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.5298 - accuracy: 0.7908 - val_loss: 1.5088 - val_accuracy: 0.4636\n",
            "Epoch 436/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.5349 - accuracy: 0.7790 - val_loss: 1.4759 - val_accuracy: 0.4503\n",
            "Epoch 437/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.5000 - accuracy: 0.8064 - val_loss: 1.4919 - val_accuracy: 0.4437\n",
            "Epoch 438/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.5040 - accuracy: 0.8101 - val_loss: 1.4806 - val_accuracy: 0.4636\n",
            "Epoch 439/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.5202 - accuracy: 0.8019 - val_loss: 1.4922 - val_accuracy: 0.4503\n",
            "Epoch 440/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.5396 - accuracy: 0.7842 - val_loss: 1.4893 - val_accuracy: 0.4437\n",
            "Epoch 441/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.5319 - accuracy: 0.7997 - val_loss: 1.5102 - val_accuracy: 0.4437\n",
            "Epoch 442/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.5220 - accuracy: 0.7990 - val_loss: 1.4956 - val_accuracy: 0.4570\n",
            "Epoch 443/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.5107 - accuracy: 0.8071 - val_loss: 1.4819 - val_accuracy: 0.4702\n",
            "Epoch 444/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.5116 - accuracy: 0.7982 - val_loss: 1.4887 - val_accuracy: 0.4305\n",
            "Epoch 445/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.5247 - accuracy: 0.7990 - val_loss: 1.4797 - val_accuracy: 0.4503\n",
            "Epoch 446/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.5274 - accuracy: 0.8041 - val_loss: 1.5127 - val_accuracy: 0.4570\n",
            "Epoch 447/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.4919 - accuracy: 0.8174 - val_loss: 1.5206 - val_accuracy: 0.4238\n",
            "Epoch 448/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.4849 - accuracy: 0.8248 - val_loss: 1.5304 - val_accuracy: 0.4503\n",
            "Epoch 449/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.5050 - accuracy: 0.8041 - val_loss: 1.4979 - val_accuracy: 0.4570\n",
            "Epoch 450/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.5038 - accuracy: 0.7982 - val_loss: 1.4995 - val_accuracy: 0.4437\n",
            "Epoch 451/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.5064 - accuracy: 0.8027 - val_loss: 1.5454 - val_accuracy: 0.4636\n",
            "Epoch 452/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.5063 - accuracy: 0.7997 - val_loss: 1.5786 - val_accuracy: 0.3974\n",
            "Epoch 453/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.5243 - accuracy: 0.7916 - val_loss: 1.4949 - val_accuracy: 0.4437\n",
            "Epoch 454/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.4893 - accuracy: 0.8123 - val_loss: 1.5568 - val_accuracy: 0.4238\n",
            "Epoch 455/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.4991 - accuracy: 0.8115 - val_loss: 1.5101 - val_accuracy: 0.4702\n",
            "Epoch 456/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.5196 - accuracy: 0.7923 - val_loss: 1.5075 - val_accuracy: 0.4238\n",
            "Epoch 457/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.5111 - accuracy: 0.8078 - val_loss: 1.5000 - val_accuracy: 0.4437\n",
            "Epoch 458/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.4918 - accuracy: 0.8204 - val_loss: 1.4934 - val_accuracy: 0.4437\n",
            "Epoch 459/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.5078 - accuracy: 0.7982 - val_loss: 1.4903 - val_accuracy: 0.4702\n",
            "Epoch 460/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.5169 - accuracy: 0.7990 - val_loss: 1.5069 - val_accuracy: 0.4503\n",
            "Epoch 461/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.4900 - accuracy: 0.8071 - val_loss: 1.5076 - val_accuracy: 0.4768\n",
            "Epoch 462/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.5009 - accuracy: 0.8145 - val_loss: 1.5036 - val_accuracy: 0.4503\n",
            "Epoch 463/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.4907 - accuracy: 0.8145 - val_loss: 1.5555 - val_accuracy: 0.4437\n",
            "Epoch 464/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.5027 - accuracy: 0.8167 - val_loss: 1.5203 - val_accuracy: 0.4702\n",
            "Epoch 465/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.5107 - accuracy: 0.8145 - val_loss: 1.5244 - val_accuracy: 0.4305\n",
            "Epoch 466/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.4999 - accuracy: 0.8078 - val_loss: 1.4887 - val_accuracy: 0.4768\n",
            "Epoch 467/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.4945 - accuracy: 0.8234 - val_loss: 1.5037 - val_accuracy: 0.4503\n",
            "Epoch 468/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.4944 - accuracy: 0.8064 - val_loss: 1.5431 - val_accuracy: 0.4305\n",
            "Epoch 469/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.4969 - accuracy: 0.8137 - val_loss: 1.4777 - val_accuracy: 0.4437\n",
            "Epoch 470/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.5108 - accuracy: 0.8004 - val_loss: 1.5217 - val_accuracy: 0.4636\n",
            "Epoch 471/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.4976 - accuracy: 0.8027 - val_loss: 1.5016 - val_accuracy: 0.4437\n",
            "Epoch 472/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.5055 - accuracy: 0.7923 - val_loss: 1.5208 - val_accuracy: 0.4437\n",
            "Epoch 473/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.4948 - accuracy: 0.8004 - val_loss: 1.5091 - val_accuracy: 0.4437\n",
            "Epoch 474/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.5024 - accuracy: 0.8034 - val_loss: 1.5647 - val_accuracy: 0.4371\n",
            "Epoch 475/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.5063 - accuracy: 0.8115 - val_loss: 1.5143 - val_accuracy: 0.4768\n",
            "Epoch 476/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.4863 - accuracy: 0.8041 - val_loss: 1.5080 - val_accuracy: 0.4437\n",
            "Epoch 477/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.4988 - accuracy: 0.8078 - val_loss: 1.5910 - val_accuracy: 0.4437\n",
            "Epoch 478/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.4814 - accuracy: 0.8174 - val_loss: 1.5201 - val_accuracy: 0.4570\n",
            "Epoch 479/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.4986 - accuracy: 0.7953 - val_loss: 1.5232 - val_accuracy: 0.4570\n",
            "Epoch 480/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.4728 - accuracy: 0.8226 - val_loss: 1.4898 - val_accuracy: 0.4503\n",
            "Epoch 481/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.4715 - accuracy: 0.8189 - val_loss: 1.5078 - val_accuracy: 0.4503\n",
            "Epoch 482/700\n",
            "85/85 [==============================] - 2s 25ms/step - loss: 0.4562 - accuracy: 0.8263 - val_loss: 1.5213 - val_accuracy: 0.4437\n",
            "Epoch 483/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.4693 - accuracy: 0.8248 - val_loss: 1.5351 - val_accuracy: 0.4636\n",
            "Epoch 484/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.4658 - accuracy: 0.8234 - val_loss: 1.5018 - val_accuracy: 0.4570\n",
            "Epoch 485/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.4931 - accuracy: 0.8160 - val_loss: 1.5300 - val_accuracy: 0.4503\n",
            "Epoch 486/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.4833 - accuracy: 0.8263 - val_loss: 1.5243 - val_accuracy: 0.4636\n",
            "Epoch 487/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.4768 - accuracy: 0.8101 - val_loss: 1.5398 - val_accuracy: 0.4702\n",
            "Epoch 488/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.4913 - accuracy: 0.8101 - val_loss: 1.5109 - val_accuracy: 0.4503\n",
            "Epoch 489/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.4830 - accuracy: 0.8137 - val_loss: 1.4960 - val_accuracy: 0.4768\n",
            "Epoch 490/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.4871 - accuracy: 0.8078 - val_loss: 1.5244 - val_accuracy: 0.4437\n",
            "Epoch 491/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.4914 - accuracy: 0.8078 - val_loss: 1.5427 - val_accuracy: 0.4702\n",
            "Epoch 492/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.4844 - accuracy: 0.8123 - val_loss: 1.5213 - val_accuracy: 0.4305\n",
            "Epoch 493/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.4738 - accuracy: 0.8130 - val_loss: 1.5276 - val_accuracy: 0.4503\n",
            "Epoch 494/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.4806 - accuracy: 0.8041 - val_loss: 1.5073 - val_accuracy: 0.4702\n",
            "Epoch 495/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.4699 - accuracy: 0.8234 - val_loss: 1.5460 - val_accuracy: 0.4437\n",
            "Epoch 496/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.4623 - accuracy: 0.8241 - val_loss: 1.5843 - val_accuracy: 0.4437\n",
            "Epoch 497/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.4651 - accuracy: 0.8108 - val_loss: 1.5179 - val_accuracy: 0.4702\n",
            "Epoch 498/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.4628 - accuracy: 0.8256 - val_loss: 1.6092 - val_accuracy: 0.4305\n",
            "Epoch 499/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.4620 - accuracy: 0.8256 - val_loss: 1.5781 - val_accuracy: 0.4238\n",
            "Epoch 500/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.4677 - accuracy: 0.8160 - val_loss: 1.5132 - val_accuracy: 0.4371\n",
            "Epoch 501/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.4738 - accuracy: 0.8204 - val_loss: 1.5066 - val_accuracy: 0.4702\n",
            "Epoch 502/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.4600 - accuracy: 0.8256 - val_loss: 1.5458 - val_accuracy: 0.4371\n",
            "Epoch 503/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.4506 - accuracy: 0.8315 - val_loss: 1.5595 - val_accuracy: 0.4570\n",
            "Epoch 504/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.4576 - accuracy: 0.8241 - val_loss: 1.6456 - val_accuracy: 0.4371\n",
            "Epoch 505/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.4718 - accuracy: 0.8160 - val_loss: 1.5578 - val_accuracy: 0.4702\n",
            "Epoch 506/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.4642 - accuracy: 0.8167 - val_loss: 1.5141 - val_accuracy: 0.4570\n",
            "Epoch 507/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.4694 - accuracy: 0.8263 - val_loss: 1.5645 - val_accuracy: 0.4503\n",
            "Epoch 508/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.4620 - accuracy: 0.8137 - val_loss: 1.5340 - val_accuracy: 0.4702\n",
            "Epoch 509/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.4504 - accuracy: 0.8263 - val_loss: 1.5350 - val_accuracy: 0.4834\n",
            "Epoch 510/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.4476 - accuracy: 0.8248 - val_loss: 1.5424 - val_accuracy: 0.4570\n",
            "Epoch 511/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.4744 - accuracy: 0.8167 - val_loss: 1.5804 - val_accuracy: 0.4371\n",
            "Epoch 512/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.4556 - accuracy: 0.8278 - val_loss: 1.5378 - val_accuracy: 0.4702\n",
            "Epoch 513/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.4346 - accuracy: 0.8300 - val_loss: 1.6140 - val_accuracy: 0.4437\n",
            "Epoch 514/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.4354 - accuracy: 0.8285 - val_loss: 1.5181 - val_accuracy: 0.4967\n",
            "Epoch 515/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.4358 - accuracy: 0.8263 - val_loss: 1.5511 - val_accuracy: 0.4570\n",
            "Epoch 516/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.4459 - accuracy: 0.8315 - val_loss: 1.5224 - val_accuracy: 0.4967\n",
            "Epoch 517/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.4475 - accuracy: 0.8256 - val_loss: 1.5474 - val_accuracy: 0.4371\n",
            "Epoch 518/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.4497 - accuracy: 0.8167 - val_loss: 1.5306 - val_accuracy: 0.4834\n",
            "Epoch 519/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.4520 - accuracy: 0.8352 - val_loss: 1.5254 - val_accuracy: 0.4437\n",
            "Epoch 520/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.4425 - accuracy: 0.8374 - val_loss: 1.5377 - val_accuracy: 0.4570\n",
            "Epoch 521/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.4229 - accuracy: 0.8396 - val_loss: 1.5439 - val_accuracy: 0.4702\n",
            "Epoch 522/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.4199 - accuracy: 0.8418 - val_loss: 1.5459 - val_accuracy: 0.4702\n",
            "Epoch 523/700\n",
            "85/85 [==============================] - 2s 25ms/step - loss: 0.4427 - accuracy: 0.8300 - val_loss: 1.5246 - val_accuracy: 0.4570\n",
            "Epoch 524/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.4386 - accuracy: 0.8226 - val_loss: 1.5280 - val_accuracy: 0.4834\n",
            "Epoch 525/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.4662 - accuracy: 0.8248 - val_loss: 1.5363 - val_accuracy: 0.4570\n",
            "Epoch 526/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.4570 - accuracy: 0.8330 - val_loss: 1.5184 - val_accuracy: 0.4437\n",
            "Epoch 527/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.4313 - accuracy: 0.8455 - val_loss: 1.5194 - val_accuracy: 0.4371\n",
            "Epoch 528/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.4549 - accuracy: 0.8241 - val_loss: 1.5740 - val_accuracy: 0.4503\n",
            "Epoch 529/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.4400 - accuracy: 0.8293 - val_loss: 1.5299 - val_accuracy: 0.4636\n",
            "Epoch 530/700\n",
            "85/85 [==============================] - 2s 25ms/step - loss: 0.4395 - accuracy: 0.8285 - val_loss: 1.5944 - val_accuracy: 0.4834\n",
            "Epoch 531/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.4476 - accuracy: 0.8344 - val_loss: 1.5508 - val_accuracy: 0.4172\n",
            "Epoch 532/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.4662 - accuracy: 0.8248 - val_loss: 1.5761 - val_accuracy: 0.4570\n",
            "Epoch 533/700\n",
            "85/85 [==============================] - 2s 25ms/step - loss: 0.4444 - accuracy: 0.8337 - val_loss: 1.5321 - val_accuracy: 0.4768\n",
            "Epoch 534/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.4373 - accuracy: 0.8441 - val_loss: 1.5175 - val_accuracy: 0.4636\n",
            "Epoch 535/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.4442 - accuracy: 0.8241 - val_loss: 1.5557 - val_accuracy: 0.4768\n",
            "Epoch 536/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.4567 - accuracy: 0.8182 - val_loss: 1.5602 - val_accuracy: 0.4702\n",
            "Epoch 537/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.4395 - accuracy: 0.8300 - val_loss: 1.5240 - val_accuracy: 0.4636\n",
            "Epoch 538/700\n",
            "85/85 [==============================] - 2s 25ms/step - loss: 0.4333 - accuracy: 0.8352 - val_loss: 1.5785 - val_accuracy: 0.4834\n",
            "Epoch 539/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.4264 - accuracy: 0.8352 - val_loss: 1.5529 - val_accuracy: 0.4768\n",
            "Epoch 540/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.4211 - accuracy: 0.8404 - val_loss: 1.6634 - val_accuracy: 0.3974\n",
            "Epoch 541/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.4547 - accuracy: 0.8160 - val_loss: 1.5458 - val_accuracy: 0.4901\n",
            "Epoch 542/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.4100 - accuracy: 0.8470 - val_loss: 1.5312 - val_accuracy: 0.4768\n",
            "Epoch 543/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.4321 - accuracy: 0.8263 - val_loss: 1.5336 - val_accuracy: 0.4901\n",
            "Epoch 544/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.4221 - accuracy: 0.8411 - val_loss: 1.5575 - val_accuracy: 0.4503\n",
            "Epoch 545/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.4115 - accuracy: 0.8433 - val_loss: 1.6281 - val_accuracy: 0.4570\n",
            "Epoch 546/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.4243 - accuracy: 0.8411 - val_loss: 1.5555 - val_accuracy: 0.4834\n",
            "Epoch 547/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.4377 - accuracy: 0.8359 - val_loss: 1.5740 - val_accuracy: 0.4570\n",
            "Epoch 548/700\n",
            "85/85 [==============================] - 2s 25ms/step - loss: 0.4422 - accuracy: 0.8322 - val_loss: 1.5509 - val_accuracy: 0.4768\n",
            "Epoch 549/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.4404 - accuracy: 0.8352 - val_loss: 1.5748 - val_accuracy: 0.4570\n",
            "Epoch 550/700\n",
            "85/85 [==============================] - 2s 25ms/step - loss: 0.4289 - accuracy: 0.8330 - val_loss: 1.5505 - val_accuracy: 0.4901\n",
            "Epoch 551/700\n",
            "85/85 [==============================] - 2s 25ms/step - loss: 0.4096 - accuracy: 0.8441 - val_loss: 1.5890 - val_accuracy: 0.4503\n",
            "Epoch 552/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.4254 - accuracy: 0.8367 - val_loss: 1.6152 - val_accuracy: 0.4570\n",
            "Epoch 553/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.4172 - accuracy: 0.8507 - val_loss: 1.6866 - val_accuracy: 0.4503\n",
            "Epoch 554/700\n",
            "85/85 [==============================] - 2s 25ms/step - loss: 0.4105 - accuracy: 0.8433 - val_loss: 1.5872 - val_accuracy: 0.4768\n",
            "Epoch 555/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.4106 - accuracy: 0.8477 - val_loss: 1.5734 - val_accuracy: 0.4636\n",
            "Epoch 556/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.4181 - accuracy: 0.8337 - val_loss: 1.5619 - val_accuracy: 0.4636\n",
            "Epoch 557/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.4241 - accuracy: 0.8477 - val_loss: 1.5386 - val_accuracy: 0.4636\n",
            "Epoch 558/700\n",
            "85/85 [==============================] - 2s 25ms/step - loss: 0.4207 - accuracy: 0.8352 - val_loss: 1.5281 - val_accuracy: 0.4570\n",
            "Epoch 559/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.3965 - accuracy: 0.8529 - val_loss: 1.5970 - val_accuracy: 0.4570\n",
            "Epoch 560/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.4199 - accuracy: 0.8411 - val_loss: 1.5973 - val_accuracy: 0.4702\n",
            "Epoch 561/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.4262 - accuracy: 0.8315 - val_loss: 1.5603 - val_accuracy: 0.4768\n",
            "Epoch 562/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.4146 - accuracy: 0.8352 - val_loss: 1.5660 - val_accuracy: 0.4503\n",
            "Epoch 563/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.4234 - accuracy: 0.8367 - val_loss: 1.6641 - val_accuracy: 0.4437\n",
            "Epoch 564/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.4127 - accuracy: 0.8433 - val_loss: 1.5571 - val_accuracy: 0.4437\n",
            "Epoch 565/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.4328 - accuracy: 0.8337 - val_loss: 1.6127 - val_accuracy: 0.4570\n",
            "Epoch 566/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.4221 - accuracy: 0.8337 - val_loss: 1.6417 - val_accuracy: 0.4371\n",
            "Epoch 567/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.4251 - accuracy: 0.8352 - val_loss: 1.5669 - val_accuracy: 0.4702\n",
            "Epoch 568/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.4187 - accuracy: 0.8396 - val_loss: 1.5721 - val_accuracy: 0.4636\n",
            "Epoch 569/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.4000 - accuracy: 0.8455 - val_loss: 1.5650 - val_accuracy: 0.4768\n",
            "Epoch 570/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.4163 - accuracy: 0.8315 - val_loss: 1.5759 - val_accuracy: 0.4967\n",
            "Epoch 571/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.4162 - accuracy: 0.8441 - val_loss: 1.5988 - val_accuracy: 0.4371\n",
            "Epoch 572/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.3993 - accuracy: 0.8477 - val_loss: 1.5928 - val_accuracy: 0.4702\n",
            "Epoch 573/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.4116 - accuracy: 0.8551 - val_loss: 1.5981 - val_accuracy: 0.4702\n",
            "Epoch 574/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.3875 - accuracy: 0.8529 - val_loss: 1.5997 - val_accuracy: 0.4702\n",
            "Epoch 575/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.3826 - accuracy: 0.8566 - val_loss: 1.6119 - val_accuracy: 0.4967\n",
            "Epoch 576/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.3989 - accuracy: 0.8448 - val_loss: 1.5868 - val_accuracy: 0.4834\n",
            "Epoch 577/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.3922 - accuracy: 0.8647 - val_loss: 1.6292 - val_accuracy: 0.4834\n",
            "Epoch 578/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.4040 - accuracy: 0.8411 - val_loss: 1.5576 - val_accuracy: 0.4636\n",
            "Epoch 579/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.4042 - accuracy: 0.8470 - val_loss: 1.6240 - val_accuracy: 0.4437\n",
            "Epoch 580/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.3847 - accuracy: 0.8559 - val_loss: 1.5825 - val_accuracy: 0.4437\n",
            "Epoch 581/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.3975 - accuracy: 0.8477 - val_loss: 1.6065 - val_accuracy: 0.4503\n",
            "Epoch 582/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.4022 - accuracy: 0.8433 - val_loss: 1.6035 - val_accuracy: 0.4636\n",
            "Epoch 583/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.3982 - accuracy: 0.8411 - val_loss: 1.6092 - val_accuracy: 0.4702\n",
            "Epoch 584/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.4038 - accuracy: 0.8514 - val_loss: 1.6255 - val_accuracy: 0.4238\n",
            "Epoch 585/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.4006 - accuracy: 0.8396 - val_loss: 1.6846 - val_accuracy: 0.4106\n",
            "Epoch 586/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.3855 - accuracy: 0.8485 - val_loss: 1.6411 - val_accuracy: 0.4437\n",
            "Epoch 587/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.4251 - accuracy: 0.8396 - val_loss: 1.5710 - val_accuracy: 0.4702\n",
            "Epoch 588/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.4010 - accuracy: 0.8500 - val_loss: 1.5734 - val_accuracy: 0.4834\n",
            "Epoch 589/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.3911 - accuracy: 0.8529 - val_loss: 1.6251 - val_accuracy: 0.4437\n",
            "Epoch 590/700\n",
            "85/85 [==============================] - 2s 25ms/step - loss: 0.4036 - accuracy: 0.8470 - val_loss: 1.6303 - val_accuracy: 0.4702\n",
            "Epoch 591/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.3821 - accuracy: 0.8588 - val_loss: 1.6361 - val_accuracy: 0.4636\n",
            "Epoch 592/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.3812 - accuracy: 0.8551 - val_loss: 1.6052 - val_accuracy: 0.4503\n",
            "Epoch 593/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.4065 - accuracy: 0.8381 - val_loss: 1.6179 - val_accuracy: 0.4570\n",
            "Epoch 594/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.3775 - accuracy: 0.8574 - val_loss: 1.6567 - val_accuracy: 0.4570\n",
            "Epoch 595/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.3985 - accuracy: 0.8448 - val_loss: 1.6215 - val_accuracy: 0.4702\n",
            "Epoch 596/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.3948 - accuracy: 0.8485 - val_loss: 1.5925 - val_accuracy: 0.4636\n",
            "Epoch 597/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.4124 - accuracy: 0.8374 - val_loss: 1.5946 - val_accuracy: 0.4503\n",
            "Epoch 598/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.3891 - accuracy: 0.8470 - val_loss: 1.6223 - val_accuracy: 0.4768\n",
            "Epoch 599/700\n",
            "85/85 [==============================] - 2s 25ms/step - loss: 0.3860 - accuracy: 0.8470 - val_loss: 1.6164 - val_accuracy: 0.4305\n",
            "Epoch 600/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.3760 - accuracy: 0.8574 - val_loss: 1.5973 - val_accuracy: 0.4768\n",
            "Epoch 601/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.3888 - accuracy: 0.8477 - val_loss: 1.6322 - val_accuracy: 0.4702\n",
            "Epoch 602/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.3883 - accuracy: 0.8492 - val_loss: 1.6286 - val_accuracy: 0.4702\n",
            "Epoch 603/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.3670 - accuracy: 0.8625 - val_loss: 1.6432 - val_accuracy: 0.4702\n",
            "Epoch 604/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.3932 - accuracy: 0.8433 - val_loss: 1.5966 - val_accuracy: 0.4636\n",
            "Epoch 605/700\n",
            "85/85 [==============================] - 2s 25ms/step - loss: 0.4027 - accuracy: 0.8514 - val_loss: 1.5872 - val_accuracy: 0.4636\n",
            "Epoch 606/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.3928 - accuracy: 0.8507 - val_loss: 1.6168 - val_accuracy: 0.4636\n",
            "Epoch 607/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.3938 - accuracy: 0.8529 - val_loss: 1.5995 - val_accuracy: 0.4768\n",
            "Epoch 608/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.3720 - accuracy: 0.8662 - val_loss: 1.6586 - val_accuracy: 0.4570\n",
            "Epoch 609/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.3733 - accuracy: 0.8603 - val_loss: 1.6185 - val_accuracy: 0.4768\n",
            "Epoch 610/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.3811 - accuracy: 0.8537 - val_loss: 1.6348 - val_accuracy: 0.4305\n",
            "Epoch 611/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.3874 - accuracy: 0.8610 - val_loss: 1.6120 - val_accuracy: 0.4636\n",
            "Epoch 612/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.3787 - accuracy: 0.8662 - val_loss: 1.6315 - val_accuracy: 0.4371\n",
            "Epoch 613/700\n",
            "85/85 [==============================] - 2s 25ms/step - loss: 0.3735 - accuracy: 0.8588 - val_loss: 1.6240 - val_accuracy: 0.4702\n",
            "Epoch 614/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.3771 - accuracy: 0.8477 - val_loss: 1.6356 - val_accuracy: 0.4371\n",
            "Epoch 615/700\n",
            "85/85 [==============================] - 2s 25ms/step - loss: 0.3722 - accuracy: 0.8529 - val_loss: 1.6398 - val_accuracy: 0.4503\n",
            "Epoch 616/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.3760 - accuracy: 0.8551 - val_loss: 1.6356 - val_accuracy: 0.4834\n",
            "Epoch 617/700\n",
            "85/85 [==============================] - 2s 26ms/step - loss: 0.3663 - accuracy: 0.8625 - val_loss: 1.7097 - val_accuracy: 0.4702\n",
            "Epoch 618/700\n",
            "85/85 [==============================] - 2s 25ms/step - loss: 0.3655 - accuracy: 0.8610 - val_loss: 1.6281 - val_accuracy: 0.4768\n",
            "Epoch 619/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.3795 - accuracy: 0.8492 - val_loss: 1.6192 - val_accuracy: 0.4834\n",
            "Epoch 620/700\n",
            "85/85 [==============================] - 2s 25ms/step - loss: 0.3540 - accuracy: 0.8655 - val_loss: 1.6563 - val_accuracy: 0.4305\n",
            "Epoch 621/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.3613 - accuracy: 0.8618 - val_loss: 1.7469 - val_accuracy: 0.3907\n",
            "Epoch 622/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.3875 - accuracy: 0.8514 - val_loss: 1.6183 - val_accuracy: 0.4768\n",
            "Epoch 623/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.3973 - accuracy: 0.8389 - val_loss: 1.6173 - val_accuracy: 0.4768\n",
            "Epoch 624/700\n",
            "85/85 [==============================] - 2s 25ms/step - loss: 0.3683 - accuracy: 0.8492 - val_loss: 1.6149 - val_accuracy: 0.4636\n",
            "Epoch 625/700\n",
            "85/85 [==============================] - 2s 25ms/step - loss: 0.3829 - accuracy: 0.8537 - val_loss: 1.6255 - val_accuracy: 0.4305\n",
            "Epoch 626/700\n",
            "85/85 [==============================] - 2s 25ms/step - loss: 0.3831 - accuracy: 0.8603 - val_loss: 1.6480 - val_accuracy: 0.4172\n",
            "Epoch 627/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.3696 - accuracy: 0.8618 - val_loss: 1.6559 - val_accuracy: 0.4371\n",
            "Epoch 628/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.3751 - accuracy: 0.8544 - val_loss: 1.6193 - val_accuracy: 0.4636\n",
            "Epoch 629/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.3464 - accuracy: 0.8662 - val_loss: 1.6457 - val_accuracy: 0.4503\n",
            "Epoch 630/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.3472 - accuracy: 0.8766 - val_loss: 1.6595 - val_accuracy: 0.4437\n",
            "Epoch 631/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.3656 - accuracy: 0.8492 - val_loss: 1.6228 - val_accuracy: 0.4371\n",
            "Epoch 632/700\n",
            "85/85 [==============================] - 2s 25ms/step - loss: 0.3700 - accuracy: 0.8574 - val_loss: 1.6496 - val_accuracy: 0.4702\n",
            "Epoch 633/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.3733 - accuracy: 0.8574 - val_loss: 1.6953 - val_accuracy: 0.4437\n",
            "Epoch 634/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.3672 - accuracy: 0.8603 - val_loss: 1.6854 - val_accuracy: 0.4371\n",
            "Epoch 635/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.3418 - accuracy: 0.8625 - val_loss: 1.6949 - val_accuracy: 0.4503\n",
            "Epoch 636/700\n",
            "85/85 [==============================] - 2s 26ms/step - loss: 0.3603 - accuracy: 0.8544 - val_loss: 1.7281 - val_accuracy: 0.4768\n",
            "Epoch 637/700\n",
            "85/85 [==============================] - 2s 25ms/step - loss: 0.3471 - accuracy: 0.8773 - val_loss: 1.7121 - val_accuracy: 0.4371\n",
            "Epoch 638/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.3799 - accuracy: 0.8537 - val_loss: 1.6796 - val_accuracy: 0.4503\n",
            "Epoch 639/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.3582 - accuracy: 0.8670 - val_loss: 1.6478 - val_accuracy: 0.4702\n",
            "Epoch 640/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.3707 - accuracy: 0.8574 - val_loss: 1.7186 - val_accuracy: 0.4437\n",
            "Epoch 641/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.3660 - accuracy: 0.8662 - val_loss: 1.6842 - val_accuracy: 0.4834\n",
            "Epoch 642/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.3581 - accuracy: 0.8670 - val_loss: 1.6534 - val_accuracy: 0.4834\n",
            "Epoch 643/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.3716 - accuracy: 0.8566 - val_loss: 1.7011 - val_accuracy: 0.4570\n",
            "Epoch 644/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.3585 - accuracy: 0.8640 - val_loss: 1.6789 - val_accuracy: 0.4503\n",
            "Epoch 645/700\n",
            "85/85 [==============================] - 2s 25ms/step - loss: 0.3757 - accuracy: 0.8574 - val_loss: 1.6486 - val_accuracy: 0.4636\n",
            "Epoch 646/700\n",
            "85/85 [==============================] - 2s 25ms/step - loss: 0.3853 - accuracy: 0.8485 - val_loss: 1.6565 - val_accuracy: 0.4570\n",
            "Epoch 647/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.3611 - accuracy: 0.8500 - val_loss: 1.6815 - val_accuracy: 0.4901\n",
            "Epoch 648/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.3549 - accuracy: 0.8714 - val_loss: 1.7436 - val_accuracy: 0.4106\n",
            "Epoch 649/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.3558 - accuracy: 0.8640 - val_loss: 1.6972 - val_accuracy: 0.4702\n",
            "Epoch 650/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.3569 - accuracy: 0.8677 - val_loss: 1.6553 - val_accuracy: 0.4371\n",
            "Epoch 651/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.3623 - accuracy: 0.8618 - val_loss: 1.6804 - val_accuracy: 0.4437\n",
            "Epoch 652/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.3536 - accuracy: 0.8647 - val_loss: 1.6699 - val_accuracy: 0.4636\n",
            "Epoch 653/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.3540 - accuracy: 0.8721 - val_loss: 1.6474 - val_accuracy: 0.4437\n",
            "Epoch 654/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.3559 - accuracy: 0.8677 - val_loss: 1.6805 - val_accuracy: 0.4238\n",
            "Epoch 655/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.3664 - accuracy: 0.8640 - val_loss: 1.6890 - val_accuracy: 0.4636\n",
            "Epoch 656/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.3458 - accuracy: 0.8677 - val_loss: 1.6602 - val_accuracy: 0.4570\n",
            "Epoch 657/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.3465 - accuracy: 0.8662 - val_loss: 1.6715 - val_accuracy: 0.4172\n",
            "Epoch 658/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.3584 - accuracy: 0.8610 - val_loss: 1.6591 - val_accuracy: 0.4636\n",
            "Epoch 659/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.3545 - accuracy: 0.8603 - val_loss: 1.6750 - val_accuracy: 0.4503\n",
            "Epoch 660/700\n",
            "85/85 [==============================] - 2s 25ms/step - loss: 0.3723 - accuracy: 0.8559 - val_loss: 1.6796 - val_accuracy: 0.4901\n",
            "Epoch 661/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.3314 - accuracy: 0.8847 - val_loss: 1.6800 - val_accuracy: 0.4901\n",
            "Epoch 662/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.3527 - accuracy: 0.8492 - val_loss: 1.6667 - val_accuracy: 0.4834\n",
            "Epoch 663/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.3672 - accuracy: 0.8610 - val_loss: 1.6367 - val_accuracy: 0.4305\n",
            "Epoch 664/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.3571 - accuracy: 0.8603 - val_loss: 1.7224 - val_accuracy: 0.3907\n",
            "Epoch 665/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.3558 - accuracy: 0.8699 - val_loss: 1.6586 - val_accuracy: 0.4503\n",
            "Epoch 666/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.3603 - accuracy: 0.8670 - val_loss: 1.7399 - val_accuracy: 0.4702\n",
            "Epoch 667/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.3538 - accuracy: 0.8588 - val_loss: 1.7076 - val_accuracy: 0.4702\n",
            "Epoch 668/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.3515 - accuracy: 0.8618 - val_loss: 1.6526 - val_accuracy: 0.4570\n",
            "Epoch 669/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.3714 - accuracy: 0.8566 - val_loss: 1.6986 - val_accuracy: 0.4636\n",
            "Epoch 670/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.3335 - accuracy: 0.8921 - val_loss: 1.7283 - val_accuracy: 0.4371\n",
            "Epoch 671/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.3325 - accuracy: 0.8714 - val_loss: 1.6540 - val_accuracy: 0.4636\n",
            "Epoch 672/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.3389 - accuracy: 0.8692 - val_loss: 1.6613 - val_accuracy: 0.4636\n",
            "Epoch 673/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.3468 - accuracy: 0.8707 - val_loss: 1.7894 - val_accuracy: 0.4305\n",
            "Epoch 674/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.3692 - accuracy: 0.8647 - val_loss: 1.6634 - val_accuracy: 0.5099\n",
            "Epoch 675/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.3423 - accuracy: 0.8736 - val_loss: 1.6852 - val_accuracy: 0.4702\n",
            "Epoch 676/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.3354 - accuracy: 0.8618 - val_loss: 1.6655 - val_accuracy: 0.4768\n",
            "Epoch 677/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.3355 - accuracy: 0.8647 - val_loss: 1.6440 - val_accuracy: 0.4437\n",
            "Epoch 678/700\n",
            "85/85 [==============================] - 2s 28ms/step - loss: 0.3616 - accuracy: 0.8707 - val_loss: 1.7318 - val_accuracy: 0.4238\n",
            "Epoch 679/700\n",
            "85/85 [==============================] - 2s 27ms/step - loss: 0.3456 - accuracy: 0.8707 - val_loss: 1.6761 - val_accuracy: 0.4967\n",
            "Epoch 680/700\n",
            "85/85 [==============================] - 3s 33ms/step - loss: 0.3366 - accuracy: 0.8729 - val_loss: 1.6516 - val_accuracy: 0.4503\n",
            "Epoch 681/700\n",
            "85/85 [==============================] - 3s 34ms/step - loss: 0.3535 - accuracy: 0.8662 - val_loss: 1.7999 - val_accuracy: 0.4570\n",
            "Epoch 682/700\n",
            "85/85 [==============================] - 2s 25ms/step - loss: 0.3567 - accuracy: 0.8581 - val_loss: 1.7189 - val_accuracy: 0.4901\n",
            "Epoch 683/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.3296 - accuracy: 0.8721 - val_loss: 1.6638 - val_accuracy: 0.4371\n",
            "Epoch 684/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.3489 - accuracy: 0.8670 - val_loss: 1.6595 - val_accuracy: 0.4371\n",
            "Epoch 685/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.3413 - accuracy: 0.8729 - val_loss: 1.6823 - val_accuracy: 0.4305\n",
            "Epoch 686/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.3273 - accuracy: 0.8736 - val_loss: 1.7506 - val_accuracy: 0.4702\n",
            "Epoch 687/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.3473 - accuracy: 0.8684 - val_loss: 1.7313 - val_accuracy: 0.4702\n",
            "Epoch 688/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.3217 - accuracy: 0.8862 - val_loss: 1.7313 - val_accuracy: 0.4570\n",
            "Epoch 689/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.3152 - accuracy: 0.8840 - val_loss: 1.6992 - val_accuracy: 0.4570\n",
            "Epoch 690/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.3289 - accuracy: 0.8714 - val_loss: 1.7306 - val_accuracy: 0.4834\n",
            "Epoch 691/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.3314 - accuracy: 0.8817 - val_loss: 1.7103 - val_accuracy: 0.4305\n",
            "Epoch 692/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.3390 - accuracy: 0.8714 - val_loss: 1.6786 - val_accuracy: 0.4371\n",
            "Epoch 693/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.3343 - accuracy: 0.8707 - val_loss: 1.8712 - val_accuracy: 0.4305\n",
            "Epoch 694/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.3278 - accuracy: 0.8869 - val_loss: 1.6680 - val_accuracy: 0.4570\n",
            "Epoch 695/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.3132 - accuracy: 0.8780 - val_loss: 1.6681 - val_accuracy: 0.4702\n",
            "Epoch 696/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.3306 - accuracy: 0.8810 - val_loss: 1.7189 - val_accuracy: 0.4172\n",
            "Epoch 697/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.3322 - accuracy: 0.8677 - val_loss: 1.7351 - val_accuracy: 0.4570\n",
            "Epoch 698/700\n",
            "85/85 [==============================] - 2s 23ms/step - loss: 0.3290 - accuracy: 0.8744 - val_loss: 1.7044 - val_accuracy: 0.4371\n",
            "Epoch 699/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.3191 - accuracy: 0.8840 - val_loss: 1.7306 - val_accuracy: 0.4901\n",
            "Epoch 700/700\n",
            "85/85 [==============================] - 2s 24ms/step - loss: 0.3346 - accuracy: 0.8773 - val_loss: 1.7117 - val_accuracy: 0.4371\n",
            "0.7153669102064201\n",
            "accuracy: 69.95%\n",
            "72.93% (+/- 2.61%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ava_acc=np.mean(cnnhistory.history['accuracy']) # numpy assumed imported as np\n",
        "print(ava_acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fu7omyRcaIN3",
        "outputId": "5f6f97cd-fd2e-4202-86df-50bf0ed9c337"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8936165570787021\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(cnnhistory.history['loss'])\n",
        "plt.plot(cnnhistory.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "oQYnuaCrDH_A",
        "outputId": "fd9d502e-5c33-461a-e327-963d3ed7ee28"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(cnnhistory.history['accuracy'])\n",
        "plt.plot(cnnhistory.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "IFkTuO8nDNdq",
        "outputId": "567f4876-4c85-4dc0-c40c-64b36fdeecd6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#predictions = model.predict_classes(x_testcnn)\n",
        "predictions = model.predict(x_testcnn)"
      ],
      "metadata": {
        "id": "A2xtrN5wDQgY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_f_ohjXKDUpY",
        "outputId": "5dd207ea-7c3b-413d-daac-f26ef6f6c7bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[5.8954419e-04, 5.2011558e-07, 2.3172747e-01, 5.4548010e-02,\n",
              "        6.9494975e-01, 1.8184707e-02],\n",
              "       [6.5438284e-12, 9.3360676e-14, 4.0685965e-21, 9.7244400e-01,\n",
              "        4.6549173e-14, 2.7556021e-02],\n",
              "       [1.0044174e-04, 9.3480012e-06, 2.6996657e-02, 2.0732565e-03,\n",
              "        9.6545726e-01, 5.3630425e-03],\n",
              "       ...,\n",
              "       [2.5828938e-06, 8.2989679e-14, 8.4370555e-07, 6.0767661e-06,\n",
              "        1.7423108e-07, 9.9999034e-01],\n",
              "       [2.2398493e-05, 5.7506888e-05, 7.0804071e-01, 2.5865963e-01,\n",
              "        3.2247972e-02, 9.7177079e-04],\n",
              "       [8.0075818e-14, 4.2438018e-17, 3.8056860e-10, 7.5423884e-07,\n",
              "        2.7624264e-10, 9.9999928e-01]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cmA2bFgsDW3D",
        "outputId": "a11e4cc4-bd8a-47b1-9cdd-6f6307efb838"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2, 3, 4, 0, 4, 4, 1, 2, 5, 0, 5, 3, 2, 2, 2, 4, 5, 4, 1, 4, 1, 2,\n",
              "       2, 4, 4, 2, 1, 1, 2, 2, 2, 5, 2, 5, 3, 0, 2, 0, 5, 5, 2, 3, 2, 2,\n",
              "       5, 1, 0, 1, 3, 4, 4, 5, 1, 1, 4, 3, 5, 0, 1, 1, 0, 1, 4, 0, 4, 1,\n",
              "       1, 0, 1, 4, 0, 0, 3, 1, 3, 1, 2, 2, 2, 2, 2, 0, 5, 3, 4, 5, 2, 4,\n",
              "       5, 2, 5, 1, 5, 3, 3, 1, 4, 1, 5, 4, 5, 1, 2, 1, 2, 5, 1, 3, 2, 5,\n",
              "       3, 1, 3, 5, 4, 4, 0, 0, 3, 1, 2, 3, 3, 5, 1, 5, 3, 4, 2, 2, 0, 2,\n",
              "       2, 5, 5, 0, 3, 3, 2, 2, 0, 4, 4, 0, 4, 2, 3, 5, 4, 1, 5, 3, 3, 2,\n",
              "       5, 4, 3, 3, 5, 3, 4, 4, 1, 5, 2, 3, 2, 2, 0, 2, 1, 3, 1, 1, 1, 5,\n",
              "       5, 2, 4, 2, 2, 1, 1, 3, 3, 5, 4, 2, 5, 0, 5, 0, 3, 3, 0, 5, 1, 4,\n",
              "       1, 4, 2, 5, 5, 4, 4, 2, 5, 2, 5, 0, 4, 0, 4, 2, 5, 3, 0, 4, 1, 1,\n",
              "       4, 0, 3, 1, 3, 4, 4, 3, 2, 4, 2, 2, 0, 4, 2, 5, 4, 2, 4, 3, 1, 2,\n",
              "       1, 0, 5, 5, 3, 2, 3, 2, 4, 5, 2, 3, 4, 1, 1, 3, 5, 0, 2, 2, 2, 1,\n",
              "       5, 1, 4, 0, 2, 4, 1, 5, 3, 4, 5, 1, 2, 4, 3, 1, 5, 5, 2, 5, 4, 1,\n",
              "       3, 1, 4, 3, 5, 0, 0, 5, 5, 1, 4, 4, 1, 5, 4, 4, 3, 2, 3, 4, 4, 1,\n",
              "       4, 5, 2, 1, 1, 4, 4, 5, 3, 2, 5, 4, 2, 4, 3, 3, 3, 0, 4, 5, 1, 5,\n",
              "       2, 4, 1, 3, 0, 1, 0, 5, 1, 4, 3, 4, 2, 5, 4, 4, 0, 5, 1, 3, 1, 2,\n",
              "       1, 4, 3, 5, 5, 5, 5, 2, 0, 3, 4, 3, 5, 2, 2, 5, 4, 4, 5, 2, 1, 2,\n",
              "       1, 4, 0, 4, 0, 5, 5, 4, 0, 0, 4, 1, 2, 5, 4, 0, 2, 3, 5, 2, 0, 3,\n",
              "       2, 5, 1, 5, 5, 0, 3, 5, 4, 0, 2, 5, 2, 5, 5, 5, 2, 5])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_Ytest = y_test.astype(int)"
      ],
      "metadata": {
        "id": "0PHDKWJWDY3g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_Ytest"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k68v2i-pDbZE",
        "outputId": "48feb987-e88e-4c99-bcfd-2b39d9803102"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2, 3, 4, 0, 4, 4, 1, 2, 5, 0, 5, 3, 2, 2, 2, 4, 5, 4, 1, 4, 1, 2,\n",
              "       2, 4, 4, 2, 1, 1, 2, 2, 2, 5, 2, 5, 3, 0, 2, 0, 5, 5, 2, 3, 2, 2,\n",
              "       5, 1, 0, 1, 3, 4, 4, 5, 1, 1, 4, 3, 5, 0, 1, 1, 0, 1, 4, 0, 4, 1,\n",
              "       1, 0, 1, 4, 0, 0, 3, 1, 3, 1, 2, 2, 2, 2, 2, 0, 5, 3, 4, 5, 2, 4,\n",
              "       5, 2, 5, 1, 5, 3, 3, 1, 4, 1, 5, 4, 5, 1, 2, 1, 2, 5, 1, 3, 2, 5,\n",
              "       3, 1, 3, 5, 4, 4, 0, 0, 3, 1, 2, 3, 3, 5, 1, 5, 3, 4, 2, 2, 0, 2,\n",
              "       2, 5, 5, 0, 3, 3, 2, 2, 0, 4, 4, 0, 4, 2, 3, 5, 4, 1, 5, 3, 3, 2,\n",
              "       5, 4, 3, 3, 5, 3, 4, 4, 1, 5, 2, 3, 2, 2, 0, 2, 1, 3, 1, 1, 1, 5,\n",
              "       5, 2, 4, 2, 2, 1, 1, 3, 3, 5, 4, 2, 5, 0, 5, 0, 3, 3, 0, 5, 1, 4,\n",
              "       1, 4, 2, 5, 5, 4, 4, 2, 5, 2, 5, 0, 4, 0, 4, 2, 5, 3, 0, 4, 1, 1,\n",
              "       4, 0, 3, 1, 3, 4, 4, 3, 2, 4, 2, 2, 0, 4, 2, 5, 4, 2, 4, 3, 1, 2,\n",
              "       1, 0, 5, 5, 3, 2, 3, 2, 4, 5, 2, 3, 4, 1, 1, 3, 5, 0, 2, 2, 2, 1,\n",
              "       5, 1, 4, 0, 2, 4, 1, 5, 3, 4, 5, 1, 2, 4, 3, 1, 5, 5, 2, 5, 4, 1,\n",
              "       3, 1, 4, 3, 5, 0, 0, 5, 5, 1, 4, 4, 1, 5, 4, 4, 3, 2, 3, 4, 4, 1,\n",
              "       4, 5, 2, 1, 1, 4, 4, 5, 3, 2, 5, 4, 2, 4, 3, 3, 3, 0, 4, 5, 1, 5,\n",
              "       2, 4, 1, 3, 0, 1, 0, 5, 1, 4, 3, 4, 2, 5, 4, 4, 0, 5, 1, 3, 1, 2,\n",
              "       1, 4, 3, 5, 5, 5, 5, 2, 0, 3, 4, 3, 5, 2, 2, 5, 4, 4, 5, 2, 1, 2,\n",
              "       1, 4, 0, 4, 0, 5, 5, 4, 0, 0, 4, 1, 2, 5, 4, 0, 2, 3, 5, 2, 0, 3,\n",
              "       2, 5, 1, 5, 5, 0, 3, 5, 4, 0, 2, 5, 2, 5, 5, 5, 2, 5])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def print_confusion_matrix(confusion_matrix, class_names, figsize = (16,16), fontsize=14):\n",
        "    \"\"\"Prints a confusion matrix, as returned by sklearn.metrics.confusion_matrix, as a heatmap.\n",
        "    \n",
        "    Arguments\n",
        "    ---------\n",
        "    confusion_matrix: numpy.ndarray\n",
        "        The numpy.ndarray object returned from a call to sklearn.metrics.confusion_matrix. \n",
        "        Similarly constructed ndarrays can also be used.\n",
        "    class_names: list\n",
        "        An ordered list of class names, in the order they index the given confusion matrix.\n",
        "    figsize: tuple\n",
        "        A 2-long tuple, the first value determining the horizontal size of the ouputted figure,\n",
        "        the second determining the vertical size. Defaults to (10,7).\n",
        "    fontsize: int\n",
        "        Font size for axes labels. Defaults to 14.\n",
        "        \n",
        "    Returns\n",
        "    -------\n",
        "    matplotlib.figure.Figure\n",
        "        The resulting confusion matrix figure\n",
        "    \"\"\"\n",
        "    df_cm = pd.DataFrame(\n",
        "        confusion_matrix, index=class_names, columns=class_names, \n",
        "    )\n",
        "    fig = plt.figure(figsize=figsize)\n",
        "    try:\n",
        "        heatmap = sns.heatmap(df_cm, annot=True, fmt=\"d\")\n",
        "    except ValueError:\n",
        "        raise ValueError(\"Confusion matrix values must be integers.\")\n",
        "        \n",
        "    heatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, ha='right', fontsize=fontsize)\n",
        "    heatmap.xaxis.set_ticklabels(heatmap.xaxis.get_ticklabels(), rotation=45, ha='right', fontsize=fontsize)\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')\n",
        "    "
      ],
      "metadata": {
        "id": "SodJmE6JFVYa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds1=predictions.argmax(axis=1)"
      ],
      "metadata": {
        "id": "VEw0FiZFMcOQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vvyRw0M0NBOb",
        "outputId": "c92b1a6b-2998-4170-e0d7-74cb2c16e92d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2, 3, 4, 1, 4, 4, 1, 2, 5, 1, 5, 3, 1, 2, 2, 5, 1, 4, 1, 2, 1, 2,\n",
              "       2, 4, 4, 2, 1, 1, 2, 2, 2, 5, 2, 5, 3, 3, 2, 0, 2, 5, 2, 3, 1, 2,\n",
              "       3, 1, 0, 1, 5, 4, 4, 5, 1, 1, 4, 3, 5, 1, 0, 1, 3, 1, 4, 1, 4, 1,\n",
              "       1, 0, 3, 4, 0, 0, 3, 1, 1, 1, 2, 2, 2, 2, 2, 0, 5, 3, 4, 5, 2, 3,\n",
              "       3, 2, 5, 1, 5, 3, 3, 1, 3, 1, 3, 4, 5, 1, 2, 1, 2, 5, 1, 3, 2, 5,\n",
              "       3, 0, 3, 5, 4, 4, 3, 0, 3, 1, 2, 1, 3, 5, 3, 5, 3, 3, 2, 2, 1, 3,\n",
              "       2, 3, 5, 0, 5, 3, 2, 4, 0, 4, 4, 1, 4, 2, 5, 5, 4, 1, 5, 3, 3, 2,\n",
              "       5, 4, 3, 3, 5, 5, 4, 4, 1, 5, 2, 5, 2, 1, 0, 2, 1, 3, 1, 3, 1, 3,\n",
              "       5, 2, 4, 2, 2, 1, 1, 5, 3, 5, 4, 2, 5, 1, 2, 1, 3, 3, 0, 5, 1, 4,\n",
              "       1, 3, 2, 5, 5, 2, 4, 2, 5, 2, 5, 0, 4, 1, 4, 2, 3, 2, 3, 4, 1, 1,\n",
              "       4, 1, 3, 1, 5, 4, 4, 3, 2, 4, 2, 2, 0, 4, 2, 5, 4, 2, 4, 3, 3, 2,\n",
              "       2, 1, 5, 5, 3, 5, 3, 2, 4, 5, 4, 2, 4, 1, 1, 3, 1, 0, 2, 2, 2, 1,\n",
              "       5, 1, 4, 0, 5, 5, 1, 3, 3, 4, 5, 1, 2, 4, 5, 1, 5, 5, 2, 3, 4, 0,\n",
              "       1, 1, 4, 5, 5, 3, 0, 5, 5, 1, 2, 3, 2, 5, 4, 4, 3, 2, 5, 2, 4, 1,\n",
              "       4, 5, 2, 1, 1, 4, 4, 5, 3, 2, 5, 4, 1, 4, 3, 3, 3, 3, 4, 2, 1, 2,\n",
              "       2, 4, 1, 3, 0, 1, 1, 5, 1, 4, 3, 4, 2, 5, 4, 2, 1, 5, 2, 3, 1, 2,\n",
              "       1, 4, 3, 1, 3, 5, 4, 2, 1, 2, 4, 3, 2, 2, 5, 5, 4, 3, 5, 2, 1, 2,\n",
              "       1, 4, 0, 4, 0, 5, 5, 4, 0, 0, 4, 1, 5, 5, 4, 0, 2, 5, 5, 2, 3, 3,\n",
              "       2, 5, 1, 5, 5, 0, 5, 1, 5, 3, 2, 5, 2, 5, 5, 5, 2, 5])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "abc = preds1.astype(int).flatten()"
      ],
      "metadata": {
        "id": "H4WEmM60NfQn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "c = confusion_matrix(new_Ytest, abc) \n",
        "c"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bKEBeEBlFjB8",
        "outputId": "05bced8d-2fe2-4581-999e-59429ec0eb60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[23, 14,  0,  8,  0,  0],\n",
              "       [ 3, 56,  3,  4,  0,  0],\n",
              "       [ 0,  4, 70,  1,  2,  4],\n",
              "       [ 0,  3,  3, 42,  0, 12],\n",
              "       [ 0,  0,  5,  6, 65,  3],\n",
              "       [ 0,  4,  5,  9,  1, 64]])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m4RjG7LWLSQx",
        "outputId": "7c75d6a4-df2b-4618-8deb-33117fcbb4a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2, 3, 4, 0, 4, 4, 1, 2, 5, 0, 5, 3, 2, 2, 2, 4, 5, 4, 1, 4, 1, 2,\n",
              "       2, 4, 4, 2, 1, 1, 2, 2, 2, 5, 2, 5, 3, 0, 2, 0, 5, 5, 2, 3, 2, 2,\n",
              "       5, 1, 0, 1, 3, 4, 4, 5, 1, 1, 4, 3, 5, 0, 1, 1, 0, 1, 4, 0, 4, 1,\n",
              "       1, 0, 1, 4, 0, 0, 3, 1, 3, 1, 2, 2, 2, 2, 2, 0, 5, 3, 4, 5, 2, 4,\n",
              "       5, 2, 5, 1, 5, 3, 3, 1, 4, 1, 5, 4, 5, 1, 2, 1, 2, 5, 1, 3, 2, 5,\n",
              "       3, 1, 3, 5, 4, 4, 0, 0, 3, 1, 2, 3, 3, 5, 1, 5, 3, 4, 2, 2, 0, 2,\n",
              "       2, 5, 5, 0, 3, 3, 2, 2, 0, 4, 4, 0, 4, 2, 3, 5, 4, 1, 5, 3, 3, 2,\n",
              "       5, 4, 3, 3, 5, 3, 4, 4, 1, 5, 2, 3, 2, 2, 0, 2, 1, 3, 1, 1, 1, 5,\n",
              "       5, 2, 4, 2, 2, 1, 1, 3, 3, 5, 4, 2, 5, 0, 5, 0, 3, 3, 0, 5, 1, 4,\n",
              "       1, 4, 2, 5, 5, 4, 4, 2, 5, 2, 5, 0, 4, 0, 4, 2, 5, 3, 0, 4, 1, 1,\n",
              "       4, 0, 3, 1, 3, 4, 4, 3, 2, 4, 2, 2, 0, 4, 2, 5, 4, 2, 4, 3, 1, 2,\n",
              "       1, 0, 5, 5, 3, 2, 3, 2, 4, 5, 2, 3, 4, 1, 1, 3, 5, 0, 2, 2, 2, 1,\n",
              "       5, 1, 4, 0, 2, 4, 1, 5, 3, 4, 5, 1, 2, 4, 3, 1, 5, 5, 2, 5, 4, 1,\n",
              "       3, 1, 4, 3, 5, 0, 0, 5, 5, 1, 4, 4, 1, 5, 4, 4, 3, 2, 3, 4, 4, 1,\n",
              "       4, 5, 2, 1, 1, 4, 4, 5, 3, 2, 5, 4, 2, 4, 3, 3, 3, 0, 4, 5, 1, 5,\n",
              "       2, 4, 1, 3, 0, 1, 0, 5, 1, 4, 3, 4, 2, 5, 4, 4, 0, 5, 1, 3, 1, 2,\n",
              "       1, 4, 3, 5, 5, 5, 5, 2, 0, 3, 4, 3, 5, 2, 2, 5, 4, 4, 5, 2, 1, 2,\n",
              "       1, 4, 0, 4, 0, 5, 5, 4, 0, 0, 4, 1, 2, 5, 4, 0, 2, 3, 5, 2, 0, 3,\n",
              "       2, 5, 1, 5, 5, 0, 3, 5, 4, 0, 2, 5, 2, 5, 5, 5, 2, 5])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize Confusion Matrix \n",
        "\n",
        "# class_names = ['male_angry', 'male_calm', 'male_fearful', 'male_happy', 'male_sad']\n",
        "# class_names = ['female_angry', 'female_calm', 'female_fearful', 'female_happy', 'female_sad']\n",
        "# class_names = ['male_negative', 'male_neutral', 'male_positive']\n",
        "#class_names = ['male_negative', 'male_positive']\n",
        "#class_names = ['female_angry', 'female_calm', 'female_fearful', 'female_happy', 'female_sad', 'female_surprised', 'female_disgust', 'female_neutral',\n",
        "               #'male_angry', 'male_calm', 'male_fearful', 'male_happy', 'male_sad' , 'male_surprised', 'male_disgust' , 'male_neutral']\n",
        "class_names = ['angry', 'calm', 'fearful', 'happy', 'sad', 'neutral']\n",
        "\n",
        "print_confusion_matrix(c, class_names)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 971
        },
        "id": "_DZVApN-FkHF",
        "outputId": "9dc44783-502f-484a-d99e-9eeff6cd8d73"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1152x1152 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('/content/drive/My Drive/models/CNN_2/last/model/model_speech_7')\n",
        "print(\"MODEL SAVED\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lsJBNeMWDl6Z",
        "outputId": "d99bfd3f-986f-4238-95b3-bb2e75c614b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/models/CNN_2/last/model/model_speech_7/assets\n",
            "MODEL SAVED\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_model=keras.models.load_model('/content/drive/My Drive/models/CNN_2/last/model/model_speech&song6_1')\n",
        "new_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q3KjaO9GDoNl",
        "outputId": "994b09dc-6ff4-4579-fddc-6306758f2168"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d_9 (Conv1D)           (None, 40, 64)            384       \n",
            "                                                                 \n",
            " activation_12 (Activation)  (None, 40, 64)            0         \n",
            "                                                                 \n",
            " dropout_9 (Dropout)         (None, 40, 64)            0         \n",
            "                                                                 \n",
            " max_pooling1d_6 (MaxPooling  (None, 10, 64)           0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " conv1d_10 (Conv1D)          (None, 10, 128)           41088     \n",
            "                                                                 \n",
            " activation_13 (Activation)  (None, 10, 128)           0         \n",
            "                                                                 \n",
            " dropout_10 (Dropout)        (None, 10, 128)           0         \n",
            "                                                                 \n",
            " max_pooling1d_7 (MaxPooling  (None, 2, 128)           0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " conv1d_11 (Conv1D)          (None, 2, 256)            164096    \n",
            "                                                                 \n",
            " activation_14 (Activation)  (None, 2, 256)            0         \n",
            "                                                                 \n",
            " dropout_11 (Dropout)        (None, 2, 256)            0         \n",
            "                                                                 \n",
            " flatten_3 (Flatten)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 8)                 4104      \n",
            "                                                                 \n",
            " activation_15 (Activation)  (None, 8)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 209,672\n",
            "Trainable params: 209,672\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = new_model.predict(x_testcnn)"
      ],
      "metadata": {
        "id": "WOKeSzc7T-MZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3RjQxa2RUBKQ",
        "outputId": "50b0119d-06ab-4a1f-ec14-ed45aa3b7905"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[9.90926765e-07, 8.24685048e-06, 9.45171297e-01, ...,\n",
              "        5.02207440e-05, 5.91571103e-09, 4.45482184e-09],\n",
              "       [5.84147124e-14, 1.03004542e-17, 4.74156901e-22, ...,\n",
              "        2.90453993e-03, 1.40868666e-21, 3.20066754e-21],\n",
              "       [2.67187943e-06, 7.45312445e-06, 9.99079552e-03, ...,\n",
              "        1.58779134e-04, 5.94584471e-08, 6.08139246e-08],\n",
              "       ...,\n",
              "       [2.72450400e-08, 3.45891537e-15, 1.00950345e-07, ...,\n",
              "        9.99999762e-01, 2.37056411e-16, 1.85730248e-15],\n",
              "       [5.54369883e-11, 2.03350559e-03, 9.84517157e-01, ...,\n",
              "        1.33372694e-02, 4.39406983e-10, 3.84911741e-10],\n",
              "       [1.14576344e-13, 2.55129555e-12, 4.90378360e-09, ...,\n",
              "        1.00000000e+00, 3.07732321e-14, 9.00190160e-14]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss, acc = new_model.evaluate(x_testcnn, y_test)\n",
        "print(\"Restored model, accuracy: {:5.2f}%\".format(100*acc))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n3kzoqPkDqqS",
        "outputId": "52097db3-4310-48b0-e526-9a1494c6852a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "13/13 [==============================] - 0s 4ms/step - loss: 1.1815 - accuracy: 0.7729\n",
            "Restored model, accuracy: 77.29%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix,accuracy_score\n",
        "import seaborn as sn\n",
        "\n",
        "print(classification_report(y_test,abc))\n",
        "\n",
        "acc = float(accuracy_score(y_test,abc))*100\n",
        "print(\"----accuracy score %s ----\" % acc)\n",
        "\n",
        "cm = confusion_matrix(y_test,abc)\n",
        "#df_cm = pd.DataFrame(cm)\n",
        "class_names = ['neutral', 'calm', 'happy','sad','angry', 'fearful' ]\n",
        "df_cm = pd.DataFrame(cm, index=class_names, columns=class_names,)\n",
        "sn.heatmap(df_cm, annot=True, fmt='')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Yx8ogGOnNneV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 512
        },
        "outputId": "d06ca8f4-7f20-4639-b7a5-56badf8f329c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.51      0.65        45\n",
            "           1       0.69      0.85      0.76        66\n",
            "           2       0.81      0.86      0.84        81\n",
            "           3       0.60      0.70      0.65        60\n",
            "           4       0.96      0.82      0.88        79\n",
            "           5       0.77      0.77      0.77        83\n",
            "\n",
            "    accuracy                           0.77       414\n",
            "   macro avg       0.79      0.75      0.76       414\n",
            "weighted avg       0.79      0.77      0.77       414\n",
            "\n",
            "----accuracy score 77.29468599033817 ----\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "fJDTGH_OUX0z"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}