{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "original RMS lr=0.0001 try3.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9SRCO-a_AlH5",
        "outputId": "eb7323e5-be7d-45bb-9b92-757fbbd7d6c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install librosa"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oi8pWV3yBVjO",
        "outputId": "4b33d636-a7a3-41eb-fb53-c70c911e25e4"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.7/dist-packages (0.8.1)\n",
            "Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.6.0)\n",
            "Requirement already satisfied: resampy>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from librosa) (0.2.2)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.21.6)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.4.1)\n",
            "Requirement already satisfied: soundfile>=0.10.2 in /usr/local/lib/python3.7/dist-packages (from librosa) (0.10.3.post1)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.1.0)\n",
            "Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.0.2)\n",
            "Requirement already satisfied: numba>=0.43.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (0.51.2)\n",
            "Requirement already satisfied: decorator>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied: audioread>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (2.1.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (21.3)\n",
            "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba>=0.43.0->librosa) (0.34.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba>=0.43.0->librosa) (57.4.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->librosa) (3.0.9)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from pooch>=1.0->librosa) (2.23.0)\n",
            "Requirement already satisfied: appdirs>=1.3.0 in /usr/local/lib/python3.7/dist-packages (from pooch>=1.0->librosa) (1.4.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2022.5.18.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (1.24.3)\n",
            "Requirement already satisfied: six>=1.3 in /usr/local/lib/python3.7/dist-packages (from resampy>=0.2.2->librosa) (1.15.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn!=0.19.0,>=0.14.0->librosa) (3.1.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.7/dist-packages (from soundfile>=0.10.2->librosa) (1.15.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.0->soundfile>=0.10.2->librosa) (2.21)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HJjcbxwy46bG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "911ebe9b-697c-41d3-d181-95c206342d18"
      },
      "source": [
        "# Orignial Notebook: https://github.com/MITESHPUTHRANNEU/Speech-Emotion-Analyzer/blob/master/final_results_gender_test.ipynb\n",
        "# This notebook author: Reza Chu\n",
        "# Last Editing Date: 31st May 2019\n",
        "\n",
        "## Python\n",
        "import os\n",
        "import random\n",
        "import sys\n",
        "\n",
        "import IPython\n",
        "from IPython.display import Audio\n",
        "from IPython.display import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "## Package\n",
        "import glob \n",
        "import keras\n",
        "import IPython.display as ipd\n",
        "import librosa\n",
        "import librosa.display\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import plotly.graph_objs as go\n",
        "import plotly.offline as py\n",
        "import plotly.tools as tls\n",
        "import seaborn as sns\n",
        "import scipy.io.wavfile\n",
        "import tensorflow as tf\n",
        "py.init_notebook_mode(connected=True)\n",
        "\n",
        "## Keras\n",
        "from keras import regularizers\n",
        "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping\n",
        "from keras.callbacks import  History, ReduceLROnPlateau, CSVLogger\n",
        "from keras.models import Model, Sequential\n",
        "from keras.layers import Dense, Embedding, LSTM\n",
        "from keras.layers import Input, Flatten, Dropout, Activation, BatchNormalization\n",
        "from keras.layers import Conv1D, MaxPooling1D, AveragePooling1D\n",
        "from keras.preprocessing import sequence\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.utils import np_utils\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "## Sklearn\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "## Rest\n",
        "from scipy.fftpack import fft\n",
        "from scipy import signal\n",
        "from scipy.io import wavfile\n",
        "from tqdm import tqdm\n",
        "\n",
        "input_duration=3\n",
        "# % pylab inline"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "        <script type=\"text/javascript\">\n",
              "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
              "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
              "        if (typeof require !== 'undefined') {\n",
              "        require.undef(\"plotly\");\n",
              "        requirejs.config({\n",
              "            paths: {\n",
              "                'plotly': ['https://cdn.plot.ly/plotly-2.8.3.min']\n",
              "            }\n",
              "        });\n",
              "        require(['plotly'], function(Plotly) {\n",
              "            window._Plotly = Plotly;\n",
              "        });\n",
              "        }\n",
              "        </script>\n",
              "        "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#radvass speech and song\n",
        "import time\n",
        "import os\n",
        "import librosa\n",
        "from librosa import display\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "count=0\n",
        "path1 = '/content/drive/MyDrive/RAVDESS_speech'\n",
        "path2 = '/content/drive/MyDrive/RAVDESS_song'\n",
        "\n",
        "lst = []\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "for subdir, dirs, files in os.walk(path2):\n",
        "  print(dirs)\n",
        "  print(subdir)\n",
        "  #print(files)\n",
        "  for file in files:\n",
        "      try:\n",
        "        count +=1\n",
        "        #Load librosa array, obtain mfcss, store the file and the mcss information in a new array\n",
        "        X, sample_rate = librosa.load(os.path.join(subdir,file), res_type='kaiser_fast')\n",
        "        mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T,axis=0) \n",
        "        # The instruction below converts the labels (from 1 to 8) to a series from 0 to 7\n",
        "        # This is because our predictor needs to start from 0 otherwise it will try to predict also 0.\n",
        "        file = int(file[7:8]) - 1 \n",
        "        arr = mfccs, file\n",
        "        lst.append(arr)\n",
        "      # If the file is not valid, skip it\n",
        "      except ValueError:\n",
        "        continue\n",
        "\n",
        "for subdir, dirs, files in os.walk(path1):\n",
        "  print(dirs)\n",
        "  print(subdir)\n",
        " # print(files)\n",
        "  for file in files:\n",
        "      try:\n",
        "        #Load librosa array, obtain mfcss, store the file and the mcss information in a new array\n",
        "        X, sample_rate = librosa.load(os.path.join(subdir,file), res_type='kaiser_fast')\n",
        "        mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T,axis=0) \n",
        "        # The instruction below converts the labels (from 1 to 8) to a series from 0 to 7\n",
        "        # This is because our predictor needs to start from 0 otherwise it will try to predict also 0.\n",
        "        file = int(file[7:8]) - 1 \n",
        "        if(file ==6 or file==7):\n",
        "          continue\n",
        "        count +=1\n",
        "        arr = mfccs, file\n",
        "        lst.append(arr)\n",
        "      # If the file is not valid, skip it\n",
        "      except ValueError:\n",
        "        continue\n",
        "\n",
        "\n",
        "\n",
        "print(\"--- Data loaded. Loading time: %s seconds ---\" % (time.time() - start_time))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IfuyRZl42ccZ",
        "outputId": "6f8b60b4-6ca8-4822-a52a-f8d94d899326"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Actor_10', 'Actor_11', 'Actor_13', 'Actor_12', 'Actor_14', 'Actor_15', 'Actor_16', 'Actor_17', 'Actor_18', 'Actor_19', 'Actor_21', 'Actor_22', 'Actor_23', 'Actor_09', 'Actor_24', 'Actor_04', 'Actor_08', 'Actor_03', 'Actor_02', 'Actor_06', 'Actor_05', 'Actor_01', 'Actor_07', 'Actor_20']\n",
            "/content/drive/MyDrive/RAVDESS_song\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_10\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_11\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_13\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_12\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_14\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_15\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_16\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_17\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_18\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_19\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_21\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_22\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_23\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_09\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_24\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_04\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_08\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_03\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_02\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_06\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_05\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_01\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_07\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_20\n",
            "['Actor_05', 'Actor_08', 'Actor_10', 'Actor_04', 'Actor_09', 'Actor_14', 'Actor_12', 'Actor_13', 'Actor_11', 'Actor_06', 'Actor_24', 'Actor_07', 'Actor_23', 'Actor_22', 'Actor_21', 'Actor_20', 'Actor_02', 'Actor_19', 'Actor_18', 'Actor_17', 'Actor_16', 'Actor_15', 'Actor_03', 'Actor_01']\n",
            "/content/drive/MyDrive/RAVDESS_speech\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_05\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_08\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_10\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_04\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_09\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_14\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_12\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_13\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_11\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_06\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_24\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_07\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_23\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_22\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_21\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_20\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_02\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_19\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_18\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_17\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_16\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_15\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_03\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_01\n",
            "--- Data loaded. Loading time: 214.0721356868744 seconds ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "count"
      ],
      "metadata": {
        "id": "Ltlhi25L2AI5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c58a310b-9e6a-40bf-e739-24699ed438d6"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2068"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy.core.fromnumeric import size\n",
        "size(lst)"
      ],
      "metadata": {
        "id": "HMOH7d7mzHB7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b6084c8-6abf-43a4-f345-4b55350e605e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/core/fromnumeric.py:3208: VisibleDeprecationWarning:\n",
            "\n",
            "Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4136"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating X and y: zip makes a list of all the first elements, and a list of all the second elements.\n",
        "X, y = zip(*lst)"
      ],
      "metadata": {
        "id": "ocdL7tSTBoMt"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "X = np.asarray(X)\n",
        "y = np.asarray(y)\n",
        "X.shape, y.shape"
      ],
      "metadata": {
        "id": "vHKwUGTbBtnF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e533ef21-a9da-43b9-f1d8-a1abdf1fbde0"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((2068, 40), (2068,))"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "id": "2sUCtbfMztE5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96d0e01b-f74b-4145-fe90-85a6e4cc631f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2068, 40)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Saving joblib files to not load them again with the loop above\n",
        "\n",
        "# import joblib\n",
        "\n",
        "# X_name = 'x.joblib'\n",
        "# y_name = 'y.joblib'\n",
        "# save_dir = '/content/drive/My Drive/graduation project/audio/paper_code/features'\n",
        "\n",
        "# savedX = joblib.dump(X, os.path.join(save_dir, X_name))\n",
        "# savedy = joblib.dump(y, os.path.join(save_dir, y_name))"
      ],
      "metadata": {
        "id": "UCzic8rlDcuk"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Loading saved models\n",
        "# import joblib\n",
        "# X = joblib.load('/content/drive/My Drive/graduation project/audio/paper_code/features/x.joblib')\n",
        "# y = joblib.load('/content/drive/My Drive/graduation project/audio/paper_code/features/y.joblib')"
      ],
      "metadata": {
        "id": "Q35CN6zDrzg1"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7PSTurzjCo5K",
        "outputId": "e809c130-aa85-486a-a959-bc0533047b4b"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2068, 40)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2,train_size=0.8, random_state=42)\n",
        "X_valid, X_test, y_valid, y_test = train_test_split(X_test,y_test, test_size=0.5,train_size=0.5, random_state=42)"
      ],
      "metadata": {
        "id": "Ai4Fy5cPCiq1"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "x_traincnn = np.expand_dims(X_train, axis=2)\n",
        "x_testcnn = np.expand_dims(X_test, axis=2)\n",
        "X_valid= np.expand_dims(X_valid, axis=2)"
      ],
      "metadata": {
        "id": "tp1Fm5K3CEXu"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_traincnn.shape, x_testcnn.shape , X_valid.shape"
      ],
      "metadata": {
        "id": "RI0MxoIPBws5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c82e9d0-c56e-44b8-8876-38e5dde3d5c1"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1654, 40, 1), (207, 40, 1), (207, 40, 1))"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow"
      ],
      "metadata": {
        "id": "goxL4Y3jKICC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d4568d7-fbff-43c4-fdd7-c31a5c977777"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (2.8.2+zzzcolab20220527125636)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (14.0.1)\n",
            "Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.26.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow) (57.4.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (4.2.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.46.3)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.0.0)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.21.6)\n",
            "Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.5.3)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.17.3)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow) (1.5.2)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.35.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.8.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.23.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.6.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (3.3.7)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.4.6)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.8)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.2.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (4.11.4)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (3.8.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2022.5.18.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (3.2.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keras"
      ],
      "metadata": {
        "id": "EkcmN9UrKSxj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2af49ede-c053-467f-81a5-85e6e71ae8b6"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.7/dist-packages (2.8.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from keras.preprocessing import sequence\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from keras.layers import Input, Flatten, Dropout, Activation\n",
        "from keras.layers import Conv1D, MaxPooling1D\n",
        "from keras.models import Model\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras import optimizers\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv1D(128, 8,padding='same', #classifier.add(Convolution2D(64, (3, 3), padding = 'same', input_shape = (128, 128, 3), activation = 'relu'))\n",
        "                 input_shape=(40,1)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(MaxPooling1D(pool_size=(5)))\n",
        "\n",
        "\n",
        "model.add(Conv1D(256,8,padding='same',))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(MaxPooling1D(pool_size=(5)))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(256))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(256))\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "model.add(Dense(6))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "#opt = tf.keras.optimizers.Adam(lr=0.00002)\n",
        "opt = tf.keras.optimizers.RMSprop(lr=0.0001, rho=0.9, epsilon=1e-07, decay=0.0)\n",
        "#opt = tf.keras.optimizers.SGD(lr=0.001, momentum=0.0, decay=0.0, nesterov=False)"
      ],
      "metadata": {
        "id": "g74fXWVAC4Cr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f16ff230-04bf-4221-9983-f2165fec65c6"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/rmsprop.py:130: UserWarning:\n",
            "\n",
            "The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H6ukOxAGC_I4",
        "outputId": "c0250238-530a-4f78-ca61-1cadbbcfe1f9"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d (Conv1D)             (None, 40, 128)           1152      \n",
            "                                                                 \n",
            " activation (Activation)     (None, 40, 128)           0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 40, 128)           0         \n",
            "                                                                 \n",
            " max_pooling1d (MaxPooling1D  (None, 8, 128)           0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv1d_1 (Conv1D)           (None, 8, 256)            262400    \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 8, 256)            0         \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 8, 256)            0         \n",
            "                                                                 \n",
            " max_pooling1d_1 (MaxPooling  (None, 1, 256)           0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 256)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 256)               65792     \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 256)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 256)               65792     \n",
            "                                                                 \n",
            " activation_3 (Activation)   (None, 256)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 6)                 1542      \n",
            "                                                                 \n",
            " activation_4 (Activation)   (None, 6)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 396,678\n",
            "Trainable params: 396,678\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='sparse_categorical_crossentropy',\n",
        "              optimizer=opt,\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "AbMlLNk4DCBM"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#cnnhistory=model.fit(x_traincnn, y_train, batch_size=16, epochs=700, validation_data=(x_testcnn, y_test))\n",
        "cnnhistory=model.fit(x_traincnn, y_train, batch_size=16, epochs=500 , validation_data=(X_valid, y_valid))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RI1v2AuADFhy",
        "outputId": "b2a7fd76-44b3-4bf1-a049-8b09595ef17b"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "104/104 [==============================] - 4s 13ms/step - loss: 4.4998 - accuracy: 0.1747 - val_loss: 1.8635 - val_accuracy: 0.2415\n",
            "Epoch 2/500\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 2.7765 - accuracy: 0.1947 - val_loss: 1.7838 - val_accuracy: 0.2077\n",
            "Epoch 3/500\n",
            "104/104 [==============================] - 1s 9ms/step - loss: 2.3650 - accuracy: 0.2134 - val_loss: 1.7591 - val_accuracy: 0.2367\n",
            "Epoch 4/500\n",
            "104/104 [==============================] - 1s 10ms/step - loss: 2.1337 - accuracy: 0.2068 - val_loss: 1.8037 - val_accuracy: 0.2077\n",
            "Epoch 5/500\n",
            "104/104 [==============================] - 1s 10ms/step - loss: 2.0293 - accuracy: 0.2207 - val_loss: 1.7293 - val_accuracy: 0.2126\n",
            "Epoch 6/500\n",
            "104/104 [==============================] - 1s 9ms/step - loss: 1.9808 - accuracy: 0.2164 - val_loss: 1.7519 - val_accuracy: 0.2319\n",
            "Epoch 7/500\n",
            "104/104 [==============================] - 1s 9ms/step - loss: 1.9164 - accuracy: 0.2430 - val_loss: 1.7429 - val_accuracy: 0.2222\n",
            "Epoch 8/500\n",
            "104/104 [==============================] - 1s 9ms/step - loss: 1.8613 - accuracy: 0.2485 - val_loss: 1.7613 - val_accuracy: 0.1594\n",
            "Epoch 9/500\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 1.8119 - accuracy: 0.2509 - val_loss: 1.7280 - val_accuracy: 0.2174\n",
            "Epoch 10/500\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 1.8018 - accuracy: 0.2594 - val_loss: 1.7006 - val_accuracy: 0.3188\n",
            "Epoch 11/500\n",
            "104/104 [==============================] - 1s 10ms/step - loss: 1.7762 - accuracy: 0.2606 - val_loss: 1.6360 - val_accuracy: 0.3092\n",
            "Epoch 12/500\n",
            "104/104 [==============================] - 1s 10ms/step - loss: 1.7512 - accuracy: 0.2666 - val_loss: 1.6096 - val_accuracy: 0.3092\n",
            "Epoch 13/500\n",
            "104/104 [==============================] - 1s 9ms/step - loss: 1.7380 - accuracy: 0.2817 - val_loss: 1.7649 - val_accuracy: 0.2415\n",
            "Epoch 14/500\n",
            "104/104 [==============================] - 1s 9ms/step - loss: 1.7116 - accuracy: 0.2836 - val_loss: 1.6631 - val_accuracy: 0.2947\n",
            "Epoch 15/500\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 1.6970 - accuracy: 0.2902 - val_loss: 1.6509 - val_accuracy: 0.2609\n",
            "Epoch 16/500\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 1.6631 - accuracy: 0.3120 - val_loss: 1.6308 - val_accuracy: 0.2560\n",
            "Epoch 17/500\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 1.6413 - accuracy: 0.3150 - val_loss: 1.6501 - val_accuracy: 0.2995\n",
            "Epoch 18/500\n",
            "104/104 [==============================] - 1s 9ms/step - loss: 1.6256 - accuracy: 0.3343 - val_loss: 1.5650 - val_accuracy: 0.3333\n",
            "Epoch 19/500\n",
            "104/104 [==============================] - 1s 9ms/step - loss: 1.6076 - accuracy: 0.3283 - val_loss: 1.5428 - val_accuracy: 0.4155\n",
            "Epoch 20/500\n",
            "104/104 [==============================] - 1s 9ms/step - loss: 1.6068 - accuracy: 0.3356 - val_loss: 1.5509 - val_accuracy: 0.3382\n",
            "Epoch 21/500\n",
            "104/104 [==============================] - 1s 9ms/step - loss: 1.5979 - accuracy: 0.3241 - val_loss: 1.6555 - val_accuracy: 0.3092\n",
            "Epoch 22/500\n",
            "104/104 [==============================] - 1s 9ms/step - loss: 1.5909 - accuracy: 0.3482 - val_loss: 1.5044 - val_accuracy: 0.3913\n",
            "Epoch 23/500\n",
            "104/104 [==============================] - 1s 9ms/step - loss: 1.5637 - accuracy: 0.3543 - val_loss: 1.5133 - val_accuracy: 0.3913\n",
            "Epoch 24/500\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 1.5510 - accuracy: 0.3349 - val_loss: 1.4705 - val_accuracy: 0.4203\n",
            "Epoch 25/500\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 1.5208 - accuracy: 0.3682 - val_loss: 1.5763 - val_accuracy: 0.3092\n",
            "Epoch 26/500\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 1.5206 - accuracy: 0.3628 - val_loss: 1.5041 - val_accuracy: 0.3623\n",
            "Epoch 27/500\n",
            "104/104 [==============================] - 1s 9ms/step - loss: 1.4898 - accuracy: 0.3748 - val_loss: 1.4152 - val_accuracy: 0.4928\n",
            "Epoch 28/500\n",
            "104/104 [==============================] - 1s 9ms/step - loss: 1.4981 - accuracy: 0.3712 - val_loss: 1.4210 - val_accuracy: 0.4831\n",
            "Epoch 29/500\n",
            "104/104 [==============================] - 1s 9ms/step - loss: 1.4719 - accuracy: 0.3815 - val_loss: 1.4517 - val_accuracy: 0.4348\n",
            "Epoch 30/500\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 1.4477 - accuracy: 0.4093 - val_loss: 1.3876 - val_accuracy: 0.4396\n",
            "Epoch 31/500\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 1.4335 - accuracy: 0.3948 - val_loss: 1.3329 - val_accuracy: 0.5072\n",
            "Epoch 32/500\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 1.4181 - accuracy: 0.4232 - val_loss: 1.3577 - val_accuracy: 0.4444\n",
            "Epoch 33/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.4032 - accuracy: 0.4347 - val_loss: 1.4097 - val_accuracy: 0.4493\n",
            "Epoch 34/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.3939 - accuracy: 0.4305 - val_loss: 1.3290 - val_accuracy: 0.5024\n",
            "Epoch 35/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.3586 - accuracy: 0.4407 - val_loss: 1.3241 - val_accuracy: 0.4928\n",
            "Epoch 36/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.3605 - accuracy: 0.4311 - val_loss: 1.3536 - val_accuracy: 0.4444\n",
            "Epoch 37/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.3437 - accuracy: 0.4541 - val_loss: 1.3393 - val_accuracy: 0.4879\n",
            "Epoch 38/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.3318 - accuracy: 0.4528 - val_loss: 1.2977 - val_accuracy: 0.5024\n",
            "Epoch 39/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.3096 - accuracy: 0.4583 - val_loss: 1.2151 - val_accuracy: 0.5700\n",
            "Epoch 40/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.2845 - accuracy: 0.4788 - val_loss: 1.3395 - val_accuracy: 0.4300\n",
            "Epoch 41/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.2845 - accuracy: 0.4692 - val_loss: 1.3254 - val_accuracy: 0.4879\n",
            "Epoch 42/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.2838 - accuracy: 0.4855 - val_loss: 1.2398 - val_accuracy: 0.5314\n",
            "Epoch 43/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.2676 - accuracy: 0.4788 - val_loss: 1.2268 - val_accuracy: 0.5507\n",
            "Epoch 44/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.2751 - accuracy: 0.4674 - val_loss: 1.1954 - val_accuracy: 0.5121\n",
            "Epoch 45/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.2353 - accuracy: 0.4976 - val_loss: 1.2542 - val_accuracy: 0.5169\n",
            "Epoch 46/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.2419 - accuracy: 0.5036 - val_loss: 1.2010 - val_accuracy: 0.5556\n",
            "Epoch 47/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.2147 - accuracy: 0.5067 - val_loss: 1.1565 - val_accuracy: 0.5362\n",
            "Epoch 48/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.2047 - accuracy: 0.5054 - val_loss: 1.1997 - val_accuracy: 0.5314\n",
            "Epoch 49/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.1863 - accuracy: 0.5079 - val_loss: 1.2063 - val_accuracy: 0.5217\n",
            "Epoch 50/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.1854 - accuracy: 0.5193 - val_loss: 1.1338 - val_accuracy: 0.5459\n",
            "Epoch 51/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.1699 - accuracy: 0.5272 - val_loss: 1.1093 - val_accuracy: 0.5749\n",
            "Epoch 52/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.1721 - accuracy: 0.5206 - val_loss: 1.1726 - val_accuracy: 0.5507\n",
            "Epoch 53/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.1721 - accuracy: 0.5290 - val_loss: 1.0985 - val_accuracy: 0.5556\n",
            "Epoch 54/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.1465 - accuracy: 0.5254 - val_loss: 1.1020 - val_accuracy: 0.6087\n",
            "Epoch 55/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.1265 - accuracy: 0.5411 - val_loss: 1.1042 - val_accuracy: 0.5314\n",
            "Epoch 56/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.1268 - accuracy: 0.5302 - val_loss: 1.0884 - val_accuracy: 0.6232\n",
            "Epoch 57/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.1008 - accuracy: 0.5363 - val_loss: 1.1474 - val_accuracy: 0.5652\n",
            "Epoch 58/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.1172 - accuracy: 0.5393 - val_loss: 1.0628 - val_accuracy: 0.5700\n",
            "Epoch 59/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.1022 - accuracy: 0.5568 - val_loss: 1.1224 - val_accuracy: 0.5556\n",
            "Epoch 60/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.1032 - accuracy: 0.5453 - val_loss: 1.0637 - val_accuracy: 0.6135\n",
            "Epoch 61/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0970 - accuracy: 0.5665 - val_loss: 1.0703 - val_accuracy: 0.6329\n",
            "Epoch 62/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0843 - accuracy: 0.5653 - val_loss: 1.0929 - val_accuracy: 0.5556\n",
            "Epoch 63/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0660 - accuracy: 0.5744 - val_loss: 1.0837 - val_accuracy: 0.5604\n",
            "Epoch 64/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0585 - accuracy: 0.5768 - val_loss: 1.0600 - val_accuracy: 0.5411\n",
            "Epoch 65/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0850 - accuracy: 0.5635 - val_loss: 1.0552 - val_accuracy: 0.5990\n",
            "Epoch 66/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0274 - accuracy: 0.5707 - val_loss: 1.0464 - val_accuracy: 0.5797\n",
            "Epoch 67/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0471 - accuracy: 0.5804 - val_loss: 1.0774 - val_accuracy: 0.5845\n",
            "Epoch 68/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0306 - accuracy: 0.5810 - val_loss: 0.9883 - val_accuracy: 0.6232\n",
            "Epoch 69/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0306 - accuracy: 0.5846 - val_loss: 1.0238 - val_accuracy: 0.6425\n",
            "Epoch 70/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0011 - accuracy: 0.6034 - val_loss: 1.0107 - val_accuracy: 0.5990\n",
            "Epoch 71/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0017 - accuracy: 0.6028 - val_loss: 0.9944 - val_accuracy: 0.6087\n",
            "Epoch 72/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0015 - accuracy: 0.5889 - val_loss: 1.0280 - val_accuracy: 0.5942\n",
            "Epoch 73/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9599 - accuracy: 0.6203 - val_loss: 1.0110 - val_accuracy: 0.5894\n",
            "Epoch 74/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9656 - accuracy: 0.6016 - val_loss: 0.9815 - val_accuracy: 0.6280\n",
            "Epoch 75/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9773 - accuracy: 0.6046 - val_loss: 1.0089 - val_accuracy: 0.6184\n",
            "Epoch 76/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9688 - accuracy: 0.6070 - val_loss: 1.0512 - val_accuracy: 0.5556\n",
            "Epoch 77/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9678 - accuracy: 0.6167 - val_loss: 0.9613 - val_accuracy: 0.6280\n",
            "Epoch 78/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9509 - accuracy: 0.6203 - val_loss: 0.9971 - val_accuracy: 0.6087\n",
            "Epoch 79/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9530 - accuracy: 0.6088 - val_loss: 1.0025 - val_accuracy: 0.5845\n",
            "Epoch 80/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9305 - accuracy: 0.6306 - val_loss: 1.0020 - val_accuracy: 0.6184\n",
            "Epoch 81/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9357 - accuracy: 0.6197 - val_loss: 0.9584 - val_accuracy: 0.6522\n",
            "Epoch 82/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9303 - accuracy: 0.6264 - val_loss: 1.0707 - val_accuracy: 0.5411\n",
            "Epoch 83/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9141 - accuracy: 0.6336 - val_loss: 0.9106 - val_accuracy: 0.6135\n",
            "Epoch 84/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9113 - accuracy: 0.6330 - val_loss: 0.9499 - val_accuracy: 0.6039\n",
            "Epoch 85/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8917 - accuracy: 0.6518 - val_loss: 0.9019 - val_accuracy: 0.6425\n",
            "Epoch 86/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8962 - accuracy: 0.6433 - val_loss: 0.9411 - val_accuracy: 0.6280\n",
            "Epoch 87/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8939 - accuracy: 0.6487 - val_loss: 0.9079 - val_accuracy: 0.6522\n",
            "Epoch 88/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8920 - accuracy: 0.6385 - val_loss: 0.9166 - val_accuracy: 0.6329\n",
            "Epoch 89/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8919 - accuracy: 0.6505 - val_loss: 0.9262 - val_accuracy: 0.6329\n",
            "Epoch 90/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8989 - accuracy: 0.6378 - val_loss: 0.9013 - val_accuracy: 0.6425\n",
            "Epoch 91/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8749 - accuracy: 0.6499 - val_loss: 0.9732 - val_accuracy: 0.5845\n",
            "Epoch 92/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8650 - accuracy: 0.6554 - val_loss: 0.9406 - val_accuracy: 0.6184\n",
            "Epoch 93/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8760 - accuracy: 0.6518 - val_loss: 0.9693 - val_accuracy: 0.6280\n",
            "Epoch 94/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8505 - accuracy: 0.6632 - val_loss: 0.9466 - val_accuracy: 0.6039\n",
            "Epoch 95/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8503 - accuracy: 0.6493 - val_loss: 0.8928 - val_accuracy: 0.6184\n",
            "Epoch 96/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8385 - accuracy: 0.6717 - val_loss: 0.8997 - val_accuracy: 0.6618\n",
            "Epoch 97/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8306 - accuracy: 0.6711 - val_loss: 0.8965 - val_accuracy: 0.6715\n",
            "Epoch 98/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8686 - accuracy: 0.6518 - val_loss: 0.8917 - val_accuracy: 0.6570\n",
            "Epoch 99/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8547 - accuracy: 0.6651 - val_loss: 0.9734 - val_accuracy: 0.6087\n",
            "Epoch 100/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8109 - accuracy: 0.6699 - val_loss: 0.9006 - val_accuracy: 0.6473\n",
            "Epoch 101/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8274 - accuracy: 0.6693 - val_loss: 0.8894 - val_accuracy: 0.6618\n",
            "Epoch 102/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8132 - accuracy: 0.6699 - val_loss: 0.8693 - val_accuracy: 0.6473\n",
            "Epoch 103/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8123 - accuracy: 0.6771 - val_loss: 0.9061 - val_accuracy: 0.6377\n",
            "Epoch 104/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8046 - accuracy: 0.6626 - val_loss: 0.8895 - val_accuracy: 0.6522\n",
            "Epoch 105/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8044 - accuracy: 0.6886 - val_loss: 0.9025 - val_accuracy: 0.6329\n",
            "Epoch 106/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8070 - accuracy: 0.6790 - val_loss: 0.8674 - val_accuracy: 0.6522\n",
            "Epoch 107/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8032 - accuracy: 0.6868 - val_loss: 0.8658 - val_accuracy: 0.6425\n",
            "Epoch 108/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7729 - accuracy: 0.6917 - val_loss: 0.8482 - val_accuracy: 0.6957\n",
            "Epoch 109/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7891 - accuracy: 0.6808 - val_loss: 0.8668 - val_accuracy: 0.6812\n",
            "Epoch 110/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7731 - accuracy: 0.6995 - val_loss: 0.8420 - val_accuracy: 0.6715\n",
            "Epoch 111/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7843 - accuracy: 0.6729 - val_loss: 0.8641 - val_accuracy: 0.6763\n",
            "Epoch 112/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7631 - accuracy: 0.7062 - val_loss: 0.9037 - val_accuracy: 0.6329\n",
            "Epoch 113/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7705 - accuracy: 0.7001 - val_loss: 0.8504 - val_accuracy: 0.6715\n",
            "Epoch 114/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.7612 - accuracy: 0.7074 - val_loss: 0.8448 - val_accuracy: 0.6570\n",
            "Epoch 115/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.7734 - accuracy: 0.6935 - val_loss: 0.8337 - val_accuracy: 0.6570\n",
            "Epoch 116/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7662 - accuracy: 0.6923 - val_loss: 0.7972 - val_accuracy: 0.7053\n",
            "Epoch 117/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7404 - accuracy: 0.7056 - val_loss: 0.8198 - val_accuracy: 0.6908\n",
            "Epoch 118/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7593 - accuracy: 0.6995 - val_loss: 0.8259 - val_accuracy: 0.6667\n",
            "Epoch 119/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7377 - accuracy: 0.7146 - val_loss: 0.7944 - val_accuracy: 0.6957\n",
            "Epoch 120/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7203 - accuracy: 0.7140 - val_loss: 0.8080 - val_accuracy: 0.6957\n",
            "Epoch 121/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7334 - accuracy: 0.7146 - val_loss: 0.8179 - val_accuracy: 0.6667\n",
            "Epoch 122/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7226 - accuracy: 0.7098 - val_loss: 0.8099 - val_accuracy: 0.7101\n",
            "Epoch 123/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7186 - accuracy: 0.7189 - val_loss: 0.8358 - val_accuracy: 0.6763\n",
            "Epoch 124/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7260 - accuracy: 0.7044 - val_loss: 0.8276 - val_accuracy: 0.6763\n",
            "Epoch 125/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7130 - accuracy: 0.7189 - val_loss: 0.8338 - val_accuracy: 0.6860\n",
            "Epoch 126/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7174 - accuracy: 0.7219 - val_loss: 0.8534 - val_accuracy: 0.6715\n",
            "Epoch 127/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7113 - accuracy: 0.7189 - val_loss: 0.7853 - val_accuracy: 0.6957\n",
            "Epoch 128/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7093 - accuracy: 0.7110 - val_loss: 0.8337 - val_accuracy: 0.6425\n",
            "Epoch 129/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7097 - accuracy: 0.7201 - val_loss: 0.8246 - val_accuracy: 0.6522\n",
            "Epoch 130/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7041 - accuracy: 0.7158 - val_loss: 0.8330 - val_accuracy: 0.7005\n",
            "Epoch 131/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6749 - accuracy: 0.7443 - val_loss: 0.8647 - val_accuracy: 0.6763\n",
            "Epoch 132/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6793 - accuracy: 0.7297 - val_loss: 0.8354 - val_accuracy: 0.6473\n",
            "Epoch 133/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7024 - accuracy: 0.7261 - val_loss: 0.8404 - val_accuracy: 0.6618\n",
            "Epoch 134/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6852 - accuracy: 0.7310 - val_loss: 0.8147 - val_accuracy: 0.7101\n",
            "Epoch 135/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6959 - accuracy: 0.7195 - val_loss: 0.8826 - val_accuracy: 0.6667\n",
            "Epoch 136/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6867 - accuracy: 0.7304 - val_loss: 0.8174 - val_accuracy: 0.6860\n",
            "Epoch 137/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6874 - accuracy: 0.7304 - val_loss: 0.7726 - val_accuracy: 0.7101\n",
            "Epoch 138/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6574 - accuracy: 0.7370 - val_loss: 0.8029 - val_accuracy: 0.7053\n",
            "Epoch 139/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6761 - accuracy: 0.7443 - val_loss: 0.7751 - val_accuracy: 0.7101\n",
            "Epoch 140/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6720 - accuracy: 0.7412 - val_loss: 0.8343 - val_accuracy: 0.6522\n",
            "Epoch 141/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6576 - accuracy: 0.7412 - val_loss: 0.7602 - val_accuracy: 0.7005\n",
            "Epoch 142/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6393 - accuracy: 0.7515 - val_loss: 0.8160 - val_accuracy: 0.6329\n",
            "Epoch 143/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6496 - accuracy: 0.7479 - val_loss: 0.8449 - val_accuracy: 0.7150\n",
            "Epoch 144/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6413 - accuracy: 0.7521 - val_loss: 0.7939 - val_accuracy: 0.7053\n",
            "Epoch 145/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6589 - accuracy: 0.7406 - val_loss: 0.8493 - val_accuracy: 0.6715\n",
            "Epoch 146/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6515 - accuracy: 0.7527 - val_loss: 0.7959 - val_accuracy: 0.7005\n",
            "Epoch 147/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6502 - accuracy: 0.7503 - val_loss: 0.7892 - val_accuracy: 0.6957\n",
            "Epoch 148/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6328 - accuracy: 0.7551 - val_loss: 0.7579 - val_accuracy: 0.7101\n",
            "Epoch 149/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6208 - accuracy: 0.7539 - val_loss: 0.8068 - val_accuracy: 0.6908\n",
            "Epoch 150/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6216 - accuracy: 0.7551 - val_loss: 0.7654 - val_accuracy: 0.7053\n",
            "Epoch 151/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6213 - accuracy: 0.7703 - val_loss: 0.7673 - val_accuracy: 0.7150\n",
            "Epoch 152/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6385 - accuracy: 0.7509 - val_loss: 0.7551 - val_accuracy: 0.7295\n",
            "Epoch 153/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6113 - accuracy: 0.7527 - val_loss: 0.8040 - val_accuracy: 0.7005\n",
            "Epoch 154/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6211 - accuracy: 0.7600 - val_loss: 0.7359 - val_accuracy: 0.6957\n",
            "Epoch 155/500\n",
            "104/104 [==============================] - 1s 11ms/step - loss: 0.6144 - accuracy: 0.7630 - val_loss: 0.8145 - val_accuracy: 0.6957\n",
            "Epoch 156/500\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 0.6154 - accuracy: 0.7612 - val_loss: 0.7607 - val_accuracy: 0.7005\n",
            "Epoch 157/500\n",
            "104/104 [==============================] - 1s 9ms/step - loss: 0.6074 - accuracy: 0.7690 - val_loss: 0.7839 - val_accuracy: 0.6908\n",
            "Epoch 158/500\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.6104 - accuracy: 0.7709 - val_loss: 0.7902 - val_accuracy: 0.7101\n",
            "Epoch 159/500\n",
            "104/104 [==============================] - 1s 10ms/step - loss: 0.6140 - accuracy: 0.7624 - val_loss: 0.8230 - val_accuracy: 0.6908\n",
            "Epoch 160/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5867 - accuracy: 0.7588 - val_loss: 0.8207 - val_accuracy: 0.6957\n",
            "Epoch 161/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5952 - accuracy: 0.7618 - val_loss: 0.7574 - val_accuracy: 0.7005\n",
            "Epoch 162/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5935 - accuracy: 0.7678 - val_loss: 0.7802 - val_accuracy: 0.7101\n",
            "Epoch 163/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5921 - accuracy: 0.7678 - val_loss: 0.7517 - val_accuracy: 0.6812\n",
            "Epoch 164/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5944 - accuracy: 0.7696 - val_loss: 0.7134 - val_accuracy: 0.7343\n",
            "Epoch 165/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5579 - accuracy: 0.7866 - val_loss: 0.7386 - val_accuracy: 0.7150\n",
            "Epoch 166/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5664 - accuracy: 0.7817 - val_loss: 0.7708 - val_accuracy: 0.7053\n",
            "Epoch 167/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5577 - accuracy: 0.7878 - val_loss: 0.7479 - val_accuracy: 0.6908\n",
            "Epoch 168/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5655 - accuracy: 0.7817 - val_loss: 0.8415 - val_accuracy: 0.6812\n",
            "Epoch 169/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5614 - accuracy: 0.7793 - val_loss: 0.7957 - val_accuracy: 0.6908\n",
            "Epoch 170/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5638 - accuracy: 0.7769 - val_loss: 0.7388 - val_accuracy: 0.6908\n",
            "Epoch 171/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5385 - accuracy: 0.7878 - val_loss: 0.7406 - val_accuracy: 0.6860\n",
            "Epoch 172/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5523 - accuracy: 0.7914 - val_loss: 0.7189 - val_accuracy: 0.7295\n",
            "Epoch 173/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5426 - accuracy: 0.7836 - val_loss: 0.7201 - val_accuracy: 0.7343\n",
            "Epoch 174/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5442 - accuracy: 0.7914 - val_loss: 0.7146 - val_accuracy: 0.7150\n",
            "Epoch 175/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5391 - accuracy: 0.7866 - val_loss: 0.7650 - val_accuracy: 0.6860\n",
            "Epoch 176/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5389 - accuracy: 0.7872 - val_loss: 0.6875 - val_accuracy: 0.7488\n",
            "Epoch 177/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5416 - accuracy: 0.7872 - val_loss: 0.7704 - val_accuracy: 0.7005\n",
            "Epoch 178/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5359 - accuracy: 0.7920 - val_loss: 0.7143 - val_accuracy: 0.7005\n",
            "Epoch 179/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5130 - accuracy: 0.8011 - val_loss: 0.7677 - val_accuracy: 0.6860\n",
            "Epoch 180/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5246 - accuracy: 0.7993 - val_loss: 0.7639 - val_accuracy: 0.7005\n",
            "Epoch 181/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5204 - accuracy: 0.8035 - val_loss: 0.7430 - val_accuracy: 0.6957\n",
            "Epoch 182/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5237 - accuracy: 0.8005 - val_loss: 0.7176 - val_accuracy: 0.7198\n",
            "Epoch 183/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5246 - accuracy: 0.7981 - val_loss: 0.7167 - val_accuracy: 0.7150\n",
            "Epoch 184/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5133 - accuracy: 0.8047 - val_loss: 0.7764 - val_accuracy: 0.6908\n",
            "Epoch 185/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4922 - accuracy: 0.8083 - val_loss: 0.7401 - val_accuracy: 0.7005\n",
            "Epoch 186/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4954 - accuracy: 0.8041 - val_loss: 0.7123 - val_accuracy: 0.7295\n",
            "Epoch 187/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5190 - accuracy: 0.8047 - val_loss: 0.7154 - val_accuracy: 0.6908\n",
            "Epoch 188/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5114 - accuracy: 0.8047 - val_loss: 0.7511 - val_accuracy: 0.6957\n",
            "Epoch 189/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4989 - accuracy: 0.8114 - val_loss: 0.7650 - val_accuracy: 0.6812\n",
            "Epoch 190/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5000 - accuracy: 0.7975 - val_loss: 0.7154 - val_accuracy: 0.7246\n",
            "Epoch 191/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5045 - accuracy: 0.8174 - val_loss: 0.6858 - val_accuracy: 0.7729\n",
            "Epoch 192/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5043 - accuracy: 0.8059 - val_loss: 0.7453 - val_accuracy: 0.7150\n",
            "Epoch 193/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4896 - accuracy: 0.8132 - val_loss: 0.7273 - val_accuracy: 0.6812\n",
            "Epoch 194/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5218 - accuracy: 0.7987 - val_loss: 0.7620 - val_accuracy: 0.7005\n",
            "Epoch 195/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4735 - accuracy: 0.8186 - val_loss: 0.7730 - val_accuracy: 0.6908\n",
            "Epoch 196/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4911 - accuracy: 0.8029 - val_loss: 0.7612 - val_accuracy: 0.7005\n",
            "Epoch 197/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4808 - accuracy: 0.8138 - val_loss: 0.7238 - val_accuracy: 0.7246\n",
            "Epoch 198/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4744 - accuracy: 0.8144 - val_loss: 0.7377 - val_accuracy: 0.6957\n",
            "Epoch 199/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4881 - accuracy: 0.8132 - val_loss: 0.7382 - val_accuracy: 0.7440\n",
            "Epoch 200/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4952 - accuracy: 0.8029 - val_loss: 0.7392 - val_accuracy: 0.7440\n",
            "Epoch 201/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4897 - accuracy: 0.8041 - val_loss: 0.6940 - val_accuracy: 0.7005\n",
            "Epoch 202/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.4603 - accuracy: 0.8222 - val_loss: 0.7223 - val_accuracy: 0.7005\n",
            "Epoch 203/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4511 - accuracy: 0.8222 - val_loss: 0.7428 - val_accuracy: 0.7005\n",
            "Epoch 204/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4829 - accuracy: 0.8162 - val_loss: 0.7516 - val_accuracy: 0.7005\n",
            "Epoch 205/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4519 - accuracy: 0.8343 - val_loss: 0.7440 - val_accuracy: 0.7295\n",
            "Epoch 206/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4870 - accuracy: 0.8102 - val_loss: 0.7294 - val_accuracy: 0.7246\n",
            "Epoch 207/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.4749 - accuracy: 0.8138 - val_loss: 0.7004 - val_accuracy: 0.7246\n",
            "Epoch 208/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4480 - accuracy: 0.8259 - val_loss: 0.7183 - val_accuracy: 0.7150\n",
            "Epoch 209/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4398 - accuracy: 0.8198 - val_loss: 0.7148 - val_accuracy: 0.7005\n",
            "Epoch 210/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4393 - accuracy: 0.8307 - val_loss: 0.7210 - val_accuracy: 0.7391\n",
            "Epoch 211/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.4487 - accuracy: 0.8192 - val_loss: 0.7411 - val_accuracy: 0.7391\n",
            "Epoch 212/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4390 - accuracy: 0.8337 - val_loss: 0.6721 - val_accuracy: 0.7585\n",
            "Epoch 213/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4354 - accuracy: 0.8253 - val_loss: 0.7214 - val_accuracy: 0.7053\n",
            "Epoch 214/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4487 - accuracy: 0.8186 - val_loss: 0.7709 - val_accuracy: 0.6908\n",
            "Epoch 215/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4381 - accuracy: 0.8216 - val_loss: 0.7110 - val_accuracy: 0.7488\n",
            "Epoch 216/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4516 - accuracy: 0.8301 - val_loss: 0.6809 - val_accuracy: 0.7633\n",
            "Epoch 217/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4444 - accuracy: 0.8271 - val_loss: 0.7117 - val_accuracy: 0.7101\n",
            "Epoch 218/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4365 - accuracy: 0.8325 - val_loss: 0.7442 - val_accuracy: 0.6908\n",
            "Epoch 219/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4230 - accuracy: 0.8416 - val_loss: 0.7390 - val_accuracy: 0.7053\n",
            "Epoch 220/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4130 - accuracy: 0.8501 - val_loss: 0.7397 - val_accuracy: 0.7150\n",
            "Epoch 221/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4148 - accuracy: 0.8380 - val_loss: 0.6963 - val_accuracy: 0.7440\n",
            "Epoch 222/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4129 - accuracy: 0.8398 - val_loss: 0.8209 - val_accuracy: 0.6957\n",
            "Epoch 223/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4456 - accuracy: 0.8259 - val_loss: 0.7578 - val_accuracy: 0.6957\n",
            "Epoch 224/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4191 - accuracy: 0.8356 - val_loss: 0.7084 - val_accuracy: 0.7488\n",
            "Epoch 225/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4223 - accuracy: 0.8422 - val_loss: 0.6653 - val_accuracy: 0.7440\n",
            "Epoch 226/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.4213 - accuracy: 0.8356 - val_loss: 0.6764 - val_accuracy: 0.7585\n",
            "Epoch 227/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4169 - accuracy: 0.8458 - val_loss: 0.7994 - val_accuracy: 0.7150\n",
            "Epoch 228/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3910 - accuracy: 0.8555 - val_loss: 0.7827 - val_accuracy: 0.7101\n",
            "Epoch 229/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4059 - accuracy: 0.8464 - val_loss: 0.7187 - val_accuracy: 0.7391\n",
            "Epoch 230/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4072 - accuracy: 0.8410 - val_loss: 0.7384 - val_accuracy: 0.7391\n",
            "Epoch 231/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4255 - accuracy: 0.8380 - val_loss: 0.7114 - val_accuracy: 0.7295\n",
            "Epoch 232/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4012 - accuracy: 0.8446 - val_loss: 0.7224 - val_accuracy: 0.7150\n",
            "Epoch 233/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4105 - accuracy: 0.8489 - val_loss: 0.7018 - val_accuracy: 0.7295\n",
            "Epoch 234/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3969 - accuracy: 0.8470 - val_loss: 0.6849 - val_accuracy: 0.7343\n",
            "Epoch 235/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4058 - accuracy: 0.8404 - val_loss: 0.6654 - val_accuracy: 0.7681\n",
            "Epoch 236/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3969 - accuracy: 0.8476 - val_loss: 0.7333 - val_accuracy: 0.7295\n",
            "Epoch 237/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4191 - accuracy: 0.8331 - val_loss: 0.6645 - val_accuracy: 0.7585\n",
            "Epoch 238/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4204 - accuracy: 0.8464 - val_loss: 0.7119 - val_accuracy: 0.7150\n",
            "Epoch 239/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3691 - accuracy: 0.8591 - val_loss: 0.6662 - val_accuracy: 0.7536\n",
            "Epoch 240/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3617 - accuracy: 0.8634 - val_loss: 0.7909 - val_accuracy: 0.7295\n",
            "Epoch 241/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.4145 - accuracy: 0.8452 - val_loss: 0.6758 - val_accuracy: 0.7440\n",
            "Epoch 242/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3783 - accuracy: 0.8609 - val_loss: 0.6739 - val_accuracy: 0.7536\n",
            "Epoch 243/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3733 - accuracy: 0.8622 - val_loss: 0.7150 - val_accuracy: 0.7391\n",
            "Epoch 244/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3742 - accuracy: 0.8567 - val_loss: 0.7120 - val_accuracy: 0.7440\n",
            "Epoch 245/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3788 - accuracy: 0.8555 - val_loss: 0.7756 - val_accuracy: 0.7053\n",
            "Epoch 246/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3730 - accuracy: 0.8646 - val_loss: 0.7211 - val_accuracy: 0.7536\n",
            "Epoch 247/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3762 - accuracy: 0.8476 - val_loss: 0.7511 - val_accuracy: 0.7198\n",
            "Epoch 248/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3514 - accuracy: 0.8688 - val_loss: 0.7732 - val_accuracy: 0.7246\n",
            "Epoch 249/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3782 - accuracy: 0.8470 - val_loss: 0.7520 - val_accuracy: 0.7053\n",
            "Epoch 250/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3662 - accuracy: 0.8634 - val_loss: 0.7382 - val_accuracy: 0.7391\n",
            "Epoch 251/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3608 - accuracy: 0.8603 - val_loss: 0.6809 - val_accuracy: 0.7729\n",
            "Epoch 252/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3783 - accuracy: 0.8537 - val_loss: 0.6982 - val_accuracy: 0.7488\n",
            "Epoch 253/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3704 - accuracy: 0.8549 - val_loss: 0.7864 - val_accuracy: 0.7150\n",
            "Epoch 254/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3697 - accuracy: 0.8622 - val_loss: 0.7322 - val_accuracy: 0.7150\n",
            "Epoch 255/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3553 - accuracy: 0.8597 - val_loss: 0.7350 - val_accuracy: 0.7440\n",
            "Epoch 256/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3662 - accuracy: 0.8646 - val_loss: 0.6900 - val_accuracy: 0.7778\n",
            "Epoch 257/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3435 - accuracy: 0.8664 - val_loss: 0.7740 - val_accuracy: 0.7053\n",
            "Epoch 258/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3682 - accuracy: 0.8628 - val_loss: 0.6948 - val_accuracy: 0.7488\n",
            "Epoch 259/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3398 - accuracy: 0.8646 - val_loss: 0.7406 - val_accuracy: 0.7198\n",
            "Epoch 260/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3549 - accuracy: 0.8634 - val_loss: 0.7582 - val_accuracy: 0.7053\n",
            "Epoch 261/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3355 - accuracy: 0.8742 - val_loss: 0.7928 - val_accuracy: 0.7005\n",
            "Epoch 262/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.3538 - accuracy: 0.8718 - val_loss: 0.7642 - val_accuracy: 0.7246\n",
            "Epoch 263/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3593 - accuracy: 0.8658 - val_loss: 0.7339 - val_accuracy: 0.7343\n",
            "Epoch 264/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.3437 - accuracy: 0.8670 - val_loss: 0.7483 - val_accuracy: 0.7101\n",
            "Epoch 265/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3275 - accuracy: 0.8724 - val_loss: 0.7607 - val_accuracy: 0.7391\n",
            "Epoch 266/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3428 - accuracy: 0.8682 - val_loss: 0.7454 - val_accuracy: 0.7053\n",
            "Epoch 267/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3653 - accuracy: 0.8646 - val_loss: 0.6850 - val_accuracy: 0.7343\n",
            "Epoch 268/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3311 - accuracy: 0.8785 - val_loss: 0.7146 - val_accuracy: 0.7391\n",
            "Epoch 269/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3301 - accuracy: 0.8742 - val_loss: 0.7916 - val_accuracy: 0.6908\n",
            "Epoch 270/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3462 - accuracy: 0.8615 - val_loss: 0.6885 - val_accuracy: 0.7681\n",
            "Epoch 271/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3400 - accuracy: 0.8736 - val_loss: 0.7364 - val_accuracy: 0.7150\n",
            "Epoch 272/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.3413 - accuracy: 0.8730 - val_loss: 0.7680 - val_accuracy: 0.7101\n",
            "Epoch 273/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.3132 - accuracy: 0.8791 - val_loss: 0.6680 - val_accuracy: 0.7729\n",
            "Epoch 274/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.3122 - accuracy: 0.8779 - val_loss: 0.6823 - val_accuracy: 0.7440\n",
            "Epoch 275/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3202 - accuracy: 0.8748 - val_loss: 0.7280 - val_accuracy: 0.7391\n",
            "Epoch 276/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.3232 - accuracy: 0.8797 - val_loss: 0.7129 - val_accuracy: 0.7343\n",
            "Epoch 277/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3030 - accuracy: 0.8851 - val_loss: 0.6873 - val_accuracy: 0.7778\n",
            "Epoch 278/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3123 - accuracy: 0.8833 - val_loss: 0.7511 - val_accuracy: 0.7150\n",
            "Epoch 279/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3019 - accuracy: 0.8797 - val_loss: 0.7451 - val_accuracy: 0.7536\n",
            "Epoch 280/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3097 - accuracy: 0.8827 - val_loss: 0.7640 - val_accuracy: 0.7343\n",
            "Epoch 281/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.3172 - accuracy: 0.8779 - val_loss: 0.7340 - val_accuracy: 0.7053\n",
            "Epoch 282/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.3091 - accuracy: 0.8875 - val_loss: 0.7521 - val_accuracy: 0.7488\n",
            "Epoch 283/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3103 - accuracy: 0.8869 - val_loss: 0.7229 - val_accuracy: 0.7343\n",
            "Epoch 284/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.3173 - accuracy: 0.8827 - val_loss: 0.7061 - val_accuracy: 0.7391\n",
            "Epoch 285/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3212 - accuracy: 0.8827 - val_loss: 0.7204 - val_accuracy: 0.7440\n",
            "Epoch 286/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2927 - accuracy: 0.8960 - val_loss: 0.7428 - val_accuracy: 0.7488\n",
            "Epoch 287/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3094 - accuracy: 0.8875 - val_loss: 0.7054 - val_accuracy: 0.7440\n",
            "Epoch 288/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2999 - accuracy: 0.8863 - val_loss: 0.7389 - val_accuracy: 0.7536\n",
            "Epoch 289/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3193 - accuracy: 0.8815 - val_loss: 0.7412 - val_accuracy: 0.7391\n",
            "Epoch 290/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2933 - accuracy: 0.8930 - val_loss: 0.7040 - val_accuracy: 0.7246\n",
            "Epoch 291/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.3229 - accuracy: 0.8924 - val_loss: 0.6904 - val_accuracy: 0.7391\n",
            "Epoch 292/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.3047 - accuracy: 0.8815 - val_loss: 0.7310 - val_accuracy: 0.6908\n",
            "Epoch 293/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2859 - accuracy: 0.8924 - val_loss: 0.8091 - val_accuracy: 0.7295\n",
            "Epoch 294/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2906 - accuracy: 0.9002 - val_loss: 0.7535 - val_accuracy: 0.7150\n",
            "Epoch 295/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2727 - accuracy: 0.8948 - val_loss: 0.6889 - val_accuracy: 0.7681\n",
            "Epoch 296/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3156 - accuracy: 0.8761 - val_loss: 0.7057 - val_accuracy: 0.7488\n",
            "Epoch 297/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.3184 - accuracy: 0.8875 - val_loss: 0.7103 - val_accuracy: 0.7440\n",
            "Epoch 298/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.3033 - accuracy: 0.8815 - val_loss: 0.7723 - val_accuracy: 0.7246\n",
            "Epoch 299/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3029 - accuracy: 0.8924 - val_loss: 0.7608 - val_accuracy: 0.7585\n",
            "Epoch 300/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2973 - accuracy: 0.8869 - val_loss: 0.7366 - val_accuracy: 0.7391\n",
            "Epoch 301/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2919 - accuracy: 0.8948 - val_loss: 0.7677 - val_accuracy: 0.7440\n",
            "Epoch 302/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3020 - accuracy: 0.8948 - val_loss: 0.7645 - val_accuracy: 0.7343\n",
            "Epoch 303/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2928 - accuracy: 0.8869 - val_loss: 0.7533 - val_accuracy: 0.7536\n",
            "Epoch 304/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2756 - accuracy: 0.9002 - val_loss: 0.7240 - val_accuracy: 0.7391\n",
            "Epoch 305/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2820 - accuracy: 0.8978 - val_loss: 0.7294 - val_accuracy: 0.7778\n",
            "Epoch 306/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2815 - accuracy: 0.8948 - val_loss: 0.7021 - val_accuracy: 0.7295\n",
            "Epoch 307/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2874 - accuracy: 0.8948 - val_loss: 0.6956 - val_accuracy: 0.7923\n",
            "Epoch 308/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3024 - accuracy: 0.8761 - val_loss: 0.7847 - val_accuracy: 0.7198\n",
            "Epoch 309/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2873 - accuracy: 0.8930 - val_loss: 0.7377 - val_accuracy: 0.7488\n",
            "Epoch 310/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2552 - accuracy: 0.9008 - val_loss: 0.7617 - val_accuracy: 0.7585\n",
            "Epoch 311/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2659 - accuracy: 0.8966 - val_loss: 0.7769 - val_accuracy: 0.7391\n",
            "Epoch 312/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2764 - accuracy: 0.8948 - val_loss: 0.6750 - val_accuracy: 0.7729\n",
            "Epoch 313/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2874 - accuracy: 0.8894 - val_loss: 0.7838 - val_accuracy: 0.7488\n",
            "Epoch 314/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2986 - accuracy: 0.8978 - val_loss: 0.7345 - val_accuracy: 0.7295\n",
            "Epoch 315/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2534 - accuracy: 0.9057 - val_loss: 0.8903 - val_accuracy: 0.6715\n",
            "Epoch 316/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2608 - accuracy: 0.8954 - val_loss: 0.7703 - val_accuracy: 0.7391\n",
            "Epoch 317/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2865 - accuracy: 0.8930 - val_loss: 0.7434 - val_accuracy: 0.7343\n",
            "Epoch 318/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2910 - accuracy: 0.8900 - val_loss: 0.9032 - val_accuracy: 0.6908\n",
            "Epoch 319/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2630 - accuracy: 0.9015 - val_loss: 0.7798 - val_accuracy: 0.7295\n",
            "Epoch 320/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2637 - accuracy: 0.9015 - val_loss: 0.9538 - val_accuracy: 0.6763\n",
            "Epoch 321/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2708 - accuracy: 0.8990 - val_loss: 0.8257 - val_accuracy: 0.7488\n",
            "Epoch 322/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2762 - accuracy: 0.8930 - val_loss: 0.7385 - val_accuracy: 0.7874\n",
            "Epoch 323/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2688 - accuracy: 0.9015 - val_loss: 0.7893 - val_accuracy: 0.7633\n",
            "Epoch 324/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2685 - accuracy: 0.8996 - val_loss: 0.7819 - val_accuracy: 0.7681\n",
            "Epoch 325/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2728 - accuracy: 0.8930 - val_loss: 0.8298 - val_accuracy: 0.7488\n",
            "Epoch 326/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2566 - accuracy: 0.8996 - val_loss: 0.8490 - val_accuracy: 0.7440\n",
            "Epoch 327/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2607 - accuracy: 0.8942 - val_loss: 0.8125 - val_accuracy: 0.7585\n",
            "Epoch 328/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2558 - accuracy: 0.8990 - val_loss: 0.7019 - val_accuracy: 0.7633\n",
            "Epoch 329/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2403 - accuracy: 0.9117 - val_loss: 0.7778 - val_accuracy: 0.7343\n",
            "Epoch 330/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2587 - accuracy: 0.9093 - val_loss: 0.7336 - val_accuracy: 0.7536\n",
            "Epoch 331/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2435 - accuracy: 0.9117 - val_loss: 0.7294 - val_accuracy: 0.7778\n",
            "Epoch 332/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2556 - accuracy: 0.9099 - val_loss: 0.7669 - val_accuracy: 0.7488\n",
            "Epoch 333/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2726 - accuracy: 0.9002 - val_loss: 0.7405 - val_accuracy: 0.7343\n",
            "Epoch 334/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2563 - accuracy: 0.9111 - val_loss: 0.7679 - val_accuracy: 0.7488\n",
            "Epoch 335/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2420 - accuracy: 0.9069 - val_loss: 0.8424 - val_accuracy: 0.7246\n",
            "Epoch 336/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2761 - accuracy: 0.9002 - val_loss: 0.8134 - val_accuracy: 0.7246\n",
            "Epoch 337/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2493 - accuracy: 0.9063 - val_loss: 0.7518 - val_accuracy: 0.7585\n",
            "Epoch 338/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2392 - accuracy: 0.9099 - val_loss: 0.7729 - val_accuracy: 0.7343\n",
            "Epoch 339/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2722 - accuracy: 0.9021 - val_loss: 0.7145 - val_accuracy: 0.7585\n",
            "Epoch 340/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2240 - accuracy: 0.9154 - val_loss: 0.7656 - val_accuracy: 0.7536\n",
            "Epoch 341/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2502 - accuracy: 0.9111 - val_loss: 0.7958 - val_accuracy: 0.7198\n",
            "Epoch 342/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2704 - accuracy: 0.9039 - val_loss: 0.6869 - val_accuracy: 0.7585\n",
            "Epoch 343/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2609 - accuracy: 0.9105 - val_loss: 0.7272 - val_accuracy: 0.7729\n",
            "Epoch 344/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2391 - accuracy: 0.9148 - val_loss: 0.7797 - val_accuracy: 0.7536\n",
            "Epoch 345/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2470 - accuracy: 0.9178 - val_loss: 0.7958 - val_accuracy: 0.7536\n",
            "Epoch 346/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2315 - accuracy: 0.9093 - val_loss: 0.7761 - val_accuracy: 0.7585\n",
            "Epoch 347/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2487 - accuracy: 0.9129 - val_loss: 0.7568 - val_accuracy: 0.7295\n",
            "Epoch 348/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2273 - accuracy: 0.9172 - val_loss: 0.7347 - val_accuracy: 0.7391\n",
            "Epoch 349/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2407 - accuracy: 0.9033 - val_loss: 0.7653 - val_accuracy: 0.7585\n",
            "Epoch 350/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2385 - accuracy: 0.9172 - val_loss: 0.8142 - val_accuracy: 0.7633\n",
            "Epoch 351/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2397 - accuracy: 0.9105 - val_loss: 0.8212 - val_accuracy: 0.7488\n",
            "Epoch 352/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2544 - accuracy: 0.8996 - val_loss: 0.7614 - val_accuracy: 0.7633\n",
            "Epoch 353/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2453 - accuracy: 0.9093 - val_loss: 0.7657 - val_accuracy: 0.7488\n",
            "Epoch 354/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2382 - accuracy: 0.9148 - val_loss: 0.8317 - val_accuracy: 0.7536\n",
            "Epoch 355/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2324 - accuracy: 0.9190 - val_loss: 0.7491 - val_accuracy: 0.7633\n",
            "Epoch 356/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2308 - accuracy: 0.9202 - val_loss: 0.7487 - val_accuracy: 0.7585\n",
            "Epoch 357/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2222 - accuracy: 0.9268 - val_loss: 0.7183 - val_accuracy: 0.7778\n",
            "Epoch 358/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2459 - accuracy: 0.9111 - val_loss: 0.7655 - val_accuracy: 0.7729\n",
            "Epoch 359/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2162 - accuracy: 0.9244 - val_loss: 0.9102 - val_accuracy: 0.7391\n",
            "Epoch 360/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2292 - accuracy: 0.9160 - val_loss: 0.7390 - val_accuracy: 0.7633\n",
            "Epoch 361/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2493 - accuracy: 0.9166 - val_loss: 0.8164 - val_accuracy: 0.7585\n",
            "Epoch 362/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2459 - accuracy: 0.9123 - val_loss: 0.8208 - val_accuracy: 0.7198\n",
            "Epoch 363/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2195 - accuracy: 0.9202 - val_loss: 0.8268 - val_accuracy: 0.7295\n",
            "Epoch 364/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2096 - accuracy: 0.9244 - val_loss: 0.7381 - val_accuracy: 0.7536\n",
            "Epoch 365/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2048 - accuracy: 0.9262 - val_loss: 0.8338 - val_accuracy: 0.7391\n",
            "Epoch 366/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2199 - accuracy: 0.9274 - val_loss: 0.7724 - val_accuracy: 0.7874\n",
            "Epoch 367/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2192 - accuracy: 0.9220 - val_loss: 0.7941 - val_accuracy: 0.7633\n",
            "Epoch 368/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2075 - accuracy: 0.9172 - val_loss: 0.8009 - val_accuracy: 0.7585\n",
            "Epoch 369/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2496 - accuracy: 0.9105 - val_loss: 0.8582 - val_accuracy: 0.7343\n",
            "Epoch 370/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2227 - accuracy: 0.9117 - val_loss: 0.8339 - val_accuracy: 0.7343\n",
            "Epoch 371/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2251 - accuracy: 0.9214 - val_loss: 0.7541 - val_accuracy: 0.7440\n",
            "Epoch 372/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2293 - accuracy: 0.9166 - val_loss: 0.7926 - val_accuracy: 0.7778\n",
            "Epoch 373/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2273 - accuracy: 0.9099 - val_loss: 0.8298 - val_accuracy: 0.7633\n",
            "Epoch 374/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1971 - accuracy: 0.9323 - val_loss: 0.7872 - val_accuracy: 0.7681\n",
            "Epoch 375/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2019 - accuracy: 0.9226 - val_loss: 0.7473 - val_accuracy: 0.7729\n",
            "Epoch 376/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2218 - accuracy: 0.9220 - val_loss: 0.7395 - val_accuracy: 0.7729\n",
            "Epoch 377/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2197 - accuracy: 0.9232 - val_loss: 0.6984 - val_accuracy: 0.7778\n",
            "Epoch 378/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2327 - accuracy: 0.9214 - val_loss: 0.7538 - val_accuracy: 0.7440\n",
            "Epoch 379/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2224 - accuracy: 0.9166 - val_loss: 0.7577 - val_accuracy: 0.7729\n",
            "Epoch 380/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2335 - accuracy: 0.9081 - val_loss: 0.7417 - val_accuracy: 0.7681\n",
            "Epoch 381/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2154 - accuracy: 0.9196 - val_loss: 0.8547 - val_accuracy: 0.7295\n",
            "Epoch 382/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2127 - accuracy: 0.9190 - val_loss: 0.7821 - val_accuracy: 0.7536\n",
            "Epoch 383/500\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 0.1981 - accuracy: 0.9323 - val_loss: 0.8579 - val_accuracy: 0.7585\n",
            "Epoch 384/500\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 0.2197 - accuracy: 0.9293 - val_loss: 0.9152 - val_accuracy: 0.7391\n",
            "Epoch 385/500\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.2239 - accuracy: 0.9160 - val_loss: 0.7081 - val_accuracy: 0.7923\n",
            "Epoch 386/500\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.2057 - accuracy: 0.9178 - val_loss: 0.7454 - val_accuracy: 0.7681\n",
            "Epoch 387/500\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.2268 - accuracy: 0.9287 - val_loss: 0.8520 - val_accuracy: 0.7681\n",
            "Epoch 388/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2148 - accuracy: 0.9208 - val_loss: 0.7908 - val_accuracy: 0.7585\n",
            "Epoch 389/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2070 - accuracy: 0.9226 - val_loss: 0.7455 - val_accuracy: 0.7729\n",
            "Epoch 390/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2175 - accuracy: 0.9262 - val_loss: 0.8606 - val_accuracy: 0.7391\n",
            "Epoch 391/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1914 - accuracy: 0.9293 - val_loss: 0.7657 - val_accuracy: 0.7826\n",
            "Epoch 392/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2078 - accuracy: 0.9299 - val_loss: 0.8280 - val_accuracy: 0.7971\n",
            "Epoch 393/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1992 - accuracy: 0.9305 - val_loss: 0.9146 - val_accuracy: 0.7585\n",
            "Epoch 394/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1890 - accuracy: 0.9317 - val_loss: 0.7644 - val_accuracy: 0.7585\n",
            "Epoch 395/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2065 - accuracy: 0.9238 - val_loss: 0.8331 - val_accuracy: 0.7343\n",
            "Epoch 396/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2194 - accuracy: 0.9202 - val_loss: 0.7747 - val_accuracy: 0.7536\n",
            "Epoch 397/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2020 - accuracy: 0.9274 - val_loss: 0.7613 - val_accuracy: 0.7681\n",
            "Epoch 398/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2135 - accuracy: 0.9232 - val_loss: 0.8401 - val_accuracy: 0.7729\n",
            "Epoch 399/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2111 - accuracy: 0.9238 - val_loss: 0.9069 - val_accuracy: 0.7198\n",
            "Epoch 400/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2040 - accuracy: 0.9244 - val_loss: 0.7807 - val_accuracy: 0.7778\n",
            "Epoch 401/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1841 - accuracy: 0.9281 - val_loss: 0.7920 - val_accuracy: 0.7778\n",
            "Epoch 402/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2002 - accuracy: 0.9256 - val_loss: 0.7580 - val_accuracy: 0.7778\n",
            "Epoch 403/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1903 - accuracy: 0.9274 - val_loss: 0.8215 - val_accuracy: 0.7440\n",
            "Epoch 404/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1806 - accuracy: 0.9371 - val_loss: 0.9079 - val_accuracy: 0.7295\n",
            "Epoch 405/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2249 - accuracy: 0.9256 - val_loss: 0.8877 - val_accuracy: 0.7440\n",
            "Epoch 406/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1839 - accuracy: 0.9317 - val_loss: 0.8069 - val_accuracy: 0.7633\n",
            "Epoch 407/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2012 - accuracy: 0.9305 - val_loss: 0.7888 - val_accuracy: 0.7826\n",
            "Epoch 408/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2187 - accuracy: 0.9232 - val_loss: 0.9251 - val_accuracy: 0.7440\n",
            "Epoch 409/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1817 - accuracy: 0.9323 - val_loss: 0.8062 - val_accuracy: 0.7633\n",
            "Epoch 410/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2042 - accuracy: 0.9287 - val_loss: 0.8364 - val_accuracy: 0.7536\n",
            "Epoch 411/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1800 - accuracy: 0.9353 - val_loss: 0.8833 - val_accuracy: 0.7488\n",
            "Epoch 412/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1786 - accuracy: 0.9383 - val_loss: 0.8136 - val_accuracy: 0.7729\n",
            "Epoch 413/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1901 - accuracy: 0.9383 - val_loss: 0.8676 - val_accuracy: 0.7585\n",
            "Epoch 414/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1882 - accuracy: 0.9311 - val_loss: 0.8123 - val_accuracy: 0.7681\n",
            "Epoch 415/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1810 - accuracy: 0.9311 - val_loss: 0.9569 - val_accuracy: 0.7246\n",
            "Epoch 416/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1999 - accuracy: 0.9250 - val_loss: 0.7610 - val_accuracy: 0.8164\n",
            "Epoch 417/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1737 - accuracy: 0.9365 - val_loss: 0.8057 - val_accuracy: 0.7778\n",
            "Epoch 418/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1758 - accuracy: 0.9299 - val_loss: 1.0225 - val_accuracy: 0.6957\n",
            "Epoch 419/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1893 - accuracy: 0.9317 - val_loss: 0.8450 - val_accuracy: 0.7440\n",
            "Epoch 420/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2075 - accuracy: 0.9238 - val_loss: 0.8581 - val_accuracy: 0.7440\n",
            "Epoch 421/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2001 - accuracy: 0.9329 - val_loss: 0.8520 - val_accuracy: 0.7633\n",
            "Epoch 422/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1820 - accuracy: 0.9335 - val_loss: 0.8852 - val_accuracy: 0.7536\n",
            "Epoch 423/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1735 - accuracy: 0.9335 - val_loss: 0.9093 - val_accuracy: 0.7488\n",
            "Epoch 424/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1601 - accuracy: 0.9480 - val_loss: 0.7990 - val_accuracy: 0.8019\n",
            "Epoch 425/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1872 - accuracy: 0.9353 - val_loss: 0.7763 - val_accuracy: 0.7729\n",
            "Epoch 426/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1876 - accuracy: 0.9256 - val_loss: 0.9279 - val_accuracy: 0.7488\n",
            "Epoch 427/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1648 - accuracy: 0.9359 - val_loss: 0.8872 - val_accuracy: 0.7633\n",
            "Epoch 428/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2088 - accuracy: 0.9341 - val_loss: 0.8641 - val_accuracy: 0.7681\n",
            "Epoch 429/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1635 - accuracy: 0.9438 - val_loss: 0.8614 - val_accuracy: 0.7923\n",
            "Epoch 430/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1811 - accuracy: 0.9335 - val_loss: 0.9157 - val_accuracy: 0.7681\n",
            "Epoch 431/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2039 - accuracy: 0.9347 - val_loss: 0.8634 - val_accuracy: 0.7874\n",
            "Epoch 432/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1593 - accuracy: 0.9456 - val_loss: 0.8250 - val_accuracy: 0.7923\n",
            "Epoch 433/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1837 - accuracy: 0.9395 - val_loss: 0.9006 - val_accuracy: 0.7391\n",
            "Epoch 434/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1616 - accuracy: 0.9371 - val_loss: 0.8380 - val_accuracy: 0.7778\n",
            "Epoch 435/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2291 - accuracy: 0.9274 - val_loss: 0.8795 - val_accuracy: 0.7633\n",
            "Epoch 436/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1978 - accuracy: 0.9262 - val_loss: 0.8063 - val_accuracy: 0.7874\n",
            "Epoch 437/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1731 - accuracy: 0.9456 - val_loss: 0.8109 - val_accuracy: 0.7729\n",
            "Epoch 438/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1745 - accuracy: 0.9365 - val_loss: 0.8414 - val_accuracy: 0.7826\n",
            "Epoch 439/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1773 - accuracy: 0.9450 - val_loss: 0.8770 - val_accuracy: 0.7440\n",
            "Epoch 440/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1956 - accuracy: 0.9359 - val_loss: 0.8179 - val_accuracy: 0.7633\n",
            "Epoch 441/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1646 - accuracy: 0.9407 - val_loss: 0.9397 - val_accuracy: 0.7585\n",
            "Epoch 442/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1911 - accuracy: 0.9347 - val_loss: 0.7518 - val_accuracy: 0.7826\n",
            "Epoch 443/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1842 - accuracy: 0.9323 - val_loss: 0.8245 - val_accuracy: 0.7681\n",
            "Epoch 444/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1781 - accuracy: 0.9389 - val_loss: 0.9448 - val_accuracy: 0.7391\n",
            "Epoch 445/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1916 - accuracy: 0.9353 - val_loss: 0.8259 - val_accuracy: 0.7536\n",
            "Epoch 446/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1855 - accuracy: 0.9341 - val_loss: 0.9882 - val_accuracy: 0.7343\n",
            "Epoch 447/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1904 - accuracy: 0.9335 - val_loss: 0.8895 - val_accuracy: 0.7440\n",
            "Epoch 448/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1691 - accuracy: 0.9389 - val_loss: 0.9525 - val_accuracy: 0.7391\n",
            "Epoch 449/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1763 - accuracy: 0.9438 - val_loss: 0.9134 - val_accuracy: 0.7681\n",
            "Epoch 450/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1769 - accuracy: 0.9444 - val_loss: 0.9572 - val_accuracy: 0.7440\n",
            "Epoch 451/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1782 - accuracy: 0.9377 - val_loss: 0.8685 - val_accuracy: 0.7729\n",
            "Epoch 452/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1660 - accuracy: 0.9383 - val_loss: 0.7191 - val_accuracy: 0.8068\n",
            "Epoch 453/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2030 - accuracy: 0.9274 - val_loss: 0.7751 - val_accuracy: 0.7971\n",
            "Epoch 454/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1669 - accuracy: 0.9407 - val_loss: 0.8146 - val_accuracy: 0.7585\n",
            "Epoch 455/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1481 - accuracy: 0.9450 - val_loss: 0.9189 - val_accuracy: 0.7536\n",
            "Epoch 456/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1755 - accuracy: 0.9371 - val_loss: 0.8665 - val_accuracy: 0.7633\n",
            "Epoch 457/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1617 - accuracy: 0.9383 - val_loss: 0.8512 - val_accuracy: 0.7633\n",
            "Epoch 458/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1715 - accuracy: 0.9468 - val_loss: 0.8134 - val_accuracy: 0.7585\n",
            "Epoch 459/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1708 - accuracy: 0.9365 - val_loss: 0.8615 - val_accuracy: 0.7681\n",
            "Epoch 460/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1560 - accuracy: 0.9486 - val_loss: 0.9836 - val_accuracy: 0.7488\n",
            "Epoch 461/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1733 - accuracy: 0.9347 - val_loss: 0.8194 - val_accuracy: 0.7923\n",
            "Epoch 462/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1852 - accuracy: 0.9414 - val_loss: 0.8717 - val_accuracy: 0.7681\n",
            "Epoch 463/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1711 - accuracy: 0.9383 - val_loss: 0.9250 - val_accuracy: 0.7585\n",
            "Epoch 464/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1829 - accuracy: 0.9359 - val_loss: 1.0309 - val_accuracy: 0.7295\n",
            "Epoch 465/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1580 - accuracy: 0.9420 - val_loss: 0.9284 - val_accuracy: 0.7536\n",
            "Epoch 466/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1555 - accuracy: 0.9510 - val_loss: 0.9110 - val_accuracy: 0.7295\n",
            "Epoch 467/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1545 - accuracy: 0.9450 - val_loss: 0.8363 - val_accuracy: 0.7826\n",
            "Epoch 468/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1642 - accuracy: 0.9492 - val_loss: 0.8951 - val_accuracy: 0.7729\n",
            "Epoch 469/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1625 - accuracy: 0.9420 - val_loss: 0.8836 - val_accuracy: 0.7681\n",
            "Epoch 470/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1619 - accuracy: 0.9341 - val_loss: 0.9490 - val_accuracy: 0.7778\n",
            "Epoch 471/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1753 - accuracy: 0.9401 - val_loss: 0.9338 - val_accuracy: 0.7536\n",
            "Epoch 472/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1578 - accuracy: 0.9432 - val_loss: 0.8588 - val_accuracy: 0.7440\n",
            "Epoch 473/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1560 - accuracy: 0.9510 - val_loss: 0.9115 - val_accuracy: 0.7874\n",
            "Epoch 474/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1634 - accuracy: 0.9407 - val_loss: 0.9026 - val_accuracy: 0.7778\n",
            "Epoch 475/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1759 - accuracy: 0.9432 - val_loss: 0.8377 - val_accuracy: 0.7633\n",
            "Epoch 476/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1559 - accuracy: 0.9528 - val_loss: 0.9146 - val_accuracy: 0.8164\n",
            "Epoch 477/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1624 - accuracy: 0.9444 - val_loss: 0.7808 - val_accuracy: 0.7729\n",
            "Epoch 478/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1753 - accuracy: 0.9407 - val_loss: 0.8597 - val_accuracy: 0.7440\n",
            "Epoch 479/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1471 - accuracy: 0.9450 - val_loss: 0.8002 - val_accuracy: 0.7778\n",
            "Epoch 480/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1633 - accuracy: 0.9401 - val_loss: 0.9610 - val_accuracy: 0.7729\n",
            "Epoch 481/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1919 - accuracy: 0.9432 - val_loss: 0.8718 - val_accuracy: 0.7874\n",
            "Epoch 482/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1663 - accuracy: 0.9407 - val_loss: 1.0424 - val_accuracy: 0.7295\n",
            "Epoch 483/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1656 - accuracy: 0.9353 - val_loss: 0.9143 - val_accuracy: 0.7488\n",
            "Epoch 484/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1451 - accuracy: 0.9486 - val_loss: 0.7619 - val_accuracy: 0.7729\n",
            "Epoch 485/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1498 - accuracy: 0.9468 - val_loss: 0.8692 - val_accuracy: 0.7923\n",
            "Epoch 486/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1379 - accuracy: 0.9516 - val_loss: 0.9174 - val_accuracy: 0.7440\n",
            "Epoch 487/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1720 - accuracy: 0.9383 - val_loss: 0.8868 - val_accuracy: 0.7488\n",
            "Epoch 488/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1621 - accuracy: 0.9432 - val_loss: 0.8971 - val_accuracy: 0.7246\n",
            "Epoch 489/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1387 - accuracy: 0.9474 - val_loss: 0.8364 - val_accuracy: 0.8019\n",
            "Epoch 490/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1567 - accuracy: 0.9438 - val_loss: 0.8503 - val_accuracy: 0.7681\n",
            "Epoch 491/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1646 - accuracy: 0.9486 - val_loss: 0.8707 - val_accuracy: 0.7681\n",
            "Epoch 492/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1503 - accuracy: 0.9450 - val_loss: 0.8938 - val_accuracy: 0.7633\n",
            "Epoch 493/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1411 - accuracy: 0.9498 - val_loss: 0.9256 - val_accuracy: 0.7778\n",
            "Epoch 494/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1502 - accuracy: 0.9438 - val_loss: 0.9831 - val_accuracy: 0.7440\n",
            "Epoch 495/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1755 - accuracy: 0.9426 - val_loss: 0.9238 - val_accuracy: 0.7681\n",
            "Epoch 496/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1672 - accuracy: 0.9377 - val_loss: 0.8849 - val_accuracy: 0.7874\n",
            "Epoch 497/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1474 - accuracy: 0.9504 - val_loss: 1.0595 - val_accuracy: 0.7536\n",
            "Epoch 498/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1644 - accuracy: 0.9444 - val_loss: 0.8812 - val_accuracy: 0.7874\n",
            "Epoch 499/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1423 - accuracy: 0.9492 - val_loss: 0.9113 - val_accuracy: 0.7633\n",
            "Epoch 500/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1502 - accuracy: 0.9462 - val_loss: 0.9147 - val_accuracy: 0.7729\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(cnnhistory.history['loss'])\n",
        "plt.plot(cnnhistory.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train','test'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "oQYnuaCrDH_A",
        "outputId": "48e22ddf-3857-47bd-b832-944c23ae1ad3"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(cnnhistory.history['accuracy'])\n",
        "plt.plot(cnnhistory.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train','test'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "IFkTuO8nDNdq",
        "outputId": "80bfbba2-7d2c-48ef-e6a7-0fe323b44c85"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#predictions = model.predict_classes(x_testcnn)\n",
        "predictions = model.predict(x_testcnn)"
      ],
      "metadata": {
        "id": "A2xtrN5wDQgY"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_f_ohjXKDUpY",
        "outputId": "6de47589-eeb2-49f2-aac8-d603e98ca7f1"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.12601828e-09, 2.43268766e-10, 1.24593666e-02, 5.83344729e-07,\n",
              "        1.07255466e-02, 9.76814449e-01],\n",
              "       [2.54928484e-03, 9.96355057e-01, 3.27709313e-05, 5.93351084e-04,\n",
              "        3.34026408e-04, 1.35537979e-04],\n",
              "       [1.31811044e-06, 3.71026144e-05, 9.86826777e-01, 1.11948555e-06,\n",
              "        1.00054946e-02, 3.12811323e-03],\n",
              "       ...,\n",
              "       [1.92413590e-05, 6.38473011e-07, 8.68757372e-04, 3.55211640e-04,\n",
              "        9.82189000e-01, 1.65671930e-02],\n",
              "       [4.11505438e-03, 3.28025557e-02, 8.46304829e-05, 8.48779917e-01,\n",
              "        1.76031099e-05, 1.14200294e-01],\n",
              "       [4.90264624e-01, 2.37941742e-02, 1.58909964e-03, 1.01493195e-01,\n",
              "        3.82813990e-01, 4.49559229e-05]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cmA2bFgsDW3D",
        "outputId": "5ac2eeb8-1673-4f43-e36a-202b835ae49b"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5, 1, 2, 5, 3, 4, 2, 0, 3, 1, 3, 2, 1, 4, 3, 0, 5, 0, 2, 5, 0, 0,\n",
              "       1, 3, 2, 3, 2, 5, 4, 2, 2, 3, 1, 2, 5, 5, 3, 5, 3, 3, 4, 1, 3, 2,\n",
              "       3, 1, 5, 3, 1, 2, 4, 4, 5, 5, 5, 1, 2, 3, 2, 5, 0, 2, 4, 2, 5, 4,\n",
              "       3, 0, 1, 2, 5, 2, 1, 2, 4, 5, 4, 1, 5, 5, 3, 1, 5, 3, 2, 4, 2, 5,\n",
              "       0, 5, 0, 5, 4, 0, 2, 4, 0, 2, 2, 0, 2, 3, 5, 3, 5, 5, 3, 1, 2, 2,\n",
              "       2, 1, 3, 2, 1, 3, 4, 4, 1, 1, 2, 4, 4, 1, 4, 2, 0, 4, 5, 5, 3, 1,\n",
              "       2, 1, 5, 5, 1, 2, 3, 3, 0, 3, 3, 0, 1, 0, 1, 2, 1, 5, 1, 2, 2, 0,\n",
              "       1, 1, 1, 1, 1, 4, 0, 1, 5, 1, 4, 5, 5, 4, 1, 0, 3, 5, 2, 3, 0, 4,\n",
              "       1, 3, 1, 0, 5, 5, 3, 5, 4, 5, 4, 0, 4, 1, 2, 1, 5, 0, 4, 3, 2, 1,\n",
              "       0, 3, 5, 0, 4, 5, 4, 5, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_Ytest = y_test.astype(int)"
      ],
      "metadata": {
        "id": "0PHDKWJWDY3g"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_Ytest"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k68v2i-pDbZE",
        "outputId": "ea628de3-b545-45cd-da5b-a64206a6760e"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5, 1, 2, 5, 3, 4, 2, 0, 3, 1, 3, 2, 1, 4, 3, 0, 5, 0, 2, 5, 0, 0,\n",
              "       1, 3, 2, 3, 2, 5, 4, 2, 2, 3, 1, 2, 5, 5, 3, 5, 3, 3, 4, 1, 3, 2,\n",
              "       3, 1, 5, 3, 1, 2, 4, 4, 5, 5, 5, 1, 2, 3, 2, 5, 0, 2, 4, 2, 5, 4,\n",
              "       3, 0, 1, 2, 5, 2, 1, 2, 4, 5, 4, 1, 5, 5, 3, 1, 5, 3, 2, 4, 2, 5,\n",
              "       0, 5, 0, 5, 4, 0, 2, 4, 0, 2, 2, 0, 2, 3, 5, 3, 5, 5, 3, 1, 2, 2,\n",
              "       2, 1, 3, 2, 1, 3, 4, 4, 1, 1, 2, 4, 4, 1, 4, 2, 0, 4, 5, 5, 3, 1,\n",
              "       2, 1, 5, 5, 1, 2, 3, 3, 0, 3, 3, 0, 1, 0, 1, 2, 1, 5, 1, 2, 2, 0,\n",
              "       1, 1, 1, 1, 1, 4, 0, 1, 5, 1, 4, 5, 5, 4, 1, 0, 3, 5, 2, 3, 0, 4,\n",
              "       1, 3, 1, 0, 5, 5, 3, 5, 4, 5, 4, 0, 4, 1, 2, 1, 5, 0, 4, 3, 2, 1,\n",
              "       0, 3, 5, 0, 4, 5, 4, 5, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds1=predictions.argmax(axis=1)\n",
        "preds1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4_cAI39VFhtp",
        "outputId": "9fbb2b41-e176-47e9-9d29-9d6e7f47d604"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5, 1, 2, 5, 3, 4, 2, 0, 3, 0, 3, 2, 1, 4, 3, 0, 5, 5, 2, 5, 0, 0,\n",
              "       1, 3, 4, 5, 2, 5, 4, 2, 2, 3, 1, 2, 5, 5, 1, 2, 3, 2, 4, 1, 2, 2,\n",
              "       3, 1, 3, 3, 1, 0, 4, 4, 5, 5, 3, 1, 2, 3, 5, 2, 0, 2, 4, 2, 5, 4,\n",
              "       0, 1, 1, 2, 3, 2, 1, 2, 4, 5, 4, 1, 5, 5, 3, 1, 5, 3, 2, 4, 2, 5,\n",
              "       0, 5, 0, 5, 4, 0, 3, 4, 3, 4, 2, 0, 2, 3, 5, 3, 5, 5, 5, 1, 2, 2,\n",
              "       2, 1, 3, 2, 1, 3, 4, 4, 1, 1, 2, 4, 4, 1, 4, 2, 0, 4, 5, 5, 5, 1,\n",
              "       4, 1, 5, 5, 1, 3, 3, 3, 0, 3, 5, 0, 1, 0, 1, 2, 1, 5, 0, 2, 2, 0,\n",
              "       1, 1, 1, 1, 1, 4, 0, 1, 5, 1, 4, 5, 5, 2, 1, 0, 5, 5, 2, 3, 3, 4,\n",
              "       1, 3, 1, 5, 5, 2, 3, 5, 4, 5, 0, 0, 4, 0, 2, 1, 3, 0, 4, 1, 2, 1,\n",
              "       1, 4, 5, 3, 2, 5, 4, 3, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "abc = preds1.astype(int).flatten()"
      ],
      "metadata": {
        "id": "H4WEmM60NfQn"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "c = confusion_matrix(new_Ytest, abc) \n",
        "c"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bKEBeEBlFjB8",
        "outputId": "a561e044-af1d-4b72-c1e6-74d325884ccc"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[18,  2,  0,  3,  0,  2],\n",
              "       [ 3, 36,  0,  0,  0,  0],\n",
              "       [ 1,  0, 31,  2,  3,  1],\n",
              "       [ 1,  2,  2, 22,  1,  5],\n",
              "       [ 2,  0,  2,  0, 26,  0],\n",
              "       [ 0,  0,  3,  5,  0, 34]])"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m4RjG7LWLSQx",
        "outputId": "8ca6356f-ba0d-481c-f8d3-1f4f0d8c88aa"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5, 1, 2, 5, 3, 4, 2, 0, 3, 1, 3, 2, 1, 4, 3, 0, 5, 0, 2, 5, 0, 0,\n",
              "       1, 3, 2, 3, 2, 5, 4, 2, 2, 3, 1, 2, 5, 5, 3, 5, 3, 3, 4, 1, 3, 2,\n",
              "       3, 1, 5, 3, 1, 2, 4, 4, 5, 5, 5, 1, 2, 3, 2, 5, 0, 2, 4, 2, 5, 4,\n",
              "       3, 0, 1, 2, 5, 2, 1, 2, 4, 5, 4, 1, 5, 5, 3, 1, 5, 3, 2, 4, 2, 5,\n",
              "       0, 5, 0, 5, 4, 0, 2, 4, 0, 2, 2, 0, 2, 3, 5, 3, 5, 5, 3, 1, 2, 2,\n",
              "       2, 1, 3, 2, 1, 3, 4, 4, 1, 1, 2, 4, 4, 1, 4, 2, 0, 4, 5, 5, 3, 1,\n",
              "       2, 1, 5, 5, 1, 2, 3, 3, 0, 3, 3, 0, 1, 0, 1, 2, 1, 5, 1, 2, 2, 0,\n",
              "       1, 1, 1, 1, 1, 4, 0, 1, 5, 1, 4, 5, 5, 4, 1, 0, 3, 5, 2, 3, 0, 4,\n",
              "       1, 3, 1, 0, 5, 5, 3, 5, 4, 5, 4, 0, 4, 1, 2, 1, 5, 0, 4, 3, 2, 1,\n",
              "       0, 3, 5, 0, 4, 5, 4, 5, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('/content/drive/My Drive/graduation project/audio/paper_code/mariam/original_500 epoch_with_valid_Adam2_3')\n",
        "print(\"MODEL SAVED\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lsJBNeMWDl6Z",
        "outputId": "7f402e9d-be44-41be-9722-f17d86a620f5"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/graduation project/audio/paper_code/mariam/original_500 epoch_with_valid_Adam2_3/assets\n",
            "MODEL SAVED\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_model=keras.models.load_model('/content/drive/My Drive/graduation project/audio/paper_code/mariam/original_500 epoch_with_valid_Adam2_3')\n",
        "new_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q3KjaO9GDoNl",
        "outputId": "7460311c-bc67-4833-d5b2-e90cd5ffa6f4"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d (Conv1D)             (None, 40, 128)           1152      \n",
            "                                                                 \n",
            " activation (Activation)     (None, 40, 128)           0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 40, 128)           0         \n",
            "                                                                 \n",
            " max_pooling1d (MaxPooling1D  (None, 8, 128)           0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv1d_1 (Conv1D)           (None, 8, 256)            262400    \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 8, 256)            0         \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 8, 256)            0         \n",
            "                                                                 \n",
            " max_pooling1d_1 (MaxPooling  (None, 1, 256)           0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 256)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 256)               65792     \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 256)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 256)               65792     \n",
            "                                                                 \n",
            " activation_3 (Activation)   (None, 256)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 6)                 1542      \n",
            "                                                                 \n",
            " activation_4 (Activation)   (None, 6)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 396,678\n",
            "Trainable params: 396,678\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss, acc =model.evaluate(x_testcnn, y_test)\n",
        "print(\"Restored model, accuracy: {:5.2f}%\".format(100*acc))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n3kzoqPkDqqS",
        "outputId": "c2ced777-800f-43f8-d913-e7686c520853"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7/7 [==============================] - 0s 4ms/step - loss: 0.5916 - accuracy: 0.8068\n",
            "Restored model, accuracy: 80.68%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss, acc =model.evaluate(X_train, y_train)\n",
        "print(\"Restored model train, accuracy: {:5.2f}%\".format(100*acc))"
      ],
      "metadata": {
        "id": "fJDTGH_OUX0z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cad19d21-3712-4318-90a4-6e92ad07748f"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "52/52 [==============================] - 0s 4ms/step - loss: 0.0447 - accuracy: 0.9946\n",
            "Restored model train, accuracy: 99.46%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix,accuracy_score\n",
        "import seaborn as sn\n",
        "\n",
        "print(classification_report(new_Ytest,abc))\n",
        "\n",
        "acc = float(accuracy_score(new_Ytest,abc))*100\n",
        "print(\"----accuracy score %s ----\" % acc)\n",
        "\n",
        "cm = confusion_matrix(new_Ytest,abc)\n",
        "#df_cm = pd.DataFrame(cm)\n",
        "class_names = ['neutral','calm', 'happy','sad','angry', 'fearful' ]\n",
        "df_cm = pd.DataFrame(cm, index=class_names, columns=class_names,)\n",
        "sn.heatmap(df_cm, annot=True, fmt='')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 517
        },
        "id": "SfSC3El94LZg",
        "outputId": "dc1d0047-2998-4f4a-c216-e29b9193d23f"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.72      0.72      0.72        25\n",
            "           1       0.90      0.92      0.91        39\n",
            "           2       0.82      0.82      0.82        38\n",
            "           3       0.69      0.67      0.68        33\n",
            "           4       0.87      0.87      0.87        30\n",
            "           5       0.81      0.81      0.81        42\n",
            "\n",
            "    accuracy                           0.81       207\n",
            "   macro avg       0.80      0.80      0.80       207\n",
            "weighted avg       0.81      0.81      0.81       207\n",
            "\n",
            "----accuracy score 80.67632850241546 ----\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "LGpgwFQqkpyU"
      },
      "execution_count": 37,
      "outputs": []
    }
  ]
}