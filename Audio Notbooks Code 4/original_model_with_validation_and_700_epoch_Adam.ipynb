{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "original model with validation and 700 epoch_Adam.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9SRCO-a_AlH5",
        "outputId": "212fea85-7439-450a-ccd6-32900a03187e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install librosa"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oi8pWV3yBVjO",
        "outputId": "629090db-7020-4729-e6a2-3f3db2971e35"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: librosa in /usr/local/lib/python3.7/dist-packages (0.8.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (21.3)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.21.5)\n",
            "Requirement already satisfied: numba>=0.43.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (0.51.2)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.0.2)\n",
            "Requirement already satisfied: resampy>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from librosa) (0.2.2)\n",
            "Requirement already satisfied: soundfile>=0.10.2 in /usr/local/lib/python3.7/dist-packages (from librosa) (0.10.3.post1)\n",
            "Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.6.0)\n",
            "Requirement already satisfied: audioread>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (2.1.9)\n",
            "Requirement already satisfied: decorator>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.1.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba>=0.43.0->librosa) (57.4.0)\n",
            "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba>=0.43.0->librosa) (0.34.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->librosa) (3.0.7)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from pooch>=1.0->librosa) (2.23.0)\n",
            "Requirement already satisfied: appdirs>=1.3.0 in /usr/local/lib/python3.7/dist-packages (from pooch>=1.0->librosa) (1.4.4)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2021.10.8)\n",
            "Requirement already satisfied: six>=1.3 in /usr/local/lib/python3.7/dist-packages (from resampy>=0.2.2->librosa) (1.15.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn!=0.19.0,>=0.14.0->librosa) (3.1.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.7/dist-packages (from soundfile>=0.10.2->librosa) (1.15.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.0->soundfile>=0.10.2->librosa) (2.21)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "wsaoikiQGfqd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HJjcbxwy46bG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "c94140e5-1cb4-4e69-d59b-ef793e72652a"
      },
      "source": [
        "# Orignial Notebook: https://github.com/MITESHPUTHRANNEU/Speech-Emotion-Analyzer/blob/master/final_results_gender_test.ipynb\n",
        "# This notebook author: Reza Chu\n",
        "# Last Editing Date: 31st May 2019\n",
        "\n",
        "## Python\n",
        "import os\n",
        "import random\n",
        "import sys\n",
        "\n",
        "import IPython\n",
        "from IPython.display import Audio\n",
        "from IPython.display import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "## Package\n",
        "import glob \n",
        "import keras\n",
        "import IPython.display as ipd\n",
        "import librosa\n",
        "import librosa.display\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import plotly.graph_objs as go\n",
        "import plotly.offline as py\n",
        "import plotly.tools as tls\n",
        "import seaborn as sns\n",
        "import scipy.io.wavfile\n",
        "import tensorflow as tf\n",
        "py.init_notebook_mode(connected=True)\n",
        "\n",
        "## Keras\n",
        "from keras import regularizers\n",
        "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping\n",
        "from keras.callbacks import  History, ReduceLROnPlateau, CSVLogger\n",
        "from keras.models import Model, Sequential\n",
        "from keras.layers import Dense, Embedding, LSTM\n",
        "from keras.layers import Input, Flatten, Dropout, Activation, BatchNormalization\n",
        "from keras.layers import Conv1D, MaxPooling1D, AveragePooling1D\n",
        "from keras.preprocessing import sequence\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.utils import np_utils\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "## Sklearn\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "## Rest\n",
        "from scipy.fftpack import fft\n",
        "from scipy import signal\n",
        "from scipy.io import wavfile\n",
        "from tqdm import tqdm\n",
        "\n",
        "input_duration=3\n",
        "# % pylab inline"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "        <script type=\"text/javascript\">\n",
              "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
              "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
              "        if (typeof require !== 'undefined') {\n",
              "        require.undef(\"plotly\");\n",
              "        requirejs.config({\n",
              "            paths: {\n",
              "                'plotly': ['https://cdn.plot.ly/plotly-2.8.3.min']\n",
              "            }\n",
              "        });\n",
              "        require(['plotly'], function(Plotly) {\n",
              "            window._Plotly = Plotly;\n",
              "        });\n",
              "        }\n",
              "        </script>\n",
              "        "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#radvass speech and song\n",
        "import time\n",
        "import os\n",
        "import librosa\n",
        "from librosa import display\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "count=0\n",
        "path1 = '/content/drive/My Drive/data_set/RAVDESS_speech'\n",
        "path2 = '/content/drive/My Drive/data_set/RAVDESS_song'\n",
        "\n",
        "lst = []\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "for subdir, dirs, files in os.walk(path2):\n",
        "  print(dirs)\n",
        "  print(subdir)\n",
        "  #print(files)\n",
        "  for file in files:\n",
        "      try:\n",
        "        count +=1\n",
        "        #Load librosa array, obtain mfcss, store the file and the mcss information in a new array\n",
        "        X, sample_rate = librosa.load(os.path.join(subdir,file), res_type='kaiser_fast')\n",
        "        mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T,axis=0) \n",
        "        # The instruction below converts the labels (from 1 to 8) to a series from 0 to 7\n",
        "        # This is because our predictor needs to start from 0 otherwise it will try to predict also 0.\n",
        "        file = int(file[7:8]) - 1 \n",
        "        arr = mfccs, file\n",
        "        lst.append(arr)\n",
        "      # If the file is not valid, skip it\n",
        "      except ValueError:\n",
        "        continue\n",
        "\n",
        "for subdir, dirs, files in os.walk(path1):\n",
        "  print(dirs)\n",
        "  print(subdir)\n",
        " # print(files)\n",
        "  for file in files:\n",
        "      try:\n",
        "        #Load librosa array, obtain mfcss, store the file and the mcss information in a new array\n",
        "        X, sample_rate = librosa.load(os.path.join(subdir,file), res_type='kaiser_fast')\n",
        "        mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T,axis=0) \n",
        "        # The instruction below converts the labels (from 1 to 8) to a series from 0 to 7\n",
        "        # This is because our predictor needs to start from 0 otherwise it will try to predict also 0.\n",
        "        file = int(file[7:8]) - 1 \n",
        "        if(file ==6 or file==7):\n",
        "          continue\n",
        "        count +=1\n",
        "        arr = mfccs, file\n",
        "        lst.append(arr)\n",
        "      # If the file is not valid, skip it\n",
        "      except ValueError:\n",
        "        continue\n",
        "\n",
        "\n",
        "\n",
        "print(\"--- Data loaded. Loading time: %s seconds ---\" % (time.time() - start_time))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IfuyRZl42ccZ",
        "outputId": "d877cfc3-d4b0-47a9-8076-a9a539d24c7a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Actor_10', 'Actor_11', 'Actor_13', 'Actor_12', 'Actor_14', 'Actor_15', 'Actor_16', 'Actor_17', 'Actor_18', 'Actor_19', 'Actor_21', 'Actor_22', 'Actor_23', 'Actor_09', 'Actor_24', 'Actor_04', 'Actor_08', 'Actor_03', 'Actor_02', 'Actor_06', 'Actor_05', 'Actor_01', 'Actor_07', 'Actor_20']\n",
            "/content/drive/My Drive/data_set/RAVDESS_song\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_song/Actor_10\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_song/Actor_11\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_song/Actor_13\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_song/Actor_12\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_song/Actor_14\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_song/Actor_15\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_song/Actor_16\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_song/Actor_17\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_song/Actor_18\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_song/Actor_19\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_song/Actor_21\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_song/Actor_22\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_song/Actor_23\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_song/Actor_09\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_song/Actor_24\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_song/Actor_04\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_song/Actor_08\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_song/Actor_03\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_song/Actor_02\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_song/Actor_06\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_song/Actor_05\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_song/Actor_01\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_song/Actor_07\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_song/Actor_20\n",
            "['Actor_05', 'Actor_08', 'Actor_10', 'Actor_04', 'Actor_09', 'Actor_14', 'Actor_12', 'Actor_13', 'Actor_11', 'Actor_06', 'Actor_24', 'Actor_07', 'Actor_23', 'Actor_22', 'Actor_21', 'Actor_20', 'Actor_02', 'Actor_19', 'Actor_18', 'Actor_17', 'Actor_16', 'Actor_15', 'Actor_03', 'Actor_01']\n",
            "/content/drive/My Drive/data_set/RAVDESS_speech\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_speech/Actor_05\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_speech/Actor_08\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_speech/Actor_10\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_speech/Actor_04\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_speech/Actor_09\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_speech/Actor_14\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_speech/Actor_12\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_speech/Actor_13\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_speech/Actor_11\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_speech/Actor_06\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_speech/Actor_24\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_speech/Actor_07\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_speech/Actor_23\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_speech/Actor_22\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_speech/Actor_21\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_speech/Actor_20\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_speech/Actor_02\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_speech/Actor_19\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_speech/Actor_18\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_speech/Actor_17\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_speech/Actor_16\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_speech/Actor_15\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_speech/Actor_03\n",
            "[]\n",
            "/content/drive/My Drive/data_set/RAVDESS_speech/Actor_01\n",
            "--- Data loaded. Loading time: 253.29601573944092 seconds ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "count"
      ],
      "metadata": {
        "id": "Ltlhi25L2AI5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22a61d13-8096-4218-faac-c8c402062422"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2068"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy.core.fromnumeric import size\n",
        "size(lst)"
      ],
      "metadata": {
        "id": "HMOH7d7mzHB7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27ace98d-9ea2-4dd1-bee5-141c6a6b242a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/core/fromnumeric.py:3208: VisibleDeprecationWarning:\n",
            "\n",
            "Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4136"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating X and y: zip makes a list of all the first elements, and a list of all the second elements.\n",
        "X, y = zip(*lst)"
      ],
      "metadata": {
        "id": "ocdL7tSTBoMt"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "X = np.asarray(X)\n",
        "y = np.asarray(y)\n",
        "X.shape, y.shape"
      ],
      "metadata": {
        "id": "vHKwUGTbBtnF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fbad0df0-aeb3-4277-ae96-0ce418ec7c4c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((2068, 40), (2068,))"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "id": "2sUCtbfMztE5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f277254f-1154-443d-9f70-eb53665e98d5"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2068, 40)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Saving joblib files to not load them again with the loop above\n",
        "\n",
        "import joblib\n",
        "\n",
        "X_name = 'saveex5.joblib'\n",
        "y_name = 'saveey5.joblib'\n",
        "save_dir = '/content/drive/My Drive/graduation project/audio/improvement1/features'\n",
        "\n",
        "savedX = joblib.dump(X, os.path.join(save_dir, X_name))\n",
        "savedy = joblib.dump(y, os.path.join(save_dir, y_name))"
      ],
      "metadata": {
        "id": "UCzic8rlDcuk"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading saved models\n",
        "import joblib\n",
        "X = joblib.load('/content/drive/My Drive/models/CNN_2/last/features/speech&songx6.joblib')\n",
        "y = joblib.load('/content/drive/My Drive/models/CNN_2/last/features/speech&songy6.joblib')"
      ],
      "metadata": {
        "id": "Q35CN6zDrzg1"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2,train_size=0.8, random_state=42)\n",
        "X_valid, X_test, y_valid, y_test = train_test_split(X_test,y_test, test_size=0.5,train_size=0.5, random_state=42)"
      ],
      "metadata": {
        "id": "Ai4Fy5cPCiq1"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7PSTurzjCo5K",
        "outputId": "292f612d-2ff3-42ae-c5a3-db8444973578"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2068, 40)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "x_traincnn = np.expand_dims(X_train, axis=2)\n",
        "x_testcnn = np.expand_dims(X_test, axis=2)\n",
        "X_valid= np.expand_dims(X_valid, axis=2)"
      ],
      "metadata": {
        "id": "tp1Fm5K3CEXu"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_traincnn.shape, x_testcnn.shape , X_valid.shape"
      ],
      "metadata": {
        "id": "RI0MxoIPBws5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b06c4527-c4fc-41b3-dc5d-1c1433c1ecc1"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1654, 40, 1), (207, 40, 1), (207, 40, 1))"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow"
      ],
      "metadata": {
        "id": "goxL4Y3jKICC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ded6c33b-f244-4ed6-becd-892d17044ce4"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (2.8.0)\n",
            "Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n",
            "Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.5.3)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.0.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.13.3)\n",
            "Requirement already satisfied: tf-estimator-nightly==2.8.0.dev2021122109 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0.dev2021122109)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.24.0)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.21.5)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (13.0.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.17.3)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow) (57.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.10.0.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.44.0)\n",
            "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow) (1.5.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.35.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.4.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.23.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (3.3.6)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.8.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.6.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.8)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.2.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (4.11.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (3.7.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (1.24.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (3.2.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keras"
      ],
      "metadata": {
        "id": "EkcmN9UrKSxj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a20517b6-94a4-4661-9d2a-6d5abdc2eb15"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: keras in /usr/local/lib/python3.7/dist-packages (2.8.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from keras.preprocessing import sequence\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from keras.layers import Input, Flatten, Dropout, Activation\n",
        "from keras.layers import Conv1D, MaxPooling1D\n",
        "from keras.models import Model\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras import optimizers\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv1D(128, 8,padding='same', #classifier.add(Convolution2D(64, (3, 3), padding = 'same', input_shape = (128, 128, 3), activation = 'relu'))\n",
        "                 input_shape=(40,1)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(MaxPooling1D(pool_size=(5)))\n",
        "\n",
        "\n",
        "model.add(Conv1D(256,8,padding='same',))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(MaxPooling1D(pool_size=(5)))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(256))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(256))\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "model.add(Dense(6))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "opt = tf.keras.optimizers.Adam(lr=0.00002)\n",
        "#opt = tf.keras.optimizers.RMSprop(lr=0.0001, rho=0.9, epsilon=1e-07, decay=0.0)\n",
        "#opt = tf.keras.optimizers.SGD(lr=0.0001, momentum=0.0, decay=0.0, nesterov=False)"
      ],
      "metadata": {
        "id": "g74fXWVAC4Cr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3b85f96-ae7d-4972-be84-2a833f5189b4"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning:\n",
            "\n",
            "The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H6ukOxAGC_I4",
        "outputId": "d8f57c74-950f-4885-a71b-a0c227781185"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d (Conv1D)             (None, 40, 128)           1152      \n",
            "                                                                 \n",
            " activation (Activation)     (None, 40, 128)           0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 40, 128)           0         \n",
            "                                                                 \n",
            " max_pooling1d (MaxPooling1D  (None, 8, 128)           0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv1d_1 (Conv1D)           (None, 8, 256)            262400    \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 8, 256)            0         \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 8, 256)            0         \n",
            "                                                                 \n",
            " max_pooling1d_1 (MaxPooling  (None, 1, 256)           0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 256)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 256)               65792     \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 256)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 256)               65792     \n",
            "                                                                 \n",
            " activation_3 (Activation)   (None, 256)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 6)                 1542      \n",
            "                                                                 \n",
            " activation_4 (Activation)   (None, 6)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 396,678\n",
            "Trainable params: 396,678\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='sparse_categorical_crossentropy',\n",
        "              optimizer=opt,\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "AbMlLNk4DCBM"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#cnnhistory=model.fit(x_traincnn, y_train, batch_size=16, epochs=700, validation_data=(x_testcnn, y_test))\n",
        "cnnhistory=model.fit(x_traincnn, y_train, batch_size=16, epochs=700 , validation_data=(X_valid, y_valid))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RI1v2AuADFhy",
        "outputId": "333463c6-7dc9-416c-9e48-307c3ed77e7f"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/700\n",
            "104/104 [==============================] - 5s 32ms/step - loss: 7.7774 - accuracy: 0.1850 - val_loss: 2.2669 - val_accuracy: 0.2271\n",
            "Epoch 2/700\n",
            "104/104 [==============================] - 3s 25ms/step - loss: 4.4403 - accuracy: 0.1844 - val_loss: 1.9875 - val_accuracy: 0.2077\n",
            "Epoch 3/700\n",
            "104/104 [==============================] - 3s 24ms/step - loss: 3.9138 - accuracy: 0.1868 - val_loss: 1.8770 - val_accuracy: 0.2126\n",
            "Epoch 4/700\n",
            "104/104 [==============================] - 2s 23ms/step - loss: 3.4064 - accuracy: 0.1953 - val_loss: 1.7447 - val_accuracy: 0.2271\n",
            "Epoch 5/700\n",
            "104/104 [==============================] - 3s 24ms/step - loss: 3.2095 - accuracy: 0.1959 - val_loss: 1.8130 - val_accuracy: 0.2271\n",
            "Epoch 6/700\n",
            "104/104 [==============================] - 3s 25ms/step - loss: 2.9886 - accuracy: 0.1832 - val_loss: 1.7508 - val_accuracy: 0.2367\n",
            "Epoch 7/700\n",
            "104/104 [==============================] - 3s 25ms/step - loss: 2.7991 - accuracy: 0.1995 - val_loss: 1.7242 - val_accuracy: 0.2609\n",
            "Epoch 8/700\n",
            "104/104 [==============================] - 2s 24ms/step - loss: 2.6932 - accuracy: 0.1941 - val_loss: 1.6917 - val_accuracy: 0.2754\n",
            "Epoch 9/700\n",
            "104/104 [==============================] - 3s 24ms/step - loss: 2.6129 - accuracy: 0.2050 - val_loss: 1.6647 - val_accuracy: 0.2609\n",
            "Epoch 10/700\n",
            "104/104 [==============================] - 3s 24ms/step - loss: 2.4595 - accuracy: 0.2025 - val_loss: 1.7004 - val_accuracy: 0.2077\n",
            "Epoch 11/700\n",
            "104/104 [==============================] - 2s 24ms/step - loss: 2.3647 - accuracy: 0.2080 - val_loss: 1.7152 - val_accuracy: 0.2367\n",
            "Epoch 12/700\n",
            "104/104 [==============================] - 3s 26ms/step - loss: 2.4001 - accuracy: 0.1862 - val_loss: 1.6731 - val_accuracy: 0.2705\n",
            "Epoch 13/700\n",
            "104/104 [==============================] - 3s 25ms/step - loss: 2.2404 - accuracy: 0.2013 - val_loss: 1.7052 - val_accuracy: 0.2947\n",
            "Epoch 14/700\n",
            "104/104 [==============================] - 3s 25ms/step - loss: 2.2064 - accuracy: 0.2189 - val_loss: 1.6740 - val_accuracy: 0.2705\n",
            "Epoch 15/700\n",
            "104/104 [==============================] - 2s 24ms/step - loss: 2.1499 - accuracy: 0.2189 - val_loss: 1.6755 - val_accuracy: 0.2560\n",
            "Epoch 16/700\n",
            "104/104 [==============================] - 2s 23ms/step - loss: 2.0957 - accuracy: 0.2346 - val_loss: 1.6949 - val_accuracy: 0.2271\n",
            "Epoch 17/700\n",
            "104/104 [==============================] - 3s 24ms/step - loss: 2.0672 - accuracy: 0.2140 - val_loss: 1.6654 - val_accuracy: 0.3575\n",
            "Epoch 18/700\n",
            "104/104 [==============================] - 3s 24ms/step - loss: 2.0541 - accuracy: 0.1983 - val_loss: 1.6997 - val_accuracy: 0.2367\n",
            "Epoch 19/700\n",
            "104/104 [==============================] - 3s 25ms/step - loss: 2.0219 - accuracy: 0.2316 - val_loss: 1.6639 - val_accuracy: 0.3768\n",
            "Epoch 20/700\n",
            "104/104 [==============================] - 2s 24ms/step - loss: 1.9900 - accuracy: 0.2273 - val_loss: 1.6535 - val_accuracy: 0.4010\n",
            "Epoch 21/700\n",
            "104/104 [==============================] - 3s 24ms/step - loss: 1.9870 - accuracy: 0.2086 - val_loss: 1.6832 - val_accuracy: 0.3382\n",
            "Epoch 22/700\n",
            "104/104 [==============================] - 2s 24ms/step - loss: 1.9520 - accuracy: 0.2364 - val_loss: 1.6688 - val_accuracy: 0.3285\n",
            "Epoch 23/700\n",
            "104/104 [==============================] - 3s 25ms/step - loss: 1.9434 - accuracy: 0.2291 - val_loss: 1.6950 - val_accuracy: 0.2899\n",
            "Epoch 24/700\n",
            "104/104 [==============================] - 3s 25ms/step - loss: 1.8949 - accuracy: 0.2388 - val_loss: 1.6757 - val_accuracy: 0.3478\n",
            "Epoch 25/700\n",
            "104/104 [==============================] - 3s 25ms/step - loss: 1.9128 - accuracy: 0.2455 - val_loss: 1.6603 - val_accuracy: 0.3575\n",
            "Epoch 26/700\n",
            "104/104 [==============================] - 3s 24ms/step - loss: 1.8709 - accuracy: 0.2334 - val_loss: 1.7167 - val_accuracy: 0.2174\n",
            "Epoch 27/700\n",
            "104/104 [==============================] - 3s 24ms/step - loss: 1.8720 - accuracy: 0.2310 - val_loss: 1.6807 - val_accuracy: 0.2657\n",
            "Epoch 28/700\n",
            "104/104 [==============================] - 2s 24ms/step - loss: 1.8831 - accuracy: 0.2412 - val_loss: 1.6667 - val_accuracy: 0.3527\n",
            "Epoch 29/700\n",
            "104/104 [==============================] - 3s 24ms/step - loss: 1.8654 - accuracy: 0.2600 - val_loss: 1.6536 - val_accuracy: 0.3140\n",
            "Epoch 30/700\n",
            "104/104 [==============================] - 3s 24ms/step - loss: 1.8303 - accuracy: 0.2388 - val_loss: 1.6556 - val_accuracy: 0.2947\n",
            "Epoch 31/700\n",
            "104/104 [==============================] - 3s 24ms/step - loss: 1.8285 - accuracy: 0.2467 - val_loss: 1.6583 - val_accuracy: 0.3285\n",
            "Epoch 32/700\n",
            "104/104 [==============================] - 3s 24ms/step - loss: 1.7968 - accuracy: 0.2509 - val_loss: 1.6386 - val_accuracy: 0.3527\n",
            "Epoch 33/700\n",
            "104/104 [==============================] - 3s 26ms/step - loss: 1.7931 - accuracy: 0.2515 - val_loss: 1.6599 - val_accuracy: 0.3478\n",
            "Epoch 34/700\n",
            "104/104 [==============================] - 4s 35ms/step - loss: 1.8004 - accuracy: 0.2533 - val_loss: 1.6401 - val_accuracy: 0.3623\n",
            "Epoch 35/700\n",
            "104/104 [==============================] - 3s 26ms/step - loss: 1.7767 - accuracy: 0.2570 - val_loss: 1.6422 - val_accuracy: 0.2995\n",
            "Epoch 36/700\n",
            "104/104 [==============================] - 3s 24ms/step - loss: 1.7644 - accuracy: 0.2811 - val_loss: 1.6446 - val_accuracy: 0.3237\n",
            "Epoch 37/700\n",
            "104/104 [==============================] - 3s 25ms/step - loss: 1.7832 - accuracy: 0.2509 - val_loss: 1.6465 - val_accuracy: 0.3237\n",
            "Epoch 38/700\n",
            "104/104 [==============================] - 3s 25ms/step - loss: 1.7761 - accuracy: 0.2612 - val_loss: 1.6346 - val_accuracy: 0.3575\n",
            "Epoch 39/700\n",
            "104/104 [==============================] - 3s 24ms/step - loss: 1.7542 - accuracy: 0.2709 - val_loss: 1.6593 - val_accuracy: 0.3333\n",
            "Epoch 40/700\n",
            "104/104 [==============================] - 3s 25ms/step - loss: 1.7383 - accuracy: 0.2678 - val_loss: 1.6409 - val_accuracy: 0.3478\n",
            "Epoch 41/700\n",
            "104/104 [==============================] - 3s 25ms/step - loss: 1.7494 - accuracy: 0.2678 - val_loss: 1.6513 - val_accuracy: 0.3285\n",
            "Epoch 42/700\n",
            "104/104 [==============================] - 3s 24ms/step - loss: 1.7068 - accuracy: 0.2854 - val_loss: 1.6297 - val_accuracy: 0.3237\n",
            "Epoch 43/700\n",
            "104/104 [==============================] - 3s 24ms/step - loss: 1.7305 - accuracy: 0.2727 - val_loss: 1.6178 - val_accuracy: 0.3382\n",
            "Epoch 44/700\n",
            "104/104 [==============================] - 3s 24ms/step - loss: 1.7267 - accuracy: 0.2594 - val_loss: 1.6401 - val_accuracy: 0.3333\n",
            "Epoch 45/700\n",
            "104/104 [==============================] - 3s 25ms/step - loss: 1.7345 - accuracy: 0.2666 - val_loss: 1.6257 - val_accuracy: 0.3478\n",
            "Epoch 46/700\n",
            "104/104 [==============================] - 3s 25ms/step - loss: 1.7187 - accuracy: 0.2981 - val_loss: 1.6206 - val_accuracy: 0.3237\n",
            "Epoch 47/700\n",
            "104/104 [==============================] - 3s 25ms/step - loss: 1.7061 - accuracy: 0.2920 - val_loss: 1.6142 - val_accuracy: 0.3623\n",
            "Epoch 48/700\n",
            "104/104 [==============================] - 3s 25ms/step - loss: 1.6932 - accuracy: 0.3059 - val_loss: 1.6083 - val_accuracy: 0.3913\n",
            "Epoch 49/700\n",
            "104/104 [==============================] - 3s 25ms/step - loss: 1.6977 - accuracy: 0.2956 - val_loss: 1.6220 - val_accuracy: 0.3478\n",
            "Epoch 50/700\n",
            "104/104 [==============================] - 3s 25ms/step - loss: 1.7109 - accuracy: 0.2932 - val_loss: 1.5872 - val_accuracy: 0.3816\n",
            "Epoch 51/700\n",
            "104/104 [==============================] - 3s 31ms/step - loss: 1.6651 - accuracy: 0.3011 - val_loss: 1.5810 - val_accuracy: 0.3720\n",
            "Epoch 52/700\n",
            "104/104 [==============================] - 3s 30ms/step - loss: 1.6891 - accuracy: 0.2811 - val_loss: 1.5817 - val_accuracy: 0.3671\n",
            "Epoch 53/700\n",
            "104/104 [==============================] - 5s 48ms/step - loss: 1.6615 - accuracy: 0.3059 - val_loss: 1.5696 - val_accuracy: 0.4010\n",
            "Epoch 54/700\n",
            "104/104 [==============================] - 3s 26ms/step - loss: 1.6883 - accuracy: 0.2860 - val_loss: 1.5758 - val_accuracy: 0.3961\n",
            "Epoch 55/700\n",
            "104/104 [==============================] - 3s 24ms/step - loss: 1.6648 - accuracy: 0.2932 - val_loss: 1.5795 - val_accuracy: 0.3527\n",
            "Epoch 56/700\n",
            "104/104 [==============================] - 3s 26ms/step - loss: 1.6470 - accuracy: 0.3047 - val_loss: 1.5593 - val_accuracy: 0.4106\n",
            "Epoch 57/700\n",
            "104/104 [==============================] - 3s 25ms/step - loss: 1.6345 - accuracy: 0.3138 - val_loss: 1.5786 - val_accuracy: 0.4106\n",
            "Epoch 58/700\n",
            "104/104 [==============================] - 3s 25ms/step - loss: 1.6418 - accuracy: 0.3065 - val_loss: 1.5810 - val_accuracy: 0.3768\n",
            "Epoch 59/700\n",
            "104/104 [==============================] - 3s 25ms/step - loss: 1.6195 - accuracy: 0.3289 - val_loss: 1.5478 - val_accuracy: 0.3768\n",
            "Epoch 60/700\n",
            "104/104 [==============================] - 3s 26ms/step - loss: 1.6602 - accuracy: 0.3029 - val_loss: 1.5586 - val_accuracy: 0.3527\n",
            "Epoch 61/700\n",
            "104/104 [==============================] - 3s 24ms/step - loss: 1.6393 - accuracy: 0.3089 - val_loss: 1.5592 - val_accuracy: 0.3720\n",
            "Epoch 62/700\n",
            "104/104 [==============================] - 3s 26ms/step - loss: 1.6348 - accuracy: 0.3180 - val_loss: 1.5388 - val_accuracy: 0.3961\n",
            "Epoch 63/700\n",
            "104/104 [==============================] - 3s 26ms/step - loss: 1.6431 - accuracy: 0.3059 - val_loss: 1.5466 - val_accuracy: 0.4348\n",
            "Epoch 64/700\n",
            "104/104 [==============================] - 3s 26ms/step - loss: 1.6132 - accuracy: 0.3295 - val_loss: 1.5473 - val_accuracy: 0.3623\n",
            "Epoch 65/700\n",
            "104/104 [==============================] - 3s 25ms/step - loss: 1.6001 - accuracy: 0.3289 - val_loss: 1.5365 - val_accuracy: 0.3768\n",
            "Epoch 66/700\n",
            "104/104 [==============================] - 3s 25ms/step - loss: 1.5944 - accuracy: 0.3398 - val_loss: 1.5629 - val_accuracy: 0.3623\n",
            "Epoch 67/700\n",
            "104/104 [==============================] - 3s 25ms/step - loss: 1.6018 - accuracy: 0.3229 - val_loss: 1.5589 - val_accuracy: 0.3768\n",
            "Epoch 68/700\n",
            "104/104 [==============================] - 3s 25ms/step - loss: 1.6179 - accuracy: 0.3156 - val_loss: 1.5524 - val_accuracy: 0.3430\n",
            "Epoch 69/700\n",
            "104/104 [==============================] - 3s 25ms/step - loss: 1.5875 - accuracy: 0.3362 - val_loss: 1.5117 - val_accuracy: 0.4493\n",
            "Epoch 70/700\n",
            "104/104 [==============================] - 3s 24ms/step - loss: 1.5992 - accuracy: 0.3368 - val_loss: 1.5117 - val_accuracy: 0.4203\n",
            "Epoch 71/700\n",
            "104/104 [==============================] - 3s 25ms/step - loss: 1.5765 - accuracy: 0.3386 - val_loss: 1.5039 - val_accuracy: 0.4106\n",
            "Epoch 72/700\n",
            "104/104 [==============================] - 3s 25ms/step - loss: 1.5787 - accuracy: 0.3452 - val_loss: 1.5032 - val_accuracy: 0.4155\n",
            "Epoch 73/700\n",
            "104/104 [==============================] - 4s 36ms/step - loss: 1.5757 - accuracy: 0.3476 - val_loss: 1.5071 - val_accuracy: 0.4396\n",
            "Epoch 74/700\n",
            "104/104 [==============================] - 3s 25ms/step - loss: 1.5704 - accuracy: 0.3622 - val_loss: 1.4955 - val_accuracy: 0.3913\n",
            "Epoch 75/700\n",
            "104/104 [==============================] - 3s 25ms/step - loss: 1.5657 - accuracy: 0.3525 - val_loss: 1.5051 - val_accuracy: 0.3961\n",
            "Epoch 76/700\n",
            "104/104 [==============================] - 3s 25ms/step - loss: 1.5519 - accuracy: 0.3700 - val_loss: 1.4868 - val_accuracy: 0.4541\n",
            "Epoch 77/700\n",
            "104/104 [==============================] - 3s 27ms/step - loss: 1.5632 - accuracy: 0.3501 - val_loss: 1.4868 - val_accuracy: 0.4010\n",
            "Epoch 78/700\n",
            "104/104 [==============================] - 3s 28ms/step - loss: 1.5325 - accuracy: 0.3676 - val_loss: 1.4797 - val_accuracy: 0.4300\n",
            "Epoch 79/700\n",
            "104/104 [==============================] - 3s 28ms/step - loss: 1.5449 - accuracy: 0.3531 - val_loss: 1.4735 - val_accuracy: 0.4396\n",
            "Epoch 80/700\n",
            "104/104 [==============================] - 3s 25ms/step - loss: 1.5377 - accuracy: 0.3537 - val_loss: 1.4865 - val_accuracy: 0.4106\n",
            "Epoch 81/700\n",
            "104/104 [==============================] - 3s 25ms/step - loss: 1.5054 - accuracy: 0.3779 - val_loss: 1.4654 - val_accuracy: 0.4589\n",
            "Epoch 82/700\n",
            "104/104 [==============================] - 3s 26ms/step - loss: 1.5122 - accuracy: 0.3821 - val_loss: 1.4575 - val_accuracy: 0.4106\n",
            "Epoch 83/700\n",
            "104/104 [==============================] - 3s 26ms/step - loss: 1.5381 - accuracy: 0.3549 - val_loss: 1.4524 - val_accuracy: 0.4348\n",
            "Epoch 84/700\n",
            "104/104 [==============================] - 3s 26ms/step - loss: 1.5067 - accuracy: 0.3960 - val_loss: 1.4509 - val_accuracy: 0.4396\n",
            "Epoch 85/700\n",
            "104/104 [==============================] - 3s 28ms/step - loss: 1.5340 - accuracy: 0.3609 - val_loss: 1.4504 - val_accuracy: 0.5121\n",
            "Epoch 86/700\n",
            "104/104 [==============================] - 3s 28ms/step - loss: 1.5213 - accuracy: 0.3706 - val_loss: 1.4398 - val_accuracy: 0.5072\n",
            "Epoch 87/700\n",
            "104/104 [==============================] - 3s 27ms/step - loss: 1.4818 - accuracy: 0.3918 - val_loss: 1.4340 - val_accuracy: 0.4493\n",
            "Epoch 88/700\n",
            "104/104 [==============================] - 3s 28ms/step - loss: 1.4965 - accuracy: 0.3767 - val_loss: 1.4347 - val_accuracy: 0.4638\n",
            "Epoch 89/700\n",
            "104/104 [==============================] - 3s 28ms/step - loss: 1.4937 - accuracy: 0.3851 - val_loss: 1.4237 - val_accuracy: 0.4879\n",
            "Epoch 90/700\n",
            "104/104 [==============================] - 3s 27ms/step - loss: 1.4897 - accuracy: 0.3936 - val_loss: 1.4217 - val_accuracy: 0.4638\n",
            "Epoch 91/700\n",
            "104/104 [==============================] - 3s 26ms/step - loss: 1.4596 - accuracy: 0.4033 - val_loss: 1.4244 - val_accuracy: 0.4348\n",
            "Epoch 92/700\n",
            "104/104 [==============================] - 3s 25ms/step - loss: 1.5045 - accuracy: 0.3851 - val_loss: 1.4067 - val_accuracy: 0.5024\n",
            "Epoch 93/700\n",
            "104/104 [==============================] - 3s 25ms/step - loss: 1.4563 - accuracy: 0.4021 - val_loss: 1.4174 - val_accuracy: 0.4734\n",
            "Epoch 94/700\n",
            "104/104 [==============================] - 3s 25ms/step - loss: 1.4779 - accuracy: 0.3990 - val_loss: 1.4391 - val_accuracy: 0.4589\n",
            "Epoch 95/700\n",
            "104/104 [==============================] - 3s 25ms/step - loss: 1.4625 - accuracy: 0.4148 - val_loss: 1.4025 - val_accuracy: 0.4734\n",
            "Epoch 96/700\n",
            "104/104 [==============================] - 3s 25ms/step - loss: 1.4673 - accuracy: 0.4008 - val_loss: 1.3899 - val_accuracy: 0.4976\n",
            "Epoch 97/700\n",
            "104/104 [==============================] - 3s 26ms/step - loss: 1.4310 - accuracy: 0.4093 - val_loss: 1.4081 - val_accuracy: 0.5024\n",
            "Epoch 98/700\n",
            "104/104 [==============================] - 3s 26ms/step - loss: 1.4545 - accuracy: 0.4154 - val_loss: 1.3855 - val_accuracy: 0.4879\n",
            "Epoch 99/700\n",
            "104/104 [==============================] - 3s 26ms/step - loss: 1.4530 - accuracy: 0.3972 - val_loss: 1.4011 - val_accuracy: 0.4928\n",
            "Epoch 100/700\n",
            "104/104 [==============================] - 3s 26ms/step - loss: 1.4384 - accuracy: 0.4129 - val_loss: 1.3878 - val_accuracy: 0.5121\n",
            "Epoch 101/700\n",
            "104/104 [==============================] - 3s 26ms/step - loss: 1.4320 - accuracy: 0.4281 - val_loss: 1.3953 - val_accuracy: 0.5024\n",
            "Epoch 102/700\n",
            "104/104 [==============================] - 3s 26ms/step - loss: 1.4100 - accuracy: 0.4414 - val_loss: 1.3768 - val_accuracy: 0.4783\n",
            "Epoch 103/700\n",
            "104/104 [==============================] - 3s 25ms/step - loss: 1.4155 - accuracy: 0.4383 - val_loss: 1.3613 - val_accuracy: 0.5169\n",
            "Epoch 104/700\n",
            "104/104 [==============================] - 3s 26ms/step - loss: 1.4334 - accuracy: 0.4081 - val_loss: 1.3598 - val_accuracy: 0.5217\n",
            "Epoch 105/700\n",
            "104/104 [==============================] - 3s 25ms/step - loss: 1.4296 - accuracy: 0.4105 - val_loss: 1.3390 - val_accuracy: 0.5266\n",
            "Epoch 106/700\n",
            "104/104 [==============================] - 3s 25ms/step - loss: 1.3972 - accuracy: 0.4389 - val_loss: 1.3649 - val_accuracy: 0.4928\n",
            "Epoch 107/700\n",
            "104/104 [==============================] - 3s 25ms/step - loss: 1.3885 - accuracy: 0.4371 - val_loss: 1.3387 - val_accuracy: 0.4928\n",
            "Epoch 108/700\n",
            "104/104 [==============================] - 3s 25ms/step - loss: 1.4066 - accuracy: 0.4202 - val_loss: 1.3426 - val_accuracy: 0.5217\n",
            "Epoch 109/700\n",
            "104/104 [==============================] - 3s 26ms/step - loss: 1.3954 - accuracy: 0.4232 - val_loss: 1.3323 - val_accuracy: 0.5217\n",
            "Epoch 110/700\n",
            "104/104 [==============================] - 3s 26ms/step - loss: 1.4090 - accuracy: 0.4172 - val_loss: 1.3305 - val_accuracy: 0.5362\n",
            "Epoch 111/700\n",
            "104/104 [==============================] - 3s 25ms/step - loss: 1.3949 - accuracy: 0.4389 - val_loss: 1.3228 - val_accuracy: 0.5266\n",
            "Epoch 112/700\n",
            "104/104 [==============================] - 4s 37ms/step - loss: 1.3832 - accuracy: 0.4407 - val_loss: 1.3293 - val_accuracy: 0.5024\n",
            "Epoch 113/700\n",
            "104/104 [==============================] - 3s 26ms/step - loss: 1.3755 - accuracy: 0.4528 - val_loss: 1.3246 - val_accuracy: 0.5072\n",
            "Epoch 114/700\n",
            "104/104 [==============================] - 3s 26ms/step - loss: 1.3576 - accuracy: 0.4589 - val_loss: 1.3245 - val_accuracy: 0.4879\n",
            "Epoch 115/700\n",
            "104/104 [==============================] - 3s 26ms/step - loss: 1.3636 - accuracy: 0.4450 - val_loss: 1.2926 - val_accuracy: 0.5362\n",
            "Epoch 116/700\n",
            "104/104 [==============================] - 3s 25ms/step - loss: 1.3482 - accuracy: 0.4474 - val_loss: 1.3153 - val_accuracy: 0.5121\n",
            "Epoch 117/700\n",
            "104/104 [==============================] - 3s 26ms/step - loss: 1.3595 - accuracy: 0.4414 - val_loss: 1.2965 - val_accuracy: 0.5217\n",
            "Epoch 118/700\n",
            "104/104 [==============================] - 3s 25ms/step - loss: 1.3636 - accuracy: 0.4559 - val_loss: 1.3010 - val_accuracy: 0.5169\n",
            "Epoch 119/700\n",
            "104/104 [==============================] - 3s 25ms/step - loss: 1.3423 - accuracy: 0.4607 - val_loss: 1.2972 - val_accuracy: 0.5169\n",
            "Epoch 120/700\n",
            "104/104 [==============================] - 3s 27ms/step - loss: 1.3339 - accuracy: 0.4698 - val_loss: 1.3037 - val_accuracy: 0.5072\n",
            "Epoch 121/700\n",
            "104/104 [==============================] - 3s 26ms/step - loss: 1.3343 - accuracy: 0.4667 - val_loss: 1.2785 - val_accuracy: 0.5459\n",
            "Epoch 122/700\n",
            "104/104 [==============================] - 3s 27ms/step - loss: 1.3298 - accuracy: 0.4637 - val_loss: 1.2762 - val_accuracy: 0.5266\n",
            "Epoch 123/700\n",
            "104/104 [==============================] - 3s 27ms/step - loss: 1.3515 - accuracy: 0.4522 - val_loss: 1.3008 - val_accuracy: 0.5024\n",
            "Epoch 124/700\n",
            "104/104 [==============================] - 3s 26ms/step - loss: 1.3243 - accuracy: 0.4595 - val_loss: 1.2626 - val_accuracy: 0.5024\n",
            "Epoch 125/700\n",
            "104/104 [==============================] - 3s 26ms/step - loss: 1.3149 - accuracy: 0.4692 - val_loss: 1.2769 - val_accuracy: 0.5314\n",
            "Epoch 126/700\n",
            "104/104 [==============================] - 3s 27ms/step - loss: 1.3177 - accuracy: 0.4740 - val_loss: 1.2674 - val_accuracy: 0.5362\n",
            "Epoch 127/700\n",
            "104/104 [==============================] - 3s 27ms/step - loss: 1.2963 - accuracy: 0.4734 - val_loss: 1.2740 - val_accuracy: 0.5314\n",
            "Epoch 128/700\n",
            "104/104 [==============================] - 3s 27ms/step - loss: 1.3251 - accuracy: 0.4583 - val_loss: 1.2736 - val_accuracy: 0.5072\n",
            "Epoch 129/700\n",
            "104/104 [==============================] - 3s 27ms/step - loss: 1.3127 - accuracy: 0.4661 - val_loss: 1.2557 - val_accuracy: 0.5314\n",
            "Epoch 130/700\n",
            "104/104 [==============================] - 3s 27ms/step - loss: 1.3126 - accuracy: 0.4595 - val_loss: 1.2350 - val_accuracy: 0.5362\n",
            "Epoch 131/700\n",
            "104/104 [==============================] - 3s 26ms/step - loss: 1.2929 - accuracy: 0.4686 - val_loss: 1.2457 - val_accuracy: 0.5459\n",
            "Epoch 132/700\n",
            "104/104 [==============================] - 3s 25ms/step - loss: 1.2954 - accuracy: 0.4800 - val_loss: 1.2367 - val_accuracy: 0.5314\n",
            "Epoch 133/700\n",
            "104/104 [==============================] - 3s 25ms/step - loss: 1.2899 - accuracy: 0.4855 - val_loss: 1.2241 - val_accuracy: 0.5604\n",
            "Epoch 134/700\n",
            "104/104 [==============================] - 3s 25ms/step - loss: 1.2868 - accuracy: 0.4758 - val_loss: 1.2282 - val_accuracy: 0.5652\n",
            "Epoch 135/700\n",
            "104/104 [==============================] - 3s 27ms/step - loss: 1.2806 - accuracy: 0.4861 - val_loss: 1.2364 - val_accuracy: 0.5556\n",
            "Epoch 136/700\n",
            "104/104 [==============================] - 3s 27ms/step - loss: 1.2830 - accuracy: 0.4837 - val_loss: 1.2230 - val_accuracy: 0.5314\n",
            "Epoch 137/700\n",
            "104/104 [==============================] - 3s 27ms/step - loss: 1.2941 - accuracy: 0.4825 - val_loss: 1.2189 - val_accuracy: 0.5652\n",
            "Epoch 138/700\n",
            "104/104 [==============================] - 3s 25ms/step - loss: 1.2968 - accuracy: 0.4982 - val_loss: 1.2140 - val_accuracy: 0.5604\n",
            "Epoch 139/700\n",
            "104/104 [==============================] - 3s 26ms/step - loss: 1.2636 - accuracy: 0.4970 - val_loss: 1.2127 - val_accuracy: 0.5507\n",
            "Epoch 140/700\n",
            "104/104 [==============================] - 3s 25ms/step - loss: 1.2622 - accuracy: 0.4867 - val_loss: 1.2042 - val_accuracy: 0.5604\n",
            "Epoch 141/700\n",
            "104/104 [==============================] - 3s 27ms/step - loss: 1.2533 - accuracy: 0.4994 - val_loss: 1.2007 - val_accuracy: 0.5556\n",
            "Epoch 142/700\n",
            "104/104 [==============================] - 3s 26ms/step - loss: 1.2592 - accuracy: 0.4952 - val_loss: 1.2007 - val_accuracy: 0.5604\n",
            "Epoch 143/700\n",
            "104/104 [==============================] - 3s 26ms/step - loss: 1.2620 - accuracy: 0.4843 - val_loss: 1.1906 - val_accuracy: 0.5700\n",
            "Epoch 144/700\n",
            "104/104 [==============================] - 3s 27ms/step - loss: 1.2571 - accuracy: 0.4915 - val_loss: 1.1866 - val_accuracy: 0.5797\n",
            "Epoch 145/700\n",
            "104/104 [==============================] - 3s 27ms/step - loss: 1.2469 - accuracy: 0.4927 - val_loss: 1.1870 - val_accuracy: 0.5556\n",
            "Epoch 146/700\n",
            "104/104 [==============================] - 3s 28ms/step - loss: 1.2536 - accuracy: 0.4940 - val_loss: 1.1861 - val_accuracy: 0.5700\n",
            "Epoch 147/700\n",
            "104/104 [==============================] - 3s 28ms/step - loss: 1.2274 - accuracy: 0.5139 - val_loss: 1.1876 - val_accuracy: 0.5604\n",
            "Epoch 148/700\n",
            "104/104 [==============================] - 3s 27ms/step - loss: 1.2296 - accuracy: 0.5109 - val_loss: 1.1742 - val_accuracy: 0.5845\n",
            "Epoch 149/700\n",
            "104/104 [==============================] - 3s 26ms/step - loss: 1.2113 - accuracy: 0.5109 - val_loss: 1.1792 - val_accuracy: 0.5700\n",
            "Epoch 150/700\n",
            "104/104 [==============================] - 3s 26ms/step - loss: 1.2172 - accuracy: 0.5127 - val_loss: 1.1898 - val_accuracy: 0.5604\n",
            "Epoch 151/700\n",
            "104/104 [==============================] - 3s 26ms/step - loss: 1.2133 - accuracy: 0.5193 - val_loss: 1.1723 - val_accuracy: 0.5942\n",
            "Epoch 152/700\n",
            "104/104 [==============================] - 3s 26ms/step - loss: 1.2190 - accuracy: 0.5157 - val_loss: 1.1615 - val_accuracy: 0.5749\n",
            "Epoch 153/700\n",
            "104/104 [==============================] - 3s 25ms/step - loss: 1.2025 - accuracy: 0.5012 - val_loss: 1.1650 - val_accuracy: 0.5749\n",
            "Epoch 154/700\n",
            "104/104 [==============================] - 3s 25ms/step - loss: 1.2079 - accuracy: 0.5012 - val_loss: 1.1550 - val_accuracy: 0.5700\n",
            "Epoch 155/700\n",
            "104/104 [==============================] - 3s 26ms/step - loss: 1.1934 - accuracy: 0.5048 - val_loss: 1.1535 - val_accuracy: 0.5652\n",
            "Epoch 156/700\n",
            "104/104 [==============================] - 3s 26ms/step - loss: 1.1932 - accuracy: 0.5272 - val_loss: 1.1452 - val_accuracy: 0.5749\n",
            "Epoch 157/700\n",
            "104/104 [==============================] - 3s 26ms/step - loss: 1.1967 - accuracy: 0.5290 - val_loss: 1.1452 - val_accuracy: 0.5652\n",
            "Epoch 158/700\n",
            "104/104 [==============================] - 3s 26ms/step - loss: 1.2134 - accuracy: 0.5163 - val_loss: 1.1457 - val_accuracy: 0.5845\n",
            "Epoch 159/700\n",
            "104/104 [==============================] - 3s 26ms/step - loss: 1.1881 - accuracy: 0.5193 - val_loss: 1.1445 - val_accuracy: 0.5749\n",
            "Epoch 160/700\n",
            "104/104 [==============================] - 3s 25ms/step - loss: 1.1968 - accuracy: 0.5224 - val_loss: 1.1400 - val_accuracy: 0.5990\n",
            "Epoch 161/700\n",
            "104/104 [==============================] - 3s 26ms/step - loss: 1.2210 - accuracy: 0.5012 - val_loss: 1.1497 - val_accuracy: 0.5894\n",
            "Epoch 162/700\n",
            "104/104 [==============================] - 3s 26ms/step - loss: 1.1986 - accuracy: 0.5157 - val_loss: 1.1367 - val_accuracy: 0.5894\n",
            "Epoch 163/700\n",
            "104/104 [==============================] - 3s 26ms/step - loss: 1.1728 - accuracy: 0.5284 - val_loss: 1.1386 - val_accuracy: 0.5894\n",
            "Epoch 164/700\n",
            "104/104 [==============================] - 3s 26ms/step - loss: 1.1827 - accuracy: 0.5224 - val_loss: 1.1319 - val_accuracy: 0.5894\n",
            "Epoch 165/700\n",
            "104/104 [==============================] - 3s 25ms/step - loss: 1.1946 - accuracy: 0.5302 - val_loss: 1.1264 - val_accuracy: 0.5845\n",
            "Epoch 166/700\n",
            "104/104 [==============================] - 3s 26ms/step - loss: 1.1806 - accuracy: 0.5357 - val_loss: 1.1197 - val_accuracy: 0.5942\n",
            "Epoch 167/700\n",
            "104/104 [==============================] - 3s 28ms/step - loss: 1.1595 - accuracy: 0.5351 - val_loss: 1.1136 - val_accuracy: 0.5894\n",
            "Epoch 168/700\n",
            "104/104 [==============================] - 3s 26ms/step - loss: 1.1663 - accuracy: 0.5314 - val_loss: 1.1140 - val_accuracy: 0.6039\n",
            "Epoch 169/700\n",
            "104/104 [==============================] - 3s 26ms/step - loss: 1.1615 - accuracy: 0.5290 - val_loss: 1.1237 - val_accuracy: 0.5749\n",
            "Epoch 170/700\n",
            "104/104 [==============================] - 3s 26ms/step - loss: 1.1513 - accuracy: 0.5472 - val_loss: 1.1074 - val_accuracy: 0.5942\n",
            "Epoch 171/700\n",
            "104/104 [==============================] - 3s 25ms/step - loss: 1.1601 - accuracy: 0.5496 - val_loss: 1.1097 - val_accuracy: 0.6039\n",
            "Epoch 172/700\n",
            "104/104 [==============================] - 3s 26ms/step - loss: 1.1407 - accuracy: 0.5459 - val_loss: 1.1015 - val_accuracy: 0.6039\n",
            "Epoch 173/700\n",
            "104/104 [==============================] - 3s 28ms/step - loss: 1.1509 - accuracy: 0.5399 - val_loss: 1.1069 - val_accuracy: 0.5942\n",
            "Epoch 174/700\n",
            "104/104 [==============================] - 3s 27ms/step - loss: 1.1602 - accuracy: 0.5290 - val_loss: 1.0988 - val_accuracy: 0.5942\n",
            "Epoch 175/700\n",
            "104/104 [==============================] - 3s 27ms/step - loss: 1.1356 - accuracy: 0.5484 - val_loss: 1.0971 - val_accuracy: 0.6232\n",
            "Epoch 176/700\n",
            "104/104 [==============================] - 3s 25ms/step - loss: 1.1551 - accuracy: 0.5417 - val_loss: 1.1179 - val_accuracy: 0.5797\n",
            "Epoch 177/700\n",
            "104/104 [==============================] - 3s 25ms/step - loss: 1.1403 - accuracy: 0.5411 - val_loss: 1.0856 - val_accuracy: 0.6184\n",
            "Epoch 178/700\n",
            "104/104 [==============================] - 3s 28ms/step - loss: 1.1299 - accuracy: 0.5484 - val_loss: 1.0827 - val_accuracy: 0.6377\n",
            "Epoch 179/700\n",
            "104/104 [==============================] - 3s 27ms/step - loss: 1.1203 - accuracy: 0.5447 - val_loss: 1.1045 - val_accuracy: 0.5990\n",
            "Epoch 180/700\n",
            "104/104 [==============================] - 3s 26ms/step - loss: 1.1201 - accuracy: 0.5623 - val_loss: 1.0986 - val_accuracy: 0.5894\n",
            "Epoch 181/700\n",
            "104/104 [==============================] - 3s 26ms/step - loss: 1.1135 - accuracy: 0.5738 - val_loss: 1.0799 - val_accuracy: 0.5797\n",
            "Epoch 182/700\n",
            "104/104 [==============================] - 3s 26ms/step - loss: 1.1161 - accuracy: 0.5393 - val_loss: 1.0931 - val_accuracy: 0.6087\n",
            "Epoch 183/700\n",
            "104/104 [==============================] - 3s 27ms/step - loss: 1.1465 - accuracy: 0.5526 - val_loss: 1.0733 - val_accuracy: 0.6135\n",
            "Epoch 184/700\n",
            "104/104 [==============================] - 3s 27ms/step - loss: 1.1334 - accuracy: 0.5405 - val_loss: 1.0763 - val_accuracy: 0.6039\n",
            "Epoch 185/700\n",
            "104/104 [==============================] - 3s 27ms/step - loss: 1.1037 - accuracy: 0.5568 - val_loss: 1.0766 - val_accuracy: 0.6329\n",
            "Epoch 186/700\n",
            "104/104 [==============================] - 3s 27ms/step - loss: 1.1055 - accuracy: 0.5586 - val_loss: 1.0618 - val_accuracy: 0.6232\n",
            "Epoch 187/700\n",
            "104/104 [==============================] - 3s 27ms/step - loss: 1.0892 - accuracy: 0.5617 - val_loss: 1.0683 - val_accuracy: 0.6039\n",
            "Epoch 188/700\n",
            "104/104 [==============================] - 3s 29ms/step - loss: 1.1019 - accuracy: 0.5695 - val_loss: 1.0759 - val_accuracy: 0.6184\n",
            "Epoch 189/700\n",
            "104/104 [==============================] - 3s 29ms/step - loss: 1.1062 - accuracy: 0.5574 - val_loss: 1.0770 - val_accuracy: 0.6184\n",
            "Epoch 190/700\n",
            "104/104 [==============================] - 3s 27ms/step - loss: 1.1029 - accuracy: 0.5538 - val_loss: 1.0600 - val_accuracy: 0.6425\n",
            "Epoch 191/700\n",
            "104/104 [==============================] - 3s 27ms/step - loss: 1.0978 - accuracy: 0.5550 - val_loss: 1.0598 - val_accuracy: 0.6087\n",
            "Epoch 192/700\n",
            "104/104 [==============================] - 3s 27ms/step - loss: 1.0902 - accuracy: 0.5556 - val_loss: 1.0601 - val_accuracy: 0.5990\n",
            "Epoch 193/700\n",
            "104/104 [==============================] - 3s 27ms/step - loss: 1.1019 - accuracy: 0.5774 - val_loss: 1.0608 - val_accuracy: 0.6087\n",
            "Epoch 194/700\n",
            "104/104 [==============================] - 3s 28ms/step - loss: 1.1043 - accuracy: 0.5593 - val_loss: 1.0472 - val_accuracy: 0.6039\n",
            "Epoch 195/700\n",
            "104/104 [==============================] - 3s 26ms/step - loss: 1.0720 - accuracy: 0.5744 - val_loss: 1.0577 - val_accuracy: 0.6425\n",
            "Epoch 196/700\n",
            "104/104 [==============================] - 3s 26ms/step - loss: 1.0648 - accuracy: 0.5786 - val_loss: 1.0549 - val_accuracy: 0.6232\n",
            "Epoch 197/700\n",
            "104/104 [==============================] - 3s 26ms/step - loss: 1.0808 - accuracy: 0.5641 - val_loss: 1.0509 - val_accuracy: 0.6184\n",
            "Epoch 198/700\n",
            "104/104 [==============================] - 3s 25ms/step - loss: 1.0925 - accuracy: 0.5568 - val_loss: 1.0464 - val_accuracy: 0.6135\n",
            "Epoch 199/700\n",
            "104/104 [==============================] - 3s 28ms/step - loss: 1.0651 - accuracy: 0.5677 - val_loss: 1.0459 - val_accuracy: 0.6087\n",
            "Epoch 200/700\n",
            "104/104 [==============================] - 3s 26ms/step - loss: 1.0785 - accuracy: 0.5726 - val_loss: 1.0436 - val_accuracy: 0.6184\n",
            "Epoch 201/700\n",
            "104/104 [==============================] - 3s 27ms/step - loss: 1.0821 - accuracy: 0.5738 - val_loss: 1.0335 - val_accuracy: 0.6232\n",
            "Epoch 202/700\n",
            "104/104 [==============================] - 3s 26ms/step - loss: 1.0701 - accuracy: 0.5744 - val_loss: 1.0345 - val_accuracy: 0.6425\n",
            "Epoch 203/700\n",
            "104/104 [==============================] - 3s 27ms/step - loss: 1.0446 - accuracy: 0.5768 - val_loss: 1.0267 - val_accuracy: 0.6087\n",
            "Epoch 204/700\n",
            "104/104 [==============================] - 3s 27ms/step - loss: 1.0573 - accuracy: 0.5683 - val_loss: 1.0283 - val_accuracy: 0.6280\n",
            "Epoch 205/700\n",
            "104/104 [==============================] - 3s 29ms/step - loss: 1.0530 - accuracy: 0.5738 - val_loss: 1.0370 - val_accuracy: 0.6232\n",
            "Epoch 206/700\n",
            "104/104 [==============================] - 3s 29ms/step - loss: 1.0375 - accuracy: 0.5955 - val_loss: 1.0272 - val_accuracy: 0.6329\n",
            "Epoch 207/700\n",
            "104/104 [==============================] - 3s 27ms/step - loss: 1.0567 - accuracy: 0.5840 - val_loss: 1.0259 - val_accuracy: 0.6184\n",
            "Epoch 208/700\n",
            "104/104 [==============================] - 3s 27ms/step - loss: 1.0390 - accuracy: 0.5780 - val_loss: 1.0161 - val_accuracy: 0.6377\n",
            "Epoch 209/700\n",
            "104/104 [==============================] - 3s 26ms/step - loss: 1.0503 - accuracy: 0.5859 - val_loss: 1.0125 - val_accuracy: 0.6329\n",
            "Epoch 210/700\n",
            "104/104 [==============================] - 3s 27ms/step - loss: 1.0645 - accuracy: 0.5865 - val_loss: 1.0199 - val_accuracy: 0.6522\n",
            "Epoch 211/700\n",
            "104/104 [==============================] - 3s 28ms/step - loss: 1.0378 - accuracy: 0.5913 - val_loss: 1.0108 - val_accuracy: 0.6570\n",
            "Epoch 212/700\n",
            "104/104 [==============================] - 3s 27ms/step - loss: 1.0460 - accuracy: 0.5840 - val_loss: 1.0282 - val_accuracy: 0.6135\n",
            "Epoch 213/700\n",
            "104/104 [==============================] - 3s 26ms/step - loss: 1.0176 - accuracy: 0.5859 - val_loss: 1.0066 - val_accuracy: 0.6135\n",
            "Epoch 214/700\n",
            "104/104 [==============================] - 3s 26ms/step - loss: 1.0192 - accuracy: 0.5895 - val_loss: 1.0098 - val_accuracy: 0.6522\n",
            "Epoch 215/700\n",
            "104/104 [==============================] - 3s 26ms/step - loss: 1.0413 - accuracy: 0.5985 - val_loss: 1.0266 - val_accuracy: 0.6473\n",
            "Epoch 216/700\n",
            "104/104 [==============================] - 3s 27ms/step - loss: 1.0130 - accuracy: 0.5979 - val_loss: 0.9947 - val_accuracy: 0.6570\n",
            "Epoch 217/700\n",
            "104/104 [==============================] - 3s 28ms/step - loss: 1.0124 - accuracy: 0.5998 - val_loss: 0.9947 - val_accuracy: 0.6280\n",
            "Epoch 218/700\n",
            "104/104 [==============================] - 3s 27ms/step - loss: 1.0349 - accuracy: 0.5877 - val_loss: 1.0043 - val_accuracy: 0.6425\n",
            "Epoch 219/700\n",
            "104/104 [==============================] - 3s 26ms/step - loss: 1.0161 - accuracy: 0.5998 - val_loss: 1.0056 - val_accuracy: 0.6329\n",
            "Epoch 220/700\n",
            "104/104 [==============================] - 3s 27ms/step - loss: 1.0159 - accuracy: 0.6070 - val_loss: 1.0034 - val_accuracy: 0.6135\n",
            "Epoch 221/700\n",
            "104/104 [==============================] - 3s 26ms/step - loss: 1.0182 - accuracy: 0.5925 - val_loss: 1.0035 - val_accuracy: 0.6087\n",
            "Epoch 222/700\n",
            "104/104 [==============================] - 3s 27ms/step - loss: 1.0190 - accuracy: 0.5852 - val_loss: 1.0014 - val_accuracy: 0.6522\n",
            "Epoch 223/700\n",
            "104/104 [==============================] - 3s 26ms/step - loss: 0.9981 - accuracy: 0.5937 - val_loss: 0.9923 - val_accuracy: 0.6618\n",
            "Epoch 224/700\n",
            "104/104 [==============================] - 3s 27ms/step - loss: 0.9941 - accuracy: 0.6070 - val_loss: 1.0013 - val_accuracy: 0.6377\n",
            "Epoch 225/700\n",
            "104/104 [==============================] - 3s 26ms/step - loss: 1.0142 - accuracy: 0.5985 - val_loss: 0.9977 - val_accuracy: 0.6473\n",
            "Epoch 226/700\n",
            "104/104 [==============================] - 3s 27ms/step - loss: 0.9944 - accuracy: 0.6082 - val_loss: 0.9995 - val_accuracy: 0.6232\n",
            "Epoch 227/700\n",
            "104/104 [==============================] - 3s 27ms/step - loss: 1.0037 - accuracy: 0.5955 - val_loss: 0.9887 - val_accuracy: 0.6570\n",
            "Epoch 228/700\n",
            "104/104 [==============================] - 3s 27ms/step - loss: 1.0201 - accuracy: 0.5985 - val_loss: 0.9795 - val_accuracy: 0.6618\n",
            "Epoch 229/700\n",
            "104/104 [==============================] - 3s 27ms/step - loss: 0.9779 - accuracy: 0.6155 - val_loss: 1.0004 - val_accuracy: 0.6667\n",
            "Epoch 230/700\n",
            "104/104 [==============================] - 3s 26ms/step - loss: 1.0125 - accuracy: 0.6149 - val_loss: 0.9844 - val_accuracy: 0.6473\n",
            "Epoch 231/700\n",
            "104/104 [==============================] - 3s 31ms/step - loss: 1.0043 - accuracy: 0.5973 - val_loss: 0.9939 - val_accuracy: 0.6425\n",
            "Epoch 232/700\n",
            "104/104 [==============================] - 3s 28ms/step - loss: 1.0042 - accuracy: 0.6046 - val_loss: 0.9852 - val_accuracy: 0.6377\n",
            "Epoch 233/700\n",
            "104/104 [==============================] - 3s 27ms/step - loss: 0.9947 - accuracy: 0.6052 - val_loss: 0.9815 - val_accuracy: 0.6425\n",
            "Epoch 234/700\n",
            "104/104 [==============================] - 3s 26ms/step - loss: 1.0075 - accuracy: 0.5973 - val_loss: 0.9754 - val_accuracy: 0.6280\n",
            "Epoch 235/700\n",
            "104/104 [==============================] - 3s 26ms/step - loss: 0.9834 - accuracy: 0.6070 - val_loss: 0.9816 - val_accuracy: 0.6377\n",
            "Epoch 236/700\n",
            "104/104 [==============================] - 3s 28ms/step - loss: 0.9722 - accuracy: 0.6227 - val_loss: 0.9834 - val_accuracy: 0.6473\n",
            "Epoch 237/700\n",
            "104/104 [==============================] - 3s 27ms/step - loss: 0.9531 - accuracy: 0.6245 - val_loss: 0.9688 - val_accuracy: 0.6473\n",
            "Epoch 238/700\n",
            "104/104 [==============================] - 3s 27ms/step - loss: 0.9588 - accuracy: 0.6330 - val_loss: 0.9759 - val_accuracy: 0.6377\n",
            "Epoch 239/700\n",
            "104/104 [==============================] - 3s 28ms/step - loss: 0.9795 - accuracy: 0.6149 - val_loss: 0.9723 - val_accuracy: 0.6570\n",
            "Epoch 240/700\n",
            "104/104 [==============================] - 3s 27ms/step - loss: 0.9723 - accuracy: 0.6239 - val_loss: 0.9571 - val_accuracy: 0.6570\n",
            "Epoch 241/700\n",
            "104/104 [==============================] - 3s 26ms/step - loss: 0.9631 - accuracy: 0.6203 - val_loss: 0.9604 - val_accuracy: 0.6570\n",
            "Epoch 242/700\n",
            "104/104 [==============================] - 3s 27ms/step - loss: 0.9527 - accuracy: 0.6270 - val_loss: 0.9553 - val_accuracy: 0.6473\n",
            "Epoch 243/700\n",
            "104/104 [==============================] - 3s 27ms/step - loss: 0.9513 - accuracy: 0.6209 - val_loss: 0.9509 - val_accuracy: 0.6473\n",
            "Epoch 244/700\n",
            "104/104 [==============================] - 3s 26ms/step - loss: 0.9588 - accuracy: 0.6119 - val_loss: 0.9691 - val_accuracy: 0.6522\n",
            "Epoch 245/700\n",
            "104/104 [==============================] - 3s 26ms/step - loss: 0.9609 - accuracy: 0.6270 - val_loss: 0.9507 - val_accuracy: 0.6473\n",
            "Epoch 246/700\n",
            "104/104 [==============================] - 3s 26ms/step - loss: 0.9524 - accuracy: 0.6270 - val_loss: 0.9598 - val_accuracy: 0.6377\n",
            "Epoch 247/700\n",
            "104/104 [==============================] - 3s 26ms/step - loss: 0.9476 - accuracy: 0.6282 - val_loss: 0.9686 - val_accuracy: 0.6473\n",
            "Epoch 248/700\n",
            "104/104 [==============================] - 3s 26ms/step - loss: 0.9416 - accuracy: 0.6342 - val_loss: 0.9581 - val_accuracy: 0.6473\n",
            "Epoch 249/700\n",
            "104/104 [==============================] - 3s 27ms/step - loss: 0.9512 - accuracy: 0.6221 - val_loss: 0.9597 - val_accuracy: 0.6473\n",
            "Epoch 250/700\n",
            "104/104 [==============================] - 3s 26ms/step - loss: 0.9490 - accuracy: 0.6300 - val_loss: 0.9578 - val_accuracy: 0.6522\n",
            "Epoch 251/700\n",
            "104/104 [==============================] - 3s 27ms/step - loss: 0.9504 - accuracy: 0.6258 - val_loss: 0.9563 - val_accuracy: 0.6522\n",
            "Epoch 252/700\n",
            "104/104 [==============================] - 3s 27ms/step - loss: 0.9419 - accuracy: 0.6312 - val_loss: 0.9456 - val_accuracy: 0.6473\n",
            "Epoch 253/700\n",
            "104/104 [==============================] - 3s 27ms/step - loss: 0.9353 - accuracy: 0.6354 - val_loss: 0.9505 - val_accuracy: 0.6763\n",
            "Epoch 254/700\n",
            "104/104 [==============================] - 3s 27ms/step - loss: 0.9557 - accuracy: 0.6203 - val_loss: 0.9381 - val_accuracy: 0.6715\n",
            "Epoch 255/700\n",
            "104/104 [==============================] - 4s 39ms/step - loss: 0.9509 - accuracy: 0.6330 - val_loss: 0.9414 - val_accuracy: 0.6715\n",
            "Epoch 256/700\n",
            "104/104 [==============================] - 4s 42ms/step - loss: 0.9451 - accuracy: 0.6372 - val_loss: 0.9504 - val_accuracy: 0.6522\n",
            "Epoch 257/700\n",
            "104/104 [==============================] - 5s 48ms/step - loss: 0.9394 - accuracy: 0.6245 - val_loss: 0.9342 - val_accuracy: 0.6715\n",
            "Epoch 258/700\n",
            "104/104 [==============================] - 3s 29ms/step - loss: 0.9338 - accuracy: 0.6336 - val_loss: 0.9292 - val_accuracy: 0.6522\n",
            "Epoch 259/700\n",
            "104/104 [==============================] - 4s 35ms/step - loss: 0.9589 - accuracy: 0.6294 - val_loss: 0.9314 - val_accuracy: 0.6667\n",
            "Epoch 260/700\n",
            "104/104 [==============================] - 5s 51ms/step - loss: 0.9160 - accuracy: 0.6391 - val_loss: 0.9248 - val_accuracy: 0.6812\n",
            "Epoch 261/700\n",
            "104/104 [==============================] - 4s 37ms/step - loss: 0.9255 - accuracy: 0.6421 - val_loss: 0.9359 - val_accuracy: 0.6377\n",
            "Epoch 262/700\n",
            "104/104 [==============================] - 4s 40ms/step - loss: 0.9287 - accuracy: 0.6385 - val_loss: 0.9288 - val_accuracy: 0.6763\n",
            "Epoch 263/700\n",
            "104/104 [==============================] - 3s 26ms/step - loss: 0.9305 - accuracy: 0.6385 - val_loss: 0.9353 - val_accuracy: 0.6618\n",
            "Epoch 264/700\n",
            "104/104 [==============================] - 3s 27ms/step - loss: 0.9249 - accuracy: 0.6378 - val_loss: 0.9356 - val_accuracy: 0.6570\n",
            "Epoch 265/700\n",
            "104/104 [==============================] - 3s 27ms/step - loss: 0.9038 - accuracy: 0.6397 - val_loss: 0.9334 - val_accuracy: 0.6618\n",
            "Epoch 266/700\n",
            "104/104 [==============================] - 3s 28ms/step - loss: 0.9106 - accuracy: 0.6427 - val_loss: 0.9127 - val_accuracy: 0.6570\n",
            "Epoch 267/700\n",
            "104/104 [==============================] - 3s 28ms/step - loss: 0.8970 - accuracy: 0.6524 - val_loss: 0.9347 - val_accuracy: 0.6522\n",
            "Epoch 268/700\n",
            "104/104 [==============================] - 3s 28ms/step - loss: 0.9200 - accuracy: 0.6427 - val_loss: 0.9122 - val_accuracy: 0.6618\n",
            "Epoch 269/700\n",
            "104/104 [==============================] - 3s 29ms/step - loss: 0.9347 - accuracy: 0.6264 - val_loss: 0.9185 - val_accuracy: 0.6715\n",
            "Epoch 270/700\n",
            "104/104 [==============================] - 3s 29ms/step - loss: 0.9064 - accuracy: 0.6403 - val_loss: 0.9060 - val_accuracy: 0.6715\n",
            "Epoch 271/700\n",
            "104/104 [==============================] - 3s 28ms/step - loss: 0.9298 - accuracy: 0.6445 - val_loss: 0.9151 - val_accuracy: 0.6667\n",
            "Epoch 272/700\n",
            "104/104 [==============================] - 3s 29ms/step - loss: 0.9139 - accuracy: 0.6421 - val_loss: 0.9075 - val_accuracy: 0.6812\n",
            "Epoch 273/700\n",
            "104/104 [==============================] - 3s 30ms/step - loss: 0.8936 - accuracy: 0.6360 - val_loss: 0.9122 - val_accuracy: 0.6280\n",
            "Epoch 274/700\n",
            "104/104 [==============================] - 3s 29ms/step - loss: 0.9133 - accuracy: 0.6360 - val_loss: 0.9129 - val_accuracy: 0.6667\n",
            "Epoch 275/700\n",
            "104/104 [==============================] - 3s 28ms/step - loss: 0.8872 - accuracy: 0.6663 - val_loss: 0.8946 - val_accuracy: 0.6763\n",
            "Epoch 276/700\n",
            "104/104 [==============================] - 3s 28ms/step - loss: 0.9007 - accuracy: 0.6524 - val_loss: 0.9038 - val_accuracy: 0.6763\n",
            "Epoch 277/700\n",
            "104/104 [==============================] - 3s 29ms/step - loss: 0.9116 - accuracy: 0.6385 - val_loss: 0.9061 - val_accuracy: 0.6763\n",
            "Epoch 278/700\n",
            "104/104 [==============================] - 3s 29ms/step - loss: 0.8923 - accuracy: 0.6590 - val_loss: 0.9082 - val_accuracy: 0.6570\n",
            "Epoch 279/700\n",
            "104/104 [==============================] - 3s 28ms/step - loss: 0.8901 - accuracy: 0.6451 - val_loss: 0.9007 - val_accuracy: 0.6667\n",
            "Epoch 280/700\n",
            "104/104 [==============================] - 3s 27ms/step - loss: 0.8797 - accuracy: 0.6524 - val_loss: 0.9011 - val_accuracy: 0.6715\n",
            "Epoch 281/700\n",
            "104/104 [==============================] - 3s 27ms/step - loss: 0.8893 - accuracy: 0.6524 - val_loss: 0.9003 - val_accuracy: 0.6522\n",
            "Epoch 282/700\n",
            "104/104 [==============================] - 3s 28ms/step - loss: 0.8855 - accuracy: 0.6530 - val_loss: 0.9019 - val_accuracy: 0.6522\n",
            "Epoch 283/700\n",
            "104/104 [==============================] - 3s 28ms/step - loss: 0.8696 - accuracy: 0.6584 - val_loss: 0.8929 - val_accuracy: 0.6667\n",
            "Epoch 284/700\n",
            "104/104 [==============================] - 3s 27ms/step - loss: 0.8847 - accuracy: 0.6439 - val_loss: 0.8943 - val_accuracy: 0.6522\n",
            "Epoch 285/700\n",
            "104/104 [==============================] - 3s 28ms/step - loss: 0.8949 - accuracy: 0.6481 - val_loss: 0.9045 - val_accuracy: 0.6618\n",
            "Epoch 286/700\n",
            "104/104 [==============================] - 3s 27ms/step - loss: 0.8565 - accuracy: 0.6723 - val_loss: 0.8848 - val_accuracy: 0.6522\n",
            "Epoch 287/700\n",
            "104/104 [==============================] - 3s 28ms/step - loss: 0.8618 - accuracy: 0.6644 - val_loss: 0.8893 - val_accuracy: 0.6763\n",
            "Epoch 288/700\n",
            "104/104 [==============================] - 3s 28ms/step - loss: 0.8745 - accuracy: 0.6644 - val_loss: 0.8827 - val_accuracy: 0.6763\n",
            "Epoch 289/700\n",
            "104/104 [==============================] - 3s 28ms/step - loss: 0.8741 - accuracy: 0.6524 - val_loss: 0.8901 - val_accuracy: 0.6618\n",
            "Epoch 290/700\n",
            "104/104 [==============================] - 3s 27ms/step - loss: 0.8535 - accuracy: 0.6602 - val_loss: 0.8892 - val_accuracy: 0.6425\n",
            "Epoch 291/700\n",
            "104/104 [==============================] - 3s 26ms/step - loss: 0.8574 - accuracy: 0.6663 - val_loss: 0.8815 - val_accuracy: 0.6812\n",
            "Epoch 292/700\n",
            "104/104 [==============================] - 3s 28ms/step - loss: 0.8612 - accuracy: 0.6620 - val_loss: 0.8910 - val_accuracy: 0.6522\n",
            "Epoch 293/700\n",
            "104/104 [==============================] - 3s 32ms/step - loss: 0.8857 - accuracy: 0.6554 - val_loss: 0.8980 - val_accuracy: 0.6570\n",
            "Epoch 294/700\n",
            "104/104 [==============================] - 3s 29ms/step - loss: 0.8702 - accuracy: 0.6663 - val_loss: 0.8780 - val_accuracy: 0.6522\n",
            "Epoch 295/700\n",
            "104/104 [==============================] - 3s 29ms/step - loss: 0.8395 - accuracy: 0.6892 - val_loss: 0.8796 - val_accuracy: 0.6618\n",
            "Epoch 296/700\n",
            "104/104 [==============================] - 3s 28ms/step - loss: 0.8763 - accuracy: 0.6542 - val_loss: 0.8788 - val_accuracy: 0.6618\n",
            "Epoch 297/700\n",
            "104/104 [==============================] - 3s 28ms/step - loss: 0.8404 - accuracy: 0.6735 - val_loss: 0.8818 - val_accuracy: 0.6667\n",
            "Epoch 298/700\n",
            "104/104 [==============================] - 3s 30ms/step - loss: 0.8624 - accuracy: 0.6675 - val_loss: 0.8808 - val_accuracy: 0.6618\n",
            "Epoch 299/700\n",
            "104/104 [==============================] - 3s 28ms/step - loss: 0.8552 - accuracy: 0.6566 - val_loss: 0.8750 - val_accuracy: 0.6763\n",
            "Epoch 300/700\n",
            "104/104 [==============================] - 3s 28ms/step - loss: 0.8506 - accuracy: 0.6820 - val_loss: 0.8764 - val_accuracy: 0.6715\n",
            "Epoch 301/700\n",
            "104/104 [==============================] - 3s 28ms/step - loss: 0.8671 - accuracy: 0.6542 - val_loss: 0.8772 - val_accuracy: 0.6570\n",
            "Epoch 302/700\n",
            "104/104 [==============================] - 3s 28ms/step - loss: 0.8376 - accuracy: 0.6729 - val_loss: 0.8691 - val_accuracy: 0.6860\n",
            "Epoch 303/700\n",
            "104/104 [==============================] - 3s 28ms/step - loss: 0.8426 - accuracy: 0.6675 - val_loss: 0.8669 - val_accuracy: 0.6812\n",
            "Epoch 304/700\n",
            "104/104 [==============================] - 3s 27ms/step - loss: 0.8569 - accuracy: 0.6590 - val_loss: 0.8721 - val_accuracy: 0.6812\n",
            "Epoch 305/700\n",
            "104/104 [==============================] - 3s 27ms/step - loss: 0.8561 - accuracy: 0.6675 - val_loss: 0.8710 - val_accuracy: 0.6570\n",
            "Epoch 306/700\n",
            "104/104 [==============================] - 3s 27ms/step - loss: 0.8436 - accuracy: 0.6620 - val_loss: 0.8690 - val_accuracy: 0.6860\n",
            "Epoch 307/700\n",
            "104/104 [==============================] - 3s 29ms/step - loss: 0.8388 - accuracy: 0.6759 - val_loss: 0.8699 - val_accuracy: 0.6667\n",
            "Epoch 308/700\n",
            "104/104 [==============================] - 3s 28ms/step - loss: 0.8347 - accuracy: 0.6759 - val_loss: 0.8645 - val_accuracy: 0.6667\n",
            "Epoch 309/700\n",
            "104/104 [==============================] - 3s 28ms/step - loss: 0.8538 - accuracy: 0.6608 - val_loss: 0.8628 - val_accuracy: 0.6618\n",
            "Epoch 310/700\n",
            "104/104 [==============================] - 3s 29ms/step - loss: 0.8690 - accuracy: 0.6475 - val_loss: 0.8728 - val_accuracy: 0.7053\n",
            "Epoch 311/700\n",
            "104/104 [==============================] - 3s 31ms/step - loss: 0.8295 - accuracy: 0.6735 - val_loss: 0.8578 - val_accuracy: 0.6957\n",
            "Epoch 312/700\n",
            "104/104 [==============================] - 3s 29ms/step - loss: 0.8353 - accuracy: 0.6699 - val_loss: 0.8488 - val_accuracy: 0.6908\n",
            "Epoch 313/700\n",
            "104/104 [==============================] - 3s 29ms/step - loss: 0.8465 - accuracy: 0.6784 - val_loss: 0.8540 - val_accuracy: 0.6908\n",
            "Epoch 314/700\n",
            "104/104 [==============================] - 3s 28ms/step - loss: 0.8342 - accuracy: 0.6790 - val_loss: 0.8470 - val_accuracy: 0.6860\n",
            "Epoch 315/700\n",
            "104/104 [==============================] - 3s 28ms/step - loss: 0.8372 - accuracy: 0.6850 - val_loss: 0.8557 - val_accuracy: 0.6860\n",
            "Epoch 316/700\n",
            "104/104 [==============================] - 3s 28ms/step - loss: 0.8347 - accuracy: 0.6814 - val_loss: 0.8523 - val_accuracy: 0.6908\n",
            "Epoch 317/700\n",
            "104/104 [==============================] - 3s 28ms/step - loss: 0.8456 - accuracy: 0.6753 - val_loss: 0.8579 - val_accuracy: 0.6763\n",
            "Epoch 318/700\n",
            "104/104 [==============================] - 3s 27ms/step - loss: 0.8297 - accuracy: 0.6729 - val_loss: 0.8668 - val_accuracy: 0.6667\n",
            "Epoch 319/700\n",
            "104/104 [==============================] - 3s 26ms/step - loss: 0.8308 - accuracy: 0.6790 - val_loss: 0.8495 - val_accuracy: 0.6908\n",
            "Epoch 320/700\n",
            "104/104 [==============================] - 3s 27ms/step - loss: 0.8253 - accuracy: 0.6856 - val_loss: 0.8544 - val_accuracy: 0.6618\n",
            "Epoch 321/700\n",
            "104/104 [==============================] - 3s 27ms/step - loss: 0.8228 - accuracy: 0.6687 - val_loss: 0.8654 - val_accuracy: 0.6763\n",
            "Epoch 322/700\n",
            "104/104 [==============================] - 3s 28ms/step - loss: 0.8258 - accuracy: 0.6753 - val_loss: 0.8615 - val_accuracy: 0.6957\n",
            "Epoch 323/700\n",
            "104/104 [==============================] - 3s 28ms/step - loss: 0.8165 - accuracy: 0.6711 - val_loss: 0.8542 - val_accuracy: 0.6957\n",
            "Epoch 324/700\n",
            "104/104 [==============================] - 3s 28ms/step - loss: 0.8418 - accuracy: 0.6747 - val_loss: 0.8679 - val_accuracy: 0.6522\n",
            "Epoch 325/700\n",
            "104/104 [==============================] - 3s 27ms/step - loss: 0.8314 - accuracy: 0.6651 - val_loss: 0.8629 - val_accuracy: 0.6812\n",
            "Epoch 326/700\n",
            "104/104 [==============================] - 3s 27ms/step - loss: 0.8079 - accuracy: 0.6790 - val_loss: 0.8629 - val_accuracy: 0.6715\n",
            "Epoch 327/700\n",
            "104/104 [==============================] - 3s 28ms/step - loss: 0.8116 - accuracy: 0.6796 - val_loss: 0.8564 - val_accuracy: 0.6377\n",
            "Epoch 328/700\n",
            "104/104 [==============================] - 3s 28ms/step - loss: 0.8198 - accuracy: 0.6753 - val_loss: 0.8523 - val_accuracy: 0.6667\n",
            "Epoch 329/700\n",
            "104/104 [==============================] - 3s 28ms/step - loss: 0.8189 - accuracy: 0.6759 - val_loss: 0.8450 - val_accuracy: 0.6715\n",
            "Epoch 330/700\n",
            "104/104 [==============================] - 3s 27ms/step - loss: 0.8179 - accuracy: 0.6838 - val_loss: 0.8426 - val_accuracy: 0.6908\n",
            "Epoch 331/700\n",
            "104/104 [==============================] - 3s 29ms/step - loss: 0.8279 - accuracy: 0.6753 - val_loss: 0.8524 - val_accuracy: 0.6618\n",
            "Epoch 332/700\n",
            "104/104 [==============================] - 3s 28ms/step - loss: 0.8250 - accuracy: 0.6784 - val_loss: 0.8581 - val_accuracy: 0.6667\n",
            "Epoch 333/700\n",
            "104/104 [==============================] - 3s 27ms/step - loss: 0.8106 - accuracy: 0.6778 - val_loss: 0.8548 - val_accuracy: 0.6860\n",
            "Epoch 334/700\n",
            "104/104 [==============================] - 3s 28ms/step - loss: 0.7924 - accuracy: 0.6947 - val_loss: 0.8386 - val_accuracy: 0.6667\n",
            "Epoch 335/700\n",
            "104/104 [==============================] - 3s 28ms/step - loss: 0.7963 - accuracy: 0.6898 - val_loss: 0.8410 - val_accuracy: 0.6667\n",
            "Epoch 336/700\n",
            "104/104 [==============================] - 3s 28ms/step - loss: 0.8034 - accuracy: 0.6923 - val_loss: 0.8392 - val_accuracy: 0.6763\n",
            "Epoch 337/700\n",
            "104/104 [==============================] - 3s 28ms/step - loss: 0.8007 - accuracy: 0.6778 - val_loss: 0.8292 - val_accuracy: 0.6908\n",
            "Epoch 338/700\n",
            "104/104 [==============================] - 3s 28ms/step - loss: 0.7997 - accuracy: 0.6814 - val_loss: 0.8332 - val_accuracy: 0.7005\n",
            "Epoch 339/700\n",
            "104/104 [==============================] - 3s 28ms/step - loss: 0.7992 - accuracy: 0.6929 - val_loss: 0.8423 - val_accuracy: 0.6618\n",
            "Epoch 340/700\n",
            "104/104 [==============================] - 3s 27ms/step - loss: 0.7947 - accuracy: 0.6874 - val_loss: 0.8419 - val_accuracy: 0.6473\n",
            "Epoch 341/700\n",
            "104/104 [==============================] - 3s 28ms/step - loss: 0.8119 - accuracy: 0.6657 - val_loss: 0.8473 - val_accuracy: 0.6618\n",
            "Epoch 342/700\n",
            "104/104 [==============================] - 3s 28ms/step - loss: 0.7909 - accuracy: 0.6904 - val_loss: 0.8365 - val_accuracy: 0.6715\n",
            "Epoch 343/700\n",
            "104/104 [==============================] - 3s 28ms/step - loss: 0.7871 - accuracy: 0.6971 - val_loss: 0.8420 - val_accuracy: 0.6522\n",
            "Epoch 344/700\n",
            "104/104 [==============================] - 3s 28ms/step - loss: 0.7976 - accuracy: 0.6989 - val_loss: 0.8370 - val_accuracy: 0.6667\n",
            "Epoch 345/700\n",
            "104/104 [==============================] - 3s 27ms/step - loss: 0.7927 - accuracy: 0.6959 - val_loss: 0.8343 - val_accuracy: 0.6618\n",
            "Epoch 346/700\n",
            "104/104 [==============================] - 3s 28ms/step - loss: 0.7762 - accuracy: 0.6989 - val_loss: 0.8365 - val_accuracy: 0.6667\n",
            "Epoch 347/700\n",
            "104/104 [==============================] - 3s 28ms/step - loss: 0.7697 - accuracy: 0.6983 - val_loss: 0.8272 - val_accuracy: 0.6812\n",
            "Epoch 348/700\n",
            "104/104 [==============================] - 3s 28ms/step - loss: 0.7766 - accuracy: 0.7037 - val_loss: 0.8227 - val_accuracy: 0.6618\n",
            "Epoch 349/700\n",
            "104/104 [==============================] - 3s 28ms/step - loss: 0.7764 - accuracy: 0.6886 - val_loss: 0.8231 - val_accuracy: 0.6715\n",
            "Epoch 350/700\n",
            "104/104 [==============================] - 3s 27ms/step - loss: 0.7664 - accuracy: 0.7031 - val_loss: 0.8249 - val_accuracy: 0.6860\n",
            "Epoch 351/700\n",
            "104/104 [==============================] - 3s 28ms/step - loss: 0.7743 - accuracy: 0.6971 - val_loss: 0.8274 - val_accuracy: 0.6715\n",
            "Epoch 352/700\n",
            "104/104 [==============================] - 3s 29ms/step - loss: 0.7832 - accuracy: 0.6989 - val_loss: 0.8238 - val_accuracy: 0.6618\n",
            "Epoch 353/700\n",
            "104/104 [==============================] - 3s 28ms/step - loss: 0.7757 - accuracy: 0.7080 - val_loss: 0.8254 - val_accuracy: 0.6667\n",
            "Epoch 354/700\n",
            "104/104 [==============================] - 3s 28ms/step - loss: 0.7763 - accuracy: 0.6898 - val_loss: 0.8281 - val_accuracy: 0.6618\n",
            "Epoch 355/700\n",
            "104/104 [==============================] - 3s 28ms/step - loss: 0.7804 - accuracy: 0.6959 - val_loss: 0.8327 - val_accuracy: 0.6715\n",
            "Epoch 356/700\n",
            "104/104 [==============================] - 3s 28ms/step - loss: 0.7959 - accuracy: 0.6826 - val_loss: 0.8267 - val_accuracy: 0.6812\n",
            "Epoch 357/700\n",
            "104/104 [==============================] - 3s 28ms/step - loss: 0.7781 - accuracy: 0.6898 - val_loss: 0.8197 - val_accuracy: 0.6860\n",
            "Epoch 358/700\n",
            "104/104 [==============================] - 3s 28ms/step - loss: 0.7711 - accuracy: 0.6995 - val_loss: 0.8280 - val_accuracy: 0.6812\n",
            "Epoch 359/700\n",
            "104/104 [==============================] - 3s 28ms/step - loss: 0.7682 - accuracy: 0.7025 - val_loss: 0.8296 - val_accuracy: 0.6763\n",
            "Epoch 360/700\n",
            "104/104 [==============================] - 3s 28ms/step - loss: 0.7685 - accuracy: 0.6911 - val_loss: 0.8197 - val_accuracy: 0.6667\n",
            "Epoch 361/700\n",
            "104/104 [==============================] - 3s 27ms/step - loss: 0.7598 - accuracy: 0.7183 - val_loss: 0.8093 - val_accuracy: 0.6715\n",
            "Epoch 362/700\n",
            "104/104 [==============================] - 3s 28ms/step - loss: 0.7736 - accuracy: 0.6977 - val_loss: 0.8147 - val_accuracy: 0.6570\n",
            "Epoch 363/700\n",
            "104/104 [==============================] - 3s 28ms/step - loss: 0.7713 - accuracy: 0.6868 - val_loss: 0.8197 - val_accuracy: 0.6522\n",
            "Epoch 364/700\n",
            "104/104 [==============================] - 3s 28ms/step - loss: 0.7550 - accuracy: 0.7110 - val_loss: 0.8179 - val_accuracy: 0.6715\n",
            "Epoch 365/700\n",
            "104/104 [==============================] - 3s 27ms/step - loss: 0.7664 - accuracy: 0.7104 - val_loss: 0.8222 - val_accuracy: 0.6715\n",
            "Epoch 366/700\n",
            "104/104 [==============================] - 3s 28ms/step - loss: 0.7601 - accuracy: 0.7110 - val_loss: 0.8135 - val_accuracy: 0.6715\n",
            "Epoch 367/700\n",
            "104/104 [==============================] - 3s 28ms/step - loss: 0.7511 - accuracy: 0.7001 - val_loss: 0.8067 - val_accuracy: 0.6763\n",
            "Epoch 368/700\n",
            "104/104 [==============================] - 3s 28ms/step - loss: 0.7623 - accuracy: 0.7056 - val_loss: 0.8075 - val_accuracy: 0.6908\n",
            "Epoch 369/700\n",
            "104/104 [==============================] - 3s 28ms/step - loss: 0.7623 - accuracy: 0.6989 - val_loss: 0.8173 - val_accuracy: 0.6570\n",
            "Epoch 370/700\n",
            "104/104 [==============================] - 3s 28ms/step - loss: 0.7626 - accuracy: 0.7037 - val_loss: 0.8179 - val_accuracy: 0.6570\n",
            "Epoch 371/700\n",
            "104/104 [==============================] - 3s 29ms/step - loss: 0.7465 - accuracy: 0.7044 - val_loss: 0.8211 - val_accuracy: 0.6522\n",
            "Epoch 372/700\n",
            "104/104 [==============================] - 3s 31ms/step - loss: 0.7443 - accuracy: 0.7116 - val_loss: 0.7957 - val_accuracy: 0.6715\n",
            "Epoch 373/700\n",
            "104/104 [==============================] - 3s 29ms/step - loss: 0.7574 - accuracy: 0.7092 - val_loss: 0.8067 - val_accuracy: 0.6473\n",
            "Epoch 374/700\n",
            "104/104 [==============================] - 3s 28ms/step - loss: 0.7531 - accuracy: 0.7170 - val_loss: 0.8066 - val_accuracy: 0.6908\n",
            "Epoch 375/700\n",
            "104/104 [==============================] - 3s 28ms/step - loss: 0.7531 - accuracy: 0.7164 - val_loss: 0.8004 - val_accuracy: 0.6667\n",
            "Epoch 376/700\n",
            "104/104 [==============================] - 3s 28ms/step - loss: 0.7469 - accuracy: 0.7110 - val_loss: 0.8005 - val_accuracy: 0.6763\n",
            "Epoch 377/700\n",
            "104/104 [==============================] - 3s 28ms/step - loss: 0.7348 - accuracy: 0.7110 - val_loss: 0.7966 - val_accuracy: 0.6715\n",
            "Epoch 378/700\n",
            "104/104 [==============================] - 3s 28ms/step - loss: 0.7603 - accuracy: 0.7044 - val_loss: 0.8069 - val_accuracy: 0.6570\n",
            "Epoch 379/700\n",
            "104/104 [==============================] - 3s 28ms/step - loss: 0.7399 - accuracy: 0.7189 - val_loss: 0.7968 - val_accuracy: 0.6763\n",
            "Epoch 380/700\n",
            "104/104 [==============================] - 3s 29ms/step - loss: 0.7118 - accuracy: 0.7273 - val_loss: 0.7990 - val_accuracy: 0.6715\n",
            "Epoch 381/700\n",
            "104/104 [==============================] - 3s 29ms/step - loss: 0.7493 - accuracy: 0.7068 - val_loss: 0.7961 - val_accuracy: 0.7005\n",
            "Epoch 382/700\n",
            "104/104 [==============================] - 3s 28ms/step - loss: 0.7372 - accuracy: 0.7056 - val_loss: 0.8028 - val_accuracy: 0.6763\n",
            "Epoch 383/700\n",
            "104/104 [==============================] - 3s 29ms/step - loss: 0.7402 - accuracy: 0.7195 - val_loss: 0.7967 - val_accuracy: 0.6860\n",
            "Epoch 384/700\n",
            "104/104 [==============================] - 3s 28ms/step - loss: 0.7283 - accuracy: 0.7110 - val_loss: 0.8045 - val_accuracy: 0.6860\n",
            "Epoch 385/700\n",
            "104/104 [==============================] - 3s 28ms/step - loss: 0.7295 - accuracy: 0.7195 - val_loss: 0.8119 - val_accuracy: 0.6715\n",
            "Epoch 386/700\n",
            "104/104 [==============================] - 3s 28ms/step - loss: 0.7297 - accuracy: 0.7146 - val_loss: 0.7925 - val_accuracy: 0.7005\n",
            "Epoch 387/700\n",
            "104/104 [==============================] - 3s 28ms/step - loss: 0.7237 - accuracy: 0.7219 - val_loss: 0.7823 - val_accuracy: 0.6763\n",
            "Epoch 388/700\n",
            "104/104 [==============================] - 3s 29ms/step - loss: 0.7473 - accuracy: 0.7164 - val_loss: 0.7902 - val_accuracy: 0.6812\n",
            "Epoch 389/700\n",
            "104/104 [==============================] - 3s 29ms/step - loss: 0.7441 - accuracy: 0.7068 - val_loss: 0.7963 - val_accuracy: 0.6812\n",
            "Epoch 390/700\n",
            "104/104 [==============================] - 3s 30ms/step - loss: 0.7230 - accuracy: 0.7291 - val_loss: 0.7964 - val_accuracy: 0.6763\n",
            "Epoch 391/700\n",
            "104/104 [==============================] - 3s 29ms/step - loss: 0.7194 - accuracy: 0.7122 - val_loss: 0.7965 - val_accuracy: 0.6715\n",
            "Epoch 392/700\n",
            "104/104 [==============================] - 3s 31ms/step - loss: 0.7321 - accuracy: 0.7237 - val_loss: 0.7868 - val_accuracy: 0.7053\n",
            "Epoch 393/700\n",
            "104/104 [==============================] - 3s 29ms/step - loss: 0.7248 - accuracy: 0.7207 - val_loss: 0.7873 - val_accuracy: 0.6860\n",
            "Epoch 394/700\n",
            "104/104 [==============================] - 3s 29ms/step - loss: 0.7222 - accuracy: 0.7104 - val_loss: 0.7909 - val_accuracy: 0.6715\n",
            "Epoch 395/700\n",
            "104/104 [==============================] - 3s 29ms/step - loss: 0.7203 - accuracy: 0.7225 - val_loss: 0.7818 - val_accuracy: 0.6812\n",
            "Epoch 396/700\n",
            "104/104 [==============================] - 3s 29ms/step - loss: 0.7126 - accuracy: 0.7346 - val_loss: 0.7889 - val_accuracy: 0.6812\n",
            "Epoch 397/700\n",
            "104/104 [==============================] - 3s 28ms/step - loss: 0.7136 - accuracy: 0.7158 - val_loss: 0.7873 - val_accuracy: 0.6715\n",
            "Epoch 398/700\n",
            "104/104 [==============================] - 3s 28ms/step - loss: 0.7077 - accuracy: 0.7213 - val_loss: 0.7833 - val_accuracy: 0.7005\n",
            "Epoch 399/700\n",
            "104/104 [==============================] - 3s 28ms/step - loss: 0.7098 - accuracy: 0.7304 - val_loss: 0.7937 - val_accuracy: 0.6618\n",
            "Epoch 400/700\n",
            "104/104 [==============================] - 3s 29ms/step - loss: 0.7036 - accuracy: 0.7304 - val_loss: 0.8100 - val_accuracy: 0.6715\n",
            "Epoch 401/700\n",
            "104/104 [==============================] - 3s 29ms/step - loss: 0.7090 - accuracy: 0.7249 - val_loss: 0.7886 - val_accuracy: 0.7005\n",
            "Epoch 402/700\n",
            "104/104 [==============================] - 3s 29ms/step - loss: 0.7150 - accuracy: 0.7255 - val_loss: 0.7778 - val_accuracy: 0.6860\n",
            "Epoch 403/700\n",
            "104/104 [==============================] - 3s 29ms/step - loss: 0.7181 - accuracy: 0.7134 - val_loss: 0.7793 - val_accuracy: 0.6667\n",
            "Epoch 404/700\n",
            "104/104 [==============================] - 3s 29ms/step - loss: 0.7320 - accuracy: 0.7116 - val_loss: 0.7902 - val_accuracy: 0.6860\n",
            "Epoch 405/700\n",
            "104/104 [==============================] - 3s 29ms/step - loss: 0.7298 - accuracy: 0.7080 - val_loss: 0.7927 - val_accuracy: 0.6812\n",
            "Epoch 406/700\n",
            "104/104 [==============================] - 3s 29ms/step - loss: 0.7065 - accuracy: 0.7316 - val_loss: 0.7877 - val_accuracy: 0.6860\n",
            "Epoch 407/700\n",
            "104/104 [==============================] - 3s 29ms/step - loss: 0.7125 - accuracy: 0.7195 - val_loss: 0.7866 - val_accuracy: 0.6860\n",
            "Epoch 408/700\n",
            "104/104 [==============================] - 3s 28ms/step - loss: 0.6941 - accuracy: 0.7382 - val_loss: 0.7935 - val_accuracy: 0.7053\n",
            "Epoch 409/700\n",
            "104/104 [==============================] - 3s 29ms/step - loss: 0.7085 - accuracy: 0.7092 - val_loss: 0.7774 - val_accuracy: 0.6715\n",
            "Epoch 410/700\n",
            "104/104 [==============================] - 3s 29ms/step - loss: 0.7059 - accuracy: 0.7152 - val_loss: 0.7844 - val_accuracy: 0.6812\n",
            "Epoch 411/700\n",
            "104/104 [==============================] - 3s 29ms/step - loss: 0.6914 - accuracy: 0.7273 - val_loss: 0.8050 - val_accuracy: 0.6957\n",
            "Epoch 412/700\n",
            "104/104 [==============================] - 3s 29ms/step - loss: 0.6913 - accuracy: 0.7310 - val_loss: 0.7730 - val_accuracy: 0.6812\n",
            "Epoch 413/700\n",
            "104/104 [==============================] - 3s 28ms/step - loss: 0.7031 - accuracy: 0.7237 - val_loss: 0.7718 - val_accuracy: 0.6957\n",
            "Epoch 414/700\n",
            "104/104 [==============================] - 3s 29ms/step - loss: 0.7093 - accuracy: 0.7225 - val_loss: 0.7831 - val_accuracy: 0.7053\n",
            "Epoch 415/700\n",
            "104/104 [==============================] - 3s 28ms/step - loss: 0.7160 - accuracy: 0.7201 - val_loss: 0.7784 - val_accuracy: 0.6860\n",
            "Epoch 416/700\n",
            "104/104 [==============================] - 3s 28ms/step - loss: 0.6859 - accuracy: 0.7418 - val_loss: 0.7657 - val_accuracy: 0.6908\n",
            "Epoch 417/700\n",
            "104/104 [==============================] - 3s 29ms/step - loss: 0.6944 - accuracy: 0.7267 - val_loss: 0.7699 - val_accuracy: 0.6812\n",
            "Epoch 418/700\n",
            "104/104 [==============================] - 3s 29ms/step - loss: 0.7031 - accuracy: 0.7195 - val_loss: 0.7669 - val_accuracy: 0.7150\n",
            "Epoch 419/700\n",
            "104/104 [==============================] - 3s 30ms/step - loss: 0.6945 - accuracy: 0.7322 - val_loss: 0.7661 - val_accuracy: 0.7150\n",
            "Epoch 420/700\n",
            "104/104 [==============================] - 3s 29ms/step - loss: 0.7015 - accuracy: 0.7285 - val_loss: 0.7645 - val_accuracy: 0.6908\n",
            "Epoch 421/700\n",
            "104/104 [==============================] - 3s 28ms/step - loss: 0.7013 - accuracy: 0.7328 - val_loss: 0.7707 - val_accuracy: 0.6908\n",
            "Epoch 422/700\n",
            "104/104 [==============================] - 3s 29ms/step - loss: 0.6886 - accuracy: 0.7310 - val_loss: 0.7574 - val_accuracy: 0.6908\n",
            "Epoch 423/700\n",
            "104/104 [==============================] - 3s 33ms/step - loss: 0.7013 - accuracy: 0.7322 - val_loss: 0.7624 - val_accuracy: 0.6908\n",
            "Epoch 424/700\n",
            "104/104 [==============================] - 3s 30ms/step - loss: 0.6906 - accuracy: 0.7358 - val_loss: 0.7603 - val_accuracy: 0.6667\n",
            "Epoch 425/700\n",
            "104/104 [==============================] - 3s 29ms/step - loss: 0.6787 - accuracy: 0.7424 - val_loss: 0.7755 - val_accuracy: 0.6957\n",
            "Epoch 426/700\n",
            "104/104 [==============================] - 3s 29ms/step - loss: 0.6877 - accuracy: 0.7297 - val_loss: 0.7687 - val_accuracy: 0.6908\n",
            "Epoch 427/700\n",
            "104/104 [==============================] - 3s 29ms/step - loss: 0.6827 - accuracy: 0.7243 - val_loss: 0.7879 - val_accuracy: 0.6715\n",
            "Epoch 428/700\n",
            "104/104 [==============================] - 3s 29ms/step - loss: 0.7029 - accuracy: 0.7285 - val_loss: 0.7635 - val_accuracy: 0.6763\n",
            "Epoch 429/700\n",
            "104/104 [==============================] - 3s 29ms/step - loss: 0.6761 - accuracy: 0.7449 - val_loss: 0.7700 - val_accuracy: 0.6908\n",
            "Epoch 430/700\n",
            "104/104 [==============================] - 3s 29ms/step - loss: 0.6753 - accuracy: 0.7285 - val_loss: 0.7639 - val_accuracy: 0.6957\n",
            "Epoch 431/700\n",
            "104/104 [==============================] - 3s 29ms/step - loss: 0.6778 - accuracy: 0.7316 - val_loss: 0.7642 - val_accuracy: 0.7101\n",
            "Epoch 432/700\n",
            "104/104 [==============================] - 3s 30ms/step - loss: 0.6582 - accuracy: 0.7467 - val_loss: 0.7582 - val_accuracy: 0.7053\n",
            "Epoch 433/700\n",
            "104/104 [==============================] - 3s 29ms/step - loss: 0.6842 - accuracy: 0.7195 - val_loss: 0.7721 - val_accuracy: 0.6812\n",
            "Epoch 434/700\n",
            "104/104 [==============================] - 3s 29ms/step - loss: 0.6778 - accuracy: 0.7437 - val_loss: 0.7610 - val_accuracy: 0.6908\n",
            "Epoch 435/700\n",
            "104/104 [==============================] - 3s 29ms/step - loss: 0.6651 - accuracy: 0.7370 - val_loss: 0.7666 - val_accuracy: 0.7005\n",
            "Epoch 436/700\n",
            "104/104 [==============================] - 3s 28ms/step - loss: 0.6628 - accuracy: 0.7430 - val_loss: 0.7610 - val_accuracy: 0.6957\n",
            "Epoch 437/700\n",
            "104/104 [==============================] - 3s 29ms/step - loss: 0.6556 - accuracy: 0.7340 - val_loss: 0.7599 - val_accuracy: 0.7101\n",
            "Epoch 438/700\n",
            "104/104 [==============================] - 3s 29ms/step - loss: 0.6573 - accuracy: 0.7570 - val_loss: 0.7584 - val_accuracy: 0.7005\n",
            "Epoch 439/700\n",
            "104/104 [==============================] - 3s 29ms/step - loss: 0.6669 - accuracy: 0.7297 - val_loss: 0.7655 - val_accuracy: 0.7005\n",
            "Epoch 440/700\n",
            "104/104 [==============================] - 3s 29ms/step - loss: 0.6627 - accuracy: 0.7370 - val_loss: 0.7488 - val_accuracy: 0.6957\n",
            "Epoch 441/700\n",
            "104/104 [==============================] - 3s 27ms/step - loss: 0.6620 - accuracy: 0.7449 - val_loss: 0.7563 - val_accuracy: 0.7295\n",
            "Epoch 442/700\n",
            "104/104 [==============================] - 3s 28ms/step - loss: 0.6571 - accuracy: 0.7479 - val_loss: 0.7569 - val_accuracy: 0.7053\n",
            "Epoch 443/700\n",
            "104/104 [==============================] - 3s 28ms/step - loss: 0.6678 - accuracy: 0.7346 - val_loss: 0.7514 - val_accuracy: 0.6860\n",
            "Epoch 444/700\n",
            "104/104 [==============================] - 3s 29ms/step - loss: 0.6703 - accuracy: 0.7358 - val_loss: 0.7545 - val_accuracy: 0.7150\n",
            "Epoch 445/700\n",
            "104/104 [==============================] - 3s 28ms/step - loss: 0.6465 - accuracy: 0.7533 - val_loss: 0.7522 - val_accuracy: 0.7101\n",
            "Epoch 446/700\n",
            "104/104 [==============================] - 3s 28ms/step - loss: 0.6510 - accuracy: 0.7430 - val_loss: 0.7516 - val_accuracy: 0.7053\n",
            "Epoch 447/700\n",
            "104/104 [==============================] - 3s 29ms/step - loss: 0.6660 - accuracy: 0.7382 - val_loss: 0.7637 - val_accuracy: 0.7150\n",
            "Epoch 448/700\n",
            "104/104 [==============================] - 3s 29ms/step - loss: 0.6873 - accuracy: 0.7279 - val_loss: 0.7513 - val_accuracy: 0.7150\n",
            "Epoch 449/700\n",
            "104/104 [==============================] - 3s 30ms/step - loss: 0.6660 - accuracy: 0.7467 - val_loss: 0.7530 - val_accuracy: 0.6957\n",
            "Epoch 450/700\n",
            "104/104 [==============================] - 3s 29ms/step - loss: 0.6808 - accuracy: 0.7249 - val_loss: 0.7614 - val_accuracy: 0.6957\n",
            "Epoch 451/700\n",
            "104/104 [==============================] - 3s 29ms/step - loss: 0.6395 - accuracy: 0.7606 - val_loss: 0.7524 - val_accuracy: 0.6957\n",
            "Epoch 452/700\n",
            "104/104 [==============================] - 3s 29ms/step - loss: 0.6377 - accuracy: 0.7545 - val_loss: 0.7579 - val_accuracy: 0.6860\n",
            "Epoch 453/700\n",
            "104/104 [==============================] - 3s 29ms/step - loss: 0.6456 - accuracy: 0.7479 - val_loss: 0.7605 - val_accuracy: 0.6860\n",
            "Epoch 454/700\n",
            "104/104 [==============================] - 3s 30ms/step - loss: 0.6669 - accuracy: 0.7497 - val_loss: 0.7597 - val_accuracy: 0.7101\n",
            "Epoch 455/700\n",
            "104/104 [==============================] - 3s 29ms/step - loss: 0.6720 - accuracy: 0.7437 - val_loss: 0.7613 - val_accuracy: 0.6957\n",
            "Epoch 456/700\n",
            "104/104 [==============================] - 3s 29ms/step - loss: 0.6608 - accuracy: 0.7394 - val_loss: 0.7497 - val_accuracy: 0.7246\n",
            "Epoch 457/700\n",
            "104/104 [==============================] - 3s 28ms/step - loss: 0.6706 - accuracy: 0.7418 - val_loss: 0.7648 - val_accuracy: 0.6957\n",
            "Epoch 458/700\n",
            "104/104 [==============================] - 3s 29ms/step - loss: 0.6671 - accuracy: 0.7430 - val_loss: 0.7407 - val_accuracy: 0.7005\n",
            "Epoch 459/700\n",
            "104/104 [==============================] - 3s 29ms/step - loss: 0.6543 - accuracy: 0.7491 - val_loss: 0.7371 - val_accuracy: 0.6957\n",
            "Epoch 460/700\n",
            "104/104 [==============================] - 3s 29ms/step - loss: 0.6437 - accuracy: 0.7443 - val_loss: 0.7315 - val_accuracy: 0.7150\n",
            "Epoch 461/700\n",
            "104/104 [==============================] - 3s 29ms/step - loss: 0.6271 - accuracy: 0.7582 - val_loss: 0.7429 - val_accuracy: 0.7246\n",
            "Epoch 462/700\n",
            "104/104 [==============================] - 3s 29ms/step - loss: 0.6598 - accuracy: 0.7328 - val_loss: 0.7455 - val_accuracy: 0.7101\n",
            "Epoch 463/700\n",
            "104/104 [==============================] - 3s 29ms/step - loss: 0.6400 - accuracy: 0.7600 - val_loss: 0.7351 - val_accuracy: 0.7150\n",
            "Epoch 464/700\n",
            "104/104 [==============================] - 3s 27ms/step - loss: 0.6436 - accuracy: 0.7497 - val_loss: 0.7417 - val_accuracy: 0.7150\n",
            "Epoch 465/700\n",
            "104/104 [==============================] - 3s 28ms/step - loss: 0.6482 - accuracy: 0.7364 - val_loss: 0.7391 - val_accuracy: 0.7053\n",
            "Epoch 466/700\n",
            "104/104 [==============================] - 3s 29ms/step - loss: 0.6590 - accuracy: 0.7449 - val_loss: 0.7375 - val_accuracy: 0.7101\n",
            "Epoch 467/700\n",
            "104/104 [==============================] - 3s 29ms/step - loss: 0.6441 - accuracy: 0.7503 - val_loss: 0.7434 - val_accuracy: 0.7101\n",
            "Epoch 468/700\n",
            "104/104 [==============================] - 3s 29ms/step - loss: 0.6418 - accuracy: 0.7479 - val_loss: 0.7437 - val_accuracy: 0.7198\n",
            "Epoch 469/700\n",
            "104/104 [==============================] - 3s 29ms/step - loss: 0.6379 - accuracy: 0.7406 - val_loss: 0.7386 - val_accuracy: 0.6957\n",
            "Epoch 470/700\n",
            "104/104 [==============================] - 3s 29ms/step - loss: 0.6228 - accuracy: 0.7539 - val_loss: 0.7264 - val_accuracy: 0.7343\n",
            "Epoch 471/700\n",
            "104/104 [==============================] - 3s 28ms/step - loss: 0.6244 - accuracy: 0.7497 - val_loss: 0.7325 - val_accuracy: 0.7391\n",
            "Epoch 472/700\n",
            "104/104 [==============================] - 3s 30ms/step - loss: 0.6368 - accuracy: 0.7545 - val_loss: 0.7313 - val_accuracy: 0.7198\n",
            "Epoch 473/700\n",
            "104/104 [==============================] - 3s 29ms/step - loss: 0.6235 - accuracy: 0.7467 - val_loss: 0.7360 - val_accuracy: 0.7488\n",
            "Epoch 474/700\n",
            "104/104 [==============================] - 3s 28ms/step - loss: 0.6223 - accuracy: 0.7503 - val_loss: 0.7323 - val_accuracy: 0.7005\n",
            "Epoch 475/700\n",
            "104/104 [==============================] - 3s 29ms/step - loss: 0.6380 - accuracy: 0.7545 - val_loss: 0.7266 - val_accuracy: 0.7343\n",
            "Epoch 476/700\n",
            "104/104 [==============================] - 3s 29ms/step - loss: 0.6482 - accuracy: 0.7473 - val_loss: 0.7292 - val_accuracy: 0.7391\n",
            "Epoch 477/700\n",
            "104/104 [==============================] - 3s 29ms/step - loss: 0.6481 - accuracy: 0.7539 - val_loss: 0.7376 - val_accuracy: 0.7150\n",
            "Epoch 478/700\n",
            "104/104 [==============================] - 3s 29ms/step - loss: 0.6375 - accuracy: 0.7576 - val_loss: 0.7393 - val_accuracy: 0.7295\n",
            "Epoch 479/700\n",
            "104/104 [==============================] - 3s 29ms/step - loss: 0.6397 - accuracy: 0.7503 - val_loss: 0.7252 - val_accuracy: 0.7053\n",
            "Epoch 480/700\n",
            "104/104 [==============================] - 3s 29ms/step - loss: 0.6117 - accuracy: 0.7727 - val_loss: 0.7184 - val_accuracy: 0.7101\n",
            "Epoch 481/700\n",
            "104/104 [==============================] - 3s 28ms/step - loss: 0.6247 - accuracy: 0.7576 - val_loss: 0.7222 - val_accuracy: 0.7246\n",
            "Epoch 482/700\n",
            "104/104 [==============================] - 3s 30ms/step - loss: 0.6130 - accuracy: 0.7696 - val_loss: 0.7215 - val_accuracy: 0.7246\n",
            "Epoch 483/700\n",
            "104/104 [==============================] - 3s 30ms/step - loss: 0.6341 - accuracy: 0.7503 - val_loss: 0.7255 - val_accuracy: 0.7150\n",
            "Epoch 484/700\n",
            "104/104 [==============================] - 3s 29ms/step - loss: 0.6053 - accuracy: 0.7636 - val_loss: 0.7474 - val_accuracy: 0.7343\n",
            "Epoch 485/700\n",
            "104/104 [==============================] - 3s 28ms/step - loss: 0.6385 - accuracy: 0.7509 - val_loss: 0.7357 - val_accuracy: 0.7246\n",
            "Epoch 486/700\n",
            "104/104 [==============================] - 3s 29ms/step - loss: 0.6249 - accuracy: 0.7521 - val_loss: 0.7237 - val_accuracy: 0.7101\n",
            "Epoch 487/700\n",
            "104/104 [==============================] - 3s 30ms/step - loss: 0.6230 - accuracy: 0.7563 - val_loss: 0.7356 - val_accuracy: 0.7053\n",
            "Epoch 488/700\n",
            "104/104 [==============================] - 3s 30ms/step - loss: 0.6023 - accuracy: 0.7739 - val_loss: 0.7361 - val_accuracy: 0.7053\n",
            "Epoch 489/700\n",
            "104/104 [==============================] - 3s 31ms/step - loss: 0.6317 - accuracy: 0.7588 - val_loss: 0.7372 - val_accuracy: 0.7053\n",
            "Epoch 490/700\n",
            "104/104 [==============================] - 3s 31ms/step - loss: 0.6299 - accuracy: 0.7624 - val_loss: 0.7374 - val_accuracy: 0.7101\n",
            "Epoch 491/700\n",
            "104/104 [==============================] - 3s 30ms/step - loss: 0.6024 - accuracy: 0.7727 - val_loss: 0.7332 - val_accuracy: 0.7101\n",
            "Epoch 492/700\n",
            "104/104 [==============================] - 3s 29ms/step - loss: 0.6164 - accuracy: 0.7660 - val_loss: 0.7394 - val_accuracy: 0.7295\n",
            "Epoch 493/700\n",
            "104/104 [==============================] - 3s 29ms/step - loss: 0.6041 - accuracy: 0.7703 - val_loss: 0.7321 - val_accuracy: 0.6957\n",
            "Epoch 494/700\n",
            "104/104 [==============================] - 3s 30ms/step - loss: 0.6124 - accuracy: 0.7606 - val_loss: 0.7406 - val_accuracy: 0.7053\n",
            "Epoch 495/700\n",
            "104/104 [==============================] - 3s 30ms/step - loss: 0.6288 - accuracy: 0.7588 - val_loss: 0.7479 - val_accuracy: 0.7005\n",
            "Epoch 496/700\n",
            "104/104 [==============================] - 3s 30ms/step - loss: 0.6105 - accuracy: 0.7672 - val_loss: 0.7313 - val_accuracy: 0.7198\n",
            "Epoch 497/700\n",
            "104/104 [==============================] - 3s 29ms/step - loss: 0.6163 - accuracy: 0.7509 - val_loss: 0.7331 - val_accuracy: 0.7198\n",
            "Epoch 498/700\n",
            "104/104 [==============================] - 3s 29ms/step - loss: 0.5911 - accuracy: 0.7636 - val_loss: 0.7329 - val_accuracy: 0.7053\n",
            "Epoch 499/700\n",
            "104/104 [==============================] - 3s 30ms/step - loss: 0.6085 - accuracy: 0.7533 - val_loss: 0.7265 - val_accuracy: 0.7198\n",
            "Epoch 500/700\n",
            "104/104 [==============================] - 3s 30ms/step - loss: 0.6066 - accuracy: 0.7703 - val_loss: 0.7244 - val_accuracy: 0.7005\n",
            "Epoch 501/700\n",
            "104/104 [==============================] - 3s 29ms/step - loss: 0.6054 - accuracy: 0.7642 - val_loss: 0.7272 - val_accuracy: 0.7101\n",
            "Epoch 502/700\n",
            "104/104 [==============================] - 3s 30ms/step - loss: 0.5936 - accuracy: 0.7678 - val_loss: 0.7117 - val_accuracy: 0.7101\n",
            "Epoch 503/700\n",
            "104/104 [==============================] - 3s 29ms/step - loss: 0.5827 - accuracy: 0.7842 - val_loss: 0.7344 - val_accuracy: 0.7005\n",
            "Epoch 504/700\n",
            "104/104 [==============================] - 3s 29ms/step - loss: 0.6303 - accuracy: 0.7443 - val_loss: 0.7165 - val_accuracy: 0.7343\n",
            "Epoch 505/700\n",
            "104/104 [==============================] - 3s 29ms/step - loss: 0.6006 - accuracy: 0.7721 - val_loss: 0.7358 - val_accuracy: 0.7295\n",
            "Epoch 506/700\n",
            "104/104 [==============================] - 3s 29ms/step - loss: 0.5998 - accuracy: 0.7660 - val_loss: 0.7489 - val_accuracy: 0.7005\n",
            "Epoch 507/700\n",
            "104/104 [==============================] - 3s 29ms/step - loss: 0.6175 - accuracy: 0.7690 - val_loss: 0.7518 - val_accuracy: 0.7246\n",
            "Epoch 508/700\n",
            "104/104 [==============================] - 3s 29ms/step - loss: 0.6102 - accuracy: 0.7582 - val_loss: 0.7331 - val_accuracy: 0.7150\n",
            "Epoch 509/700\n",
            "104/104 [==============================] - 3s 29ms/step - loss: 0.5860 - accuracy: 0.7769 - val_loss: 0.7252 - val_accuracy: 0.7391\n",
            "Epoch 510/700\n",
            "104/104 [==============================] - 3s 29ms/step - loss: 0.5960 - accuracy: 0.7539 - val_loss: 0.7238 - val_accuracy: 0.7101\n",
            "Epoch 511/700\n",
            "104/104 [==============================] - 3s 30ms/step - loss: 0.5874 - accuracy: 0.7733 - val_loss: 0.7158 - val_accuracy: 0.7295\n",
            "Epoch 512/700\n",
            "104/104 [==============================] - 3s 29ms/step - loss: 0.5818 - accuracy: 0.7733 - val_loss: 0.7314 - val_accuracy: 0.7246\n",
            "Epoch 513/700\n",
            "104/104 [==============================] - 3s 29ms/step - loss: 0.5949 - accuracy: 0.7642 - val_loss: 0.7249 - val_accuracy: 0.7101\n",
            "Epoch 514/700\n",
            "104/104 [==============================] - 3s 29ms/step - loss: 0.5951 - accuracy: 0.7733 - val_loss: 0.7159 - val_accuracy: 0.7150\n",
            "Epoch 515/700\n",
            "104/104 [==============================] - 3s 29ms/step - loss: 0.5859 - accuracy: 0.7775 - val_loss: 0.7128 - val_accuracy: 0.7198\n",
            "Epoch 516/700\n",
            "104/104 [==============================] - 3s 29ms/step - loss: 0.5774 - accuracy: 0.7751 - val_loss: 0.7122 - val_accuracy: 0.7053\n",
            "Epoch 517/700\n",
            "104/104 [==============================] - 3s 30ms/step - loss: 0.5970 - accuracy: 0.7606 - val_loss: 0.7211 - val_accuracy: 0.7053\n",
            "Epoch 518/700\n",
            "104/104 [==============================] - 3s 29ms/step - loss: 0.5961 - accuracy: 0.7751 - val_loss: 0.7298 - val_accuracy: 0.6957\n",
            "Epoch 519/700\n",
            "104/104 [==============================] - 3s 29ms/step - loss: 0.5922 - accuracy: 0.7709 - val_loss: 0.7159 - val_accuracy: 0.7101\n",
            "Epoch 520/700\n",
            "104/104 [==============================] - 3s 28ms/step - loss: 0.5835 - accuracy: 0.7799 - val_loss: 0.7208 - val_accuracy: 0.7150\n",
            "Epoch 521/700\n",
            "104/104 [==============================] - 3s 29ms/step - loss: 0.5842 - accuracy: 0.7703 - val_loss: 0.7163 - val_accuracy: 0.7150\n",
            "Epoch 522/700\n",
            "104/104 [==============================] - 3s 29ms/step - loss: 0.5793 - accuracy: 0.7848 - val_loss: 0.7233 - val_accuracy: 0.7198\n",
            "Epoch 523/700\n",
            "104/104 [==============================] - 3s 29ms/step - loss: 0.5623 - accuracy: 0.7830 - val_loss: 0.7231 - val_accuracy: 0.7246\n",
            "Epoch 524/700\n",
            "104/104 [==============================] - 3s 29ms/step - loss: 0.5631 - accuracy: 0.7896 - val_loss: 0.7353 - val_accuracy: 0.7053\n",
            "Epoch 525/700\n",
            "104/104 [==============================] - 3s 29ms/step - loss: 0.5535 - accuracy: 0.7836 - val_loss: 0.7131 - val_accuracy: 0.7391\n",
            "Epoch 526/700\n",
            "104/104 [==============================] - 3s 29ms/step - loss: 0.5926 - accuracy: 0.7624 - val_loss: 0.7255 - val_accuracy: 0.6908\n",
            "Epoch 527/700\n",
            "104/104 [==============================] - 3s 29ms/step - loss: 0.5788 - accuracy: 0.7727 - val_loss: 0.7292 - val_accuracy: 0.7295\n",
            "Epoch 528/700\n",
            "104/104 [==============================] - 3s 31ms/step - loss: 0.6051 - accuracy: 0.7660 - val_loss: 0.7240 - val_accuracy: 0.7343\n",
            "Epoch 529/700\n",
            "104/104 [==============================] - 3s 30ms/step - loss: 0.5838 - accuracy: 0.7733 - val_loss: 0.7171 - val_accuracy: 0.7198\n",
            "Epoch 530/700\n",
            "104/104 [==============================] - 3s 30ms/step - loss: 0.5919 - accuracy: 0.7715 - val_loss: 0.7132 - val_accuracy: 0.7150\n",
            "Epoch 531/700\n",
            "104/104 [==============================] - 3s 31ms/step - loss: 0.5620 - accuracy: 0.7830 - val_loss: 0.7050 - val_accuracy: 0.7150\n",
            "Epoch 532/700\n",
            "104/104 [==============================] - 3s 29ms/step - loss: 0.5762 - accuracy: 0.7842 - val_loss: 0.7258 - val_accuracy: 0.7101\n",
            "Epoch 533/700\n",
            "104/104 [==============================] - 3s 29ms/step - loss: 0.5679 - accuracy: 0.7830 - val_loss: 0.7207 - val_accuracy: 0.7295\n",
            "Epoch 534/700\n",
            "104/104 [==============================] - 3s 29ms/step - loss: 0.5812 - accuracy: 0.7727 - val_loss: 0.7076 - val_accuracy: 0.7295\n",
            "Epoch 535/700\n",
            "104/104 [==============================] - 3s 29ms/step - loss: 0.5544 - accuracy: 0.7920 - val_loss: 0.7009 - val_accuracy: 0.7343\n",
            "Epoch 536/700\n",
            "104/104 [==============================] - 3s 29ms/step - loss: 0.5548 - accuracy: 0.8029 - val_loss: 0.7140 - val_accuracy: 0.7150\n",
            "Epoch 537/700\n",
            "104/104 [==============================] - 3s 29ms/step - loss: 0.5583 - accuracy: 0.7914 - val_loss: 0.7066 - val_accuracy: 0.7246\n",
            "Epoch 538/700\n",
            "104/104 [==============================] - 3s 30ms/step - loss: 0.5750 - accuracy: 0.7775 - val_loss: 0.7174 - val_accuracy: 0.7005\n",
            "Epoch 539/700\n",
            "104/104 [==============================] - 3s 31ms/step - loss: 0.5785 - accuracy: 0.7763 - val_loss: 0.7057 - val_accuracy: 0.7295\n",
            "Epoch 540/700\n",
            "104/104 [==============================] - 3s 29ms/step - loss: 0.5704 - accuracy: 0.7721 - val_loss: 0.7024 - val_accuracy: 0.7101\n",
            "Epoch 541/700\n",
            "104/104 [==============================] - 3s 30ms/step - loss: 0.5843 - accuracy: 0.7757 - val_loss: 0.7128 - val_accuracy: 0.6957\n",
            "Epoch 542/700\n",
            "104/104 [==============================] - 3s 28ms/step - loss: 0.5708 - accuracy: 0.7769 - val_loss: 0.7127 - val_accuracy: 0.6957\n",
            "Epoch 543/700\n",
            "104/104 [==============================] - 3s 29ms/step - loss: 0.5624 - accuracy: 0.7902 - val_loss: 0.7052 - val_accuracy: 0.7150\n",
            "Epoch 544/700\n",
            "104/104 [==============================] - 3s 29ms/step - loss: 0.5547 - accuracy: 0.7908 - val_loss: 0.7018 - val_accuracy: 0.7295\n",
            "Epoch 545/700\n",
            "104/104 [==============================] - 3s 29ms/step - loss: 0.5685 - accuracy: 0.7830 - val_loss: 0.6932 - val_accuracy: 0.7246\n",
            "Epoch 546/700\n",
            "104/104 [==============================] - 3s 29ms/step - loss: 0.5619 - accuracy: 0.7836 - val_loss: 0.6969 - val_accuracy: 0.7053\n",
            "Epoch 547/700\n",
            "104/104 [==============================] - 3s 29ms/step - loss: 0.5619 - accuracy: 0.7842 - val_loss: 0.7027 - val_accuracy: 0.7053\n",
            "Epoch 548/700\n",
            "104/104 [==============================] - 3s 30ms/step - loss: 0.5495 - accuracy: 0.7811 - val_loss: 0.7071 - val_accuracy: 0.7053\n",
            "Epoch 549/700\n",
            "104/104 [==============================] - 3s 30ms/step - loss: 0.5379 - accuracy: 0.7860 - val_loss: 0.7093 - val_accuracy: 0.7053\n",
            "Epoch 550/700\n",
            "104/104 [==============================] - 3s 30ms/step - loss: 0.5693 - accuracy: 0.7799 - val_loss: 0.7097 - val_accuracy: 0.7005\n",
            "Epoch 551/700\n",
            "104/104 [==============================] - 3s 30ms/step - loss: 0.5576 - accuracy: 0.7817 - val_loss: 0.6972 - val_accuracy: 0.7150\n",
            "Epoch 552/700\n",
            "104/104 [==============================] - 3s 31ms/step - loss: 0.5768 - accuracy: 0.7751 - val_loss: 0.6984 - val_accuracy: 0.7246\n",
            "Epoch 553/700\n",
            "104/104 [==============================] - 3s 33ms/step - loss: 0.5519 - accuracy: 0.7860 - val_loss: 0.7087 - val_accuracy: 0.7053\n",
            "Epoch 554/700\n",
            "104/104 [==============================] - 3s 30ms/step - loss: 0.5371 - accuracy: 0.7963 - val_loss: 0.6989 - val_accuracy: 0.7101\n",
            "Epoch 555/700\n",
            "104/104 [==============================] - 3s 30ms/step - loss: 0.5550 - accuracy: 0.7890 - val_loss: 0.7011 - val_accuracy: 0.7150\n",
            "Epoch 556/700\n",
            "104/104 [==============================] - 3s 29ms/step - loss: 0.5481 - accuracy: 0.8005 - val_loss: 0.6979 - val_accuracy: 0.7150\n",
            "Epoch 557/700\n",
            "104/104 [==============================] - 3s 30ms/step - loss: 0.5446 - accuracy: 0.7938 - val_loss: 0.6882 - val_accuracy: 0.7150\n",
            "Epoch 558/700\n",
            "104/104 [==============================] - 3s 30ms/step - loss: 0.5573 - accuracy: 0.7823 - val_loss: 0.7044 - val_accuracy: 0.7101\n",
            "Epoch 559/700\n",
            "104/104 [==============================] - 3s 29ms/step - loss: 0.5415 - accuracy: 0.7969 - val_loss: 0.7066 - val_accuracy: 0.7150\n",
            "Epoch 560/700\n",
            "104/104 [==============================] - 3s 29ms/step - loss: 0.5499 - accuracy: 0.7842 - val_loss: 0.6917 - val_accuracy: 0.7150\n",
            "Epoch 561/700\n",
            "104/104 [==============================] - 3s 29ms/step - loss: 0.5670 - accuracy: 0.7757 - val_loss: 0.7212 - val_accuracy: 0.6763\n",
            "Epoch 562/700\n",
            "104/104 [==============================] - 3s 30ms/step - loss: 0.5350 - accuracy: 0.7866 - val_loss: 0.7026 - val_accuracy: 0.7246\n",
            "Epoch 563/700\n",
            "104/104 [==============================] - 3s 30ms/step - loss: 0.5452 - accuracy: 0.7878 - val_loss: 0.6980 - val_accuracy: 0.7246\n",
            "Epoch 564/700\n",
            "104/104 [==============================] - 3s 29ms/step - loss: 0.5471 - accuracy: 0.7932 - val_loss: 0.7097 - val_accuracy: 0.7101\n",
            "Epoch 565/700\n",
            "104/104 [==============================] - 3s 29ms/step - loss: 0.5518 - accuracy: 0.7884 - val_loss: 0.7007 - val_accuracy: 0.7246\n",
            "Epoch 566/700\n",
            "104/104 [==============================] - 3s 29ms/step - loss: 0.5497 - accuracy: 0.7908 - val_loss: 0.7009 - val_accuracy: 0.7101\n",
            "Epoch 567/700\n",
            "104/104 [==============================] - 3s 30ms/step - loss: 0.5479 - accuracy: 0.7932 - val_loss: 0.7189 - val_accuracy: 0.7101\n",
            "Epoch 568/700\n",
            "104/104 [==============================] - 3s 30ms/step - loss: 0.5406 - accuracy: 0.7920 - val_loss: 0.7086 - val_accuracy: 0.7005\n",
            "Epoch 569/700\n",
            "104/104 [==============================] - 3s 30ms/step - loss: 0.5161 - accuracy: 0.8071 - val_loss: 0.7083 - val_accuracy: 0.7053\n",
            "Epoch 570/700\n",
            "104/104 [==============================] - 3s 32ms/step - loss: 0.5315 - accuracy: 0.7999 - val_loss: 0.6900 - val_accuracy: 0.7005\n",
            "Epoch 571/700\n",
            "104/104 [==============================] - 3s 30ms/step - loss: 0.5356 - accuracy: 0.7981 - val_loss: 0.6971 - val_accuracy: 0.7053\n",
            "Epoch 572/700\n",
            "104/104 [==============================] - 3s 31ms/step - loss: 0.5409 - accuracy: 0.7969 - val_loss: 0.6951 - val_accuracy: 0.7150\n",
            "Epoch 573/700\n",
            "104/104 [==============================] - 3s 30ms/step - loss: 0.5214 - accuracy: 0.8108 - val_loss: 0.7002 - val_accuracy: 0.7053\n",
            "Epoch 574/700\n",
            "104/104 [==============================] - 3s 30ms/step - loss: 0.5194 - accuracy: 0.7950 - val_loss: 0.6761 - val_accuracy: 0.7295\n",
            "Epoch 575/700\n",
            "104/104 [==============================] - 3s 29ms/step - loss: 0.5354 - accuracy: 0.7920 - val_loss: 0.6941 - val_accuracy: 0.7101\n",
            "Epoch 576/700\n",
            "104/104 [==============================] - 3s 29ms/step - loss: 0.5439 - accuracy: 0.7878 - val_loss: 0.6861 - val_accuracy: 0.7246\n",
            "Epoch 577/700\n",
            "104/104 [==============================] - 3s 30ms/step - loss: 0.5300 - accuracy: 0.7969 - val_loss: 0.6877 - val_accuracy: 0.7198\n",
            "Epoch 578/700\n",
            "104/104 [==============================] - 3s 29ms/step - loss: 0.5209 - accuracy: 0.7981 - val_loss: 0.6851 - val_accuracy: 0.7198\n",
            "Epoch 579/700\n",
            "104/104 [==============================] - 3s 30ms/step - loss: 0.5049 - accuracy: 0.8156 - val_loss: 0.6880 - val_accuracy: 0.7150\n",
            "Epoch 580/700\n",
            "104/104 [==============================] - 3s 31ms/step - loss: 0.5279 - accuracy: 0.7950 - val_loss: 0.6816 - val_accuracy: 0.7391\n",
            "Epoch 581/700\n",
            "104/104 [==============================] - 3s 29ms/step - loss: 0.5258 - accuracy: 0.8011 - val_loss: 0.6825 - val_accuracy: 0.7343\n",
            "Epoch 582/700\n",
            "104/104 [==============================] - 3s 30ms/step - loss: 0.5200 - accuracy: 0.8047 - val_loss: 0.6958 - val_accuracy: 0.7391\n",
            "Epoch 583/700\n",
            "104/104 [==============================] - 3s 29ms/step - loss: 0.5145 - accuracy: 0.7993 - val_loss: 0.6822 - val_accuracy: 0.7295\n",
            "Epoch 584/700\n",
            "104/104 [==============================] - 3s 30ms/step - loss: 0.5081 - accuracy: 0.8102 - val_loss: 0.6768 - val_accuracy: 0.7391\n",
            "Epoch 585/700\n",
            "104/104 [==============================] - 3s 29ms/step - loss: 0.5327 - accuracy: 0.7860 - val_loss: 0.6908 - val_accuracy: 0.7343\n",
            "Epoch 586/700\n",
            "104/104 [==============================] - 3s 31ms/step - loss: 0.5364 - accuracy: 0.8011 - val_loss: 0.7066 - val_accuracy: 0.7246\n",
            "Epoch 587/700\n",
            "104/104 [==============================] - 3s 30ms/step - loss: 0.5411 - accuracy: 0.8065 - val_loss: 0.7008 - val_accuracy: 0.7101\n",
            "Epoch 588/700\n",
            "104/104 [==============================] - 3s 29ms/step - loss: 0.5227 - accuracy: 0.7896 - val_loss: 0.6966 - val_accuracy: 0.6812\n",
            "Epoch 589/700\n",
            "104/104 [==============================] - 3s 30ms/step - loss: 0.5239 - accuracy: 0.7956 - val_loss: 0.6829 - val_accuracy: 0.7295\n",
            "Epoch 590/700\n",
            "104/104 [==============================] - 3s 31ms/step - loss: 0.5177 - accuracy: 0.8059 - val_loss: 0.6876 - val_accuracy: 0.7198\n",
            "Epoch 591/700\n",
            "104/104 [==============================] - 3s 31ms/step - loss: 0.5168 - accuracy: 0.8053 - val_loss: 0.6887 - val_accuracy: 0.7101\n",
            "Epoch 592/700\n",
            "104/104 [==============================] - 3s 30ms/step - loss: 0.5086 - accuracy: 0.7993 - val_loss: 0.6956 - val_accuracy: 0.7343\n",
            "Epoch 593/700\n",
            "104/104 [==============================] - 3s 30ms/step - loss: 0.5188 - accuracy: 0.7956 - val_loss: 0.7007 - val_accuracy: 0.7101\n",
            "Epoch 594/700\n",
            "104/104 [==============================] - 3s 30ms/step - loss: 0.4918 - accuracy: 0.8222 - val_loss: 0.6951 - val_accuracy: 0.7246\n",
            "Epoch 595/700\n",
            "104/104 [==============================] - 3s 30ms/step - loss: 0.5099 - accuracy: 0.7950 - val_loss: 0.6933 - val_accuracy: 0.7391\n",
            "Epoch 596/700\n",
            "104/104 [==============================] - 3s 30ms/step - loss: 0.5154 - accuracy: 0.8041 - val_loss: 0.6796 - val_accuracy: 0.7198\n",
            "Epoch 597/700\n",
            "104/104 [==============================] - 3s 30ms/step - loss: 0.5090 - accuracy: 0.8059 - val_loss: 0.6785 - val_accuracy: 0.7440\n",
            "Epoch 598/700\n",
            "104/104 [==============================] - 3s 30ms/step - loss: 0.5291 - accuracy: 0.7944 - val_loss: 0.6854 - val_accuracy: 0.7391\n",
            "Epoch 599/700\n",
            "104/104 [==============================] - 3s 30ms/step - loss: 0.5059 - accuracy: 0.8089 - val_loss: 0.6752 - val_accuracy: 0.7198\n",
            "Epoch 600/700\n",
            "104/104 [==============================] - 3s 30ms/step - loss: 0.5170 - accuracy: 0.7999 - val_loss: 0.6910 - val_accuracy: 0.7150\n",
            "Epoch 601/700\n",
            "104/104 [==============================] - 3s 30ms/step - loss: 0.5130 - accuracy: 0.8005 - val_loss: 0.6931 - val_accuracy: 0.7343\n",
            "Epoch 602/700\n",
            "104/104 [==============================] - 3s 29ms/step - loss: 0.5159 - accuracy: 0.7908 - val_loss: 0.6762 - val_accuracy: 0.7246\n",
            "Epoch 603/700\n",
            "104/104 [==============================] - 3s 29ms/step - loss: 0.5109 - accuracy: 0.8071 - val_loss: 0.6801 - val_accuracy: 0.7101\n",
            "Epoch 604/700\n",
            "104/104 [==============================] - 3s 29ms/step - loss: 0.5223 - accuracy: 0.7969 - val_loss: 0.6839 - val_accuracy: 0.7150\n",
            "Epoch 605/700\n",
            "104/104 [==============================] - 3s 30ms/step - loss: 0.5022 - accuracy: 0.8059 - val_loss: 0.6756 - val_accuracy: 0.7391\n",
            "Epoch 606/700\n",
            "104/104 [==============================] - 3s 30ms/step - loss: 0.5138 - accuracy: 0.7981 - val_loss: 0.6992 - val_accuracy: 0.7053\n",
            "Epoch 607/700\n",
            "104/104 [==============================] - 3s 30ms/step - loss: 0.5144 - accuracy: 0.8138 - val_loss: 0.6659 - val_accuracy: 0.7391\n",
            "Epoch 608/700\n",
            "104/104 [==============================] - 3s 31ms/step - loss: 0.5132 - accuracy: 0.8065 - val_loss: 0.6790 - val_accuracy: 0.7246\n",
            "Epoch 609/700\n",
            "104/104 [==============================] - 3s 30ms/step - loss: 0.5293 - accuracy: 0.7993 - val_loss: 0.6753 - val_accuracy: 0.7246\n",
            "Epoch 610/700\n",
            "104/104 [==============================] - 3s 30ms/step - loss: 0.5044 - accuracy: 0.8017 - val_loss: 0.6801 - val_accuracy: 0.7198\n",
            "Epoch 611/700\n",
            "104/104 [==============================] - 3s 30ms/step - loss: 0.4853 - accuracy: 0.8229 - val_loss: 0.6877 - val_accuracy: 0.7150\n",
            "Epoch 612/700\n",
            "104/104 [==============================] - 3s 29ms/step - loss: 0.4983 - accuracy: 0.8059 - val_loss: 0.6927 - val_accuracy: 0.7150\n",
            "Epoch 613/700\n",
            "104/104 [==============================] - 3s 30ms/step - loss: 0.4938 - accuracy: 0.8017 - val_loss: 0.6878 - val_accuracy: 0.7198\n",
            "Epoch 614/700\n",
            "104/104 [==============================] - 3s 30ms/step - loss: 0.4981 - accuracy: 0.8168 - val_loss: 0.6850 - val_accuracy: 0.7198\n",
            "Epoch 615/700\n",
            "104/104 [==============================] - 3s 30ms/step - loss: 0.5122 - accuracy: 0.8017 - val_loss: 0.6826 - val_accuracy: 0.7295\n",
            "Epoch 616/700\n",
            "104/104 [==============================] - 3s 30ms/step - loss: 0.5020 - accuracy: 0.8047 - val_loss: 0.6693 - val_accuracy: 0.7391\n",
            "Epoch 617/700\n",
            "104/104 [==============================] - 3s 29ms/step - loss: 0.4886 - accuracy: 0.8053 - val_loss: 0.6769 - val_accuracy: 0.7343\n",
            "Epoch 618/700\n",
            "104/104 [==============================] - 3s 29ms/step - loss: 0.4864 - accuracy: 0.8150 - val_loss: 0.6813 - val_accuracy: 0.7295\n",
            "Epoch 619/700\n",
            "104/104 [==============================] - 3s 30ms/step - loss: 0.5036 - accuracy: 0.8071 - val_loss: 0.6798 - val_accuracy: 0.7198\n",
            "Epoch 620/700\n",
            "104/104 [==============================] - 3s 31ms/step - loss: 0.4816 - accuracy: 0.8192 - val_loss: 0.6674 - val_accuracy: 0.7150\n",
            "Epoch 621/700\n",
            "104/104 [==============================] - 3s 30ms/step - loss: 0.4917 - accuracy: 0.8132 - val_loss: 0.6750 - val_accuracy: 0.7150\n",
            "Epoch 622/700\n",
            "104/104 [==============================] - 3s 29ms/step - loss: 0.4801 - accuracy: 0.8138 - val_loss: 0.6843 - val_accuracy: 0.7101\n",
            "Epoch 623/700\n",
            "104/104 [==============================] - 3s 29ms/step - loss: 0.4771 - accuracy: 0.8180 - val_loss: 0.6781 - val_accuracy: 0.7198\n",
            "Epoch 624/700\n",
            "104/104 [==============================] - 3s 30ms/step - loss: 0.4800 - accuracy: 0.8198 - val_loss: 0.6831 - val_accuracy: 0.7295\n",
            "Epoch 625/700\n",
            "104/104 [==============================] - 3s 30ms/step - loss: 0.4755 - accuracy: 0.8174 - val_loss: 0.6658 - val_accuracy: 0.7295\n",
            "Epoch 626/700\n",
            "104/104 [==============================] - 3s 30ms/step - loss: 0.4911 - accuracy: 0.8144 - val_loss: 0.6634 - val_accuracy: 0.7488\n",
            "Epoch 627/700\n",
            "104/104 [==============================] - 3s 31ms/step - loss: 0.4776 - accuracy: 0.8180 - val_loss: 0.6777 - val_accuracy: 0.7295\n",
            "Epoch 628/700\n",
            "104/104 [==============================] - 3s 30ms/step - loss: 0.5033 - accuracy: 0.8041 - val_loss: 0.6897 - val_accuracy: 0.7391\n",
            "Epoch 629/700\n",
            "104/104 [==============================] - 3s 30ms/step - loss: 0.4817 - accuracy: 0.8180 - val_loss: 0.7038 - val_accuracy: 0.7198\n",
            "Epoch 630/700\n",
            "104/104 [==============================] - 3s 31ms/step - loss: 0.4796 - accuracy: 0.8307 - val_loss: 0.6942 - val_accuracy: 0.7053\n",
            "Epoch 631/700\n",
            "104/104 [==============================] - 3s 30ms/step - loss: 0.4773 - accuracy: 0.8174 - val_loss: 0.6847 - val_accuracy: 0.7295\n",
            "Epoch 632/700\n",
            "104/104 [==============================] - 3s 30ms/step - loss: 0.4693 - accuracy: 0.8180 - val_loss: 0.6825 - val_accuracy: 0.7198\n",
            "Epoch 633/700\n",
            "104/104 [==============================] - 3s 31ms/step - loss: 0.4813 - accuracy: 0.8204 - val_loss: 0.6661 - val_accuracy: 0.7246\n",
            "Epoch 634/700\n",
            "104/104 [==============================] - 3s 31ms/step - loss: 0.4817 - accuracy: 0.8192 - val_loss: 0.6645 - val_accuracy: 0.7343\n",
            "Epoch 635/700\n",
            "104/104 [==============================] - 3s 29ms/step - loss: 0.4832 - accuracy: 0.8089 - val_loss: 0.6746 - val_accuracy: 0.7198\n",
            "Epoch 636/700\n",
            "104/104 [==============================] - 3s 30ms/step - loss: 0.4803 - accuracy: 0.8241 - val_loss: 0.6969 - val_accuracy: 0.7101\n",
            "Epoch 637/700\n",
            "104/104 [==============================] - 3s 30ms/step - loss: 0.5003 - accuracy: 0.8144 - val_loss: 0.6656 - val_accuracy: 0.7101\n",
            "Epoch 638/700\n",
            "104/104 [==============================] - 3s 30ms/step - loss: 0.4881 - accuracy: 0.8065 - val_loss: 0.6881 - val_accuracy: 0.7246\n",
            "Epoch 639/700\n",
            "104/104 [==============================] - 3s 30ms/step - loss: 0.4870 - accuracy: 0.8114 - val_loss: 0.6673 - val_accuracy: 0.7198\n",
            "Epoch 640/700\n",
            "104/104 [==============================] - 3s 30ms/step - loss: 0.4925 - accuracy: 0.8017 - val_loss: 0.6901 - val_accuracy: 0.7005\n",
            "Epoch 641/700\n",
            "104/104 [==============================] - 3s 30ms/step - loss: 0.4780 - accuracy: 0.8102 - val_loss: 0.6614 - val_accuracy: 0.7295\n",
            "Epoch 642/700\n",
            "104/104 [==============================] - 3s 30ms/step - loss: 0.4913 - accuracy: 0.8144 - val_loss: 0.6762 - val_accuracy: 0.7343\n",
            "Epoch 643/700\n",
            "104/104 [==============================] - 3s 30ms/step - loss: 0.4677 - accuracy: 0.8204 - val_loss: 0.6823 - val_accuracy: 0.7295\n",
            "Epoch 644/700\n",
            "104/104 [==============================] - 3s 30ms/step - loss: 0.4659 - accuracy: 0.8174 - val_loss: 0.6753 - val_accuracy: 0.7053\n",
            "Epoch 645/700\n",
            "104/104 [==============================] - 3s 30ms/step - loss: 0.4775 - accuracy: 0.8108 - val_loss: 0.6712 - val_accuracy: 0.7198\n",
            "Epoch 646/700\n",
            "104/104 [==============================] - 3s 30ms/step - loss: 0.4984 - accuracy: 0.8077 - val_loss: 0.6714 - val_accuracy: 0.7295\n",
            "Epoch 647/700\n",
            "104/104 [==============================] - 3s 30ms/step - loss: 0.4748 - accuracy: 0.8198 - val_loss: 0.6815 - val_accuracy: 0.7053\n",
            "Epoch 648/700\n",
            "104/104 [==============================] - 3s 31ms/step - loss: 0.4655 - accuracy: 0.8168 - val_loss: 0.6471 - val_accuracy: 0.7295\n",
            "Epoch 649/700\n",
            "104/104 [==============================] - 3s 31ms/step - loss: 0.4597 - accuracy: 0.8198 - val_loss: 0.6602 - val_accuracy: 0.7246\n",
            "Epoch 650/700\n",
            "104/104 [==============================] - 3s 30ms/step - loss: 0.4916 - accuracy: 0.8144 - val_loss: 0.6649 - val_accuracy: 0.7246\n",
            "Epoch 651/700\n",
            "104/104 [==============================] - 3s 30ms/step - loss: 0.4517 - accuracy: 0.8301 - val_loss: 0.6698 - val_accuracy: 0.7440\n",
            "Epoch 652/700\n",
            "104/104 [==============================] - 3s 30ms/step - loss: 0.4850 - accuracy: 0.8047 - val_loss: 0.6930 - val_accuracy: 0.7005\n",
            "Epoch 653/700\n",
            "104/104 [==============================] - 3s 30ms/step - loss: 0.4443 - accuracy: 0.8265 - val_loss: 0.6570 - val_accuracy: 0.7343\n",
            "Epoch 654/700\n",
            "104/104 [==============================] - 3s 30ms/step - loss: 0.4597 - accuracy: 0.8271 - val_loss: 0.6853 - val_accuracy: 0.7246\n",
            "Epoch 655/700\n",
            "104/104 [==============================] - 3s 29ms/step - loss: 0.4490 - accuracy: 0.8295 - val_loss: 0.6682 - val_accuracy: 0.7440\n",
            "Epoch 656/700\n",
            "104/104 [==============================] - 3s 29ms/step - loss: 0.4577 - accuracy: 0.8241 - val_loss: 0.6752 - val_accuracy: 0.7246\n",
            "Epoch 657/700\n",
            "104/104 [==============================] - 3s 30ms/step - loss: 0.4583 - accuracy: 0.8271 - val_loss: 0.6623 - val_accuracy: 0.7295\n",
            "Epoch 658/700\n",
            "104/104 [==============================] - 3s 30ms/step - loss: 0.4710 - accuracy: 0.8186 - val_loss: 0.6854 - val_accuracy: 0.7198\n",
            "Epoch 659/700\n",
            "104/104 [==============================] - 3s 30ms/step - loss: 0.4448 - accuracy: 0.8349 - val_loss: 0.6639 - val_accuracy: 0.7343\n",
            "Epoch 660/700\n",
            "104/104 [==============================] - 3s 30ms/step - loss: 0.4489 - accuracy: 0.8259 - val_loss: 0.6486 - val_accuracy: 0.7391\n",
            "Epoch 661/700\n",
            "104/104 [==============================] - 3s 30ms/step - loss: 0.4388 - accuracy: 0.8374 - val_loss: 0.6680 - val_accuracy: 0.7246\n",
            "Epoch 662/700\n",
            "104/104 [==============================] - 3s 30ms/step - loss: 0.4548 - accuracy: 0.8301 - val_loss: 0.6567 - val_accuracy: 0.7198\n",
            "Epoch 663/700\n",
            "104/104 [==============================] - 3s 30ms/step - loss: 0.4634 - accuracy: 0.8210 - val_loss: 0.6588 - val_accuracy: 0.7488\n",
            "Epoch 664/700\n",
            "104/104 [==============================] - 3s 31ms/step - loss: 0.4403 - accuracy: 0.8349 - val_loss: 0.6772 - val_accuracy: 0.7343\n",
            "Epoch 665/700\n",
            "104/104 [==============================] - 3s 32ms/step - loss: 0.4562 - accuracy: 0.8253 - val_loss: 0.6628 - val_accuracy: 0.7295\n",
            "Epoch 666/700\n",
            "104/104 [==============================] - 3s 30ms/step - loss: 0.4762 - accuracy: 0.8216 - val_loss: 0.6910 - val_accuracy: 0.7150\n",
            "Epoch 667/700\n",
            "104/104 [==============================] - 3s 30ms/step - loss: 0.4241 - accuracy: 0.8313 - val_loss: 0.6614 - val_accuracy: 0.7440\n",
            "Epoch 668/700\n",
            "104/104 [==============================] - 3s 31ms/step - loss: 0.4401 - accuracy: 0.8380 - val_loss: 0.6502 - val_accuracy: 0.7440\n",
            "Epoch 669/700\n",
            "104/104 [==============================] - 3s 30ms/step - loss: 0.4435 - accuracy: 0.8349 - val_loss: 0.6569 - val_accuracy: 0.7391\n",
            "Epoch 670/700\n",
            "104/104 [==============================] - 3s 30ms/step - loss: 0.4529 - accuracy: 0.8271 - val_loss: 0.6658 - val_accuracy: 0.7391\n",
            "Epoch 671/700\n",
            "104/104 [==============================] - 3s 31ms/step - loss: 0.4451 - accuracy: 0.8265 - val_loss: 0.6855 - val_accuracy: 0.7150\n",
            "Epoch 672/700\n",
            "104/104 [==============================] - 3s 32ms/step - loss: 0.4349 - accuracy: 0.8458 - val_loss: 0.6632 - val_accuracy: 0.7343\n",
            "Epoch 673/700\n",
            "104/104 [==============================] - 3s 30ms/step - loss: 0.4349 - accuracy: 0.8362 - val_loss: 0.6720 - val_accuracy: 0.7246\n",
            "Epoch 674/700\n",
            "104/104 [==============================] - 3s 30ms/step - loss: 0.4432 - accuracy: 0.8229 - val_loss: 0.6612 - val_accuracy: 0.7488\n",
            "Epoch 675/700\n",
            "104/104 [==============================] - 3s 33ms/step - loss: 0.4261 - accuracy: 0.8434 - val_loss: 0.6785 - val_accuracy: 0.7440\n",
            "Epoch 676/700\n",
            "104/104 [==============================] - 3s 31ms/step - loss: 0.4541 - accuracy: 0.8229 - val_loss: 0.6503 - val_accuracy: 0.7440\n",
            "Epoch 677/700\n",
            "104/104 [==============================] - 3s 30ms/step - loss: 0.4473 - accuracy: 0.8319 - val_loss: 0.6880 - val_accuracy: 0.7150\n",
            "Epoch 678/700\n",
            "104/104 [==============================] - 3s 30ms/step - loss: 0.4463 - accuracy: 0.8265 - val_loss: 0.6605 - val_accuracy: 0.7150\n",
            "Epoch 679/700\n",
            "104/104 [==============================] - 3s 32ms/step - loss: 0.4447 - accuracy: 0.8307 - val_loss: 0.6576 - val_accuracy: 0.7246\n",
            "Epoch 680/700\n",
            "104/104 [==============================] - 3s 33ms/step - loss: 0.4445 - accuracy: 0.8356 - val_loss: 0.6516 - val_accuracy: 0.7150\n",
            "Epoch 681/700\n",
            "104/104 [==============================] - 3s 30ms/step - loss: 0.4349 - accuracy: 0.8404 - val_loss: 0.6504 - val_accuracy: 0.7295\n",
            "Epoch 682/700\n",
            "104/104 [==============================] - 3s 31ms/step - loss: 0.4405 - accuracy: 0.8422 - val_loss: 0.6604 - val_accuracy: 0.7295\n",
            "Epoch 683/700\n",
            "104/104 [==============================] - 3s 30ms/step - loss: 0.4416 - accuracy: 0.8368 - val_loss: 0.6553 - val_accuracy: 0.7585\n",
            "Epoch 684/700\n",
            "104/104 [==============================] - 3s 31ms/step - loss: 0.4349 - accuracy: 0.8271 - val_loss: 0.6593 - val_accuracy: 0.7150\n",
            "Epoch 685/700\n",
            "104/104 [==============================] - 3s 31ms/step - loss: 0.4398 - accuracy: 0.8265 - val_loss: 0.6702 - val_accuracy: 0.7150\n",
            "Epoch 686/700\n",
            "104/104 [==============================] - 3s 30ms/step - loss: 0.4407 - accuracy: 0.8235 - val_loss: 0.6495 - val_accuracy: 0.7488\n",
            "Epoch 687/700\n",
            "104/104 [==============================] - 3s 30ms/step - loss: 0.4299 - accuracy: 0.8307 - val_loss: 0.6403 - val_accuracy: 0.7440\n",
            "Epoch 688/700\n",
            "104/104 [==============================] - 3s 30ms/step - loss: 0.4074 - accuracy: 0.8458 - val_loss: 0.6337 - val_accuracy: 0.7585\n",
            "Epoch 689/700\n",
            "104/104 [==============================] - 3s 31ms/step - loss: 0.4337 - accuracy: 0.8392 - val_loss: 0.6459 - val_accuracy: 0.7295\n",
            "Epoch 690/700\n",
            "104/104 [==============================] - 3s 31ms/step - loss: 0.4474 - accuracy: 0.8283 - val_loss: 0.6386 - val_accuracy: 0.7488\n",
            "Epoch 691/700\n",
            "104/104 [==============================] - 3s 31ms/step - loss: 0.4274 - accuracy: 0.8428 - val_loss: 0.6435 - val_accuracy: 0.7343\n",
            "Epoch 692/700\n",
            "104/104 [==============================] - 3s 30ms/step - loss: 0.4245 - accuracy: 0.8331 - val_loss: 0.6501 - val_accuracy: 0.7246\n",
            "Epoch 693/700\n",
            "104/104 [==============================] - 3s 31ms/step - loss: 0.4189 - accuracy: 0.8428 - val_loss: 0.6393 - val_accuracy: 0.7150\n",
            "Epoch 694/700\n",
            "104/104 [==============================] - 3s 30ms/step - loss: 0.4255 - accuracy: 0.8386 - val_loss: 0.6601 - val_accuracy: 0.7440\n",
            "Epoch 695/700\n",
            "104/104 [==============================] - 3s 30ms/step - loss: 0.4293 - accuracy: 0.8343 - val_loss: 0.6452 - val_accuracy: 0.7343\n",
            "Epoch 696/700\n",
            "104/104 [==============================] - 3s 30ms/step - loss: 0.4223 - accuracy: 0.8380 - val_loss: 0.6623 - val_accuracy: 0.7246\n",
            "Epoch 697/700\n",
            "104/104 [==============================] - 3s 29ms/step - loss: 0.4147 - accuracy: 0.8434 - val_loss: 0.6485 - val_accuracy: 0.7440\n",
            "Epoch 698/700\n",
            "104/104 [==============================] - 3s 30ms/step - loss: 0.4452 - accuracy: 0.8198 - val_loss: 0.6389 - val_accuracy: 0.7295\n",
            "Epoch 699/700\n",
            "104/104 [==============================] - 3s 30ms/step - loss: 0.4256 - accuracy: 0.8416 - val_loss: 0.6499 - val_accuracy: 0.7343\n",
            "Epoch 700/700\n",
            "104/104 [==============================] - 3s 30ms/step - loss: 0.4228 - accuracy: 0.8428 - val_loss: 0.6497 - val_accuracy: 0.7391\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(cnnhistory.history['loss'])\n",
        "plt.plot(cnnhistory.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train','test'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "oQYnuaCrDH_A",
        "outputId": "3c50b135-60b2-4fd6-d08d-92d91d2e9294"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXgAAAEWCAYAAABsY4yMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXxc5X3v8c9vFs1o3yx5k1cMxgtgsAETCGEJJCwlCykhCUmbpHXapm3S29JCm+Wmr9570y1J0yYhbiFNSkJCWJI0IcEQtlDAIBsD3vC+SLYsWdYujZaZ5/5xjo02G0n4eEbH3/fr5ZdmzjLnN0J855nnPOc55pxDRETCJ5LtAkREJBgKeBGRkFLAi4iElAJeRCSkFPAiIiGlgBcRCSkFvAhgZv9pZn83xm33mNk73+rriARNAS8iElIKeBGRkFLAy6Thd43cbmavmlmXmd1tZlPN7Jdm1mFmj5tZ+aDtbzKzTWbWamZPmdmiQevON7P1/n4/ApLDjnWjmW3w933OzM6dYM2/b2Y7zOyImf3MzGb4y83MvmpmjWbWbmavmdlSf931ZrbZr63ezP5iQr8wOe0p4GWyuRm4BjgL+C3gl8BfA1V4f89/CmBmZwH3AZ/11z0C/LeZ5ZlZHvAT4L+ACuDH/uvi73s+cA/wKaAS+DbwMzNLjKdQM7sK+H/ALcB0YC/wQ3/1tcDl/vso9bdp9tfdDXzKOVcMLAWeGM9xRY5SwMtk86/OuUPOuXrgN8Ba59zLzrkU8DBwvr/dB4FfOOcec871A/8E5ANvA1YCceBrzrl+59wDwEuDjrEK+LZzbq1zLu2c+y7Q6+83Hh8B7nHOrXfO9QJ3ApeY2VygHygGzgbMObfFOXfQ368fWGxmJc65Fufc+nEeVwRQwMvkc2jQ455Rnhf5j2fgtZgBcM5lgP3ATH9dvRs6097eQY/nAH/ud8+0mlkrMMvfbzyG19CJ10qf6Zx7Avg34BtAo5mtNrMSf9ObgeuBvWb2tJldMs7jigAKeAmvA3hBDXh93nghXQ8cBGb6y46aPejxfuD/OOfKBv0rcM7d9xZrKMTr8qkHcM593Tm3HFiM11Vzu7/8Jefce4BqvK6k+8d5XBFAAS/hdT9wg5ldbWZx4M/xulmeA54HBoA/NbO4mb0fuGjQvv8O/IGZXeyfDC00sxvMrHicNdwHfNzMlvn99/8Xr0tpj5ld6L9+HOgCUkDGP0fwETMr9buW2oHMW/g9yGlMAS+h5Jx7HbgN+FfgMN4J2d9yzvU55/qA9wO/CxzB669/aNC+tcDv43WhtAA7/G3HW8PjwOeBB/G+NZwB3OqvLsH7IGnB68ZpBv7RX/dRYI+ZtQN/gNeXLzJupht+iIiEk1rwIiIhpYAXEQkpBbyISEgp4EVEQiqW7QIGmzJlips7d262yxARmTTWrVt32DlXNdq6QAPezP4M+D3AAa8BH/cvKR/V3Llzqa2tDbIkEZFQMbO9x1sXWBeNmc3Em/hphXNuKRDljTHAIiISsKD74GNAvpnFgAK8S7dFROQUCCzg/dn+/gnYh3cVX5tzbs3w7cxslZnVmlltU1NTUOWIiJx2AuuD92+88B5gHtAK/NjMbnPO3Tt4O+fcamA1wIoVK0ZcVtvf309dXR2p1HG77kMhmUxSU1NDPB7PdikiEhJBnmR9J7DbOdcEYGYP4c3Ffe8J9xqmrq6O4uJi5s6dy9DJ/8LDOUdzczN1dXXMmzcv2+WISEgE2Qe/D1hpZgX+tKxXA1vG+yKpVIrKysrQhjuAmVFZWRn6bykicmoF2Qe/FngAWI83RDKC3xUzXmEO96NOh/coIqdWoOPgnXNfBL4Y5DEADrWnKMiLUpxU/7WIyFGhmKqgqaOXzt6BQF67tbWVb37zm+Pe7/rrr6e1tTWAikRExiYUAQ9418oG4HgBPzBw4g+URx55hLKysmCKEhEZg5yai+atCOq2JXfccQc7d+5k2bJlxONxkskk5eXlbN26lW3btvHe976X/fv3k0ql+MxnPsOqVauAN6Zd6Ozs5LrrruOyyy7jueeeY+bMmfz0pz8lPz8/oIpFRDyTKuC/9N+b2HygfcTy7r4BYpEIebHxfyFZPKOEL/7WkuOu//KXv8zGjRvZsGEDTz31FDfccAMbN248NpzxnnvuoaKigp6eHi688EJuvvlmKisrh7zG9u3bue+++/j3f/93brnlFh588EFuu+22cdcqIjIekyrgc8FFF100ZKz617/+dR5++GEA9u/fz/bt20cE/Lx581i2bBkAy5cvZ8+ePaesXhE5fU2qgD9eS3vTgTbKC/KYURZ8t0dhYeGxx0899RSPP/44zz//PAUFBVxxxRWjjmVPJBLHHkejUXp6egKvU0QkNCdZg+qDLy4upqOjY9R1bW1tlJeXU1BQwNatW3nhhRcCqkJEZPwmVQs+GyorK7n00ktZunQp+fn5TJ069di6d7/73dx1110sWrSIhQsXsnLlyixWKiIylDkXVNt3/FasWOGG3/Bjy5YtLFq06IT7bT7QRml+HjPLJ/fIlLG8VxGRwcxsnXNuxWjrQtJFYwTXSSMiMjmFJOAV7yIiw4Um4EVEZKhwBLwmYhQRGSEUAa98FxEZKRQBD6gTXkRkmNAEfFD5PtHpggG+9rWv0d3dfZIrEhEZm9AEfFAU8CIyWYXiStYg++AHTxd8zTXXUF1dzf33309vby/ve9/7+NKXvkRXVxe33HILdXV1pNNpPv/5z3Po0CEOHDjAlVdeyZQpU3jyyScDrFJEZKTAAt7MFgI/GrRoPvAF59zXJvyiv7wDGl4bsXh23wCRiEEsOv7XnHYOXPfl464ePF3wmjVreOCBB3jxxRdxznHTTTfxzDPP0NTUxIwZM/jFL34BeHPUlJaW8pWvfIUnn3ySKVOmjL8uEZG3KMibbr/unFvmnFsGLAe6gYeDOt6psGbNGtasWcP555/PBRdcwNatW9m+fTvnnHMOjz32GH/1V3/Fb37zG0pLS7NdqojIKeuiuRrY6Zzb+5Ze5Tgt7X0N7RTkxZhdUfCWXv7NOOe48847+dSnPjVi3fr163nkkUf43Oc+x9VXX80XvvCFQGsREXkzp+ok663AfaOtMLNVZlZrZrVNTU0TevEg++AHTxf8rne9i3vuuYfOzk4A6uvraWxs5MCBAxQUFHDbbbdx++23s379+hH7ioicaoG34M0sD7gJuHO09c651cBq8GaTnOBRAhsnOXi64Ouuu44Pf/jDXHLJJQAUFRVx7733smPHDm6//XYikQjxeJxvfetbAKxatYp3v/vdzJgxQydZReSUC3y6YDN7D/Bp59y1b7btRKcLfr2hg/x4hNmVhSfcLtdpumARGa9sTxf8IY7TPXMy6UJWEZGhAg14MysErgEeCvI4IiIyUqB98M65LqDyJLwOZsc/lRqGycZy6c5aIhIOOT9VQTKZpLm5+cQBOMkT3jlHc3MzyWQy26WISIjk/FQFNTU11NXVcaIhlIfaU8QiRndj4hRWdnIlk0lqamqyXYaIhEjOB3w8HmfevHkn3ObPvvYMsysKWP2xZaeoKhGR3JfzXTRjYWZk1IUtIjJEOAIe0EBJEZGhwhHwBhqEIiIyVCgCPmKm9ruIyDChCHgzyKgJLyIyRDgCHnXRiIgMF4qAR100IiIjhCLgI6ZL/UVEhgtFwKuLRkRkpHAEvBlOnTQiIkOEI+BRC15EZLhQBHzETAEvIjJMKAIejYMXERkhFAFvaCYaEZHhwhHwSngRkRGCvidrmZk9YGZbzWyLmV0SxHEiGkUjIjJC0Df8+BfgV865D5hZHlAQxEG8uWiCeGURkckrsIA3s1LgcuB3AZxzfUBfIMfCdCWriMgwQXbRzAOagO+Y2ctm9h9mVjh8IzNbZWa1ZlZ7ovuunoiZuuBFRIYLMuBjwAXAt5xz5wNdwB3DN3LOrXbOrXDOraiqqprQgUzj4EVERggy4OuAOufcWv/5A3iBf9J5V7Iq4UVEBgss4J1zDcB+M1voL7oa2BzEsdRFIyIyUtCjaP4E+L4/gmYX8PEgDqK5aERERgo04J1zG4AVQR4DvHHwmqpARGSo0FzJqnwXERkqFAEPumWfiMhwoQh40y37RERGCEXAR9RFIyIyQigC3tBkYyIiw4Uj4NWCFxEZITwBn+0iRERyTEgCXuPgRUSGC0fAg5rwIiLDhCPgTePgRUSGC0XARzQOXkRkhFAEvKFb9omIDBeOgNdNt0VERghHwKNx8CIiw4Uj4HXLPhGREUIS8DrJKiIyXDgCHg2DFxEZLhwBr7loRERGCPSWfWa2B+gA0sCAcy6Q2/dFNIpGRGSEoG+6DXClc+5wkAcw0zh4EZHhQtFFAxpFIyIyXNAB74A1ZrbOzFaNtoGZrTKzWjOrbWpqmtBBTLONiYiMEHTAX+acuwC4Dvi0mV0+fAPn3Grn3Arn3IqqqqoJHUS37BMRGSnQgHfO1fs/G4GHgYuCOI6h+eBFRIYLLODNrNDMio8+Bq4FNgZzLHXQiIgMF+QomqnAw+Z1kMeAHzjnfhXEgTQXjYjISIEFvHNuF3BeUK8/mDcXjRJeRGSwUAyT1JWsIiIjhSPg0S37RESGC0fAazZJEZERQhHwEY2iEREZIRQBb6Zx8CIiw4Uj4NFJVhGR4UIR8KiLRkRkhFAEfESXsoqIjBCKgDdQH7yIyDChCPh4NMJAxpHRXT9ERI4JRcAn4t7b6EtnslyJiEjuCEfAx6IA9PYr4EVEjhpTwJvZZ8ysxDx3m9l6M7s26OLGKum34HsH0lmuREQkd4y1Bf8J51w73pzu5cBHgS8HVtU4HWvBD6gFLyJy1FgD3vyf1wP/5ZzbNGhZ1iViasGLiAw31oBfZ2Zr8AL+Uf9OTTnTXD4a8Cn1wYuIHDPWG358ElgG7HLOdZtZBfDx4Moan0RcXTQiIsONtQV/CfC6c67VzG4DPge0jWVHM4ua2ctm9vOJFvlm1EUjIjLSWAP+W0C3mZ0H/DmwE/jeGPf9DLBlArWN2RsBrxa8iMhRYw34AefdUeM9wL85574BFL/ZTmZWA9wA/MfES3xzGgcvIjLSWPvgO8zsTrzhkW83swgQH8N+XwP+kjF8GLwVCY2DFxEZYawt+A8CvXjj4RuAGuAfT7SDmd0INDrn1r3JdqvMrNbMapuamsZYzlDqohERGWlMAe+H+veBUj+4U865N+uDvxS4ycz2AD8ErjKze0d57dXOuRXOuRVVVVXjq96nC51EREYa61QFtwAvAr8N3AKsNbMPnGgf59ydzrka59xc4FbgCefcbW+x3lEd66LpVxeNiMhRY+2D/xvgQudcI4CZVQGPAw8EVdh4qItGRGSksQZ85Gi4+5oZx0yUzrmngKfGXtb45EUV8CIiw4014H9lZo8C9/nPPwg8EkxJ42dmJGIRjaIRERlkTAHvnLvdzG7GO3EKsNo593BwZY1fIhbROHgRkUHG2oLHOfcg8GCAtbwliXhUXTQiIoOcMODNrAMY7UanBjjnXEkgVU2AumhERIY6YcA75wK9AvVk8gJeLXgRkaNCcU9W8C52Uh+8iMgbwhPwcXXRiIgMFp6AVxeNiMgQIQp4jaIRERksRAEf0Vw0IiKDhCbgk/EoPQp4EZFjQhPw5QVxWrr6sl2GiEjOCE3AVxQmaE8N0J9WP7yICIQq4L07CLZ0qxUvIgKhCvgEAC1d/VmuREQkN4Qm4Mv9FnxzV2+WKxERyQ2hCfhKteBFRIYITcAfbcEfUQteRAQIMODNLGlmL5rZK2a2ycy+FNSxAMoL8gA4oha8iAgwjht+TEAvcJVzrtPM4sCzZvZL59wLQRwsHo1QkoypBS8i4gss4J1zDuj0n8b9f6PdPOSkqSxK0KyLnUREgID74M0samYbgEbgMefc2lG2WWVmtWZW29TU9JaOV14Q1zh4ERFfoAHvnEs755YBNcBFZrZ0lG1WO+dWOOdWVFVVvaXjVRQmaO5UwIuIwCkaReOcawWeBN4d5HEqCtWCFxE5KshRNFVmVuY/zgeuAbYGdTzwWvBHuvrwuv9FRE5vQY6imQ5818yieB8k9zvnfh7g8agojNOfdnT2DlCcjAd5KBGRnBfkKJpXgfODev3RHJ2PprmzTwEvIqe90FzJClBTng/AviPdWa5ERCT7QhXw86cUArD7cFeWKxERyb5QBXxVcYKiREwBLyJCyALezJg3pZCdTZ1vvrGISMiFKuAB5k0pVAteRISQBnx9aw+p/nS2SxERyarQBfz8qkKcg73NGkkjIqe38AX8lCIAdh9WP7yInN5CF/BzpxQAsEv98CJymgtdwBcn41QXJ1iz6RCZjOakEZHTV+gCHqCxo5cN+1v52SsHsl2KiEjWhDLg37loKgAH2nqyXImISPaEMuC/+ZELAGjr1g24ReT0FY6A/+FHYP33jj3Ni0WYXVHAofZUFosSEcmuIOeDP3V2/wZKZg5ZNLUkwW6NhReR01g4WvDJEuhtH7Lo6kVTeWV/K1sb2o+zk4hIuIUj4BMlkBoa5O+/wGvRP775UDYqEhHJunAE/Cgt+OriJOfWlPLE1sYsFSUikl1B3nR7lpk9aWabzWyTmX0mqGN5Lfi2EYuvOrual/e3anZJETktBdmCHwD+3Dm3GFgJfNrMFgdypFFa8AAfvmg2hXkxPvGfL9E7oNklReT0EljAO+cOOufW+487gC3AzBPvNUGj9MEDVJck+fqHlrH7cBfffnpXIIcWEclVp6QP3szmAucDa0dZt8rMas2stqmpaWIHSJZ6XTSZka30KxdWc/G8Cr7y2DYe0wlXETmNBB7wZlYEPAh81jk3opntnFvtnFvhnFtRVVU1sYOUzQKXho6Dox2f1R9bQVVxgs/88GW2HeqY2DFERCaZQAPezOJ44f5959xDgR2ofK73s2XPqKtL8+PcddsFdPelufarz/DDF/fpjk8iEnpBjqIx4G5gi3PuK0EdB3gj4I/sPu4my+dU8PYzpwBwx0Ov8dcPvRZoSSIi2RZkC/5S4KPAVWa2wf93fSBHKp3l/Xz0b6D/+DNI/tcnL2b1R5ezfE45D71cz1fWvM6Rrr5AShIRyTZzLnduirFixQpXW1s7sZ3/d6n38x13wJV3nnDT7r4BPvIfa3l5XysAy+eUc/u7FrJyfuXEji0ikiVmts45t2K0deG4knWwgxvedJOCvBjf+8RFfPKyeQCs29vCratf4L3f+B9+8nI9mw6MvGhKRGSyCU8L/tX74aHfBwzOuBJ2PQ03fhXiBRDPhwXvhN3PwK+/BFf+DZzt9RYd7uyloS3Fjf/67LGXikeNa5dMo6oowR9dcQYVhXnEouH7LBSRye9ELfjwBDxATyv8/ZyxbXvz3ZDuhzOvAYvQu+t/+Mu1SWbPms2zOw4f674BOH92Gff9/kqe23mYyxZUkRdT2ItIbjh9Ah7glR/BM/8AhdXQ2wGHRhktk1cEfZ2j759fQeaqL1CXSnDdL/LoIn/EJp+/cTE3nDOdWNSYUpR4a/WKiLwFp1fAj6anBdIDUFQFmQykWmHXk7DhB1C5wLsKdvcz0F4/dL/5V+Cu+jxrNjfxvadeYW1mEQPEMIOjv7Y/uWoBn7h0HuWFeSe/bhGRN6GAH6u+bhhIweFt8NM/hubtIzbpXXILu/fsprGjj3/rv4kX3SLMIBmLcvPymfzJVWdSlIhRkBfFuxRARCQ4CviJcA4aXoU9z3onbHc/AwMjx9hvuvxbvNbYzz9viNJE+ZB13/n4hVxxVhW7DndxRlXRqapcRE4jCviTIZP2TsrW10JfF/R3w48/Dni/PxeJs7vgHF5oLeVLA79DL0O7bN65qJov3LiE2ZUFWSheRMLqRAEfjptunwqRqPdv7mVvLJt/BdSvg+2PYQ0bmb/3WebH4NbiV2grnM9DfRfxnaaF9Lso8dfXcvmWRqaVJPnb9yyhsihBTXk+U0uS2XpHIhJyasGfTM7Bzl/Dxodg/1po3jFk9Z7MVJ7KnMfjmeU8mzkHgJXzK5g3pYg7rjub0vx4NqoWkUlMXTTZkEl7rfvNP4WdT0LjpiGrf5l/A8+1V/Hj9DtIkaCyMI9rFk9lQXUR150zncrCPGIR0wVWInJCCvhc0NUMe34DXU3w6o+g7qVjqxrP+jA/2QVPdM/npcxCKosLaOzoZeX8ClZdPh8z4/Izq4hGNCpHRIZSwOca57ypFZ79CsQS0PAauIy3CmNvbC4tfVF+mn4bD6Qvp4cEFcUFfGzlHPLzomw71MHnblxMSVJdOiKnOwV8ruvr9rpzvnvjG7cfHKQxNoOvRn+XH7Ytxvnzw80sy2fhtGKmlSa5+YKZLJ9TkYXCRSTbFPCTTWejd5XtrqegdCa8fC8AmUQJA/FiNlVey/cPzGBz9Cw2t3qt+HecVcW8KYW8Y2EV8yoLebW+ja0H2/nU5WdQWqCWvkhYKeAnu73PwcYHoa0e2vZD4xbvHrRAqvQMNnaV0teb4sfpd/BI5uIRY/CXzCjhczcs5qJ5FUQjhnNOV9mKhIQCPmz6uuDAy95QzH1rcbufwfyrbHujhewsWk5TX4L8TCf/3bmQn6dX0kKxv7MX7NctncaXbz6X53ce5mBbit9921yFvsgkpIAPu0zau7L21fu91v7+F6Gvw5tkDchE4qSixRwZSPBk/xJqrIk2Ctni5vFsegmb3ByWzCjlbWdUUl2cJNWf5polUykvyNOFWCI5LisBb2b3ADcCjc65pWPZRwF/kg30QeNmL/h3PuEN0ew+PGKzBqvi5YG5FJLiucwS9rlqGlwFu9x0WinmhnOn88dXLiA/7o3gWTqzlBllI6dRFpFTL1sBfznQCXxPAZ9D0v1eP/6mn3jPX7obonFcyx6MkX8LDUzh6QHvP98WN5t1mbM4L7KTnqLZFFfPJm/6Eq5dPJWzphWTiEVoaEsxq7yAiMbsi5wSWeuiMbO5wM8V8JPAQC9YBI7shroXcRh0N8OOx0nvfYFYpnfU3bZlZtJLnH5iHHHFlFoXPS7Br6JX0Fm+iL/74CWkElVUlxePur+IvDU5HfBmtgpYBTB79uzle/fuDawemaD0AJh5NzTf+zypg1tINe2ksOkV2irOpTdjxI5sw2UyTLOWEbv3uDy2Jc+lxh0giqOr/GzSJbM4lL+AnlgJfdXn0mhVfPji2Vl4cyKTW04H/GBqwU9yztG05Td0xcuZm9fB66++wNral1gS2ctCt4siesg44zCllNJFwvoB7wOgnyj51k+cAQCeSp/HC7EVvP38pVTNWURJLMO0OWdCoti7MKywMpvvVCRnKOAla46Oue/v78cN9NLaBzuaUuSlu2jb9DhnxRo4tOtVupvriRWWkdd9iBWRbcd9vQxGBEdH0TwihZW49oN0Jqrpn3UpNVOrScVLya+eD7F8XH45bS1NlJ15ibdzT4t3P95M2rtaOL8cYrrVokxumg9esubo2Pp4PA7xONX5UF1aBEyBhZ8EYNag7Z/fcZhv7azjXTV9dLcc4pFnnmd6IsURymhvbeYMt49ro7V0tnfT297PfGugqKceWl+G1xhyi3QDyoCG+CzyY0ZRqp6of4EYgIsmsDOvId1+kIgbwJa8HwoqvFs2WhSmLoGqs72fvR3eKKRECaT7oGQmRDTTp+S2IEfR3AdcAUwBDgFfdM7dfaJ91IKXN/N6Qwfr97XQ2N7L3iNdVBUnuPvpbQwQZUFBimTPQWbndWI4KgYO8fbIa8y0w8dOBGdchP2uii6SRMhwfayWjkyCqdFOCl3n2AupOtu79gCD6kXehHF9XXDZn3kTyEViEEvC4dehYj7MXOF9a5hyFiRLINUOa++Ci//AuxVkNM/remp4FZa8zzvnMZxzoy+X05oudJJQG0hniJgRiRg9felj0yofaO2hs3eAeDRCOuPo6htg26EOth7sYHtjB/WtPZwzs5RoJMKjr+6jhkamWgsvZRZSShdTrYUbK+qYYu0cGUjSOpBHMtXA4qkFLOp8kcOxqczM66SsazeZaIJkz6HxFx+JQWZg6LJECcxeCTMu8Na7tHctw5Fd8LY/8Ya65hXA9POgtxOqFnrdTZ2N3reLSNS7eXxPq9cldda7Tu4HQyYNmL7B5AgFvMib2HygnZ7+AQoTMVq7+9ne2MnGujae3XGY3oE0xck41cUJNh9oJ+McXX3pIftHyDDbDtHl8qmyVhxGUXSAcxYtZH7TE+xrd8yeOZMlycPMyu+loihJpLCSju3PstHO4ryKfgpad0B9LS6/AtrrsXTfyXlzU8+BXv+cA3jfFqYu8bqhEkXQsgeWfgC2Pwp7n/e+kZh5F8o1b/e6o+Zc6m2751nvauniabDiE94Hytk3et88MmmI53uT5BVP8z6giqd75z5mXfTGeQ+X8T6Ejqd1v3dMnDdUt6j65PweQkoBL3ISOefYd6Sbrt40dS3dRCNGXUsPu5o6qS5J8o+Pvn5s24hBZpT/xeJRoyQZp7lraIhfubCKDftbae3u5R0Lysnra6Ui3cy8RRfwWl0rt55fxVnFfUTz8qm0dqhf73UJZdKkUx0cbEtRWV5K/rSzofMQPP8Nr2VfPNUL9Hg+tO71QjSaB2n/+gf/fgRecYVQMt37BjDQ633DSPcO26bA76Iap2jCO96iG6G/x+vaSpR4rx3P925qf1SiBHrboWwOzL7Ee7zoJu+D5shuwMG2R70usIr53lXbM1fAtKXe65bMeOPcydIPwK4nIZYPcy7x3leyzPtwK5sN237lfcCt/CMorIbX7vc+6CrmeyO3iqd735z6Or0PudkrvRqTpW9M8b3/JVhwtTcZYPUiaKuDVCtMO2f8v6dxUMCLnGK/2tjAWVOLmFmeT1tP/7FpHgoTMV7Z38rWhg4a23tZOrOUqSUJ/nnNNnoH0jR39RGPRugbyBCPGvnxKO2pgRGvH40YN547nebOPpLxCLsPd3Gkq4+Wbm/o6ccumcMvXj1Ifl6Uj1w8h4F0hpnl+TR29PKhC2dRmjAcxoZdByhLRpjbuw0rqsaV1mCRmBeig6XaYPtj0H0ElrwX8gq91n48Hw6+4p1XyCvynmfS3vruZti+xutmatnjnZOI5nmB+PovoLDKC/zxTdAAAAuBSURBVOGWPd75hZ4W70PDZbwWfKLY+3Bp2TOyG+uoomlegLu093pdTRP/jzZad9lYVJwBR3Z6j6vOhqatQ9df/pfe76++Fi79LFQv9s7N1H4HonHvQyu/DBZeN6GyFfAik0SqP00yHqWhLcXUkgQZBy3dfTy3s5nCvChrdx/hlxsPUpyIs+9INyXJGAMZR2PHyCuNS/PjlOZ72w0WjRhl+XGS8Sj1rT0j9qsuTpCMR1kxx+/SMfjwRbOZWpLk357YQVVxgrOnF3P90unHnZLCOUeqP0N+3gm6Yobr6/Ja+JHo0HMGA71eS3znE1449rR4XUOpVph/pdeqBq8l3rjVuzVmXpH3Gt1HYOevvfMVi98LmX7Y/DPvQ+bILiit8bqcZl3ktd5f+Kb3rajzEDTvgIIpsPx3vPsztOyG8rneBw5434jc0K66Y8vG+2FRNBX+4vjDg09EAS8SQoPn9W9P9dPY3suC6iIeee0gXb0DvO/8mUTMuOuZnby4+wi3Xjib/LwoD66r44mtjeTnRXnPeTPY1tjJM9sm1vKdU1lAqt8LubmVhVw8r4JLF0zhg6tfAOCiuRW8Y2EV1yyeSn1rD7/ZdpgL55Zz8fxKyvLjdPYNsKm+nXNqSilKeKO2ewfSJGLj+GA4VVr2eh8igz98upq98wqRCGQy3oiovEJvXU+r182UavW+jQykYN1/eh8elQu8rrCKed4HyYzzvZPlE6CAF5Hjcs5xuLOPtp4+7xtDVx+xqPHK/jbOm1XKxvp2Nh9op7QgzgPr6vjt5TXsPtzFloZ2Uv0ZDO+bx5TiBLuauiZcx/I55TS0pahv7WFmWT4r51dSXZLg6rOrOdTeS1Vxgob2FDecM9075kCaZ7Y1MXdKIWdPKzn2Ov3pDPHo0BE+fQMZ8mLhHPWjgBeRwAykM2Qc5MUivLK/lR++tI/zasq4eXkN//X8XvY0d3GgtYdza8q4eF4FGw+088KuZjpTAzy/q/m4rzu9NMnBttSo64qTMToGnZtYOLWYjlQ/RckY2w55XTYXzC5j44F2FlQVsaOxkz+75iwqi/LYf6SbZbPKmFNZyBlVhaQzjlfq2phdUUBVcQKAjfVtzCjLpyQZI2LG3iPdzK4oYCCTyblvFwp4Eck5zjnaewYoLYhzuLOXysI80hlHd3+a3v4MVcUJfrqhnlf2t1GYiNI3kMHM+M7/7Oa8WWXsbe7iA8trSPVneHlfC+v3tQ55/bmVBexp7qaqOEHTKOcoAM6sLmJ74xsXuC2ZUUKqP83OQd9EppUkaWh/44OmJBnjvlUr2VjfxpIZpRQmYrze0M6mA+386dVnHvv2cPREedB3SlPAi0hoZDJu1JO7Oxo7AceC6uJj5yd6+tIk4xGaOnu594V9LJ5ewpzKAu56eid1Ld4J5saOFA1tKZbOLGVnYyfn1JTS3ZfmrOpiflS7f9z1zShNUpIfZ2tDB1OKElQW5lFZlEepf2J7T3MXb18whfNmlfHyvlY2H2znD684gxVzyif0YaCAFxEZg9FuSN/ZO0BhXpQDbSme39nMY5sbqChMcEZVIS/sauZgW4qCvCgv7WmhMC/KrIoCtjZ0AN51DUe6++nqHaCtp/+43yQqCvNY97l3KuBFRHLRka4+SpIxYtEIzjk6ewcoTsaHbPODtfuoKk5QURintz/D4a4+phTlETFj5fyJTYGt2SRFRAJWUfjG1NNmNiLcgVN+U5twjhsSEREFvIhIWCngRURCSgEvIhJSCngRkZBSwIuIhJQCXkQkpBTwIiIhlVNXsppZE7B3grtPAQ6fxHKCNJlqhclV72SqFVRvkCZTrTDxeuc456pGW5FTAf9WmFnt8S7XzTWTqVaYXPVOplpB9QZpMtUKwdSrLhoRkZBSwIuIhFSYAn51tgsYh8lUK0yueidTraB6gzSZaoUA6g1NH7yIiAwVpha8iIgMooAXEQmpSR/wZvZuM3vdzHaY2R3ZrgfAzO4xs0Yz2zhoWYWZPWZm2/2f5f5yM7Ov+/W/amYXnOJaZ5nZk2a22cw2mdlncrzepJm9aGav+PV+yV8+z8zW+nX9yMzy/OUJ//kOf/3cU1mvX0PUzF42s59Pglr3mNlrZrbBzGr9Zbn6t1BmZg+Y2VYz22Jml+RwrQv93+nRf+1m9tnA63XOTdp/QBTYCcwH8oBXgMU5UNflwAXAxkHL/gG4w398B/D3/uPrgV8CBqwE1p7iWqcDF/iPi4FtwOIcrteAIv9xHFjr13E/cKu//C7gD/3HfwTc5T++FfhRFv4e/hfwA+Dn/vNcrnUPMGXYslz9W/gu8Hv+4zygLFdrHVZ3FGgA5gRdb1be4En8RV0CPDro+Z3Andmuy69l7rCAfx2Y7j+eDrzuP/428KHRtstS3T8FrpkM9QIFwHrgYrwrAGPD/y6AR4FL/Mcxfzs7hTXWAL8GrgJ+7v8Pm5O1+scdLeBz7m8BKAV2D//95GKto9R+LfA/p6Leyd5FMxPYP+h5nb8sF011zh30HzcAU/3HOfMe/C6B8/FaxTlbr9/lsQFoBB7D+xbX6pwbGKWmY/X669uAid3deGK+BvwlkPGfV5K7tQI4YI2ZrTOzVf6yXPxbmAc0Ad/xu7/+w8wKc7TW4W4F7vMfB1rvZA/4Scl5H8k5NT7VzIqAB4HPOufaB6/LtXqdc2nn3DK81vFFwNlZLmlUZnYj0OicW5ftWsbhMufcBcB1wKfN7PLBK3PobyGG1w36Lefc+UAXXhfHMTlU6zH++ZabgB8PXxdEvZM94OuBWYOe1/jLctEhM5sO4P9s9Jdn/T2YWRwv3L/vnHvIX5yz9R7lnGsFnsTr5igzs9goNR2r119fCjSfohIvBW4ysz3AD/G6af4lR2sFwDlX7/9sBB7G+wDNxb+FOqDOObfWf/4AXuDnYq2DXQesd84d8p8HWu9kD/iXgDP9UQl5eF99fpblmo7nZ8Dv+I9/B6+v++jyj/lnzVcCbYO+sgXOzAy4G9jinPvKJKi3yszK/Mf5eOcLtuAF/QeOU+/R9/EB4Am/pRQ459ydzrka59xcvL/NJ5xzH8nFWgHMrNDMio8+xusr3kgO/i045xqA/Wa20F90NbA5F2sd5kO80T1ztK7g6s3GSYaTfMLieryRHzuBv8l2PX5N9wEHgX68lsYn8fpSfw1sBx4HKvxtDfiGX/9rwIpTXOtleF8LXwU2+P+uz+F6zwVe9uvdCHzBXz4feBHYgff1N+EvT/rPd/jr52fpb+IK3hhFk5O1+nW94v/bdPT/pxz+W1gG1Pp/Cz8BynO1Vr+GQrxvZKWDlgVar6YqEBEJqcneRSMiIsehgBcRCSkFvIhISCngRURCSgEvIhJSCniRk8DMrjB/tkiRXKGAFxEJKQW8nFbM7Dbz5pPfYGbf9icu6zSzr5o3v/yvzazK33aZmb3gz8f98KC5uheY2ePmzUm/3szO8F++aND85N/3rxIWyRoFvJw2zGwR8EHgUudNVpYGPoJ3hWGtc24J8DTwRX+X7wF/5Zw7F+9qwqPLvw98wzl3HvA2vKuWwZuJ87N48+nPx5uLRiRrYm++iUhoXA0sB17yG9f5eJM7ZYAf+dvcCzxkZqVAmXPuaX/5d4Ef+3O1zHTOPQzgnEsB+K/3onOuzn++Ae+eAM8G/7ZERqeAl9OJAd91zt05ZKHZ54dtN9H5O3oHPU6j/78ky9RFI6eTXwMfMLNqOHav0Tl4/x8cnd3xw8Czzrk2oMXM3u4v/yjwtHOuA6gzs/f6r5Ews4JT+i5ExkgtDDltOOc2m9nn8O5YFMGb7fPTeDeLuMhf14jXTw/e9K13+QG+C/i4v/yjwLfN7G/91/jtU/g2RMZMs0nKac/MOp1zRdmuQ+RkUxeNiEhIqQUvIhJSasGLiISUAl5EJKQU8CIiIaWAFxEJKQW8iEhI/X9j2pQ5a5A6pwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "01otXNBSCLs9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(cnnhistory.history['accuracy'])\n",
        "plt.plot(cnnhistory.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train','test'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "IFkTuO8nDNdq",
        "outputId": "4670c37d-7e46-43ac-b7f5-fc47e64a6b18"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#predictions = model.predict_classes(x_testcnn)\n",
        "predictions = model.predict(x_testcnn)"
      ],
      "metadata": {
        "id": "A2xtrN5wDQgY"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_f_ohjXKDUpY",
        "outputId": "6f27a14c-c264-43ae-920a-85827122569b"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[2.5228269e-03, 6.4984993e-03, 8.9828774e-02, 3.5088599e-02,\n",
              "        6.2064642e-01, 2.4541488e-01],\n",
              "       [1.5428974e-02, 9.5694941e-01, 3.2211498e-03, 1.2654116e-02,\n",
              "        1.0278971e-02, 1.4673951e-03],\n",
              "       [1.4455679e-04, 1.9713868e-03, 8.8393193e-01, 1.2939210e-03,\n",
              "        8.6332612e-02, 2.6325485e-02],\n",
              "       ...,\n",
              "       [6.8583054e-04, 2.2354607e-04, 5.4497183e-03, 5.9432480e-03,\n",
              "        8.0725175e-01, 1.8044592e-01],\n",
              "       [3.2034941e-02, 1.4035478e-02, 9.0121776e-03, 7.0192873e-01,\n",
              "        8.0252998e-03, 2.3496330e-01],\n",
              "       [9.0879906e-04, 2.2140313e-04, 1.4437077e-03, 4.8813066e-01,\n",
              "        6.4508065e-05, 5.0923085e-01]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cmA2bFgsDW3D",
        "outputId": "b11eeb4a-cd8d-4e0c-aa38-ad7e39855361"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5, 1, 2, 5, 4, 3, 2, 0, 3, 0, 3, 2, 0, 3, 3, 0, 5, 0, 2, 4, 0, 0,\n",
              "       1, 3, 2, 3, 2, 5, 3, 1, 2, 4, 2, 2, 5, 5, 3, 5, 3, 3, 4, 1, 2, 2,\n",
              "       3, 1, 5, 3, 1, 0, 4, 5, 5, 5, 5, 1, 2, 3, 2, 5, 0, 2, 4, 2, 5, 4,\n",
              "       2, 0, 2, 3, 5, 2, 0, 3, 4, 4, 4, 0, 5, 5, 3, 4, 5, 3, 2, 4, 1, 5,\n",
              "       0, 5, 0, 5, 4, 0, 1, 4, 0, 2, 2, 0, 2, 4, 5, 3, 4, 5, 3, 1, 2, 2,\n",
              "       2, 1, 3, 2, 1, 2, 4, 4, 2, 1, 2, 4, 5, 1, 4, 2, 0, 4, 5, 5, 3, 1,\n",
              "       2, 1, 5, 5, 1, 2, 3, 3, 0, 3, 3, 0, 1, 0, 1, 2, 2, 5, 2, 2, 2, 1,\n",
              "       1, 0, 1, 1, 1, 4, 0, 1, 5, 1, 5, 5, 5, 4, 1, 0, 3, 5, 2, 4, 1, 4,\n",
              "       1, 3, 2, 0, 5, 5, 3, 5, 4, 5, 4, 0, 4, 1, 2, 1, 4, 0, 4, 3, 2, 1,\n",
              "       0, 3, 5, 0, 4, 5, 4, 5, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_Ytest = y_test.astype(int)"
      ],
      "metadata": {
        "id": "0PHDKWJWDY3g"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_Ytest"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k68v2i-pDbZE",
        "outputId": "89df4e63-e9d1-4162-d61f-19b473c1b6b6"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5, 1, 2, 5, 4, 3, 2, 0, 3, 0, 3, 2, 0, 3, 3, 0, 5, 0, 2, 4, 0, 0,\n",
              "       1, 3, 2, 3, 2, 5, 3, 1, 2, 4, 2, 2, 5, 5, 3, 5, 3, 3, 4, 1, 2, 2,\n",
              "       3, 1, 5, 3, 1, 0, 4, 5, 5, 5, 5, 1, 2, 3, 2, 5, 0, 2, 4, 2, 5, 4,\n",
              "       2, 0, 2, 3, 5, 2, 0, 3, 4, 4, 4, 0, 5, 5, 3, 4, 5, 3, 2, 4, 1, 5,\n",
              "       0, 5, 0, 5, 4, 0, 1, 4, 0, 2, 2, 0, 2, 4, 5, 3, 4, 5, 3, 1, 2, 2,\n",
              "       2, 1, 3, 2, 1, 2, 4, 4, 2, 1, 2, 4, 5, 1, 4, 2, 0, 4, 5, 5, 3, 1,\n",
              "       2, 1, 5, 5, 1, 2, 3, 3, 0, 3, 3, 0, 1, 0, 1, 2, 2, 5, 2, 2, 2, 1,\n",
              "       1, 0, 1, 1, 1, 4, 0, 1, 5, 1, 5, 5, 5, 4, 1, 0, 3, 5, 2, 4, 1, 4,\n",
              "       1, 3, 2, 0, 5, 5, 3, 5, 4, 5, 4, 0, 4, 1, 2, 1, 4, 0, 4, 3, 2, 1,\n",
              "       0, 3, 5, 0, 4, 5, 4, 5, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds1=predictions.argmax(axis=1)\n",
        "preds1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4_cAI39VFhtp",
        "outputId": "1843664a-dcf0-4336-a8c3-71c39e7ecb76"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([4, 1, 2, 5, 4, 1, 2, 0, 3, 1, 3, 2, 1, 1, 3, 0, 5, 3, 5, 4, 2, 1,\n",
              "       1, 3, 4, 5, 2, 2, 3, 3, 2, 4, 4, 2, 5, 4, 1, 5, 3, 2, 5, 1, 4, 2,\n",
              "       3, 0, 3, 3, 1, 1, 4, 5, 4, 3, 3, 1, 1, 3, 2, 0, 0, 2, 4, 4, 5, 4,\n",
              "       2, 0, 2, 4, 5, 2, 0, 1, 4, 4, 4, 3, 5, 5, 3, 2, 5, 3, 2, 4, 1, 3,\n",
              "       1, 4, 0, 5, 4, 4, 1, 4, 3, 4, 2, 4, 2, 1, 5, 3, 4, 5, 5, 1, 2, 2,\n",
              "       2, 1, 3, 2, 1, 4, 4, 4, 3, 2, 5, 4, 0, 1, 4, 5, 2, 2, 4, 5, 5, 1,\n",
              "       4, 1, 5, 5, 1, 3, 5, 3, 0, 3, 4, 0, 2, 0, 1, 2, 2, 2, 2, 2, 4, 1,\n",
              "       1, 4, 1, 1, 2, 4, 0, 1, 5, 1, 5, 5, 4, 4, 1, 0, 5, 3, 2, 4, 3, 4,\n",
              "       1, 3, 1, 5, 5, 5, 3, 5, 4, 5, 4, 0, 4, 0, 2, 1, 4, 0, 4, 3, 2, 1,\n",
              "       0, 4, 5, 0, 4, 2, 4, 3, 5])"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "abc = preds1.astype(int).flatten()"
      ],
      "metadata": {
        "id": "H4WEmM60NfQn"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "c = confusion_matrix(new_Ytest, abc) \n",
        "c"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bKEBeEBlFjB8",
        "outputId": "78842645-e24e-4590-ed38-0b159f613feb"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[15,  5,  2,  3,  3,  1],\n",
              "       [ 2, 25,  3,  2,  0,  0],\n",
              "       [ 0,  2, 26,  2,  8,  3],\n",
              "       [ 0,  4,  1, 18,  3,  6],\n",
              "       [ 0,  1,  2,  0, 28,  1],\n",
              "       [ 2,  0,  3,  6,  6, 24]])"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m4RjG7LWLSQx",
        "outputId": "6b0a229e-f6d3-47d5-c0ed-f9640a85f49a"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5, 1, 2, 5, 4, 3, 2, 0, 3, 0, 3, 2, 0, 3, 3, 0, 5, 0, 2, 4, 0, 0,\n",
              "       1, 3, 2, 3, 2, 5, 3, 1, 2, 4, 2, 2, 5, 5, 3, 5, 3, 3, 4, 1, 2, 2,\n",
              "       3, 1, 5, 3, 1, 0, 4, 5, 5, 5, 5, 1, 2, 3, 2, 5, 0, 2, 4, 2, 5, 4,\n",
              "       2, 0, 2, 3, 5, 2, 0, 3, 4, 4, 4, 0, 5, 5, 3, 4, 5, 3, 2, 4, 1, 5,\n",
              "       0, 5, 0, 5, 4, 0, 1, 4, 0, 2, 2, 0, 2, 4, 5, 3, 4, 5, 3, 1, 2, 2,\n",
              "       2, 1, 3, 2, 1, 2, 4, 4, 2, 1, 2, 4, 5, 1, 4, 2, 0, 4, 5, 5, 3, 1,\n",
              "       2, 1, 5, 5, 1, 2, 3, 3, 0, 3, 3, 0, 1, 0, 1, 2, 2, 5, 2, 2, 2, 1,\n",
              "       1, 0, 1, 1, 1, 4, 0, 1, 5, 1, 5, 5, 5, 4, 1, 0, 3, 5, 2, 4, 1, 4,\n",
              "       1, 3, 2, 0, 5, 5, 3, 5, 4, 5, 4, 0, 4, 1, 2, 1, 4, 0, 4, 3, 2, 1,\n",
              "       0, 3, 5, 0, 4, 5, 4, 5, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('/content/drive/My Drive/graduation project/audio/paper_code/mariam/original_700 epoch_with_valid_Adam2')\n",
        "print(\"MODEL SAVED\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lsJBNeMWDl6Z",
        "outputId": "aa5c7f2b-3ae3-48bb-b92e-a615ecfa791f"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/graduation project/audio/paper_code/mariam/original_700 epoch_with_valid_Adam2/assets\n",
            "MODEL SAVED\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_model=keras.models.load_model('/content/drive/My Drive/graduation project/audio/paper_code/mariam/original_700 epoch_with_valid_Adam2')\n",
        "new_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q3KjaO9GDoNl",
        "outputId": "14e7edd0-60d3-465e-8e61-f108dabd28ab"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d (Conv1D)             (None, 40, 128)           1152      \n",
            "                                                                 \n",
            " activation (Activation)     (None, 40, 128)           0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 40, 128)           0         \n",
            "                                                                 \n",
            " max_pooling1d (MaxPooling1D  (None, 8, 128)           0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv1d_1 (Conv1D)           (None, 8, 256)            262400    \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 8, 256)            0         \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 8, 256)            0         \n",
            "                                                                 \n",
            " max_pooling1d_1 (MaxPooling  (None, 1, 256)           0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 256)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 256)               65792     \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 256)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 256)               65792     \n",
            "                                                                 \n",
            " activation_3 (Activation)   (None, 256)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 6)                 1542      \n",
            "                                                                 \n",
            " activation_4 (Activation)   (None, 6)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 396,678\n",
            "Trainable params: 396,678\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = new_model.predict(x_testcnn)"
      ],
      "metadata": {
        "id": "WOKeSzc7T-MZ"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3RjQxa2RUBKQ",
        "outputId": "1ecd3384-4422-465a-eb6c-af4655dd3be2"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[2.5228269e-03, 6.4984993e-03, 8.9828774e-02, 3.5088599e-02,\n",
              "        6.2064642e-01, 2.4541488e-01],\n",
              "       [1.5428974e-02, 9.5694941e-01, 3.2211498e-03, 1.2654116e-02,\n",
              "        1.0278971e-02, 1.4673951e-03],\n",
              "       [1.4455679e-04, 1.9713868e-03, 8.8393193e-01, 1.2939210e-03,\n",
              "        8.6332612e-02, 2.6325485e-02],\n",
              "       ...,\n",
              "       [6.8583054e-04, 2.2354607e-04, 5.4497183e-03, 5.9432480e-03,\n",
              "        8.0725175e-01, 1.8044592e-01],\n",
              "       [3.2034941e-02, 1.4035478e-02, 9.0121776e-03, 7.0192873e-01,\n",
              "        8.0252998e-03, 2.3496330e-01],\n",
              "       [9.0879906e-04, 2.2140313e-04, 1.4437077e-03, 4.8813066e-01,\n",
              "        6.4508065e-05, 5.0923085e-01]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss, acc =new_model.evaluate(x_testcnn, y_test)\n",
        "print(\"Restored model, accuracy: {:5.2f}%\".format(100*acc))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n3kzoqPkDqqS",
        "outputId": "65e8d59a-24d0-4159-b4e8-1bbfc77b9162"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7/7 [==============================] - 0s 7ms/step - loss: 0.8145 - accuracy: 0.6570\n",
            "Restored model, accuracy: 65.70%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss, acc =new_model.evaluate(X_train, y_train)\n",
        "print(\"Restored model train, accuracy: {:5.2f}%\".format(100*acc))"
      ],
      "metadata": {
        "id": "fJDTGH_OUX0z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03a287be-58b7-472f-c26a-4b86f2a6f5ea"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "52/52 [==============================] - 1s 8ms/step - loss: 0.5233 - accuracy: 0.8489\n",
            "Restored model train, accuracy: 84.89%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix,accuracy_score\n",
        "import seaborn as sn\n",
        "\n",
        "print(classification_report(new_Ytest,abc))\n",
        "\n",
        "acc = float(accuracy_score(new_Ytest,abc))*100\n",
        "print(\"----accuracy score %s ----\" % acc)\n",
        "\n",
        "cm = confusion_matrix(new_Ytest,abc)\n",
        "#df_cm = pd.DataFrame(cm)\n",
        "class_names = ['neutral','calm', 'happy','sad','angry', 'fearful' ]\n",
        "df_cm = pd.DataFrame(cm, index=class_names, columns=class_names,)\n",
        "sn.heatmap(df_cm, annot=True, fmt='')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 512
        },
        "id": "SfSC3El94LZg",
        "outputId": "659dd531-54f2-452b-f99f-d2e10f02bffc"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.45      0.60        29\n",
            "           1       0.65      0.69      0.67        32\n",
            "           2       0.77      0.73      0.75        41\n",
            "           3       0.44      0.62      0.52        32\n",
            "           4       0.60      0.78      0.68        32\n",
            "           5       0.67      0.54      0.59        41\n",
            "\n",
            "    accuracy                           0.64       207\n",
            "   macro avg       0.68      0.64      0.64       207\n",
            "weighted avg       0.68      0.64      0.64       207\n",
            "\n",
            "----accuracy score 63.76811594202898 ----\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVoAAAD8CAYAAAA2Y2wxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deZgU5dX38e/pWdhBFmU3oOASFzZBFPABF0CiokaJJIrGPMEkLuirJsYH425cohEVEVBkUVDUKApIQNSoiAgoso2yL7OwjIDsMNN93j+qZtLCzHT10N3VNZ4PV13TXd1d/aOm50zNXXfdt6gqxhhjkifkdwBjjKnqrNAaY0ySWaE1xpgks0JrjDFJZoXWGGOSzAqtMcYkmRVaY4wpg4hUF5EvReQbEVkmIve761uLyDwRWSUir4tIdqxtWaE1xpiyHQDOVdV2QHugr4h0BR4D/qmqbYDtwO9ibcgKrTHGlEEdu927We6iwLnAm+76ccClsbaVmZSEUd5p8utAXXr2kGz0O0LcFn2/xu8Icft9s25+R4jL7D3B28eb9m7zO0Lcdu5ZI0e6jaLCNZ5rTvbRx98ADI5aNUpVR5XcEZEMYCHQBhgOrAZ2qGqx+5RcoHms90l6oTXGmHTlFtVRFTweBtqLyFHA28BJlXkfK7TGmKolEk74JlV1h4h8BJwFHCUime5RbQsgL9brrY3WGFO1hIu9LxUQkaPdI1lEpAZwAZADfARc4T7tWmBKrEgVHtGKyC6cxt/DHsJpK64b6w2MMSaVVCOJ2lRTYJzbThsCJqvqVBFZDrwmIg8BXwMvxdpQhYVWVeskIq0xxqRMJDGFVlUXAx3KWL8G6BLPtuJqoxWRY4DqUW+4IZ7XG2NM0iXuiDZhPBVaEbkEeBJoBmwBfobTVnFK8qIZY0wlJOFk2JHyejLsQaArsEJVWwPnAV8kLZUxxlSWRrwvKeK16aBIVb8XkZCIhFT1IxF5OqnJjDGmEjRGbwI/eC20O0SkNvAJ8KqIbAH2JC+WMcZUUoJOhiWS16aD/sBe4DZgBs5laBcnK5QxxlRaEJsO3D5kU1W1FxDBGUTBGGPSUxqeDItZaFU1LCIREamnqj+kIpQxxlRaULt3AbuBJSIyi6i2WVW9JSmpDtHhn4NpckEHDhTu5MOefwHg5D9fSZO+nSAS4UDhTr4a8gL7N+9IRZxKCYVCTJgxmi2bCrlt0F/8jhNTn949eeqpB8gIhRjz8iQef2K435FiOvd3v6Dbr84FVfK+28j4O5+n+ECR37HKlV0tm4nvjiY7O4uMzAz+/d5snnm83PFN0sLwEY/R98JebN36PV07X+h3nLKl4ckwr220/wLuwTkZttBdFiQr1KE2vP4Jnw987EfrVj4/lY/OvYuPzr+bTbO+5sT/d3mq4lTKwN9fydqV6/2O4UkoFOKZYQ9z0cVXc1q7XvzqV5dy8slt/Y5VoXqN69Prugt59OK7eLDPHYRCIc64+Gy/Y1Xo4IGDDLr8D1zS69f07/Vrepx7Nu06nep3rAq9+sqbXH7pb/2OUbFIxPuSIl4L7VGqOi56AeonM1i077/4lqIdu3+0rnj3vtLbGTWrpSpKpRzT9Gi6nXcW70yc6ncUT7p07sDq1etYu3YDRUVFTJ48hUsu7uN3rJhCGSGyqmcTygiRXSObHzZv9ztSTHv3OJ/jzKxMMrMyUU3v4Zs/nzOf7dvS9y9HANWw5yVVvBbaa8tYd10Cc1TKyXcNoPfCZ2n5y27kPP6G33HKdfsDt/DMQ8+jadjtpCzNmjdhY25+6f3cvAKaNWviY6LYfti8nQ9Gv8fDn4/g0S9HsW/XXnI+Xex3rJhCoRBTPnqVuTmzmPPxPBZ/tczvSMGXhr0OKiy0IjJQRN4DWovIu1HLR0C5w7eLyGARWSAiC2buXZXozKVyHp3MzE43s/GtORx3fe+kvc+R6H7+2Wwr3M63i1f4HaVKq1m3Fu0u6Mw9PW7krjNvILtmdbpc2sPvWDFFIhH69/oN55zej9M7nkLbk473O1LwBbDp4HOcMQ6+db+WLLcD5f4tqaqjVPUMVT2jd802icpartx/zaHZL+IaTCdl2nU5jXN6d+PdLyfz8Av30bl7Rx547h6/Y1UoP28TLVs0K73fonlT8vM3+ZgotpO6n0bhxi3s3raLSHGYRTPmcVynE/yO5dmunbuZ99kCepx7lt9Rgi8Nj2hjDZO4HliPM6p4WqnVugl71jo//E37dmLXqvwYr/DH8EdGMvyRkQB0Oqs9V/9xIH+76UGfU1Vs/oJFtGnTmlatWpKXt4kBA/pzzaAb/Y5VoW35hbTu0Jas6tkU7T/ISd1OY/3i1X7HqlD9hkdRXFTMrp27qVa9Gt16nsmoZ6yb+hELp19PE6+jd0UPAJ6NMxvknlQN/H3GiJtodPbJZDeoQ5+vnuXbJ96i8Xntqd2mKRpR9uUWsujPMcfeNR6Fw2GG3DqU6dMmkhEKMXbc6yxfnt5NH+sWreLr97/g7mmPESkOs3HZOj6b9IHfsSp0TONGPPbc/YRCIUKhEO9PmcXHsz7zO1aFxowdRvceZ9KwYX1yVszhkYeGMWH8ZL9j/VganguReM9yiojgXJLbVVXvivV8mwU3+WwW3OSzWXBTIxGz4O6fO8lzzal+1sAjfj8v4p4zzJ3r/B0qaKM1xhjfpOHJMK9NB9FXA4SAM4D9SUlkjDFHIg2bDrxeghs9UlcxsA6n+cAYY9KKBvVkmKqm+TV3xhjjSsNBZTy10YrICSIyW0SWuvdPF5GhyY1mjDGVkIZttF5Pho0G/goUQek0vFclK5QxxlRa0C5YiFJTVb90enaVSr+xyIwxJsAnwwpF5HjcixZE5AqgIGmpjDGmstKwjdZrob0RGAWcJCJ5wFrgN0lLZYwxlVWcfn9sey20ecDLwEdAA2AnztCJDyQplzHGVE4aHtF6PRk2BacvbRGQjzO1jU03boxJPwnqdSAiLUXkIxFZLiLLRGSIu/4+EckTkUXu0i9WJK9HtC1Uta/H5xpjjH8Sd0RbDNyuql+JSB1goTtvIsA/VfUfXjfktdB+LiKnqeqSeJMaY0xKJajXgaoW4J70V9VdIpIDNK/MtrwW2u7AdSKyFjgAiPPeenqsFw7a9UVlcvmm4M4z/Y4QtxOGBW+Uph80/S6TrMiaH6yTTWAkoY1WRFoBHYB5QDfgJhEZhDNJ7e2qWuEEdV4LbZrOK2yMMYeIo9eBiAwGBketGqWqow55Tm3gLeBWVd0pIiOAB3G6uz6IM+vM9RW9j9exDoIxT7YxxsQxxrZbVEeV97iIZOEU2VdV9V/uazZHPT4aiDm9tdcjWmOMCYYEtdG6kxy8BOSo6lNR65u67bcAlwFLY23LCq0xpmpJ3CW43YBrgCUisshddzcwUETa4zQdrANuiLUhK7TGmKolQSfDVPUznBP/h5oe77as0BpjqpZw2O8Eh7FCa4ypWgI8epcxxgSDFVpjjEmyNBxUxnOhFZHTgVbRrynpV2aMMelCI9770aaK1+nGxwCnA8uAkl8XClihNcaklwA3HXRV1Z8nNYkxxiRCGvY68Doe7VwRsUJrjEl/aTgLrtcj2vE4xXYTcY7eZYwxKRXgpoOXcC9F479ttL4YPuIx+l7Yi61bv6dr5/QdVEzqNqDaZX9CatcDhaKFsymeN4OsC35N5okdIRwmsm0zB6a8APv3+h33R5o1b8KwEX+n0dENUVVeHfcGL418xe9YFWp6XDNufu6O0vvHHNuYN5+axIwxMcf78FWf3j156qkHyAiFGPPyJB5/YrjfkSoUiLxxDCqTKl4L7VZVfTepSTx69ZU3GTVyPCNHex7c3B+RCAdnvkKkYB1kV6fGDY8QXrOEyJol7Jv9GkQiZJ0/kKzu/Sn6YJLfaX+kuLiY+4c+ztLFOdSqXZMZH73BJx/PZeV3q/2OVq6CNfnc3e//ASChEMPnvciCf8/zOVXFQqEQzwx7mL79BpKbW8AXc6fz3tSZ5OSs9DtamQKTNw2PaL220X4tIhNFZKCIXF6yJDVZOT6fM5/t23b48dZx0d07nCILcHA/ka15SJ0GhFcvKf0gRHJXEqrbwLeM5dmyuZCli3MA2LN7LytXrKFJ02N8TuXdqd1OY/OGTRTmbfU7SoW6dO7A6tXrWLt2A0VFRUyePIVLLu7jd6xyBSZvRL0vKeL1iLYGTtts76h11r3LIzmqEaGmrYjkrfrR+swOPSlelt4zULRo2YxTTz+Zrxcu9juKZ2dd0oO5737qd4yYmjVvwsbc/NL7uXkFdOncwcdEFQtM3jTsdeB14O/fxrPR6FHLq2U3JDuzbiWiVRHZ1ag24DYOzhgPB/aVrs7qcSlEIoQXf+ZjuIrVrFWT0eOf5t6/PsruXcGY9DgjK5NO53fmtccm+B3F+ETTsOmgwkIrIs/iHLmWSVVvKWd96ajldWsdl34t06kSyqDagNsoXjKHcM780tWZ7c8h44QO7B//sI/hKpaZmcnocU/z9hvTeH/qB37H8ax9z46sXbqGnYU/+B0lpvy8TbRs0az0fovmTcnP3+RjoooFJm8ArwxbkJIUVVR2/8FoYT7Fc/87fGVGm3ZkdbuYfS8/AEUHfUxXsSeffYBVK9Yw6vlxfkeJy9mXdA9EswHA/AWLaNOmNa1atSQvbxMDBvTnmkE3+h2rXIHJG7SxDlQ17X7KxowdRvceZ9KwYX1yVszhkYeGMWH8ZL9jHSZ07IlktTuHyOYNVP/D3wEomv062RdeCxlZVB90NwCR3FUcnPqSn1EP07lrR664qj/Ll33HzE/eAuDRB5/mw1npXcCq1ajGqT3a8+LdL/gdxZNwOMyQW4cyfdpEMkIhxo57neXLV/gdq1yByZuGR7SiHvqcicjRwF+AnwPVS9ar6rmxXhu0poNgTjcenBNVJf6n7gl+R4jL5IIv/Y7wk1B8MK+sGQ3isudvV3muObUeeO2I388Lr927XgVygNbA/Tjz5Myv6AXGGOMLjXhfUsRroW2oqi8BRar6H1W9Hoh5NGuMMSkX4H60Re7XAhH5BZAPpF9Pe2PMT17gundFeUhE6gG3A88CdYFbk5bKGGMqKw1PhnltOrgS58TZUlXtBVwAXJa8WMYYU0kBbjo4XVVLBxhQ1W0ikobX3hljfvKCegkuEBKR+qq6HUBEGsTxWmOMSZnAzhkGPIkz8Pcb7v0rgfS9ftQY89MV1EKrquNFZAH/7dJ1uaouT14sY4yppAD3OsAtrFZcjTHpLQ2PaL32OjDGmGBIUK8DEWkpIh+JyHIRWSYiQ9z1DURkloisdL/WjxXJCq0xpkrRcMTzEkMxcLuq/hzoCtzozgZ+FzBbVdsCs937FUp6z4G9RQeS/RYJ1fSJ9J5nqizfrw/OeLElWrW92O8IcbmwSfB6M361a63fEfyRoKYDVS0ACtzbu0QkB2gO9Ad6uk8bB3yMM+hWuayLljGmSomne1f0bDCuUe7EBYc+rxXQAZgHNHaLMMAmoHGs97FCa4ypWuIotNGzwZRHRGoDbwG3qupOkf+OrKiqKiIx39DaaI0xVUskjiUGEcnCKbKvqmrJZLSbRaSp+3hTYEus7VihNcZUKVoc8bxURJxD15eAHFV9Kuqhd4Fr3dvXAlNiZbKmA2NM1ZK46xW6AdcAS0RkkbvubuBRYLKI/A5YDwyItSFPhVZEbgZeKRnrwBhj0lWixjpQ1c+A8qa6OS+ebXltOmgMzBeRySLSV6Jbg40xJp0ksI02UTwVWlUdCrTFaa+4DlgpIo+IyPFJzGaMMXHTiHpeUsXzyTB1psvd5C7FQH3gTRF5PEnZjDEmfml4ROu1jXYIMAgoBF4E7lTVIhEJASuBPycvojHGeKfFfic4nNdeBw1whkZcH71SVSMiclHiYxljTOWkcBZxz7yOR3uviHQUkf6AAnNU9Sv3sZxkBjTGmLikYaH11EYrIvfgDJ7QEGgEvCwiQ5MZzBhjKkMj3pdU8dp0cDXQTlX3A4jIo8Ai4KFkBTPGmMpIx6YDr70O8oHqUferAXmJj+NNn949Wbb0E75d/hl/vvNGv2J4NnzEY6xe9yVfzH/f7yjlOnDgIFf97xAuv/ZP9P/NDTz34gQAcvM3MfD3t3LhgOu5/Z6/U1RU5HPSsjVr3oQ33n2Zj+a+y4efT+F3N1ztdyRPatWtxV0v/JURH47g+dkjOLHjSX5HKldQ9rGGxfOSKuL02orxJJF3gM7ALJw22guAL4FcAFW9pbzXZmY3T2hntVAoRM6yT+nbbyC5uQV8MXc6V1/zJ3JyViZk+zWzqiVkO9HO7taZPXv2MnL0P+ja+cKEbz8R49GqKvv27admzRoUFRcz6I93cNeQGxj/+tuc9z9n0+/8ntz/+LOc2LY1V1125Oc/Ez0e7TGNG3FM46NZujiHWrVrMuOjN7j+6ltY+d3qhGy/Y53WCdnOoW596jaWf7mMma/NJDMrk2o1qrFn556EbDvR49Emex8D5G1fdsTVb9M5PT3XnCaffJySauv1iPZtnGt8P8IZ5Pb/cAZSWOguKdOlcwdWr17H2rUbKCoqYvLkKVxycZ9URojb53Pms33bDr9jVEhEqFmzBgDFxcUUFxcjIsxb+A29e/YAoH+/8/nwk7l+xizXls2FLF3snJfds3svK1esoUnTY3xOVbGadWpyapdTmPnaTACKi4oTVmSTISj7WCPieUkVr70OxolINnASzhHtd6p6MKnJytGseRM25uaX3s/NK6BL5+CNfp+OwuEwA66/hQ15+Qy8/CJaNm9Kndq1yMzMAKDx0Y3YsvV7n1PG1qJlM049/WS+XrjY7ygVatyyMT9s28mtT95Kq5Nbs3rJKkbdN4oD+9J/VpJ03seBbaMVkX7AauAZ4DlglYiU+zewiAwWkQUisiASSd/f0ObHMjIyeGvccGa/PYEly1ewdv1GvyPFrWatmowe/zT3/vVRdu9K789eRmYGx596PNMnTOfWfkPYv+8AV/zpSr9jxZTu+1hVPC+p4rXp4Cmgl6r2VNX/AXoB/yzvyao6SlXPUNUzQqFaichZKj9vEy1bNCu936J5U/LzNyX0PX7q6tapTZeOp7No6bfs2r2H4uIwAJu3FnLM0Q19Tle+zMxMRo97mrffmMb7U9N/HrXCgkIKCwpZsWgFAHOmz+H4U9N7+JAg7ON07N7ltdDuUtVVUffXALuSkCem+QsW0aZNa1q1aklWVhYDBvTnvakz/YhSpWzbvoOdu3YDsP/AAebO/5rjWrWkS8fTmfnxpwBMmf4B5/Y4y8+YFXry2QdYtWINo54f53cUT3Zs3UFhQSHNj2sOQLtu7di4coPPqSoWhH0cCYvnJVW89qNdICLTgck4bbRX4gybeDlA1BQPSRcOhxly61CmT5tIRijE2HGvs3z5ilS9faWMGTuM7j3OpGHD+uSsmMMjDw1jwvjJfsf6ka3fb+f/HvoH4UgEjSh9zu1Bz25ncnyrY7nz3kd5dtR4Tj7heC6/qLffUcvUuWtHrriqP8uXfcfMT94C4NEHn+bDWZ/6nKxiI//2Arc/cweZWZls3rCJp+942u9I5QrKPk7lSS6vvHbvermCh1VVry/vwUR370q2ZHTvSjabbjz5ktW9K5mCON14Irp3rWt/geea02rRrJRUZa+9Dn6b7CDGGJMIHo4dU87rMInVgd8BpxB1hVhFR7LGGOOHdGw68HoybALQBOgD/AdogU8nw4wxpiLp2L3L68mwNqp6pYj0dy9emAikVwu4McYA4RT2JvDKa6EtGUlkh4icijOdTfpde2eM+clL5ZGqV14L7SgRqQ8MBd4FagP3JC2VMcZUUjq20XottBOAXwKtcAYAB2cKcmOMSSuB7XWAM1LXDzgjdaX/iBfGmJ+sIB/RtlDVvklNYowxCRCOeO1MlTpeE30uIqclNYkxxiSAqvclVSo8ohWRJThjG2QCvxWRNThNB4Jz6e3pyY9ojDHeRRLY60BExgAXAVtU9VR33X3A74Gt7tPuVtXpFW0nVtPBkc9ZYowxKZTg7l1jccbgHn/I+n+q6j+8bqTCQquq6+PPZYwx/klkk4CqfiIirY50O15Phv1kdKx/nN8R4tbwZ+f7HSFuGwcEaz+3nLzc7whxC+JnORHiaToQkcHA4KhVo1R1lIeX3iQig4AFwO2qur2iJ6ff6TljjDkC4UjI8xI9G4y7eCmyI4DjgfZAAfBkrBdYoTXGVCkax1Kp7atuVtWwqkaA0UCXWK+xpgNjTJWSyF4HZRGRpqpa4N69DFga6zVWaI0xVUoiex2IyCSgJ9BIRHKBe4GeItIe56B4HXBDrO1YoTXGVCmJnNxWVQeWsfqleLdjhdYYU6UowR3rwBhjAqE4wOPRGmNMINgRrTHGJFki22gTxQqtMaZKsSNaY4xJMjuiNcaYJAsH7Yg2ajzaMtl4tMaYdJOGM9l4Ho/2RvfrBPfrb5ITx5s+vXvy1FMPkBEKMeblSTz+xHA/43jy2txX2LtnH5FwmHBxmBt+cWPsF/lo+IjH6HthL7Zu/Z6unS/0O06ZpMHR1PzfvyB16wPKwf9M4+Cst5Fadajxx6GEGjUmUriZvc8/CHt3+x33MEHYx4cKwuc4ErQj2pLxaEXkAlXtEPXQXSLyFXBXMsOVJRQK8cywh+nbbyC5uQV8MXc6702dSU7OylRHidttV97OD9t3+h3Dk1dfeZNRI8czcrTnsY1TLxxm3+svEFm/CqrXoPa9IyhetpDsbn0IL/+avdNfo1q/q6j+i6vY/8aLfqc9TCD2cRnS/XOchpPgeh69S0SkW9Sds+N4bUJ16dyB1avXsXbtBoqKipg8eQqXXNzHjyhV2udz5rN92w6/Y1RIf9jmFFmA/fuIFGwgdFQjMjuczcE5MwE4OGcmmR26VbAV/wRhHwdRJI4lVbyeDPsdMEZE6uHMF7YduD5pqSrQrHkTNubml97PzSugS+cOFbwiPagqT0x8DFXlvVenMfXVaX5HqlKkYWMyjm1D8ZpvCdWrj/6wDXCKcahefZ/TVR1B+BxHJGBNByVUdSHQzi20qOoPFT0/etRyyahHKFTrSHMG3s2X30rhpu85quFR/GPSY2xYtYHF85b4HatqqFadWjfdy75Jz8P+vYc/nsrpTqu4IHyOw34HKIPnP/9F5Bc4w4ENEZG/icjfyntu9KjliS6y+XmbaNmiWen9Fs2bkp+/KaHvkQyFm74HYMf3O/hsxhxObn+Sz4mqiIwMat50HwfnzqZ44WcARH7YjtRrAIDUa0Bkp/15nihB+BxHxPuSKp4KrYi8APwKuBmn6eBK4GdJzFWu+QsW0aZNa1q1aklWVhYDBvTnvakz/YjiWfUa1alRq0bp7TPO6cTa79b5G6qKqPHbO4jkr+fgzLdK1xUvmkt2t94AZHfrTfHXn/sVr0oJyuc4gnheUsVrG+3Zqnq6iCxW1ftF5Eng/WQGK084HGbIrUOZPm0iGaEQY8e9zvLlK/yI4ln9o+vz4Iv3AZCRkcHsdz7ky4/n+xsqhjFjh9G9x5k0bFifnBVzeOShYUwYP9nvWD+S0fZUsrtdQHjjGmrf/wIA+98aw4Fpr1HzT0PJOqcvWriFvSMe9Dlp2YKwj6MF5XOcjg1Foh7ar0TkS1XtIiJfAJcD24Clqtom1mszs5un4/+7XN2POdnvCHH7avsavyPELXiz4AZvHwdxFtyPcz844sPM8c2v9lxzBuW9kpLDWq9HtO+JyFHAE8BXOL80RictlTHGVFKQxzr4Fgir6lsi8nOgI/BO8mIZY0zlhNOvd5fnXgf3qOouEekOnAu8iDO3uTHGpJV0vGDBa6Et6Zr2C2C0qk4DspMTyRhjKi/IhTZPREbidPGaLiLV4nitMcakjIr3JVW8FssBwL+BPqq6A2gA3Jm0VMYYU0npeETr9RLcvcC/ou4XAAXJCmWMMZWVjpfg2gwLxpgqJYgDfxtjTKAEuR+tMcYEQjoWWus5YIypUjSOJRYRGSMiW0RkadS6BiIyS0RWul9jDnhshdYYU6UkeJjEsUDfQ9bdBcxW1bbAbDxM6WWF1hhTpYTjWGJR1U9wBtGK1h8Y594eB1waazvWRnuIII6EVSe7ht8R4ha00bA2j/Nl5qYj0u6PP83hSCJxDJQYPRuMa5SqjorxssZuF1eATUDjWO9jhdYYU6XEczLMLaqxCmtFr1cRiVnZrenAGFOlJPJkWDk2i0hTAPfrllgvsEJrjKlSUnAJ7rvAte7ta4EpsV5gTQfGmCqlOPZf8p6JyCSgJ9BIRHKBe4FHgcki8jtgPc5YMBWyQmuMqVISOXeWqg4s56Hz4tmOFVpjTJUS2CvDRORmL1c/GGOM3yKo5yVVvJ4MawzMF5HJItJXRNJwfBxjjElJr4O4eSq0qjoUaAu8BFwHrBSRR0Tk+CRmM8aYuKXjwN+eu3epquJcBbEJKAbqA2+KyONJymaMMXELo56XVPF0MkxEhgCDgEKcGXDvVNUiEQkBK4E/Jy+iMcZ4l44nw7z2OqgPXK6q66NXqmpERC5KfCxjjKkcTWnrqzcxmw5EJAO46tAiW0JVcxKeyhhjKikd22hjHtGqalhEvhORY1V1QypCxdKnd0+eeuoBMkIhxrw8icefGO53pAoNH/EYfS/sxdat39O184V+x4mpWfMmDBvxdxod3RBV5dVxb/DSyFf8jlWhIOzjTTv2MPTNOWzbvR8Eftm5Lb85+2RGzP6Gf81fSf1a1QG4uXcHepzY3Oe0h8uuls3Ed0eTnZ1FRmYG/35vNs88XunxWJImld22vIqn6WCZiHwJ7ClZqaqXJCVVBUKhEM8Me5i+/QaSm1vAF3On897UmeTkrEx1FM9efeVNRo0cz8jR//A7iifFxcXcP/Rxli7OoVbtmsz46A0++XguK79b7Xe0cgVhH2eEhNsv7MTJzRuy50ARA4dPo2ubpgBc3e1kru1xis8JK3bwwEEGXf4H9u7ZR2ZmBpOmvsR/Zn/ONwuXxn5xCqVfmfVeaO9Jaoo4dOncgdWr17F2rXNwPXnyFC65uE9aF9rP58zn2GPT7wilPFs2F7JlcyEAe3bvZeWKNTRpekxaF9og7OOj69bk6IeHdlIAABHNSURBVLo1AahVLYvjjq7Hlp17fU4Vn7179gGQmZVJZlYmTmek9FKchqXWU6FV1f8kO4hXzZo3YWNufun93LwCunTu4GOiqq1Fy2acevrJfL1wsd9RqpS87bv5tmAbp7VoxKL1W3nti++Y+vUaft68Ibf360TdGtX8jlimUCjE27MncGzrlrz60hss/mqZ35EOE8iTYQAisktEdh6ybBSRt0XkuDKeP1hEFojIgkhkT1mbNAFQs1ZNRo9/mnv/+ii7d9n3MVH2Hijijon/4c5fdKZ29WwGnHkCU2+/lNdvuohGdWrw5PSFfkcsVyQSoX+v33DO6f04veMptD0p/a5ZSseTYV4vWHgauBNoDrQA7gAmAq8BYw59sqqOUtUzVPWMUKhWorICkJ+3iZYtmpXeb9G8Kfn5mxL6HgYyMzMZPe5p3n5jGu9P/cDvOFVGUTjC7RP/Q792rTnvlGMBaFi7BhmhEKGQcHnntizNLfQ5ZWy7du5m3mcL6HHuWX5HOYzG8S9VvBbaS1R1pKruUtWd7vQPfVT1dZwTZSkzf8Ei2rRpTatWLcnKymLAgP68N3VmKiP8JDz57AOsWrGGUc+Pi/1k44mqcv+/5tL6mHpc0/3npeu3RrXTfrh8A20aH+VHvJjqNzyKOnVrA1CtejW69TyTNSvX+RuqDOl4ROv1ZNheERkAvOnevwLY795OaYNIOBxmyK1DmT5tIhmhEGPHvc7y5StSGSFuY8YOo3uPM2nYsD45K+bwyEPDmDB+st+xytW5a0euuKo/y5d9x8xP3gLg0Qef5sNZn/qcrHxB2MeL1m9l6qI1tG18FAOenQo4XblmLF7LdwXbEaBZ/doM7X+mv0HLcUzjRjz23P2EQiFCoRDvT5nFx7M+8zvWYcJpeIJOvJw1dNthhwFn4RTWL4DbgDygk6qWu7czs5un3/+6AjWz0vMkREWCOAvuroP7/I4QF5sFNzVWbF1wxCMD/vpnl3muORPXv52SkQi99jpYA1xczsPp9yvNGPOTlY69DrwOKnM08HugVfRrVDV4v+aNMVVakAeVmQJ8CnwAhJMXxxhjjkyQL8Gtqap/SWoSY4xJgHRsOvDavWuqiPRLahJjjEmAsKrnJVW8HtEOAe4WkQNAESA4ky7UTVoyY4yphMA2HahqHRFpgDNvWPXkRjLGmMoL7MkwEflfnKPaFsAioCvwOXBe8qIZY0z8gtxGOwToDKxX1V5AB+CHpKUyxphKiqCel1Tx2ka7X1X3iwgiUk1VvxWRE5OazBhjKiEdx8j1WmhzReQo4B1glohsB8qcQ8wYY/yUyGnERWQdsAvn+oFiVT2jMtvxejLsMvfmfSLyEVAPmFGZNzTGmGRKQpNAL1U9orErvR7Rlkqn2RaMMeZQQW46MGmsafUGfkeI2//UbeR3hLj87vb0nfWgPF/f2NbvCL5I8BGtAjNFRIGR7ljccbNCa4ypUuLp3iUig4HBUatGHVJMu6tqnogcg3N+6ltV/STeTFZojTFVSjyX1rpFtdyjVFXNc79uEZG3gS5A3IXWaz9aY4wJhET1oxWRWiJSp+Q20BtYWplMdkRrjKlSEthG2xh4W0TAqZUTVbVSva2s0BpjqpRE9TpwZ5Zpl4htlVtoRWQXZU+8aCN3GWPSVqBG71LVOqkMYowxiZCOg8rEbDoQkWPLWq+qGxIfxxhjjkxY02+gRC9ttNOiblcHWgPfAackJZExxhyBQF4ZpqqnRd8XkY7An5KWyBhjjkCg2mjLo6pficiZyQhjjDFHKqhttP8v6m4I6AjkJy2RMcYcgUgQmw6A6N4HxThttm8lJ44xxhyZQB3RisgEVb0G2KGqw1KYyRhjKi1ovQ46iUgz4HoRGY9zoUIpVd2W1GQV6NO7J0899QAZoRBjXp7E408M9yuKJ8NHPEbfC3uxdev3dO18od9xPAuFQkyYMZotmwq5bdBf/I5ToabHNePm5+4ovX/MsY1586lJzBgz1cdUFQtCZqnbgGqX/QmpXQ8UihbOpnjeDLIu+DWZJ3aEcJjIts0cmPIC7N/rd1wgeE0HLwCzgeOAhfy40Kq7PuVCoRDPDHuYvv0GkptbwBdzp/Pe1Jnk5Kz0I44nr77yJqNGjmfk6H/4HSUuA39/JWtXrqdWnVp+R4mpYE0+d/dzTidIKMTweS+y4N/zfE5VsUBkjkQ4OPMVIgXrILs6NW54hPCaJUTWLGHf7NcgEiHr/IFkde9P0QeT/E4LpGfTQbmjd6nqM6p6MjBGVY9T1dZRiy9FFqBL5w6sXr2OtWs3UFRUxOTJU7jk4j5+xfHk8znz2b5th98x4nJM06Ppdt5ZvDMxfY6uvDq122ls3rCJwrytfkfxLF0z6+4dTpEFOLifyNY8pE4DwquXQMT5Ez2Su5JQ3fQZfD6i6nlJlQqHSRSRDKBXirJ40qx5Ezbm/rfTQ25eAc2aNfExUdV0+wO38MxDz6OR9GvviuWsS3ow991P/Y4RlyBklqMaEWraikjeqh+tz+zQk+JV3/iU6nAax79UqbDQqmoY+K68y3DLIyKDRWSBiCyIRPYcUUCTet3PP5tthdv5dvEKv6PELSMrk07nd+aLaZ/7HcWzQGTOrka1AbdxcMZ4OLCvdHVWj0shEiG8+DMfw/1YWMOel1Tx0r2rPrBMRL4ESqumql5S3guiRy3PzG6e0F8b+XmbaNmiWen9Fs2bkp+/KZFv8ZPXrstpnNO7G93O60p2tWxq16nFA8/dw99uetDvaDG179mRtUvXsLPwB7+jeJb2mUMZVBtwG8VL5hDOmV+6OrP9OWSc0IH94x/2MdzhAnkJLnBP0lPEYf6CRbRp05pWrVqSl7eJAQP6c82gG/2OVaUMf2Qkwx8ZCUCns9pz9R8HBqLIApx9Sfe0/xP8UOmeObv/YLQwn+K500vXZbRpR1a3i9n38gNQdNDHdIcL5CW46Ta9eDgcZsitQ5k+bSIZoRBjx73O8uXp/SfumLHD6N7jTBo2rE/Oijk88tAwJoyf7HesKqdajWqc2qM9L979gt9RPEv3zKFjTySr3TlENm+g+h/+DkDR7NfJvvBayMii+qC7AYjkruLg1Jf8jFoqHY9oJVYoEekKPAucDGQDGcAerwN/J7rpINlqZlXzO0LcTqjb3O8IcTshO1jTjQfR6N9W9ztC3GrdN0liP6tiTY/6ueeaU7Bj+RG/nxdemg6eA64C3gDOAAYBJyQzlDHGVFag+tFGU9VVQIaqhlX1ZaBvcmMZY0zlhDXieUkVL0e0e0UkG1gkIo8DBdg05caYNJWObbReCuY17vNuwune1RL4ZTJDGWNMZaXjlWFeeh2sF5EaQFNVvT8FmYwxptICeUQrIhcDi4AZ7v32IvJusoMZY0xlRFDPS6p4aTq4D+gC7ABQ1UU4EzQaY0zaUVXPS6p4ORlWpKo/iPx4ONok5THGmCMStIG/SywTkV8DGSLSFrgFSOPRL4wxP2XpOPB3uU0HIjLBvbkaOAU4AEwCdgK3Jj+aMcbEL2hNByVT2fwKZ0zaJ6MeqwnsT2YwY4ypjEReGSYifYFhOEMPvKiqj1ZmO16nslkQ/d74OJWNMcZUJFFHqu7EB8OBC4BcYL6IvKuqy+PdVrmFVlWfAZ4RkRGq+sdKpzXGmBRKYBttF2CVqq4BEJHXgP5A4gptiSMtssUH85I2Oo6IDHYHGQ+EoOWF4GUOWl6wzIkWT80RkcHA4KhVo6L+X82BjVGP5QJnViZT0McsGBz7KWklaHkheJmDlhcss29UdZSqnhG1JOWXR9ALrTHGJEseztguJVq46+JmhdYYY8o2H2grIq3dEQyvAio1/ICXCxbSWVq2EVUgaHkheJmDlhcsc1pS1WIRuQn4N073rjGquqwy24o5lY0xxpgjY00HxhiTZFZojTEmyQJdaEWklTvgTWVeuzvReTy853Ui8pwP79tKRJam+n3Tie2Dw4nILSKSIyKvpmpbfvzcpYOgnwxrBfwamHjoAyKSqarFKU9kTAIl+XP8J+B8Vc2t7Aai8h3xtqoyX45o3aOLHBEZLSLLRGSmiNQQkeNFZIaILBSRT0XkJPf5Y0XkiqjXl/xWfBToISKLROQ294jxXRH5EJgtIrVFZLaIfCUiS0Skf5L+P4NEZLGIfCMiE0TkYhGZJyJfi8gHItK4jNeMFZERIvKFiKwRkZ4iMsbdL2OTEDOjjP39exGZ7+Z+S0RqRmV7QUQWiMgKEbnIXX+diEwRkY9FZKWI3Ouuf0BESkd0E5GHRWRIEv4PiEgtEZnmZl4qIr8Skb+5/4+lIjJK3MGTRaST+7xvgBuTkaeMfO+4n99l7lVHiMhud598436/G7vrj3fvLxGRh0o+1+5n4VNxZjJZnoz9KyIv4IxX8r6I/J/72fvS/cz2d5/Tys3xlbucXU6+6G3dJiL3icgdUe+1VERaHUnewItnSLFELThHosVAe/f+ZOBqnEFs2rrrzgQ+dG+PBa6Iev1u92tPYGrU+utwLpNr4N7PBOq6txsBq/hvT4vdCfq/nAKsABq59xsA9aPe53+BJ6PyPRf1f3oNZ5Ce/jjDT56G88tvYcm+SfL+bhj1nIeAm6OyzXCztHX3aXU3fwHQEKgBLAXOcLf/lfvaEM7Qmg0Tlf+Q/8svgdFR9+uVfL/d+xOAi93bi4Fz3NtPAEtT8Nku+eyV7J+GOIMwlWR6HBjq3p4KDHRv/+GQz/UeoHXU9y/h+xdY5/5cPAJc7a47yv0818IZpa+6u74tsKCsfNHbcm/fB9wR9dhSoFUif+6CtvjZdLBWnWlxwCksrYCzgTfkv7M5VKvEdmep6jb3tgCPiMg5QATn2uXGwKbKhi7DucAbqloIoKrbROQ04HURaQpkA2vLee17qqoisgTYrKpLAERkGc7+WFTO6yqjrP19qog8hPPDVRunv2CJyaoaAVaKyBrgJHf9LFX93s35L6C7qj4tIt+LSAec/ft1yXOSYAnwpIg8hvNL9lMR+aWI/BmnMDTAGaz+U+AoVf3Efd0E4MIkZYp2i4hc5t5uiVOgDuIUVXD2/QXu7bOAS93bE4F/RG3nS1VdC6Cq65K8f3sDl0QdhVYHjgXygedEpD0QBk4oK5+Jzc9CeyDqdhjnA7RDVduX8dxi3GYOEQnhFK/y7Im6/RvgaKCTqhaJyDqcD1GyPQs8parvikhPnN/wZSnZBxF+vD8iJP57c+j+roFz5Hqpqn4jItfhHKmUOLSDtcZY/yLOEW8TYMwRpy2Hqq4QkY5AP+AhEZmN0yxwhqpuFJH7SM33+DDu9/p84CxV3SsiH7tZitQ9nMPZ916+t3sOuZ/M/SvAL1X1ux+tdPblZqAdzs9f9BjUh+aLVvrz6vLl+5FO0qnXwU5grYhcCSCOdu5j64BO7u1LgCz39i6gTgXbrAdscYtsL+BnCU8NHwJXikhDABFp4L5vyTXR1ybhPROlDlAgIlk4v5SiXSkiIRE5Hqf9reSH8AIRaSDOFPSXAnPc9W8DfYHO/PjIOKHEGYx+r6q+gtMc0NF9qFBEagNXAKjqDmCHiHR3Hz/0/5cM9YDtbpE9Cega4/lf4DSFgHN5Z0WSuX//Ddwc1bbdwV1fDyhw/7K5BufqKC/W4X5f3F+KP/nJXNOt18FvgBEiMhSnmL4GfAOMBqa4JzVm8N/fpouBsLt+LLD9kO29Crzn/mm+APg20YFVdZmIPAz8R0TCwNc4R7BviMh2nEKcrh+0e4B5wFb3a/QvrQ3Al0Bd4A+qut/9OfwSeAtngI1XVHUBgKoeFJGPcP4qCScx82nAEyISAYqAP+IU/KU4TULzo577W2CMiCgwM4mZSswA/iAiOTi/mL6I8fxbgVdE5P/c1/5Q3hOTvH8fBJ4GFrt/Ma4FLgKeB94SkUH8+OculreAQW4T2DycNt+fNLsE1xxGnF4PU1X1zUPWX4fzJ/pNZbwmBHwFXKmqK1ORM+jE6eWxz22nvwrnxFiZPWNs/wZbOjUdmIASkZ/j9OiYbUUgLp2ARSKyGKcf6u1lPcn2b/DZEa0xxiSZHdEaY0ySWaE1xpgks0JrjDFJZoXWGGOSzAqtMcYk2f8HYhwSLNQWbuEAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "y5OoGgupF7kU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}