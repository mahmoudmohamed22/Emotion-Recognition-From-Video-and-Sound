{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "original_rms_0.00002_without decay_1000_pentience=35_1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9SRCO-a_AlH5",
        "outputId": "f7b62229-79e3-4c63-bcf1-ec3b2e05186a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install librosa"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Lo4mUwG9RMd",
        "outputId": "5a146c53-311c-4f12-a744-d42c7728558a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.7/dist-packages (0.8.1)\n",
            "Requirement already satisfied: decorator>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.21.6)\n",
            "Requirement already satisfied: numba>=0.43.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (0.51.2)\n",
            "Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.6.0)\n",
            "Requirement already satisfied: audioread>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (2.1.9)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.4.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (21.3)\n",
            "Requirement already satisfied: resampy>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from librosa) (0.2.2)\n",
            "Requirement already satisfied: soundfile>=0.10.2 in /usr/local/lib/python3.7/dist-packages (from librosa) (0.10.3.post1)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.1.0)\n",
            "Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.0.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba>=0.43.0->librosa) (57.4.0)\n",
            "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba>=0.43.0->librosa) (0.34.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->librosa) (3.0.9)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from pooch>=1.0->librosa) (2.23.0)\n",
            "Requirement already satisfied: appdirs>=1.3.0 in /usr/local/lib/python3.7/dist-packages (from pooch>=1.0->librosa) (1.4.4)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2022.5.18.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (1.24.3)\n",
            "Requirement already satisfied: six>=1.3 in /usr/local/lib/python3.7/dist-packages (from resampy>=0.2.2->librosa) (1.15.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn!=0.19.0,>=0.14.0->librosa) (3.1.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.7/dist-packages (from soundfile>=0.10.2->librosa) (1.15.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.0->soundfile>=0.10.2->librosa) (2.21)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HJjcbxwy46bG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "e977fd9d-d4f6-475c-df62-ed0e8bd2090c"
      },
      "source": [
        "# Orignial Notebook: https://github.com/MITESHPUTHRANNEU/Speech-Emotion-Analyzer/blob/master/final_results_gender_test.ipynb\n",
        "# This notebook author: Reza Chu\n",
        "# Last Editing Date: 31st May 2019\n",
        "\n",
        "## Python\n",
        "import os\n",
        "import random\n",
        "import sys\n",
        "\n",
        "import IPython\n",
        "from IPython.display import Audio\n",
        "from IPython.display import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "## Package\n",
        "import glob \n",
        "import keras\n",
        "import IPython.display as ipd\n",
        "import librosa\n",
        "import librosa.display\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import plotly.graph_objs as go\n",
        "import plotly.offline as py\n",
        "import plotly.tools as tls\n",
        "import seaborn as sns\n",
        "import scipy.io.wavfile\n",
        "import tensorflow as tf\n",
        "py.init_notebook_mode(connected=True)\n",
        "\n",
        "## Keras\n",
        "from keras import regularizers\n",
        "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping\n",
        "from keras.callbacks import  History, ReduceLROnPlateau, CSVLogger\n",
        "from keras.models import Model, Sequential\n",
        "from keras.layers import Dense, Embedding, LSTM\n",
        "from keras.layers import Input, Flatten, Dropout, Activation, BatchNormalization\n",
        "from keras.layers import Conv1D, MaxPooling1D, AveragePooling1D\n",
        "from keras.preprocessing import sequence\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.utils import np_utils\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "## Sklearn\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "## Rest\n",
        "from scipy.fftpack import fft\n",
        "from scipy import signal\n",
        "from scipy.io import wavfile\n",
        "from tqdm import tqdm\n",
        "\n",
        "input_duration=3\n",
        "# % pylab inline"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "        <script type=\"text/javascript\">\n",
              "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
              "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
              "        if (typeof require !== 'undefined') {\n",
              "        require.undef(\"plotly\");\n",
              "        requirejs.config({\n",
              "            paths: {\n",
              "                'plotly': ['https://cdn.plot.ly/plotly-2.8.3.min']\n",
              "            }\n",
              "        });\n",
              "        require(['plotly'], function(Plotly) {\n",
              "            window._Plotly = Plotly;\n",
              "        });\n",
              "        }\n",
              "        </script>\n",
              "        "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Saving joblib files to not load them again with the loop above\n",
        "\n",
        "# import joblib\n",
        "\n",
        "# X_name = 'x.joblib'\n",
        "# y_name = 'y.joblib'\n",
        "# save_dir = '/content/drive/My Drive/graduation project/audio/paper_code/features'\n",
        "\n",
        "# savedX = joblib.dump(X, os.path.join(save_dir, X_name))\n",
        "# savedy = joblib.dump(y, os.path.join(save_dir, y_name))"
      ],
      "metadata": {
        "id": "UCzic8rlDcuk"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Loading saved models\n",
        "import joblib\n",
        "X = joblib.load('/content/drive/My Drive/graduation project/audio/paper_code/features/x.joblib')\n",
        "y = joblib.load('/content/drive/My Drive/graduation project/audio/paper_code/features/y.joblib')"
      ],
      "metadata": {
        "id": "Q35CN6zDrzg1"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7PSTurzjCo5K",
        "outputId": "3d8e1f1a-ab1e-4c69-833a-bafc84c4036a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2068, 40)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.1 ,shuffle = True\n",
        "                                                    , random_state=42)\n",
        "X_train , X_valid, y_train, y_valid = train_test_split(X_train,y_train, test_size=0.1112305212 , shuffle = True \n",
        "                                                       , random_state=42)"
      ],
      "metadata": {
        "id": "Ai4Fy5cPCiq1"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "x_traincnn = np.expand_dims(X_train, axis=2)\n",
        "x_testcnn = np.expand_dims(X_test, axis=2)\n",
        "X_valid= np.expand_dims(X_valid, axis=2)"
      ],
      "metadata": {
        "id": "tp1Fm5K3CEXu"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_traincnn.shape, x_testcnn.shape , X_valid.shape\n",
        "#1861"
      ],
      "metadata": {
        "id": "RI0MxoIPBws5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8153b576-ba77-40ae-b4e7-660b5019a8a2"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1654, 40, 1), (207, 40, 1), (207, 40, 1))"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oALhiMUd9G2Y",
        "outputId": "5432ac19-1aba-4ebf-b4fb-fe28ec10c4ee"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (2.8.2+zzzcolab20220527125636)\n",
            "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.46.3)\n",
            "Requirement already satisfied: tensorflow-estimator<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.17.3)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (4.2.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow) (57.4.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.26.0)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.21.6)\n",
            "Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.5.3)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (14.0.1)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.0.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow) (1.5.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.6.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.23.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.4.6)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.35.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (3.3.7)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.8.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (4.11.4)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (3.8.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2022.5.18.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (3.2.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from keras.preprocessing import sequence\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from keras.layers import Input, Flatten, Dropout, Activation\n",
        "from keras.layers import Conv1D, MaxPooling1D\n",
        "from keras.models import Model\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras import optimizers\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv1D(128, 8,padding='same', #classifier.add(Convolution2D(64, (3, 3), padding = 'same', input_shape = (128, 128, 3), activation = 'relu'))\n",
        "                 input_shape=(40,1)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(MaxPooling1D(pool_size=(5)))\n",
        "\n",
        "\n",
        "model.add(Conv1D(256,8,padding='same',))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(MaxPooling1D(pool_size=(5)))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(256))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(256))\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "model.add(Dense(6))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "opt = tf.keras.optimizers.RMSprop(lr=0.00002 , decay=0.0)\n",
        "#opt = tf.keras.optimizers.RMSprop(lr=0.0001, rho=0.9, epsilon=1e-07, decay=0.0)\n",
        "#opt = tf.keras.optimizers.SGD(lr=0.001, momentum=0.0, decay=0.0, nesterov=False)"
      ],
      "metadata": {
        "id": "g74fXWVAC4Cr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d94f8b84-ecf6-4e1b-b876-d504e098d45e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/rmsprop.py:130: UserWarning:\n",
            "\n",
            "The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H6ukOxAGC_I4",
        "outputId": "a27e74a7-f949-4d09-fdf1-5e896075d6d8"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d (Conv1D)             (None, 40, 128)           1152      \n",
            "                                                                 \n",
            " activation (Activation)     (None, 40, 128)           0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 40, 128)           0         \n",
            "                                                                 \n",
            " max_pooling1d (MaxPooling1D  (None, 8, 128)           0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv1d_1 (Conv1D)           (None, 8, 256)            262400    \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 8, 256)            0         \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 8, 256)            0         \n",
            "                                                                 \n",
            " max_pooling1d_1 (MaxPooling  (None, 1, 256)           0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 256)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 256)               65792     \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 256)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 256)               65792     \n",
            "                                                                 \n",
            " activation_3 (Activation)   (None, 256)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 6)                 1542      \n",
            "                                                                 \n",
            " activation_4 (Activation)   (None, 6)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 396,678\n",
            "Trainable params: 396,678\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='sparse_categorical_crossentropy',\n",
        "              optimizer=opt,\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "AbMlLNk4DCBM"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an Instance of Early Stopping Callback.\n",
        "early_stopping_callback = EarlyStopping(monitor = 'val_loss', patience = 35, mode = 'min', restore_best_weights = True)\n",
        "\n",
        "cnnhistory=model.fit(x_traincnn, y_train, batch_size=16, epochs=1000 , shuffle = True, \n",
        "                     validation_data=(X_valid, y_valid) , callbacks = [early_stopping_callback]\n",
        "                     )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RI1v2AuADFhy",
        "outputId": "d8f42a77-8436-4d94-d106-27af73a0a613"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "104/104 [==============================] - 6s 13ms/step - loss: 5.6460 - accuracy: 0.1765 - val_loss: 2.7408 - val_accuracy: 0.1594\n",
            "Epoch 2/1000\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 4.4974 - accuracy: 0.1735 - val_loss: 1.8874 - val_accuracy: 0.2029\n",
            "Epoch 3/1000\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 3.7871 - accuracy: 0.1796 - val_loss: 1.9715 - val_accuracy: 0.1594\n",
            "Epoch 4/1000\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 3.2987 - accuracy: 0.1929 - val_loss: 1.8034 - val_accuracy: 0.2319\n",
            "Epoch 5/1000\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 3.0361 - accuracy: 0.1814 - val_loss: 1.9379 - val_accuracy: 0.1884\n",
            "Epoch 6/1000\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 2.8518 - accuracy: 0.1880 - val_loss: 1.7819 - val_accuracy: 0.1594\n",
            "Epoch 7/1000\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 2.6705 - accuracy: 0.1892 - val_loss: 1.8004 - val_accuracy: 0.2222\n",
            "Epoch 8/1000\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 2.5996 - accuracy: 0.1705 - val_loss: 1.7787 - val_accuracy: 0.1498\n",
            "Epoch 9/1000\n",
            "104/104 [==============================] - 1s 9ms/step - loss: 2.3716 - accuracy: 0.2056 - val_loss: 1.7771 - val_accuracy: 0.2802\n",
            "Epoch 10/1000\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 2.3049 - accuracy: 0.1977 - val_loss: 1.7144 - val_accuracy: 0.2995\n",
            "Epoch 11/1000\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 2.2114 - accuracy: 0.2128 - val_loss: 1.7482 - val_accuracy: 0.2754\n",
            "Epoch 12/1000\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 2.2483 - accuracy: 0.1965 - val_loss: 1.7326 - val_accuracy: 0.2705\n",
            "Epoch 13/1000\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 2.1136 - accuracy: 0.2189 - val_loss: 1.7131 - val_accuracy: 0.2657\n",
            "Epoch 14/1000\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 2.0783 - accuracy: 0.2146 - val_loss: 1.7083 - val_accuracy: 0.3140\n",
            "Epoch 15/1000\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 2.0554 - accuracy: 0.2037 - val_loss: 1.7054 - val_accuracy: 0.2947\n",
            "Epoch 16/1000\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 2.0126 - accuracy: 0.2297 - val_loss: 1.7126 - val_accuracy: 0.2560\n",
            "Epoch 17/1000\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 1.9778 - accuracy: 0.2394 - val_loss: 1.7082 - val_accuracy: 0.3092\n",
            "Epoch 18/1000\n",
            "104/104 [==============================] - 1s 9ms/step - loss: 1.9514 - accuracy: 0.2443 - val_loss: 1.7445 - val_accuracy: 0.2319\n",
            "Epoch 19/1000\n",
            "104/104 [==============================] - 1s 9ms/step - loss: 1.9598 - accuracy: 0.2213 - val_loss: 1.6919 - val_accuracy: 0.3382\n",
            "Epoch 20/1000\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 1.9054 - accuracy: 0.2352 - val_loss: 1.7070 - val_accuracy: 0.2850\n",
            "Epoch 21/1000\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 1.9079 - accuracy: 0.2056 - val_loss: 1.6961 - val_accuracy: 0.3382\n",
            "Epoch 22/1000\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 1.8850 - accuracy: 0.2539 - val_loss: 1.6926 - val_accuracy: 0.2705\n",
            "Epoch 23/1000\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 1.8543 - accuracy: 0.2479 - val_loss: 1.6823 - val_accuracy: 0.3333\n",
            "Epoch 24/1000\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 1.8282 - accuracy: 0.2376 - val_loss: 1.6912 - val_accuracy: 0.3285\n",
            "Epoch 25/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.8532 - accuracy: 0.2461 - val_loss: 1.6760 - val_accuracy: 0.2899\n",
            "Epoch 26/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.8263 - accuracy: 0.2515 - val_loss: 1.6984 - val_accuracy: 0.3237\n",
            "Epoch 27/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.8481 - accuracy: 0.2539 - val_loss: 1.6662 - val_accuracy: 0.3092\n",
            "Epoch 28/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.7918 - accuracy: 0.2660 - val_loss: 1.6528 - val_accuracy: 0.2899\n",
            "Epoch 29/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.8033 - accuracy: 0.2769 - val_loss: 1.6787 - val_accuracy: 0.3333\n",
            "Epoch 30/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.7910 - accuracy: 0.2690 - val_loss: 1.6564 - val_accuracy: 0.3575\n",
            "Epoch 31/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.8142 - accuracy: 0.2485 - val_loss: 1.6498 - val_accuracy: 0.2802\n",
            "Epoch 32/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.7694 - accuracy: 0.2745 - val_loss: 1.6428 - val_accuracy: 0.3816\n",
            "Epoch 33/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.7630 - accuracy: 0.2642 - val_loss: 1.6516 - val_accuracy: 0.3720\n",
            "Epoch 34/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.7885 - accuracy: 0.2666 - val_loss: 1.6390 - val_accuracy: 0.3720\n",
            "Epoch 35/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.7587 - accuracy: 0.2618 - val_loss: 1.6338 - val_accuracy: 0.3865\n",
            "Epoch 36/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.7485 - accuracy: 0.2830 - val_loss: 1.6441 - val_accuracy: 0.3527\n",
            "Epoch 37/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.7419 - accuracy: 0.2690 - val_loss: 1.6366 - val_accuracy: 0.3671\n",
            "Epoch 38/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.7319 - accuracy: 0.2902 - val_loss: 1.6225 - val_accuracy: 0.3816\n",
            "Epoch 39/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.7118 - accuracy: 0.2854 - val_loss: 1.6232 - val_accuracy: 0.3430\n",
            "Epoch 40/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.7337 - accuracy: 0.2787 - val_loss: 1.6160 - val_accuracy: 0.3961\n",
            "Epoch 41/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.7227 - accuracy: 0.2908 - val_loss: 1.6094 - val_accuracy: 0.3527\n",
            "Epoch 42/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.7139 - accuracy: 0.2842 - val_loss: 1.6235 - val_accuracy: 0.3333\n",
            "Epoch 43/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.6871 - accuracy: 0.3089 - val_loss: 1.6025 - val_accuracy: 0.3671\n",
            "Epoch 44/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.7091 - accuracy: 0.2999 - val_loss: 1.6205 - val_accuracy: 0.3913\n",
            "Epoch 45/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.7122 - accuracy: 0.2817 - val_loss: 1.6115 - val_accuracy: 0.3720\n",
            "Epoch 46/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.6965 - accuracy: 0.2811 - val_loss: 1.6208 - val_accuracy: 0.3575\n",
            "Epoch 47/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.6849 - accuracy: 0.3023 - val_loss: 1.6061 - val_accuracy: 0.3865\n",
            "Epoch 48/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.6707 - accuracy: 0.3114 - val_loss: 1.5998 - val_accuracy: 0.3768\n",
            "Epoch 49/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.6649 - accuracy: 0.3120 - val_loss: 1.6006 - val_accuracy: 0.3623\n",
            "Epoch 50/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.6846 - accuracy: 0.3011 - val_loss: 1.5912 - val_accuracy: 0.3961\n",
            "Epoch 51/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.6755 - accuracy: 0.3077 - val_loss: 1.5759 - val_accuracy: 0.3671\n",
            "Epoch 52/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.6546 - accuracy: 0.3108 - val_loss: 1.5798 - val_accuracy: 0.3913\n",
            "Epoch 53/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.6469 - accuracy: 0.3077 - val_loss: 1.5733 - val_accuracy: 0.4493\n",
            "Epoch 54/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.6409 - accuracy: 0.3144 - val_loss: 1.5627 - val_accuracy: 0.4348\n",
            "Epoch 55/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.6466 - accuracy: 0.3162 - val_loss: 1.5767 - val_accuracy: 0.3575\n",
            "Epoch 56/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.6311 - accuracy: 0.3174 - val_loss: 1.5811 - val_accuracy: 0.3720\n",
            "Epoch 57/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.6165 - accuracy: 0.3259 - val_loss: 1.5661 - val_accuracy: 0.3865\n",
            "Epoch 58/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.6041 - accuracy: 0.3585 - val_loss: 1.5553 - val_accuracy: 0.4203\n",
            "Epoch 59/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.5976 - accuracy: 0.3428 - val_loss: 1.5448 - val_accuracy: 0.4155\n",
            "Epoch 60/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.6189 - accuracy: 0.3380 - val_loss: 1.5462 - val_accuracy: 0.4251\n",
            "Epoch 61/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.6259 - accuracy: 0.3222 - val_loss: 1.5413 - val_accuracy: 0.3865\n",
            "Epoch 62/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.5963 - accuracy: 0.3513 - val_loss: 1.5335 - val_accuracy: 0.3913\n",
            "Epoch 63/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.5897 - accuracy: 0.3386 - val_loss: 1.5377 - val_accuracy: 0.3575\n",
            "Epoch 64/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.5695 - accuracy: 0.3628 - val_loss: 1.5335 - val_accuracy: 0.4251\n",
            "Epoch 65/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.6047 - accuracy: 0.3253 - val_loss: 1.5273 - val_accuracy: 0.4106\n",
            "Epoch 66/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.5709 - accuracy: 0.3531 - val_loss: 1.5290 - val_accuracy: 0.4010\n",
            "Epoch 67/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.5716 - accuracy: 0.3362 - val_loss: 1.5438 - val_accuracy: 0.4155\n",
            "Epoch 68/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.5648 - accuracy: 0.3416 - val_loss: 1.5134 - val_accuracy: 0.3913\n",
            "Epoch 69/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.5879 - accuracy: 0.3283 - val_loss: 1.5172 - val_accuracy: 0.4058\n",
            "Epoch 70/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.5454 - accuracy: 0.3640 - val_loss: 1.5037 - val_accuracy: 0.4203\n",
            "Epoch 71/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.5639 - accuracy: 0.3549 - val_loss: 1.5112 - val_accuracy: 0.4444\n",
            "Epoch 72/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.5555 - accuracy: 0.3543 - val_loss: 1.5348 - val_accuracy: 0.4155\n",
            "Epoch 73/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.5703 - accuracy: 0.3622 - val_loss: 1.4980 - val_accuracy: 0.3961\n",
            "Epoch 74/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.5361 - accuracy: 0.3833 - val_loss: 1.4967 - val_accuracy: 0.4783\n",
            "Epoch 75/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.5497 - accuracy: 0.3664 - val_loss: 1.5141 - val_accuracy: 0.4396\n",
            "Epoch 76/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.5340 - accuracy: 0.3730 - val_loss: 1.4837 - val_accuracy: 0.4300\n",
            "Epoch 77/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.5375 - accuracy: 0.3591 - val_loss: 1.4790 - val_accuracy: 0.4155\n",
            "Epoch 78/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.5250 - accuracy: 0.3682 - val_loss: 1.4949 - val_accuracy: 0.3865\n",
            "Epoch 79/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.5142 - accuracy: 0.3773 - val_loss: 1.4985 - val_accuracy: 0.3575\n",
            "Epoch 80/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.5427 - accuracy: 0.3658 - val_loss: 1.4768 - val_accuracy: 0.4010\n",
            "Epoch 81/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.5162 - accuracy: 0.3779 - val_loss: 1.4801 - val_accuracy: 0.4203\n",
            "Epoch 82/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.5299 - accuracy: 0.3634 - val_loss: 1.4653 - val_accuracy: 0.3961\n",
            "Epoch 83/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.4957 - accuracy: 0.3803 - val_loss: 1.4691 - val_accuracy: 0.4541\n",
            "Epoch 84/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.5144 - accuracy: 0.3664 - val_loss: 1.4709 - val_accuracy: 0.4058\n",
            "Epoch 85/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.4907 - accuracy: 0.3900 - val_loss: 1.4585 - val_accuracy: 0.4010\n",
            "Epoch 86/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.5019 - accuracy: 0.3906 - val_loss: 1.4622 - val_accuracy: 0.4783\n",
            "Epoch 87/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.4746 - accuracy: 0.4111 - val_loss: 1.4476 - val_accuracy: 0.5169\n",
            "Epoch 88/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.4870 - accuracy: 0.3748 - val_loss: 1.4261 - val_accuracy: 0.4928\n",
            "Epoch 89/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.4956 - accuracy: 0.3736 - val_loss: 1.4506 - val_accuracy: 0.4783\n",
            "Epoch 90/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.4720 - accuracy: 0.4075 - val_loss: 1.4459 - val_accuracy: 0.4638\n",
            "Epoch 91/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.4317 - accuracy: 0.4178 - val_loss: 1.4236 - val_accuracy: 0.4831\n",
            "Epoch 92/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.4706 - accuracy: 0.3845 - val_loss: 1.4253 - val_accuracy: 0.4928\n",
            "Epoch 93/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.4623 - accuracy: 0.4105 - val_loss: 1.4175 - val_accuracy: 0.4879\n",
            "Epoch 94/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.4619 - accuracy: 0.3869 - val_loss: 1.4114 - val_accuracy: 0.4976\n",
            "Epoch 95/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.4488 - accuracy: 0.4099 - val_loss: 1.4087 - val_accuracy: 0.4686\n",
            "Epoch 96/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.4323 - accuracy: 0.4135 - val_loss: 1.4155 - val_accuracy: 0.5072\n",
            "Epoch 97/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.4512 - accuracy: 0.4039 - val_loss: 1.4102 - val_accuracy: 0.4203\n",
            "Epoch 98/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.4404 - accuracy: 0.4281 - val_loss: 1.4267 - val_accuracy: 0.4203\n",
            "Epoch 99/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.4513 - accuracy: 0.3978 - val_loss: 1.4260 - val_accuracy: 0.4831\n",
            "Epoch 100/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.4398 - accuracy: 0.4135 - val_loss: 1.3822 - val_accuracy: 0.5072\n",
            "Epoch 101/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.4224 - accuracy: 0.4148 - val_loss: 1.3888 - val_accuracy: 0.5411\n",
            "Epoch 102/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.4167 - accuracy: 0.4027 - val_loss: 1.3993 - val_accuracy: 0.4396\n",
            "Epoch 103/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.4305 - accuracy: 0.4202 - val_loss: 1.3984 - val_accuracy: 0.4348\n",
            "Epoch 104/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.4165 - accuracy: 0.4287 - val_loss: 1.3737 - val_accuracy: 0.4686\n",
            "Epoch 105/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.4186 - accuracy: 0.4196 - val_loss: 1.3687 - val_accuracy: 0.4976\n",
            "Epoch 106/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.4033 - accuracy: 0.4232 - val_loss: 1.3636 - val_accuracy: 0.5072\n",
            "Epoch 107/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.3947 - accuracy: 0.4353 - val_loss: 1.3646 - val_accuracy: 0.4976\n",
            "Epoch 108/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.3933 - accuracy: 0.4256 - val_loss: 1.3805 - val_accuracy: 0.4638\n",
            "Epoch 109/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.3683 - accuracy: 0.4281 - val_loss: 1.3519 - val_accuracy: 0.4928\n",
            "Epoch 110/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.3976 - accuracy: 0.4347 - val_loss: 1.3582 - val_accuracy: 0.4783\n",
            "Epoch 111/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.3766 - accuracy: 0.4462 - val_loss: 1.3575 - val_accuracy: 0.5169\n",
            "Epoch 112/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.3931 - accuracy: 0.4329 - val_loss: 1.3516 - val_accuracy: 0.5072\n",
            "Epoch 113/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.3668 - accuracy: 0.4504 - val_loss: 1.3320 - val_accuracy: 0.5507\n",
            "Epoch 114/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.3998 - accuracy: 0.4214 - val_loss: 1.3459 - val_accuracy: 0.5411\n",
            "Epoch 115/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.3613 - accuracy: 0.4553 - val_loss: 1.3541 - val_accuracy: 0.4783\n",
            "Epoch 116/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.3625 - accuracy: 0.4432 - val_loss: 1.3554 - val_accuracy: 0.4976\n",
            "Epoch 117/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.3719 - accuracy: 0.4444 - val_loss: 1.3535 - val_accuracy: 0.4879\n",
            "Epoch 118/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.3860 - accuracy: 0.4244 - val_loss: 1.3253 - val_accuracy: 0.5121\n",
            "Epoch 119/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.3325 - accuracy: 0.4613 - val_loss: 1.3253 - val_accuracy: 0.5024\n",
            "Epoch 120/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.3556 - accuracy: 0.4541 - val_loss: 1.3370 - val_accuracy: 0.5072\n",
            "Epoch 121/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.3378 - accuracy: 0.4553 - val_loss: 1.3223 - val_accuracy: 0.5121\n",
            "Epoch 122/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.3600 - accuracy: 0.4486 - val_loss: 1.3093 - val_accuracy: 0.5459\n",
            "Epoch 123/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.3331 - accuracy: 0.4541 - val_loss: 1.3320 - val_accuracy: 0.4879\n",
            "Epoch 124/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.3136 - accuracy: 0.4843 - val_loss: 1.3088 - val_accuracy: 0.4976\n",
            "Epoch 125/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.3221 - accuracy: 0.4607 - val_loss: 1.2993 - val_accuracy: 0.4783\n",
            "Epoch 126/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.3370 - accuracy: 0.4782 - val_loss: 1.2919 - val_accuracy: 0.5507\n",
            "Epoch 127/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.3356 - accuracy: 0.4722 - val_loss: 1.2980 - val_accuracy: 0.5749\n",
            "Epoch 128/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.3234 - accuracy: 0.4619 - val_loss: 1.2851 - val_accuracy: 0.5072\n",
            "Epoch 129/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.3240 - accuracy: 0.4516 - val_loss: 1.2869 - val_accuracy: 0.5459\n",
            "Epoch 130/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.3023 - accuracy: 0.4873 - val_loss: 1.2990 - val_accuracy: 0.5362\n",
            "Epoch 131/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.3295 - accuracy: 0.4528 - val_loss: 1.2796 - val_accuracy: 0.5266\n",
            "Epoch 132/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.3231 - accuracy: 0.4619 - val_loss: 1.2915 - val_accuracy: 0.4879\n",
            "Epoch 133/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.2948 - accuracy: 0.4794 - val_loss: 1.2827 - val_accuracy: 0.5266\n",
            "Epoch 134/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.2901 - accuracy: 0.4728 - val_loss: 1.3109 - val_accuracy: 0.4879\n",
            "Epoch 135/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.3003 - accuracy: 0.4692 - val_loss: 1.2651 - val_accuracy: 0.5314\n",
            "Epoch 136/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 1.2920 - accuracy: 0.4873 - val_loss: 1.2729 - val_accuracy: 0.4928\n",
            "Epoch 137/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 1.2881 - accuracy: 0.4849 - val_loss: 1.2703 - val_accuracy: 0.5314\n",
            "Epoch 138/1000\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 1.2731 - accuracy: 0.4903 - val_loss: 1.2497 - val_accuracy: 0.5556\n",
            "Epoch 139/1000\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 1.2877 - accuracy: 0.4891 - val_loss: 1.2774 - val_accuracy: 0.5024\n",
            "Epoch 140/1000\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 1.2775 - accuracy: 0.4970 - val_loss: 1.2471 - val_accuracy: 0.5556\n",
            "Epoch 141/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.2887 - accuracy: 0.4758 - val_loss: 1.2371 - val_accuracy: 0.5411\n",
            "Epoch 142/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.2740 - accuracy: 0.4825 - val_loss: 1.2423 - val_accuracy: 0.5652\n",
            "Epoch 143/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.2583 - accuracy: 0.4879 - val_loss: 1.2333 - val_accuracy: 0.5459\n",
            "Epoch 144/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.2611 - accuracy: 0.4915 - val_loss: 1.2217 - val_accuracy: 0.5556\n",
            "Epoch 145/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.2732 - accuracy: 0.4897 - val_loss: 1.2431 - val_accuracy: 0.5362\n",
            "Epoch 146/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.2739 - accuracy: 0.4831 - val_loss: 1.2204 - val_accuracy: 0.5411\n",
            "Epoch 147/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.2543 - accuracy: 0.4837 - val_loss: 1.2316 - val_accuracy: 0.5700\n",
            "Epoch 148/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.2595 - accuracy: 0.4964 - val_loss: 1.2298 - val_accuracy: 0.5556\n",
            "Epoch 149/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.2547 - accuracy: 0.4819 - val_loss: 1.2311 - val_accuracy: 0.5652\n",
            "Epoch 150/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.2505 - accuracy: 0.4933 - val_loss: 1.2181 - val_accuracy: 0.5652\n",
            "Epoch 151/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.2408 - accuracy: 0.5127 - val_loss: 1.2270 - val_accuracy: 0.5411\n",
            "Epoch 152/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.2403 - accuracy: 0.4994 - val_loss: 1.2230 - val_accuracy: 0.5604\n",
            "Epoch 153/1000\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 1.2248 - accuracy: 0.5097 - val_loss: 1.2101 - val_accuracy: 0.5362\n",
            "Epoch 154/1000\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 1.2162 - accuracy: 0.5079 - val_loss: 1.2085 - val_accuracy: 0.5411\n",
            "Epoch 155/1000\n",
            "104/104 [==============================] - 1s 9ms/step - loss: 1.2261 - accuracy: 0.5036 - val_loss: 1.1951 - val_accuracy: 0.5556\n",
            "Epoch 156/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.2252 - accuracy: 0.5067 - val_loss: 1.2081 - val_accuracy: 0.5266\n",
            "Epoch 157/1000\n",
            "104/104 [==============================] - 1s 9ms/step - loss: 1.2086 - accuracy: 0.5284 - val_loss: 1.1967 - val_accuracy: 0.5556\n",
            "Epoch 158/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.2250 - accuracy: 0.5054 - val_loss: 1.2034 - val_accuracy: 0.5266\n",
            "Epoch 159/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.2084 - accuracy: 0.5278 - val_loss: 1.1902 - val_accuracy: 0.5797\n",
            "Epoch 160/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.2265 - accuracy: 0.4909 - val_loss: 1.2169 - val_accuracy: 0.5459\n",
            "Epoch 161/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.2111 - accuracy: 0.5175 - val_loss: 1.1865 - val_accuracy: 0.5797\n",
            "Epoch 162/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.1856 - accuracy: 0.5242 - val_loss: 1.1822 - val_accuracy: 0.5459\n",
            "Epoch 163/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.2154 - accuracy: 0.5230 - val_loss: 1.1667 - val_accuracy: 0.5845\n",
            "Epoch 164/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.1990 - accuracy: 0.5091 - val_loss: 1.1937 - val_accuracy: 0.5797\n",
            "Epoch 165/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.1902 - accuracy: 0.5230 - val_loss: 1.1773 - val_accuracy: 0.5507\n",
            "Epoch 166/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.1949 - accuracy: 0.5169 - val_loss: 1.1662 - val_accuracy: 0.5845\n",
            "Epoch 167/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.1993 - accuracy: 0.5079 - val_loss: 1.1693 - val_accuracy: 0.5652\n",
            "Epoch 168/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.1898 - accuracy: 0.5278 - val_loss: 1.1650 - val_accuracy: 0.5797\n",
            "Epoch 169/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.1847 - accuracy: 0.5230 - val_loss: 1.1570 - val_accuracy: 0.5749\n",
            "Epoch 170/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.2052 - accuracy: 0.5181 - val_loss: 1.1437 - val_accuracy: 0.5845\n",
            "Epoch 171/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.1852 - accuracy: 0.5145 - val_loss: 1.1537 - val_accuracy: 0.5990\n",
            "Epoch 172/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.1908 - accuracy: 0.5236 - val_loss: 1.1544 - val_accuracy: 0.5990\n",
            "Epoch 173/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.1739 - accuracy: 0.5193 - val_loss: 1.1593 - val_accuracy: 0.5700\n",
            "Epoch 174/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.1817 - accuracy: 0.5260 - val_loss: 1.1420 - val_accuracy: 0.5990\n",
            "Epoch 175/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.1507 - accuracy: 0.5212 - val_loss: 1.1565 - val_accuracy: 0.5990\n",
            "Epoch 176/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.1679 - accuracy: 0.5266 - val_loss: 1.1461 - val_accuracy: 0.5942\n",
            "Epoch 177/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.1651 - accuracy: 0.5351 - val_loss: 1.1494 - val_accuracy: 0.5942\n",
            "Epoch 178/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.1673 - accuracy: 0.5441 - val_loss: 1.1334 - val_accuracy: 0.6087\n",
            "Epoch 179/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.1681 - accuracy: 0.5326 - val_loss: 1.1449 - val_accuracy: 0.6087\n",
            "Epoch 180/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.1439 - accuracy: 0.5520 - val_loss: 1.1272 - val_accuracy: 0.5700\n",
            "Epoch 181/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.1542 - accuracy: 0.5369 - val_loss: 1.1181 - val_accuracy: 0.5990\n",
            "Epoch 182/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.1681 - accuracy: 0.5405 - val_loss: 1.1314 - val_accuracy: 0.5990\n",
            "Epoch 183/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.1264 - accuracy: 0.5574 - val_loss: 1.1144 - val_accuracy: 0.6135\n",
            "Epoch 184/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.1452 - accuracy: 0.5387 - val_loss: 1.1320 - val_accuracy: 0.6135\n",
            "Epoch 185/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.1355 - accuracy: 0.5526 - val_loss: 1.1191 - val_accuracy: 0.6039\n",
            "Epoch 186/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.1526 - accuracy: 0.5290 - val_loss: 1.1394 - val_accuracy: 0.6135\n",
            "Epoch 187/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.1244 - accuracy: 0.5532 - val_loss: 1.1235 - val_accuracy: 0.5942\n",
            "Epoch 188/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.1280 - accuracy: 0.5453 - val_loss: 1.1209 - val_accuracy: 0.5845\n",
            "Epoch 189/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.1332 - accuracy: 0.5278 - val_loss: 1.1175 - val_accuracy: 0.5604\n",
            "Epoch 190/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.1218 - accuracy: 0.5556 - val_loss: 1.1194 - val_accuracy: 0.5894\n",
            "Epoch 191/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.1522 - accuracy: 0.5193 - val_loss: 1.1259 - val_accuracy: 0.5845\n",
            "Epoch 192/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.1408 - accuracy: 0.5599 - val_loss: 1.0949 - val_accuracy: 0.6184\n",
            "Epoch 193/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.1221 - accuracy: 0.5593 - val_loss: 1.1139 - val_accuracy: 0.5990\n",
            "Epoch 194/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.1261 - accuracy: 0.5466 - val_loss: 1.1212 - val_accuracy: 0.6087\n",
            "Epoch 195/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.1124 - accuracy: 0.5659 - val_loss: 1.1003 - val_accuracy: 0.5990\n",
            "Epoch 196/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.1158 - accuracy: 0.5562 - val_loss: 1.0983 - val_accuracy: 0.5797\n",
            "Epoch 197/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 1.0945 - accuracy: 0.5574 - val_loss: 1.0881 - val_accuracy: 0.5990\n",
            "Epoch 198/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.1262 - accuracy: 0.5520 - val_loss: 1.0864 - val_accuracy: 0.6280\n",
            "Epoch 199/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.1000 - accuracy: 0.5550 - val_loss: 1.0718 - val_accuracy: 0.5942\n",
            "Epoch 200/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.1208 - accuracy: 0.5502 - val_loss: 1.0818 - val_accuracy: 0.5894\n",
            "Epoch 201/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.1061 - accuracy: 0.5689 - val_loss: 1.0845 - val_accuracy: 0.6039\n",
            "Epoch 202/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.1149 - accuracy: 0.5562 - val_loss: 1.0801 - val_accuracy: 0.6232\n",
            "Epoch 203/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.1001 - accuracy: 0.5738 - val_loss: 1.0858 - val_accuracy: 0.6087\n",
            "Epoch 204/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.1213 - accuracy: 0.5605 - val_loss: 1.0778 - val_accuracy: 0.6135\n",
            "Epoch 205/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0867 - accuracy: 0.5701 - val_loss: 1.0593 - val_accuracy: 0.6232\n",
            "Epoch 206/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0975 - accuracy: 0.5593 - val_loss: 1.0699 - val_accuracy: 0.6280\n",
            "Epoch 207/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0806 - accuracy: 0.5665 - val_loss: 1.0688 - val_accuracy: 0.6087\n",
            "Epoch 208/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0807 - accuracy: 0.5647 - val_loss: 1.0548 - val_accuracy: 0.6232\n",
            "Epoch 209/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0757 - accuracy: 0.5713 - val_loss: 1.0842 - val_accuracy: 0.6039\n",
            "Epoch 210/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0907 - accuracy: 0.5707 - val_loss: 1.0714 - val_accuracy: 0.6087\n",
            "Epoch 211/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0570 - accuracy: 0.5719 - val_loss: 1.0619 - val_accuracy: 0.6377\n",
            "Epoch 212/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0776 - accuracy: 0.5629 - val_loss: 1.0605 - val_accuracy: 0.6135\n",
            "Epoch 213/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0847 - accuracy: 0.5732 - val_loss: 1.0565 - val_accuracy: 0.6135\n",
            "Epoch 214/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0689 - accuracy: 0.5937 - val_loss: 1.0433 - val_accuracy: 0.6473\n",
            "Epoch 215/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0531 - accuracy: 0.5786 - val_loss: 1.0279 - val_accuracy: 0.6280\n",
            "Epoch 216/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0932 - accuracy: 0.5556 - val_loss: 1.0423 - val_accuracy: 0.6329\n",
            "Epoch 217/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0645 - accuracy: 0.5744 - val_loss: 1.0463 - val_accuracy: 0.6377\n",
            "Epoch 218/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0736 - accuracy: 0.5623 - val_loss: 1.0421 - val_accuracy: 0.6329\n",
            "Epoch 219/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0520 - accuracy: 0.5695 - val_loss: 1.0213 - val_accuracy: 0.6280\n",
            "Epoch 220/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0658 - accuracy: 0.5750 - val_loss: 1.0287 - val_accuracy: 0.6570\n",
            "Epoch 221/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0537 - accuracy: 0.5883 - val_loss: 1.0402 - val_accuracy: 0.6087\n",
            "Epoch 222/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0567 - accuracy: 0.5683 - val_loss: 1.0334 - val_accuracy: 0.6667\n",
            "Epoch 223/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0537 - accuracy: 0.5865 - val_loss: 1.0211 - val_accuracy: 0.6522\n",
            "Epoch 224/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0509 - accuracy: 0.5828 - val_loss: 1.0487 - val_accuracy: 0.6329\n",
            "Epoch 225/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0291 - accuracy: 0.5937 - val_loss: 1.0164 - val_accuracy: 0.6570\n",
            "Epoch 226/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0356 - accuracy: 0.5750 - val_loss: 1.0384 - val_accuracy: 0.6039\n",
            "Epoch 227/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0420 - accuracy: 0.5846 - val_loss: 1.0309 - val_accuracy: 0.6425\n",
            "Epoch 228/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0191 - accuracy: 0.5865 - val_loss: 1.0098 - val_accuracy: 0.6618\n",
            "Epoch 229/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0296 - accuracy: 0.5834 - val_loss: 1.0257 - val_accuracy: 0.6522\n",
            "Epoch 230/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0532 - accuracy: 0.5901 - val_loss: 1.0032 - val_accuracy: 0.6715\n",
            "Epoch 231/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0305 - accuracy: 0.5925 - val_loss: 0.9966 - val_accuracy: 0.6763\n",
            "Epoch 232/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0493 - accuracy: 0.5889 - val_loss: 0.9979 - val_accuracy: 0.6280\n",
            "Epoch 233/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0269 - accuracy: 0.5992 - val_loss: 1.0132 - val_accuracy: 0.6618\n",
            "Epoch 234/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0270 - accuracy: 0.6016 - val_loss: 1.0117 - val_accuracy: 0.6280\n",
            "Epoch 235/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0093 - accuracy: 0.6022 - val_loss: 1.0162 - val_accuracy: 0.6135\n",
            "Epoch 236/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0274 - accuracy: 0.5961 - val_loss: 1.0081 - val_accuracy: 0.6329\n",
            "Epoch 237/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0069 - accuracy: 0.5985 - val_loss: 1.0020 - val_accuracy: 0.6425\n",
            "Epoch 238/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9864 - accuracy: 0.6088 - val_loss: 0.9854 - val_accuracy: 0.6329\n",
            "Epoch 239/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0007 - accuracy: 0.6004 - val_loss: 0.9941 - val_accuracy: 0.6425\n",
            "Epoch 240/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9965 - accuracy: 0.6082 - val_loss: 1.0053 - val_accuracy: 0.6667\n",
            "Epoch 241/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0068 - accuracy: 0.6052 - val_loss: 0.9941 - val_accuracy: 0.6522\n",
            "Epoch 242/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0325 - accuracy: 0.5992 - val_loss: 0.9913 - val_accuracy: 0.6280\n",
            "Epoch 243/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0165 - accuracy: 0.5967 - val_loss: 0.9923 - val_accuracy: 0.6377\n",
            "Epoch 244/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0067 - accuracy: 0.5973 - val_loss: 0.9852 - val_accuracy: 0.6570\n",
            "Epoch 245/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0056 - accuracy: 0.5961 - val_loss: 0.9707 - val_accuracy: 0.6667\n",
            "Epoch 246/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0068 - accuracy: 0.5973 - val_loss: 0.9970 - val_accuracy: 0.6667\n",
            "Epoch 247/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9927 - accuracy: 0.5961 - val_loss: 0.9774 - val_accuracy: 0.6667\n",
            "Epoch 248/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9882 - accuracy: 0.6004 - val_loss: 0.9567 - val_accuracy: 0.6957\n",
            "Epoch 249/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9912 - accuracy: 0.6052 - val_loss: 1.0095 - val_accuracy: 0.6667\n",
            "Epoch 250/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0061 - accuracy: 0.5907 - val_loss: 0.9826 - val_accuracy: 0.6618\n",
            "Epoch 251/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0002 - accuracy: 0.5967 - val_loss: 0.9816 - val_accuracy: 0.6570\n",
            "Epoch 252/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9881 - accuracy: 0.6016 - val_loss: 0.9894 - val_accuracy: 0.6425\n",
            "Epoch 253/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9951 - accuracy: 0.6100 - val_loss: 0.9689 - val_accuracy: 0.6667\n",
            "Epoch 254/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0037 - accuracy: 0.6040 - val_loss: 0.9639 - val_accuracy: 0.6667\n",
            "Epoch 255/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9836 - accuracy: 0.5998 - val_loss: 0.9637 - val_accuracy: 0.6667\n",
            "Epoch 256/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9801 - accuracy: 0.6227 - val_loss: 0.9626 - val_accuracy: 0.6860\n",
            "Epoch 257/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9654 - accuracy: 0.6245 - val_loss: 0.9611 - val_accuracy: 0.6425\n",
            "Epoch 258/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9672 - accuracy: 0.6203 - val_loss: 0.9583 - val_accuracy: 0.6763\n",
            "Epoch 259/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9930 - accuracy: 0.5901 - val_loss: 0.9615 - val_accuracy: 0.6618\n",
            "Epoch 260/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9579 - accuracy: 0.6252 - val_loss: 0.9374 - val_accuracy: 0.6763\n",
            "Epoch 261/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9647 - accuracy: 0.6161 - val_loss: 0.9447 - val_accuracy: 0.6812\n",
            "Epoch 262/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9686 - accuracy: 0.6161 - val_loss: 0.9367 - val_accuracy: 0.6957\n",
            "Epoch 263/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9626 - accuracy: 0.6137 - val_loss: 0.9370 - val_accuracy: 0.6957\n",
            "Epoch 264/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9776 - accuracy: 0.6149 - val_loss: 0.9481 - val_accuracy: 0.6715\n",
            "Epoch 265/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.9583 - accuracy: 0.6191 - val_loss: 0.9476 - val_accuracy: 0.6763\n",
            "Epoch 266/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9737 - accuracy: 0.6058 - val_loss: 0.9559 - val_accuracy: 0.6618\n",
            "Epoch 267/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9600 - accuracy: 0.6131 - val_loss: 0.9476 - val_accuracy: 0.6667\n",
            "Epoch 268/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9489 - accuracy: 0.6179 - val_loss: 0.9526 - val_accuracy: 0.6570\n",
            "Epoch 269/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9544 - accuracy: 0.6173 - val_loss: 0.9567 - val_accuracy: 0.6377\n",
            "Epoch 270/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9664 - accuracy: 0.6324 - val_loss: 0.9493 - val_accuracy: 0.6860\n",
            "Epoch 271/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9354 - accuracy: 0.6137 - val_loss: 0.9306 - val_accuracy: 0.6908\n",
            "Epoch 272/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9647 - accuracy: 0.6239 - val_loss: 0.9402 - val_accuracy: 0.6763\n",
            "Epoch 273/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9599 - accuracy: 0.6131 - val_loss: 0.9382 - val_accuracy: 0.6715\n",
            "Epoch 274/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9605 - accuracy: 0.6143 - val_loss: 0.9442 - val_accuracy: 0.6570\n",
            "Epoch 275/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9479 - accuracy: 0.6197 - val_loss: 0.9327 - val_accuracy: 0.6522\n",
            "Epoch 276/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9380 - accuracy: 0.6294 - val_loss: 0.9148 - val_accuracy: 0.7005\n",
            "Epoch 277/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9393 - accuracy: 0.6191 - val_loss: 0.9246 - val_accuracy: 0.6715\n",
            "Epoch 278/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9475 - accuracy: 0.6252 - val_loss: 0.9403 - val_accuracy: 0.6715\n",
            "Epoch 279/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9464 - accuracy: 0.6397 - val_loss: 0.9185 - val_accuracy: 0.6522\n",
            "Epoch 280/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9375 - accuracy: 0.6378 - val_loss: 0.9166 - val_accuracy: 0.7053\n",
            "Epoch 281/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9169 - accuracy: 0.6336 - val_loss: 0.9011 - val_accuracy: 0.7198\n",
            "Epoch 282/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9098 - accuracy: 0.6463 - val_loss: 0.9239 - val_accuracy: 0.6860\n",
            "Epoch 283/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9488 - accuracy: 0.6185 - val_loss: 0.9221 - val_accuracy: 0.6763\n",
            "Epoch 284/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9439 - accuracy: 0.6215 - val_loss: 0.9000 - val_accuracy: 0.7198\n",
            "Epoch 285/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9203 - accuracy: 0.6239 - val_loss: 0.9069 - val_accuracy: 0.7246\n",
            "Epoch 286/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9451 - accuracy: 0.6185 - val_loss: 0.8937 - val_accuracy: 0.7391\n",
            "Epoch 287/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9237 - accuracy: 0.6288 - val_loss: 0.8957 - val_accuracy: 0.7150\n",
            "Epoch 288/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9213 - accuracy: 0.6403 - val_loss: 0.8967 - val_accuracy: 0.7053\n",
            "Epoch 289/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9425 - accuracy: 0.6258 - val_loss: 0.9113 - val_accuracy: 0.7101\n",
            "Epoch 290/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9327 - accuracy: 0.6300 - val_loss: 0.9103 - val_accuracy: 0.6860\n",
            "Epoch 291/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9109 - accuracy: 0.6433 - val_loss: 0.8993 - val_accuracy: 0.6860\n",
            "Epoch 292/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9359 - accuracy: 0.6209 - val_loss: 0.9181 - val_accuracy: 0.6618\n",
            "Epoch 293/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.9045 - accuracy: 0.6378 - val_loss: 0.9151 - val_accuracy: 0.6667\n",
            "Epoch 294/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9362 - accuracy: 0.6155 - val_loss: 0.9138 - val_accuracy: 0.6618\n",
            "Epoch 295/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9151 - accuracy: 0.6409 - val_loss: 0.9331 - val_accuracy: 0.6667\n",
            "Epoch 296/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9312 - accuracy: 0.6336 - val_loss: 0.9262 - val_accuracy: 0.6763\n",
            "Epoch 297/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9090 - accuracy: 0.6312 - val_loss: 0.9119 - val_accuracy: 0.7005\n",
            "Epoch 298/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9060 - accuracy: 0.6366 - val_loss: 0.8852 - val_accuracy: 0.7198\n",
            "Epoch 299/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9091 - accuracy: 0.6306 - val_loss: 0.8956 - val_accuracy: 0.7005\n",
            "Epoch 300/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9078 - accuracy: 0.6469 - val_loss: 0.8862 - val_accuracy: 0.6957\n",
            "Epoch 301/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9013 - accuracy: 0.6378 - val_loss: 0.9059 - val_accuracy: 0.6812\n",
            "Epoch 302/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8981 - accuracy: 0.6451 - val_loss: 0.9098 - val_accuracy: 0.7005\n",
            "Epoch 303/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9073 - accuracy: 0.6378 - val_loss: 0.8790 - val_accuracy: 0.7101\n",
            "Epoch 304/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9084 - accuracy: 0.6391 - val_loss: 0.9024 - val_accuracy: 0.7101\n",
            "Epoch 305/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8967 - accuracy: 0.6499 - val_loss: 0.8807 - val_accuracy: 0.6957\n",
            "Epoch 306/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9095 - accuracy: 0.6342 - val_loss: 0.8783 - val_accuracy: 0.7343\n",
            "Epoch 307/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8833 - accuracy: 0.6518 - val_loss: 0.8864 - val_accuracy: 0.7101\n",
            "Epoch 308/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8797 - accuracy: 0.6542 - val_loss: 0.8955 - val_accuracy: 0.6908\n",
            "Epoch 309/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8874 - accuracy: 0.6427 - val_loss: 0.8836 - val_accuracy: 0.7005\n",
            "Epoch 310/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9046 - accuracy: 0.6445 - val_loss: 0.8791 - val_accuracy: 0.7101\n",
            "Epoch 311/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8838 - accuracy: 0.6505 - val_loss: 0.8804 - val_accuracy: 0.7005\n",
            "Epoch 312/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8792 - accuracy: 0.6554 - val_loss: 0.8642 - val_accuracy: 0.7246\n",
            "Epoch 313/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8889 - accuracy: 0.6354 - val_loss: 0.8719 - val_accuracy: 0.7246\n",
            "Epoch 314/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.9024 - accuracy: 0.6475 - val_loss: 0.8664 - val_accuracy: 0.7101\n",
            "Epoch 315/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.9021 - accuracy: 0.6475 - val_loss: 0.8656 - val_accuracy: 0.7150\n",
            "Epoch 316/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8853 - accuracy: 0.6499 - val_loss: 0.8784 - val_accuracy: 0.7053\n",
            "Epoch 317/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8999 - accuracy: 0.6445 - val_loss: 0.8999 - val_accuracy: 0.6957\n",
            "Epoch 318/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9015 - accuracy: 0.6499 - val_loss: 0.8621 - val_accuracy: 0.7101\n",
            "Epoch 319/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8750 - accuracy: 0.6524 - val_loss: 0.8622 - val_accuracy: 0.7150\n",
            "Epoch 320/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8665 - accuracy: 0.6657 - val_loss: 0.8802 - val_accuracy: 0.6860\n",
            "Epoch 321/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8929 - accuracy: 0.6475 - val_loss: 0.8816 - val_accuracy: 0.6763\n",
            "Epoch 322/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8726 - accuracy: 0.6469 - val_loss: 0.8640 - val_accuracy: 0.7198\n",
            "Epoch 323/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.8600 - accuracy: 0.6608 - val_loss: 0.8571 - val_accuracy: 0.7101\n",
            "Epoch 324/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8682 - accuracy: 0.6663 - val_loss: 0.8654 - val_accuracy: 0.7053\n",
            "Epoch 325/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8616 - accuracy: 0.6651 - val_loss: 0.8631 - val_accuracy: 0.6715\n",
            "Epoch 326/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8760 - accuracy: 0.6620 - val_loss: 0.8500 - val_accuracy: 0.6860\n",
            "Epoch 327/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8614 - accuracy: 0.6566 - val_loss: 0.8467 - val_accuracy: 0.7488\n",
            "Epoch 328/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8644 - accuracy: 0.6602 - val_loss: 0.8490 - val_accuracy: 0.7488\n",
            "Epoch 329/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8695 - accuracy: 0.6554 - val_loss: 0.8511 - val_accuracy: 0.7246\n",
            "Epoch 330/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8692 - accuracy: 0.6493 - val_loss: 0.8594 - val_accuracy: 0.6860\n",
            "Epoch 331/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.8666 - accuracy: 0.6675 - val_loss: 0.8643 - val_accuracy: 0.7101\n",
            "Epoch 332/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8519 - accuracy: 0.6572 - val_loss: 0.8397 - val_accuracy: 0.7150\n",
            "Epoch 333/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8702 - accuracy: 0.6578 - val_loss: 0.8560 - val_accuracy: 0.7150\n",
            "Epoch 334/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8549 - accuracy: 0.6590 - val_loss: 0.8497 - val_accuracy: 0.7343\n",
            "Epoch 335/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8567 - accuracy: 0.6608 - val_loss: 0.8408 - val_accuracy: 0.7343\n",
            "Epoch 336/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.8358 - accuracy: 0.6584 - val_loss: 0.8422 - val_accuracy: 0.7295\n",
            "Epoch 337/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8440 - accuracy: 0.6693 - val_loss: 0.8274 - val_accuracy: 0.7343\n",
            "Epoch 338/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8471 - accuracy: 0.6644 - val_loss: 0.8328 - val_accuracy: 0.7198\n",
            "Epoch 339/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8474 - accuracy: 0.6644 - val_loss: 0.8458 - val_accuracy: 0.7101\n",
            "Epoch 340/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8422 - accuracy: 0.6675 - val_loss: 0.8521 - val_accuracy: 0.7101\n",
            "Epoch 341/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8244 - accuracy: 0.6705 - val_loss: 0.8316 - val_accuracy: 0.7343\n",
            "Epoch 342/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8454 - accuracy: 0.6602 - val_loss: 0.8491 - val_accuracy: 0.7005\n",
            "Epoch 343/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8464 - accuracy: 0.6669 - val_loss: 0.8419 - val_accuracy: 0.7343\n",
            "Epoch 344/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.8378 - accuracy: 0.6632 - val_loss: 0.8370 - val_accuracy: 0.7246\n",
            "Epoch 345/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8431 - accuracy: 0.6530 - val_loss: 0.8313 - val_accuracy: 0.7295\n",
            "Epoch 346/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8346 - accuracy: 0.6717 - val_loss: 0.8369 - val_accuracy: 0.7101\n",
            "Epoch 347/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8428 - accuracy: 0.6638 - val_loss: 0.8271 - val_accuracy: 0.7440\n",
            "Epoch 348/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8271 - accuracy: 0.6705 - val_loss: 0.8314 - val_accuracy: 0.7198\n",
            "Epoch 349/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8469 - accuracy: 0.6578 - val_loss: 0.8247 - val_accuracy: 0.7246\n",
            "Epoch 350/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8391 - accuracy: 0.6687 - val_loss: 0.8441 - val_accuracy: 0.7246\n",
            "Epoch 351/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8220 - accuracy: 0.6747 - val_loss: 0.8390 - val_accuracy: 0.7101\n",
            "Epoch 352/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8215 - accuracy: 0.6638 - val_loss: 0.8590 - val_accuracy: 0.6763\n",
            "Epoch 353/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8399 - accuracy: 0.6681 - val_loss: 0.8418 - val_accuracy: 0.7005\n",
            "Epoch 354/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8264 - accuracy: 0.6741 - val_loss: 0.8280 - val_accuracy: 0.7101\n",
            "Epoch 355/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8338 - accuracy: 0.6620 - val_loss: 0.8174 - val_accuracy: 0.7295\n",
            "Epoch 356/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8198 - accuracy: 0.6632 - val_loss: 0.8403 - val_accuracy: 0.6908\n",
            "Epoch 357/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8262 - accuracy: 0.6723 - val_loss: 0.8148 - val_accuracy: 0.7246\n",
            "Epoch 358/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8349 - accuracy: 0.6657 - val_loss: 0.8180 - val_accuracy: 0.7391\n",
            "Epoch 359/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8081 - accuracy: 0.6880 - val_loss: 0.8146 - val_accuracy: 0.7440\n",
            "Epoch 360/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8289 - accuracy: 0.6687 - val_loss: 0.8203 - val_accuracy: 0.7198\n",
            "Epoch 361/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8005 - accuracy: 0.6802 - val_loss: 0.8203 - val_accuracy: 0.7198\n",
            "Epoch 362/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8161 - accuracy: 0.6717 - val_loss: 0.8175 - val_accuracy: 0.7440\n",
            "Epoch 363/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8233 - accuracy: 0.6898 - val_loss: 0.8166 - val_accuracy: 0.7391\n",
            "Epoch 364/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8113 - accuracy: 0.6850 - val_loss: 0.8088 - val_accuracy: 0.7488\n",
            "Epoch 365/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8387 - accuracy: 0.6632 - val_loss: 0.8337 - val_accuracy: 0.7198\n",
            "Epoch 366/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8011 - accuracy: 0.6687 - val_loss: 0.8169 - val_accuracy: 0.7440\n",
            "Epoch 367/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8104 - accuracy: 0.6820 - val_loss: 0.8034 - val_accuracy: 0.7440\n",
            "Epoch 368/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8081 - accuracy: 0.6826 - val_loss: 0.8045 - val_accuracy: 0.7246\n",
            "Epoch 369/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7922 - accuracy: 0.6880 - val_loss: 0.8076 - val_accuracy: 0.7246\n",
            "Epoch 370/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8078 - accuracy: 0.6935 - val_loss: 0.8134 - val_accuracy: 0.7391\n",
            "Epoch 371/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8217 - accuracy: 0.6747 - val_loss: 0.8414 - val_accuracy: 0.7101\n",
            "Epoch 372/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7828 - accuracy: 0.6844 - val_loss: 0.8265 - val_accuracy: 0.7150\n",
            "Epoch 373/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7941 - accuracy: 0.6784 - val_loss: 0.8046 - val_accuracy: 0.7343\n",
            "Epoch 374/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7969 - accuracy: 0.6844 - val_loss: 0.8469 - val_accuracy: 0.7005\n",
            "Epoch 375/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7954 - accuracy: 0.6850 - val_loss: 0.7983 - val_accuracy: 0.7391\n",
            "Epoch 376/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7975 - accuracy: 0.6911 - val_loss: 0.8058 - val_accuracy: 0.7391\n",
            "Epoch 377/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7840 - accuracy: 0.6983 - val_loss: 0.8017 - val_accuracy: 0.7488\n",
            "Epoch 378/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7949 - accuracy: 0.6892 - val_loss: 0.8165 - val_accuracy: 0.7295\n",
            "Epoch 379/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8075 - accuracy: 0.6886 - val_loss: 0.8032 - val_accuracy: 0.7440\n",
            "Epoch 380/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8014 - accuracy: 0.6705 - val_loss: 0.8042 - val_accuracy: 0.7391\n",
            "Epoch 381/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7858 - accuracy: 0.6911 - val_loss: 0.7819 - val_accuracy: 0.7246\n",
            "Epoch 382/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8028 - accuracy: 0.6868 - val_loss: 0.8011 - val_accuracy: 0.7488\n",
            "Epoch 383/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7822 - accuracy: 0.7001 - val_loss: 0.7965 - val_accuracy: 0.7005\n",
            "Epoch 384/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8138 - accuracy: 0.6892 - val_loss: 0.7890 - val_accuracy: 0.7343\n",
            "Epoch 385/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8018 - accuracy: 0.6765 - val_loss: 0.8021 - val_accuracy: 0.7101\n",
            "Epoch 386/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7704 - accuracy: 0.7013 - val_loss: 0.8168 - val_accuracy: 0.7005\n",
            "Epoch 387/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8010 - accuracy: 0.6862 - val_loss: 0.7913 - val_accuracy: 0.7633\n",
            "Epoch 388/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.7835 - accuracy: 0.7007 - val_loss: 0.7885 - val_accuracy: 0.7440\n",
            "Epoch 389/1000\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.7738 - accuracy: 0.6995 - val_loss: 0.7839 - val_accuracy: 0.7295\n",
            "Epoch 390/1000\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.8060 - accuracy: 0.6886 - val_loss: 0.7948 - val_accuracy: 0.7295\n",
            "Epoch 391/1000\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.8019 - accuracy: 0.6747 - val_loss: 0.7927 - val_accuracy: 0.7295\n",
            "Epoch 392/1000\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.7753 - accuracy: 0.6844 - val_loss: 0.8066 - val_accuracy: 0.7101\n",
            "Epoch 393/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7890 - accuracy: 0.6826 - val_loss: 0.7896 - val_accuracy: 0.7198\n",
            "Epoch 394/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7729 - accuracy: 0.7031 - val_loss: 0.7776 - val_accuracy: 0.7150\n",
            "Epoch 395/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7640 - accuracy: 0.6953 - val_loss: 0.7992 - val_accuracy: 0.7101\n",
            "Epoch 396/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7641 - accuracy: 0.7013 - val_loss: 0.7917 - val_accuracy: 0.7295\n",
            "Epoch 397/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7870 - accuracy: 0.6880 - val_loss: 0.7985 - val_accuracy: 0.7343\n",
            "Epoch 398/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7785 - accuracy: 0.6923 - val_loss: 0.7920 - val_accuracy: 0.7391\n",
            "Epoch 399/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7694 - accuracy: 0.7031 - val_loss: 0.8135 - val_accuracy: 0.7101\n",
            "Epoch 400/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7546 - accuracy: 0.6947 - val_loss: 0.7790 - val_accuracy: 0.7488\n",
            "Epoch 401/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7794 - accuracy: 0.6898 - val_loss: 0.7867 - val_accuracy: 0.7343\n",
            "Epoch 402/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7682 - accuracy: 0.6977 - val_loss: 0.7825 - val_accuracy: 0.7343\n",
            "Epoch 403/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7652 - accuracy: 0.6965 - val_loss: 0.7757 - val_accuracy: 0.7440\n",
            "Epoch 404/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.7552 - accuracy: 0.7050 - val_loss: 0.7704 - val_accuracy: 0.7246\n",
            "Epoch 405/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7427 - accuracy: 0.7062 - val_loss: 0.7866 - val_accuracy: 0.7391\n",
            "Epoch 406/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.7832 - accuracy: 0.6808 - val_loss: 0.7777 - val_accuracy: 0.7343\n",
            "Epoch 407/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7703 - accuracy: 0.6868 - val_loss: 0.7791 - val_accuracy: 0.7343\n",
            "Epoch 408/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7558 - accuracy: 0.7080 - val_loss: 0.7810 - val_accuracy: 0.7295\n",
            "Epoch 409/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7613 - accuracy: 0.6971 - val_loss: 0.7853 - val_accuracy: 0.7295\n",
            "Epoch 410/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7558 - accuracy: 0.6953 - val_loss: 0.7994 - val_accuracy: 0.7101\n",
            "Epoch 411/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7593 - accuracy: 0.7031 - val_loss: 0.7661 - val_accuracy: 0.7440\n",
            "Epoch 412/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7541 - accuracy: 0.6947 - val_loss: 0.7804 - val_accuracy: 0.7295\n",
            "Epoch 413/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7735 - accuracy: 0.6977 - val_loss: 0.7810 - val_accuracy: 0.7440\n",
            "Epoch 414/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7551 - accuracy: 0.7025 - val_loss: 0.7702 - val_accuracy: 0.7150\n",
            "Epoch 415/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7363 - accuracy: 0.7044 - val_loss: 0.7582 - val_accuracy: 0.7391\n",
            "Epoch 416/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7454 - accuracy: 0.7116 - val_loss: 0.7685 - val_accuracy: 0.7391\n",
            "Epoch 417/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7554 - accuracy: 0.6911 - val_loss: 0.7862 - val_accuracy: 0.7198\n",
            "Epoch 418/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7466 - accuracy: 0.7110 - val_loss: 0.7658 - val_accuracy: 0.7440\n",
            "Epoch 419/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7368 - accuracy: 0.7128 - val_loss: 0.7632 - val_accuracy: 0.7343\n",
            "Epoch 420/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7647 - accuracy: 0.6983 - val_loss: 0.7675 - val_accuracy: 0.7391\n",
            "Epoch 421/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7442 - accuracy: 0.7110 - val_loss: 0.7756 - val_accuracy: 0.7391\n",
            "Epoch 422/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.7361 - accuracy: 0.6959 - val_loss: 0.7779 - val_accuracy: 0.7391\n",
            "Epoch 423/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7244 - accuracy: 0.7062 - val_loss: 0.7574 - val_accuracy: 0.7295\n",
            "Epoch 424/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7426 - accuracy: 0.6989 - val_loss: 0.7731 - val_accuracy: 0.7536\n",
            "Epoch 425/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.7225 - accuracy: 0.7110 - val_loss: 0.7473 - val_accuracy: 0.7391\n",
            "Epoch 426/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7586 - accuracy: 0.7080 - val_loss: 0.7638 - val_accuracy: 0.7536\n",
            "Epoch 427/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7629 - accuracy: 0.7013 - val_loss: 0.7458 - val_accuracy: 0.7488\n",
            "Epoch 428/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.7455 - accuracy: 0.6971 - val_loss: 0.7617 - val_accuracy: 0.7391\n",
            "Epoch 429/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.7594 - accuracy: 0.7074 - val_loss: 0.7610 - val_accuracy: 0.7440\n",
            "Epoch 430/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7548 - accuracy: 0.6971 - val_loss: 0.7681 - val_accuracy: 0.6908\n",
            "Epoch 431/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7341 - accuracy: 0.7044 - val_loss: 0.7689 - val_accuracy: 0.7343\n",
            "Epoch 432/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7339 - accuracy: 0.7170 - val_loss: 0.7685 - val_accuracy: 0.7246\n",
            "Epoch 433/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7301 - accuracy: 0.7152 - val_loss: 0.7467 - val_accuracy: 0.7488\n",
            "Epoch 434/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7236 - accuracy: 0.7074 - val_loss: 0.7463 - val_accuracy: 0.7488\n",
            "Epoch 435/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7343 - accuracy: 0.7013 - val_loss: 0.7493 - val_accuracy: 0.7585\n",
            "Epoch 436/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7259 - accuracy: 0.7213 - val_loss: 0.7822 - val_accuracy: 0.7053\n",
            "Epoch 437/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7481 - accuracy: 0.7116 - val_loss: 0.7590 - val_accuracy: 0.7488\n",
            "Epoch 438/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7189 - accuracy: 0.7158 - val_loss: 0.7455 - val_accuracy: 0.7440\n",
            "Epoch 439/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7115 - accuracy: 0.7140 - val_loss: 0.7600 - val_accuracy: 0.7440\n",
            "Epoch 440/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7476 - accuracy: 0.6923 - val_loss: 0.7492 - val_accuracy: 0.7488\n",
            "Epoch 441/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7453 - accuracy: 0.7074 - val_loss: 0.7713 - val_accuracy: 0.7391\n",
            "Epoch 442/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7350 - accuracy: 0.7116 - val_loss: 0.7573 - val_accuracy: 0.7488\n",
            "Epoch 443/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7488 - accuracy: 0.7152 - val_loss: 0.7388 - val_accuracy: 0.7536\n",
            "Epoch 444/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7352 - accuracy: 0.7062 - val_loss: 0.7508 - val_accuracy: 0.7536\n",
            "Epoch 445/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7229 - accuracy: 0.7201 - val_loss: 0.7430 - val_accuracy: 0.7585\n",
            "Epoch 446/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7304 - accuracy: 0.7074 - val_loss: 0.7461 - val_accuracy: 0.7585\n",
            "Epoch 447/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7197 - accuracy: 0.7122 - val_loss: 0.7427 - val_accuracy: 0.7343\n",
            "Epoch 448/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7198 - accuracy: 0.7122 - val_loss: 0.7367 - val_accuracy: 0.7536\n",
            "Epoch 449/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7594 - accuracy: 0.6904 - val_loss: 0.7416 - val_accuracy: 0.7488\n",
            "Epoch 450/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6833 - accuracy: 0.7285 - val_loss: 0.7352 - val_accuracy: 0.7488\n",
            "Epoch 451/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7435 - accuracy: 0.7068 - val_loss: 0.7437 - val_accuracy: 0.7729\n",
            "Epoch 452/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6978 - accuracy: 0.7152 - val_loss: 0.7379 - val_accuracy: 0.7633\n",
            "Epoch 453/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.7259 - accuracy: 0.7104 - val_loss: 0.7416 - val_accuracy: 0.7440\n",
            "Epoch 454/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7053 - accuracy: 0.7140 - val_loss: 0.7386 - val_accuracy: 0.7343\n",
            "Epoch 455/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.7050 - accuracy: 0.7189 - val_loss: 0.7264 - val_accuracy: 0.7536\n",
            "Epoch 456/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7068 - accuracy: 0.7195 - val_loss: 0.7470 - val_accuracy: 0.7295\n",
            "Epoch 457/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7069 - accuracy: 0.7255 - val_loss: 0.7348 - val_accuracy: 0.7391\n",
            "Epoch 458/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7160 - accuracy: 0.7255 - val_loss: 0.7417 - val_accuracy: 0.7536\n",
            "Epoch 459/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7130 - accuracy: 0.7122 - val_loss: 0.7406 - val_accuracy: 0.7633\n",
            "Epoch 460/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7253 - accuracy: 0.7025 - val_loss: 0.7471 - val_accuracy: 0.7391\n",
            "Epoch 461/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6965 - accuracy: 0.7237 - val_loss: 0.7394 - val_accuracy: 0.7585\n",
            "Epoch 462/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7235 - accuracy: 0.7201 - val_loss: 0.7402 - val_accuracy: 0.7488\n",
            "Epoch 463/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7116 - accuracy: 0.7116 - val_loss: 0.7399 - val_accuracy: 0.7633\n",
            "Epoch 464/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.7060 - accuracy: 0.7122 - val_loss: 0.7388 - val_accuracy: 0.7585\n",
            "Epoch 465/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6989 - accuracy: 0.7231 - val_loss: 0.7328 - val_accuracy: 0.7778\n",
            "Epoch 466/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6834 - accuracy: 0.7273 - val_loss: 0.7477 - val_accuracy: 0.7150\n",
            "Epoch 467/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6995 - accuracy: 0.7261 - val_loss: 0.7521 - val_accuracy: 0.7440\n",
            "Epoch 468/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7082 - accuracy: 0.7189 - val_loss: 0.7337 - val_accuracy: 0.7585\n",
            "Epoch 469/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6929 - accuracy: 0.7237 - val_loss: 0.7344 - val_accuracy: 0.7585\n",
            "Epoch 470/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6820 - accuracy: 0.7334 - val_loss: 0.7250 - val_accuracy: 0.7681\n",
            "Epoch 471/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7125 - accuracy: 0.7201 - val_loss: 0.7239 - val_accuracy: 0.7826\n",
            "Epoch 472/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6921 - accuracy: 0.7267 - val_loss: 0.7300 - val_accuracy: 0.7488\n",
            "Epoch 473/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6952 - accuracy: 0.7249 - val_loss: 0.7335 - val_accuracy: 0.7681\n",
            "Epoch 474/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7016 - accuracy: 0.7255 - val_loss: 0.7381 - val_accuracy: 0.7488\n",
            "Epoch 475/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7047 - accuracy: 0.7195 - val_loss: 0.7234 - val_accuracy: 0.7488\n",
            "Epoch 476/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6933 - accuracy: 0.7261 - val_loss: 0.7011 - val_accuracy: 0.7681\n",
            "Epoch 477/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6765 - accuracy: 0.7346 - val_loss: 0.7163 - val_accuracy: 0.7585\n",
            "Epoch 478/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6988 - accuracy: 0.7279 - val_loss: 0.7425 - val_accuracy: 0.7246\n",
            "Epoch 479/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7095 - accuracy: 0.7225 - val_loss: 0.7158 - val_accuracy: 0.7633\n",
            "Epoch 480/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6793 - accuracy: 0.7279 - val_loss: 0.6976 - val_accuracy: 0.7585\n",
            "Epoch 481/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6906 - accuracy: 0.7219 - val_loss: 0.7119 - val_accuracy: 0.7729\n",
            "Epoch 482/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6937 - accuracy: 0.7225 - val_loss: 0.7291 - val_accuracy: 0.7778\n",
            "Epoch 483/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6866 - accuracy: 0.7322 - val_loss: 0.7204 - val_accuracy: 0.7778\n",
            "Epoch 484/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6918 - accuracy: 0.7267 - val_loss: 0.7204 - val_accuracy: 0.7585\n",
            "Epoch 485/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7021 - accuracy: 0.7231 - val_loss: 0.7123 - val_accuracy: 0.7729\n",
            "Epoch 486/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6660 - accuracy: 0.7424 - val_loss: 0.7329 - val_accuracy: 0.7488\n",
            "Epoch 487/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6927 - accuracy: 0.7237 - val_loss: 0.7149 - val_accuracy: 0.7633\n",
            "Epoch 488/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.7060 - accuracy: 0.7037 - val_loss: 0.7174 - val_accuracy: 0.7536\n",
            "Epoch 489/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6667 - accuracy: 0.7394 - val_loss: 0.7094 - val_accuracy: 0.7536\n",
            "Epoch 490/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6666 - accuracy: 0.7382 - val_loss: 0.7274 - val_accuracy: 0.7778\n",
            "Epoch 491/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7050 - accuracy: 0.7183 - val_loss: 0.7414 - val_accuracy: 0.7440\n",
            "Epoch 492/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6862 - accuracy: 0.7424 - val_loss: 0.7186 - val_accuracy: 0.7633\n",
            "Epoch 493/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6744 - accuracy: 0.7225 - val_loss: 0.7273 - val_accuracy: 0.7488\n",
            "Epoch 494/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6779 - accuracy: 0.7364 - val_loss: 0.7320 - val_accuracy: 0.7681\n",
            "Epoch 495/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6611 - accuracy: 0.7424 - val_loss: 0.7274 - val_accuracy: 0.7536\n",
            "Epoch 496/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6565 - accuracy: 0.7527 - val_loss: 0.7255 - val_accuracy: 0.7440\n",
            "Epoch 497/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6931 - accuracy: 0.7249 - val_loss: 0.7297 - val_accuracy: 0.7440\n",
            "Epoch 498/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6809 - accuracy: 0.7364 - val_loss: 0.7246 - val_accuracy: 0.7585\n",
            "Epoch 499/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6688 - accuracy: 0.7412 - val_loss: 0.7158 - val_accuracy: 0.7536\n",
            "Epoch 500/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6906 - accuracy: 0.7255 - val_loss: 0.7380 - val_accuracy: 0.7391\n",
            "Epoch 501/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6529 - accuracy: 0.7352 - val_loss: 0.7342 - val_accuracy: 0.7681\n",
            "Epoch 502/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6729 - accuracy: 0.7340 - val_loss: 0.7317 - val_accuracy: 0.7440\n",
            "Epoch 503/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6713 - accuracy: 0.7134 - val_loss: 0.7160 - val_accuracy: 0.7536\n",
            "Epoch 504/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6406 - accuracy: 0.7497 - val_loss: 0.7093 - val_accuracy: 0.7585\n",
            "Epoch 505/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6737 - accuracy: 0.7352 - val_loss: 0.6981 - val_accuracy: 0.7536\n",
            "Epoch 506/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6693 - accuracy: 0.7340 - val_loss: 0.7128 - val_accuracy: 0.7778\n",
            "Epoch 507/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6671 - accuracy: 0.7461 - val_loss: 0.6994 - val_accuracy: 0.7729\n",
            "Epoch 508/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6646 - accuracy: 0.7406 - val_loss: 0.7239 - val_accuracy: 0.7633\n",
            "Epoch 509/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6514 - accuracy: 0.7443 - val_loss: 0.7125 - val_accuracy: 0.7536\n",
            "Epoch 510/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6635 - accuracy: 0.7376 - val_loss: 0.7008 - val_accuracy: 0.7971\n",
            "Epoch 511/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6722 - accuracy: 0.7424 - val_loss: 0.7139 - val_accuracy: 0.7633\n",
            "Epoch 512/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6343 - accuracy: 0.7430 - val_loss: 0.7001 - val_accuracy: 0.7440\n",
            "Epoch 513/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6742 - accuracy: 0.7437 - val_loss: 0.6839 - val_accuracy: 0.7729\n",
            "Epoch 514/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6504 - accuracy: 0.7497 - val_loss: 0.7157 - val_accuracy: 0.7391\n",
            "Epoch 515/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6701 - accuracy: 0.7388 - val_loss: 0.7092 - val_accuracy: 0.7729\n",
            "Epoch 516/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6413 - accuracy: 0.7449 - val_loss: 0.7045 - val_accuracy: 0.7585\n",
            "Epoch 517/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6430 - accuracy: 0.7491 - val_loss: 0.7225 - val_accuracy: 0.7536\n",
            "Epoch 518/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6541 - accuracy: 0.7437 - val_loss: 0.7153 - val_accuracy: 0.7729\n",
            "Epoch 519/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6486 - accuracy: 0.7424 - val_loss: 0.7205 - val_accuracy: 0.7778\n",
            "Epoch 520/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6555 - accuracy: 0.7358 - val_loss: 0.7113 - val_accuracy: 0.7633\n",
            "Epoch 521/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6617 - accuracy: 0.7455 - val_loss: 0.7063 - val_accuracy: 0.7585\n",
            "Epoch 522/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6481 - accuracy: 0.7485 - val_loss: 0.7234 - val_accuracy: 0.7536\n",
            "Epoch 523/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6536 - accuracy: 0.7424 - val_loss: 0.7079 - val_accuracy: 0.7681\n",
            "Epoch 524/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6451 - accuracy: 0.7509 - val_loss: 0.7366 - val_accuracy: 0.7391\n",
            "Epoch 525/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6286 - accuracy: 0.7539 - val_loss: 0.7025 - val_accuracy: 0.7633\n",
            "Epoch 526/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6449 - accuracy: 0.7461 - val_loss: 0.7179 - val_accuracy: 0.7729\n",
            "Epoch 527/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6613 - accuracy: 0.7473 - val_loss: 0.7063 - val_accuracy: 0.7681\n",
            "Epoch 528/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6365 - accuracy: 0.7612 - val_loss: 0.7057 - val_accuracy: 0.7633\n",
            "Epoch 529/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6531 - accuracy: 0.7491 - val_loss: 0.7149 - val_accuracy: 0.7729\n",
            "Epoch 530/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6428 - accuracy: 0.7334 - val_loss: 0.6886 - val_accuracy: 0.7681\n",
            "Epoch 531/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6615 - accuracy: 0.7382 - val_loss: 0.7137 - val_accuracy: 0.7585\n",
            "Epoch 532/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6163 - accuracy: 0.7624 - val_loss: 0.6944 - val_accuracy: 0.7585\n",
            "Epoch 533/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6566 - accuracy: 0.7322 - val_loss: 0.7057 - val_accuracy: 0.7633\n",
            "Epoch 534/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6448 - accuracy: 0.7412 - val_loss: 0.7113 - val_accuracy: 0.7826\n",
            "Epoch 535/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6444 - accuracy: 0.7455 - val_loss: 0.6892 - val_accuracy: 0.7778\n",
            "Epoch 536/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6293 - accuracy: 0.7612 - val_loss: 0.7007 - val_accuracy: 0.7681\n",
            "Epoch 537/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6217 - accuracy: 0.7533 - val_loss: 0.7125 - val_accuracy: 0.7488\n",
            "Epoch 538/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6218 - accuracy: 0.7582 - val_loss: 0.6906 - val_accuracy: 0.7681\n",
            "Epoch 539/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6337 - accuracy: 0.7576 - val_loss: 0.6971 - val_accuracy: 0.7681\n",
            "Epoch 540/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6210 - accuracy: 0.7582 - val_loss: 0.6784 - val_accuracy: 0.7585\n",
            "Epoch 541/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6424 - accuracy: 0.7467 - val_loss: 0.6907 - val_accuracy: 0.7874\n",
            "Epoch 542/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6477 - accuracy: 0.7491 - val_loss: 0.6945 - val_accuracy: 0.7778\n",
            "Epoch 543/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6075 - accuracy: 0.7642 - val_loss: 0.6824 - val_accuracy: 0.7826\n",
            "Epoch 544/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6295 - accuracy: 0.7618 - val_loss: 0.7020 - val_accuracy: 0.7826\n",
            "Epoch 545/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6383 - accuracy: 0.7515 - val_loss: 0.6999 - val_accuracy: 0.7778\n",
            "Epoch 546/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6171 - accuracy: 0.7521 - val_loss: 0.7003 - val_accuracy: 0.7729\n",
            "Epoch 547/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6286 - accuracy: 0.7551 - val_loss: 0.6943 - val_accuracy: 0.7778\n",
            "Epoch 548/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6355 - accuracy: 0.7533 - val_loss: 0.7081 - val_accuracy: 0.7681\n",
            "Epoch 549/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6175 - accuracy: 0.7539 - val_loss: 0.6929 - val_accuracy: 0.7681\n",
            "Epoch 550/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6279 - accuracy: 0.7606 - val_loss: 0.7049 - val_accuracy: 0.7778\n",
            "Epoch 551/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6250 - accuracy: 0.7545 - val_loss: 0.7082 - val_accuracy: 0.7633\n",
            "Epoch 552/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6380 - accuracy: 0.7576 - val_loss: 0.7243 - val_accuracy: 0.7778\n",
            "Epoch 553/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6393 - accuracy: 0.7473 - val_loss: 0.7029 - val_accuracy: 0.7681\n",
            "Epoch 554/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6199 - accuracy: 0.7570 - val_loss: 0.6840 - val_accuracy: 0.7681\n",
            "Epoch 555/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6232 - accuracy: 0.7551 - val_loss: 0.7027 - val_accuracy: 0.7633\n",
            "Epoch 556/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6222 - accuracy: 0.7563 - val_loss: 0.7049 - val_accuracy: 0.7536\n",
            "Epoch 557/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6222 - accuracy: 0.7666 - val_loss: 0.7119 - val_accuracy: 0.7729\n",
            "Epoch 558/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6353 - accuracy: 0.7455 - val_loss: 0.7223 - val_accuracy: 0.7633\n",
            "Epoch 559/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6034 - accuracy: 0.7660 - val_loss: 0.6919 - val_accuracy: 0.7729\n",
            "Epoch 560/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6158 - accuracy: 0.7588 - val_loss: 0.6894 - val_accuracy: 0.7681\n",
            "Epoch 561/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6498 - accuracy: 0.7334 - val_loss: 0.6894 - val_accuracy: 0.7826\n",
            "Epoch 562/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6130 - accuracy: 0.7636 - val_loss: 0.6901 - val_accuracy: 0.7729\n",
            "Epoch 563/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5944 - accuracy: 0.7672 - val_loss: 0.6959 - val_accuracy: 0.7585\n",
            "Epoch 564/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6198 - accuracy: 0.7443 - val_loss: 0.6934 - val_accuracy: 0.7633\n",
            "Epoch 565/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6067 - accuracy: 0.7570 - val_loss: 0.6971 - val_accuracy: 0.7633\n",
            "Epoch 566/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6243 - accuracy: 0.7563 - val_loss: 0.6889 - val_accuracy: 0.7633\n",
            "Epoch 567/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6280 - accuracy: 0.7539 - val_loss: 0.6805 - val_accuracy: 0.7778\n",
            "Epoch 568/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6015 - accuracy: 0.7624 - val_loss: 0.7023 - val_accuracy: 0.7729\n",
            "Epoch 569/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6149 - accuracy: 0.7563 - val_loss: 0.7045 - val_accuracy: 0.7923\n",
            "Epoch 570/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6024 - accuracy: 0.7654 - val_loss: 0.6949 - val_accuracy: 0.7826\n",
            "Epoch 571/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6233 - accuracy: 0.7503 - val_loss: 0.6750 - val_accuracy: 0.7826\n",
            "Epoch 572/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6140 - accuracy: 0.7648 - val_loss: 0.6677 - val_accuracy: 0.7729\n",
            "Epoch 573/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6096 - accuracy: 0.7594 - val_loss: 0.6853 - val_accuracy: 0.7729\n",
            "Epoch 574/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6114 - accuracy: 0.7690 - val_loss: 0.6906 - val_accuracy: 0.7633\n",
            "Epoch 575/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6095 - accuracy: 0.7684 - val_loss: 0.7044 - val_accuracy: 0.7536\n",
            "Epoch 576/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5967 - accuracy: 0.7594 - val_loss: 0.6794 - val_accuracy: 0.7729\n",
            "Epoch 577/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6003 - accuracy: 0.7666 - val_loss: 0.6933 - val_accuracy: 0.7874\n",
            "Epoch 578/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6115 - accuracy: 0.7648 - val_loss: 0.6912 - val_accuracy: 0.7923\n",
            "Epoch 579/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6056 - accuracy: 0.7648 - val_loss: 0.6999 - val_accuracy: 0.7488\n",
            "Epoch 580/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5832 - accuracy: 0.7690 - val_loss: 0.6995 - val_accuracy: 0.7585\n",
            "Epoch 581/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5995 - accuracy: 0.7563 - val_loss: 0.6683 - val_accuracy: 0.7826\n",
            "Epoch 582/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5844 - accuracy: 0.7678 - val_loss: 0.6797 - val_accuracy: 0.7729\n",
            "Epoch 583/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6070 - accuracy: 0.7521 - val_loss: 0.6834 - val_accuracy: 0.7778\n",
            "Epoch 584/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6151 - accuracy: 0.7551 - val_loss: 0.6624 - val_accuracy: 0.7633\n",
            "Epoch 585/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6098 - accuracy: 0.7570 - val_loss: 0.6661 - val_accuracy: 0.7778\n",
            "Epoch 586/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6058 - accuracy: 0.7618 - val_loss: 0.6761 - val_accuracy: 0.7633\n",
            "Epoch 587/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5982 - accuracy: 0.7709 - val_loss: 0.6823 - val_accuracy: 0.7729\n",
            "Epoch 588/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5931 - accuracy: 0.7715 - val_loss: 0.6822 - val_accuracy: 0.7536\n",
            "Epoch 589/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6158 - accuracy: 0.7557 - val_loss: 0.6858 - val_accuracy: 0.7681\n",
            "Epoch 590/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6000 - accuracy: 0.7739 - val_loss: 0.6842 - val_accuracy: 0.7826\n",
            "Epoch 591/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5826 - accuracy: 0.7624 - val_loss: 0.6768 - val_accuracy: 0.7874\n",
            "Epoch 592/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5913 - accuracy: 0.7769 - val_loss: 0.7041 - val_accuracy: 0.7488\n",
            "Epoch 593/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5849 - accuracy: 0.7757 - val_loss: 0.6926 - val_accuracy: 0.7826\n",
            "Epoch 594/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6241 - accuracy: 0.7582 - val_loss: 0.7196 - val_accuracy: 0.7440\n",
            "Epoch 595/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5924 - accuracy: 0.7666 - val_loss: 0.6738 - val_accuracy: 0.7633\n",
            "Epoch 596/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5870 - accuracy: 0.7582 - val_loss: 0.6752 - val_accuracy: 0.7681\n",
            "Epoch 597/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5706 - accuracy: 0.7733 - val_loss: 0.6954 - val_accuracy: 0.7633\n",
            "Epoch 598/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5675 - accuracy: 0.7648 - val_loss: 0.7099 - val_accuracy: 0.7585\n",
            "Epoch 599/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6087 - accuracy: 0.7636 - val_loss: 0.6849 - val_accuracy: 0.7729\n",
            "Epoch 600/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5646 - accuracy: 0.7799 - val_loss: 0.6942 - val_accuracy: 0.7826\n",
            "Epoch 601/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5726 - accuracy: 0.7763 - val_loss: 0.6904 - val_accuracy: 0.7536\n",
            "Epoch 602/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5870 - accuracy: 0.7733 - val_loss: 0.6695 - val_accuracy: 0.7729\n",
            "Epoch 603/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5968 - accuracy: 0.7636 - val_loss: 0.6859 - val_accuracy: 0.7681\n",
            "Epoch 604/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6022 - accuracy: 0.7576 - val_loss: 0.6763 - val_accuracy: 0.7729\n",
            "Epoch 605/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5732 - accuracy: 0.7793 - val_loss: 0.6814 - val_accuracy: 0.7681\n",
            "Epoch 606/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5810 - accuracy: 0.7612 - val_loss: 0.6885 - val_accuracy: 0.7971\n",
            "Epoch 607/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5715 - accuracy: 0.7781 - val_loss: 0.6723 - val_accuracy: 0.7729\n",
            "Epoch 608/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5905 - accuracy: 0.7690 - val_loss: 0.6881 - val_accuracy: 0.7633\n",
            "Epoch 609/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5713 - accuracy: 0.7775 - val_loss: 0.7024 - val_accuracy: 0.7295\n",
            "Epoch 610/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5983 - accuracy: 0.7648 - val_loss: 0.6775 - val_accuracy: 0.7729\n",
            "Epoch 611/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5838 - accuracy: 0.7721 - val_loss: 0.6886 - val_accuracy: 0.7874\n",
            "Epoch 612/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5794 - accuracy: 0.7666 - val_loss: 0.6734 - val_accuracy: 0.7681\n",
            "Epoch 613/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5698 - accuracy: 0.7787 - val_loss: 0.6744 - val_accuracy: 0.7681\n",
            "Epoch 614/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5668 - accuracy: 0.7715 - val_loss: 0.6699 - val_accuracy: 0.7729\n",
            "Epoch 615/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5921 - accuracy: 0.7696 - val_loss: 0.6710 - val_accuracy: 0.7826\n",
            "Epoch 616/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5722 - accuracy: 0.7690 - val_loss: 0.6936 - val_accuracy: 0.7633\n",
            "Epoch 617/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5731 - accuracy: 0.7721 - val_loss: 0.6834 - val_accuracy: 0.7826\n",
            "Epoch 618/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5906 - accuracy: 0.7690 - val_loss: 0.6970 - val_accuracy: 0.7681\n",
            "Epoch 619/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5798 - accuracy: 0.7703 - val_loss: 0.6717 - val_accuracy: 0.7633\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(cnnhistory.history['loss'])\n",
        "plt.plot(cnnhistory.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train','test'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "oQYnuaCrDH_A",
        "outputId": "8f95d57c-38f1-4a8c-c82d-d0e0b39755c5"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(cnnhistory.history['accuracy'])\n",
        "plt.plot(cnnhistory.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train','test'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "IFkTuO8nDNdq",
        "outputId": "45b09038-72fd-46d0-92b8-2ba3266a9947"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model.predict(x_testcnn)"
      ],
      "metadata": {
        "id": "A2xtrN5wDQgY"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_f_ohjXKDUpY",
        "outputId": "4fe3be11-6a9c-4121-e0d3-699519a0af52"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[2.3104550e-01, 1.9136849e-01, 2.1748328e-01, 1.7422740e-01,\n",
              "        1.3346100e-01, 5.2414283e-02],\n",
              "       [3.4505187e-04, 1.2650544e-05, 8.2076781e-07, 9.8724908e-01,\n",
              "        1.9915702e-04, 1.2193248e-02],\n",
              "       [1.5639557e-01, 9.2233181e-02, 1.2747410e-01, 2.8588828e-01,\n",
              "        6.7210354e-02, 2.7079844e-01],\n",
              "       ...,\n",
              "       [3.3445828e-04, 7.8479734e-06, 6.8993936e-03, 1.2980846e-03,\n",
              "        9.8225635e-01, 9.2037804e-03],\n",
              "       [3.3234977e-05, 5.9162617e-01, 3.9669269e-01, 5.5014407e-03,\n",
              "        1.9586901e-03, 4.1877623e-03],\n",
              "       [5.4774529e-05, 3.5136894e-05, 2.0627728e-02, 2.8254959e-04,\n",
              "        9.6604878e-01, 1.2951094e-02]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cmA2bFgsDW3D",
        "outputId": "b1728362-cc98-4b4a-c1ce-93d4926a7f30"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([3, 3, 3, 0, 4, 4, 1, 2, 5, 0, 5, 3, 2, 2, 1, 4, 4, 5, 2, 4, 1, 2,\n",
              "       3, 5, 4, 2, 1, 2, 2, 2, 2, 5, 2, 5, 3, 1, 2, 0, 4, 5, 2, 3, 2, 2,\n",
              "       5, 2, 0, 1, 3, 4, 4, 5, 1, 1, 4, 4, 5, 1, 1, 1, 0, 1, 5, 0, 4, 1,\n",
              "       1, 0, 1, 4, 1, 0, 4, 1, 3, 1, 2, 2, 1, 2, 3, 0, 5, 3, 5, 5, 2, 4,\n",
              "       5, 1, 5, 1, 5, 3, 4, 1, 4, 1, 5, 4, 5, 1, 2, 1, 1, 5, 1, 3, 2, 5,\n",
              "       2, 1, 3, 5, 4, 4, 0, 0, 3, 1, 2, 2, 3, 5, 1, 5, 3, 4, 2, 2, 0, 2,\n",
              "       2, 5, 5, 0, 3, 3, 2, 2, 0, 3, 4, 0, 4, 2, 4, 5, 4, 1, 5, 3, 2, 2,\n",
              "       5, 4, 3, 3, 4, 3, 3, 4, 1, 5, 2, 3, 2, 2, 0, 2, 1, 3, 1, 2, 2, 5,\n",
              "       5, 1, 4, 2, 2, 1, 1, 3, 3, 5, 5, 2, 5, 1, 5, 0, 3, 3, 0, 5, 1, 4,\n",
              "       1, 4, 2, 5, 5, 1, 4, 2, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_Ytest = y_test.astype(int)"
      ],
      "metadata": {
        "id": "0PHDKWJWDY3g"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_Ytest"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k68v2i-pDbZE",
        "outputId": "50474984-6533-470b-e119-70bfe2ebec97"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([3, 3, 3, 0, 4, 4, 1, 2, 5, 0, 5, 3, 2, 2, 1, 4, 4, 5, 2, 4, 1, 2,\n",
              "       3, 5, 4, 2, 1, 2, 2, 2, 2, 5, 2, 5, 3, 1, 2, 0, 4, 5, 2, 3, 2, 2,\n",
              "       5, 2, 0, 1, 3, 4, 4, 5, 1, 1, 4, 4, 5, 1, 1, 1, 0, 1, 5, 0, 4, 1,\n",
              "       1, 0, 1, 4, 1, 0, 4, 1, 3, 1, 2, 2, 1, 2, 3, 0, 5, 3, 5, 5, 2, 4,\n",
              "       5, 1, 5, 1, 5, 3, 4, 1, 4, 1, 5, 4, 5, 1, 2, 1, 1, 5, 1, 3, 2, 5,\n",
              "       2, 1, 3, 5, 4, 4, 0, 0, 3, 1, 2, 2, 3, 5, 1, 5, 3, 4, 2, 2, 0, 2,\n",
              "       2, 5, 5, 0, 3, 3, 2, 2, 0, 3, 4, 0, 4, 2, 4, 5, 4, 1, 5, 3, 2, 2,\n",
              "       5, 4, 3, 3, 4, 3, 3, 4, 1, 5, 2, 3, 2, 2, 0, 2, 1, 3, 1, 2, 2, 5,\n",
              "       5, 1, 4, 2, 2, 1, 1, 3, 3, 5, 5, 2, 5, 1, 5, 0, 3, 3, 0, 5, 1, 4,\n",
              "       1, 4, 2, 5, 5, 1, 4, 2, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds1=predictions.argmax(axis=1)\n",
        "preds1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4_cAI39VFhtp",
        "outputId": "c16f814f-32e5-49bb-911f-debd6fb7f189"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 3, 3, 0, 4, 4, 1, 2, 5, 1, 4, 3, 2, 2, 1, 4, 4, 3, 2, 4, 2, 2,\n",
              "       2, 3, 4, 2, 1, 1, 2, 2, 2, 5, 2, 5, 3, 1, 2, 0, 4, 2, 2, 3, 2, 2,\n",
              "       3, 2, 1, 1, 3, 4, 4, 5, 1, 1, 4, 4, 5, 1, 1, 1, 3, 1, 2, 1, 4, 1,\n",
              "       1, 1, 1, 4, 1, 2, 4, 3, 5, 5, 2, 2, 1, 2, 1, 0, 3, 3, 5, 2, 2, 5,\n",
              "       3, 1, 5, 1, 5, 3, 2, 2, 4, 1, 5, 4, 5, 1, 2, 1, 1, 5, 1, 3, 2, 5,\n",
              "       1, 1, 3, 5, 4, 4, 0, 0, 3, 1, 1, 2, 1, 5, 1, 3, 3, 5, 2, 2, 1, 4,\n",
              "       2, 3, 2, 0, 3, 3, 2, 4, 0, 3, 4, 1, 4, 4, 4, 2, 4, 1, 5, 3, 2, 2,\n",
              "       5, 4, 3, 3, 4, 5, 3, 4, 1, 5, 2, 3, 2, 2, 0, 2, 1, 3, 1, 4, 4, 3,\n",
              "       4, 1, 4, 2, 4, 1, 1, 3, 3, 5, 5, 2, 5, 1, 4, 1, 3, 3, 2, 4, 2, 4,\n",
              "       1, 4, 0, 2, 4, 2, 4, 1, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "abc = preds1.astype(int).flatten()"
      ],
      "metadata": {
        "id": "H4WEmM60NfQn"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "c = confusion_matrix(new_Ytest, abc) \n",
        "c"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bKEBeEBlFjB8",
        "outputId": "b7fef87d-aeba-463a-c01b-d7dbebbc9372"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 8,  7,  2,  1,  0,  0],\n",
              "       [ 0, 35,  4,  1,  0,  1],\n",
              "       [ 1,  4, 34,  0,  6,  0],\n",
              "       [ 1,  2,  1, 25,  0,  2],\n",
              "       [ 0,  0,  1,  0, 30,  2],\n",
              "       [ 0,  0,  6,  8,  5, 20]])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m4RjG7LWLSQx",
        "outputId": "25291334-e658-405c-fe17-594ceb3b716f"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([3, 3, 3, 0, 4, 4, 1, 2, 5, 0, 5, 3, 2, 2, 1, 4, 4, 5, 2, 4, 1, 2,\n",
              "       3, 5, 4, 2, 1, 2, 2, 2, 2, 5, 2, 5, 3, 1, 2, 0, 4, 5, 2, 3, 2, 2,\n",
              "       5, 2, 0, 1, 3, 4, 4, 5, 1, 1, 4, 4, 5, 1, 1, 1, 0, 1, 5, 0, 4, 1,\n",
              "       1, 0, 1, 4, 1, 0, 4, 1, 3, 1, 2, 2, 1, 2, 3, 0, 5, 3, 5, 5, 2, 4,\n",
              "       5, 1, 5, 1, 5, 3, 4, 1, 4, 1, 5, 4, 5, 1, 2, 1, 1, 5, 1, 3, 2, 5,\n",
              "       2, 1, 3, 5, 4, 4, 0, 0, 3, 1, 2, 2, 3, 5, 1, 5, 3, 4, 2, 2, 0, 2,\n",
              "       2, 5, 5, 0, 3, 3, 2, 2, 0, 3, 4, 0, 4, 2, 4, 5, 4, 1, 5, 3, 2, 2,\n",
              "       5, 4, 3, 3, 4, 3, 3, 4, 1, 5, 2, 3, 2, 2, 0, 2, 1, 3, 1, 2, 2, 5,\n",
              "       5, 1, 4, 2, 2, 1, 1, 3, 3, 5, 5, 2, 5, 1, 5, 0, 3, 3, 0, 5, 1, 4,\n",
              "       1, 4, 2, 5, 5, 1, 4, 2, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss, acc =model.evaluate(x_testcnn, y_test)\n",
        "print(\"Restored model, accuracy: {:5.2f}%\".format(100*acc))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n3kzoqPkDqqS",
        "outputId": "3d5cd2f9-8a44-473f-941e-be74c670b7a5"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7/7 [==============================] - 0s 3ms/step - loss: 0.7095 - accuracy: 0.7343\n",
            "Restored model, accuracy: 73.43%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss, acc =model.evaluate(X_train, y_train)\n",
        "print(\"Restored model train, accuracy: {:5.2f}%\".format(100*acc))"
      ],
      "metadata": {
        "id": "fJDTGH_OUX0z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aee7d6e5-60fb-44dc-b634-82086d31285f"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5131 - accuracy: 0.8307\n",
            "Restored model train, accuracy: 83.07%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix,accuracy_score\n",
        "import seaborn as sn\n",
        "\n",
        "print(classification_report(new_Ytest,abc))\n",
        "\n",
        "acc = float(accuracy_score(new_Ytest,abc))*100\n",
        "print(\"----accuracy score %s ----\" % acc)\n",
        "\n",
        "cm = confusion_matrix(new_Ytest,abc)\n",
        "#df_cm = pd.DataFrame(cm)\n",
        "class_names = ['neutral','calm', 'happy','sad','angry', 'fearful' ]\n",
        "df_cm = pd.DataFrame(cm, index=class_names, columns=class_names,)\n",
        "sn.heatmap(df_cm, annot=True, fmt='')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 512
        },
        "id": "SfSC3El94LZg",
        "outputId": "cd4f27ca-2ac6-4e49-8ace-1cedab3b5c5e"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.44      0.57        18\n",
            "           1       0.73      0.85      0.79        41\n",
            "           2       0.71      0.76      0.73        45\n",
            "           3       0.71      0.81      0.76        31\n",
            "           4       0.73      0.91      0.81        33\n",
            "           5       0.80      0.51      0.62        39\n",
            "\n",
            "    accuracy                           0.73       207\n",
            "   macro avg       0.75      0.71      0.71       207\n",
            "weighted avg       0.74      0.73      0.72       207\n",
            "\n",
            "----accuracy score 73.42995169082126 ----\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "A6UOIsB2xKek"
      },
      "execution_count": 28,
      "outputs": []
    }
  ]
}