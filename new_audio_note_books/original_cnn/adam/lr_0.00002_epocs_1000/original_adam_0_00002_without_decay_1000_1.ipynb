{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "original_adam_0.00002_without decay_1000_1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9SRCO-a_AlH5",
        "outputId": "fa06c42d-f263-4beb-e4f4-aabc1ce95f02"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install librosa"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Lo4mUwG9RMd",
        "outputId": "abf27995-2a18-44a0-e689-05d20af959a7"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.7/dist-packages (0.8.1)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.1.0)\n",
            "Requirement already satisfied: audioread>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (2.1.9)\n",
            "Requirement already satisfied: decorator>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied: numba>=0.43.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (0.51.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (21.3)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.21.6)\n",
            "Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.6.0)\n",
            "Requirement already satisfied: soundfile>=0.10.2 in /usr/local/lib/python3.7/dist-packages (from librosa) (0.10.3.post1)\n",
            "Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.0.2)\n",
            "Requirement already satisfied: resampy>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from librosa) (0.2.2)\n",
            "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba>=0.43.0->librosa) (0.34.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba>=0.43.0->librosa) (57.4.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->librosa) (3.0.9)\n",
            "Requirement already satisfied: appdirs>=1.3.0 in /usr/local/lib/python3.7/dist-packages (from pooch>=1.0->librosa) (1.4.4)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from pooch>=1.0->librosa) (2.23.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2022.5.18.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2.10)\n",
            "Requirement already satisfied: six>=1.3 in /usr/local/lib/python3.7/dist-packages (from resampy>=0.2.2->librosa) (1.15.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn!=0.19.0,>=0.14.0->librosa) (3.1.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.7/dist-packages (from soundfile>=0.10.2->librosa) (1.15.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.0->soundfile>=0.10.2->librosa) (2.21)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HJjcbxwy46bG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "51897c9a-4f58-4ab0-aac4-de9fd2ef7bc7"
      },
      "source": [
        "# Orignial Notebook: https://github.com/MITESHPUTHRANNEU/Speech-Emotion-Analyzer/blob/master/final_results_gender_test.ipynb\n",
        "# This notebook author: Reza Chu\n",
        "# Last Editing Date: 31st May 2019\n",
        "\n",
        "## Python\n",
        "import os\n",
        "import random\n",
        "import sys\n",
        "\n",
        "import IPython\n",
        "from IPython.display import Audio\n",
        "from IPython.display import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "## Package\n",
        "import glob \n",
        "import keras\n",
        "import IPython.display as ipd\n",
        "import librosa\n",
        "import librosa.display\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import plotly.graph_objs as go\n",
        "import plotly.offline as py\n",
        "import plotly.tools as tls\n",
        "import seaborn as sns\n",
        "import scipy.io.wavfile\n",
        "import tensorflow as tf\n",
        "py.init_notebook_mode(connected=True)\n",
        "\n",
        "## Keras\n",
        "from keras import regularizers\n",
        "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping\n",
        "from keras.callbacks import  History, ReduceLROnPlateau, CSVLogger\n",
        "from keras.models import Model, Sequential\n",
        "from keras.layers import Dense, Embedding, LSTM\n",
        "from keras.layers import Input, Flatten, Dropout, Activation, BatchNormalization\n",
        "from keras.layers import Conv1D, MaxPooling1D, AveragePooling1D\n",
        "from keras.preprocessing import sequence\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.utils import np_utils\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "## Sklearn\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "## Rest\n",
        "from scipy.fftpack import fft\n",
        "from scipy import signal\n",
        "from scipy.io import wavfile\n",
        "from tqdm import tqdm\n",
        "\n",
        "input_duration=3\n",
        "# % pylab inline"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "        <script type=\"text/javascript\">\n",
              "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
              "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
              "        if (typeof require !== 'undefined') {\n",
              "        require.undef(\"plotly\");\n",
              "        requirejs.config({\n",
              "            paths: {\n",
              "                'plotly': ['https://cdn.plot.ly/plotly-2.8.3.min']\n",
              "            }\n",
              "        });\n",
              "        require(['plotly'], function(Plotly) {\n",
              "            window._Plotly = Plotly;\n",
              "        });\n",
              "        }\n",
              "        </script>\n",
              "        "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Saving joblib files to not load them again with the loop above\n",
        "\n",
        "# import joblib\n",
        "\n",
        "# X_name = 'x.joblib'\n",
        "# y_name = 'y.joblib'\n",
        "# save_dir = '/content/drive/My Drive/graduation project/audio/paper_code/features'\n",
        "\n",
        "# savedX = joblib.dump(X, os.path.join(save_dir, X_name))\n",
        "# savedy = joblib.dump(y, os.path.join(save_dir, y_name))"
      ],
      "metadata": {
        "id": "UCzic8rlDcuk"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Loading saved models\n",
        "import joblib\n",
        "X = joblib.load('/content/drive/My Drive/graduation project/audio/paper_code/features/x.joblib')\n",
        "y = joblib.load('/content/drive/My Drive/graduation project/audio/paper_code/features/y.joblib')"
      ],
      "metadata": {
        "id": "Q35CN6zDrzg1"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7PSTurzjCo5K",
        "outputId": "90b7df21-c60a-4ffe-b525-68146082b39e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2068, 40)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.1 ,shuffle = True\n",
        "                                                    , random_state=42)\n",
        "X_train , X_valid, y_train, y_valid = train_test_split(X_train,y_train, test_size=0.1112305212 , shuffle = True \n",
        "                                                       , random_state=42)"
      ],
      "metadata": {
        "id": "Ai4Fy5cPCiq1"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "x_traincnn = np.expand_dims(X_train, axis=2)\n",
        "x_testcnn = np.expand_dims(X_test, axis=2)\n",
        "X_valid= np.expand_dims(X_valid, axis=2)"
      ],
      "metadata": {
        "id": "tp1Fm5K3CEXu"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_traincnn.shape, x_testcnn.shape , X_valid.shape\n",
        "#1861"
      ],
      "metadata": {
        "id": "RI0MxoIPBws5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "07e8333c-8537-43c0-97bd-215449d3bb0e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1654, 40, 1), (207, 40, 1), (207, 40, 1))"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oALhiMUd9G2Y",
        "outputId": "af2fa60e-cb99-4938-8746-71a38fb07b7d"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (2.8.2+zzzcolab20220527125636)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.5.3)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (4.2.0)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.46.3)\n",
            "Requirement already satisfied: tensorflow-estimator<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (14.0.1)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.21.6)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.17.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow) (57.4.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.26.0)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.0.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow) (1.5.2)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.23.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.35.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.6.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (3.3.7)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.8.1)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (4.11.4)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (3.8.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2022.5.18.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (1.24.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (3.2.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from keras.preprocessing import sequence\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from keras.layers import Input, Flatten, Dropout, Activation\n",
        "from keras.layers import Conv1D, MaxPooling1D\n",
        "from keras.models import Model\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras import optimizers\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv1D(128, 8,padding='same', #classifier.add(Convolution2D(64, (3, 3), padding = 'same', input_shape = (128, 128, 3), activation = 'relu'))\n",
        "                 input_shape=(40,1)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(MaxPooling1D(pool_size=(5)))\n",
        "\n",
        "\n",
        "model.add(Conv1D(256,8,padding='same',))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(MaxPooling1D(pool_size=(5)))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(256))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(256))\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "model.add(Dense(6))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "opt = tf.keras.optimizers.Adam(lr=0.00002 , decay=0.0)\n",
        "#opt = tf.keras.optimizers.RMSprop(lr=0.0001, rho=0.9, epsilon=1e-07, decay=0.0)\n",
        "#opt = tf.keras.optimizers.SGD(lr=0.001, momentum=0.0, decay=0.0, nesterov=False)"
      ],
      "metadata": {
        "id": "g74fXWVAC4Cr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "64a15386-5f12-44ac-9bd0-1c02d1852b22"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning:\n",
            "\n",
            "The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H6ukOxAGC_I4",
        "outputId": "4cec3fd1-7a3d-4007-ca37-60ddfe846a2e"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d (Conv1D)             (None, 40, 128)           1152      \n",
            "                                                                 \n",
            " activation (Activation)     (None, 40, 128)           0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 40, 128)           0         \n",
            "                                                                 \n",
            " max_pooling1d (MaxPooling1D  (None, 8, 128)           0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv1d_1 (Conv1D)           (None, 8, 256)            262400    \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 8, 256)            0         \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 8, 256)            0         \n",
            "                                                                 \n",
            " max_pooling1d_1 (MaxPooling  (None, 1, 256)           0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 256)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 256)               65792     \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 256)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 256)               65792     \n",
            "                                                                 \n",
            " activation_3 (Activation)   (None, 256)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 6)                 1542      \n",
            "                                                                 \n",
            " activation_4 (Activation)   (None, 6)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 396,678\n",
            "Trainable params: 396,678\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='sparse_categorical_crossentropy',\n",
        "              optimizer=opt,\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "AbMlLNk4DCBM"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an Instance of Early Stopping Callback.\n",
        "early_stopping_callback = EarlyStopping(monitor = 'val_loss', patience = 25, mode = 'min', restore_best_weights = True)\n",
        "\n",
        "cnnhistory=model.fit(x_traincnn, y_train, batch_size=16, epochs=1000 , shuffle = True, \n",
        "                     validation_data=(X_valid, y_valid) \n",
        "                     , callbacks = [early_stopping_callback]\n",
        "                     )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RI1v2AuADFhy",
        "outputId": "a2baa4a8-875e-410c-c539-c4e0c4b26fb9"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "104/104 [==============================] - 4s 8ms/step - loss: 6.4939 - accuracy: 0.1759 - val_loss: 2.0773 - val_accuracy: 0.1498\n",
            "Epoch 2/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 5.0148 - accuracy: 0.1699 - val_loss: 2.0587 - val_accuracy: 0.1981\n",
            "Epoch 3/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 4.2337 - accuracy: 0.1862 - val_loss: 1.8277 - val_accuracy: 0.2126\n",
            "Epoch 4/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 3.7155 - accuracy: 0.1904 - val_loss: 1.8515 - val_accuracy: 0.1691\n",
            "Epoch 5/1000\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 3.4419 - accuracy: 0.1868 - val_loss: 1.7968 - val_accuracy: 0.1304\n",
            "Epoch 6/1000\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 3.2115 - accuracy: 0.1826 - val_loss: 1.7596 - val_accuracy: 0.2271\n",
            "Epoch 7/1000\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 2.9428 - accuracy: 0.2092 - val_loss: 1.7154 - val_accuracy: 0.2560\n",
            "Epoch 8/1000\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 2.9092 - accuracy: 0.1868 - val_loss: 1.7898 - val_accuracy: 0.1932\n",
            "Epoch 9/1000\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 2.5977 - accuracy: 0.1983 - val_loss: 1.7727 - val_accuracy: 0.2367\n",
            "Epoch 10/1000\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 2.5373 - accuracy: 0.2213 - val_loss: 1.7841 - val_accuracy: 0.2029\n",
            "Epoch 11/1000\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 2.4746 - accuracy: 0.1983 - val_loss: 1.7555 - val_accuracy: 0.2077\n",
            "Epoch 12/1000\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 2.4060 - accuracy: 0.2092 - val_loss: 1.7413 - val_accuracy: 0.2464\n",
            "Epoch 13/1000\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 2.3469 - accuracy: 0.1995 - val_loss: 1.7192 - val_accuracy: 0.3285\n",
            "Epoch 14/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 2.2819 - accuracy: 0.2183 - val_loss: 1.7037 - val_accuracy: 0.2560\n",
            "Epoch 15/1000\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 2.2458 - accuracy: 0.2037 - val_loss: 1.7052 - val_accuracy: 0.2512\n",
            "Epoch 16/1000\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 2.2134 - accuracy: 0.2346 - val_loss: 1.7299 - val_accuracy: 0.2609\n",
            "Epoch 17/1000\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 2.1425 - accuracy: 0.2279 - val_loss: 1.6965 - val_accuracy: 0.2850\n",
            "Epoch 18/1000\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 2.1502 - accuracy: 0.2062 - val_loss: 1.7055 - val_accuracy: 0.2995\n",
            "Epoch 19/1000\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 2.0916 - accuracy: 0.2207 - val_loss: 1.7157 - val_accuracy: 0.2222\n",
            "Epoch 20/1000\n",
            "104/104 [==============================] - 1s 9ms/step - loss: 2.0534 - accuracy: 0.2201 - val_loss: 1.6990 - val_accuracy: 0.2415\n",
            "Epoch 21/1000\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 2.0098 - accuracy: 0.2279 - val_loss: 1.6851 - val_accuracy: 0.2947\n",
            "Epoch 22/1000\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 2.0012 - accuracy: 0.2322 - val_loss: 1.7230 - val_accuracy: 0.2077\n",
            "Epoch 23/1000\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 1.9501 - accuracy: 0.2370 - val_loss: 1.6919 - val_accuracy: 0.2947\n",
            "Epoch 24/1000\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 1.9909 - accuracy: 0.2461 - val_loss: 1.6728 - val_accuracy: 0.3430\n",
            "Epoch 25/1000\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 1.9433 - accuracy: 0.2394 - val_loss: 1.6638 - val_accuracy: 0.3092\n",
            "Epoch 26/1000\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 1.9608 - accuracy: 0.2394 - val_loss: 1.6617 - val_accuracy: 0.3285\n",
            "Epoch 27/1000\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 1.9286 - accuracy: 0.2461 - val_loss: 1.6604 - val_accuracy: 0.2754\n",
            "Epoch 28/1000\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 1.8917 - accuracy: 0.2594 - val_loss: 1.6644 - val_accuracy: 0.3237\n",
            "Epoch 29/1000\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 1.8847 - accuracy: 0.2570 - val_loss: 1.6616 - val_accuracy: 0.2802\n",
            "Epoch 30/1000\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 1.8558 - accuracy: 0.2467 - val_loss: 1.6482 - val_accuracy: 0.3430\n",
            "Epoch 31/1000\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 1.8640 - accuracy: 0.2539 - val_loss: 1.6665 - val_accuracy: 0.2802\n",
            "Epoch 32/1000\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 1.8581 - accuracy: 0.2467 - val_loss: 1.6457 - val_accuracy: 0.3285\n",
            "Epoch 33/1000\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 1.8497 - accuracy: 0.2563 - val_loss: 1.6450 - val_accuracy: 0.3671\n",
            "Epoch 34/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 1.8475 - accuracy: 0.2557 - val_loss: 1.6389 - val_accuracy: 0.3285\n",
            "Epoch 35/1000\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 1.8195 - accuracy: 0.2769 - val_loss: 1.6533 - val_accuracy: 0.2415\n",
            "Epoch 36/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.8103 - accuracy: 0.2636 - val_loss: 1.6409 - val_accuracy: 0.3720\n",
            "Epoch 37/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.7726 - accuracy: 0.2703 - val_loss: 1.6414 - val_accuracy: 0.3333\n",
            "Epoch 38/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.7735 - accuracy: 0.2709 - val_loss: 1.6336 - val_accuracy: 0.3720\n",
            "Epoch 39/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.7920 - accuracy: 0.2745 - val_loss: 1.6292 - val_accuracy: 0.3092\n",
            "Epoch 40/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.7715 - accuracy: 0.2811 - val_loss: 1.6143 - val_accuracy: 0.4396\n",
            "Epoch 41/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.7647 - accuracy: 0.2763 - val_loss: 1.6283 - val_accuracy: 0.3575\n",
            "Epoch 42/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.7463 - accuracy: 0.2854 - val_loss: 1.6198 - val_accuracy: 0.3913\n",
            "Epoch 43/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.7464 - accuracy: 0.2739 - val_loss: 1.6212 - val_accuracy: 0.4155\n",
            "Epoch 44/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.7295 - accuracy: 0.2817 - val_loss: 1.6305 - val_accuracy: 0.3237\n",
            "Epoch 45/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.7346 - accuracy: 0.2872 - val_loss: 1.6153 - val_accuracy: 0.3816\n",
            "Epoch 46/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.7269 - accuracy: 0.2854 - val_loss: 1.6153 - val_accuracy: 0.3816\n",
            "Epoch 47/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.7096 - accuracy: 0.3035 - val_loss: 1.6078 - val_accuracy: 0.4251\n",
            "Epoch 48/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.6957 - accuracy: 0.2944 - val_loss: 1.5943 - val_accuracy: 0.4251\n",
            "Epoch 49/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.7066 - accuracy: 0.2860 - val_loss: 1.5926 - val_accuracy: 0.3913\n",
            "Epoch 50/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.7228 - accuracy: 0.2938 - val_loss: 1.6117 - val_accuracy: 0.3720\n",
            "Epoch 51/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.6759 - accuracy: 0.3132 - val_loss: 1.5991 - val_accuracy: 0.4010\n",
            "Epoch 52/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.6987 - accuracy: 0.2811 - val_loss: 1.5950 - val_accuracy: 0.4010\n",
            "Epoch 53/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.6757 - accuracy: 0.3029 - val_loss: 1.5820 - val_accuracy: 0.4348\n",
            "Epoch 54/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.6751 - accuracy: 0.3041 - val_loss: 1.5979 - val_accuracy: 0.3430\n",
            "Epoch 55/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.6781 - accuracy: 0.3120 - val_loss: 1.5885 - val_accuracy: 0.3768\n",
            "Epoch 56/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.6510 - accuracy: 0.3126 - val_loss: 1.5744 - val_accuracy: 0.3720\n",
            "Epoch 57/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.6709 - accuracy: 0.3150 - val_loss: 1.5644 - val_accuracy: 0.4493\n",
            "Epoch 58/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.6721 - accuracy: 0.2993 - val_loss: 1.5735 - val_accuracy: 0.4300\n",
            "Epoch 59/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.6600 - accuracy: 0.3089 - val_loss: 1.5665 - val_accuracy: 0.3913\n",
            "Epoch 60/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.6247 - accuracy: 0.3198 - val_loss: 1.5573 - val_accuracy: 0.4686\n",
            "Epoch 61/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.6232 - accuracy: 0.3313 - val_loss: 1.5659 - val_accuracy: 0.3865\n",
            "Epoch 62/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.6495 - accuracy: 0.3210 - val_loss: 1.5547 - val_accuracy: 0.4251\n",
            "Epoch 63/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.6337 - accuracy: 0.3259 - val_loss: 1.5554 - val_accuracy: 0.4203\n",
            "Epoch 64/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.6171 - accuracy: 0.3343 - val_loss: 1.5452 - val_accuracy: 0.4444\n",
            "Epoch 65/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.6265 - accuracy: 0.3180 - val_loss: 1.5511 - val_accuracy: 0.4348\n",
            "Epoch 66/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.6182 - accuracy: 0.3422 - val_loss: 1.5598 - val_accuracy: 0.3527\n",
            "Epoch 67/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.6149 - accuracy: 0.3404 - val_loss: 1.5528 - val_accuracy: 0.4251\n",
            "Epoch 68/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.6217 - accuracy: 0.3186 - val_loss: 1.5489 - val_accuracy: 0.4010\n",
            "Epoch 69/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.6111 - accuracy: 0.3295 - val_loss: 1.5469 - val_accuracy: 0.4155\n",
            "Epoch 70/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.6272 - accuracy: 0.3295 - val_loss: 1.5404 - val_accuracy: 0.4251\n",
            "Epoch 71/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.5775 - accuracy: 0.3428 - val_loss: 1.5359 - val_accuracy: 0.4638\n",
            "Epoch 72/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.5828 - accuracy: 0.3422 - val_loss: 1.5335 - val_accuracy: 0.3961\n",
            "Epoch 73/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.5735 - accuracy: 0.3428 - val_loss: 1.5313 - val_accuracy: 0.4203\n",
            "Epoch 74/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.6082 - accuracy: 0.3174 - val_loss: 1.5215 - val_accuracy: 0.4541\n",
            "Epoch 75/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.5678 - accuracy: 0.3555 - val_loss: 1.5144 - val_accuracy: 0.4444\n",
            "Epoch 76/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.5682 - accuracy: 0.3640 - val_loss: 1.5029 - val_accuracy: 0.4638\n",
            "Epoch 77/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.5730 - accuracy: 0.3489 - val_loss: 1.5072 - val_accuracy: 0.4686\n",
            "Epoch 78/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.5598 - accuracy: 0.3440 - val_loss: 1.4963 - val_accuracy: 0.4396\n",
            "Epoch 79/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.5533 - accuracy: 0.3597 - val_loss: 1.5047 - val_accuracy: 0.4444\n",
            "Epoch 80/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.5555 - accuracy: 0.3482 - val_loss: 1.4903 - val_accuracy: 0.4203\n",
            "Epoch 81/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.5359 - accuracy: 0.3591 - val_loss: 1.4832 - val_accuracy: 0.4638\n",
            "Epoch 82/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.5620 - accuracy: 0.3507 - val_loss: 1.4845 - val_accuracy: 0.4638\n",
            "Epoch 83/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.5510 - accuracy: 0.3482 - val_loss: 1.4819 - val_accuracy: 0.4686\n",
            "Epoch 84/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.5583 - accuracy: 0.3609 - val_loss: 1.4678 - val_accuracy: 0.4976\n",
            "Epoch 85/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.5352 - accuracy: 0.3603 - val_loss: 1.4659 - val_accuracy: 0.4638\n",
            "Epoch 86/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.5248 - accuracy: 0.3785 - val_loss: 1.4669 - val_accuracy: 0.4493\n",
            "Epoch 87/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.5215 - accuracy: 0.3736 - val_loss: 1.4591 - val_accuracy: 0.4493\n",
            "Epoch 88/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.5078 - accuracy: 0.3851 - val_loss: 1.4643 - val_accuracy: 0.4976\n",
            "Epoch 89/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.5160 - accuracy: 0.3773 - val_loss: 1.4542 - val_accuracy: 0.4686\n",
            "Epoch 90/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.4938 - accuracy: 0.3869 - val_loss: 1.4629 - val_accuracy: 0.4251\n",
            "Epoch 91/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.4904 - accuracy: 0.3912 - val_loss: 1.4423 - val_accuracy: 0.4686\n",
            "Epoch 92/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.4943 - accuracy: 0.3827 - val_loss: 1.4390 - val_accuracy: 0.4831\n",
            "Epoch 93/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.5000 - accuracy: 0.3730 - val_loss: 1.4395 - val_accuracy: 0.4783\n",
            "Epoch 94/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.4822 - accuracy: 0.3827 - val_loss: 1.4438 - val_accuracy: 0.4783\n",
            "Epoch 95/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.4844 - accuracy: 0.4021 - val_loss: 1.4202 - val_accuracy: 0.4638\n",
            "Epoch 96/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.4899 - accuracy: 0.3833 - val_loss: 1.4315 - val_accuracy: 0.4928\n",
            "Epoch 97/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.4872 - accuracy: 0.3972 - val_loss: 1.4238 - val_accuracy: 0.4493\n",
            "Epoch 98/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.4726 - accuracy: 0.3912 - val_loss: 1.4156 - val_accuracy: 0.4686\n",
            "Epoch 99/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.4749 - accuracy: 0.3863 - val_loss: 1.4087 - val_accuracy: 0.4976\n",
            "Epoch 100/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.4705 - accuracy: 0.4166 - val_loss: 1.4078 - val_accuracy: 0.5121\n",
            "Epoch 101/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.4534 - accuracy: 0.4002 - val_loss: 1.3964 - val_accuracy: 0.5121\n",
            "Epoch 102/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.4515 - accuracy: 0.4202 - val_loss: 1.4239 - val_accuracy: 0.4300\n",
            "Epoch 103/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.4357 - accuracy: 0.4099 - val_loss: 1.3795 - val_accuracy: 0.5169\n",
            "Epoch 104/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.4312 - accuracy: 0.4178 - val_loss: 1.3844 - val_accuracy: 0.5169\n",
            "Epoch 105/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.4383 - accuracy: 0.4093 - val_loss: 1.3914 - val_accuracy: 0.4879\n",
            "Epoch 106/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.4288 - accuracy: 0.4244 - val_loss: 1.4001 - val_accuracy: 0.4589\n",
            "Epoch 107/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.4202 - accuracy: 0.4220 - val_loss: 1.3894 - val_accuracy: 0.4976\n",
            "Epoch 108/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.4091 - accuracy: 0.4407 - val_loss: 1.3802 - val_accuracy: 0.5121\n",
            "Epoch 109/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.4339 - accuracy: 0.4105 - val_loss: 1.3803 - val_accuracy: 0.5362\n",
            "Epoch 110/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.4202 - accuracy: 0.4250 - val_loss: 1.3758 - val_accuracy: 0.5072\n",
            "Epoch 111/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.4021 - accuracy: 0.4287 - val_loss: 1.3800 - val_accuracy: 0.4831\n",
            "Epoch 112/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.4047 - accuracy: 0.4335 - val_loss: 1.3751 - val_accuracy: 0.4831\n",
            "Epoch 113/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.4022 - accuracy: 0.4305 - val_loss: 1.3615 - val_accuracy: 0.5121\n",
            "Epoch 114/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.4256 - accuracy: 0.4208 - val_loss: 1.3515 - val_accuracy: 0.5217\n",
            "Epoch 115/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.3958 - accuracy: 0.4208 - val_loss: 1.3622 - val_accuracy: 0.5121\n",
            "Epoch 116/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.3965 - accuracy: 0.4395 - val_loss: 1.3574 - val_accuracy: 0.5072\n",
            "Epoch 117/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.3858 - accuracy: 0.4317 - val_loss: 1.3509 - val_accuracy: 0.5362\n",
            "Epoch 118/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.3859 - accuracy: 0.4287 - val_loss: 1.3443 - val_accuracy: 0.4879\n",
            "Epoch 119/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.3940 - accuracy: 0.4214 - val_loss: 1.3415 - val_accuracy: 0.5459\n",
            "Epoch 120/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.3648 - accuracy: 0.4547 - val_loss: 1.3360 - val_accuracy: 0.5362\n",
            "Epoch 121/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.3733 - accuracy: 0.4311 - val_loss: 1.3332 - val_accuracy: 0.5314\n",
            "Epoch 122/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.3436 - accuracy: 0.4583 - val_loss: 1.3450 - val_accuracy: 0.5072\n",
            "Epoch 123/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.3825 - accuracy: 0.4407 - val_loss: 1.3209 - val_accuracy: 0.5217\n",
            "Epoch 124/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.3815 - accuracy: 0.4414 - val_loss: 1.3326 - val_accuracy: 0.5072\n",
            "Epoch 125/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 1.3822 - accuracy: 0.4371 - val_loss: 1.3237 - val_accuracy: 0.5266\n",
            "Epoch 126/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 1.3449 - accuracy: 0.4595 - val_loss: 1.3171 - val_accuracy: 0.5314\n",
            "Epoch 127/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 1.3656 - accuracy: 0.4541 - val_loss: 1.2986 - val_accuracy: 0.5604\n",
            "Epoch 128/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 1.3405 - accuracy: 0.4565 - val_loss: 1.3046 - val_accuracy: 0.4976\n",
            "Epoch 129/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 1.3439 - accuracy: 0.4655 - val_loss: 1.3203 - val_accuracy: 0.5217\n",
            "Epoch 130/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.3543 - accuracy: 0.4516 - val_loss: 1.2932 - val_accuracy: 0.5411\n",
            "Epoch 131/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.3268 - accuracy: 0.4601 - val_loss: 1.3051 - val_accuracy: 0.5217\n",
            "Epoch 132/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.3393 - accuracy: 0.4528 - val_loss: 1.3178 - val_accuracy: 0.4879\n",
            "Epoch 133/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.3363 - accuracy: 0.4565 - val_loss: 1.2941 - val_accuracy: 0.5217\n",
            "Epoch 134/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.3022 - accuracy: 0.4667 - val_loss: 1.2947 - val_accuracy: 0.4783\n",
            "Epoch 135/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.3122 - accuracy: 0.4625 - val_loss: 1.2914 - val_accuracy: 0.5024\n",
            "Epoch 136/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.3330 - accuracy: 0.4704 - val_loss: 1.3039 - val_accuracy: 0.5024\n",
            "Epoch 137/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.3118 - accuracy: 0.4746 - val_loss: 1.2967 - val_accuracy: 0.5314\n",
            "Epoch 138/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 1.3222 - accuracy: 0.4704 - val_loss: 1.2781 - val_accuracy: 0.5121\n",
            "Epoch 139/1000\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 1.3173 - accuracy: 0.4625 - val_loss: 1.2686 - val_accuracy: 0.5749\n",
            "Epoch 140/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 1.3139 - accuracy: 0.4680 - val_loss: 1.2659 - val_accuracy: 0.5604\n",
            "Epoch 141/1000\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 1.3070 - accuracy: 0.4764 - val_loss: 1.2718 - val_accuracy: 0.5266\n",
            "Epoch 142/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.3028 - accuracy: 0.4734 - val_loss: 1.2743 - val_accuracy: 0.5411\n",
            "Epoch 143/1000\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 1.2798 - accuracy: 0.4952 - val_loss: 1.2643 - val_accuracy: 0.5507\n",
            "Epoch 144/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.2679 - accuracy: 0.4843 - val_loss: 1.2674 - val_accuracy: 0.5314\n",
            "Epoch 145/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.2872 - accuracy: 0.4692 - val_loss: 1.2533 - val_accuracy: 0.5604\n",
            "Epoch 146/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.2886 - accuracy: 0.4776 - val_loss: 1.2390 - val_accuracy: 0.5266\n",
            "Epoch 147/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.2914 - accuracy: 0.4776 - val_loss: 1.2541 - val_accuracy: 0.5507\n",
            "Epoch 148/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.2781 - accuracy: 0.4861 - val_loss: 1.2390 - val_accuracy: 0.5507\n",
            "Epoch 149/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.2735 - accuracy: 0.4855 - val_loss: 1.2532 - val_accuracy: 0.5024\n",
            "Epoch 150/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.2784 - accuracy: 0.4825 - val_loss: 1.2319 - val_accuracy: 0.5652\n",
            "Epoch 151/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.2802 - accuracy: 0.4776 - val_loss: 1.2272 - val_accuracy: 0.5749\n",
            "Epoch 152/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.2544 - accuracy: 0.4897 - val_loss: 1.2334 - val_accuracy: 0.5604\n",
            "Epoch 153/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.2458 - accuracy: 0.4952 - val_loss: 1.2234 - val_accuracy: 0.5411\n",
            "Epoch 154/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.2606 - accuracy: 0.4952 - val_loss: 1.2479 - val_accuracy: 0.5314\n",
            "Epoch 155/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.2413 - accuracy: 0.5012 - val_loss: 1.2193 - val_accuracy: 0.5411\n",
            "Epoch 156/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.2364 - accuracy: 0.5012 - val_loss: 1.2186 - val_accuracy: 0.5411\n",
            "Epoch 157/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.2281 - accuracy: 0.5193 - val_loss: 1.2333 - val_accuracy: 0.5507\n",
            "Epoch 158/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.2314 - accuracy: 0.5079 - val_loss: 1.2286 - val_accuracy: 0.5362\n",
            "Epoch 159/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.2343 - accuracy: 0.5109 - val_loss: 1.2155 - val_accuracy: 0.5411\n",
            "Epoch 160/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.2333 - accuracy: 0.5024 - val_loss: 1.2073 - val_accuracy: 0.5652\n",
            "Epoch 161/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.2340 - accuracy: 0.5091 - val_loss: 1.2202 - val_accuracy: 0.5459\n",
            "Epoch 162/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.2220 - accuracy: 0.4933 - val_loss: 1.2060 - val_accuracy: 0.5459\n",
            "Epoch 163/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.2096 - accuracy: 0.5175 - val_loss: 1.2005 - val_accuracy: 0.5556\n",
            "Epoch 164/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.2186 - accuracy: 0.5036 - val_loss: 1.1960 - val_accuracy: 0.5507\n",
            "Epoch 165/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.2311 - accuracy: 0.5109 - val_loss: 1.1982 - val_accuracy: 0.5652\n",
            "Epoch 166/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.2214 - accuracy: 0.5187 - val_loss: 1.1909 - val_accuracy: 0.5652\n",
            "Epoch 167/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.2118 - accuracy: 0.5151 - val_loss: 1.1858 - val_accuracy: 0.5894\n",
            "Epoch 168/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.2030 - accuracy: 0.5230 - val_loss: 1.1866 - val_accuracy: 0.5894\n",
            "Epoch 169/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.2202 - accuracy: 0.5157 - val_loss: 1.1815 - val_accuracy: 0.5749\n",
            "Epoch 170/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.2012 - accuracy: 0.5200 - val_loss: 1.1869 - val_accuracy: 0.5749\n",
            "Epoch 171/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.1966 - accuracy: 0.5254 - val_loss: 1.1927 - val_accuracy: 0.5604\n",
            "Epoch 172/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.2031 - accuracy: 0.5175 - val_loss: 1.1887 - val_accuracy: 0.5459\n",
            "Epoch 173/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.2008 - accuracy: 0.5230 - val_loss: 1.1866 - val_accuracy: 0.5652\n",
            "Epoch 174/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.1871 - accuracy: 0.5242 - val_loss: 1.1791 - val_accuracy: 0.5749\n",
            "Epoch 175/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.2000 - accuracy: 0.5067 - val_loss: 1.1707 - val_accuracy: 0.5797\n",
            "Epoch 176/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.2004 - accuracy: 0.5230 - val_loss: 1.1902 - val_accuracy: 0.5604\n",
            "Epoch 177/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.1849 - accuracy: 0.5278 - val_loss: 1.1593 - val_accuracy: 0.5990\n",
            "Epoch 178/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.1766 - accuracy: 0.5224 - val_loss: 1.1698 - val_accuracy: 0.5894\n",
            "Epoch 179/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.1923 - accuracy: 0.5326 - val_loss: 1.1486 - val_accuracy: 0.6087\n",
            "Epoch 180/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.1587 - accuracy: 0.5387 - val_loss: 1.1557 - val_accuracy: 0.5894\n",
            "Epoch 181/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.1625 - accuracy: 0.5399 - val_loss: 1.1480 - val_accuracy: 0.5894\n",
            "Epoch 182/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.1602 - accuracy: 0.5326 - val_loss: 1.1503 - val_accuracy: 0.5845\n",
            "Epoch 183/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.1594 - accuracy: 0.5351 - val_loss: 1.1464 - val_accuracy: 0.5990\n",
            "Epoch 184/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.1598 - accuracy: 0.5314 - val_loss: 1.1671 - val_accuracy: 0.5700\n",
            "Epoch 185/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.1775 - accuracy: 0.5405 - val_loss: 1.1706 - val_accuracy: 0.5556\n",
            "Epoch 186/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.1596 - accuracy: 0.5393 - val_loss: 1.1664 - val_accuracy: 0.5604\n",
            "Epoch 187/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.1517 - accuracy: 0.5272 - val_loss: 1.1410 - val_accuracy: 0.5749\n",
            "Epoch 188/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.1562 - accuracy: 0.5339 - val_loss: 1.1478 - val_accuracy: 0.5797\n",
            "Epoch 189/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.1463 - accuracy: 0.5459 - val_loss: 1.1425 - val_accuracy: 0.5749\n",
            "Epoch 190/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.1405 - accuracy: 0.5363 - val_loss: 1.1341 - val_accuracy: 0.5845\n",
            "Epoch 191/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.1213 - accuracy: 0.5490 - val_loss: 1.1395 - val_accuracy: 0.5652\n",
            "Epoch 192/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.1349 - accuracy: 0.5466 - val_loss: 1.1162 - val_accuracy: 0.5990\n",
            "Epoch 193/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.1508 - accuracy: 0.5423 - val_loss: 1.1273 - val_accuracy: 0.5749\n",
            "Epoch 194/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.1373 - accuracy: 0.5478 - val_loss: 1.1159 - val_accuracy: 0.5749\n",
            "Epoch 195/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.1373 - accuracy: 0.5435 - val_loss: 1.1165 - val_accuracy: 0.5845\n",
            "Epoch 196/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.1259 - accuracy: 0.5459 - val_loss: 1.1177 - val_accuracy: 0.5942\n",
            "Epoch 197/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.1184 - accuracy: 0.5599 - val_loss: 1.1267 - val_accuracy: 0.5797\n",
            "Epoch 198/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.1141 - accuracy: 0.5490 - val_loss: 1.1173 - val_accuracy: 0.6329\n",
            "Epoch 199/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.1403 - accuracy: 0.5472 - val_loss: 1.1329 - val_accuracy: 0.5652\n",
            "Epoch 200/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.0946 - accuracy: 0.5665 - val_loss: 1.1115 - val_accuracy: 0.6087\n",
            "Epoch 201/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.1078 - accuracy: 0.5659 - val_loss: 1.1024 - val_accuracy: 0.6087\n",
            "Epoch 202/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.1092 - accuracy: 0.5623 - val_loss: 1.1109 - val_accuracy: 0.6039\n",
            "Epoch 203/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.0891 - accuracy: 0.5744 - val_loss: 1.1179 - val_accuracy: 0.5894\n",
            "Epoch 204/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.0977 - accuracy: 0.5514 - val_loss: 1.1000 - val_accuracy: 0.5749\n",
            "Epoch 205/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.0986 - accuracy: 0.5683 - val_loss: 1.1083 - val_accuracy: 0.5797\n",
            "Epoch 206/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.1121 - accuracy: 0.5593 - val_loss: 1.0973 - val_accuracy: 0.5749\n",
            "Epoch 207/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.0998 - accuracy: 0.5713 - val_loss: 1.0873 - val_accuracy: 0.6087\n",
            "Epoch 208/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.1106 - accuracy: 0.5586 - val_loss: 1.1177 - val_accuracy: 0.6039\n",
            "Epoch 209/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.0975 - accuracy: 0.5586 - val_loss: 1.0972 - val_accuracy: 0.5942\n",
            "Epoch 210/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0741 - accuracy: 0.5732 - val_loss: 1.0780 - val_accuracy: 0.5797\n",
            "Epoch 211/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0910 - accuracy: 0.5738 - val_loss: 1.0633 - val_accuracy: 0.5942\n",
            "Epoch 212/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.0680 - accuracy: 0.5683 - val_loss: 1.0765 - val_accuracy: 0.6039\n",
            "Epoch 213/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0834 - accuracy: 0.5707 - val_loss: 1.0741 - val_accuracy: 0.5652\n",
            "Epoch 214/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.0761 - accuracy: 0.5635 - val_loss: 1.0774 - val_accuracy: 0.5700\n",
            "Epoch 215/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.0486 - accuracy: 0.5883 - val_loss: 1.0750 - val_accuracy: 0.6087\n",
            "Epoch 216/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0900 - accuracy: 0.5556 - val_loss: 1.0745 - val_accuracy: 0.5990\n",
            "Epoch 217/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.0588 - accuracy: 0.5810 - val_loss: 1.0794 - val_accuracy: 0.5942\n",
            "Epoch 218/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0730 - accuracy: 0.5695 - val_loss: 1.0762 - val_accuracy: 0.6039\n",
            "Epoch 219/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0725 - accuracy: 0.5810 - val_loss: 1.0692 - val_accuracy: 0.6135\n",
            "Epoch 220/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.0553 - accuracy: 0.5816 - val_loss: 1.0586 - val_accuracy: 0.6184\n",
            "Epoch 221/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0728 - accuracy: 0.5768 - val_loss: 1.0894 - val_accuracy: 0.5749\n",
            "Epoch 222/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.0601 - accuracy: 0.5659 - val_loss: 1.0675 - val_accuracy: 0.6280\n",
            "Epoch 223/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0375 - accuracy: 0.5877 - val_loss: 1.0714 - val_accuracy: 0.5797\n",
            "Epoch 224/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.0681 - accuracy: 0.5744 - val_loss: 1.0400 - val_accuracy: 0.6377\n",
            "Epoch 225/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0658 - accuracy: 0.5665 - val_loss: 1.0477 - val_accuracy: 0.6377\n",
            "Epoch 226/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0483 - accuracy: 0.5798 - val_loss: 1.0315 - val_accuracy: 0.6232\n",
            "Epoch 227/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.0375 - accuracy: 0.6028 - val_loss: 1.0377 - val_accuracy: 0.6184\n",
            "Epoch 228/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0479 - accuracy: 0.5822 - val_loss: 1.0466 - val_accuracy: 0.6280\n",
            "Epoch 229/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0383 - accuracy: 0.5925 - val_loss: 1.0318 - val_accuracy: 0.6135\n",
            "Epoch 230/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0530 - accuracy: 0.5719 - val_loss: 1.0173 - val_accuracy: 0.6473\n",
            "Epoch 231/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0323 - accuracy: 0.5895 - val_loss: 1.0226 - val_accuracy: 0.6232\n",
            "Epoch 232/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.0356 - accuracy: 0.5822 - val_loss: 1.0228 - val_accuracy: 0.6618\n",
            "Epoch 233/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.0361 - accuracy: 0.5828 - val_loss: 1.0410 - val_accuracy: 0.6135\n",
            "Epoch 234/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0456 - accuracy: 0.5913 - val_loss: 1.0318 - val_accuracy: 0.6280\n",
            "Epoch 235/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0488 - accuracy: 0.5750 - val_loss: 1.0287 - val_accuracy: 0.6329\n",
            "Epoch 236/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0396 - accuracy: 0.5889 - val_loss: 1.0214 - val_accuracy: 0.6280\n",
            "Epoch 237/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0047 - accuracy: 0.5895 - val_loss: 1.0071 - val_accuracy: 0.6232\n",
            "Epoch 238/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 1.0504 - accuracy: 0.5883 - val_loss: 1.0165 - val_accuracy: 0.6425\n",
            "Epoch 239/1000\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 1.0143 - accuracy: 0.5998 - val_loss: 1.0102 - val_accuracy: 0.6522\n",
            "Epoch 240/1000\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 1.0208 - accuracy: 0.5852 - val_loss: 1.0251 - val_accuracy: 0.6135\n",
            "Epoch 241/1000\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 1.0028 - accuracy: 0.5998 - val_loss: 1.0333 - val_accuracy: 0.6329\n",
            "Epoch 242/1000\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 1.0105 - accuracy: 0.6010 - val_loss: 1.0123 - val_accuracy: 0.6232\n",
            "Epoch 243/1000\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 1.0185 - accuracy: 0.5955 - val_loss: 1.0083 - val_accuracy: 0.6377\n",
            "Epoch 244/1000\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 1.0157 - accuracy: 0.6125 - val_loss: 0.9949 - val_accuracy: 0.6570\n",
            "Epoch 245/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 1.0108 - accuracy: 0.5895 - val_loss: 1.0052 - val_accuracy: 0.6280\n",
            "Epoch 246/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.9906 - accuracy: 0.6094 - val_loss: 1.0078 - val_accuracy: 0.6377\n",
            "Epoch 247/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9977 - accuracy: 0.6034 - val_loss: 0.9996 - val_accuracy: 0.6135\n",
            "Epoch 248/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9860 - accuracy: 0.6161 - val_loss: 0.9815 - val_accuracy: 0.6715\n",
            "Epoch 249/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9863 - accuracy: 0.6167 - val_loss: 0.9840 - val_accuracy: 0.6522\n",
            "Epoch 250/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9788 - accuracy: 0.6233 - val_loss: 0.9821 - val_accuracy: 0.6570\n",
            "Epoch 251/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9773 - accuracy: 0.6185 - val_loss: 1.0042 - val_accuracy: 0.6473\n",
            "Epoch 252/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0077 - accuracy: 0.5998 - val_loss: 0.9849 - val_accuracy: 0.6667\n",
            "Epoch 253/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.9798 - accuracy: 0.6167 - val_loss: 0.9820 - val_accuracy: 0.6473\n",
            "Epoch 254/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.9810 - accuracy: 0.6167 - val_loss: 0.9644 - val_accuracy: 0.6763\n",
            "Epoch 255/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.9829 - accuracy: 0.6131 - val_loss: 0.9801 - val_accuracy: 0.6667\n",
            "Epoch 256/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9663 - accuracy: 0.6088 - val_loss: 0.9819 - val_accuracy: 0.6570\n",
            "Epoch 257/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.9895 - accuracy: 0.6028 - val_loss: 0.9914 - val_accuracy: 0.6232\n",
            "Epoch 258/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9683 - accuracy: 0.6155 - val_loss: 0.9754 - val_accuracy: 0.6570\n",
            "Epoch 259/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9969 - accuracy: 0.6131 - val_loss: 0.9542 - val_accuracy: 0.6812\n",
            "Epoch 260/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9794 - accuracy: 0.6088 - val_loss: 0.9630 - val_accuracy: 0.6473\n",
            "Epoch 261/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9597 - accuracy: 0.6058 - val_loss: 0.9839 - val_accuracy: 0.6570\n",
            "Epoch 262/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9660 - accuracy: 0.6149 - val_loss: 0.9586 - val_accuracy: 0.6329\n",
            "Epoch 263/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.9697 - accuracy: 0.6119 - val_loss: 0.9592 - val_accuracy: 0.6618\n",
            "Epoch 264/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9448 - accuracy: 0.6191 - val_loss: 0.9588 - val_accuracy: 0.6715\n",
            "Epoch 265/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.9583 - accuracy: 0.6227 - val_loss: 0.9674 - val_accuracy: 0.6522\n",
            "Epoch 266/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9462 - accuracy: 0.6348 - val_loss: 0.9610 - val_accuracy: 0.6473\n",
            "Epoch 267/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9701 - accuracy: 0.6185 - val_loss: 0.9401 - val_accuracy: 0.6908\n",
            "Epoch 268/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9847 - accuracy: 0.6046 - val_loss: 0.9528 - val_accuracy: 0.6763\n",
            "Epoch 269/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9410 - accuracy: 0.6197 - val_loss: 0.9696 - val_accuracy: 0.6329\n",
            "Epoch 270/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9571 - accuracy: 0.6094 - val_loss: 0.9486 - val_accuracy: 0.6812\n",
            "Epoch 271/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.9790 - accuracy: 0.6149 - val_loss: 0.9488 - val_accuracy: 0.6812\n",
            "Epoch 272/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.9497 - accuracy: 0.6258 - val_loss: 0.9479 - val_accuracy: 0.6473\n",
            "Epoch 273/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.9432 - accuracy: 0.6336 - val_loss: 0.9548 - val_accuracy: 0.6473\n",
            "Epoch 274/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.9422 - accuracy: 0.6288 - val_loss: 0.9409 - val_accuracy: 0.6763\n",
            "Epoch 275/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9180 - accuracy: 0.6409 - val_loss: 0.9361 - val_accuracy: 0.6570\n",
            "Epoch 276/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9329 - accuracy: 0.6409 - val_loss: 0.9631 - val_accuracy: 0.6522\n",
            "Epoch 277/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9346 - accuracy: 0.6179 - val_loss: 0.9457 - val_accuracy: 0.6667\n",
            "Epoch 278/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9387 - accuracy: 0.6391 - val_loss: 0.9285 - val_accuracy: 0.6763\n",
            "Epoch 279/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9487 - accuracy: 0.6082 - val_loss: 0.9387 - val_accuracy: 0.6812\n",
            "Epoch 280/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.9249 - accuracy: 0.6409 - val_loss: 0.9275 - val_accuracy: 0.6667\n",
            "Epoch 281/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.9200 - accuracy: 0.6239 - val_loss: 0.9359 - val_accuracy: 0.6280\n",
            "Epoch 282/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9285 - accuracy: 0.6378 - val_loss: 0.9256 - val_accuracy: 0.6763\n",
            "Epoch 283/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9223 - accuracy: 0.6366 - val_loss: 0.9130 - val_accuracy: 0.6957\n",
            "Epoch 284/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.9218 - accuracy: 0.6421 - val_loss: 0.9182 - val_accuracy: 0.6860\n",
            "Epoch 285/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.9030 - accuracy: 0.6409 - val_loss: 0.9151 - val_accuracy: 0.6812\n",
            "Epoch 286/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.9245 - accuracy: 0.6336 - val_loss: 0.9264 - val_accuracy: 0.6812\n",
            "Epoch 287/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9201 - accuracy: 0.6348 - val_loss: 0.9031 - val_accuracy: 0.6908\n",
            "Epoch 288/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9263 - accuracy: 0.6336 - val_loss: 0.9365 - val_accuracy: 0.6570\n",
            "Epoch 289/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.8950 - accuracy: 0.6403 - val_loss: 0.9139 - val_accuracy: 0.6860\n",
            "Epoch 290/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9165 - accuracy: 0.6463 - val_loss: 0.8920 - val_accuracy: 0.7101\n",
            "Epoch 291/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8916 - accuracy: 0.6348 - val_loss: 0.9223 - val_accuracy: 0.6570\n",
            "Epoch 292/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8907 - accuracy: 0.6487 - val_loss: 0.9060 - val_accuracy: 0.6667\n",
            "Epoch 293/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.8985 - accuracy: 0.6451 - val_loss: 0.8869 - val_accuracy: 0.7150\n",
            "Epoch 294/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8945 - accuracy: 0.6475 - val_loss: 0.9134 - val_accuracy: 0.6473\n",
            "Epoch 295/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9047 - accuracy: 0.6445 - val_loss: 0.9029 - val_accuracy: 0.6715\n",
            "Epoch 296/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9005 - accuracy: 0.6469 - val_loss: 0.9016 - val_accuracy: 0.6908\n",
            "Epoch 297/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8787 - accuracy: 0.6536 - val_loss: 0.9072 - val_accuracy: 0.6715\n",
            "Epoch 298/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9017 - accuracy: 0.6282 - val_loss: 0.8985 - val_accuracy: 0.7053\n",
            "Epoch 299/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.8993 - accuracy: 0.6590 - val_loss: 0.8969 - val_accuracy: 0.6763\n",
            "Epoch 300/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8845 - accuracy: 0.6608 - val_loss: 0.8998 - val_accuracy: 0.6812\n",
            "Epoch 301/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.8706 - accuracy: 0.6554 - val_loss: 0.9036 - val_accuracy: 0.6860\n",
            "Epoch 302/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.9040 - accuracy: 0.6385 - val_loss: 0.8964 - val_accuracy: 0.6908\n",
            "Epoch 303/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.8887 - accuracy: 0.6481 - val_loss: 0.8869 - val_accuracy: 0.6763\n",
            "Epoch 304/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.8888 - accuracy: 0.6536 - val_loss: 0.8978 - val_accuracy: 0.7005\n",
            "Epoch 305/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8892 - accuracy: 0.6415 - val_loss: 0.9082 - val_accuracy: 0.6473\n",
            "Epoch 306/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8793 - accuracy: 0.6493 - val_loss: 0.8918 - val_accuracy: 0.6715\n",
            "Epoch 307/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8670 - accuracy: 0.6602 - val_loss: 0.8930 - val_accuracy: 0.6812\n",
            "Epoch 308/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8945 - accuracy: 0.6415 - val_loss: 0.8896 - val_accuracy: 0.6812\n",
            "Epoch 309/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.8791 - accuracy: 0.6439 - val_loss: 0.8912 - val_accuracy: 0.6908\n",
            "Epoch 310/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8904 - accuracy: 0.6572 - val_loss: 0.8738 - val_accuracy: 0.7101\n",
            "Epoch 311/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8640 - accuracy: 0.6566 - val_loss: 0.8782 - val_accuracy: 0.6908\n",
            "Epoch 312/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8762 - accuracy: 0.6481 - val_loss: 0.8766 - val_accuracy: 0.6812\n",
            "Epoch 313/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8916 - accuracy: 0.6427 - val_loss: 0.8629 - val_accuracy: 0.7005\n",
            "Epoch 314/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.8815 - accuracy: 0.6524 - val_loss: 0.8771 - val_accuracy: 0.7005\n",
            "Epoch 315/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8529 - accuracy: 0.6644 - val_loss: 0.8643 - val_accuracy: 0.7101\n",
            "Epoch 316/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8622 - accuracy: 0.6566 - val_loss: 0.8567 - val_accuracy: 0.7295\n",
            "Epoch 317/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.8633 - accuracy: 0.6657 - val_loss: 0.8681 - val_accuracy: 0.6812\n",
            "Epoch 318/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8795 - accuracy: 0.6542 - val_loss: 0.8598 - val_accuracy: 0.7005\n",
            "Epoch 319/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.8538 - accuracy: 0.6675 - val_loss: 0.8754 - val_accuracy: 0.6763\n",
            "Epoch 320/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8386 - accuracy: 0.6687 - val_loss: 0.8628 - val_accuracy: 0.6957\n",
            "Epoch 321/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8756 - accuracy: 0.6511 - val_loss: 0.8574 - val_accuracy: 0.7005\n",
            "Epoch 322/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8520 - accuracy: 0.6675 - val_loss: 0.8529 - val_accuracy: 0.6957\n",
            "Epoch 323/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8574 - accuracy: 0.6699 - val_loss: 0.8520 - val_accuracy: 0.7391\n",
            "Epoch 324/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8349 - accuracy: 0.6687 - val_loss: 0.8612 - val_accuracy: 0.6908\n",
            "Epoch 325/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8401 - accuracy: 0.6741 - val_loss: 0.8589 - val_accuracy: 0.7101\n",
            "Epoch 326/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8609 - accuracy: 0.6729 - val_loss: 0.8665 - val_accuracy: 0.7005\n",
            "Epoch 327/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8271 - accuracy: 0.6784 - val_loss: 0.8665 - val_accuracy: 0.7101\n",
            "Epoch 328/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8510 - accuracy: 0.6584 - val_loss: 0.8662 - val_accuracy: 0.6812\n",
            "Epoch 329/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.8391 - accuracy: 0.6778 - val_loss: 0.8509 - val_accuracy: 0.7053\n",
            "Epoch 330/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.8417 - accuracy: 0.6675 - val_loss: 0.8491 - val_accuracy: 0.7053\n",
            "Epoch 331/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.8295 - accuracy: 0.6778 - val_loss: 0.8405 - val_accuracy: 0.7101\n",
            "Epoch 332/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8361 - accuracy: 0.6663 - val_loss: 0.8427 - val_accuracy: 0.7391\n",
            "Epoch 333/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8220 - accuracy: 0.6735 - val_loss: 0.8411 - val_accuracy: 0.7246\n",
            "Epoch 334/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8360 - accuracy: 0.6723 - val_loss: 0.8364 - val_accuracy: 0.7246\n",
            "Epoch 335/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8441 - accuracy: 0.6669 - val_loss: 0.8594 - val_accuracy: 0.7101\n",
            "Epoch 336/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.8525 - accuracy: 0.6632 - val_loss: 0.8358 - val_accuracy: 0.7198\n",
            "Epoch 337/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8229 - accuracy: 0.6868 - val_loss: 0.8429 - val_accuracy: 0.7295\n",
            "Epoch 338/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8346 - accuracy: 0.6681 - val_loss: 0.8496 - val_accuracy: 0.7198\n",
            "Epoch 339/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8239 - accuracy: 0.6717 - val_loss: 0.8311 - val_accuracy: 0.7246\n",
            "Epoch 340/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8324 - accuracy: 0.6814 - val_loss: 0.8516 - val_accuracy: 0.6908\n",
            "Epoch 341/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.8400 - accuracy: 0.6693 - val_loss: 0.8459 - val_accuracy: 0.7198\n",
            "Epoch 342/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8193 - accuracy: 0.6759 - val_loss: 0.8452 - val_accuracy: 0.7246\n",
            "Epoch 343/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8346 - accuracy: 0.6451 - val_loss: 0.8714 - val_accuracy: 0.6860\n",
            "Epoch 344/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8039 - accuracy: 0.6856 - val_loss: 0.8568 - val_accuracy: 0.6957\n",
            "Epoch 345/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.8171 - accuracy: 0.6790 - val_loss: 0.8355 - val_accuracy: 0.7198\n",
            "Epoch 346/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7884 - accuracy: 0.6911 - val_loss: 0.8377 - val_accuracy: 0.7198\n",
            "Epoch 347/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.8085 - accuracy: 0.6856 - val_loss: 0.8392 - val_accuracy: 0.7150\n",
            "Epoch 348/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.8386 - accuracy: 0.6626 - val_loss: 0.8374 - val_accuracy: 0.7343\n",
            "Epoch 349/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.8273 - accuracy: 0.6699 - val_loss: 0.8484 - val_accuracy: 0.6957\n",
            "Epoch 350/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8130 - accuracy: 0.6723 - val_loss: 0.8290 - val_accuracy: 0.7391\n",
            "Epoch 351/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.8196 - accuracy: 0.6705 - val_loss: 0.8648 - val_accuracy: 0.6715\n",
            "Epoch 352/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8204 - accuracy: 0.6729 - val_loss: 0.8453 - val_accuracy: 0.7053\n",
            "Epoch 353/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8039 - accuracy: 0.6935 - val_loss: 0.8348 - val_accuracy: 0.7295\n",
            "Epoch 354/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.8179 - accuracy: 0.6844 - val_loss: 0.8291 - val_accuracy: 0.7440\n",
            "Epoch 355/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7772 - accuracy: 0.6935 - val_loss: 0.8295 - val_accuracy: 0.7101\n",
            "Epoch 356/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8083 - accuracy: 0.6850 - val_loss: 0.8256 - val_accuracy: 0.7053\n",
            "Epoch 357/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8038 - accuracy: 0.6729 - val_loss: 0.8256 - val_accuracy: 0.7150\n",
            "Epoch 358/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8133 - accuracy: 0.6681 - val_loss: 0.8044 - val_accuracy: 0.7150\n",
            "Epoch 359/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8139 - accuracy: 0.6784 - val_loss: 0.8163 - val_accuracy: 0.7101\n",
            "Epoch 360/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7792 - accuracy: 0.6832 - val_loss: 0.8437 - val_accuracy: 0.7005\n",
            "Epoch 361/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7997 - accuracy: 0.6844 - val_loss: 0.8266 - val_accuracy: 0.7246\n",
            "Epoch 362/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7817 - accuracy: 0.6929 - val_loss: 0.8243 - val_accuracy: 0.7053\n",
            "Epoch 363/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.7903 - accuracy: 0.6911 - val_loss: 0.8155 - val_accuracy: 0.7246\n",
            "Epoch 364/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.8033 - accuracy: 0.6820 - val_loss: 0.8128 - val_accuracy: 0.7343\n",
            "Epoch 365/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.7734 - accuracy: 0.7098 - val_loss: 0.8151 - val_accuracy: 0.7343\n",
            "Epoch 366/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8080 - accuracy: 0.6820 - val_loss: 0.8159 - val_accuracy: 0.7440\n",
            "Epoch 367/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7938 - accuracy: 0.6814 - val_loss: 0.8226 - val_accuracy: 0.7246\n",
            "Epoch 368/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.7913 - accuracy: 0.6832 - val_loss: 0.8173 - val_accuracy: 0.7295\n",
            "Epoch 369/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7758 - accuracy: 0.6971 - val_loss: 0.8006 - val_accuracy: 0.7295\n",
            "Epoch 370/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7633 - accuracy: 0.6995 - val_loss: 0.7962 - val_accuracy: 0.7246\n",
            "Epoch 371/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7854 - accuracy: 0.6880 - val_loss: 0.8047 - val_accuracy: 0.7391\n",
            "Epoch 372/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7906 - accuracy: 0.6911 - val_loss: 0.8105 - val_accuracy: 0.7246\n",
            "Epoch 373/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7912 - accuracy: 0.6904 - val_loss: 0.8417 - val_accuracy: 0.7053\n",
            "Epoch 374/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7608 - accuracy: 0.7044 - val_loss: 0.7954 - val_accuracy: 0.7343\n",
            "Epoch 375/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7692 - accuracy: 0.6983 - val_loss: 0.8188 - val_accuracy: 0.7053\n",
            "Epoch 376/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.7690 - accuracy: 0.6947 - val_loss: 0.8221 - val_accuracy: 0.7343\n",
            "Epoch 377/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.7476 - accuracy: 0.7098 - val_loss: 0.7867 - val_accuracy: 0.7391\n",
            "Epoch 378/1000\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.7746 - accuracy: 0.7001 - val_loss: 0.7964 - val_accuracy: 0.7391\n",
            "Epoch 379/1000\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.7552 - accuracy: 0.6989 - val_loss: 0.7956 - val_accuracy: 0.7198\n",
            "Epoch 380/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.7618 - accuracy: 0.6995 - val_loss: 0.7864 - val_accuracy: 0.7343\n",
            "Epoch 381/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.7656 - accuracy: 0.6953 - val_loss: 0.7875 - val_accuracy: 0.7391\n",
            "Epoch 382/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7635 - accuracy: 0.7025 - val_loss: 0.7739 - val_accuracy: 0.7536\n",
            "Epoch 383/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7629 - accuracy: 0.7001 - val_loss: 0.7938 - val_accuracy: 0.7391\n",
            "Epoch 384/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7580 - accuracy: 0.7019 - val_loss: 0.7847 - val_accuracy: 0.7246\n",
            "Epoch 385/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7497 - accuracy: 0.7104 - val_loss: 0.7884 - val_accuracy: 0.7295\n",
            "Epoch 386/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.7663 - accuracy: 0.7037 - val_loss: 0.7845 - val_accuracy: 0.7440\n",
            "Epoch 387/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7593 - accuracy: 0.7086 - val_loss: 0.7711 - val_accuracy: 0.7391\n",
            "Epoch 388/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.7592 - accuracy: 0.7019 - val_loss: 0.7969 - val_accuracy: 0.7246\n",
            "Epoch 389/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.7445 - accuracy: 0.7146 - val_loss: 0.7633 - val_accuracy: 0.7536\n",
            "Epoch 390/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.7592 - accuracy: 0.7001 - val_loss: 0.7780 - val_accuracy: 0.7391\n",
            "Epoch 391/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7438 - accuracy: 0.7050 - val_loss: 0.7894 - val_accuracy: 0.7295\n",
            "Epoch 392/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7544 - accuracy: 0.6983 - val_loss: 0.7879 - val_accuracy: 0.7488\n",
            "Epoch 393/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7385 - accuracy: 0.7074 - val_loss: 0.7844 - val_accuracy: 0.7295\n",
            "Epoch 394/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7620 - accuracy: 0.7001 - val_loss: 0.7996 - val_accuracy: 0.7198\n",
            "Epoch 395/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.7540 - accuracy: 0.7001 - val_loss: 0.7741 - val_accuracy: 0.7391\n",
            "Epoch 396/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.7759 - accuracy: 0.6802 - val_loss: 0.7687 - val_accuracy: 0.7246\n",
            "Epoch 397/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7313 - accuracy: 0.7140 - val_loss: 0.7959 - val_accuracy: 0.7246\n",
            "Epoch 398/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7442 - accuracy: 0.7050 - val_loss: 0.7897 - val_accuracy: 0.7246\n",
            "Epoch 399/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7496 - accuracy: 0.7013 - val_loss: 0.8033 - val_accuracy: 0.7246\n",
            "Epoch 400/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7320 - accuracy: 0.7056 - val_loss: 0.7773 - val_accuracy: 0.7391\n",
            "Epoch 401/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7474 - accuracy: 0.7074 - val_loss: 0.7697 - val_accuracy: 0.7391\n",
            "Epoch 402/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.7232 - accuracy: 0.7243 - val_loss: 0.7767 - val_accuracy: 0.7536\n",
            "Epoch 403/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.7609 - accuracy: 0.6953 - val_loss: 0.7896 - val_accuracy: 0.7295\n",
            "Epoch 404/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.7600 - accuracy: 0.6965 - val_loss: 0.7828 - val_accuracy: 0.7343\n",
            "Epoch 405/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.7330 - accuracy: 0.7092 - val_loss: 0.7778 - val_accuracy: 0.7150\n",
            "Epoch 406/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.7165 - accuracy: 0.7328 - val_loss: 0.7867 - val_accuracy: 0.7198\n",
            "Epoch 407/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7541 - accuracy: 0.7170 - val_loss: 0.7835 - val_accuracy: 0.7343\n",
            "Epoch 408/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7338 - accuracy: 0.7098 - val_loss: 0.7803 - val_accuracy: 0.7536\n",
            "Epoch 409/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.7256 - accuracy: 0.7189 - val_loss: 0.7680 - val_accuracy: 0.7585\n",
            "Epoch 410/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7373 - accuracy: 0.7134 - val_loss: 0.7961 - val_accuracy: 0.7150\n",
            "Epoch 411/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7406 - accuracy: 0.7092 - val_loss: 0.7615 - val_accuracy: 0.7343\n",
            "Epoch 412/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7528 - accuracy: 0.6923 - val_loss: 0.7809 - val_accuracy: 0.7198\n",
            "Epoch 413/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7320 - accuracy: 0.7086 - val_loss: 0.7717 - val_accuracy: 0.7295\n",
            "Epoch 414/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7163 - accuracy: 0.7201 - val_loss: 0.7676 - val_accuracy: 0.7343\n",
            "Epoch 415/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7189 - accuracy: 0.7189 - val_loss: 0.7474 - val_accuracy: 0.7488\n",
            "Epoch 416/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7297 - accuracy: 0.7297 - val_loss: 0.7584 - val_accuracy: 0.7391\n",
            "Epoch 417/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7143 - accuracy: 0.7189 - val_loss: 0.7609 - val_accuracy: 0.7343\n",
            "Epoch 418/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7375 - accuracy: 0.7092 - val_loss: 0.7576 - val_accuracy: 0.7633\n",
            "Epoch 419/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.7237 - accuracy: 0.7231 - val_loss: 0.7506 - val_accuracy: 0.7681\n",
            "Epoch 420/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7185 - accuracy: 0.7243 - val_loss: 0.7614 - val_accuracy: 0.7488\n",
            "Epoch 421/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7172 - accuracy: 0.7146 - val_loss: 0.7598 - val_accuracy: 0.7681\n",
            "Epoch 422/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7102 - accuracy: 0.7134 - val_loss: 0.7793 - val_accuracy: 0.7343\n",
            "Epoch 423/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7233 - accuracy: 0.7116 - val_loss: 0.7607 - val_accuracy: 0.7440\n",
            "Epoch 424/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7236 - accuracy: 0.7183 - val_loss: 0.7625 - val_accuracy: 0.7391\n",
            "Epoch 425/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.7133 - accuracy: 0.7158 - val_loss: 0.7643 - val_accuracy: 0.7343\n",
            "Epoch 426/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7185 - accuracy: 0.7122 - val_loss: 0.7694 - val_accuracy: 0.7150\n",
            "Epoch 427/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7057 - accuracy: 0.7225 - val_loss: 0.7516 - val_accuracy: 0.7633\n",
            "Epoch 428/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7009 - accuracy: 0.7195 - val_loss: 0.7762 - val_accuracy: 0.7198\n",
            "Epoch 429/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.7088 - accuracy: 0.7207 - val_loss: 0.7714 - val_accuracy: 0.7391\n",
            "Epoch 430/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7046 - accuracy: 0.7122 - val_loss: 0.7572 - val_accuracy: 0.7536\n",
            "Epoch 431/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6983 - accuracy: 0.7225 - val_loss: 0.7549 - val_accuracy: 0.7198\n",
            "Epoch 432/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6972 - accuracy: 0.7249 - val_loss: 0.7565 - val_accuracy: 0.7488\n",
            "Epoch 433/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7038 - accuracy: 0.7243 - val_loss: 0.7593 - val_accuracy: 0.7536\n",
            "Epoch 434/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7085 - accuracy: 0.7201 - val_loss: 0.7774 - val_accuracy: 0.7440\n",
            "Epoch 435/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6955 - accuracy: 0.7255 - val_loss: 0.7573 - val_accuracy: 0.7585\n",
            "Epoch 436/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7001 - accuracy: 0.7370 - val_loss: 0.7470 - val_accuracy: 0.7488\n",
            "Epoch 437/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6983 - accuracy: 0.7213 - val_loss: 0.7674 - val_accuracy: 0.7440\n",
            "Epoch 438/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7025 - accuracy: 0.7195 - val_loss: 0.7716 - val_accuracy: 0.7246\n",
            "Epoch 439/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6958 - accuracy: 0.7213 - val_loss: 0.7498 - val_accuracy: 0.7488\n",
            "Epoch 440/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6655 - accuracy: 0.7370 - val_loss: 0.7432 - val_accuracy: 0.7440\n",
            "Epoch 441/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7140 - accuracy: 0.7183 - val_loss: 0.7437 - val_accuracy: 0.7633\n",
            "Epoch 442/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6898 - accuracy: 0.7195 - val_loss: 0.7361 - val_accuracy: 0.7585\n",
            "Epoch 443/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6851 - accuracy: 0.7388 - val_loss: 0.7399 - val_accuracy: 0.7536\n",
            "Epoch 444/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6986 - accuracy: 0.7231 - val_loss: 0.7439 - val_accuracy: 0.7391\n",
            "Epoch 445/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.7061 - accuracy: 0.7092 - val_loss: 0.7408 - val_accuracy: 0.7295\n",
            "Epoch 446/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6859 - accuracy: 0.7291 - val_loss: 0.7478 - val_accuracy: 0.7440\n",
            "Epoch 447/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6835 - accuracy: 0.7213 - val_loss: 0.7302 - val_accuracy: 0.7440\n",
            "Epoch 448/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6887 - accuracy: 0.7255 - val_loss: 0.7479 - val_accuracy: 0.7536\n",
            "Epoch 449/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7231 - accuracy: 0.6983 - val_loss: 0.7593 - val_accuracy: 0.7246\n",
            "Epoch 450/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6788 - accuracy: 0.7400 - val_loss: 0.7421 - val_accuracy: 0.7585\n",
            "Epoch 451/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6846 - accuracy: 0.7267 - val_loss: 0.7329 - val_accuracy: 0.7391\n",
            "Epoch 452/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6837 - accuracy: 0.7261 - val_loss: 0.7402 - val_accuracy: 0.7488\n",
            "Epoch 453/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6855 - accuracy: 0.7382 - val_loss: 0.7285 - val_accuracy: 0.7536\n",
            "Epoch 454/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6710 - accuracy: 0.7449 - val_loss: 0.7393 - val_accuracy: 0.7633\n",
            "Epoch 455/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6859 - accuracy: 0.7340 - val_loss: 0.7302 - val_accuracy: 0.7440\n",
            "Epoch 456/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6790 - accuracy: 0.7310 - val_loss: 0.7345 - val_accuracy: 0.7729\n",
            "Epoch 457/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6682 - accuracy: 0.7394 - val_loss: 0.7485 - val_accuracy: 0.7246\n",
            "Epoch 458/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6604 - accuracy: 0.7400 - val_loss: 0.7525 - val_accuracy: 0.7295\n",
            "Epoch 459/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6922 - accuracy: 0.7219 - val_loss: 0.7361 - val_accuracy: 0.7536\n",
            "Epoch 460/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6715 - accuracy: 0.7322 - val_loss: 0.7342 - val_accuracy: 0.7440\n",
            "Epoch 461/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6851 - accuracy: 0.7249 - val_loss: 0.7380 - val_accuracy: 0.7391\n",
            "Epoch 462/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6784 - accuracy: 0.7285 - val_loss: 0.7385 - val_accuracy: 0.7295\n",
            "Epoch 463/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6835 - accuracy: 0.7352 - val_loss: 0.7354 - val_accuracy: 0.7440\n",
            "Epoch 464/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6657 - accuracy: 0.7370 - val_loss: 0.7309 - val_accuracy: 0.7729\n",
            "Epoch 465/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6556 - accuracy: 0.7491 - val_loss: 0.7319 - val_accuracy: 0.7585\n",
            "Epoch 466/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6758 - accuracy: 0.7328 - val_loss: 0.7302 - val_accuracy: 0.7536\n",
            "Epoch 467/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6807 - accuracy: 0.7304 - val_loss: 0.7415 - val_accuracy: 0.7440\n",
            "Epoch 468/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6562 - accuracy: 0.7557 - val_loss: 0.7304 - val_accuracy: 0.7488\n",
            "Epoch 469/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6521 - accuracy: 0.7449 - val_loss: 0.7260 - val_accuracy: 0.7440\n",
            "Epoch 470/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6616 - accuracy: 0.7455 - val_loss: 0.7223 - val_accuracy: 0.7440\n",
            "Epoch 471/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.6772 - accuracy: 0.7491 - val_loss: 0.7497 - val_accuracy: 0.7391\n",
            "Epoch 472/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6736 - accuracy: 0.7316 - val_loss: 0.7570 - val_accuracy: 0.7488\n",
            "Epoch 473/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6531 - accuracy: 0.7424 - val_loss: 0.7356 - val_accuracy: 0.7391\n",
            "Epoch 474/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6459 - accuracy: 0.7479 - val_loss: 0.7449 - val_accuracy: 0.7440\n",
            "Epoch 475/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6449 - accuracy: 0.7485 - val_loss: 0.7248 - val_accuracy: 0.7585\n",
            "Epoch 476/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6612 - accuracy: 0.7376 - val_loss: 0.7227 - val_accuracy: 0.7536\n",
            "Epoch 477/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6535 - accuracy: 0.7533 - val_loss: 0.7373 - val_accuracy: 0.7488\n",
            "Epoch 478/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6629 - accuracy: 0.7400 - val_loss: 0.7136 - val_accuracy: 0.7536\n",
            "Epoch 479/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6442 - accuracy: 0.7563 - val_loss: 0.7370 - val_accuracy: 0.7536\n",
            "Epoch 480/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6351 - accuracy: 0.7437 - val_loss: 0.7362 - val_accuracy: 0.7488\n",
            "Epoch 481/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6675 - accuracy: 0.7382 - val_loss: 0.7291 - val_accuracy: 0.7295\n",
            "Epoch 482/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6487 - accuracy: 0.7406 - val_loss: 0.7329 - val_accuracy: 0.7536\n",
            "Epoch 483/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6506 - accuracy: 0.7437 - val_loss: 0.7177 - val_accuracy: 0.7488\n",
            "Epoch 484/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6394 - accuracy: 0.7424 - val_loss: 0.7053 - val_accuracy: 0.7488\n",
            "Epoch 485/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6463 - accuracy: 0.7388 - val_loss: 0.7146 - val_accuracy: 0.7488\n",
            "Epoch 486/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6524 - accuracy: 0.7412 - val_loss: 0.7336 - val_accuracy: 0.7343\n",
            "Epoch 487/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6416 - accuracy: 0.7491 - val_loss: 0.7138 - val_accuracy: 0.7585\n",
            "Epoch 488/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6499 - accuracy: 0.7352 - val_loss: 0.7106 - val_accuracy: 0.7488\n",
            "Epoch 489/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6608 - accuracy: 0.7382 - val_loss: 0.7151 - val_accuracy: 0.7585\n",
            "Epoch 490/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6354 - accuracy: 0.7521 - val_loss: 0.7399 - val_accuracy: 0.7488\n",
            "Epoch 491/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6415 - accuracy: 0.7473 - val_loss: 0.7228 - val_accuracy: 0.7633\n",
            "Epoch 492/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6519 - accuracy: 0.7340 - val_loss: 0.7138 - val_accuracy: 0.7585\n",
            "Epoch 493/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6197 - accuracy: 0.7678 - val_loss: 0.7028 - val_accuracy: 0.7778\n",
            "Epoch 494/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6438 - accuracy: 0.7497 - val_loss: 0.7217 - val_accuracy: 0.7585\n",
            "Epoch 495/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.6423 - accuracy: 0.7418 - val_loss: 0.7104 - val_accuracy: 0.7778\n",
            "Epoch 496/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6269 - accuracy: 0.7539 - val_loss: 0.7247 - val_accuracy: 0.7729\n",
            "Epoch 497/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6140 - accuracy: 0.7606 - val_loss: 0.7087 - val_accuracy: 0.7729\n",
            "Epoch 498/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6168 - accuracy: 0.7654 - val_loss: 0.7036 - val_accuracy: 0.7391\n",
            "Epoch 499/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6158 - accuracy: 0.7576 - val_loss: 0.7269 - val_accuracy: 0.7488\n",
            "Epoch 500/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6280 - accuracy: 0.7600 - val_loss: 0.7062 - val_accuracy: 0.7585\n",
            "Epoch 501/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6197 - accuracy: 0.7642 - val_loss: 0.7257 - val_accuracy: 0.7536\n",
            "Epoch 502/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6233 - accuracy: 0.7576 - val_loss: 0.6923 - val_accuracy: 0.7681\n",
            "Epoch 503/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6258 - accuracy: 0.7509 - val_loss: 0.6987 - val_accuracy: 0.7778\n",
            "Epoch 504/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6104 - accuracy: 0.7648 - val_loss: 0.6920 - val_accuracy: 0.7681\n",
            "Epoch 505/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6001 - accuracy: 0.7660 - val_loss: 0.7078 - val_accuracy: 0.7585\n",
            "Epoch 506/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6247 - accuracy: 0.7594 - val_loss: 0.7041 - val_accuracy: 0.7826\n",
            "Epoch 507/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6270 - accuracy: 0.7533 - val_loss: 0.7111 - val_accuracy: 0.7488\n",
            "Epoch 508/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6136 - accuracy: 0.7545 - val_loss: 0.7003 - val_accuracy: 0.7488\n",
            "Epoch 509/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6182 - accuracy: 0.7690 - val_loss: 0.7116 - val_accuracy: 0.7585\n",
            "Epoch 510/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6314 - accuracy: 0.7612 - val_loss: 0.7201 - val_accuracy: 0.7440\n",
            "Epoch 511/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6177 - accuracy: 0.7533 - val_loss: 0.7158 - val_accuracy: 0.7633\n",
            "Epoch 512/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6024 - accuracy: 0.7696 - val_loss: 0.6980 - val_accuracy: 0.7729\n",
            "Epoch 513/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6164 - accuracy: 0.7576 - val_loss: 0.6949 - val_accuracy: 0.7633\n",
            "Epoch 514/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6118 - accuracy: 0.7642 - val_loss: 0.7008 - val_accuracy: 0.7729\n",
            "Epoch 515/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6202 - accuracy: 0.7545 - val_loss: 0.7053 - val_accuracy: 0.7585\n",
            "Epoch 516/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.5938 - accuracy: 0.7618 - val_loss: 0.7048 - val_accuracy: 0.7729\n",
            "Epoch 517/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5998 - accuracy: 0.7539 - val_loss: 0.7091 - val_accuracy: 0.7633\n",
            "Epoch 518/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6037 - accuracy: 0.7660 - val_loss: 0.6958 - val_accuracy: 0.7681\n",
            "Epoch 519/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6046 - accuracy: 0.7588 - val_loss: 0.7008 - val_accuracy: 0.7536\n",
            "Epoch 520/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5888 - accuracy: 0.7684 - val_loss: 0.6971 - val_accuracy: 0.7681\n",
            "Epoch 521/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6135 - accuracy: 0.7576 - val_loss: 0.6972 - val_accuracy: 0.7681\n",
            "Epoch 522/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6114 - accuracy: 0.7624 - val_loss: 0.7151 - val_accuracy: 0.7585\n",
            "Epoch 523/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6102 - accuracy: 0.7630 - val_loss: 0.7052 - val_accuracy: 0.7536\n",
            "Epoch 524/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6091 - accuracy: 0.7600 - val_loss: 0.6888 - val_accuracy: 0.7585\n",
            "Epoch 525/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6144 - accuracy: 0.7582 - val_loss: 0.6942 - val_accuracy: 0.7488\n",
            "Epoch 526/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6001 - accuracy: 0.7642 - val_loss: 0.7073 - val_accuracy: 0.7778\n",
            "Epoch 527/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6106 - accuracy: 0.7588 - val_loss: 0.7033 - val_accuracy: 0.7681\n",
            "Epoch 528/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.5937 - accuracy: 0.7636 - val_loss: 0.6970 - val_accuracy: 0.7536\n",
            "Epoch 529/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5784 - accuracy: 0.7793 - val_loss: 0.6981 - val_accuracy: 0.7681\n",
            "Epoch 530/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6040 - accuracy: 0.7594 - val_loss: 0.6985 - val_accuracy: 0.7826\n",
            "Epoch 531/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5996 - accuracy: 0.7636 - val_loss: 0.6887 - val_accuracy: 0.7729\n",
            "Epoch 532/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6014 - accuracy: 0.7715 - val_loss: 0.6826 - val_accuracy: 0.7633\n",
            "Epoch 533/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.5939 - accuracy: 0.7582 - val_loss: 0.6820 - val_accuracy: 0.7729\n",
            "Epoch 534/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5817 - accuracy: 0.7739 - val_loss: 0.6963 - val_accuracy: 0.7778\n",
            "Epoch 535/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5978 - accuracy: 0.7606 - val_loss: 0.6903 - val_accuracy: 0.7729\n",
            "Epoch 536/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.5889 - accuracy: 0.7684 - val_loss: 0.6929 - val_accuracy: 0.7778\n",
            "Epoch 537/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6015 - accuracy: 0.7642 - val_loss: 0.6894 - val_accuracy: 0.7778\n",
            "Epoch 538/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.5989 - accuracy: 0.7666 - val_loss: 0.7217 - val_accuracy: 0.7729\n",
            "Epoch 539/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6006 - accuracy: 0.7739 - val_loss: 0.7065 - val_accuracy: 0.7633\n",
            "Epoch 540/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.5944 - accuracy: 0.7557 - val_loss: 0.6994 - val_accuracy: 0.7440\n",
            "Epoch 541/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.5866 - accuracy: 0.7787 - val_loss: 0.7020 - val_accuracy: 0.7778\n",
            "Epoch 542/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.5771 - accuracy: 0.7745 - val_loss: 0.6934 - val_accuracy: 0.7633\n",
            "Epoch 543/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.5815 - accuracy: 0.7684 - val_loss: 0.6948 - val_accuracy: 0.7874\n",
            "Epoch 544/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6026 - accuracy: 0.7624 - val_loss: 0.6925 - val_accuracy: 0.7633\n",
            "Epoch 545/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.5876 - accuracy: 0.7805 - val_loss: 0.6928 - val_accuracy: 0.7681\n",
            "Epoch 546/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5602 - accuracy: 0.7799 - val_loss: 0.7001 - val_accuracy: 0.7440\n",
            "Epoch 547/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5768 - accuracy: 0.7696 - val_loss: 0.6958 - val_accuracy: 0.7778\n",
            "Epoch 548/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5687 - accuracy: 0.7799 - val_loss: 0.6896 - val_accuracy: 0.7826\n",
            "Epoch 549/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.5771 - accuracy: 0.7757 - val_loss: 0.6866 - val_accuracy: 0.7778\n",
            "Epoch 550/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.5714 - accuracy: 0.7733 - val_loss: 0.6906 - val_accuracy: 0.7681\n",
            "Epoch 551/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5798 - accuracy: 0.7696 - val_loss: 0.6903 - val_accuracy: 0.7874\n",
            "Epoch 552/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5852 - accuracy: 0.7690 - val_loss: 0.6909 - val_accuracy: 0.7923\n",
            "Epoch 553/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5981 - accuracy: 0.7666 - val_loss: 0.6796 - val_accuracy: 0.7923\n",
            "Epoch 554/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.5694 - accuracy: 0.7745 - val_loss: 0.6804 - val_accuracy: 0.7874\n",
            "Epoch 555/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5913 - accuracy: 0.7684 - val_loss: 0.6721 - val_accuracy: 0.7826\n",
            "Epoch 556/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.5804 - accuracy: 0.7763 - val_loss: 0.7092 - val_accuracy: 0.7729\n",
            "Epoch 557/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5797 - accuracy: 0.7745 - val_loss: 0.6822 - val_accuracy: 0.7633\n",
            "Epoch 558/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5690 - accuracy: 0.7739 - val_loss: 0.6847 - val_accuracy: 0.7488\n",
            "Epoch 559/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.5776 - accuracy: 0.7793 - val_loss: 0.6782 - val_accuracy: 0.7729\n",
            "Epoch 560/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5865 - accuracy: 0.7745 - val_loss: 0.6943 - val_accuracy: 0.7681\n",
            "Epoch 561/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5726 - accuracy: 0.7860 - val_loss: 0.6888 - val_accuracy: 0.7585\n",
            "Epoch 562/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.5668 - accuracy: 0.7890 - val_loss: 0.6825 - val_accuracy: 0.7729\n",
            "Epoch 563/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.5650 - accuracy: 0.7757 - val_loss: 0.6895 - val_accuracy: 0.7585\n",
            "Epoch 564/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5765 - accuracy: 0.7745 - val_loss: 0.6751 - val_accuracy: 0.7826\n",
            "Epoch 565/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5534 - accuracy: 0.7866 - val_loss: 0.6885 - val_accuracy: 0.7488\n",
            "Epoch 566/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.5616 - accuracy: 0.7848 - val_loss: 0.6726 - val_accuracy: 0.7585\n",
            "Epoch 567/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.5515 - accuracy: 0.7878 - val_loss: 0.6868 - val_accuracy: 0.7729\n",
            "Epoch 568/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.5616 - accuracy: 0.7884 - val_loss: 0.6747 - val_accuracy: 0.7585\n",
            "Epoch 569/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.5641 - accuracy: 0.7763 - val_loss: 0.6816 - val_accuracy: 0.7585\n",
            "Epoch 570/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5647 - accuracy: 0.7872 - val_loss: 0.6791 - val_accuracy: 0.7633\n",
            "Epoch 571/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.5878 - accuracy: 0.7745 - val_loss: 0.6942 - val_accuracy: 0.7488\n",
            "Epoch 572/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.5677 - accuracy: 0.7805 - val_loss: 0.6864 - val_accuracy: 0.7536\n",
            "Epoch 573/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5592 - accuracy: 0.7763 - val_loss: 0.6723 - val_accuracy: 0.7729\n",
            "Epoch 574/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5753 - accuracy: 0.7678 - val_loss: 0.6761 - val_accuracy: 0.7681\n",
            "Epoch 575/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.5486 - accuracy: 0.7896 - val_loss: 0.6738 - val_accuracy: 0.7729\n",
            "Epoch 576/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5716 - accuracy: 0.7823 - val_loss: 0.6821 - val_accuracy: 0.7729\n",
            "Epoch 577/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5426 - accuracy: 0.7866 - val_loss: 0.6850 - val_accuracy: 0.7874\n",
            "Epoch 578/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.5658 - accuracy: 0.7848 - val_loss: 0.6868 - val_accuracy: 0.7729\n",
            "Epoch 579/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.5339 - accuracy: 0.7902 - val_loss: 0.6807 - val_accuracy: 0.7778\n",
            "Epoch 580/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.5803 - accuracy: 0.7727 - val_loss: 0.6877 - val_accuracy: 0.7826\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(cnnhistory.history['loss'])\n",
        "plt.plot(cnnhistory.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train','test'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "oQYnuaCrDH_A",
        "outputId": "c0b384db-ae10-47d0-b926-ef8ffd1d75dd"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(cnnhistory.history['accuracy'])\n",
        "plt.plot(cnnhistory.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train','test'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "IFkTuO8nDNdq",
        "outputId": "8d2b47b5-2e61-4b58-bfd1-72f1a0588720"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model.predict(x_testcnn)"
      ],
      "metadata": {
        "id": "A2xtrN5wDQgY"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_f_ohjXKDUpY",
        "outputId": "9b958bfb-8089-41b1-f58b-2f7bce2ecb0f"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.89666525e-01, 7.88844153e-02, 2.29357585e-01, 1.99400023e-01,\n",
              "        1.87114060e-01, 1.15577400e-01],\n",
              "       [2.93714984e-04, 7.38258896e-05, 1.18976914e-05, 9.51366663e-01,\n",
              "        3.05568770e-04, 4.79483195e-02],\n",
              "       [1.53243646e-01, 4.71682847e-02, 1.44306391e-01, 3.30001891e-01,\n",
              "        5.49888574e-02, 2.70290881e-01],\n",
              "       ...,\n",
              "       [1.03029411e-03, 1.49877005e-05, 5.94607322e-03, 2.10445910e-03,\n",
              "        9.70390737e-01, 2.05134302e-02],\n",
              "       [3.68456422e-05, 7.44135678e-01, 2.38068849e-01, 9.31528211e-03,\n",
              "        3.06756375e-03, 5.37581556e-03],\n",
              "       [2.53194623e-04, 3.64286272e-04, 3.49229798e-02, 3.21068009e-03,\n",
              "        9.31395173e-01, 2.98536438e-02]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cmA2bFgsDW3D",
        "outputId": "956e9e5c-3bdf-4cfe-ae87-c82ce5e11286"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([3, 3, 3, 0, 4, 4, 1, 2, 5, 0, 5, 3, 2, 2, 1, 4, 4, 5, 2, 4, 1, 2,\n",
              "       3, 5, 4, 2, 1, 2, 2, 2, 2, 5, 2, 5, 3, 1, 2, 0, 4, 5, 2, 3, 2, 2,\n",
              "       5, 2, 0, 1, 3, 4, 4, 5, 1, 1, 4, 4, 5, 1, 1, 1, 0, 1, 5, 0, 4, 1,\n",
              "       1, 0, 1, 4, 1, 0, 4, 1, 3, 1, 2, 2, 1, 2, 3, 0, 5, 3, 5, 5, 2, 4,\n",
              "       5, 1, 5, 1, 5, 3, 4, 1, 4, 1, 5, 4, 5, 1, 2, 1, 1, 5, 1, 3, 2, 5,\n",
              "       2, 1, 3, 5, 4, 4, 0, 0, 3, 1, 2, 2, 3, 5, 1, 5, 3, 4, 2, 2, 0, 2,\n",
              "       2, 5, 5, 0, 3, 3, 2, 2, 0, 3, 4, 0, 4, 2, 4, 5, 4, 1, 5, 3, 2, 2,\n",
              "       5, 4, 3, 3, 4, 3, 3, 4, 1, 5, 2, 3, 2, 2, 0, 2, 1, 3, 1, 2, 2, 5,\n",
              "       5, 1, 4, 2, 2, 1, 1, 3, 3, 5, 5, 2, 5, 1, 5, 0, 3, 3, 0, 5, 1, 4,\n",
              "       1, 4, 2, 5, 5, 1, 4, 2, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_Ytest = y_test.astype(int)"
      ],
      "metadata": {
        "id": "0PHDKWJWDY3g"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_Ytest"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k68v2i-pDbZE",
        "outputId": "9ea8e707-def8-41ba-d06d-59b6addeb065"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([3, 3, 3, 0, 4, 4, 1, 2, 5, 0, 5, 3, 2, 2, 1, 4, 4, 5, 2, 4, 1, 2,\n",
              "       3, 5, 4, 2, 1, 2, 2, 2, 2, 5, 2, 5, 3, 1, 2, 0, 4, 5, 2, 3, 2, 2,\n",
              "       5, 2, 0, 1, 3, 4, 4, 5, 1, 1, 4, 4, 5, 1, 1, 1, 0, 1, 5, 0, 4, 1,\n",
              "       1, 0, 1, 4, 1, 0, 4, 1, 3, 1, 2, 2, 1, 2, 3, 0, 5, 3, 5, 5, 2, 4,\n",
              "       5, 1, 5, 1, 5, 3, 4, 1, 4, 1, 5, 4, 5, 1, 2, 1, 1, 5, 1, 3, 2, 5,\n",
              "       2, 1, 3, 5, 4, 4, 0, 0, 3, 1, 2, 2, 3, 5, 1, 5, 3, 4, 2, 2, 0, 2,\n",
              "       2, 5, 5, 0, 3, 3, 2, 2, 0, 3, 4, 0, 4, 2, 4, 5, 4, 1, 5, 3, 2, 2,\n",
              "       5, 4, 3, 3, 4, 3, 3, 4, 1, 5, 2, 3, 2, 2, 0, 2, 1, 3, 1, 2, 2, 5,\n",
              "       5, 1, 4, 2, 2, 1, 1, 3, 3, 5, 5, 2, 5, 1, 5, 0, 3, 3, 0, 5, 1, 4,\n",
              "       1, 4, 2, 5, 5, 1, 4, 2, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds1=predictions.argmax(axis=1)\n",
        "preds1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4_cAI39VFhtp",
        "outputId": "1a246773-0c48-4923-c708-9c51650969d0"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2, 3, 3, 4, 4, 4, 1, 2, 5, 1, 4, 3, 2, 2, 0, 4, 4, 3, 3, 4, 2, 2,\n",
              "       2, 3, 4, 2, 1, 0, 2, 2, 2, 5, 2, 5, 3, 1, 2, 0, 4, 5, 2, 3, 2, 2,\n",
              "       3, 2, 1, 1, 3, 4, 4, 2, 1, 1, 4, 4, 5, 1, 1, 1, 3, 1, 2, 0, 4, 1,\n",
              "       1, 1, 1, 4, 0, 2, 4, 1, 3, 2, 2, 2, 0, 2, 1, 0, 5, 3, 5, 5, 2, 3,\n",
              "       5, 1, 5, 1, 5, 3, 2, 2, 4, 1, 5, 4, 5, 1, 5, 1, 1, 5, 1, 3, 2, 5,\n",
              "       5, 0, 3, 5, 4, 4, 2, 0, 3, 0, 1, 2, 1, 3, 1, 3, 3, 4, 2, 2, 0, 4,\n",
              "       2, 3, 3, 0, 3, 3, 2, 4, 0, 5, 4, 0, 4, 4, 4, 2, 4, 1, 5, 3, 2, 2,\n",
              "       5, 4, 3, 5, 4, 5, 3, 4, 2, 5, 2, 3, 2, 2, 0, 2, 1, 3, 1, 4, 4, 4,\n",
              "       5, 1, 4, 2, 4, 1, 1, 3, 3, 5, 5, 2, 5, 1, 4, 1, 3, 3, 2, 5, 2, 4,\n",
              "       1, 4, 5, 5, 5, 3, 4, 1, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "abc = preds1.astype(int).flatten()"
      ],
      "metadata": {
        "id": "H4WEmM60NfQn"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "c = confusion_matrix(new_Ytest, abc) \n",
        "c"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bKEBeEBlFjB8",
        "outputId": "8117ae9f-b10f-4fd3-bacb-33adc4123c5b"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 9,  4,  3,  1,  1,  0],\n",
              "       [ 5, 30,  5,  1,  0,  0],\n",
              "       [ 1,  2, 32,  1,  6,  3],\n",
              "       [ 0,  2,  2, 24,  0,  3],\n",
              "       [ 0,  0,  1,  1, 31,  0],\n",
              "       [ 0,  0,  3,  7,  3, 26]])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m4RjG7LWLSQx",
        "outputId": "2f2f5767-dc49-4e59-bc7e-c42dd6bf3085"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([3, 3, 3, 0, 4, 4, 1, 2, 5, 0, 5, 3, 2, 2, 1, 4, 4, 5, 2, 4, 1, 2,\n",
              "       3, 5, 4, 2, 1, 2, 2, 2, 2, 5, 2, 5, 3, 1, 2, 0, 4, 5, 2, 3, 2, 2,\n",
              "       5, 2, 0, 1, 3, 4, 4, 5, 1, 1, 4, 4, 5, 1, 1, 1, 0, 1, 5, 0, 4, 1,\n",
              "       1, 0, 1, 4, 1, 0, 4, 1, 3, 1, 2, 2, 1, 2, 3, 0, 5, 3, 5, 5, 2, 4,\n",
              "       5, 1, 5, 1, 5, 3, 4, 1, 4, 1, 5, 4, 5, 1, 2, 1, 1, 5, 1, 3, 2, 5,\n",
              "       2, 1, 3, 5, 4, 4, 0, 0, 3, 1, 2, 2, 3, 5, 1, 5, 3, 4, 2, 2, 0, 2,\n",
              "       2, 5, 5, 0, 3, 3, 2, 2, 0, 3, 4, 0, 4, 2, 4, 5, 4, 1, 5, 3, 2, 2,\n",
              "       5, 4, 3, 3, 4, 3, 3, 4, 1, 5, 2, 3, 2, 2, 0, 2, 1, 3, 1, 2, 2, 5,\n",
              "       5, 1, 4, 2, 2, 1, 1, 3, 3, 5, 5, 2, 5, 1, 5, 0, 3, 3, 0, 5, 1, 4,\n",
              "       1, 4, 2, 5, 5, 1, 4, 2, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss, acc =model.evaluate(x_testcnn, y_test)\n",
        "print(\"Restored model, accuracy: {:5.2f}%\".format(100*acc))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n3kzoqPkDqqS",
        "outputId": "9f1e20ee-5375-4d5f-c9d7-b5e7d9b51b84"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7/7 [==============================] - 0s 3ms/step - loss: 0.6963 - accuracy: 0.7343\n",
            "Restored model, accuracy: 73.43%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss, acc =model.evaluate(X_train, y_train)\n",
        "print(\"Restored model train, accuracy: {:5.2f}%\".format(100*acc))"
      ],
      "metadata": {
        "id": "fJDTGH_OUX0z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ef2311f-0aea-4c49-f2f9-49c6c85c189b"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "52/52 [==============================] - 0s 4ms/step - loss: 0.4947 - accuracy: 0.8748\n",
            "Restored model train, accuracy: 87.48%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix,accuracy_score\n",
        "import seaborn as sn\n",
        "\n",
        "print(classification_report(new_Ytest,abc))\n",
        "\n",
        "acc = float(accuracy_score(new_Ytest,abc))*100\n",
        "print(\"----accuracy score %s ----\" % acc)\n",
        "\n",
        "cm = confusion_matrix(new_Ytest,abc)\n",
        "#df_cm = pd.DataFrame(cm)\n",
        "class_names = ['neutral','calm', 'happy','sad','angry', 'fearful' ]\n",
        "df_cm = pd.DataFrame(cm, index=class_names, columns=class_names,)\n",
        "sn.heatmap(df_cm, annot=True, fmt='')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 508
        },
        "id": "SfSC3El94LZg",
        "outputId": "424c4d31-aa0d-441c-f6c0-03e49061f997"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.60      0.50      0.55        18\n",
            "           1       0.79      0.73      0.76        41\n",
            "           2       0.70      0.71      0.70        45\n",
            "           3       0.69      0.77      0.73        31\n",
            "           4       0.76      0.94      0.84        33\n",
            "           5       0.81      0.67      0.73        39\n",
            "\n",
            "    accuracy                           0.73       207\n",
            "   macro avg       0.72      0.72      0.72       207\n",
            "weighted avg       0.74      0.73      0.73       207\n",
            "\n",
            "----accuracy score 73.42995169082126 ----\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "A6UOIsB2xKek"
      },
      "execution_count": 28,
      "outputs": []
    }
  ]
}