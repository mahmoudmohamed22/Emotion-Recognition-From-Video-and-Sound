{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "original_adam_0.00002_without decay_1000_4.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9SRCO-a_AlH5",
        "outputId": "2712a21a-06af-4aa9-ce63-fbac714f78f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install librosa"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Lo4mUwG9RMd",
        "outputId": "5f302c5c-ebba-4ec5-858e-d852c06b11f0"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.7/dist-packages (0.8.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (21.3)\n",
            "Requirement already satisfied: soundfile>=0.10.2 in /usr/local/lib/python3.7/dist-packages (from librosa) (0.10.3.post1)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.1.0)\n",
            "Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.0.2)\n",
            "Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.6.0)\n",
            "Requirement already satisfied: audioread>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (2.1.9)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.21.6)\n",
            "Requirement already satisfied: resampy>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from librosa) (0.2.2)\n",
            "Requirement already satisfied: numba>=0.43.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (0.51.2)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.4.1)\n",
            "Requirement already satisfied: decorator>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba>=0.43.0->librosa) (0.34.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba>=0.43.0->librosa) (57.4.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->librosa) (3.0.9)\n",
            "Requirement already satisfied: appdirs>=1.3.0 in /usr/local/lib/python3.7/dist-packages (from pooch>=1.0->librosa) (1.4.4)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from pooch>=1.0->librosa) (2.23.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2022.5.18.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2.10)\n",
            "Requirement already satisfied: six>=1.3 in /usr/local/lib/python3.7/dist-packages (from resampy>=0.2.2->librosa) (1.15.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn!=0.19.0,>=0.14.0->librosa) (3.1.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.7/dist-packages (from soundfile>=0.10.2->librosa) (1.15.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.0->soundfile>=0.10.2->librosa) (2.21)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HJjcbxwy46bG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "6c91c108-782a-4902-b3d9-c5cbc5c251fe"
      },
      "source": [
        "# Orignial Notebook: https://github.com/MITESHPUTHRANNEU/Speech-Emotion-Analyzer/blob/master/final_results_gender_test.ipynb\n",
        "# This notebook author: Reza Chu\n",
        "# Last Editing Date: 31st May 2019\n",
        "\n",
        "## Python\n",
        "import os\n",
        "import random\n",
        "import sys\n",
        "\n",
        "import IPython\n",
        "from IPython.display import Audio\n",
        "from IPython.display import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "## Package\n",
        "import glob \n",
        "import keras\n",
        "import IPython.display as ipd\n",
        "import librosa\n",
        "import librosa.display\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import plotly.graph_objs as go\n",
        "import plotly.offline as py\n",
        "import plotly.tools as tls\n",
        "import seaborn as sns\n",
        "import scipy.io.wavfile\n",
        "import tensorflow as tf\n",
        "py.init_notebook_mode(connected=True)\n",
        "\n",
        "## Keras\n",
        "from keras import regularizers\n",
        "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping\n",
        "from keras.callbacks import  History, ReduceLROnPlateau, CSVLogger\n",
        "from keras.models import Model, Sequential\n",
        "from keras.layers import Dense, Embedding, LSTM\n",
        "from keras.layers import Input, Flatten, Dropout, Activation, BatchNormalization\n",
        "from keras.layers import Conv1D, MaxPooling1D, AveragePooling1D\n",
        "from keras.preprocessing import sequence\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.utils import np_utils\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "## Sklearn\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "## Rest\n",
        "from scipy.fftpack import fft\n",
        "from scipy import signal\n",
        "from scipy.io import wavfile\n",
        "from tqdm import tqdm\n",
        "\n",
        "input_duration=3\n",
        "# % pylab inline"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "        <script type=\"text/javascript\">\n",
              "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
              "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
              "        if (typeof require !== 'undefined') {\n",
              "        require.undef(\"plotly\");\n",
              "        requirejs.config({\n",
              "            paths: {\n",
              "                'plotly': ['https://cdn.plot.ly/plotly-2.8.3.min']\n",
              "            }\n",
              "        });\n",
              "        require(['plotly'], function(Plotly) {\n",
              "            window._Plotly = Plotly;\n",
              "        });\n",
              "        }\n",
              "        </script>\n",
              "        "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Saving joblib files to not load them again with the loop above\n",
        "\n",
        "# import joblib\n",
        "\n",
        "# X_name = 'x.joblib'\n",
        "# y_name = 'y.joblib'\n",
        "# save_dir = '/content/drive/My Drive/graduation project/audio/paper_code/features'\n",
        "\n",
        "# savedX = joblib.dump(X, os.path.join(save_dir, X_name))\n",
        "# savedy = joblib.dump(y, os.path.join(save_dir, y_name))"
      ],
      "metadata": {
        "id": "UCzic8rlDcuk"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Loading saved models\n",
        "import joblib\n",
        "X = joblib.load('/content/drive/My Drive/graduation project/audio/paper_code/features/x.joblib')\n",
        "y = joblib.load('/content/drive/My Drive/graduation project/audio/paper_code/features/y.joblib')"
      ],
      "metadata": {
        "id": "Q35CN6zDrzg1"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7PSTurzjCo5K",
        "outputId": "40bc4290-6ad1-4f55-dbd9-0843f373fb5b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2068, 40)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.1 ,shuffle = True\n",
        "                                                    , random_state=42)\n",
        "X_train , X_valid, y_train, y_valid = train_test_split(X_train,y_train, test_size=0.1112305212 , shuffle = True \n",
        "                                                       , random_state=42)"
      ],
      "metadata": {
        "id": "Ai4Fy5cPCiq1"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "x_traincnn = np.expand_dims(X_train, axis=2)\n",
        "x_testcnn = np.expand_dims(X_test, axis=2)\n",
        "X_valid= np.expand_dims(X_valid, axis=2)"
      ],
      "metadata": {
        "id": "tp1Fm5K3CEXu"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_traincnn.shape, x_testcnn.shape , X_valid.shape\n",
        "#1861"
      ],
      "metadata": {
        "id": "RI0MxoIPBws5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d89bd4e-242a-443d-db99-5bf1ac0c1dfe"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1654, 40, 1), (207, 40, 1), (207, 40, 1))"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oALhiMUd9G2Y",
        "outputId": "e97f7b85-7403-477f-9ee6-3985cf5088ef"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (2.8.2+zzzcolab20220527125636)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.46.3)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (14.0.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow) (57.4.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.17.3)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.21.6)\n",
            "Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (4.2.0)\n",
            "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.5.3)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.0.0)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.26.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow) (1.5.2)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.23.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.8.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.35.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.6.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (3.3.7)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (4.11.4)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (3.8.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2022.5.18.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (1.24.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (3.2.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from keras.preprocessing import sequence\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from keras.layers import Input, Flatten, Dropout, Activation\n",
        "from keras.layers import Conv1D, MaxPooling1D\n",
        "from keras.models import Model\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras import optimizers\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv1D(128, 8,padding='same', #classifier.add(Convolution2D(64, (3, 3), padding = 'same', input_shape = (128, 128, 3), activation = 'relu'))\n",
        "                 input_shape=(40,1)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(MaxPooling1D(pool_size=(5)))\n",
        "\n",
        "\n",
        "model.add(Conv1D(256,8,padding='same',))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(MaxPooling1D(pool_size=(5)))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(256))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(256))\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "model.add(Dense(6))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "opt = tf.keras.optimizers.Adam(lr=0.00002 , decay=0.0)\n",
        "#opt = tf.keras.optimizers.RMSprop(lr=0.0001, rho=0.9, epsilon=1e-07, decay=0.0)\n",
        "#opt = tf.keras.optimizers.SGD(lr=0.001, momentum=0.0, decay=0.0, nesterov=False)"
      ],
      "metadata": {
        "id": "g74fXWVAC4Cr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d67e46c8-84b9-4e8a-ceca-b1c57060b65f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning:\n",
            "\n",
            "The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H6ukOxAGC_I4",
        "outputId": "9a043276-f3a7-4768-d74e-6c73fc33548e"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d (Conv1D)             (None, 40, 128)           1152      \n",
            "                                                                 \n",
            " activation (Activation)     (None, 40, 128)           0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 40, 128)           0         \n",
            "                                                                 \n",
            " max_pooling1d (MaxPooling1D  (None, 8, 128)           0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv1d_1 (Conv1D)           (None, 8, 256)            262400    \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 8, 256)            0         \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 8, 256)            0         \n",
            "                                                                 \n",
            " max_pooling1d_1 (MaxPooling  (None, 1, 256)           0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 256)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 256)               65792     \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 256)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 256)               65792     \n",
            "                                                                 \n",
            " activation_3 (Activation)   (None, 256)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 6)                 1542      \n",
            "                                                                 \n",
            " activation_4 (Activation)   (None, 6)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 396,678\n",
            "Trainable params: 396,678\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='sparse_categorical_crossentropy',\n",
        "              optimizer=opt,\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "AbMlLNk4DCBM"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an Instance of Early Stopping Callback.\n",
        "early_stopping_callback = EarlyStopping(monitor = 'val_loss', patience = 25, mode = 'min', restore_best_weights = True)\n",
        "\n",
        "cnnhistory=model.fit(x_traincnn, y_train, batch_size=16, epochs=1000 , shuffle = True, \n",
        "                     validation_data=(X_valid, y_valid) \n",
        "                     , callbacks = [early_stopping_callback]\n",
        "                     )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RI1v2AuADFhy",
        "outputId": "05ab99f3-1520-4090-8465-fa7f56e253c4"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "104/104 [==============================] - 4s 7ms/step - loss: 7.0536 - accuracy: 0.1759 - val_loss: 2.3728 - val_accuracy: 0.2560\n",
            "Epoch 2/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 5.0236 - accuracy: 0.1892 - val_loss: 2.3938 - val_accuracy: 0.1787\n",
            "Epoch 3/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 4.5105 - accuracy: 0.1651 - val_loss: 2.3219 - val_accuracy: 0.2415\n",
            "Epoch 4/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 3.8977 - accuracy: 0.1820 - val_loss: 2.1258 - val_accuracy: 0.2464\n",
            "Epoch 5/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 3.4778 - accuracy: 0.1989 - val_loss: 1.9059 - val_accuracy: 0.2271\n",
            "Epoch 6/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 3.3376 - accuracy: 0.1947 - val_loss: 1.8328 - val_accuracy: 0.2126\n",
            "Epoch 7/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 2.9802 - accuracy: 0.1959 - val_loss: 1.8897 - val_accuracy: 0.1836\n",
            "Epoch 8/1000\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 2.9085 - accuracy: 0.1977 - val_loss: 1.7760 - val_accuracy: 0.2319\n",
            "Epoch 9/1000\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 2.7553 - accuracy: 0.1844 - val_loss: 1.7462 - val_accuracy: 0.2512\n",
            "Epoch 10/1000\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 2.5703 - accuracy: 0.2050 - val_loss: 1.7301 - val_accuracy: 0.2464\n",
            "Epoch 11/1000\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 2.5775 - accuracy: 0.2170 - val_loss: 1.8107 - val_accuracy: 0.2560\n",
            "Epoch 12/1000\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 2.4819 - accuracy: 0.2086 - val_loss: 1.7807 - val_accuracy: 0.2464\n",
            "Epoch 13/1000\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 2.4056 - accuracy: 0.2128 - val_loss: 1.8091 - val_accuracy: 0.2657\n",
            "Epoch 14/1000\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 2.3321 - accuracy: 0.2007 - val_loss: 1.7300 - val_accuracy: 0.2512\n",
            "Epoch 15/1000\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 2.2812 - accuracy: 0.2177 - val_loss: 1.7260 - val_accuracy: 0.2754\n",
            "Epoch 16/1000\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 2.2138 - accuracy: 0.2273 - val_loss: 1.7530 - val_accuracy: 0.2174\n",
            "Epoch 17/1000\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 2.2077 - accuracy: 0.2140 - val_loss: 1.7720 - val_accuracy: 0.2271\n",
            "Epoch 18/1000\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 2.1330 - accuracy: 0.2122 - val_loss: 1.7254 - val_accuracy: 0.2464\n",
            "Epoch 19/1000\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 2.0869 - accuracy: 0.2231 - val_loss: 1.7242 - val_accuracy: 0.2995\n",
            "Epoch 20/1000\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 2.0757 - accuracy: 0.2110 - val_loss: 1.7342 - val_accuracy: 0.3237\n",
            "Epoch 21/1000\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 2.0543 - accuracy: 0.2237 - val_loss: 1.7687 - val_accuracy: 0.2464\n",
            "Epoch 22/1000\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 2.0255 - accuracy: 0.2267 - val_loss: 1.7214 - val_accuracy: 0.2899\n",
            "Epoch 23/1000\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 2.0106 - accuracy: 0.2388 - val_loss: 1.7239 - val_accuracy: 0.2560\n",
            "Epoch 24/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 2.0250 - accuracy: 0.2170 - val_loss: 1.7242 - val_accuracy: 0.2367\n",
            "Epoch 25/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 2.0015 - accuracy: 0.2146 - val_loss: 1.7372 - val_accuracy: 0.3430\n",
            "Epoch 26/1000\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 1.9584 - accuracy: 0.2261 - val_loss: 1.7418 - val_accuracy: 0.2947\n",
            "Epoch 27/1000\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 1.9085 - accuracy: 0.2304 - val_loss: 1.7317 - val_accuracy: 0.2995\n",
            "Epoch 28/1000\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 1.8989 - accuracy: 0.2503 - val_loss: 1.7233 - val_accuracy: 0.3043\n",
            "Epoch 29/1000\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 1.9050 - accuracy: 0.2412 - val_loss: 1.6982 - val_accuracy: 0.3188\n",
            "Epoch 30/1000\n",
            "104/104 [==============================] - 1s 9ms/step - loss: 1.9197 - accuracy: 0.2400 - val_loss: 1.7132 - val_accuracy: 0.2995\n",
            "Epoch 31/1000\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 1.8681 - accuracy: 0.2491 - val_loss: 1.6915 - val_accuracy: 0.3043\n",
            "Epoch 32/1000\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 1.8929 - accuracy: 0.2479 - val_loss: 1.6996 - val_accuracy: 0.3382\n",
            "Epoch 33/1000\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 1.8741 - accuracy: 0.2370 - val_loss: 1.6817 - val_accuracy: 0.3140\n",
            "Epoch 34/1000\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 1.8453 - accuracy: 0.2346 - val_loss: 1.6902 - val_accuracy: 0.2899\n",
            "Epoch 35/1000\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 1.8401 - accuracy: 0.2515 - val_loss: 1.6707 - val_accuracy: 0.3430\n",
            "Epoch 36/1000\n",
            "104/104 [==============================] - 1s 10ms/step - loss: 1.8113 - accuracy: 0.2618 - val_loss: 1.6679 - val_accuracy: 0.3285\n",
            "Epoch 37/1000\n",
            "104/104 [==============================] - 1s 10ms/step - loss: 1.8410 - accuracy: 0.2557 - val_loss: 1.6767 - val_accuracy: 0.3188\n",
            "Epoch 38/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 1.8204 - accuracy: 0.2424 - val_loss: 1.6761 - val_accuracy: 0.3333\n",
            "Epoch 39/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.8331 - accuracy: 0.2443 - val_loss: 1.6693 - val_accuracy: 0.3478\n",
            "Epoch 40/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.7878 - accuracy: 0.2642 - val_loss: 1.6778 - val_accuracy: 0.2754\n",
            "Epoch 41/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.8009 - accuracy: 0.2570 - val_loss: 1.6688 - val_accuracy: 0.3333\n",
            "Epoch 42/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.8044 - accuracy: 0.2539 - val_loss: 1.6738 - val_accuracy: 0.3768\n",
            "Epoch 43/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.7684 - accuracy: 0.2479 - val_loss: 1.6659 - val_accuracy: 0.3527\n",
            "Epoch 44/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.7748 - accuracy: 0.2545 - val_loss: 1.6580 - val_accuracy: 0.3623\n",
            "Epoch 45/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.7632 - accuracy: 0.2739 - val_loss: 1.6611 - val_accuracy: 0.3478\n",
            "Epoch 46/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.7533 - accuracy: 0.2709 - val_loss: 1.6525 - val_accuracy: 0.3623\n",
            "Epoch 47/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.7690 - accuracy: 0.2648 - val_loss: 1.6498 - val_accuracy: 0.3478\n",
            "Epoch 48/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.7549 - accuracy: 0.2551 - val_loss: 1.6345 - val_accuracy: 0.3865\n",
            "Epoch 49/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.7375 - accuracy: 0.2721 - val_loss: 1.6366 - val_accuracy: 0.3285\n",
            "Epoch 50/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.7529 - accuracy: 0.2696 - val_loss: 1.6466 - val_accuracy: 0.3188\n",
            "Epoch 51/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.7262 - accuracy: 0.2757 - val_loss: 1.6419 - val_accuracy: 0.3333\n",
            "Epoch 52/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.7495 - accuracy: 0.2696 - val_loss: 1.6328 - val_accuracy: 0.3768\n",
            "Epoch 53/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.7211 - accuracy: 0.2799 - val_loss: 1.6223 - val_accuracy: 0.3816\n",
            "Epoch 54/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.7241 - accuracy: 0.2805 - val_loss: 1.6194 - val_accuracy: 0.3623\n",
            "Epoch 55/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.6963 - accuracy: 0.2799 - val_loss: 1.6329 - val_accuracy: 0.3816\n",
            "Epoch 56/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.6920 - accuracy: 0.2842 - val_loss: 1.6188 - val_accuracy: 0.3478\n",
            "Epoch 57/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.7054 - accuracy: 0.2854 - val_loss: 1.6148 - val_accuracy: 0.3768\n",
            "Epoch 58/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.6824 - accuracy: 0.3023 - val_loss: 1.6009 - val_accuracy: 0.3382\n",
            "Epoch 59/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.6962 - accuracy: 0.2727 - val_loss: 1.6032 - val_accuracy: 0.4058\n",
            "Epoch 60/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.6655 - accuracy: 0.2872 - val_loss: 1.5994 - val_accuracy: 0.3768\n",
            "Epoch 61/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.6668 - accuracy: 0.2926 - val_loss: 1.6038 - val_accuracy: 0.4010\n",
            "Epoch 62/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.6910 - accuracy: 0.2878 - val_loss: 1.5813 - val_accuracy: 0.4348\n",
            "Epoch 63/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.6578 - accuracy: 0.3162 - val_loss: 1.5906 - val_accuracy: 0.3961\n",
            "Epoch 64/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.6449 - accuracy: 0.3077 - val_loss: 1.5833 - val_accuracy: 0.3720\n",
            "Epoch 65/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.6307 - accuracy: 0.3259 - val_loss: 1.5956 - val_accuracy: 0.3430\n",
            "Epoch 66/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.6632 - accuracy: 0.3180 - val_loss: 1.5823 - val_accuracy: 0.3623\n",
            "Epoch 67/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.6359 - accuracy: 0.3198 - val_loss: 1.5783 - val_accuracy: 0.3527\n",
            "Epoch 68/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.6411 - accuracy: 0.3162 - val_loss: 1.5786 - val_accuracy: 0.3961\n",
            "Epoch 69/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.6269 - accuracy: 0.3337 - val_loss: 1.5744 - val_accuracy: 0.3623\n",
            "Epoch 70/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.6377 - accuracy: 0.3089 - val_loss: 1.5727 - val_accuracy: 0.3768\n",
            "Epoch 71/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.6223 - accuracy: 0.3343 - val_loss: 1.5597 - val_accuracy: 0.3720\n",
            "Epoch 72/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.6562 - accuracy: 0.3071 - val_loss: 1.5727 - val_accuracy: 0.3575\n",
            "Epoch 73/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.6003 - accuracy: 0.3186 - val_loss: 1.5575 - val_accuracy: 0.3575\n",
            "Epoch 74/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.6242 - accuracy: 0.3162 - val_loss: 1.5661 - val_accuracy: 0.3527\n",
            "Epoch 75/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.6055 - accuracy: 0.3247 - val_loss: 1.5397 - val_accuracy: 0.3816\n",
            "Epoch 76/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.6087 - accuracy: 0.3198 - val_loss: 1.5413 - val_accuracy: 0.3720\n",
            "Epoch 77/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.5977 - accuracy: 0.3301 - val_loss: 1.5369 - val_accuracy: 0.4010\n",
            "Epoch 78/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.6224 - accuracy: 0.3065 - val_loss: 1.5314 - val_accuracy: 0.4251\n",
            "Epoch 79/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.5932 - accuracy: 0.3386 - val_loss: 1.5443 - val_accuracy: 0.3720\n",
            "Epoch 80/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.5740 - accuracy: 0.3525 - val_loss: 1.5400 - val_accuracy: 0.3768\n",
            "Epoch 81/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.5817 - accuracy: 0.3349 - val_loss: 1.5224 - val_accuracy: 0.4058\n",
            "Epoch 82/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.5897 - accuracy: 0.3440 - val_loss: 1.5127 - val_accuracy: 0.4203\n",
            "Epoch 83/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.5748 - accuracy: 0.3537 - val_loss: 1.5089 - val_accuracy: 0.4444\n",
            "Epoch 84/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.5782 - accuracy: 0.3507 - val_loss: 1.5016 - val_accuracy: 0.4155\n",
            "Epoch 85/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.5792 - accuracy: 0.3446 - val_loss: 1.5047 - val_accuracy: 0.4155\n",
            "Epoch 86/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.5509 - accuracy: 0.3585 - val_loss: 1.4947 - val_accuracy: 0.4300\n",
            "Epoch 87/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.5590 - accuracy: 0.3501 - val_loss: 1.4959 - val_accuracy: 0.4396\n",
            "Epoch 88/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.5529 - accuracy: 0.3634 - val_loss: 1.4860 - val_accuracy: 0.4589\n",
            "Epoch 89/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.5429 - accuracy: 0.3640 - val_loss: 1.4849 - val_accuracy: 0.4493\n",
            "Epoch 90/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.5383 - accuracy: 0.3597 - val_loss: 1.4847 - val_accuracy: 0.4444\n",
            "Epoch 91/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.5590 - accuracy: 0.3495 - val_loss: 1.4913 - val_accuracy: 0.3913\n",
            "Epoch 92/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.5406 - accuracy: 0.3519 - val_loss: 1.4767 - val_accuracy: 0.4541\n",
            "Epoch 93/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.5404 - accuracy: 0.3549 - val_loss: 1.4850 - val_accuracy: 0.4396\n",
            "Epoch 94/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.5173 - accuracy: 0.3609 - val_loss: 1.4810 - val_accuracy: 0.4589\n",
            "Epoch 95/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.5223 - accuracy: 0.3628 - val_loss: 1.4679 - val_accuracy: 0.4589\n",
            "Epoch 96/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.5074 - accuracy: 0.3736 - val_loss: 1.4670 - val_accuracy: 0.4106\n",
            "Epoch 97/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.5068 - accuracy: 0.3779 - val_loss: 1.4707 - val_accuracy: 0.4589\n",
            "Epoch 98/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.4901 - accuracy: 0.3748 - val_loss: 1.4622 - val_accuracy: 0.4444\n",
            "Epoch 99/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.5109 - accuracy: 0.3706 - val_loss: 1.4630 - val_accuracy: 0.4444\n",
            "Epoch 100/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.5182 - accuracy: 0.3803 - val_loss: 1.4655 - val_accuracy: 0.4348\n",
            "Epoch 101/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.5002 - accuracy: 0.3779 - val_loss: 1.4567 - val_accuracy: 0.4058\n",
            "Epoch 102/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.4989 - accuracy: 0.3791 - val_loss: 1.4543 - val_accuracy: 0.4686\n",
            "Epoch 103/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.4584 - accuracy: 0.4045 - val_loss: 1.4491 - val_accuracy: 0.4783\n",
            "Epoch 104/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.4782 - accuracy: 0.3912 - val_loss: 1.4334 - val_accuracy: 0.4734\n",
            "Epoch 105/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.4776 - accuracy: 0.3857 - val_loss: 1.4425 - val_accuracy: 0.4734\n",
            "Epoch 106/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.4749 - accuracy: 0.4033 - val_loss: 1.4210 - val_accuracy: 0.4493\n",
            "Epoch 107/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.4614 - accuracy: 0.3888 - val_loss: 1.4431 - val_accuracy: 0.4444\n",
            "Epoch 108/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.4491 - accuracy: 0.4208 - val_loss: 1.4464 - val_accuracy: 0.4879\n",
            "Epoch 109/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.4668 - accuracy: 0.3948 - val_loss: 1.4299 - val_accuracy: 0.4541\n",
            "Epoch 110/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.4561 - accuracy: 0.4002 - val_loss: 1.4190 - val_accuracy: 0.4541\n",
            "Epoch 111/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.4514 - accuracy: 0.4008 - val_loss: 1.4026 - val_accuracy: 0.4783\n",
            "Epoch 112/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.4487 - accuracy: 0.3918 - val_loss: 1.3963 - val_accuracy: 0.4831\n",
            "Epoch 113/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.4452 - accuracy: 0.4045 - val_loss: 1.3973 - val_accuracy: 0.4928\n",
            "Epoch 114/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.4200 - accuracy: 0.4238 - val_loss: 1.3962 - val_accuracy: 0.4541\n",
            "Epoch 115/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.4433 - accuracy: 0.4021 - val_loss: 1.3905 - val_accuracy: 0.4541\n",
            "Epoch 116/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.4085 - accuracy: 0.4268 - val_loss: 1.3878 - val_accuracy: 0.4976\n",
            "Epoch 117/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.4055 - accuracy: 0.4281 - val_loss: 1.3765 - val_accuracy: 0.4928\n",
            "Epoch 118/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.4150 - accuracy: 0.4202 - val_loss: 1.3845 - val_accuracy: 0.4928\n",
            "Epoch 119/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.4260 - accuracy: 0.4039 - val_loss: 1.3726 - val_accuracy: 0.5266\n",
            "Epoch 120/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.4023 - accuracy: 0.4274 - val_loss: 1.3705 - val_accuracy: 0.5362\n",
            "Epoch 121/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.4045 - accuracy: 0.4377 - val_loss: 1.3556 - val_accuracy: 0.4783\n",
            "Epoch 122/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.3872 - accuracy: 0.4329 - val_loss: 1.3581 - val_accuracy: 0.4348\n",
            "Epoch 123/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.3911 - accuracy: 0.4256 - val_loss: 1.3580 - val_accuracy: 0.4976\n",
            "Epoch 124/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.3851 - accuracy: 0.4377 - val_loss: 1.3618 - val_accuracy: 0.5169\n",
            "Epoch 125/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.3831 - accuracy: 0.4256 - val_loss: 1.3520 - val_accuracy: 0.4976\n",
            "Epoch 126/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.3687 - accuracy: 0.4407 - val_loss: 1.3461 - val_accuracy: 0.5266\n",
            "Epoch 127/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.3755 - accuracy: 0.4365 - val_loss: 1.3458 - val_accuracy: 0.4638\n",
            "Epoch 128/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.3485 - accuracy: 0.4674 - val_loss: 1.3328 - val_accuracy: 0.5169\n",
            "Epoch 129/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.3668 - accuracy: 0.4456 - val_loss: 1.3288 - val_accuracy: 0.5411\n",
            "Epoch 130/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.3527 - accuracy: 0.4389 - val_loss: 1.3209 - val_accuracy: 0.5217\n",
            "Epoch 131/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.3667 - accuracy: 0.4426 - val_loss: 1.3226 - val_accuracy: 0.5072\n",
            "Epoch 132/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.3557 - accuracy: 0.4444 - val_loss: 1.3125 - val_accuracy: 0.5217\n",
            "Epoch 133/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.3411 - accuracy: 0.4746 - val_loss: 1.3085 - val_accuracy: 0.5411\n",
            "Epoch 134/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.3504 - accuracy: 0.4407 - val_loss: 1.3119 - val_accuracy: 0.5411\n",
            "Epoch 135/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.3611 - accuracy: 0.4365 - val_loss: 1.3156 - val_accuracy: 0.5266\n",
            "Epoch 136/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.3482 - accuracy: 0.4516 - val_loss: 1.3134 - val_accuracy: 0.5314\n",
            "Epoch 137/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.3331 - accuracy: 0.4625 - val_loss: 1.3091 - val_accuracy: 0.5266\n",
            "Epoch 138/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.3367 - accuracy: 0.4583 - val_loss: 1.3014 - val_accuracy: 0.5121\n",
            "Epoch 139/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.3129 - accuracy: 0.4643 - val_loss: 1.2994 - val_accuracy: 0.5121\n",
            "Epoch 140/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.3426 - accuracy: 0.4462 - val_loss: 1.2962 - val_accuracy: 0.4976\n",
            "Epoch 141/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.3286 - accuracy: 0.4541 - val_loss: 1.2863 - val_accuracy: 0.5314\n",
            "Epoch 142/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.3238 - accuracy: 0.4686 - val_loss: 1.2852 - val_accuracy: 0.4928\n",
            "Epoch 143/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.3144 - accuracy: 0.4655 - val_loss: 1.2811 - val_accuracy: 0.5169\n",
            "Epoch 144/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.3293 - accuracy: 0.4504 - val_loss: 1.2817 - val_accuracy: 0.5459\n",
            "Epoch 145/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.2967 - accuracy: 0.4879 - val_loss: 1.2646 - val_accuracy: 0.5507\n",
            "Epoch 146/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.2843 - accuracy: 0.4915 - val_loss: 1.2655 - val_accuracy: 0.5362\n",
            "Epoch 147/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.2990 - accuracy: 0.4692 - val_loss: 1.2738 - val_accuracy: 0.5024\n",
            "Epoch 148/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.2928 - accuracy: 0.4746 - val_loss: 1.2629 - val_accuracy: 0.5411\n",
            "Epoch 149/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.2932 - accuracy: 0.4674 - val_loss: 1.2783 - val_accuracy: 0.5169\n",
            "Epoch 150/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.2823 - accuracy: 0.4692 - val_loss: 1.2531 - val_accuracy: 0.5459\n",
            "Epoch 151/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.2791 - accuracy: 0.4879 - val_loss: 1.2625 - val_accuracy: 0.5072\n",
            "Epoch 152/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.2934 - accuracy: 0.4631 - val_loss: 1.2486 - val_accuracy: 0.5556\n",
            "Epoch 153/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.2758 - accuracy: 0.4843 - val_loss: 1.2540 - val_accuracy: 0.5362\n",
            "Epoch 154/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.2860 - accuracy: 0.4782 - val_loss: 1.2469 - val_accuracy: 0.5411\n",
            "Epoch 155/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.2805 - accuracy: 0.4800 - val_loss: 1.2425 - val_accuracy: 0.5556\n",
            "Epoch 156/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.2573 - accuracy: 0.5012 - val_loss: 1.2399 - val_accuracy: 0.5266\n",
            "Epoch 157/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.2619 - accuracy: 0.4946 - val_loss: 1.2352 - val_accuracy: 0.5652\n",
            "Epoch 158/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.2325 - accuracy: 0.5097 - val_loss: 1.2338 - val_accuracy: 0.5411\n",
            "Epoch 159/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.2414 - accuracy: 0.4849 - val_loss: 1.2380 - val_accuracy: 0.5604\n",
            "Epoch 160/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.2479 - accuracy: 0.4897 - val_loss: 1.2320 - val_accuracy: 0.5845\n",
            "Epoch 161/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.2273 - accuracy: 0.5115 - val_loss: 1.2361 - val_accuracy: 0.5556\n",
            "Epoch 162/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.2407 - accuracy: 0.5085 - val_loss: 1.2296 - val_accuracy: 0.5266\n",
            "Epoch 163/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.2475 - accuracy: 0.4952 - val_loss: 1.2219 - val_accuracy: 0.5121\n",
            "Epoch 164/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.2450 - accuracy: 0.5054 - val_loss: 1.2238 - val_accuracy: 0.5556\n",
            "Epoch 165/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.2296 - accuracy: 0.5030 - val_loss: 1.2201 - val_accuracy: 0.5700\n",
            "Epoch 166/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.2464 - accuracy: 0.5018 - val_loss: 1.1987 - val_accuracy: 0.6039\n",
            "Epoch 167/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.2208 - accuracy: 0.5157 - val_loss: 1.2119 - val_accuracy: 0.5459\n",
            "Epoch 168/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.2198 - accuracy: 0.5097 - val_loss: 1.2047 - val_accuracy: 0.5845\n",
            "Epoch 169/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.2246 - accuracy: 0.5006 - val_loss: 1.1949 - val_accuracy: 0.5749\n",
            "Epoch 170/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.2263 - accuracy: 0.5073 - val_loss: 1.1876 - val_accuracy: 0.5459\n",
            "Epoch 171/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.1980 - accuracy: 0.5181 - val_loss: 1.1809 - val_accuracy: 0.6039\n",
            "Epoch 172/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.2136 - accuracy: 0.5042 - val_loss: 1.1709 - val_accuracy: 0.6039\n",
            "Epoch 173/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.1888 - accuracy: 0.5091 - val_loss: 1.1695 - val_accuracy: 0.5894\n",
            "Epoch 174/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.1920 - accuracy: 0.5308 - val_loss: 1.1735 - val_accuracy: 0.5990\n",
            "Epoch 175/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.1980 - accuracy: 0.5097 - val_loss: 1.1672 - val_accuracy: 0.5604\n",
            "Epoch 176/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.2165 - accuracy: 0.5042 - val_loss: 1.1825 - val_accuracy: 0.5700\n",
            "Epoch 177/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.2002 - accuracy: 0.5085 - val_loss: 1.1615 - val_accuracy: 0.5797\n",
            "Epoch 178/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.2021 - accuracy: 0.5169 - val_loss: 1.1700 - val_accuracy: 0.5556\n",
            "Epoch 179/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.1973 - accuracy: 0.5109 - val_loss: 1.1617 - val_accuracy: 0.5990\n",
            "Epoch 180/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.1897 - accuracy: 0.5230 - val_loss: 1.1528 - val_accuracy: 0.6135\n",
            "Epoch 181/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.1936 - accuracy: 0.5157 - val_loss: 1.1576 - val_accuracy: 0.5700\n",
            "Epoch 182/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.1894 - accuracy: 0.5163 - val_loss: 1.1661 - val_accuracy: 0.5942\n",
            "Epoch 183/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.1677 - accuracy: 0.5224 - val_loss: 1.1479 - val_accuracy: 0.6184\n",
            "Epoch 184/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.1586 - accuracy: 0.5369 - val_loss: 1.1442 - val_accuracy: 0.6087\n",
            "Epoch 185/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.1742 - accuracy: 0.5254 - val_loss: 1.1433 - val_accuracy: 0.6232\n",
            "Epoch 186/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.1998 - accuracy: 0.5163 - val_loss: 1.1408 - val_accuracy: 0.6039\n",
            "Epoch 187/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.1749 - accuracy: 0.5320 - val_loss: 1.1454 - val_accuracy: 0.6232\n",
            "Epoch 188/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.1465 - accuracy: 0.5417 - val_loss: 1.1502 - val_accuracy: 0.5845\n",
            "Epoch 189/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.1561 - accuracy: 0.5278 - val_loss: 1.1323 - val_accuracy: 0.5845\n",
            "Epoch 190/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.1540 - accuracy: 0.5308 - val_loss: 1.1338 - val_accuracy: 0.5894\n",
            "Epoch 191/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.1325 - accuracy: 0.5502 - val_loss: 1.1361 - val_accuracy: 0.6184\n",
            "Epoch 192/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.1554 - accuracy: 0.5320 - val_loss: 1.1368 - val_accuracy: 0.6232\n",
            "Epoch 193/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.1329 - accuracy: 0.5484 - val_loss: 1.1298 - val_accuracy: 0.5845\n",
            "Epoch 194/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.1402 - accuracy: 0.5472 - val_loss: 1.1347 - val_accuracy: 0.5845\n",
            "Epoch 195/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.1499 - accuracy: 0.5429 - val_loss: 1.1326 - val_accuracy: 0.6135\n",
            "Epoch 196/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.1351 - accuracy: 0.5423 - val_loss: 1.1265 - val_accuracy: 0.5990\n",
            "Epoch 197/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.1236 - accuracy: 0.5484 - val_loss: 1.1169 - val_accuracy: 0.6087\n",
            "Epoch 198/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.1484 - accuracy: 0.5459 - val_loss: 1.1126 - val_accuracy: 0.6087\n",
            "Epoch 199/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.1328 - accuracy: 0.5502 - val_loss: 1.1077 - val_accuracy: 0.5990\n",
            "Epoch 200/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.1381 - accuracy: 0.5544 - val_loss: 1.1063 - val_accuracy: 0.6135\n",
            "Epoch 201/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.1182 - accuracy: 0.5605 - val_loss: 1.1016 - val_accuracy: 0.6087\n",
            "Epoch 202/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.1043 - accuracy: 0.5490 - val_loss: 1.0954 - val_accuracy: 0.6039\n",
            "Epoch 203/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.1222 - accuracy: 0.5671 - val_loss: 1.1080 - val_accuracy: 0.6039\n",
            "Epoch 204/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.1046 - accuracy: 0.5550 - val_loss: 1.1036 - val_accuracy: 0.6087\n",
            "Epoch 205/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0966 - accuracy: 0.5659 - val_loss: 1.0949 - val_accuracy: 0.5990\n",
            "Epoch 206/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.0983 - accuracy: 0.5641 - val_loss: 1.1051 - val_accuracy: 0.6135\n",
            "Epoch 207/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.1168 - accuracy: 0.5593 - val_loss: 1.0972 - val_accuracy: 0.6232\n",
            "Epoch 208/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0914 - accuracy: 0.5701 - val_loss: 1.0840 - val_accuracy: 0.6232\n",
            "Epoch 209/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.0976 - accuracy: 0.5550 - val_loss: 1.0920 - val_accuracy: 0.6087\n",
            "Epoch 210/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.0911 - accuracy: 0.5574 - val_loss: 1.0897 - val_accuracy: 0.6087\n",
            "Epoch 211/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.0858 - accuracy: 0.5635 - val_loss: 1.0975 - val_accuracy: 0.5797\n",
            "Epoch 212/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0937 - accuracy: 0.5768 - val_loss: 1.0686 - val_accuracy: 0.6473\n",
            "Epoch 213/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0737 - accuracy: 0.5774 - val_loss: 1.0719 - val_accuracy: 0.6184\n",
            "Epoch 214/1000\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 1.0978 - accuracy: 0.5562 - val_loss: 1.0796 - val_accuracy: 0.5990\n",
            "Epoch 215/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.0799 - accuracy: 0.5701 - val_loss: 1.0699 - val_accuracy: 0.6232\n",
            "Epoch 216/1000\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 1.0853 - accuracy: 0.5605 - val_loss: 1.0696 - val_accuracy: 0.6425\n",
            "Epoch 217/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0983 - accuracy: 0.5629 - val_loss: 1.0921 - val_accuracy: 0.5749\n",
            "Epoch 218/1000\n",
            "104/104 [==============================] - 1s 9ms/step - loss: 1.0643 - accuracy: 0.5701 - val_loss: 1.0636 - val_accuracy: 0.6377\n",
            "Epoch 219/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0669 - accuracy: 0.5689 - val_loss: 1.0576 - val_accuracy: 0.6377\n",
            "Epoch 220/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.0669 - accuracy: 0.5913 - val_loss: 1.0576 - val_accuracy: 0.6184\n",
            "Epoch 221/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.0692 - accuracy: 0.5762 - val_loss: 1.0605 - val_accuracy: 0.6232\n",
            "Epoch 222/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0577 - accuracy: 0.5828 - val_loss: 1.0551 - val_accuracy: 0.6473\n",
            "Epoch 223/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0577 - accuracy: 0.5786 - val_loss: 1.0512 - val_accuracy: 0.5942\n",
            "Epoch 224/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0541 - accuracy: 0.5804 - val_loss: 1.0575 - val_accuracy: 0.6087\n",
            "Epoch 225/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.0625 - accuracy: 0.5828 - val_loss: 1.0316 - val_accuracy: 0.6522\n",
            "Epoch 226/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.0549 - accuracy: 0.5804 - val_loss: 1.0422 - val_accuracy: 0.6377\n",
            "Epoch 227/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.0507 - accuracy: 0.5762 - val_loss: 1.0403 - val_accuracy: 0.6135\n",
            "Epoch 228/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.0376 - accuracy: 0.5949 - val_loss: 1.0475 - val_accuracy: 0.6039\n",
            "Epoch 229/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.0657 - accuracy: 0.5641 - val_loss: 1.0546 - val_accuracy: 0.6039\n",
            "Epoch 230/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.0457 - accuracy: 0.5780 - val_loss: 1.0279 - val_accuracy: 0.6232\n",
            "Epoch 231/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0492 - accuracy: 0.5998 - val_loss: 1.0370 - val_accuracy: 0.6377\n",
            "Epoch 232/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.0366 - accuracy: 0.5865 - val_loss: 1.0285 - val_accuracy: 0.6473\n",
            "Epoch 233/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.0460 - accuracy: 0.5707 - val_loss: 1.0326 - val_accuracy: 0.6522\n",
            "Epoch 234/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.0236 - accuracy: 0.5937 - val_loss: 1.0325 - val_accuracy: 0.6473\n",
            "Epoch 235/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.0257 - accuracy: 0.5865 - val_loss: 1.0170 - val_accuracy: 0.6329\n",
            "Epoch 236/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.0479 - accuracy: 0.5816 - val_loss: 1.0243 - val_accuracy: 0.6280\n",
            "Epoch 237/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.0098 - accuracy: 0.5961 - val_loss: 1.0139 - val_accuracy: 0.6473\n",
            "Epoch 238/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.0189 - accuracy: 0.5913 - val_loss: 1.0141 - val_accuracy: 0.6329\n",
            "Epoch 239/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0072 - accuracy: 0.6034 - val_loss: 1.0188 - val_accuracy: 0.6425\n",
            "Epoch 240/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.0076 - accuracy: 0.5955 - val_loss: 1.0161 - val_accuracy: 0.6473\n",
            "Epoch 241/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.0278 - accuracy: 0.5907 - val_loss: 1.0403 - val_accuracy: 0.6184\n",
            "Epoch 242/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.0182 - accuracy: 0.5889 - val_loss: 1.0089 - val_accuracy: 0.6329\n",
            "Epoch 243/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0246 - accuracy: 0.5937 - val_loss: 1.0146 - val_accuracy: 0.6329\n",
            "Epoch 244/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9919 - accuracy: 0.6040 - val_loss: 1.0164 - val_accuracy: 0.6425\n",
            "Epoch 245/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.0146 - accuracy: 0.5901 - val_loss: 1.0152 - val_accuracy: 0.6377\n",
            "Epoch 246/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0063 - accuracy: 0.6064 - val_loss: 1.0065 - val_accuracy: 0.6280\n",
            "Epoch 247/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.9891 - accuracy: 0.5979 - val_loss: 1.0015 - val_accuracy: 0.6329\n",
            "Epoch 248/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0405 - accuracy: 0.5744 - val_loss: 0.9959 - val_accuracy: 0.6667\n",
            "Epoch 249/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9846 - accuracy: 0.6088 - val_loss: 1.0041 - val_accuracy: 0.6473\n",
            "Epoch 250/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0015 - accuracy: 0.5937 - val_loss: 0.9993 - val_accuracy: 0.6522\n",
            "Epoch 251/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0096 - accuracy: 0.5937 - val_loss: 0.9931 - val_accuracy: 0.6667\n",
            "Epoch 252/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.9957 - accuracy: 0.6131 - val_loss: 0.9988 - val_accuracy: 0.6618\n",
            "Epoch 253/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.9922 - accuracy: 0.6197 - val_loss: 1.0092 - val_accuracy: 0.6280\n",
            "Epoch 254/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.9959 - accuracy: 0.6100 - val_loss: 0.9918 - val_accuracy: 0.6280\n",
            "Epoch 255/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0012 - accuracy: 0.5985 - val_loss: 0.9920 - val_accuracy: 0.6425\n",
            "Epoch 256/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9975 - accuracy: 0.6010 - val_loss: 1.0004 - val_accuracy: 0.6377\n",
            "Epoch 257/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9803 - accuracy: 0.6173 - val_loss: 0.9974 - val_accuracy: 0.6473\n",
            "Epoch 258/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.9713 - accuracy: 0.6191 - val_loss: 1.0046 - val_accuracy: 0.6232\n",
            "Epoch 259/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.9611 - accuracy: 0.6239 - val_loss: 0.9908 - val_accuracy: 0.6425\n",
            "Epoch 260/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9754 - accuracy: 0.6034 - val_loss: 0.9687 - val_accuracy: 0.6715\n",
            "Epoch 261/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.9676 - accuracy: 0.6143 - val_loss: 0.9871 - val_accuracy: 0.6522\n",
            "Epoch 262/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.9913 - accuracy: 0.6022 - val_loss: 0.9934 - val_accuracy: 0.6425\n",
            "Epoch 263/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9673 - accuracy: 0.6137 - val_loss: 0.9679 - val_accuracy: 0.6618\n",
            "Epoch 264/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9433 - accuracy: 0.6221 - val_loss: 0.9638 - val_accuracy: 0.6570\n",
            "Epoch 265/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9814 - accuracy: 0.6131 - val_loss: 0.9716 - val_accuracy: 0.6570\n",
            "Epoch 266/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9626 - accuracy: 0.6179 - val_loss: 0.9786 - val_accuracy: 0.6377\n",
            "Epoch 267/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.9498 - accuracy: 0.6233 - val_loss: 0.9623 - val_accuracy: 0.6715\n",
            "Epoch 268/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9377 - accuracy: 0.6239 - val_loss: 0.9692 - val_accuracy: 0.6377\n",
            "Epoch 269/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.9483 - accuracy: 0.6348 - val_loss: 0.9650 - val_accuracy: 0.6667\n",
            "Epoch 270/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9571 - accuracy: 0.6197 - val_loss: 0.9591 - val_accuracy: 0.6763\n",
            "Epoch 271/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.9317 - accuracy: 0.6348 - val_loss: 0.9529 - val_accuracy: 0.6667\n",
            "Epoch 272/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9437 - accuracy: 0.6245 - val_loss: 0.9564 - val_accuracy: 0.6667\n",
            "Epoch 273/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.9378 - accuracy: 0.6306 - val_loss: 0.9426 - val_accuracy: 0.6522\n",
            "Epoch 274/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.9555 - accuracy: 0.6185 - val_loss: 0.9390 - val_accuracy: 0.6715\n",
            "Epoch 275/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.9330 - accuracy: 0.6203 - val_loss: 0.9455 - val_accuracy: 0.6570\n",
            "Epoch 276/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.9327 - accuracy: 0.6481 - val_loss: 0.9415 - val_accuracy: 0.6522\n",
            "Epoch 277/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.9201 - accuracy: 0.6397 - val_loss: 0.9497 - val_accuracy: 0.6522\n",
            "Epoch 278/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.9375 - accuracy: 0.6264 - val_loss: 0.9392 - val_accuracy: 0.6763\n",
            "Epoch 279/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9188 - accuracy: 0.6366 - val_loss: 0.9389 - val_accuracy: 0.6715\n",
            "Epoch 280/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9116 - accuracy: 0.6415 - val_loss: 0.9346 - val_accuracy: 0.6763\n",
            "Epoch 281/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.8945 - accuracy: 0.6493 - val_loss: 0.9392 - val_accuracy: 0.6667\n",
            "Epoch 282/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9375 - accuracy: 0.6348 - val_loss: 0.9435 - val_accuracy: 0.6763\n",
            "Epoch 283/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.9421 - accuracy: 0.6264 - val_loss: 0.9295 - val_accuracy: 0.6618\n",
            "Epoch 284/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9275 - accuracy: 0.6306 - val_loss: 0.9404 - val_accuracy: 0.6715\n",
            "Epoch 285/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9068 - accuracy: 0.6372 - val_loss: 0.9503 - val_accuracy: 0.6329\n",
            "Epoch 286/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9286 - accuracy: 0.6378 - val_loss: 0.9248 - val_accuracy: 0.7005\n",
            "Epoch 287/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.9162 - accuracy: 0.6348 - val_loss: 0.9154 - val_accuracy: 0.6908\n",
            "Epoch 288/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9130 - accuracy: 0.6372 - val_loss: 0.9301 - val_accuracy: 0.6812\n",
            "Epoch 289/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9110 - accuracy: 0.6427 - val_loss: 0.9299 - val_accuracy: 0.6618\n",
            "Epoch 290/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9216 - accuracy: 0.6372 - val_loss: 0.9264 - val_accuracy: 0.6763\n",
            "Epoch 291/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.9137 - accuracy: 0.6427 - val_loss: 0.9308 - val_accuracy: 0.6618\n",
            "Epoch 292/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9359 - accuracy: 0.6288 - val_loss: 0.9215 - val_accuracy: 0.6667\n",
            "Epoch 293/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9100 - accuracy: 0.6312 - val_loss: 0.9217 - val_accuracy: 0.6908\n",
            "Epoch 294/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8894 - accuracy: 0.6590 - val_loss: 0.9184 - val_accuracy: 0.6667\n",
            "Epoch 295/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8856 - accuracy: 0.6427 - val_loss: 0.9064 - val_accuracy: 0.6908\n",
            "Epoch 296/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.9121 - accuracy: 0.6264 - val_loss: 0.9157 - val_accuracy: 0.6908\n",
            "Epoch 297/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.9044 - accuracy: 0.6403 - val_loss: 0.9219 - val_accuracy: 0.6860\n",
            "Epoch 298/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.8845 - accuracy: 0.6554 - val_loss: 0.8989 - val_accuracy: 0.6957\n",
            "Epoch 299/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.8890 - accuracy: 0.6481 - val_loss: 0.9120 - val_accuracy: 0.6908\n",
            "Epoch 300/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.9021 - accuracy: 0.6397 - val_loss: 0.9109 - val_accuracy: 0.6812\n",
            "Epoch 301/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.8984 - accuracy: 0.6451 - val_loss: 0.9054 - val_accuracy: 0.6908\n",
            "Epoch 302/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8877 - accuracy: 0.6578 - val_loss: 0.9053 - val_accuracy: 0.6667\n",
            "Epoch 303/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8701 - accuracy: 0.6669 - val_loss: 0.9126 - val_accuracy: 0.6860\n",
            "Epoch 304/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.8911 - accuracy: 0.6487 - val_loss: 0.9124 - val_accuracy: 0.7101\n",
            "Epoch 305/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8945 - accuracy: 0.6542 - val_loss: 0.8954 - val_accuracy: 0.6860\n",
            "Epoch 306/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.8767 - accuracy: 0.6554 - val_loss: 0.9142 - val_accuracy: 0.6715\n",
            "Epoch 307/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8711 - accuracy: 0.6663 - val_loss: 0.9057 - val_accuracy: 0.6860\n",
            "Epoch 308/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.8782 - accuracy: 0.6530 - val_loss: 0.9200 - val_accuracy: 0.6715\n",
            "Epoch 309/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8978 - accuracy: 0.6548 - val_loss: 0.9152 - val_accuracy: 0.6667\n",
            "Epoch 310/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.8579 - accuracy: 0.6620 - val_loss: 0.9060 - val_accuracy: 0.7005\n",
            "Epoch 311/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.8738 - accuracy: 0.6493 - val_loss: 0.9102 - val_accuracy: 0.6860\n",
            "Epoch 312/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8842 - accuracy: 0.6475 - val_loss: 0.8981 - val_accuracy: 0.7150\n",
            "Epoch 313/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8734 - accuracy: 0.6348 - val_loss: 0.8997 - val_accuracy: 0.6812\n",
            "Epoch 314/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8767 - accuracy: 0.6445 - val_loss: 0.8985 - val_accuracy: 0.6860\n",
            "Epoch 315/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8846 - accuracy: 0.6451 - val_loss: 0.8871 - val_accuracy: 0.6957\n",
            "Epoch 316/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8720 - accuracy: 0.6638 - val_loss: 0.8809 - val_accuracy: 0.7005\n",
            "Epoch 317/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.8750 - accuracy: 0.6518 - val_loss: 0.8915 - val_accuracy: 0.6957\n",
            "Epoch 318/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8451 - accuracy: 0.6675 - val_loss: 0.8845 - val_accuracy: 0.6860\n",
            "Epoch 319/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.8797 - accuracy: 0.6644 - val_loss: 0.9213 - val_accuracy: 0.6715\n",
            "Epoch 320/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8688 - accuracy: 0.6638 - val_loss: 0.8912 - val_accuracy: 0.7005\n",
            "Epoch 321/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8695 - accuracy: 0.6566 - val_loss: 0.8974 - val_accuracy: 0.6763\n",
            "Epoch 322/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8333 - accuracy: 0.6862 - val_loss: 0.8969 - val_accuracy: 0.6812\n",
            "Epoch 323/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.8477 - accuracy: 0.6723 - val_loss: 0.8822 - val_accuracy: 0.7005\n",
            "Epoch 324/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8517 - accuracy: 0.6657 - val_loss: 0.8625 - val_accuracy: 0.7246\n",
            "Epoch 325/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8384 - accuracy: 0.6705 - val_loss: 0.8808 - val_accuracy: 0.6860\n",
            "Epoch 326/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8563 - accuracy: 0.6681 - val_loss: 0.8630 - val_accuracy: 0.7005\n",
            "Epoch 327/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8506 - accuracy: 0.6505 - val_loss: 0.8672 - val_accuracy: 0.7150\n",
            "Epoch 328/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.8423 - accuracy: 0.6608 - val_loss: 0.8712 - val_accuracy: 0.7053\n",
            "Epoch 329/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.8517 - accuracy: 0.6584 - val_loss: 0.8815 - val_accuracy: 0.7005\n",
            "Epoch 330/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8284 - accuracy: 0.6796 - val_loss: 0.8689 - val_accuracy: 0.6763\n",
            "Epoch 331/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8585 - accuracy: 0.6590 - val_loss: 0.8762 - val_accuracy: 0.7198\n",
            "Epoch 332/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8704 - accuracy: 0.6499 - val_loss: 0.8772 - val_accuracy: 0.7150\n",
            "Epoch 333/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.8281 - accuracy: 0.6741 - val_loss: 0.8706 - val_accuracy: 0.7053\n",
            "Epoch 334/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.8537 - accuracy: 0.6602 - val_loss: 0.8702 - val_accuracy: 0.7198\n",
            "Epoch 335/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.8185 - accuracy: 0.6747 - val_loss: 0.8732 - val_accuracy: 0.6908\n",
            "Epoch 336/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.8282 - accuracy: 0.6717 - val_loss: 0.8763 - val_accuracy: 0.6812\n",
            "Epoch 337/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.8352 - accuracy: 0.6644 - val_loss: 0.8536 - val_accuracy: 0.7053\n",
            "Epoch 338/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.8329 - accuracy: 0.6614 - val_loss: 0.8769 - val_accuracy: 0.7198\n",
            "Epoch 339/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8249 - accuracy: 0.6790 - val_loss: 0.8626 - val_accuracy: 0.7005\n",
            "Epoch 340/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8169 - accuracy: 0.6868 - val_loss: 0.8754 - val_accuracy: 0.6957\n",
            "Epoch 341/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8194 - accuracy: 0.6747 - val_loss: 0.8743 - val_accuracy: 0.7005\n",
            "Epoch 342/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8445 - accuracy: 0.6614 - val_loss: 0.8587 - val_accuracy: 0.6860\n",
            "Epoch 343/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8256 - accuracy: 0.6699 - val_loss: 0.8792 - val_accuracy: 0.6812\n",
            "Epoch 344/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.8304 - accuracy: 0.6548 - val_loss: 0.8699 - val_accuracy: 0.6860\n",
            "Epoch 345/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8361 - accuracy: 0.6717 - val_loss: 0.8477 - val_accuracy: 0.7150\n",
            "Epoch 346/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.8253 - accuracy: 0.6620 - val_loss: 0.8657 - val_accuracy: 0.6860\n",
            "Epoch 347/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8234 - accuracy: 0.6717 - val_loss: 0.8597 - val_accuracy: 0.7101\n",
            "Epoch 348/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.8109 - accuracy: 0.6904 - val_loss: 0.8634 - val_accuracy: 0.6957\n",
            "Epoch 349/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7967 - accuracy: 0.6971 - val_loss: 0.8517 - val_accuracy: 0.7053\n",
            "Epoch 350/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8080 - accuracy: 0.6886 - val_loss: 0.8397 - val_accuracy: 0.7198\n",
            "Epoch 351/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8491 - accuracy: 0.6560 - val_loss: 0.8503 - val_accuracy: 0.7101\n",
            "Epoch 352/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8184 - accuracy: 0.6790 - val_loss: 0.8396 - val_accuracy: 0.7053\n",
            "Epoch 353/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8269 - accuracy: 0.6784 - val_loss: 0.8552 - val_accuracy: 0.6715\n",
            "Epoch 354/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.7972 - accuracy: 0.6765 - val_loss: 0.8550 - val_accuracy: 0.7005\n",
            "Epoch 355/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8169 - accuracy: 0.6747 - val_loss: 0.8439 - val_accuracy: 0.7150\n",
            "Epoch 356/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8253 - accuracy: 0.6687 - val_loss: 0.8639 - val_accuracy: 0.6957\n",
            "Epoch 357/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7982 - accuracy: 0.6808 - val_loss: 0.8560 - val_accuracy: 0.6908\n",
            "Epoch 358/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8184 - accuracy: 0.6784 - val_loss: 0.8585 - val_accuracy: 0.6957\n",
            "Epoch 359/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8157 - accuracy: 0.6802 - val_loss: 0.8472 - val_accuracy: 0.7150\n",
            "Epoch 360/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7959 - accuracy: 0.6868 - val_loss: 0.8468 - val_accuracy: 0.6908\n",
            "Epoch 361/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.7962 - accuracy: 0.6844 - val_loss: 0.8577 - val_accuracy: 0.7005\n",
            "Epoch 362/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.7930 - accuracy: 0.6923 - val_loss: 0.8481 - val_accuracy: 0.6957\n",
            "Epoch 363/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.7938 - accuracy: 0.6886 - val_loss: 0.8392 - val_accuracy: 0.7150\n",
            "Epoch 364/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8022 - accuracy: 0.6693 - val_loss: 0.8217 - val_accuracy: 0.7246\n",
            "Epoch 365/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7965 - accuracy: 0.6778 - val_loss: 0.8252 - val_accuracy: 0.7053\n",
            "Epoch 366/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.7873 - accuracy: 0.6862 - val_loss: 0.8232 - val_accuracy: 0.7101\n",
            "Epoch 367/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7970 - accuracy: 0.6880 - val_loss: 0.8268 - val_accuracy: 0.7150\n",
            "Epoch 368/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.7915 - accuracy: 0.6844 - val_loss: 0.8173 - val_accuracy: 0.6957\n",
            "Epoch 369/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8149 - accuracy: 0.6741 - val_loss: 0.8242 - val_accuracy: 0.7150\n",
            "Epoch 370/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.7964 - accuracy: 0.6796 - val_loss: 0.8400 - val_accuracy: 0.7005\n",
            "Epoch 371/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.7861 - accuracy: 0.6874 - val_loss: 0.8305 - val_accuracy: 0.7246\n",
            "Epoch 372/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7702 - accuracy: 0.7007 - val_loss: 0.8104 - val_accuracy: 0.7440\n",
            "Epoch 373/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7821 - accuracy: 0.6868 - val_loss: 0.8154 - val_accuracy: 0.7343\n",
            "Epoch 374/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7860 - accuracy: 0.6826 - val_loss: 0.8163 - val_accuracy: 0.7295\n",
            "Epoch 375/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8058 - accuracy: 0.6753 - val_loss: 0.8084 - val_accuracy: 0.7391\n",
            "Epoch 376/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7651 - accuracy: 0.7001 - val_loss: 0.8335 - val_accuracy: 0.6763\n",
            "Epoch 377/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7683 - accuracy: 0.6965 - val_loss: 0.8095 - val_accuracy: 0.7101\n",
            "Epoch 378/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7693 - accuracy: 0.6989 - val_loss: 0.8166 - val_accuracy: 0.7101\n",
            "Epoch 379/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7632 - accuracy: 0.7031 - val_loss: 0.8223 - val_accuracy: 0.7101\n",
            "Epoch 380/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7714 - accuracy: 0.6983 - val_loss: 0.8336 - val_accuracy: 0.7053\n",
            "Epoch 381/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8040 - accuracy: 0.6790 - val_loss: 0.8239 - val_accuracy: 0.7101\n",
            "Epoch 382/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7658 - accuracy: 0.7086 - val_loss: 0.8252 - val_accuracy: 0.7101\n",
            "Epoch 383/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7781 - accuracy: 0.6874 - val_loss: 0.8114 - val_accuracy: 0.6908\n",
            "Epoch 384/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7787 - accuracy: 0.6917 - val_loss: 0.8059 - val_accuracy: 0.7101\n",
            "Epoch 385/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7916 - accuracy: 0.6844 - val_loss: 0.8200 - val_accuracy: 0.7053\n",
            "Epoch 386/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7811 - accuracy: 0.6959 - val_loss: 0.8332 - val_accuracy: 0.7053\n",
            "Epoch 387/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.7474 - accuracy: 0.7122 - val_loss: 0.8110 - val_accuracy: 0.7101\n",
            "Epoch 388/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7522 - accuracy: 0.7044 - val_loss: 0.8207 - val_accuracy: 0.7005\n",
            "Epoch 389/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7549 - accuracy: 0.6935 - val_loss: 0.8091 - val_accuracy: 0.7053\n",
            "Epoch 390/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.7490 - accuracy: 0.7050 - val_loss: 0.7934 - val_accuracy: 0.7295\n",
            "Epoch 391/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7599 - accuracy: 0.6953 - val_loss: 0.8007 - val_accuracy: 0.7053\n",
            "Epoch 392/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7509 - accuracy: 0.7056 - val_loss: 0.8162 - val_accuracy: 0.6860\n",
            "Epoch 393/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.7809 - accuracy: 0.6898 - val_loss: 0.7996 - val_accuracy: 0.7150\n",
            "Epoch 394/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7473 - accuracy: 0.7098 - val_loss: 0.8130 - val_accuracy: 0.7101\n",
            "Epoch 395/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7384 - accuracy: 0.7062 - val_loss: 0.8246 - val_accuracy: 0.6860\n",
            "Epoch 396/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7409 - accuracy: 0.7050 - val_loss: 0.8176 - val_accuracy: 0.7053\n",
            "Epoch 397/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7290 - accuracy: 0.7140 - val_loss: 0.8074 - val_accuracy: 0.7150\n",
            "Epoch 398/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7315 - accuracy: 0.7056 - val_loss: 0.7999 - val_accuracy: 0.7198\n",
            "Epoch 399/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.7372 - accuracy: 0.7110 - val_loss: 0.7937 - val_accuracy: 0.7391\n",
            "Epoch 400/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7582 - accuracy: 0.6977 - val_loss: 0.7829 - val_accuracy: 0.7343\n",
            "Epoch 401/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7468 - accuracy: 0.7044 - val_loss: 0.7976 - val_accuracy: 0.7295\n",
            "Epoch 402/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7431 - accuracy: 0.6989 - val_loss: 0.7898 - val_accuracy: 0.7295\n",
            "Epoch 403/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7412 - accuracy: 0.7050 - val_loss: 0.7862 - val_accuracy: 0.7295\n",
            "Epoch 404/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7323 - accuracy: 0.7086 - val_loss: 0.8039 - val_accuracy: 0.7150\n",
            "Epoch 405/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7421 - accuracy: 0.6995 - val_loss: 0.7860 - val_accuracy: 0.7343\n",
            "Epoch 406/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7564 - accuracy: 0.7013 - val_loss: 0.7958 - val_accuracy: 0.7343\n",
            "Epoch 407/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.7572 - accuracy: 0.6989 - val_loss: 0.8128 - val_accuracy: 0.7005\n",
            "Epoch 408/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.7425 - accuracy: 0.7050 - val_loss: 0.8194 - val_accuracy: 0.6763\n",
            "Epoch 409/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7324 - accuracy: 0.7068 - val_loss: 0.7928 - val_accuracy: 0.7198\n",
            "Epoch 410/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7334 - accuracy: 0.7092 - val_loss: 0.7976 - val_accuracy: 0.7295\n",
            "Epoch 411/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7393 - accuracy: 0.7116 - val_loss: 0.7847 - val_accuracy: 0.7198\n",
            "Epoch 412/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7402 - accuracy: 0.7140 - val_loss: 0.7822 - val_accuracy: 0.7295\n",
            "Epoch 413/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7351 - accuracy: 0.7164 - val_loss: 0.7887 - val_accuracy: 0.7440\n",
            "Epoch 414/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7370 - accuracy: 0.7037 - val_loss: 0.7864 - val_accuracy: 0.7440\n",
            "Epoch 415/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.7242 - accuracy: 0.7128 - val_loss: 0.7941 - val_accuracy: 0.7295\n",
            "Epoch 416/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7229 - accuracy: 0.7207 - val_loss: 0.7889 - val_accuracy: 0.7246\n",
            "Epoch 417/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7170 - accuracy: 0.7285 - val_loss: 0.7771 - val_accuracy: 0.7198\n",
            "Epoch 418/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7278 - accuracy: 0.7044 - val_loss: 0.7992 - val_accuracy: 0.7246\n",
            "Epoch 419/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7247 - accuracy: 0.7104 - val_loss: 0.7831 - val_accuracy: 0.7391\n",
            "Epoch 420/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7201 - accuracy: 0.7231 - val_loss: 0.7757 - val_accuracy: 0.7343\n",
            "Epoch 421/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7127 - accuracy: 0.7213 - val_loss: 0.7673 - val_accuracy: 0.7440\n",
            "Epoch 422/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7409 - accuracy: 0.7140 - val_loss: 0.7788 - val_accuracy: 0.7198\n",
            "Epoch 423/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7187 - accuracy: 0.7164 - val_loss: 0.7936 - val_accuracy: 0.7198\n",
            "Epoch 424/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.7182 - accuracy: 0.7195 - val_loss: 0.7716 - val_accuracy: 0.7150\n",
            "Epoch 425/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7149 - accuracy: 0.7158 - val_loss: 0.7750 - val_accuracy: 0.7150\n",
            "Epoch 426/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.7237 - accuracy: 0.7098 - val_loss: 0.8005 - val_accuracy: 0.7053\n",
            "Epoch 427/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7298 - accuracy: 0.7104 - val_loss: 0.7811 - val_accuracy: 0.7198\n",
            "Epoch 428/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.7329 - accuracy: 0.7189 - val_loss: 0.7803 - val_accuracy: 0.7391\n",
            "Epoch 429/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6932 - accuracy: 0.7352 - val_loss: 0.7768 - val_accuracy: 0.7391\n",
            "Epoch 430/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.7218 - accuracy: 0.7086 - val_loss: 0.7784 - val_accuracy: 0.7198\n",
            "Epoch 431/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7056 - accuracy: 0.7189 - val_loss: 0.7850 - val_accuracy: 0.7150\n",
            "Epoch 432/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6936 - accuracy: 0.7255 - val_loss: 0.7793 - val_accuracy: 0.7246\n",
            "Epoch 433/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7044 - accuracy: 0.7170 - val_loss: 0.7596 - val_accuracy: 0.7343\n",
            "Epoch 434/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7102 - accuracy: 0.7183 - val_loss: 0.7739 - val_accuracy: 0.7198\n",
            "Epoch 435/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7113 - accuracy: 0.7219 - val_loss: 0.7712 - val_accuracy: 0.7295\n",
            "Epoch 436/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6711 - accuracy: 0.7249 - val_loss: 0.7674 - val_accuracy: 0.7295\n",
            "Epoch 437/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7040 - accuracy: 0.7316 - val_loss: 0.7562 - val_accuracy: 0.7295\n",
            "Epoch 438/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7082 - accuracy: 0.7098 - val_loss: 0.7602 - val_accuracy: 0.7343\n",
            "Epoch 439/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7107 - accuracy: 0.7170 - val_loss: 0.7639 - val_accuracy: 0.7391\n",
            "Epoch 440/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6957 - accuracy: 0.7195 - val_loss: 0.7588 - val_accuracy: 0.7391\n",
            "Epoch 441/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6983 - accuracy: 0.7243 - val_loss: 0.7532 - val_accuracy: 0.7295\n",
            "Epoch 442/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7081 - accuracy: 0.7110 - val_loss: 0.7667 - val_accuracy: 0.7391\n",
            "Epoch 443/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6904 - accuracy: 0.7249 - val_loss: 0.7665 - val_accuracy: 0.7488\n",
            "Epoch 444/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6849 - accuracy: 0.7273 - val_loss: 0.7591 - val_accuracy: 0.7585\n",
            "Epoch 445/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7115 - accuracy: 0.7074 - val_loss: 0.7600 - val_accuracy: 0.7536\n",
            "Epoch 446/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6943 - accuracy: 0.7249 - val_loss: 0.7783 - val_accuracy: 0.7198\n",
            "Epoch 447/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6929 - accuracy: 0.7207 - val_loss: 0.7807 - val_accuracy: 0.7246\n",
            "Epoch 448/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.6802 - accuracy: 0.7364 - val_loss: 0.7768 - val_accuracy: 0.7391\n",
            "Epoch 449/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6873 - accuracy: 0.7267 - val_loss: 0.7694 - val_accuracy: 0.7246\n",
            "Epoch 450/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7093 - accuracy: 0.7231 - val_loss: 0.7664 - val_accuracy: 0.7150\n",
            "Epoch 451/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6807 - accuracy: 0.7418 - val_loss: 0.7546 - val_accuracy: 0.7440\n",
            "Epoch 452/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6904 - accuracy: 0.7291 - val_loss: 0.7600 - val_accuracy: 0.7343\n",
            "Epoch 453/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6600 - accuracy: 0.7509 - val_loss: 0.7450 - val_accuracy: 0.7391\n",
            "Epoch 454/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6837 - accuracy: 0.7352 - val_loss: 0.7550 - val_accuracy: 0.7343\n",
            "Epoch 455/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6871 - accuracy: 0.7207 - val_loss: 0.7548 - val_accuracy: 0.7488\n",
            "Epoch 456/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6722 - accuracy: 0.7430 - val_loss: 0.7575 - val_accuracy: 0.7246\n",
            "Epoch 457/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6660 - accuracy: 0.7352 - val_loss: 0.7575 - val_accuracy: 0.7343\n",
            "Epoch 458/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.7075 - accuracy: 0.7122 - val_loss: 0.7669 - val_accuracy: 0.7295\n",
            "Epoch 459/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6853 - accuracy: 0.7177 - val_loss: 0.7747 - val_accuracy: 0.7198\n",
            "Epoch 460/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6802 - accuracy: 0.7346 - val_loss: 0.7291 - val_accuracy: 0.7488\n",
            "Epoch 461/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6525 - accuracy: 0.7424 - val_loss: 0.7525 - val_accuracy: 0.7440\n",
            "Epoch 462/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6696 - accuracy: 0.7418 - val_loss: 0.7495 - val_accuracy: 0.7343\n",
            "Epoch 463/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6634 - accuracy: 0.7376 - val_loss: 0.7485 - val_accuracy: 0.7488\n",
            "Epoch 464/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6857 - accuracy: 0.7352 - val_loss: 0.7416 - val_accuracy: 0.7391\n",
            "Epoch 465/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6890 - accuracy: 0.7310 - val_loss: 0.7585 - val_accuracy: 0.7343\n",
            "Epoch 466/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6721 - accuracy: 0.7376 - val_loss: 0.7513 - val_accuracy: 0.7391\n",
            "Epoch 467/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6824 - accuracy: 0.7358 - val_loss: 0.7494 - val_accuracy: 0.7536\n",
            "Epoch 468/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6518 - accuracy: 0.7497 - val_loss: 0.7527 - val_accuracy: 0.7295\n",
            "Epoch 469/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6655 - accuracy: 0.7310 - val_loss: 0.7360 - val_accuracy: 0.7440\n",
            "Epoch 470/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6825 - accuracy: 0.7310 - val_loss: 0.7406 - val_accuracy: 0.7343\n",
            "Epoch 471/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6801 - accuracy: 0.7328 - val_loss: 0.7334 - val_accuracy: 0.7585\n",
            "Epoch 472/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6592 - accuracy: 0.7485 - val_loss: 0.7515 - val_accuracy: 0.7391\n",
            "Epoch 473/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6518 - accuracy: 0.7461 - val_loss: 0.7472 - val_accuracy: 0.7391\n",
            "Epoch 474/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6650 - accuracy: 0.7418 - val_loss: 0.7428 - val_accuracy: 0.7343\n",
            "Epoch 475/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6455 - accuracy: 0.7412 - val_loss: 0.7350 - val_accuracy: 0.7633\n",
            "Epoch 476/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6515 - accuracy: 0.7400 - val_loss: 0.7384 - val_accuracy: 0.7488\n",
            "Epoch 477/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6396 - accuracy: 0.7551 - val_loss: 0.7371 - val_accuracy: 0.7391\n",
            "Epoch 478/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6444 - accuracy: 0.7443 - val_loss: 0.7334 - val_accuracy: 0.7488\n",
            "Epoch 479/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6635 - accuracy: 0.7358 - val_loss: 0.7197 - val_accuracy: 0.7633\n",
            "Epoch 480/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6549 - accuracy: 0.7400 - val_loss: 0.7491 - val_accuracy: 0.7343\n",
            "Epoch 481/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6581 - accuracy: 0.7352 - val_loss: 0.7405 - val_accuracy: 0.7343\n",
            "Epoch 482/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6610 - accuracy: 0.7358 - val_loss: 0.7486 - val_accuracy: 0.7391\n",
            "Epoch 483/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6584 - accuracy: 0.7412 - val_loss: 0.7359 - val_accuracy: 0.7488\n",
            "Epoch 484/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6511 - accuracy: 0.7322 - val_loss: 0.7334 - val_accuracy: 0.7633\n",
            "Epoch 485/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6500 - accuracy: 0.7491 - val_loss: 0.7343 - val_accuracy: 0.7391\n",
            "Epoch 486/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6537 - accuracy: 0.7394 - val_loss: 0.7572 - val_accuracy: 0.7295\n",
            "Epoch 487/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6658 - accuracy: 0.7443 - val_loss: 0.7459 - val_accuracy: 0.7440\n",
            "Epoch 488/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6369 - accuracy: 0.7443 - val_loss: 0.7498 - val_accuracy: 0.7391\n",
            "Epoch 489/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6399 - accuracy: 0.7660 - val_loss: 0.7327 - val_accuracy: 0.7440\n",
            "Epoch 490/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6628 - accuracy: 0.7358 - val_loss: 0.7308 - val_accuracy: 0.7440\n",
            "Epoch 491/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6497 - accuracy: 0.7461 - val_loss: 0.7433 - val_accuracy: 0.7391\n",
            "Epoch 492/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6409 - accuracy: 0.7418 - val_loss: 0.7560 - val_accuracy: 0.7198\n",
            "Epoch 493/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6291 - accuracy: 0.7479 - val_loss: 0.7389 - val_accuracy: 0.7295\n",
            "Epoch 494/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6392 - accuracy: 0.7400 - val_loss: 0.7332 - val_accuracy: 0.7585\n",
            "Epoch 495/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5984 - accuracy: 0.7696 - val_loss: 0.7388 - val_accuracy: 0.7488\n",
            "Epoch 496/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6646 - accuracy: 0.7231 - val_loss: 0.7374 - val_accuracy: 0.7343\n",
            "Epoch 497/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6338 - accuracy: 0.7515 - val_loss: 0.7412 - val_accuracy: 0.7198\n",
            "Epoch 498/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6348 - accuracy: 0.7449 - val_loss: 0.7292 - val_accuracy: 0.7391\n",
            "Epoch 499/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6388 - accuracy: 0.7461 - val_loss: 0.7278 - val_accuracy: 0.7488\n",
            "Epoch 500/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6377 - accuracy: 0.7449 - val_loss: 0.7087 - val_accuracy: 0.7826\n",
            "Epoch 501/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6193 - accuracy: 0.7539 - val_loss: 0.7113 - val_accuracy: 0.7536\n",
            "Epoch 502/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.5998 - accuracy: 0.7690 - val_loss: 0.7382 - val_accuracy: 0.7440\n",
            "Epoch 503/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6428 - accuracy: 0.7455 - val_loss: 0.7370 - val_accuracy: 0.7536\n",
            "Epoch 504/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6339 - accuracy: 0.7521 - val_loss: 0.7298 - val_accuracy: 0.7585\n",
            "Epoch 505/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6293 - accuracy: 0.7618 - val_loss: 0.7260 - val_accuracy: 0.7440\n",
            "Epoch 506/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6286 - accuracy: 0.7539 - val_loss: 0.7263 - val_accuracy: 0.7536\n",
            "Epoch 507/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5840 - accuracy: 0.7678 - val_loss: 0.7214 - val_accuracy: 0.7633\n",
            "Epoch 508/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6329 - accuracy: 0.7430 - val_loss: 0.7286 - val_accuracy: 0.7488\n",
            "Epoch 509/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6416 - accuracy: 0.7461 - val_loss: 0.7133 - val_accuracy: 0.7440\n",
            "Epoch 510/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6217 - accuracy: 0.7527 - val_loss: 0.7141 - val_accuracy: 0.7633\n",
            "Epoch 511/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6293 - accuracy: 0.7557 - val_loss: 0.7147 - val_accuracy: 0.7536\n",
            "Epoch 512/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6215 - accuracy: 0.7521 - val_loss: 0.7199 - val_accuracy: 0.7585\n",
            "Epoch 513/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6124 - accuracy: 0.7570 - val_loss: 0.7249 - val_accuracy: 0.7488\n",
            "Epoch 514/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6264 - accuracy: 0.7443 - val_loss: 0.7076 - val_accuracy: 0.7633\n",
            "Epoch 515/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6221 - accuracy: 0.7497 - val_loss: 0.7120 - val_accuracy: 0.7681\n",
            "Epoch 516/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6255 - accuracy: 0.7533 - val_loss: 0.7155 - val_accuracy: 0.7633\n",
            "Epoch 517/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6235 - accuracy: 0.7648 - val_loss: 0.7026 - val_accuracy: 0.7536\n",
            "Epoch 518/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6125 - accuracy: 0.7600 - val_loss: 0.7043 - val_accuracy: 0.7778\n",
            "Epoch 519/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6006 - accuracy: 0.7690 - val_loss: 0.7011 - val_accuracy: 0.7633\n",
            "Epoch 520/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6233 - accuracy: 0.7515 - val_loss: 0.7221 - val_accuracy: 0.7681\n",
            "Epoch 521/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6245 - accuracy: 0.7563 - val_loss: 0.7215 - val_accuracy: 0.7536\n",
            "Epoch 522/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6107 - accuracy: 0.7618 - val_loss: 0.7131 - val_accuracy: 0.7536\n",
            "Epoch 523/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6003 - accuracy: 0.7672 - val_loss: 0.7056 - val_accuracy: 0.7681\n",
            "Epoch 524/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.5950 - accuracy: 0.7642 - val_loss: 0.7123 - val_accuracy: 0.7729\n",
            "Epoch 525/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6280 - accuracy: 0.7588 - val_loss: 0.7058 - val_accuracy: 0.7681\n",
            "Epoch 526/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6119 - accuracy: 0.7624 - val_loss: 0.7270 - val_accuracy: 0.7343\n",
            "Epoch 527/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6304 - accuracy: 0.7509 - val_loss: 0.7156 - val_accuracy: 0.7633\n",
            "Epoch 528/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6358 - accuracy: 0.7545 - val_loss: 0.7270 - val_accuracy: 0.7391\n",
            "Epoch 529/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5888 - accuracy: 0.7696 - val_loss: 0.7019 - val_accuracy: 0.7633\n",
            "Epoch 530/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6030 - accuracy: 0.7727 - val_loss: 0.7202 - val_accuracy: 0.7440\n",
            "Epoch 531/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.5836 - accuracy: 0.7690 - val_loss: 0.6954 - val_accuracy: 0.7681\n",
            "Epoch 532/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6196 - accuracy: 0.7503 - val_loss: 0.7041 - val_accuracy: 0.7440\n",
            "Epoch 533/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6063 - accuracy: 0.7588 - val_loss: 0.7172 - val_accuracy: 0.7295\n",
            "Epoch 534/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6044 - accuracy: 0.7576 - val_loss: 0.6973 - val_accuracy: 0.7440\n",
            "Epoch 535/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6010 - accuracy: 0.7690 - val_loss: 0.7025 - val_accuracy: 0.7633\n",
            "Epoch 536/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6041 - accuracy: 0.7618 - val_loss: 0.7140 - val_accuracy: 0.7585\n",
            "Epoch 537/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5919 - accuracy: 0.7666 - val_loss: 0.6897 - val_accuracy: 0.7778\n",
            "Epoch 538/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5913 - accuracy: 0.7624 - val_loss: 0.6978 - val_accuracy: 0.7729\n",
            "Epoch 539/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5957 - accuracy: 0.7709 - val_loss: 0.7097 - val_accuracy: 0.7681\n",
            "Epoch 540/1000\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.5648 - accuracy: 0.7817 - val_loss: 0.6971 - val_accuracy: 0.7585\n",
            "Epoch 541/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6082 - accuracy: 0.7570 - val_loss: 0.7030 - val_accuracy: 0.7440\n",
            "Epoch 542/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5866 - accuracy: 0.7709 - val_loss: 0.7118 - val_accuracy: 0.7729\n",
            "Epoch 543/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5976 - accuracy: 0.7666 - val_loss: 0.6925 - val_accuracy: 0.7681\n",
            "Epoch 544/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.5899 - accuracy: 0.7757 - val_loss: 0.7062 - val_accuracy: 0.7440\n",
            "Epoch 545/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5909 - accuracy: 0.7666 - val_loss: 0.7010 - val_accuracy: 0.7778\n",
            "Epoch 546/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.5833 - accuracy: 0.7690 - val_loss: 0.7083 - val_accuracy: 0.7536\n",
            "Epoch 547/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5680 - accuracy: 0.7751 - val_loss: 0.7129 - val_accuracy: 0.7536\n",
            "Epoch 548/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5841 - accuracy: 0.7648 - val_loss: 0.6998 - val_accuracy: 0.7633\n",
            "Epoch 549/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.5980 - accuracy: 0.7654 - val_loss: 0.6970 - val_accuracy: 0.7681\n",
            "Epoch 550/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5809 - accuracy: 0.7757 - val_loss: 0.7260 - val_accuracy: 0.7391\n",
            "Epoch 551/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.5691 - accuracy: 0.7775 - val_loss: 0.7030 - val_accuracy: 0.7585\n",
            "Epoch 552/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6052 - accuracy: 0.7612 - val_loss: 0.7136 - val_accuracy: 0.7585\n",
            "Epoch 553/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6005 - accuracy: 0.7630 - val_loss: 0.6985 - val_accuracy: 0.7585\n",
            "Epoch 554/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5758 - accuracy: 0.7836 - val_loss: 0.7031 - val_accuracy: 0.7729\n",
            "Epoch 555/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5914 - accuracy: 0.7763 - val_loss: 0.7031 - val_accuracy: 0.7585\n",
            "Epoch 556/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5676 - accuracy: 0.7830 - val_loss: 0.7191 - val_accuracy: 0.7343\n",
            "Epoch 557/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5710 - accuracy: 0.7715 - val_loss: 0.7075 - val_accuracy: 0.7585\n",
            "Epoch 558/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5766 - accuracy: 0.7775 - val_loss: 0.6998 - val_accuracy: 0.7826\n",
            "Epoch 559/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.5791 - accuracy: 0.7642 - val_loss: 0.7039 - val_accuracy: 0.7536\n",
            "Epoch 560/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5850 - accuracy: 0.7624 - val_loss: 0.7074 - val_accuracy: 0.7391\n",
            "Epoch 561/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.5807 - accuracy: 0.7805 - val_loss: 0.6987 - val_accuracy: 0.7536\n",
            "Epoch 562/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5767 - accuracy: 0.7751 - val_loss: 0.6778 - val_accuracy: 0.7681\n",
            "Epoch 563/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5757 - accuracy: 0.7775 - val_loss: 0.6866 - val_accuracy: 0.7729\n",
            "Epoch 564/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5443 - accuracy: 0.7920 - val_loss: 0.7006 - val_accuracy: 0.7488\n",
            "Epoch 565/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.5628 - accuracy: 0.7739 - val_loss: 0.6925 - val_accuracy: 0.7585\n",
            "Epoch 566/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5759 - accuracy: 0.7684 - val_loss: 0.6857 - val_accuracy: 0.7778\n",
            "Epoch 567/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.5767 - accuracy: 0.7757 - val_loss: 0.6905 - val_accuracy: 0.7633\n",
            "Epoch 568/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.5652 - accuracy: 0.7872 - val_loss: 0.6843 - val_accuracy: 0.7681\n",
            "Epoch 569/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.5552 - accuracy: 0.7872 - val_loss: 0.7051 - val_accuracy: 0.7391\n",
            "Epoch 570/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.5523 - accuracy: 0.7793 - val_loss: 0.6909 - val_accuracy: 0.7778\n",
            "Epoch 571/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5692 - accuracy: 0.7739 - val_loss: 0.6945 - val_accuracy: 0.7729\n",
            "Epoch 572/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.5621 - accuracy: 0.7854 - val_loss: 0.6989 - val_accuracy: 0.7633\n",
            "Epoch 573/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5675 - accuracy: 0.7727 - val_loss: 0.6828 - val_accuracy: 0.7729\n",
            "Epoch 574/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5689 - accuracy: 0.7787 - val_loss: 0.6955 - val_accuracy: 0.7729\n",
            "Epoch 575/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5468 - accuracy: 0.7836 - val_loss: 0.6826 - val_accuracy: 0.7681\n",
            "Epoch 576/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5697 - accuracy: 0.7721 - val_loss: 0.7042 - val_accuracy: 0.7585\n",
            "Epoch 577/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.5618 - accuracy: 0.7878 - val_loss: 0.6886 - val_accuracy: 0.7681\n",
            "Epoch 578/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.5582 - accuracy: 0.7811 - val_loss: 0.6784 - val_accuracy: 0.7681\n",
            "Epoch 579/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5496 - accuracy: 0.7854 - val_loss: 0.6913 - val_accuracy: 0.7633\n",
            "Epoch 580/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5554 - accuracy: 0.7739 - val_loss: 0.7080 - val_accuracy: 0.7488\n",
            "Epoch 581/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.5376 - accuracy: 0.7878 - val_loss: 0.7176 - val_accuracy: 0.7391\n",
            "Epoch 582/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5682 - accuracy: 0.7751 - val_loss: 0.6793 - val_accuracy: 0.7778\n",
            "Epoch 583/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5312 - accuracy: 0.7854 - val_loss: 0.6883 - val_accuracy: 0.7778\n",
            "Epoch 584/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.5315 - accuracy: 0.7890 - val_loss: 0.6854 - val_accuracy: 0.7923\n",
            "Epoch 585/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5531 - accuracy: 0.7745 - val_loss: 0.6845 - val_accuracy: 0.7826\n",
            "Epoch 586/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5553 - accuracy: 0.7763 - val_loss: 0.6821 - val_accuracy: 0.7826\n",
            "Epoch 587/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5318 - accuracy: 0.7999 - val_loss: 0.6799 - val_accuracy: 0.7778\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(cnnhistory.history['loss'])\n",
        "plt.plot(cnnhistory.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train','test'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "oQYnuaCrDH_A",
        "outputId": "98199c05-9c56-4c48-d0e4-57105dcedee6"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(cnnhistory.history['accuracy'])\n",
        "plt.plot(cnnhistory.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train','test'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "IFkTuO8nDNdq",
        "outputId": "4241f146-b734-436c-d886-df7c549e2a3b"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model.predict(x_testcnn)"
      ],
      "metadata": {
        "id": "A2xtrN5wDQgY"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_f_ohjXKDUpY",
        "outputId": "01666197-4db3-4a83-8a43-aeece40c8fd4"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.78855702e-01, 7.79643580e-02, 2.60106713e-01, 2.33253509e-01,\n",
              "        2.04556555e-01, 4.52631973e-02],\n",
              "       [1.03418054e-02, 1.30740766e-04, 6.96016059e-06, 9.27901149e-01,\n",
              "        1.72581524e-03, 5.98935522e-02],\n",
              "       [1.87676042e-01, 1.10667355e-01, 9.96006206e-02, 3.36494088e-01,\n",
              "        4.94175255e-02, 2.16144353e-01],\n",
              "       ...,\n",
              "       [2.21677613e-03, 2.03636205e-06, 5.08674188e-04, 4.33663698e-03,\n",
              "        9.70497310e-01, 2.24385485e-02],\n",
              "       [8.94909972e-05, 6.45988762e-01, 3.41330856e-01, 5.17574418e-03,\n",
              "        2.76402314e-03, 4.65111434e-03],\n",
              "       [5.98126731e-04, 3.42115207e-04, 9.32802409e-02, 1.78912096e-03,\n",
              "        8.84781301e-01, 1.92090459e-02]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cmA2bFgsDW3D",
        "outputId": "6fd95dbf-98a3-4b4d-c168-daba7e7712b7"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([3, 3, 3, 0, 4, 4, 1, 2, 5, 0, 5, 3, 2, 2, 1, 4, 4, 5, 2, 4, 1, 2,\n",
              "       3, 5, 4, 2, 1, 2, 2, 2, 2, 5, 2, 5, 3, 1, 2, 0, 4, 5, 2, 3, 2, 2,\n",
              "       5, 2, 0, 1, 3, 4, 4, 5, 1, 1, 4, 4, 5, 1, 1, 1, 0, 1, 5, 0, 4, 1,\n",
              "       1, 0, 1, 4, 1, 0, 4, 1, 3, 1, 2, 2, 1, 2, 3, 0, 5, 3, 5, 5, 2, 4,\n",
              "       5, 1, 5, 1, 5, 3, 4, 1, 4, 1, 5, 4, 5, 1, 2, 1, 1, 5, 1, 3, 2, 5,\n",
              "       2, 1, 3, 5, 4, 4, 0, 0, 3, 1, 2, 2, 3, 5, 1, 5, 3, 4, 2, 2, 0, 2,\n",
              "       2, 5, 5, 0, 3, 3, 2, 2, 0, 3, 4, 0, 4, 2, 4, 5, 4, 1, 5, 3, 2, 2,\n",
              "       5, 4, 3, 3, 4, 3, 3, 4, 1, 5, 2, 3, 2, 2, 0, 2, 1, 3, 1, 2, 2, 5,\n",
              "       5, 1, 4, 2, 2, 1, 1, 3, 3, 5, 5, 2, 5, 1, 5, 0, 3, 3, 0, 5, 1, 4,\n",
              "       1, 4, 2, 5, 5, 1, 4, 2, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_Ytest = y_test.astype(int)"
      ],
      "metadata": {
        "id": "0PHDKWJWDY3g"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_Ytest"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k68v2i-pDbZE",
        "outputId": "3014e158-51f8-4ae9-9e48-67ee5c2f1ced"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([3, 3, 3, 0, 4, 4, 1, 2, 5, 0, 5, 3, 2, 2, 1, 4, 4, 5, 2, 4, 1, 2,\n",
              "       3, 5, 4, 2, 1, 2, 2, 2, 2, 5, 2, 5, 3, 1, 2, 0, 4, 5, 2, 3, 2, 2,\n",
              "       5, 2, 0, 1, 3, 4, 4, 5, 1, 1, 4, 4, 5, 1, 1, 1, 0, 1, 5, 0, 4, 1,\n",
              "       1, 0, 1, 4, 1, 0, 4, 1, 3, 1, 2, 2, 1, 2, 3, 0, 5, 3, 5, 5, 2, 4,\n",
              "       5, 1, 5, 1, 5, 3, 4, 1, 4, 1, 5, 4, 5, 1, 2, 1, 1, 5, 1, 3, 2, 5,\n",
              "       2, 1, 3, 5, 4, 4, 0, 0, 3, 1, 2, 2, 3, 5, 1, 5, 3, 4, 2, 2, 0, 2,\n",
              "       2, 5, 5, 0, 3, 3, 2, 2, 0, 3, 4, 0, 4, 2, 4, 5, 4, 1, 5, 3, 2, 2,\n",
              "       5, 4, 3, 3, 4, 3, 3, 4, 1, 5, 2, 3, 2, 2, 0, 2, 1, 3, 1, 2, 2, 5,\n",
              "       5, 1, 4, 2, 2, 1, 1, 3, 3, 5, 5, 2, 5, 1, 5, 0, 3, 3, 0, 5, 1, 4,\n",
              "       1, 4, 2, 5, 5, 1, 4, 2, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds1=predictions.argmax(axis=1)\n",
        "preds1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4_cAI39VFhtp",
        "outputId": "a9ff586e-7ce7-4a02-cf3f-2682696b16c7"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2, 3, 3, 3, 4, 4, 1, 2, 3, 1, 4, 3, 2, 2, 0, 4, 4, 3, 3, 4, 2, 2,\n",
              "       2, 3, 4, 2, 2, 0, 2, 2, 2, 5, 3, 5, 3, 1, 2, 0, 4, 5, 2, 5, 2, 2,\n",
              "       3, 2, 1, 1, 3, 4, 4, 5, 1, 1, 4, 4, 5, 1, 1, 1, 3, 1, 2, 1, 4, 1,\n",
              "       1, 1, 1, 4, 1, 2, 4, 1, 3, 3, 2, 2, 1, 4, 1, 0, 5, 3, 5, 4, 2, 3,\n",
              "       3, 1, 5, 1, 4, 3, 2, 2, 4, 1, 5, 4, 5, 1, 2, 1, 1, 5, 1, 5, 2, 5,\n",
              "       3, 0, 3, 0, 4, 4, 3, 0, 3, 3, 1, 2, 1, 3, 1, 3, 3, 4, 2, 2, 3, 2,\n",
              "       2, 3, 3, 0, 5, 3, 2, 4, 0, 5, 4, 1, 4, 4, 4, 2, 4, 1, 5, 3, 2, 2,\n",
              "       5, 4, 2, 3, 4, 5, 3, 4, 1, 5, 2, 3, 2, 2, 0, 2, 1, 3, 1, 4, 4, 4,\n",
              "       5, 1, 4, 2, 4, 1, 1, 3, 3, 5, 5, 2, 5, 1, 4, 1, 3, 3, 2, 5, 2, 4,\n",
              "       1, 4, 3, 2, 4, 2, 4, 1, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "abc = preds1.astype(int).flatten()"
      ],
      "metadata": {
        "id": "H4WEmM60NfQn"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "c = confusion_matrix(new_Ytest, abc) \n",
        "c"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bKEBeEBlFjB8",
        "outputId": "9fe266eb-bc8a-4d8b-d4a5-98733d8d7133"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 6,  6,  2,  4,  0,  0],\n",
              "       [ 2, 32,  5,  2,  0,  0],\n",
              "       [ 1,  2, 32,  4,  6,  0],\n",
              "       [ 0,  2,  3, 21,  0,  5],\n",
              "       [ 0,  0,  1,  1, 31,  0],\n",
              "       [ 1,  0,  3,  9,  6, 20]])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m4RjG7LWLSQx",
        "outputId": "034fb030-769f-4361-d57b-96ed68970e4b"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([3, 3, 3, 0, 4, 4, 1, 2, 5, 0, 5, 3, 2, 2, 1, 4, 4, 5, 2, 4, 1, 2,\n",
              "       3, 5, 4, 2, 1, 2, 2, 2, 2, 5, 2, 5, 3, 1, 2, 0, 4, 5, 2, 3, 2, 2,\n",
              "       5, 2, 0, 1, 3, 4, 4, 5, 1, 1, 4, 4, 5, 1, 1, 1, 0, 1, 5, 0, 4, 1,\n",
              "       1, 0, 1, 4, 1, 0, 4, 1, 3, 1, 2, 2, 1, 2, 3, 0, 5, 3, 5, 5, 2, 4,\n",
              "       5, 1, 5, 1, 5, 3, 4, 1, 4, 1, 5, 4, 5, 1, 2, 1, 1, 5, 1, 3, 2, 5,\n",
              "       2, 1, 3, 5, 4, 4, 0, 0, 3, 1, 2, 2, 3, 5, 1, 5, 3, 4, 2, 2, 0, 2,\n",
              "       2, 5, 5, 0, 3, 3, 2, 2, 0, 3, 4, 0, 4, 2, 4, 5, 4, 1, 5, 3, 2, 2,\n",
              "       5, 4, 3, 3, 4, 3, 3, 4, 1, 5, 2, 3, 2, 2, 0, 2, 1, 3, 1, 2, 2, 5,\n",
              "       5, 1, 4, 2, 2, 1, 1, 3, 3, 5, 5, 2, 5, 1, 5, 0, 3, 3, 0, 5, 1, 4,\n",
              "       1, 4, 2, 5, 5, 1, 4, 2, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss, acc =model.evaluate(x_testcnn, y_test)\n",
        "print(\"Restored model, accuracy: {:5.2f}%\".format(100*acc))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n3kzoqPkDqqS",
        "outputId": "1a71975f-a7c0-4940-9c6a-4df3930cf6e5"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7/7 [==============================] - 0s 3ms/step - loss: 0.6873 - accuracy: 0.6860\n",
            "Restored model, accuracy: 68.60%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss, acc =model.evaluate(X_train, y_train)\n",
        "print(\"Restored model train, accuracy: {:5.2f}%\".format(100*acc))"
      ],
      "metadata": {
        "id": "fJDTGH_OUX0z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f70d4b0b-0d1a-4c3a-9215-68f438ca22d7"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "52/52 [==============================] - 0s 4ms/step - loss: 0.4884 - accuracy: 0.8603\n",
            "Restored model train, accuracy: 86.03%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix,accuracy_score\n",
        "import seaborn as sn\n",
        "\n",
        "print(classification_report(new_Ytest,abc))\n",
        "\n",
        "acc = float(accuracy_score(new_Ytest,abc))*100\n",
        "print(\"----accuracy score %s ----\" % acc)\n",
        "\n",
        "cm = confusion_matrix(new_Ytest,abc)\n",
        "#df_cm = pd.DataFrame(cm)\n",
        "class_names = ['neutral','calm', 'happy','sad','angry', 'fearful' ]\n",
        "df_cm = pd.DataFrame(cm, index=class_names, columns=class_names,)\n",
        "sn.heatmap(df_cm, annot=True, fmt='')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 508
        },
        "id": "SfSC3El94LZg",
        "outputId": "13bcb354-3a4d-4a67-f082-ebc216fb59ee"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.60      0.33      0.43        18\n",
            "           1       0.76      0.78      0.77        41\n",
            "           2       0.70      0.71      0.70        45\n",
            "           3       0.51      0.68      0.58        31\n",
            "           4       0.72      0.94      0.82        33\n",
            "           5       0.80      0.51      0.62        39\n",
            "\n",
            "    accuracy                           0.69       207\n",
            "   macro avg       0.68      0.66      0.65       207\n",
            "weighted avg       0.70      0.69      0.68       207\n",
            "\n",
            "----accuracy score 68.59903381642512 ----\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "A6UOIsB2xKek"
      },
      "execution_count": 28,
      "outputs": []
    }
  ]
}