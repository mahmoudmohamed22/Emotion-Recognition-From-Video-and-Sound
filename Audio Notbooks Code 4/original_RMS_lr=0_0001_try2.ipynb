{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "original RMS lr=0.0001 try2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9SRCO-a_AlH5",
        "outputId": "33ecf772-bdea-43fe-ebf6-5d5b5310b979"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install librosa"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oi8pWV3yBVjO",
        "outputId": "7902fc16-8d5d-40d5-97fb-c580a6eba4eb"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.7/dist-packages (0.8.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.21.6)\n",
            "Requirement already satisfied: decorator>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (21.3)\n",
            "Requirement already satisfied: soundfile>=0.10.2 in /usr/local/lib/python3.7/dist-packages (from librosa) (0.10.3.post1)\n",
            "Requirement already satisfied: resampy>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from librosa) (0.2.2)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.4.1)\n",
            "Requirement already satisfied: audioread>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (2.1.9)\n",
            "Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.6.0)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.1.0)\n",
            "Requirement already satisfied: numba>=0.43.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (0.51.2)\n",
            "Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.0.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba>=0.43.0->librosa) (57.4.0)\n",
            "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba>=0.43.0->librosa) (0.34.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->librosa) (3.0.9)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from pooch>=1.0->librosa) (2.23.0)\n",
            "Requirement already satisfied: appdirs>=1.3.0 in /usr/local/lib/python3.7/dist-packages (from pooch>=1.0->librosa) (1.4.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2022.5.18.1)\n",
            "Requirement already satisfied: six>=1.3 in /usr/local/lib/python3.7/dist-packages (from resampy>=0.2.2->librosa) (1.15.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn!=0.19.0,>=0.14.0->librosa) (3.1.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.7/dist-packages (from soundfile>=0.10.2->librosa) (1.15.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.0->soundfile>=0.10.2->librosa) (2.21)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HJjcbxwy46bG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "21ec63a3-ad90-4e21-9c0d-14487df64491"
      },
      "source": [
        "# Orignial Notebook: https://github.com/MITESHPUTHRANNEU/Speech-Emotion-Analyzer/blob/master/final_results_gender_test.ipynb\n",
        "# This notebook author: Reza Chu\n",
        "# Last Editing Date: 31st May 2019\n",
        "\n",
        "## Python\n",
        "import os\n",
        "import random\n",
        "import sys\n",
        "\n",
        "import IPython\n",
        "from IPython.display import Audio\n",
        "from IPython.display import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "## Package\n",
        "import glob \n",
        "import keras\n",
        "import IPython.display as ipd\n",
        "import librosa\n",
        "import librosa.display\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import plotly.graph_objs as go\n",
        "import plotly.offline as py\n",
        "import plotly.tools as tls\n",
        "import seaborn as sns\n",
        "import scipy.io.wavfile\n",
        "import tensorflow as tf\n",
        "py.init_notebook_mode(connected=True)\n",
        "\n",
        "## Keras\n",
        "from keras import regularizers\n",
        "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping\n",
        "from keras.callbacks import  History, ReduceLROnPlateau, CSVLogger\n",
        "from keras.models import Model, Sequential\n",
        "from keras.layers import Dense, Embedding, LSTM\n",
        "from keras.layers import Input, Flatten, Dropout, Activation, BatchNormalization\n",
        "from keras.layers import Conv1D, MaxPooling1D, AveragePooling1D\n",
        "from keras.preprocessing import sequence\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.utils import np_utils\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "## Sklearn\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "## Rest\n",
        "from scipy.fftpack import fft\n",
        "from scipy import signal\n",
        "from scipy.io import wavfile\n",
        "from tqdm import tqdm\n",
        "\n",
        "input_duration=3\n",
        "# % pylab inline"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "        <script type=\"text/javascript\">\n",
              "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
              "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
              "        if (typeof require !== 'undefined') {\n",
              "        require.undef(\"plotly\");\n",
              "        requirejs.config({\n",
              "            paths: {\n",
              "                'plotly': ['https://cdn.plot.ly/plotly-2.8.3.min']\n",
              "            }\n",
              "        });\n",
              "        require(['plotly'], function(Plotly) {\n",
              "            window._Plotly = Plotly;\n",
              "        });\n",
              "        }\n",
              "        </script>\n",
              "        "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#radvass speech and song\n",
        "import time\n",
        "import os\n",
        "import librosa\n",
        "from librosa import display\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "count=0\n",
        "path1 = '/content/drive/MyDrive/RAVDESS_speech'\n",
        "path2 = '/content/drive/MyDrive/RAVDESS_song'\n",
        "\n",
        "lst = []\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "for subdir, dirs, files in os.walk(path2):\n",
        "  print(dirs)\n",
        "  print(subdir)\n",
        "  #print(files)\n",
        "  for file in files:\n",
        "      try:\n",
        "        count +=1\n",
        "        #Load librosa array, obtain mfcss, store the file and the mcss information in a new array\n",
        "        X, sample_rate = librosa.load(os.path.join(subdir,file), res_type='kaiser_fast')\n",
        "        mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T,axis=0) \n",
        "        # The instruction below converts the labels (from 1 to 8) to a series from 0 to 7\n",
        "        # This is because our predictor needs to start from 0 otherwise it will try to predict also 0.\n",
        "        file = int(file[7:8]) - 1 \n",
        "        arr = mfccs, file\n",
        "        lst.append(arr)\n",
        "      # If the file is not valid, skip it\n",
        "      except ValueError:\n",
        "        continue\n",
        "\n",
        "for subdir, dirs, files in os.walk(path1):\n",
        "  print(dirs)\n",
        "  print(subdir)\n",
        " # print(files)\n",
        "  for file in files:\n",
        "      try:\n",
        "        #Load librosa array, obtain mfcss, store the file and the mcss information in a new array\n",
        "        X, sample_rate = librosa.load(os.path.join(subdir,file), res_type='kaiser_fast')\n",
        "        mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T,axis=0) \n",
        "        # The instruction below converts the labels (from 1 to 8) to a series from 0 to 7\n",
        "        # This is because our predictor needs to start from 0 otherwise it will try to predict also 0.\n",
        "        file = int(file[7:8]) - 1 \n",
        "        if(file ==6 or file==7):\n",
        "          continue\n",
        "        count +=1\n",
        "        arr = mfccs, file\n",
        "        lst.append(arr)\n",
        "      # If the file is not valid, skip it\n",
        "      except ValueError:\n",
        "        continue\n",
        "\n",
        "\n",
        "\n",
        "print(\"--- Data loaded. Loading time: %s seconds ---\" % (time.time() - start_time))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IfuyRZl42ccZ",
        "outputId": "766e7030-5496-491d-b0e1-b64a591a4d62"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Actor_10', 'Actor_11', 'Actor_13', 'Actor_12', 'Actor_14', 'Actor_15', 'Actor_16', 'Actor_17', 'Actor_18', 'Actor_19', 'Actor_21', 'Actor_22', 'Actor_23', 'Actor_09', 'Actor_24', 'Actor_04', 'Actor_08', 'Actor_03', 'Actor_02', 'Actor_06', 'Actor_05', 'Actor_01', 'Actor_07', 'Actor_20']\n",
            "/content/drive/MyDrive/RAVDESS_song\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_10\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_11\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_13\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_12\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_14\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_15\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_16\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_17\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_18\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_19\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_21\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_22\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_23\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_09\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_24\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_04\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_08\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_03\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_02\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_06\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_05\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_01\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_07\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_20\n",
            "['Actor_05', 'Actor_08', 'Actor_10', 'Actor_04', 'Actor_09', 'Actor_14', 'Actor_12', 'Actor_13', 'Actor_11', 'Actor_06', 'Actor_24', 'Actor_07', 'Actor_23', 'Actor_22', 'Actor_21', 'Actor_20', 'Actor_02', 'Actor_19', 'Actor_18', 'Actor_17', 'Actor_16', 'Actor_15', 'Actor_03', 'Actor_01']\n",
            "/content/drive/MyDrive/RAVDESS_speech\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_05\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_08\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_10\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_04\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_09\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_14\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_12\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_13\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_11\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_06\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_24\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_07\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_23\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_22\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_21\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_20\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_02\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_19\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_18\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_17\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_16\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_15\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_03\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_01\n",
            "--- Data loaded. Loading time: 218.32681012153625 seconds ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "count"
      ],
      "metadata": {
        "id": "Ltlhi25L2AI5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ed68ae1-bf3d-4e76-e77a-5953f5c62b66"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2068"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy.core.fromnumeric import size\n",
        "size(lst)"
      ],
      "metadata": {
        "id": "HMOH7d7mzHB7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6427d6b5-f8e0-4ed0-ab1a-7f207ea6aad0"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/core/fromnumeric.py:3208: VisibleDeprecationWarning:\n",
            "\n",
            "Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4136"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating X and y: zip makes a list of all the first elements, and a list of all the second elements.\n",
        "X, y = zip(*lst)"
      ],
      "metadata": {
        "id": "ocdL7tSTBoMt"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "X = np.asarray(X)\n",
        "y = np.asarray(y)\n",
        "X.shape, y.shape"
      ],
      "metadata": {
        "id": "vHKwUGTbBtnF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc513455-a2d8-4d0b-b152-ca8437fdeb5f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((2068, 40), (2068,))"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "id": "2sUCtbfMztE5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f319fad-a0de-44e5-ea30-2f3a429f04ef"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2068, 40)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Saving joblib files to not load them again with the loop above\n",
        "\n",
        "# import joblib\n",
        "\n",
        "# X_name = 'x.joblib'\n",
        "# y_name = 'y.joblib'\n",
        "# save_dir = '/content/drive/My Drive/graduation project/audio/paper_code/features'\n",
        "\n",
        "# savedX = joblib.dump(X, os.path.join(save_dir, X_name))\n",
        "# savedy = joblib.dump(y, os.path.join(save_dir, y_name))"
      ],
      "metadata": {
        "id": "UCzic8rlDcuk"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Loading saved models\n",
        "# import joblib\n",
        "# X = joblib.load('/content/drive/My Drive/graduation project/audio/paper_code/features/x.joblib')\n",
        "# y = joblib.load('/content/drive/My Drive/graduation project/audio/paper_code/features/y.joblib')"
      ],
      "metadata": {
        "id": "Q35CN6zDrzg1"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7PSTurzjCo5K",
        "outputId": "a6e37341-4039-4f99-9fd8-f57941f9c4dd"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2068, 40)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2,train_size=0.8, random_state=42)\n",
        "X_valid, X_test, y_valid, y_test = train_test_split(X_test,y_test, test_size=0.5,train_size=0.5, random_state=42)"
      ],
      "metadata": {
        "id": "Ai4Fy5cPCiq1"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "x_traincnn = np.expand_dims(X_train, axis=2)\n",
        "x_testcnn = np.expand_dims(X_test, axis=2)\n",
        "X_valid= np.expand_dims(X_valid, axis=2)"
      ],
      "metadata": {
        "id": "tp1Fm5K3CEXu"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_traincnn.shape, x_testcnn.shape , X_valid.shape"
      ],
      "metadata": {
        "id": "RI0MxoIPBws5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e6c0ed0d-340e-4348-9929-c5822ffbbebc"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1654, 40, 1), (207, 40, 1), (207, 40, 1))"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow"
      ],
      "metadata": {
        "id": "goxL4Y3jKICC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed32d024-fd7d-48b8-a5cb-42d37639e5c3"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (2.8.2+zzzcolab20220527125636)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow) (57.4.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.26.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (4.2.0)\n",
            "Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.5.3)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (14.0.1)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.46.3)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.17.3)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.0.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.21.6)\n",
            "Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow) (1.5.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (3.3.7)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.23.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.6.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.8.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.35.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (4.11.4)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (3.8.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2022.5.18.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (3.2.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keras"
      ],
      "metadata": {
        "id": "EkcmN9UrKSxj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87446cc1-0897-4c55-b2c4-1821823b8071"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.7/dist-packages (2.8.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from keras.preprocessing import sequence\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from keras.layers import Input, Flatten, Dropout, Activation\n",
        "from keras.layers import Conv1D, MaxPooling1D\n",
        "from keras.models import Model\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras import optimizers\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv1D(128, 8,padding='same', #classifier.add(Convolution2D(64, (3, 3), padding = 'same', input_shape = (128, 128, 3), activation = 'relu'))\n",
        "                 input_shape=(40,1)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(MaxPooling1D(pool_size=(5)))\n",
        "\n",
        "\n",
        "model.add(Conv1D(256,8,padding='same',))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(MaxPooling1D(pool_size=(5)))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(256))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(256))\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "model.add(Dense(6))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "#opt = tf.keras.optimizers.Adam(lr=0.00002)\n",
        "opt = tf.keras.optimizers.RMSprop(lr=0.0001, rho=0.9, epsilon=1e-07, decay=0.0)\n",
        "#opt = tf.keras.optimizers.SGD(lr=0.001, momentum=0.0, decay=0.0, nesterov=False)"
      ],
      "metadata": {
        "id": "g74fXWVAC4Cr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e74a4b7-0ea4-4955-845c-569361d73fc3"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/rmsprop.py:130: UserWarning:\n",
            "\n",
            "The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H6ukOxAGC_I4",
        "outputId": "e23667ea-3cb2-47bb-ab7a-cebb8a00efe1"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d (Conv1D)             (None, 40, 128)           1152      \n",
            "                                                                 \n",
            " activation (Activation)     (None, 40, 128)           0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 40, 128)           0         \n",
            "                                                                 \n",
            " max_pooling1d (MaxPooling1D  (None, 8, 128)           0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv1d_1 (Conv1D)           (None, 8, 256)            262400    \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 8, 256)            0         \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 8, 256)            0         \n",
            "                                                                 \n",
            " max_pooling1d_1 (MaxPooling  (None, 1, 256)           0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 256)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 256)               65792     \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 256)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 256)               65792     \n",
            "                                                                 \n",
            " activation_3 (Activation)   (None, 256)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 6)                 1542      \n",
            "                                                                 \n",
            " activation_4 (Activation)   (None, 6)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 396,678\n",
            "Trainable params: 396,678\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='sparse_categorical_crossentropy',\n",
        "              optimizer=opt,\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "AbMlLNk4DCBM"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#cnnhistory=model.fit(x_traincnn, y_train, batch_size=16, epochs=700, validation_data=(x_testcnn, y_test))\n",
        "cnnhistory=model.fit(x_traincnn, y_train, batch_size=16, epochs=500 , validation_data=(X_valid, y_valid))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RI1v2AuADFhy",
        "outputId": "df650686-5035-407f-a677-6db6c3da5d3d"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "104/104 [==============================] - 4s 8ms/step - loss: 4.3891 - accuracy: 0.1886 - val_loss: 2.0547 - val_accuracy: 0.2512\n",
            "Epoch 2/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 2.7326 - accuracy: 0.1892 - val_loss: 1.7597 - val_accuracy: 0.2367\n",
            "Epoch 3/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 2.2902 - accuracy: 0.2001 - val_loss: 1.7534 - val_accuracy: 0.2560\n",
            "Epoch 4/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 2.1584 - accuracy: 0.2134 - val_loss: 1.9825 - val_accuracy: 0.2271\n",
            "Epoch 5/500\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 2.0365 - accuracy: 0.2116 - val_loss: 1.6594 - val_accuracy: 0.3623\n",
            "Epoch 6/500\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 1.9414 - accuracy: 0.2328 - val_loss: 1.6803 - val_accuracy: 0.2995\n",
            "Epoch 7/500\n",
            "104/104 [==============================] - 1s 9ms/step - loss: 1.8994 - accuracy: 0.2388 - val_loss: 1.6479 - val_accuracy: 0.2609\n",
            "Epoch 8/500\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 1.8665 - accuracy: 0.2394 - val_loss: 1.6689 - val_accuracy: 0.2850\n",
            "Epoch 9/500\n",
            "104/104 [==============================] - 1s 9ms/step - loss: 1.8539 - accuracy: 0.2364 - val_loss: 1.6541 - val_accuracy: 0.3333\n",
            "Epoch 10/500\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 1.7965 - accuracy: 0.2594 - val_loss: 1.6633 - val_accuracy: 0.2367\n",
            "Epoch 11/500\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 1.7639 - accuracy: 0.2684 - val_loss: 1.6365 - val_accuracy: 0.3140\n",
            "Epoch 12/500\n",
            "104/104 [==============================] - 1s 9ms/step - loss: 1.7618 - accuracy: 0.2672 - val_loss: 1.6152 - val_accuracy: 0.2995\n",
            "Epoch 13/500\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 1.7235 - accuracy: 0.2890 - val_loss: 1.6475 - val_accuracy: 0.2512\n",
            "Epoch 14/500\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 1.6938 - accuracy: 0.2902 - val_loss: 1.6872 - val_accuracy: 0.2464\n",
            "Epoch 15/500\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 1.6831 - accuracy: 0.3053 - val_loss: 1.6099 - val_accuracy: 0.2754\n",
            "Epoch 16/500\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 1.6798 - accuracy: 0.3065 - val_loss: 1.6020 - val_accuracy: 0.3188\n",
            "Epoch 17/500\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 1.6714 - accuracy: 0.3096 - val_loss: 1.5189 - val_accuracy: 0.3430\n",
            "Epoch 18/500\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 1.6573 - accuracy: 0.2860 - val_loss: 1.5283 - val_accuracy: 0.4348\n",
            "Epoch 19/500\n",
            "104/104 [==============================] - 1s 9ms/step - loss: 1.6091 - accuracy: 0.3349 - val_loss: 1.5989 - val_accuracy: 0.3382\n",
            "Epoch 20/500\n",
            "104/104 [==============================] - 1s 10ms/step - loss: 1.5829 - accuracy: 0.3434 - val_loss: 1.5206 - val_accuracy: 0.3816\n",
            "Epoch 21/500\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 1.5649 - accuracy: 0.3591 - val_loss: 1.4784 - val_accuracy: 0.4300\n",
            "Epoch 22/500\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 1.5396 - accuracy: 0.3615 - val_loss: 1.4919 - val_accuracy: 0.3527\n",
            "Epoch 23/500\n",
            "104/104 [==============================] - 1s 9ms/step - loss: 1.5481 - accuracy: 0.3513 - val_loss: 1.5736 - val_accuracy: 0.3285\n",
            "Epoch 24/500\n",
            "104/104 [==============================] - 1s 10ms/step - loss: 1.5156 - accuracy: 0.3779 - val_loss: 1.4430 - val_accuracy: 0.3816\n",
            "Epoch 25/500\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 1.5035 - accuracy: 0.3791 - val_loss: 1.6422 - val_accuracy: 0.3188\n",
            "Epoch 26/500\n",
            "104/104 [==============================] - 1s 10ms/step - loss: 1.4832 - accuracy: 0.3894 - val_loss: 1.3819 - val_accuracy: 0.4831\n",
            "Epoch 27/500\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 1.4732 - accuracy: 0.3857 - val_loss: 1.3790 - val_accuracy: 0.4348\n",
            "Epoch 28/500\n",
            "104/104 [==============================] - 1s 10ms/step - loss: 1.4800 - accuracy: 0.3942 - val_loss: 1.3797 - val_accuracy: 0.4638\n",
            "Epoch 29/500\n",
            "104/104 [==============================] - 1s 9ms/step - loss: 1.4290 - accuracy: 0.4371 - val_loss: 1.3655 - val_accuracy: 0.5362\n",
            "Epoch 30/500\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 1.4255 - accuracy: 0.4051 - val_loss: 1.3387 - val_accuracy: 0.5362\n",
            "Epoch 31/500\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 1.4106 - accuracy: 0.4232 - val_loss: 1.3520 - val_accuracy: 0.4396\n",
            "Epoch 32/500\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 1.3989 - accuracy: 0.4220 - val_loss: 1.3398 - val_accuracy: 0.4638\n",
            "Epoch 33/500\n",
            "104/104 [==============================] - 1s 9ms/step - loss: 1.3560 - accuracy: 0.4541 - val_loss: 1.3662 - val_accuracy: 0.4541\n",
            "Epoch 34/500\n",
            "104/104 [==============================] - 1s 10ms/step - loss: 1.3615 - accuracy: 0.4389 - val_loss: 1.2903 - val_accuracy: 0.4831\n",
            "Epoch 35/500\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 1.3423 - accuracy: 0.4474 - val_loss: 1.3217 - val_accuracy: 0.4928\n",
            "Epoch 36/500\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 1.3584 - accuracy: 0.4547 - val_loss: 1.3006 - val_accuracy: 0.4831\n",
            "Epoch 37/500\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 1.3125 - accuracy: 0.4583 - val_loss: 1.2600 - val_accuracy: 0.5217\n",
            "Epoch 38/500\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 1.2964 - accuracy: 0.4746 - val_loss: 1.2695 - val_accuracy: 0.5266\n",
            "Epoch 39/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.2953 - accuracy: 0.4692 - val_loss: 1.2827 - val_accuracy: 0.4783\n",
            "Epoch 40/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.2721 - accuracy: 0.4686 - val_loss: 1.2261 - val_accuracy: 0.5169\n",
            "Epoch 41/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.2800 - accuracy: 0.4807 - val_loss: 1.2549 - val_accuracy: 0.5072\n",
            "Epoch 42/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.2135 - accuracy: 0.4873 - val_loss: 1.1956 - val_accuracy: 0.5314\n",
            "Epoch 43/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.2594 - accuracy: 0.4988 - val_loss: 1.1678 - val_accuracy: 0.5604\n",
            "Epoch 44/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.2238 - accuracy: 0.5000 - val_loss: 1.2872 - val_accuracy: 0.4541\n",
            "Epoch 45/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.1846 - accuracy: 0.5242 - val_loss: 1.2562 - val_accuracy: 0.5121\n",
            "Epoch 46/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.2108 - accuracy: 0.5169 - val_loss: 1.1330 - val_accuracy: 0.5604\n",
            "Epoch 47/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.1885 - accuracy: 0.5151 - val_loss: 1.1251 - val_accuracy: 0.5507\n",
            "Epoch 48/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.1819 - accuracy: 0.5079 - val_loss: 1.1107 - val_accuracy: 0.5652\n",
            "Epoch 49/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.1604 - accuracy: 0.5260 - val_loss: 1.1620 - val_accuracy: 0.5411\n",
            "Epoch 50/500\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 1.1604 - accuracy: 0.5266 - val_loss: 1.1533 - val_accuracy: 0.5700\n",
            "Epoch 51/500\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 1.1524 - accuracy: 0.5405 - val_loss: 1.1491 - val_accuracy: 0.5266\n",
            "Epoch 52/500\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 1.1418 - accuracy: 0.5151 - val_loss: 1.0944 - val_accuracy: 0.5459\n",
            "Epoch 53/500\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 1.1473 - accuracy: 0.5363 - val_loss: 1.0603 - val_accuracy: 0.5942\n",
            "Epoch 54/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 1.1182 - accuracy: 0.5514 - val_loss: 1.0636 - val_accuracy: 0.6184\n",
            "Epoch 55/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.1102 - accuracy: 0.5435 - val_loss: 1.0734 - val_accuracy: 0.5652\n",
            "Epoch 56/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0990 - accuracy: 0.5526 - val_loss: 1.0489 - val_accuracy: 0.6087\n",
            "Epoch 57/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0878 - accuracy: 0.5671 - val_loss: 1.0585 - val_accuracy: 0.6232\n",
            "Epoch 58/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0975 - accuracy: 0.5586 - val_loss: 1.0915 - val_accuracy: 0.5314\n",
            "Epoch 59/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0700 - accuracy: 0.5653 - val_loss: 1.1160 - val_accuracy: 0.5217\n",
            "Epoch 60/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0946 - accuracy: 0.5459 - val_loss: 1.1206 - val_accuracy: 0.6039\n",
            "Epoch 61/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0612 - accuracy: 0.5828 - val_loss: 1.0322 - val_accuracy: 0.6087\n",
            "Epoch 62/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0298 - accuracy: 0.5828 - val_loss: 1.0855 - val_accuracy: 0.5700\n",
            "Epoch 63/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0681 - accuracy: 0.5683 - val_loss: 1.0261 - val_accuracy: 0.6087\n",
            "Epoch 64/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0412 - accuracy: 0.5732 - val_loss: 1.0232 - val_accuracy: 0.5652\n",
            "Epoch 65/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0348 - accuracy: 0.5859 - val_loss: 0.9885 - val_accuracy: 0.6232\n",
            "Epoch 66/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0151 - accuracy: 0.5895 - val_loss: 0.9970 - val_accuracy: 0.6280\n",
            "Epoch 67/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0096 - accuracy: 0.5961 - val_loss: 1.0890 - val_accuracy: 0.5749\n",
            "Epoch 68/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9877 - accuracy: 0.6064 - val_loss: 0.9760 - val_accuracy: 0.6135\n",
            "Epoch 69/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9908 - accuracy: 0.6004 - val_loss: 0.9851 - val_accuracy: 0.6184\n",
            "Epoch 70/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0140 - accuracy: 0.5852 - val_loss: 1.0869 - val_accuracy: 0.5604\n",
            "Epoch 71/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0085 - accuracy: 0.5804 - val_loss: 1.0003 - val_accuracy: 0.6135\n",
            "Epoch 72/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9810 - accuracy: 0.6119 - val_loss: 1.0201 - val_accuracy: 0.5749\n",
            "Epoch 73/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9629 - accuracy: 0.6227 - val_loss: 1.0095 - val_accuracy: 0.5894\n",
            "Epoch 74/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9747 - accuracy: 0.6052 - val_loss: 0.9781 - val_accuracy: 0.5942\n",
            "Epoch 75/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9734 - accuracy: 0.6076 - val_loss: 0.9338 - val_accuracy: 0.6667\n",
            "Epoch 76/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9497 - accuracy: 0.6149 - val_loss: 0.9428 - val_accuracy: 0.6425\n",
            "Epoch 77/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9436 - accuracy: 0.6409 - val_loss: 0.9547 - val_accuracy: 0.6280\n",
            "Epoch 78/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9416 - accuracy: 0.6312 - val_loss: 0.9702 - val_accuracy: 0.6232\n",
            "Epoch 79/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9235 - accuracy: 0.6330 - val_loss: 0.9432 - val_accuracy: 0.6232\n",
            "Epoch 80/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9323 - accuracy: 0.6270 - val_loss: 0.9144 - val_accuracy: 0.6522\n",
            "Epoch 81/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9197 - accuracy: 0.6221 - val_loss: 0.9287 - val_accuracy: 0.6522\n",
            "Epoch 82/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9138 - accuracy: 0.6366 - val_loss: 0.9235 - val_accuracy: 0.6667\n",
            "Epoch 83/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9003 - accuracy: 0.6372 - val_loss: 0.9475 - val_accuracy: 0.6329\n",
            "Epoch 84/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9014 - accuracy: 0.6403 - val_loss: 0.8816 - val_accuracy: 0.6618\n",
            "Epoch 85/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9029 - accuracy: 0.6481 - val_loss: 0.9166 - val_accuracy: 0.6425\n",
            "Epoch 86/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8760 - accuracy: 0.6409 - val_loss: 0.9076 - val_accuracy: 0.6329\n",
            "Epoch 87/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8783 - accuracy: 0.6403 - val_loss: 0.9529 - val_accuracy: 0.6135\n",
            "Epoch 88/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8738 - accuracy: 0.6475 - val_loss: 0.9121 - val_accuracy: 0.6473\n",
            "Epoch 89/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8663 - accuracy: 0.6554 - val_loss: 0.9485 - val_accuracy: 0.6329\n",
            "Epoch 90/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8433 - accuracy: 0.6602 - val_loss: 0.8886 - val_accuracy: 0.6522\n",
            "Epoch 91/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8689 - accuracy: 0.6644 - val_loss: 0.9088 - val_accuracy: 0.6087\n",
            "Epoch 92/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8508 - accuracy: 0.6644 - val_loss: 0.8846 - val_accuracy: 0.6860\n",
            "Epoch 93/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8798 - accuracy: 0.6391 - val_loss: 0.8882 - val_accuracy: 0.6473\n",
            "Epoch 94/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8549 - accuracy: 0.6572 - val_loss: 0.8720 - val_accuracy: 0.6957\n",
            "Epoch 95/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8414 - accuracy: 0.6657 - val_loss: 0.8642 - val_accuracy: 0.6473\n",
            "Epoch 96/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8314 - accuracy: 0.6681 - val_loss: 0.8696 - val_accuracy: 0.6425\n",
            "Epoch 97/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8423 - accuracy: 0.6693 - val_loss: 0.9696 - val_accuracy: 0.6087\n",
            "Epoch 98/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8357 - accuracy: 0.6765 - val_loss: 0.9089 - val_accuracy: 0.6377\n",
            "Epoch 99/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8055 - accuracy: 0.6790 - val_loss: 0.9001 - val_accuracy: 0.6570\n",
            "Epoch 100/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8154 - accuracy: 0.6705 - val_loss: 0.8440 - val_accuracy: 0.6522\n",
            "Epoch 101/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8102 - accuracy: 0.6771 - val_loss: 0.8701 - val_accuracy: 0.6667\n",
            "Epoch 102/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8121 - accuracy: 0.6693 - val_loss: 0.8459 - val_accuracy: 0.6860\n",
            "Epoch 103/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8029 - accuracy: 0.6820 - val_loss: 0.8518 - val_accuracy: 0.6425\n",
            "Epoch 104/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7939 - accuracy: 0.6886 - val_loss: 0.8838 - val_accuracy: 0.6667\n",
            "Epoch 105/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7905 - accuracy: 0.6778 - val_loss: 0.9194 - val_accuracy: 0.6280\n",
            "Epoch 106/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8177 - accuracy: 0.6711 - val_loss: 0.8708 - val_accuracy: 0.6715\n",
            "Epoch 107/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7803 - accuracy: 0.6844 - val_loss: 0.8484 - val_accuracy: 0.6860\n",
            "Epoch 108/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7856 - accuracy: 0.6790 - val_loss: 0.8513 - val_accuracy: 0.6908\n",
            "Epoch 109/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7645 - accuracy: 0.6983 - val_loss: 0.8499 - val_accuracy: 0.6812\n",
            "Epoch 110/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7739 - accuracy: 0.6923 - val_loss: 0.8911 - val_accuracy: 0.6377\n",
            "Epoch 111/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7708 - accuracy: 0.6917 - val_loss: 0.8736 - val_accuracy: 0.6184\n",
            "Epoch 112/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7441 - accuracy: 0.7134 - val_loss: 0.8371 - val_accuracy: 0.6812\n",
            "Epoch 113/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7569 - accuracy: 0.6947 - val_loss: 0.8127 - val_accuracy: 0.7101\n",
            "Epoch 114/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7373 - accuracy: 0.7050 - val_loss: 0.8074 - val_accuracy: 0.6715\n",
            "Epoch 115/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7383 - accuracy: 0.7092 - val_loss: 0.8463 - val_accuracy: 0.6522\n",
            "Epoch 116/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7154 - accuracy: 0.7158 - val_loss: 0.8448 - val_accuracy: 0.6522\n",
            "Epoch 117/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7553 - accuracy: 0.7007 - val_loss: 0.8131 - val_accuracy: 0.6908\n",
            "Epoch 118/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7257 - accuracy: 0.7104 - val_loss: 0.8252 - val_accuracy: 0.6763\n",
            "Epoch 119/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7456 - accuracy: 0.7134 - val_loss: 0.8324 - val_accuracy: 0.6812\n",
            "Epoch 120/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7242 - accuracy: 0.7116 - val_loss: 0.8303 - val_accuracy: 0.6715\n",
            "Epoch 121/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7102 - accuracy: 0.7261 - val_loss: 0.7905 - val_accuracy: 0.7053\n",
            "Epoch 122/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7319 - accuracy: 0.7158 - val_loss: 0.8546 - val_accuracy: 0.6667\n",
            "Epoch 123/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7158 - accuracy: 0.7104 - val_loss: 0.7900 - val_accuracy: 0.7101\n",
            "Epoch 124/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7209 - accuracy: 0.7104 - val_loss: 0.7776 - val_accuracy: 0.6957\n",
            "Epoch 125/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7128 - accuracy: 0.7170 - val_loss: 0.7759 - val_accuracy: 0.7295\n",
            "Epoch 126/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6861 - accuracy: 0.7304 - val_loss: 0.7855 - val_accuracy: 0.7005\n",
            "Epoch 127/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6979 - accuracy: 0.7310 - val_loss: 0.7684 - val_accuracy: 0.6957\n",
            "Epoch 128/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6838 - accuracy: 0.7304 - val_loss: 0.7924 - val_accuracy: 0.7005\n",
            "Epoch 129/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6918 - accuracy: 0.7225 - val_loss: 0.7993 - val_accuracy: 0.6763\n",
            "Epoch 130/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7115 - accuracy: 0.7122 - val_loss: 0.8322 - val_accuracy: 0.6473\n",
            "Epoch 131/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6705 - accuracy: 0.7364 - val_loss: 0.7798 - val_accuracy: 0.7101\n",
            "Epoch 132/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6872 - accuracy: 0.7279 - val_loss: 0.8154 - val_accuracy: 0.6715\n",
            "Epoch 133/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6823 - accuracy: 0.7328 - val_loss: 0.7912 - val_accuracy: 0.6763\n",
            "Epoch 134/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6743 - accuracy: 0.7316 - val_loss: 0.7739 - val_accuracy: 0.6812\n",
            "Epoch 135/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6836 - accuracy: 0.7279 - val_loss: 0.7900 - val_accuracy: 0.6908\n",
            "Epoch 136/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6521 - accuracy: 0.7388 - val_loss: 0.7507 - val_accuracy: 0.7053\n",
            "Epoch 137/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6413 - accuracy: 0.7533 - val_loss: 0.8349 - val_accuracy: 0.6522\n",
            "Epoch 138/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6571 - accuracy: 0.7334 - val_loss: 0.7769 - val_accuracy: 0.7053\n",
            "Epoch 139/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6624 - accuracy: 0.7443 - val_loss: 0.7776 - val_accuracy: 0.6618\n",
            "Epoch 140/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6249 - accuracy: 0.7624 - val_loss: 0.7692 - val_accuracy: 0.6715\n",
            "Epoch 141/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6497 - accuracy: 0.7527 - val_loss: 0.7761 - val_accuracy: 0.6667\n",
            "Epoch 142/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6539 - accuracy: 0.7430 - val_loss: 0.7713 - val_accuracy: 0.6812\n",
            "Epoch 143/500\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 0.6200 - accuracy: 0.7612 - val_loss: 0.7685 - val_accuracy: 0.7053\n",
            "Epoch 144/500\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 0.6253 - accuracy: 0.7600 - val_loss: 0.7601 - val_accuracy: 0.7295\n",
            "Epoch 145/500\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.6192 - accuracy: 0.7515 - val_loss: 0.7463 - val_accuracy: 0.7101\n",
            "Epoch 146/500\n",
            "104/104 [==============================] - 1s 9ms/step - loss: 0.6302 - accuracy: 0.7576 - val_loss: 0.8200 - val_accuracy: 0.6860\n",
            "Epoch 147/500\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.6195 - accuracy: 0.7654 - val_loss: 0.8151 - val_accuracy: 0.6329\n",
            "Epoch 148/500\n",
            "104/104 [==============================] - 1s 9ms/step - loss: 0.6458 - accuracy: 0.7449 - val_loss: 0.8119 - val_accuracy: 0.6473\n",
            "Epoch 149/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6251 - accuracy: 0.7612 - val_loss: 0.7576 - val_accuracy: 0.7005\n",
            "Epoch 150/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6121 - accuracy: 0.7563 - val_loss: 0.7646 - val_accuracy: 0.7343\n",
            "Epoch 151/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6143 - accuracy: 0.7672 - val_loss: 0.7366 - val_accuracy: 0.7005\n",
            "Epoch 152/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6158 - accuracy: 0.7588 - val_loss: 0.7764 - val_accuracy: 0.7053\n",
            "Epoch 153/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6038 - accuracy: 0.7582 - val_loss: 0.7062 - val_accuracy: 0.7536\n",
            "Epoch 154/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6093 - accuracy: 0.7630 - val_loss: 0.8054 - val_accuracy: 0.6522\n",
            "Epoch 155/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6111 - accuracy: 0.7696 - val_loss: 0.7761 - val_accuracy: 0.6522\n",
            "Epoch 156/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6096 - accuracy: 0.7624 - val_loss: 0.7628 - val_accuracy: 0.7295\n",
            "Epoch 157/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5788 - accuracy: 0.7763 - val_loss: 0.7417 - val_accuracy: 0.6908\n",
            "Epoch 158/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6076 - accuracy: 0.7624 - val_loss: 0.7681 - val_accuracy: 0.6860\n",
            "Epoch 159/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6098 - accuracy: 0.7648 - val_loss: 0.7757 - val_accuracy: 0.6812\n",
            "Epoch 160/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5894 - accuracy: 0.7660 - val_loss: 0.7293 - val_accuracy: 0.7295\n",
            "Epoch 161/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5566 - accuracy: 0.7763 - val_loss: 0.7875 - val_accuracy: 0.6715\n",
            "Epoch 162/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5677 - accuracy: 0.7830 - val_loss: 0.7729 - val_accuracy: 0.6860\n",
            "Epoch 163/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5691 - accuracy: 0.7842 - val_loss: 0.7270 - val_accuracy: 0.7246\n",
            "Epoch 164/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5630 - accuracy: 0.7733 - val_loss: 0.7170 - val_accuracy: 0.7053\n",
            "Epoch 165/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5701 - accuracy: 0.7787 - val_loss: 0.7051 - val_accuracy: 0.7440\n",
            "Epoch 166/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5699 - accuracy: 0.7739 - val_loss: 0.6921 - val_accuracy: 0.7488\n",
            "Epoch 167/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5345 - accuracy: 0.7969 - val_loss: 0.6935 - val_accuracy: 0.7150\n",
            "Epoch 168/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5247 - accuracy: 0.7981 - val_loss: 0.7601 - val_accuracy: 0.6860\n",
            "Epoch 169/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5490 - accuracy: 0.7830 - val_loss: 0.7338 - val_accuracy: 0.7101\n",
            "Epoch 170/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5606 - accuracy: 0.7799 - val_loss: 0.6856 - val_accuracy: 0.7391\n",
            "Epoch 171/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5245 - accuracy: 0.8035 - val_loss: 0.7002 - val_accuracy: 0.7343\n",
            "Epoch 172/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5626 - accuracy: 0.7745 - val_loss: 0.7246 - val_accuracy: 0.7246\n",
            "Epoch 173/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5300 - accuracy: 0.7987 - val_loss: 0.7436 - val_accuracy: 0.6957\n",
            "Epoch 174/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5595 - accuracy: 0.7920 - val_loss: 0.7612 - val_accuracy: 0.7101\n",
            "Epoch 175/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5080 - accuracy: 0.8089 - val_loss: 0.6893 - val_accuracy: 0.7440\n",
            "Epoch 176/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5564 - accuracy: 0.7908 - val_loss: 0.7817 - val_accuracy: 0.6715\n",
            "Epoch 177/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5352 - accuracy: 0.7914 - val_loss: 0.7072 - val_accuracy: 0.7101\n",
            "Epoch 178/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5431 - accuracy: 0.8047 - val_loss: 0.7398 - val_accuracy: 0.6957\n",
            "Epoch 179/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5226 - accuracy: 0.7944 - val_loss: 0.7370 - val_accuracy: 0.7150\n",
            "Epoch 180/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5268 - accuracy: 0.7914 - val_loss: 0.7932 - val_accuracy: 0.6715\n",
            "Epoch 181/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5200 - accuracy: 0.8041 - val_loss: 0.7251 - val_accuracy: 0.7488\n",
            "Epoch 182/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5302 - accuracy: 0.7938 - val_loss: 0.7243 - val_accuracy: 0.7198\n",
            "Epoch 183/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5157 - accuracy: 0.8005 - val_loss: 0.7836 - val_accuracy: 0.7150\n",
            "Epoch 184/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5302 - accuracy: 0.7987 - val_loss: 0.7082 - val_accuracy: 0.7343\n",
            "Epoch 185/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4972 - accuracy: 0.8071 - val_loss: 0.7411 - val_accuracy: 0.7198\n",
            "Epoch 186/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4937 - accuracy: 0.8089 - val_loss: 0.6892 - val_accuracy: 0.7343\n",
            "Epoch 187/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5089 - accuracy: 0.8071 - val_loss: 0.6811 - val_accuracy: 0.7150\n",
            "Epoch 188/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4961 - accuracy: 0.8077 - val_loss: 0.6963 - val_accuracy: 0.7150\n",
            "Epoch 189/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4833 - accuracy: 0.8180 - val_loss: 0.6931 - val_accuracy: 0.7440\n",
            "Epoch 190/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4887 - accuracy: 0.8150 - val_loss: 0.6929 - val_accuracy: 0.7295\n",
            "Epoch 191/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4777 - accuracy: 0.8253 - val_loss: 0.7239 - val_accuracy: 0.7101\n",
            "Epoch 192/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4739 - accuracy: 0.8216 - val_loss: 0.7548 - val_accuracy: 0.6860\n",
            "Epoch 193/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5019 - accuracy: 0.8089 - val_loss: 0.6705 - val_accuracy: 0.7488\n",
            "Epoch 194/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4974 - accuracy: 0.8108 - val_loss: 0.6786 - val_accuracy: 0.7488\n",
            "Epoch 195/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4744 - accuracy: 0.8192 - val_loss: 0.6835 - val_accuracy: 0.7101\n",
            "Epoch 196/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4740 - accuracy: 0.8253 - val_loss: 0.6544 - val_accuracy: 0.7343\n",
            "Epoch 197/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4832 - accuracy: 0.8053 - val_loss: 0.7291 - val_accuracy: 0.7246\n",
            "Epoch 198/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4505 - accuracy: 0.8271 - val_loss: 0.8746 - val_accuracy: 0.6667\n",
            "Epoch 199/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4824 - accuracy: 0.8174 - val_loss: 0.7937 - val_accuracy: 0.7053\n",
            "Epoch 200/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4752 - accuracy: 0.8259 - val_loss: 0.7020 - val_accuracy: 0.7101\n",
            "Epoch 201/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4504 - accuracy: 0.8235 - val_loss: 0.6999 - val_accuracy: 0.7198\n",
            "Epoch 202/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4594 - accuracy: 0.8144 - val_loss: 0.7436 - val_accuracy: 0.7198\n",
            "Epoch 203/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4694 - accuracy: 0.8174 - val_loss: 0.6948 - val_accuracy: 0.7391\n",
            "Epoch 204/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4600 - accuracy: 0.8307 - val_loss: 0.6815 - val_accuracy: 0.7585\n",
            "Epoch 205/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4434 - accuracy: 0.8295 - val_loss: 0.7143 - val_accuracy: 0.7488\n",
            "Epoch 206/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4484 - accuracy: 0.8343 - val_loss: 0.6805 - val_accuracy: 0.7343\n",
            "Epoch 207/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4425 - accuracy: 0.8331 - val_loss: 0.6900 - val_accuracy: 0.7246\n",
            "Epoch 208/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4346 - accuracy: 0.8301 - val_loss: 0.7316 - val_accuracy: 0.7198\n",
            "Epoch 209/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4616 - accuracy: 0.8362 - val_loss: 0.7170 - val_accuracy: 0.7343\n",
            "Epoch 210/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4220 - accuracy: 0.8362 - val_loss: 0.7571 - val_accuracy: 0.7295\n",
            "Epoch 211/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4650 - accuracy: 0.8229 - val_loss: 0.7674 - val_accuracy: 0.7198\n",
            "Epoch 212/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4303 - accuracy: 0.8265 - val_loss: 0.6872 - val_accuracy: 0.7536\n",
            "Epoch 213/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4451 - accuracy: 0.8319 - val_loss: 0.6832 - val_accuracy: 0.7101\n",
            "Epoch 214/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4324 - accuracy: 0.8259 - val_loss: 0.7381 - val_accuracy: 0.6860\n",
            "Epoch 215/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4040 - accuracy: 0.8392 - val_loss: 0.6986 - val_accuracy: 0.7343\n",
            "Epoch 216/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4422 - accuracy: 0.8307 - val_loss: 0.7276 - val_accuracy: 0.6957\n",
            "Epoch 217/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4189 - accuracy: 0.8362 - val_loss: 0.7643 - val_accuracy: 0.6812\n",
            "Epoch 218/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4334 - accuracy: 0.8362 - val_loss: 0.6447 - val_accuracy: 0.7778\n",
            "Epoch 219/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4219 - accuracy: 0.8368 - val_loss: 0.6827 - val_accuracy: 0.7295\n",
            "Epoch 220/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4125 - accuracy: 0.8368 - val_loss: 0.7607 - val_accuracy: 0.7150\n",
            "Epoch 221/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4065 - accuracy: 0.8404 - val_loss: 0.6558 - val_accuracy: 0.7198\n",
            "Epoch 222/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4175 - accuracy: 0.8398 - val_loss: 0.6815 - val_accuracy: 0.7295\n",
            "Epoch 223/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4281 - accuracy: 0.8464 - val_loss: 0.6395 - val_accuracy: 0.8019\n",
            "Epoch 224/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4002 - accuracy: 0.8519 - val_loss: 0.6745 - val_accuracy: 0.7391\n",
            "Epoch 225/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.3924 - accuracy: 0.8513 - val_loss: 0.7093 - val_accuracy: 0.7198\n",
            "Epoch 226/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3848 - accuracy: 0.8561 - val_loss: 0.6767 - val_accuracy: 0.7198\n",
            "Epoch 227/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3905 - accuracy: 0.8440 - val_loss: 0.7172 - val_accuracy: 0.7246\n",
            "Epoch 228/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.3777 - accuracy: 0.8567 - val_loss: 0.8284 - val_accuracy: 0.6618\n",
            "Epoch 229/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4076 - accuracy: 0.8585 - val_loss: 0.6574 - val_accuracy: 0.7729\n",
            "Epoch 230/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3805 - accuracy: 0.8567 - val_loss: 0.7479 - val_accuracy: 0.7633\n",
            "Epoch 231/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3826 - accuracy: 0.8543 - val_loss: 0.7169 - val_accuracy: 0.6908\n",
            "Epoch 232/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4026 - accuracy: 0.8561 - val_loss: 0.6817 - val_accuracy: 0.7198\n",
            "Epoch 233/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.3888 - accuracy: 0.8525 - val_loss: 0.6876 - val_accuracy: 0.7246\n",
            "Epoch 234/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3937 - accuracy: 0.8567 - val_loss: 0.7307 - val_accuracy: 0.7053\n",
            "Epoch 235/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3848 - accuracy: 0.8555 - val_loss: 0.6817 - val_accuracy: 0.7536\n",
            "Epoch 236/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3750 - accuracy: 0.8495 - val_loss: 0.6871 - val_accuracy: 0.7246\n",
            "Epoch 237/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3897 - accuracy: 0.8591 - val_loss: 0.6900 - val_accuracy: 0.7440\n",
            "Epoch 238/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.3908 - accuracy: 0.8464 - val_loss: 0.6828 - val_accuracy: 0.7005\n",
            "Epoch 239/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3960 - accuracy: 0.8507 - val_loss: 0.6729 - val_accuracy: 0.7585\n",
            "Epoch 240/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3885 - accuracy: 0.8622 - val_loss: 0.7365 - val_accuracy: 0.7053\n",
            "Epoch 241/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3706 - accuracy: 0.8658 - val_loss: 0.6726 - val_accuracy: 0.7246\n",
            "Epoch 242/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3667 - accuracy: 0.8688 - val_loss: 0.7059 - val_accuracy: 0.7488\n",
            "Epoch 243/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3839 - accuracy: 0.8609 - val_loss: 0.6600 - val_accuracy: 0.7391\n",
            "Epoch 244/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.3619 - accuracy: 0.8597 - val_loss: 0.6948 - val_accuracy: 0.7150\n",
            "Epoch 245/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3606 - accuracy: 0.8640 - val_loss: 0.6822 - val_accuracy: 0.7005\n",
            "Epoch 246/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3588 - accuracy: 0.8652 - val_loss: 0.6575 - val_accuracy: 0.7536\n",
            "Epoch 247/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3538 - accuracy: 0.8640 - val_loss: 0.6740 - val_accuracy: 0.7633\n",
            "Epoch 248/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3556 - accuracy: 0.8628 - val_loss: 0.7158 - val_accuracy: 0.7246\n",
            "Epoch 249/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3566 - accuracy: 0.8640 - val_loss: 0.6622 - val_accuracy: 0.7633\n",
            "Epoch 250/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3561 - accuracy: 0.8634 - val_loss: 0.7033 - val_accuracy: 0.7053\n",
            "Epoch 251/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.3875 - accuracy: 0.8597 - val_loss: 0.6706 - val_accuracy: 0.7633\n",
            "Epoch 252/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.3561 - accuracy: 0.8712 - val_loss: 0.6978 - val_accuracy: 0.7295\n",
            "Epoch 253/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3495 - accuracy: 0.8706 - val_loss: 0.6208 - val_accuracy: 0.7585\n",
            "Epoch 254/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3379 - accuracy: 0.8773 - val_loss: 0.7603 - val_accuracy: 0.7101\n",
            "Epoch 255/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3531 - accuracy: 0.8676 - val_loss: 0.7446 - val_accuracy: 0.6957\n",
            "Epoch 256/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3375 - accuracy: 0.8791 - val_loss: 0.7098 - val_accuracy: 0.7440\n",
            "Epoch 257/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3772 - accuracy: 0.8549 - val_loss: 0.6468 - val_accuracy: 0.7778\n",
            "Epoch 258/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.3202 - accuracy: 0.8761 - val_loss: 0.7197 - val_accuracy: 0.7053\n",
            "Epoch 259/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3338 - accuracy: 0.8797 - val_loss: 0.6677 - val_accuracy: 0.7536\n",
            "Epoch 260/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3490 - accuracy: 0.8682 - val_loss: 0.6913 - val_accuracy: 0.7488\n",
            "Epoch 261/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3552 - accuracy: 0.8718 - val_loss: 0.7383 - val_accuracy: 0.7005\n",
            "Epoch 262/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3683 - accuracy: 0.8640 - val_loss: 0.6844 - val_accuracy: 0.7488\n",
            "Epoch 263/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3386 - accuracy: 0.8797 - val_loss: 0.7013 - val_accuracy: 0.7343\n",
            "Epoch 264/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3279 - accuracy: 0.8827 - val_loss: 0.6737 - val_accuracy: 0.7633\n",
            "Epoch 265/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3309 - accuracy: 0.8718 - val_loss: 0.6812 - val_accuracy: 0.7440\n",
            "Epoch 266/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3299 - accuracy: 0.8779 - val_loss: 0.6381 - val_accuracy: 0.7681\n",
            "Epoch 267/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3523 - accuracy: 0.8718 - val_loss: 0.6471 - val_accuracy: 0.7633\n",
            "Epoch 268/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3017 - accuracy: 0.8894 - val_loss: 0.6716 - val_accuracy: 0.7440\n",
            "Epoch 269/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3141 - accuracy: 0.8742 - val_loss: 0.6770 - val_accuracy: 0.7440\n",
            "Epoch 270/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.3234 - accuracy: 0.8767 - val_loss: 0.6464 - val_accuracy: 0.7295\n",
            "Epoch 271/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.3062 - accuracy: 0.8863 - val_loss: 0.6438 - val_accuracy: 0.7681\n",
            "Epoch 272/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3298 - accuracy: 0.8773 - val_loss: 0.6535 - val_accuracy: 0.7536\n",
            "Epoch 273/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.3136 - accuracy: 0.8815 - val_loss: 0.6536 - val_accuracy: 0.7585\n",
            "Epoch 274/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3287 - accuracy: 0.8748 - val_loss: 0.6620 - val_accuracy: 0.7633\n",
            "Epoch 275/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2942 - accuracy: 0.8948 - val_loss: 0.7381 - val_accuracy: 0.7826\n",
            "Epoch 276/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3247 - accuracy: 0.8815 - val_loss: 0.6847 - val_accuracy: 0.7295\n",
            "Epoch 277/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3039 - accuracy: 0.8845 - val_loss: 0.7025 - val_accuracy: 0.7585\n",
            "Epoch 278/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2930 - accuracy: 0.8906 - val_loss: 0.6723 - val_accuracy: 0.7391\n",
            "Epoch 279/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.3097 - accuracy: 0.8900 - val_loss: 0.6579 - val_accuracy: 0.7633\n",
            "Epoch 280/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.3052 - accuracy: 0.8863 - val_loss: 0.6449 - val_accuracy: 0.7923\n",
            "Epoch 281/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2974 - accuracy: 0.8930 - val_loss: 0.6808 - val_accuracy: 0.7585\n",
            "Epoch 282/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3211 - accuracy: 0.8869 - val_loss: 0.6610 - val_accuracy: 0.7536\n",
            "Epoch 283/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2978 - accuracy: 0.8942 - val_loss: 0.6551 - val_accuracy: 0.7729\n",
            "Epoch 284/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2920 - accuracy: 0.8888 - val_loss: 0.8050 - val_accuracy: 0.6908\n",
            "Epoch 285/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3204 - accuracy: 0.8724 - val_loss: 0.6974 - val_accuracy: 0.7681\n",
            "Epoch 286/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3031 - accuracy: 0.8918 - val_loss: 0.6801 - val_accuracy: 0.7681\n",
            "Epoch 287/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2760 - accuracy: 0.8912 - val_loss: 0.6416 - val_accuracy: 0.7585\n",
            "Epoch 288/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2877 - accuracy: 0.8912 - val_loss: 0.6708 - val_accuracy: 0.7536\n",
            "Epoch 289/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2982 - accuracy: 0.8924 - val_loss: 0.7162 - val_accuracy: 0.7778\n",
            "Epoch 290/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2792 - accuracy: 0.8960 - val_loss: 0.7247 - val_accuracy: 0.7488\n",
            "Epoch 291/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3039 - accuracy: 0.8936 - val_loss: 0.6788 - val_accuracy: 0.7778\n",
            "Epoch 292/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2857 - accuracy: 0.8881 - val_loss: 0.6855 - val_accuracy: 0.7246\n",
            "Epoch 293/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2806 - accuracy: 0.8966 - val_loss: 0.6785 - val_accuracy: 0.7440\n",
            "Epoch 294/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2786 - accuracy: 0.8990 - val_loss: 0.6809 - val_accuracy: 0.7246\n",
            "Epoch 295/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2880 - accuracy: 0.8924 - val_loss: 0.6532 - val_accuracy: 0.7440\n",
            "Epoch 296/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2838 - accuracy: 0.8912 - val_loss: 0.6126 - val_accuracy: 0.8164\n",
            "Epoch 297/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2834 - accuracy: 0.8954 - val_loss: 0.6166 - val_accuracy: 0.7778\n",
            "Epoch 298/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2768 - accuracy: 0.8960 - val_loss: 0.6470 - val_accuracy: 0.7778\n",
            "Epoch 299/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2736 - accuracy: 0.8972 - val_loss: 0.6836 - val_accuracy: 0.7440\n",
            "Epoch 300/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2931 - accuracy: 0.8888 - val_loss: 0.7248 - val_accuracy: 0.7826\n",
            "Epoch 301/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2788 - accuracy: 0.8924 - val_loss: 0.7368 - val_accuracy: 0.7295\n",
            "Epoch 302/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2698 - accuracy: 0.9033 - val_loss: 0.6279 - val_accuracy: 0.7923\n",
            "Epoch 303/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2721 - accuracy: 0.8960 - val_loss: 0.6556 - val_accuracy: 0.7826\n",
            "Epoch 304/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2646 - accuracy: 0.9027 - val_loss: 0.6459 - val_accuracy: 0.7923\n",
            "Epoch 305/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2730 - accuracy: 0.9087 - val_loss: 0.6773 - val_accuracy: 0.7585\n",
            "Epoch 306/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2794 - accuracy: 0.9015 - val_loss: 0.6712 - val_accuracy: 0.7778\n",
            "Epoch 307/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2817 - accuracy: 0.8966 - val_loss: 0.7519 - val_accuracy: 0.7295\n",
            "Epoch 308/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2779 - accuracy: 0.8978 - val_loss: 0.7270 - val_accuracy: 0.7971\n",
            "Epoch 309/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2449 - accuracy: 0.9111 - val_loss: 0.6574 - val_accuracy: 0.7536\n",
            "Epoch 310/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2794 - accuracy: 0.8936 - val_loss: 0.6912 - val_accuracy: 0.7536\n",
            "Epoch 311/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3006 - accuracy: 0.8978 - val_loss: 0.6483 - val_accuracy: 0.7778\n",
            "Epoch 312/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2472 - accuracy: 0.9081 - val_loss: 0.6400 - val_accuracy: 0.7971\n",
            "Epoch 313/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2470 - accuracy: 0.9051 - val_loss: 0.7312 - val_accuracy: 0.7295\n",
            "Epoch 314/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2525 - accuracy: 0.9093 - val_loss: 0.7060 - val_accuracy: 0.7488\n",
            "Epoch 315/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2648 - accuracy: 0.8954 - val_loss: 0.6666 - val_accuracy: 0.7923\n",
            "Epoch 316/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2607 - accuracy: 0.9045 - val_loss: 0.7184 - val_accuracy: 0.7633\n",
            "Epoch 317/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2839 - accuracy: 0.8930 - val_loss: 0.7281 - val_accuracy: 0.7440\n",
            "Epoch 318/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2561 - accuracy: 0.9093 - val_loss: 0.7031 - val_accuracy: 0.7536\n",
            "Epoch 319/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2532 - accuracy: 0.9075 - val_loss: 0.6855 - val_accuracy: 0.7681\n",
            "Epoch 320/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2816 - accuracy: 0.9027 - val_loss: 0.7159 - val_accuracy: 0.7633\n",
            "Epoch 321/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2574 - accuracy: 0.9039 - val_loss: 0.7349 - val_accuracy: 0.7585\n",
            "Epoch 322/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2625 - accuracy: 0.9021 - val_loss: 0.6876 - val_accuracy: 0.7874\n",
            "Epoch 323/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2460 - accuracy: 0.9033 - val_loss: 0.7474 - val_accuracy: 0.7729\n",
            "Epoch 324/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2748 - accuracy: 0.9002 - val_loss: 0.6795 - val_accuracy: 0.7923\n",
            "Epoch 325/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2438 - accuracy: 0.9226 - val_loss: 0.7482 - val_accuracy: 0.7729\n",
            "Epoch 326/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2585 - accuracy: 0.9051 - val_loss: 0.7136 - val_accuracy: 0.7391\n",
            "Epoch 327/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2164 - accuracy: 0.9166 - val_loss: 0.6841 - val_accuracy: 0.7826\n",
            "Epoch 328/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2607 - accuracy: 0.9033 - val_loss: 0.7689 - val_accuracy: 0.7053\n",
            "Epoch 329/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2686 - accuracy: 0.9008 - val_loss: 0.6898 - val_accuracy: 0.7585\n",
            "Epoch 330/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2217 - accuracy: 0.9196 - val_loss: 0.6766 - val_accuracy: 0.7729\n",
            "Epoch 331/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2422 - accuracy: 0.9135 - val_loss: 0.7179 - val_accuracy: 0.7681\n",
            "Epoch 332/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2412 - accuracy: 0.9141 - val_loss: 0.7331 - val_accuracy: 0.7585\n",
            "Epoch 333/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2752 - accuracy: 0.9002 - val_loss: 0.7382 - val_accuracy: 0.7440\n",
            "Epoch 334/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2319 - accuracy: 0.9166 - val_loss: 0.8174 - val_accuracy: 0.7391\n",
            "Epoch 335/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2383 - accuracy: 0.9190 - val_loss: 0.7103 - val_accuracy: 0.7729\n",
            "Epoch 336/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2356 - accuracy: 0.9117 - val_loss: 0.7157 - val_accuracy: 0.7440\n",
            "Epoch 337/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2302 - accuracy: 0.9111 - val_loss: 0.7379 - val_accuracy: 0.7391\n",
            "Epoch 338/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2412 - accuracy: 0.9129 - val_loss: 0.7269 - val_accuracy: 0.7729\n",
            "Epoch 339/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2398 - accuracy: 0.9160 - val_loss: 0.7957 - val_accuracy: 0.7488\n",
            "Epoch 340/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2403 - accuracy: 0.9093 - val_loss: 0.7883 - val_accuracy: 0.7391\n",
            "Epoch 341/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2374 - accuracy: 0.9135 - val_loss: 0.7007 - val_accuracy: 0.7343\n",
            "Epoch 342/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2228 - accuracy: 0.9129 - val_loss: 0.6892 - val_accuracy: 0.7874\n",
            "Epoch 343/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2367 - accuracy: 0.9135 - val_loss: 0.7115 - val_accuracy: 0.7391\n",
            "Epoch 344/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2434 - accuracy: 0.9099 - val_loss: 0.6553 - val_accuracy: 0.7923\n",
            "Epoch 345/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2606 - accuracy: 0.9111 - val_loss: 0.8051 - val_accuracy: 0.7633\n",
            "Epoch 346/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2115 - accuracy: 0.9250 - val_loss: 0.6876 - val_accuracy: 0.7923\n",
            "Epoch 347/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2121 - accuracy: 0.9226 - val_loss: 0.7447 - val_accuracy: 0.7874\n",
            "Epoch 348/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2305 - accuracy: 0.9178 - val_loss: 0.6985 - val_accuracy: 0.7778\n",
            "Epoch 349/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2187 - accuracy: 0.9226 - val_loss: 0.7320 - val_accuracy: 0.7585\n",
            "Epoch 350/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2414 - accuracy: 0.9184 - val_loss: 0.6608 - val_accuracy: 0.8068\n",
            "Epoch 351/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2352 - accuracy: 0.9178 - val_loss: 0.7939 - val_accuracy: 0.7343\n",
            "Epoch 352/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2111 - accuracy: 0.9220 - val_loss: 0.7654 - val_accuracy: 0.8019\n",
            "Epoch 353/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2423 - accuracy: 0.9160 - val_loss: 0.6908 - val_accuracy: 0.8019\n",
            "Epoch 354/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2181 - accuracy: 0.9220 - val_loss: 0.7294 - val_accuracy: 0.7874\n",
            "Epoch 355/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2485 - accuracy: 0.9075 - val_loss: 0.8064 - val_accuracy: 0.7585\n",
            "Epoch 356/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2217 - accuracy: 0.9268 - val_loss: 0.7500 - val_accuracy: 0.7826\n",
            "Epoch 357/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2358 - accuracy: 0.9214 - val_loss: 0.7779 - val_accuracy: 0.7633\n",
            "Epoch 358/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2360 - accuracy: 0.9190 - val_loss: 0.8052 - val_accuracy: 0.7488\n",
            "Epoch 359/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2131 - accuracy: 0.9311 - val_loss: 0.7467 - val_accuracy: 0.7681\n",
            "Epoch 360/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2149 - accuracy: 0.9274 - val_loss: 0.7463 - val_accuracy: 0.7778\n",
            "Epoch 361/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2179 - accuracy: 0.9287 - val_loss: 0.7190 - val_accuracy: 0.7729\n",
            "Epoch 362/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2131 - accuracy: 0.9208 - val_loss: 0.7204 - val_accuracy: 0.7923\n",
            "Epoch 363/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2116 - accuracy: 0.9208 - val_loss: 0.8051 - val_accuracy: 0.7536\n",
            "Epoch 364/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2211 - accuracy: 0.9208 - val_loss: 0.7478 - val_accuracy: 0.7633\n",
            "Epoch 365/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2141 - accuracy: 0.9148 - val_loss: 0.7603 - val_accuracy: 0.7681\n",
            "Epoch 366/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2341 - accuracy: 0.9178 - val_loss: 0.7210 - val_accuracy: 0.7874\n",
            "Epoch 367/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2047 - accuracy: 0.9154 - val_loss: 0.8113 - val_accuracy: 0.7923\n",
            "Epoch 368/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2160 - accuracy: 0.9250 - val_loss: 0.7180 - val_accuracy: 0.7729\n",
            "Epoch 369/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2071 - accuracy: 0.9293 - val_loss: 0.7418 - val_accuracy: 0.7633\n",
            "Epoch 370/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2192 - accuracy: 0.9214 - val_loss: 0.7075 - val_accuracy: 0.7729\n",
            "Epoch 371/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2466 - accuracy: 0.9160 - val_loss: 0.6775 - val_accuracy: 0.7440\n",
            "Epoch 372/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2039 - accuracy: 0.9323 - val_loss: 0.7030 - val_accuracy: 0.8019\n",
            "Epoch 373/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2405 - accuracy: 0.9172 - val_loss: 0.7031 - val_accuracy: 0.7778\n",
            "Epoch 374/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2160 - accuracy: 0.9220 - val_loss: 0.7336 - val_accuracy: 0.7536\n",
            "Epoch 375/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2064 - accuracy: 0.9281 - val_loss: 0.8541 - val_accuracy: 0.7198\n",
            "Epoch 376/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2038 - accuracy: 0.9256 - val_loss: 0.7716 - val_accuracy: 0.7729\n",
            "Epoch 377/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1993 - accuracy: 0.9244 - val_loss: 0.8060 - val_accuracy: 0.7729\n",
            "Epoch 378/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1860 - accuracy: 0.9317 - val_loss: 0.6875 - val_accuracy: 0.7971\n",
            "Epoch 379/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2296 - accuracy: 0.9184 - val_loss: 0.7486 - val_accuracy: 0.7633\n",
            "Epoch 380/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1857 - accuracy: 0.9299 - val_loss: 0.7299 - val_accuracy: 0.8068\n",
            "Epoch 381/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2065 - accuracy: 0.9214 - val_loss: 0.7647 - val_accuracy: 0.7681\n",
            "Epoch 382/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1948 - accuracy: 0.9281 - val_loss: 0.7174 - val_accuracy: 0.7778\n",
            "Epoch 383/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2142 - accuracy: 0.9160 - val_loss: 0.7399 - val_accuracy: 0.8164\n",
            "Epoch 384/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1902 - accuracy: 0.9268 - val_loss: 0.7753 - val_accuracy: 0.7585\n",
            "Epoch 385/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2264 - accuracy: 0.9214 - val_loss: 0.8908 - val_accuracy: 0.7681\n",
            "Epoch 386/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1969 - accuracy: 0.9293 - val_loss: 0.7574 - val_accuracy: 0.7633\n",
            "Epoch 387/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2122 - accuracy: 0.9268 - val_loss: 0.7242 - val_accuracy: 0.7826\n",
            "Epoch 388/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2034 - accuracy: 0.9335 - val_loss: 0.6946 - val_accuracy: 0.7874\n",
            "Epoch 389/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1994 - accuracy: 0.9305 - val_loss: 0.8046 - val_accuracy: 0.7343\n",
            "Epoch 390/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1947 - accuracy: 0.9383 - val_loss: 0.6845 - val_accuracy: 0.8019\n",
            "Epoch 391/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1893 - accuracy: 0.9329 - val_loss: 0.6818 - val_accuracy: 0.8068\n",
            "Epoch 392/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2249 - accuracy: 0.9256 - val_loss: 0.7744 - val_accuracy: 0.7633\n",
            "Epoch 393/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1889 - accuracy: 0.9383 - val_loss: 0.8625 - val_accuracy: 0.7633\n",
            "Epoch 394/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2197 - accuracy: 0.9220 - val_loss: 0.8489 - val_accuracy: 0.7585\n",
            "Epoch 395/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1768 - accuracy: 0.9329 - val_loss: 0.7363 - val_accuracy: 0.7874\n",
            "Epoch 396/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2072 - accuracy: 0.9274 - val_loss: 0.7573 - val_accuracy: 0.7633\n",
            "Epoch 397/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1623 - accuracy: 0.9438 - val_loss: 0.8924 - val_accuracy: 0.7391\n",
            "Epoch 398/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1909 - accuracy: 0.9323 - val_loss: 0.8992 - val_accuracy: 0.7536\n",
            "Epoch 399/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1876 - accuracy: 0.9347 - val_loss: 0.7813 - val_accuracy: 0.7778\n",
            "Epoch 400/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1716 - accuracy: 0.9438 - val_loss: 0.7714 - val_accuracy: 0.7681\n",
            "Epoch 401/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1969 - accuracy: 0.9293 - val_loss: 0.7018 - val_accuracy: 0.7971\n",
            "Epoch 402/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1936 - accuracy: 0.9341 - val_loss: 0.7853 - val_accuracy: 0.7778\n",
            "Epoch 403/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1809 - accuracy: 0.9305 - val_loss: 0.7718 - val_accuracy: 0.7826\n",
            "Epoch 404/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1998 - accuracy: 0.9262 - val_loss: 0.7788 - val_accuracy: 0.7923\n",
            "Epoch 405/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1813 - accuracy: 0.9414 - val_loss: 0.7804 - val_accuracy: 0.7585\n",
            "Epoch 406/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1732 - accuracy: 0.9389 - val_loss: 0.8157 - val_accuracy: 0.7778\n",
            "Epoch 407/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1822 - accuracy: 0.9341 - val_loss: 0.7639 - val_accuracy: 0.7874\n",
            "Epoch 408/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1926 - accuracy: 0.9347 - val_loss: 0.7825 - val_accuracy: 0.7585\n",
            "Epoch 409/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2061 - accuracy: 0.9353 - val_loss: 0.7887 - val_accuracy: 0.7778\n",
            "Epoch 410/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1702 - accuracy: 0.9426 - val_loss: 0.7700 - val_accuracy: 0.7874\n",
            "Epoch 411/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2078 - accuracy: 0.9256 - val_loss: 0.9292 - val_accuracy: 0.7536\n",
            "Epoch 412/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1858 - accuracy: 0.9305 - val_loss: 0.8288 - val_accuracy: 0.7971\n",
            "Epoch 413/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2001 - accuracy: 0.9287 - val_loss: 0.7701 - val_accuracy: 0.7778\n",
            "Epoch 414/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2013 - accuracy: 0.9268 - val_loss: 0.8305 - val_accuracy: 0.7440\n",
            "Epoch 415/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1931 - accuracy: 0.9281 - val_loss: 0.7872 - val_accuracy: 0.7778\n",
            "Epoch 416/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2022 - accuracy: 0.9287 - val_loss: 0.7242 - val_accuracy: 0.7971\n",
            "Epoch 417/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1916 - accuracy: 0.9329 - val_loss: 0.8305 - val_accuracy: 0.7971\n",
            "Epoch 418/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1881 - accuracy: 0.9407 - val_loss: 0.8835 - val_accuracy: 0.7536\n",
            "Epoch 419/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1836 - accuracy: 0.9335 - val_loss: 0.7039 - val_accuracy: 0.8213\n",
            "Epoch 420/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1939 - accuracy: 0.9305 - val_loss: 0.7984 - val_accuracy: 0.7971\n",
            "Epoch 421/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1973 - accuracy: 0.9262 - val_loss: 0.7384 - val_accuracy: 0.7778\n",
            "Epoch 422/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1778 - accuracy: 0.9359 - val_loss: 0.7500 - val_accuracy: 0.8019\n",
            "Epoch 423/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1875 - accuracy: 0.9293 - val_loss: 0.8545 - val_accuracy: 0.7826\n",
            "Epoch 424/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1496 - accuracy: 0.9450 - val_loss: 0.7621 - val_accuracy: 0.7971\n",
            "Epoch 425/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1879 - accuracy: 0.9281 - val_loss: 0.8849 - val_accuracy: 0.7729\n",
            "Epoch 426/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1653 - accuracy: 0.9414 - val_loss: 0.7487 - val_accuracy: 0.7874\n",
            "Epoch 427/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1785 - accuracy: 0.9383 - val_loss: 0.7263 - val_accuracy: 0.8068\n",
            "Epoch 428/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1677 - accuracy: 0.9395 - val_loss: 0.7486 - val_accuracy: 0.7923\n",
            "Epoch 429/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1742 - accuracy: 0.9401 - val_loss: 0.7521 - val_accuracy: 0.7923\n",
            "Epoch 430/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1533 - accuracy: 0.9480 - val_loss: 0.7660 - val_accuracy: 0.7826\n",
            "Epoch 431/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1762 - accuracy: 0.9311 - val_loss: 0.7653 - val_accuracy: 0.7826\n",
            "Epoch 432/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2000 - accuracy: 0.9353 - val_loss: 0.7220 - val_accuracy: 0.7971\n",
            "Epoch 433/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1931 - accuracy: 0.9262 - val_loss: 0.8473 - val_accuracy: 0.7585\n",
            "Epoch 434/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1918 - accuracy: 0.9353 - val_loss: 0.8222 - val_accuracy: 0.7729\n",
            "Epoch 435/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1720 - accuracy: 0.9432 - val_loss: 0.7401 - val_accuracy: 0.8068\n",
            "Epoch 436/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1731 - accuracy: 0.9444 - val_loss: 0.8114 - val_accuracy: 0.8213\n",
            "Epoch 437/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1683 - accuracy: 0.9468 - val_loss: 0.7763 - val_accuracy: 0.7971\n",
            "Epoch 438/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1823 - accuracy: 0.9329 - val_loss: 0.8550 - val_accuracy: 0.7826\n",
            "Epoch 439/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1904 - accuracy: 0.9323 - val_loss: 0.8948 - val_accuracy: 0.8068\n",
            "Epoch 440/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1760 - accuracy: 0.9335 - val_loss: 0.8032 - val_accuracy: 0.7874\n",
            "Epoch 441/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1656 - accuracy: 0.9426 - val_loss: 0.7956 - val_accuracy: 0.7681\n",
            "Epoch 442/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1602 - accuracy: 0.9516 - val_loss: 0.8592 - val_accuracy: 0.7778\n",
            "Epoch 443/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1609 - accuracy: 0.9395 - val_loss: 0.8036 - val_accuracy: 0.7826\n",
            "Epoch 444/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1785 - accuracy: 0.9462 - val_loss: 0.7932 - val_accuracy: 0.7440\n",
            "Epoch 445/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1909 - accuracy: 0.9359 - val_loss: 0.8504 - val_accuracy: 0.7633\n",
            "Epoch 446/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1671 - accuracy: 0.9347 - val_loss: 0.8735 - val_accuracy: 0.7778\n",
            "Epoch 447/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1652 - accuracy: 0.9432 - val_loss: 0.8614 - val_accuracy: 0.7391\n",
            "Epoch 448/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1879 - accuracy: 0.9444 - val_loss: 0.8224 - val_accuracy: 0.8309\n",
            "Epoch 449/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1628 - accuracy: 0.9444 - val_loss: 0.8571 - val_accuracy: 0.7826\n",
            "Epoch 450/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1764 - accuracy: 0.9462 - val_loss: 0.8337 - val_accuracy: 0.7923\n",
            "Epoch 451/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1669 - accuracy: 0.9420 - val_loss: 0.7705 - val_accuracy: 0.7681\n",
            "Epoch 452/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2204 - accuracy: 0.9329 - val_loss: 0.8443 - val_accuracy: 0.8116\n",
            "Epoch 453/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1623 - accuracy: 0.9359 - val_loss: 0.8508 - val_accuracy: 0.7826\n",
            "Epoch 454/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1455 - accuracy: 0.9444 - val_loss: 0.8389 - val_accuracy: 0.7826\n",
            "Epoch 455/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1706 - accuracy: 0.9353 - val_loss: 0.8777 - val_accuracy: 0.7778\n",
            "Epoch 456/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1820 - accuracy: 0.9341 - val_loss: 0.8623 - val_accuracy: 0.7826\n",
            "Epoch 457/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1465 - accuracy: 0.9474 - val_loss: 0.7784 - val_accuracy: 0.8164\n",
            "Epoch 458/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1655 - accuracy: 0.9420 - val_loss: 0.7459 - val_accuracy: 0.8019\n",
            "Epoch 459/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1587 - accuracy: 0.9474 - val_loss: 0.8732 - val_accuracy: 0.7826\n",
            "Epoch 460/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1785 - accuracy: 0.9377 - val_loss: 0.8874 - val_accuracy: 0.7923\n",
            "Epoch 461/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1404 - accuracy: 0.9528 - val_loss: 0.7657 - val_accuracy: 0.8116\n",
            "Epoch 462/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1791 - accuracy: 0.9414 - val_loss: 0.8585 - val_accuracy: 0.7971\n",
            "Epoch 463/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1768 - accuracy: 0.9401 - val_loss: 0.8149 - val_accuracy: 0.8068\n",
            "Epoch 464/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1402 - accuracy: 0.9474 - val_loss: 0.8548 - val_accuracy: 0.7778\n",
            "Epoch 465/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1538 - accuracy: 0.9414 - val_loss: 0.8087 - val_accuracy: 0.7971\n",
            "Epoch 466/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1821 - accuracy: 0.9389 - val_loss: 0.7372 - val_accuracy: 0.8019\n",
            "Epoch 467/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1753 - accuracy: 0.9426 - val_loss: 0.8096 - val_accuracy: 0.7971\n",
            "Epoch 468/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1569 - accuracy: 0.9462 - val_loss: 0.8739 - val_accuracy: 0.7681\n",
            "Epoch 469/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1369 - accuracy: 0.9522 - val_loss: 0.8972 - val_accuracy: 0.8019\n",
            "Epoch 470/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1558 - accuracy: 0.9486 - val_loss: 0.9022 - val_accuracy: 0.7874\n",
            "Epoch 471/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1546 - accuracy: 0.9444 - val_loss: 0.8873 - val_accuracy: 0.7971\n",
            "Epoch 472/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1763 - accuracy: 0.9407 - val_loss: 0.8402 - val_accuracy: 0.8068\n",
            "Epoch 473/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1836 - accuracy: 0.9414 - val_loss: 0.7442 - val_accuracy: 0.7874\n",
            "Epoch 474/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1360 - accuracy: 0.9528 - val_loss: 0.8435 - val_accuracy: 0.7778\n",
            "Epoch 475/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1409 - accuracy: 0.9486 - val_loss: 0.8561 - val_accuracy: 0.8164\n",
            "Epoch 476/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1910 - accuracy: 0.9353 - val_loss: 0.8579 - val_accuracy: 0.7681\n",
            "Epoch 477/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1669 - accuracy: 0.9395 - val_loss: 0.7815 - val_accuracy: 0.7826\n",
            "Epoch 478/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1494 - accuracy: 0.9510 - val_loss: 0.8901 - val_accuracy: 0.7971\n",
            "Epoch 479/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1414 - accuracy: 0.9474 - val_loss: 0.8000 - val_accuracy: 0.7826\n",
            "Epoch 480/500\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.1566 - accuracy: 0.9420 - val_loss: 0.8055 - val_accuracy: 0.8068\n",
            "Epoch 481/500\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.1457 - accuracy: 0.9498 - val_loss: 0.8597 - val_accuracy: 0.7923\n",
            "Epoch 482/500\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.1641 - accuracy: 0.9474 - val_loss: 0.9026 - val_accuracy: 0.7923\n",
            "Epoch 483/500\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.1398 - accuracy: 0.9510 - val_loss: 0.8549 - val_accuracy: 0.7681\n",
            "Epoch 484/500\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.1533 - accuracy: 0.9468 - val_loss: 0.8518 - val_accuracy: 0.7971\n",
            "Epoch 485/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1473 - accuracy: 0.9468 - val_loss: 1.0099 - val_accuracy: 0.7585\n",
            "Epoch 486/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1595 - accuracy: 0.9438 - val_loss: 0.9272 - val_accuracy: 0.7633\n",
            "Epoch 487/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1617 - accuracy: 0.9474 - val_loss: 0.9005 - val_accuracy: 0.7971\n",
            "Epoch 488/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1319 - accuracy: 0.9541 - val_loss: 0.9467 - val_accuracy: 0.7729\n",
            "Epoch 489/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1635 - accuracy: 0.9492 - val_loss: 0.8802 - val_accuracy: 0.8019\n",
            "Epoch 490/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1768 - accuracy: 0.9420 - val_loss: 0.8527 - val_accuracy: 0.7874\n",
            "Epoch 491/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1517 - accuracy: 0.9498 - val_loss: 0.7722 - val_accuracy: 0.7826\n",
            "Epoch 492/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1767 - accuracy: 0.9414 - val_loss: 0.7894 - val_accuracy: 0.8019\n",
            "Epoch 493/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1453 - accuracy: 0.9522 - val_loss: 0.8394 - val_accuracy: 0.7729\n",
            "Epoch 494/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1551 - accuracy: 0.9462 - val_loss: 0.9077 - val_accuracy: 0.7874\n",
            "Epoch 495/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1599 - accuracy: 0.9401 - val_loss: 0.7963 - val_accuracy: 0.7681\n",
            "Epoch 496/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1343 - accuracy: 0.9534 - val_loss: 0.8632 - val_accuracy: 0.7729\n",
            "Epoch 497/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1674 - accuracy: 0.9432 - val_loss: 0.9226 - val_accuracy: 0.7729\n",
            "Epoch 498/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1443 - accuracy: 0.9486 - val_loss: 0.7492 - val_accuracy: 0.8164\n",
            "Epoch 499/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1543 - accuracy: 0.9474 - val_loss: 0.9641 - val_accuracy: 0.7633\n",
            "Epoch 500/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1291 - accuracy: 0.9522 - val_loss: 0.9139 - val_accuracy: 0.7585\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(cnnhistory.history['loss'])\n",
        "plt.plot(cnnhistory.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train','test'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "oQYnuaCrDH_A",
        "outputId": "919f47bc-a30f-4f60-cdf0-514642116a4f"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(cnnhistory.history['accuracy'])\n",
        "plt.plot(cnnhistory.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train','test'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "IFkTuO8nDNdq",
        "outputId": "b484d21b-24b6-4cf1-8028-7556f722743c"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#predictions = model.predict_classes(x_testcnn)\n",
        "predictions = model.predict(x_testcnn)"
      ],
      "metadata": {
        "id": "A2xtrN5wDQgY"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_f_ohjXKDUpY",
        "outputId": "d8858f3a-6c06-4ccc-b1ff-211dda85d6d6"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[5.7568856e-09, 2.2054616e-10, 2.7440407e-03, 3.6848638e-07,\n",
              "        1.4711208e-05, 9.9724078e-01],\n",
              "       [2.0756341e-04, 9.9704832e-01, 1.6157343e-05, 2.5709418e-03,\n",
              "        1.4838784e-04, 8.6865739e-06],\n",
              "       [4.6079223e-15, 5.1103830e-06, 9.9999464e-01, 2.1217236e-10,\n",
              "        1.4270108e-07, 1.4684247e-07],\n",
              "       ...,\n",
              "       [1.3173266e-07, 7.2995947e-09, 1.0594547e-04, 1.3564589e-05,\n",
              "        9.9791354e-01, 1.9667959e-03],\n",
              "       [2.0077599e-04, 7.4346943e-05, 2.2372338e-05, 9.4355595e-01,\n",
              "        1.2103354e-05, 5.6134459e-02],\n",
              "       [8.7414846e-02, 1.6280819e-02, 5.0913768e-05, 1.5923541e-02,\n",
              "        8.8032794e-01, 1.8440790e-06]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cmA2bFgsDW3D",
        "outputId": "f5da3fa2-4f22-4104-ae14-bb35c732733c"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5, 1, 2, 5, 3, 4, 2, 0, 3, 1, 3, 2, 1, 4, 3, 0, 5, 0, 2, 5, 0, 0,\n",
              "       1, 3, 2, 3, 2, 5, 4, 2, 2, 3, 1, 2, 5, 5, 3, 5, 3, 3, 4, 1, 3, 2,\n",
              "       3, 1, 5, 3, 1, 2, 4, 4, 5, 5, 5, 1, 2, 3, 2, 5, 0, 2, 4, 2, 5, 4,\n",
              "       3, 0, 1, 2, 5, 2, 1, 2, 4, 5, 4, 1, 5, 5, 3, 1, 5, 3, 2, 4, 2, 5,\n",
              "       0, 5, 0, 5, 4, 0, 2, 4, 0, 2, 2, 0, 2, 3, 5, 3, 5, 5, 3, 1, 2, 2,\n",
              "       2, 1, 3, 2, 1, 3, 4, 4, 1, 1, 2, 4, 4, 1, 4, 2, 0, 4, 5, 5, 3, 1,\n",
              "       2, 1, 5, 5, 1, 2, 3, 3, 0, 3, 3, 0, 1, 0, 1, 2, 1, 5, 1, 2, 2, 0,\n",
              "       1, 1, 1, 1, 1, 4, 0, 1, 5, 1, 4, 5, 5, 4, 1, 0, 3, 5, 2, 3, 0, 4,\n",
              "       1, 3, 1, 0, 5, 5, 3, 5, 4, 5, 4, 0, 4, 1, 2, 1, 5, 0, 4, 3, 2, 1,\n",
              "       0, 3, 5, 0, 4, 5, 4, 5, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_Ytest = y_test.astype(int)"
      ],
      "metadata": {
        "id": "0PHDKWJWDY3g"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_Ytest"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k68v2i-pDbZE",
        "outputId": "a4f98d6e-5e31-46ac-8985-d1abe78cfc85"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5, 1, 2, 5, 3, 4, 2, 0, 3, 1, 3, 2, 1, 4, 3, 0, 5, 0, 2, 5, 0, 0,\n",
              "       1, 3, 2, 3, 2, 5, 4, 2, 2, 3, 1, 2, 5, 5, 3, 5, 3, 3, 4, 1, 3, 2,\n",
              "       3, 1, 5, 3, 1, 2, 4, 4, 5, 5, 5, 1, 2, 3, 2, 5, 0, 2, 4, 2, 5, 4,\n",
              "       3, 0, 1, 2, 5, 2, 1, 2, 4, 5, 4, 1, 5, 5, 3, 1, 5, 3, 2, 4, 2, 5,\n",
              "       0, 5, 0, 5, 4, 0, 2, 4, 0, 2, 2, 0, 2, 3, 5, 3, 5, 5, 3, 1, 2, 2,\n",
              "       2, 1, 3, 2, 1, 3, 4, 4, 1, 1, 2, 4, 4, 1, 4, 2, 0, 4, 5, 5, 3, 1,\n",
              "       2, 1, 5, 5, 1, 2, 3, 3, 0, 3, 3, 0, 1, 0, 1, 2, 1, 5, 1, 2, 2, 0,\n",
              "       1, 1, 1, 1, 1, 4, 0, 1, 5, 1, 4, 5, 5, 4, 1, 0, 3, 5, 2, 3, 0, 4,\n",
              "       1, 3, 1, 0, 5, 5, 3, 5, 4, 5, 4, 0, 4, 1, 2, 1, 5, 0, 4, 3, 2, 1,\n",
              "       0, 3, 5, 0, 4, 5, 4, 5, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds1=predictions.argmax(axis=1)\n",
        "preds1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4_cAI39VFhtp",
        "outputId": "0144ea50-fc2e-43bc-bfad-b5e04029b221"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5, 1, 2, 5, 1, 4, 2, 0, 3, 0, 3, 2, 1, 4, 3, 0, 5, 3, 2, 5, 2, 0,\n",
              "       1, 3, 2, 3, 2, 0, 4, 2, 2, 3, 0, 2, 5, 4, 1, 5, 3, 3, 4, 1, 2, 2,\n",
              "       3, 0, 3, 3, 1, 2, 4, 4, 5, 5, 3, 1, 2, 3, 4, 5, 0, 2, 4, 2, 5, 4,\n",
              "       3, 0, 1, 2, 3, 2, 1, 2, 4, 5, 4, 1, 5, 2, 3, 1, 5, 3, 2, 4, 2, 3,\n",
              "       0, 2, 0, 5, 4, 0, 3, 4, 3, 4, 2, 0, 2, 3, 5, 3, 5, 2, 5, 1, 4, 2,\n",
              "       2, 1, 3, 2, 1, 3, 4, 4, 0, 1, 2, 4, 4, 1, 4, 2, 0, 4, 4, 5, 5, 1,\n",
              "       2, 1, 2, 5, 1, 3, 3, 3, 0, 3, 5, 0, 1, 0, 1, 2, 1, 5, 0, 2, 2, 0,\n",
              "       1, 4, 1, 1, 2, 4, 0, 1, 5, 1, 4, 5, 4, 2, 1, 0, 5, 1, 2, 3, 1, 4,\n",
              "       1, 3, 1, 0, 5, 2, 3, 5, 4, 4, 2, 0, 4, 0, 2, 1, 3, 0, 4, 1, 2, 1,\n",
              "       1, 4, 5, 0, 4, 5, 4, 3, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "abc = preds1.astype(int).flatten()"
      ],
      "metadata": {
        "id": "H4WEmM60NfQn"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "c = confusion_matrix(new_Ytest, abc) \n",
        "c"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bKEBeEBlFjB8",
        "outputId": "2e29f51a-7be5-43da-b93f-83d6210e0fd9"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[20,  2,  1,  2,  0,  0],\n",
              "       [ 6, 31,  1,  0,  1,  0],\n",
              "       [ 0,  0, 33,  2,  3,  0],\n",
              "       [ 0,  3,  1, 24,  1,  4],\n",
              "       [ 0,  0,  2,  0, 28,  0],\n",
              "       [ 1,  1,  5,  6,  4, 25]])"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m4RjG7LWLSQx",
        "outputId": "6306117c-188e-4efd-ed2e-ffe33e71e952"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5, 1, 2, 5, 3, 4, 2, 0, 3, 1, 3, 2, 1, 4, 3, 0, 5, 0, 2, 5, 0, 0,\n",
              "       1, 3, 2, 3, 2, 5, 4, 2, 2, 3, 1, 2, 5, 5, 3, 5, 3, 3, 4, 1, 3, 2,\n",
              "       3, 1, 5, 3, 1, 2, 4, 4, 5, 5, 5, 1, 2, 3, 2, 5, 0, 2, 4, 2, 5, 4,\n",
              "       3, 0, 1, 2, 5, 2, 1, 2, 4, 5, 4, 1, 5, 5, 3, 1, 5, 3, 2, 4, 2, 5,\n",
              "       0, 5, 0, 5, 4, 0, 2, 4, 0, 2, 2, 0, 2, 3, 5, 3, 5, 5, 3, 1, 2, 2,\n",
              "       2, 1, 3, 2, 1, 3, 4, 4, 1, 1, 2, 4, 4, 1, 4, 2, 0, 4, 5, 5, 3, 1,\n",
              "       2, 1, 5, 5, 1, 2, 3, 3, 0, 3, 3, 0, 1, 0, 1, 2, 1, 5, 1, 2, 2, 0,\n",
              "       1, 1, 1, 1, 1, 4, 0, 1, 5, 1, 4, 5, 5, 4, 1, 0, 3, 5, 2, 3, 0, 4,\n",
              "       1, 3, 1, 0, 5, 5, 3, 5, 4, 5, 4, 0, 4, 1, 2, 1, 5, 0, 4, 3, 2, 1,\n",
              "       0, 3, 5, 0, 4, 5, 4, 5, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('/content/drive/My Drive/graduation project/audio/paper_code/mariam/original_500 epoch_with_valid_Adam2_3')\n",
        "print(\"MODEL SAVED\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lsJBNeMWDl6Z",
        "outputId": "a63c6fa5-69fa-4a9e-94b3-39bdd79a6bf9"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/graduation project/audio/paper_code/mariam/original_500 epoch_with_valid_Adam2_3/assets\n",
            "MODEL SAVED\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_model=keras.models.load_model('/content/drive/My Drive/graduation project/audio/paper_code/mariam/original_500 epoch_with_valid_Adam2_3')\n",
        "new_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q3KjaO9GDoNl",
        "outputId": "fa373069-5541-4b54-997b-7ca175e254b8"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d (Conv1D)             (None, 40, 128)           1152      \n",
            "                                                                 \n",
            " activation (Activation)     (None, 40, 128)           0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 40, 128)           0         \n",
            "                                                                 \n",
            " max_pooling1d (MaxPooling1D  (None, 8, 128)           0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv1d_1 (Conv1D)           (None, 8, 256)            262400    \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 8, 256)            0         \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 8, 256)            0         \n",
            "                                                                 \n",
            " max_pooling1d_1 (MaxPooling  (None, 1, 256)           0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 256)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 256)               65792     \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 256)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 256)               65792     \n",
            "                                                                 \n",
            " activation_3 (Activation)   (None, 256)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 6)                 1542      \n",
            "                                                                 \n",
            " activation_4 (Activation)   (None, 6)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 396,678\n",
            "Trainable params: 396,678\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss, acc =model.evaluate(x_testcnn, y_test)\n",
        "print(\"Restored model, accuracy: {:5.2f}%\".format(100*acc))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n3kzoqPkDqqS",
        "outputId": "c85d5505-7478-4279-e5f1-e5b9edb7eea0"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7/7 [==============================] - 0s 3ms/step - loss: 0.7448 - accuracy: 0.7778\n",
            "Restored model, accuracy: 77.78%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss, acc =model.evaluate(X_train, y_train)\n",
        "print(\"Restored model train, accuracy: {:5.2f}%\".format(100*acc))"
      ],
      "metadata": {
        "id": "fJDTGH_OUX0z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85da8a03-4d5d-4472-9d1b-a43ba1750fbe"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "52/52 [==============================] - 0s 4ms/step - loss: 0.0508 - accuracy: 0.9891\n",
            "Restored model train, accuracy: 98.91%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix,accuracy_score\n",
        "import seaborn as sn\n",
        "\n",
        "print(classification_report(new_Ytest,abc))\n",
        "\n",
        "acc = float(accuracy_score(new_Ytest,abc))*100\n",
        "print(\"----accuracy score %s ----\" % acc)\n",
        "\n",
        "cm = confusion_matrix(new_Ytest,abc)\n",
        "#df_cm = pd.DataFrame(cm)\n",
        "class_names = ['neutral','calm', 'happy','sad','angry', 'fearful' ]\n",
        "df_cm = pd.DataFrame(cm, index=class_names, columns=class_names,)\n",
        "sn.heatmap(df_cm, annot=True, fmt='')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 517
        },
        "id": "SfSC3El94LZg",
        "outputId": "b87eefbc-4c20-443b-cda1-f90ab6d0300b"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.74      0.80      0.77        25\n",
            "           1       0.84      0.79      0.82        39\n",
            "           2       0.77      0.87      0.81        38\n",
            "           3       0.71      0.73      0.72        33\n",
            "           4       0.76      0.93      0.84        30\n",
            "           5       0.86      0.60      0.70        42\n",
            "\n",
            "    accuracy                           0.78       207\n",
            "   macro avg       0.78      0.79      0.78       207\n",
            "weighted avg       0.79      0.78      0.77       207\n",
            "\n",
            "----accuracy score 77.77777777777779 ----\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "LGpgwFQqkpyU"
      },
      "execution_count": 37,
      "outputs": []
    }
  ]
}