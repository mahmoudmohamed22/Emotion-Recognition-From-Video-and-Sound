{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "original RMS lr=0.0001 try1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9SRCO-a_AlH5",
        "outputId": "9b041841-05e7-4acd-ecaf-490954e46555"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install librosa"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oi8pWV3yBVjO",
        "outputId": "47c617dd-8cea-40b8-b6a9-39a3fb373ef3"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.7/dist-packages (0.8.1)\n",
            "Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.0.2)\n",
            "Requirement already satisfied: numba>=0.43.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (0.51.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (21.3)\n",
            "Requirement already satisfied: audioread>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (2.1.9)\n",
            "Requirement already satisfied: decorator>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.1.0)\n",
            "Requirement already satisfied: soundfile>=0.10.2 in /usr/local/lib/python3.7/dist-packages (from librosa) (0.10.3.post1)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.4.1)\n",
            "Requirement already satisfied: resampy>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from librosa) (0.2.2)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.21.6)\n",
            "Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.6.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba>=0.43.0->librosa) (57.4.0)\n",
            "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba>=0.43.0->librosa) (0.34.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->librosa) (3.0.9)\n",
            "Requirement already satisfied: appdirs>=1.3.0 in /usr/local/lib/python3.7/dist-packages (from pooch>=1.0->librosa) (1.4.4)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from pooch>=1.0->librosa) (2.23.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2022.5.18.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (3.0.4)\n",
            "Requirement already satisfied: six>=1.3 in /usr/local/lib/python3.7/dist-packages (from resampy>=0.2.2->librosa) (1.15.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn!=0.19.0,>=0.14.0->librosa) (3.1.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.7/dist-packages (from soundfile>=0.10.2->librosa) (1.15.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.0->soundfile>=0.10.2->librosa) (2.21)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HJjcbxwy46bG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "15c1f2f1-be64-433c-ed0e-75786a0a2bb4"
      },
      "source": [
        "# Orignial Notebook: https://github.com/MITESHPUTHRANNEU/Speech-Emotion-Analyzer/blob/master/final_results_gender_test.ipynb\n",
        "# This notebook author: Reza Chu\n",
        "# Last Editing Date: 31st May 2019\n",
        "\n",
        "## Python\n",
        "import os\n",
        "import random\n",
        "import sys\n",
        "\n",
        "import IPython\n",
        "from IPython.display import Audio\n",
        "from IPython.display import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "## Package\n",
        "import glob \n",
        "import keras\n",
        "import IPython.display as ipd\n",
        "import librosa\n",
        "import librosa.display\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import plotly.graph_objs as go\n",
        "import plotly.offline as py\n",
        "import plotly.tools as tls\n",
        "import seaborn as sns\n",
        "import scipy.io.wavfile\n",
        "import tensorflow as tf\n",
        "py.init_notebook_mode(connected=True)\n",
        "\n",
        "## Keras\n",
        "from keras import regularizers\n",
        "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping\n",
        "from keras.callbacks import  History, ReduceLROnPlateau, CSVLogger\n",
        "from keras.models import Model, Sequential\n",
        "from keras.layers import Dense, Embedding, LSTM\n",
        "from keras.layers import Input, Flatten, Dropout, Activation, BatchNormalization\n",
        "from keras.layers import Conv1D, MaxPooling1D, AveragePooling1D\n",
        "from keras.preprocessing import sequence\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.utils import np_utils\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "## Sklearn\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "## Rest\n",
        "from scipy.fftpack import fft\n",
        "from scipy import signal\n",
        "from scipy.io import wavfile\n",
        "from tqdm import tqdm\n",
        "\n",
        "input_duration=3\n",
        "# % pylab inline"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "        <script type=\"text/javascript\">\n",
              "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
              "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
              "        if (typeof require !== 'undefined') {\n",
              "        require.undef(\"plotly\");\n",
              "        requirejs.config({\n",
              "            paths: {\n",
              "                'plotly': ['https://cdn.plot.ly/plotly-2.8.3.min']\n",
              "            }\n",
              "        });\n",
              "        require(['plotly'], function(Plotly) {\n",
              "            window._Plotly = Plotly;\n",
              "        });\n",
              "        }\n",
              "        </script>\n",
              "        "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#radvass speech and song\n",
        "import time\n",
        "import os\n",
        "import librosa\n",
        "from librosa import display\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "count=0\n",
        "path1 = '/content/drive/MyDrive/RAVDESS_speech'\n",
        "path2 = '/content/drive/MyDrive/RAVDESS_song'\n",
        "\n",
        "lst = []\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "for subdir, dirs, files in os.walk(path2):\n",
        "  print(dirs)\n",
        "  print(subdir)\n",
        "  #print(files)\n",
        "  for file in files:\n",
        "      try:\n",
        "        count +=1\n",
        "        #Load librosa array, obtain mfcss, store the file and the mcss information in a new array\n",
        "        X, sample_rate = librosa.load(os.path.join(subdir,file), res_type='kaiser_fast')\n",
        "        mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T,axis=0) \n",
        "        # The instruction below converts the labels (from 1 to 8) to a series from 0 to 7\n",
        "        # This is because our predictor needs to start from 0 otherwise it will try to predict also 0.\n",
        "        file = int(file[7:8]) - 1 \n",
        "        arr = mfccs, file\n",
        "        lst.append(arr)\n",
        "      # If the file is not valid, skip it\n",
        "      except ValueError:\n",
        "        continue\n",
        "\n",
        "for subdir, dirs, files in os.walk(path1):\n",
        "  print(dirs)\n",
        "  print(subdir)\n",
        " # print(files)\n",
        "  for file in files:\n",
        "      try:\n",
        "        #Load librosa array, obtain mfcss, store the file and the mcss information in a new array\n",
        "        X, sample_rate = librosa.load(os.path.join(subdir,file), res_type='kaiser_fast')\n",
        "        mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T,axis=0) \n",
        "        # The instruction below converts the labels (from 1 to 8) to a series from 0 to 7\n",
        "        # This is because our predictor needs to start from 0 otherwise it will try to predict also 0.\n",
        "        file = int(file[7:8]) - 1 \n",
        "        if(file ==6 or file==7):\n",
        "          continue\n",
        "        count +=1\n",
        "        arr = mfccs, file\n",
        "        lst.append(arr)\n",
        "      # If the file is not valid, skip it\n",
        "      except ValueError:\n",
        "        continue\n",
        "\n",
        "\n",
        "\n",
        "print(\"--- Data loaded. Loading time: %s seconds ---\" % (time.time() - start_time))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IfuyRZl42ccZ",
        "outputId": "92509888-e831-4089-cae7-9050d3b3d111"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Actor_10', 'Actor_11', 'Actor_13', 'Actor_12', 'Actor_14', 'Actor_15', 'Actor_16', 'Actor_17', 'Actor_18', 'Actor_19', 'Actor_21', 'Actor_22', 'Actor_23', 'Actor_09', 'Actor_24', 'Actor_04', 'Actor_08', 'Actor_03', 'Actor_02', 'Actor_06', 'Actor_05', 'Actor_01', 'Actor_07', 'Actor_20']\n",
            "/content/drive/MyDrive/RAVDESS_song\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_10\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_11\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_13\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_12\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_14\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_15\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_16\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_17\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_18\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_19\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_21\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_22\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_23\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_09\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_24\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_04\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_08\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_03\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_02\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_06\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_05\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_01\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_07\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_20\n",
            "['Actor_05', 'Actor_08', 'Actor_10', 'Actor_04', 'Actor_09', 'Actor_14', 'Actor_12', 'Actor_13', 'Actor_11', 'Actor_06', 'Actor_24', 'Actor_07', 'Actor_23', 'Actor_22', 'Actor_21', 'Actor_20', 'Actor_02', 'Actor_19', 'Actor_18', 'Actor_17', 'Actor_16', 'Actor_15', 'Actor_03', 'Actor_01']\n",
            "/content/drive/MyDrive/RAVDESS_speech\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_05\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_08\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_10\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_04\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_09\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_14\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_12\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_13\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_11\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_06\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_24\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_07\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_23\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_22\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_21\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_20\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_02\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_19\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_18\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_17\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_16\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_15\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_03\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_01\n",
            "--- Data loaded. Loading time: 756.4914510250092 seconds ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "count"
      ],
      "metadata": {
        "id": "Ltlhi25L2AI5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c82409b-cb8a-465a-d898-8a38162f1294"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2068"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy.core.fromnumeric import size\n",
        "size(lst)"
      ],
      "metadata": {
        "id": "HMOH7d7mzHB7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac93d79c-6b25-4057-a118-882ca3d4f347"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/core/fromnumeric.py:3208: VisibleDeprecationWarning:\n",
            "\n",
            "Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4136"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating X and y: zip makes a list of all the first elements, and a list of all the second elements.\n",
        "X, y = zip(*lst)"
      ],
      "metadata": {
        "id": "ocdL7tSTBoMt"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "X = np.asarray(X)\n",
        "y = np.asarray(y)\n",
        "X.shape, y.shape"
      ],
      "metadata": {
        "id": "vHKwUGTbBtnF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "abda46ea-55e3-4f62-a16a-805aa58a4811"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((2068, 40), (2068,))"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "id": "2sUCtbfMztE5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d168939-c326-4878-e788-a9549caadb17"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2068, 40)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Saving joblib files to not load them again with the loop above\n",
        "\n",
        "# import joblib\n",
        "\n",
        "# X_name = 'x.joblib'\n",
        "# y_name = 'y.joblib'\n",
        "# save_dir = '/content/drive/My Drive/graduation project/audio/paper_code/features'\n",
        "\n",
        "# savedX = joblib.dump(X, os.path.join(save_dir, X_name))\n",
        "# savedy = joblib.dump(y, os.path.join(save_dir, y_name))"
      ],
      "metadata": {
        "id": "UCzic8rlDcuk"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Loading saved models\n",
        "# import joblib\n",
        "# X = joblib.load('/content/drive/My Drive/graduation project/audio/paper_code/features/x.joblib')\n",
        "# y = joblib.load('/content/drive/My Drive/graduation project/audio/paper_code/features/y.joblib')"
      ],
      "metadata": {
        "id": "Q35CN6zDrzg1"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7PSTurzjCo5K",
        "outputId": "9c204bd4-55a7-467d-c342-e38d7e98244b"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2068, 40)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2,train_size=0.8, random_state=42)\n",
        "X_valid, X_test, y_valid, y_test = train_test_split(X_test,y_test, test_size=0.5,train_size=0.5, random_state=42)"
      ],
      "metadata": {
        "id": "Ai4Fy5cPCiq1"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "x_traincnn = np.expand_dims(X_train, axis=2)\n",
        "x_testcnn = np.expand_dims(X_test, axis=2)\n",
        "X_valid= np.expand_dims(X_valid, axis=2)"
      ],
      "metadata": {
        "id": "tp1Fm5K3CEXu"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_traincnn.shape, x_testcnn.shape , X_valid.shape"
      ],
      "metadata": {
        "id": "RI0MxoIPBws5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5267d471-def7-4f07-9c22-bd31af8e4183"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1654, 40, 1), (207, 40, 1), (207, 40, 1))"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow"
      ],
      "metadata": {
        "id": "goxL4Y3jKICC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc6ff6ef-1e35-431b-b9a6-3a6c073822c2"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (2.8.2+zzzcolab20220527125636)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow) (57.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (14.0.1)\n",
            "Requirement already satisfied: tensorflow-estimator<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.21.6)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.0.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.46.3)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.26.0)\n",
            "Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.17.3)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (4.2.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.5.3)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow) (1.5.2)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.4.6)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (3.3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.6.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.8.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.23.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.35.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (4.11.4)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (3.8.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2022.5.18.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (3.2.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keras"
      ],
      "metadata": {
        "id": "EkcmN9UrKSxj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "30a84aee-b246-47f9-d034-3d88ca3cafd7"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.7/dist-packages (2.8.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from keras.preprocessing import sequence\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from keras.layers import Input, Flatten, Dropout, Activation\n",
        "from keras.layers import Conv1D, MaxPooling1D\n",
        "from keras.models import Model\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras import optimizers\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv1D(128, 8,padding='same', #classifier.add(Convolution2D(64, (3, 3), padding = 'same', input_shape = (128, 128, 3), activation = 'relu'))\n",
        "                 input_shape=(40,1)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(MaxPooling1D(pool_size=(5)))\n",
        "\n",
        "\n",
        "model.add(Conv1D(256,8,padding='same',))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(MaxPooling1D(pool_size=(5)))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(256))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(256))\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "model.add(Dense(6))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "#opt = tf.keras.optimizers.Adam(lr=0.00002)\n",
        "opt = tf.keras.optimizers.RMSprop(lr=0.0001, rho=0.9, epsilon=1e-07, decay=0.0)\n",
        "#opt = tf.keras.optimizers.SGD(lr=0.001, momentum=0.0, decay=0.0, nesterov=False)"
      ],
      "metadata": {
        "id": "g74fXWVAC4Cr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dfd9403d-806b-4ac0-aee0-3f6bc22953a1"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/rmsprop.py:130: UserWarning:\n",
            "\n",
            "The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H6ukOxAGC_I4",
        "outputId": "9a7b18a6-6df0-4004-a804-9caf0f15a935"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d (Conv1D)             (None, 40, 128)           1152      \n",
            "                                                                 \n",
            " activation (Activation)     (None, 40, 128)           0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 40, 128)           0         \n",
            "                                                                 \n",
            " max_pooling1d (MaxPooling1D  (None, 8, 128)           0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv1d_1 (Conv1D)           (None, 8, 256)            262400    \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 8, 256)            0         \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 8, 256)            0         \n",
            "                                                                 \n",
            " max_pooling1d_1 (MaxPooling  (None, 1, 256)           0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 256)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 256)               65792     \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 256)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 256)               65792     \n",
            "                                                                 \n",
            " activation_3 (Activation)   (None, 256)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 6)                 1542      \n",
            "                                                                 \n",
            " activation_4 (Activation)   (None, 6)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 396,678\n",
            "Trainable params: 396,678\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='sparse_categorical_crossentropy',\n",
        "              optimizer=opt,\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "AbMlLNk4DCBM"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#cnnhistory=model.fit(x_traincnn, y_train, batch_size=16, epochs=700, validation_data=(x_testcnn, y_test))\n",
        "cnnhistory=model.fit(x_traincnn, y_train, batch_size=16, epochs=500 , validation_data=(X_valid, y_valid))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RI1v2AuADFhy",
        "outputId": "8e166e5e-7102-4798-e088-10c3bf81166f"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "104/104 [==============================] - 16s 19ms/step - loss: 4.9219 - accuracy: 0.1741 - val_loss: 2.0500 - val_accuracy: 0.1836\n",
            "Epoch 2/500\n",
            "104/104 [==============================] - 1s 10ms/step - loss: 2.9902 - accuracy: 0.1759 - val_loss: 2.0220 - val_accuracy: 0.2029\n",
            "Epoch 3/500\n",
            "104/104 [==============================] - 1s 9ms/step - loss: 2.3372 - accuracy: 0.2044 - val_loss: 1.6790 - val_accuracy: 0.3140\n",
            "Epoch 4/500\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 2.1756 - accuracy: 0.2122 - val_loss: 1.8728 - val_accuracy: 0.1836\n",
            "Epoch 5/500\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 2.0661 - accuracy: 0.2279 - val_loss: 1.9706 - val_accuracy: 0.0628\n",
            "Epoch 6/500\n",
            "104/104 [==============================] - 1s 9ms/step - loss: 1.9766 - accuracy: 0.2019 - val_loss: 1.7018 - val_accuracy: 0.3720\n",
            "Epoch 7/500\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 1.9279 - accuracy: 0.2261 - val_loss: 1.7021 - val_accuracy: 0.3043\n",
            "Epoch 8/500\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 1.9105 - accuracy: 0.2177 - val_loss: 1.6933 - val_accuracy: 0.3140\n",
            "Epoch 9/500\n",
            "104/104 [==============================] - 1s 9ms/step - loss: 1.8303 - accuracy: 0.2521 - val_loss: 1.6892 - val_accuracy: 0.2657\n",
            "Epoch 10/500\n",
            "104/104 [==============================] - 1s 9ms/step - loss: 1.8213 - accuracy: 0.2449 - val_loss: 1.7464 - val_accuracy: 0.2271\n",
            "Epoch 11/500\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 1.7586 - accuracy: 0.2703 - val_loss: 1.6566 - val_accuracy: 0.3237\n",
            "Epoch 12/500\n",
            "104/104 [==============================] - 1s 9ms/step - loss: 1.7521 - accuracy: 0.2860 - val_loss: 1.6001 - val_accuracy: 0.3720\n",
            "Epoch 13/500\n",
            "104/104 [==============================] - 1s 9ms/step - loss: 1.7100 - accuracy: 0.2854 - val_loss: 1.6558 - val_accuracy: 0.2512\n",
            "Epoch 14/500\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 1.7030 - accuracy: 0.2848 - val_loss: 1.6102 - val_accuracy: 0.3043\n",
            "Epoch 15/500\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 1.7299 - accuracy: 0.2648 - val_loss: 1.6158 - val_accuracy: 0.3188\n",
            "Epoch 16/500\n",
            "104/104 [==============================] - 1s 9ms/step - loss: 1.6614 - accuracy: 0.3023 - val_loss: 1.5557 - val_accuracy: 0.4010\n",
            "Epoch 17/500\n",
            "104/104 [==============================] - 1s 9ms/step - loss: 1.6462 - accuracy: 0.3180 - val_loss: 1.5836 - val_accuracy: 0.3478\n",
            "Epoch 18/500\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 1.6217 - accuracy: 0.3241 - val_loss: 1.5897 - val_accuracy: 0.3188\n",
            "Epoch 19/500\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 1.6159 - accuracy: 0.3531 - val_loss: 1.5369 - val_accuracy: 0.4155\n",
            "Epoch 20/500\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 1.5753 - accuracy: 0.3416 - val_loss: 1.5393 - val_accuracy: 0.3768\n",
            "Epoch 21/500\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 1.5843 - accuracy: 0.3362 - val_loss: 1.5155 - val_accuracy: 0.3575\n",
            "Epoch 22/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.5563 - accuracy: 0.3470 - val_loss: 1.5312 - val_accuracy: 0.3720\n",
            "Epoch 23/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.5294 - accuracy: 0.3773 - val_loss: 1.4455 - val_accuracy: 0.4734\n",
            "Epoch 24/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.5447 - accuracy: 0.3615 - val_loss: 1.4258 - val_accuracy: 0.4541\n",
            "Epoch 25/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.4786 - accuracy: 0.3863 - val_loss: 1.4396 - val_accuracy: 0.4058\n",
            "Epoch 26/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.4989 - accuracy: 0.3851 - val_loss: 1.3969 - val_accuracy: 0.3961\n",
            "Epoch 27/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.4425 - accuracy: 0.3984 - val_loss: 1.4357 - val_accuracy: 0.3961\n",
            "Epoch 28/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.4650 - accuracy: 0.3972 - val_loss: 1.4533 - val_accuracy: 0.4444\n",
            "Epoch 29/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.4485 - accuracy: 0.4117 - val_loss: 1.3911 - val_accuracy: 0.4155\n",
            "Epoch 30/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.4096 - accuracy: 0.4166 - val_loss: 1.4570 - val_accuracy: 0.3382\n",
            "Epoch 31/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.4214 - accuracy: 0.4129 - val_loss: 1.3661 - val_accuracy: 0.4879\n",
            "Epoch 32/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.4095 - accuracy: 0.4256 - val_loss: 1.3623 - val_accuracy: 0.4976\n",
            "Epoch 33/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.3976 - accuracy: 0.4178 - val_loss: 1.3641 - val_accuracy: 0.4879\n",
            "Epoch 34/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.3827 - accuracy: 0.4274 - val_loss: 1.3309 - val_accuracy: 0.4783\n",
            "Epoch 35/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.3539 - accuracy: 0.4389 - val_loss: 1.3563 - val_accuracy: 0.4879\n",
            "Epoch 36/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.3482 - accuracy: 0.4377 - val_loss: 1.2639 - val_accuracy: 0.5024\n",
            "Epoch 37/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.3377 - accuracy: 0.4601 - val_loss: 1.2961 - val_accuracy: 0.4783\n",
            "Epoch 38/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.3260 - accuracy: 0.4432 - val_loss: 1.2717 - val_accuracy: 0.5121\n",
            "Epoch 39/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.2903 - accuracy: 0.4813 - val_loss: 1.2105 - val_accuracy: 0.5604\n",
            "Epoch 40/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.2694 - accuracy: 0.4758 - val_loss: 1.1732 - val_accuracy: 0.5507\n",
            "Epoch 41/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.2907 - accuracy: 0.4807 - val_loss: 1.3568 - val_accuracy: 0.4396\n",
            "Epoch 42/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.2723 - accuracy: 0.4764 - val_loss: 1.2707 - val_accuracy: 0.4831\n",
            "Epoch 43/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.2342 - accuracy: 0.4958 - val_loss: 1.2027 - val_accuracy: 0.5024\n",
            "Epoch 44/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.2515 - accuracy: 0.4891 - val_loss: 1.1496 - val_accuracy: 0.5845\n",
            "Epoch 45/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.2203 - accuracy: 0.5200 - val_loss: 1.2036 - val_accuracy: 0.5024\n",
            "Epoch 46/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.2226 - accuracy: 0.5079 - val_loss: 1.1760 - val_accuracy: 0.5700\n",
            "Epoch 47/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.2107 - accuracy: 0.5054 - val_loss: 1.1474 - val_accuracy: 0.5507\n",
            "Epoch 48/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.2054 - accuracy: 0.5036 - val_loss: 1.1557 - val_accuracy: 0.5411\n",
            "Epoch 49/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.2041 - accuracy: 0.5060 - val_loss: 1.1395 - val_accuracy: 0.5797\n",
            "Epoch 50/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.1940 - accuracy: 0.5091 - val_loss: 1.1782 - val_accuracy: 0.5314\n",
            "Epoch 51/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.1589 - accuracy: 0.5230 - val_loss: 1.1132 - val_accuracy: 0.5894\n",
            "Epoch 52/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.1693 - accuracy: 0.5175 - val_loss: 1.0936 - val_accuracy: 0.5797\n",
            "Epoch 53/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.1626 - accuracy: 0.5435 - val_loss: 1.0971 - val_accuracy: 0.5845\n",
            "Epoch 54/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.1416 - accuracy: 0.5302 - val_loss: 1.0894 - val_accuracy: 0.5894\n",
            "Epoch 55/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.1354 - accuracy: 0.5345 - val_loss: 1.1588 - val_accuracy: 0.5266\n",
            "Epoch 56/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.1103 - accuracy: 0.5387 - val_loss: 1.1117 - val_accuracy: 0.5507\n",
            "Epoch 57/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.1337 - accuracy: 0.5453 - val_loss: 1.1372 - val_accuracy: 0.5797\n",
            "Epoch 58/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0962 - accuracy: 0.5520 - val_loss: 1.0546 - val_accuracy: 0.6087\n",
            "Epoch 59/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0942 - accuracy: 0.5689 - val_loss: 1.0541 - val_accuracy: 0.5942\n",
            "Epoch 60/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0756 - accuracy: 0.5605 - val_loss: 1.0646 - val_accuracy: 0.5894\n",
            "Epoch 61/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0847 - accuracy: 0.5623 - val_loss: 1.1009 - val_accuracy: 0.5604\n",
            "Epoch 62/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0799 - accuracy: 0.5526 - val_loss: 1.0525 - val_accuracy: 0.6232\n",
            "Epoch 63/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0661 - accuracy: 0.5756 - val_loss: 1.0871 - val_accuracy: 0.5894\n",
            "Epoch 64/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0527 - accuracy: 0.5786 - val_loss: 1.0451 - val_accuracy: 0.5749\n",
            "Epoch 65/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0441 - accuracy: 0.5689 - val_loss: 1.0245 - val_accuracy: 0.6184\n",
            "Epoch 66/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0486 - accuracy: 0.5701 - val_loss: 1.0223 - val_accuracy: 0.6039\n",
            "Epoch 67/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0352 - accuracy: 0.5756 - val_loss: 1.0138 - val_accuracy: 0.5990\n",
            "Epoch 68/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0111 - accuracy: 0.5877 - val_loss: 1.0363 - val_accuracy: 0.5845\n",
            "Epoch 69/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0253 - accuracy: 0.5871 - val_loss: 0.9800 - val_accuracy: 0.6522\n",
            "Epoch 70/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0278 - accuracy: 0.5877 - val_loss: 0.9884 - val_accuracy: 0.6280\n",
            "Epoch 71/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9861 - accuracy: 0.6004 - val_loss: 1.0367 - val_accuracy: 0.5797\n",
            "Epoch 72/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0203 - accuracy: 0.5865 - val_loss: 1.0021 - val_accuracy: 0.6087\n",
            "Epoch 73/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0051 - accuracy: 0.5955 - val_loss: 0.9749 - val_accuracy: 0.6184\n",
            "Epoch 74/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9875 - accuracy: 0.5931 - val_loss: 0.9854 - val_accuracy: 0.6135\n",
            "Epoch 75/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9820 - accuracy: 0.5998 - val_loss: 0.9554 - val_accuracy: 0.6570\n",
            "Epoch 76/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9712 - accuracy: 0.6040 - val_loss: 0.9679 - val_accuracy: 0.5894\n",
            "Epoch 77/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9600 - accuracy: 0.6112 - val_loss: 0.9468 - val_accuracy: 0.5990\n",
            "Epoch 78/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9591 - accuracy: 0.6300 - val_loss: 0.9803 - val_accuracy: 0.5942\n",
            "Epoch 79/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9571 - accuracy: 0.6046 - val_loss: 0.9774 - val_accuracy: 0.6184\n",
            "Epoch 80/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9316 - accuracy: 0.6209 - val_loss: 0.9162 - val_accuracy: 0.6570\n",
            "Epoch 81/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9193 - accuracy: 0.6360 - val_loss: 0.9789 - val_accuracy: 0.5797\n",
            "Epoch 82/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9425 - accuracy: 0.6239 - val_loss: 0.9511 - val_accuracy: 0.6232\n",
            "Epoch 83/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9220 - accuracy: 0.6245 - val_loss: 0.9439 - val_accuracy: 0.5942\n",
            "Epoch 84/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9240 - accuracy: 0.6239 - val_loss: 0.9234 - val_accuracy: 0.6232\n",
            "Epoch 85/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9081 - accuracy: 0.6354 - val_loss: 0.9364 - val_accuracy: 0.6329\n",
            "Epoch 86/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9233 - accuracy: 0.6270 - val_loss: 0.9194 - val_accuracy: 0.6135\n",
            "Epoch 87/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8822 - accuracy: 0.6493 - val_loss: 0.9021 - val_accuracy: 0.6377\n",
            "Epoch 88/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9060 - accuracy: 0.6397 - val_loss: 0.8880 - val_accuracy: 0.6715\n",
            "Epoch 89/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8995 - accuracy: 0.6366 - val_loss: 0.9021 - val_accuracy: 0.6425\n",
            "Epoch 90/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8873 - accuracy: 0.6463 - val_loss: 0.8963 - val_accuracy: 0.6377\n",
            "Epoch 91/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8836 - accuracy: 0.6518 - val_loss: 0.9243 - val_accuracy: 0.6473\n",
            "Epoch 92/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8713 - accuracy: 0.6560 - val_loss: 0.9106 - val_accuracy: 0.6329\n",
            "Epoch 93/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8796 - accuracy: 0.6620 - val_loss: 0.8645 - val_accuracy: 0.7005\n",
            "Epoch 94/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8470 - accuracy: 0.6584 - val_loss: 0.8842 - val_accuracy: 0.6715\n",
            "Epoch 95/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8815 - accuracy: 0.6457 - val_loss: 0.9083 - val_accuracy: 0.6087\n",
            "Epoch 96/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8472 - accuracy: 0.6548 - val_loss: 0.8909 - val_accuracy: 0.6522\n",
            "Epoch 97/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8584 - accuracy: 0.6524 - val_loss: 0.9281 - val_accuracy: 0.6232\n",
            "Epoch 98/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8419 - accuracy: 0.6657 - val_loss: 0.8821 - val_accuracy: 0.6329\n",
            "Epoch 99/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8486 - accuracy: 0.6741 - val_loss: 0.9247 - val_accuracy: 0.6184\n",
            "Epoch 100/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8267 - accuracy: 0.6669 - val_loss: 0.8497 - val_accuracy: 0.6570\n",
            "Epoch 101/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8367 - accuracy: 0.6554 - val_loss: 0.9419 - val_accuracy: 0.6087\n",
            "Epoch 102/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8405 - accuracy: 0.6536 - val_loss: 0.8659 - val_accuracy: 0.6570\n",
            "Epoch 103/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8196 - accuracy: 0.6693 - val_loss: 0.8950 - val_accuracy: 0.6667\n",
            "Epoch 104/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8051 - accuracy: 0.6814 - val_loss: 0.8957 - val_accuracy: 0.6667\n",
            "Epoch 105/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8130 - accuracy: 0.6687 - val_loss: 0.8412 - val_accuracy: 0.6812\n",
            "Epoch 106/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7934 - accuracy: 0.6880 - val_loss: 0.9029 - val_accuracy: 0.6039\n",
            "Epoch 107/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8089 - accuracy: 0.6669 - val_loss: 0.8308 - val_accuracy: 0.6522\n",
            "Epoch 108/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7781 - accuracy: 0.6838 - val_loss: 0.8361 - val_accuracy: 0.6763\n",
            "Epoch 109/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7891 - accuracy: 0.6844 - val_loss: 0.8999 - val_accuracy: 0.6377\n",
            "Epoch 110/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7925 - accuracy: 0.6729 - val_loss: 0.8589 - val_accuracy: 0.6425\n",
            "Epoch 111/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7785 - accuracy: 0.6929 - val_loss: 0.8217 - val_accuracy: 0.6860\n",
            "Epoch 112/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7897 - accuracy: 0.6868 - val_loss: 0.8267 - val_accuracy: 0.6957\n",
            "Epoch 113/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7705 - accuracy: 0.6971 - val_loss: 0.8298 - val_accuracy: 0.6957\n",
            "Epoch 114/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7834 - accuracy: 0.6874 - val_loss: 0.9177 - val_accuracy: 0.6329\n",
            "Epoch 115/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7556 - accuracy: 0.7025 - val_loss: 0.8942 - val_accuracy: 0.6377\n",
            "Epoch 116/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7739 - accuracy: 0.6838 - val_loss: 0.8602 - val_accuracy: 0.6184\n",
            "Epoch 117/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7435 - accuracy: 0.7007 - val_loss: 0.8089 - val_accuracy: 0.6908\n",
            "Epoch 118/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7529 - accuracy: 0.6923 - val_loss: 0.8182 - val_accuracy: 0.6957\n",
            "Epoch 119/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7477 - accuracy: 0.7086 - val_loss: 0.8005 - val_accuracy: 0.6812\n",
            "Epoch 120/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7613 - accuracy: 0.6947 - val_loss: 0.8176 - val_accuracy: 0.6618\n",
            "Epoch 121/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7552 - accuracy: 0.7031 - val_loss: 0.7982 - val_accuracy: 0.7005\n",
            "Epoch 122/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7254 - accuracy: 0.7177 - val_loss: 0.8042 - val_accuracy: 0.6957\n",
            "Epoch 123/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7447 - accuracy: 0.6892 - val_loss: 0.8315 - val_accuracy: 0.7101\n",
            "Epoch 124/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7320 - accuracy: 0.7104 - val_loss: 0.8107 - val_accuracy: 0.7005\n",
            "Epoch 125/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7122 - accuracy: 0.7207 - val_loss: 0.8075 - val_accuracy: 0.6763\n",
            "Epoch 126/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7264 - accuracy: 0.7152 - val_loss: 0.8361 - val_accuracy: 0.6763\n",
            "Epoch 127/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7052 - accuracy: 0.7201 - val_loss: 0.7738 - val_accuracy: 0.6763\n",
            "Epoch 128/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7132 - accuracy: 0.7189 - val_loss: 0.7978 - val_accuracy: 0.7246\n",
            "Epoch 129/500\n",
            "104/104 [==============================] - 1s 9ms/step - loss: 0.6986 - accuracy: 0.7261 - val_loss: 0.7952 - val_accuracy: 0.6715\n",
            "Epoch 130/500\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 0.6848 - accuracy: 0.7376 - val_loss: 0.8321 - val_accuracy: 0.6570\n",
            "Epoch 131/500\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 0.7037 - accuracy: 0.7158 - val_loss: 0.7652 - val_accuracy: 0.7053\n",
            "Epoch 132/500\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 0.6950 - accuracy: 0.7237 - val_loss: 0.7829 - val_accuracy: 0.7005\n",
            "Epoch 133/500\n",
            "104/104 [==============================] - 1s 9ms/step - loss: 0.6870 - accuracy: 0.7376 - val_loss: 0.8182 - val_accuracy: 0.6570\n",
            "Epoch 134/500\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.6732 - accuracy: 0.7310 - val_loss: 0.7541 - val_accuracy: 0.6957\n",
            "Epoch 135/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6865 - accuracy: 0.7304 - val_loss: 0.7616 - val_accuracy: 0.7005\n",
            "Epoch 136/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6627 - accuracy: 0.7352 - val_loss: 0.7593 - val_accuracy: 0.7005\n",
            "Epoch 137/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6875 - accuracy: 0.7334 - val_loss: 0.7729 - val_accuracy: 0.6763\n",
            "Epoch 138/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6847 - accuracy: 0.7207 - val_loss: 0.8066 - val_accuracy: 0.6667\n",
            "Epoch 139/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6473 - accuracy: 0.7527 - val_loss: 0.8056 - val_accuracy: 0.6908\n",
            "Epoch 140/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6622 - accuracy: 0.7352 - val_loss: 0.7534 - val_accuracy: 0.7053\n",
            "Epoch 141/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6486 - accuracy: 0.7418 - val_loss: 0.7866 - val_accuracy: 0.6522\n",
            "Epoch 142/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6480 - accuracy: 0.7473 - val_loss: 0.7647 - val_accuracy: 0.6812\n",
            "Epoch 143/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6608 - accuracy: 0.7437 - val_loss: 0.7315 - val_accuracy: 0.7053\n",
            "Epoch 144/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6516 - accuracy: 0.7388 - val_loss: 0.7467 - val_accuracy: 0.6957\n",
            "Epoch 145/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6448 - accuracy: 0.7388 - val_loss: 0.7731 - val_accuracy: 0.6763\n",
            "Epoch 146/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6454 - accuracy: 0.7515 - val_loss: 0.7598 - val_accuracy: 0.6957\n",
            "Epoch 147/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6442 - accuracy: 0.7582 - val_loss: 0.7319 - val_accuracy: 0.6957\n",
            "Epoch 148/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6478 - accuracy: 0.7437 - val_loss: 0.7536 - val_accuracy: 0.6957\n",
            "Epoch 149/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6381 - accuracy: 0.7545 - val_loss: 0.7475 - val_accuracy: 0.6957\n",
            "Epoch 150/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6384 - accuracy: 0.7509 - val_loss: 0.7306 - val_accuracy: 0.7101\n",
            "Epoch 151/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6351 - accuracy: 0.7527 - val_loss: 0.7983 - val_accuracy: 0.7053\n",
            "Epoch 152/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6381 - accuracy: 0.7533 - val_loss: 0.7497 - val_accuracy: 0.6957\n",
            "Epoch 153/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6287 - accuracy: 0.7503 - val_loss: 0.7856 - val_accuracy: 0.6812\n",
            "Epoch 154/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6322 - accuracy: 0.7594 - val_loss: 0.7241 - val_accuracy: 0.7053\n",
            "Epoch 155/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6151 - accuracy: 0.7642 - val_loss: 0.7328 - val_accuracy: 0.7005\n",
            "Epoch 156/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6164 - accuracy: 0.7594 - val_loss: 0.7716 - val_accuracy: 0.6957\n",
            "Epoch 157/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6167 - accuracy: 0.7509 - val_loss: 0.7043 - val_accuracy: 0.7198\n",
            "Epoch 158/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6028 - accuracy: 0.7624 - val_loss: 0.7403 - val_accuracy: 0.7053\n",
            "Epoch 159/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6125 - accuracy: 0.7696 - val_loss: 0.7417 - val_accuracy: 0.7488\n",
            "Epoch 160/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6033 - accuracy: 0.7563 - val_loss: 0.7299 - val_accuracy: 0.7005\n",
            "Epoch 161/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6156 - accuracy: 0.7563 - val_loss: 0.7227 - val_accuracy: 0.7391\n",
            "Epoch 162/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5787 - accuracy: 0.7709 - val_loss: 0.7735 - val_accuracy: 0.6715\n",
            "Epoch 163/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5987 - accuracy: 0.7654 - val_loss: 0.7151 - val_accuracy: 0.7198\n",
            "Epoch 164/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5792 - accuracy: 0.7672 - val_loss: 0.7657 - val_accuracy: 0.6763\n",
            "Epoch 165/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5810 - accuracy: 0.7751 - val_loss: 0.7336 - val_accuracy: 0.6908\n",
            "Epoch 166/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5869 - accuracy: 0.7739 - val_loss: 0.6983 - val_accuracy: 0.7101\n",
            "Epoch 167/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5743 - accuracy: 0.7799 - val_loss: 0.7212 - val_accuracy: 0.7295\n",
            "Epoch 168/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5804 - accuracy: 0.7763 - val_loss: 0.7388 - val_accuracy: 0.7101\n",
            "Epoch 169/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5703 - accuracy: 0.7872 - val_loss: 0.7302 - val_accuracy: 0.7585\n",
            "Epoch 170/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5622 - accuracy: 0.7854 - val_loss: 0.7462 - val_accuracy: 0.7295\n",
            "Epoch 171/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5778 - accuracy: 0.7890 - val_loss: 0.7430 - val_accuracy: 0.6957\n",
            "Epoch 172/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5692 - accuracy: 0.7739 - val_loss: 0.7113 - val_accuracy: 0.7585\n",
            "Epoch 173/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5627 - accuracy: 0.7757 - val_loss: 0.7512 - val_accuracy: 0.7053\n",
            "Epoch 174/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5157 - accuracy: 0.7963 - val_loss: 0.7169 - val_accuracy: 0.7295\n",
            "Epoch 175/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5565 - accuracy: 0.7823 - val_loss: 0.7281 - val_accuracy: 0.7150\n",
            "Epoch 176/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5573 - accuracy: 0.7860 - val_loss: 0.7355 - val_accuracy: 0.6957\n",
            "Epoch 177/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5353 - accuracy: 0.8005 - val_loss: 0.6988 - val_accuracy: 0.7536\n",
            "Epoch 178/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5438 - accuracy: 0.7932 - val_loss: 0.7053 - val_accuracy: 0.7101\n",
            "Epoch 179/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5361 - accuracy: 0.7854 - val_loss: 0.6980 - val_accuracy: 0.7246\n",
            "Epoch 180/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5351 - accuracy: 0.7956 - val_loss: 0.7356 - val_accuracy: 0.6812\n",
            "Epoch 181/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5560 - accuracy: 0.7896 - val_loss: 0.6933 - val_accuracy: 0.7101\n",
            "Epoch 182/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5298 - accuracy: 0.7938 - val_loss: 0.7009 - val_accuracy: 0.7198\n",
            "Epoch 183/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5349 - accuracy: 0.7950 - val_loss: 0.6918 - val_accuracy: 0.7198\n",
            "Epoch 184/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5151 - accuracy: 0.8071 - val_loss: 0.7176 - val_accuracy: 0.7101\n",
            "Epoch 185/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5279 - accuracy: 0.8047 - val_loss: 0.7227 - val_accuracy: 0.7150\n",
            "Epoch 186/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5233 - accuracy: 0.7908 - val_loss: 0.7222 - val_accuracy: 0.7053\n",
            "Epoch 187/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5324 - accuracy: 0.7890 - val_loss: 0.6838 - val_accuracy: 0.7295\n",
            "Epoch 188/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5100 - accuracy: 0.8017 - val_loss: 0.7357 - val_accuracy: 0.7198\n",
            "Epoch 189/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5058 - accuracy: 0.8035 - val_loss: 0.7226 - val_accuracy: 0.7198\n",
            "Epoch 190/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5139 - accuracy: 0.8023 - val_loss: 0.6722 - val_accuracy: 0.7246\n",
            "Epoch 191/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5068 - accuracy: 0.8077 - val_loss: 0.6804 - val_accuracy: 0.7246\n",
            "Epoch 192/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5136 - accuracy: 0.8041 - val_loss: 0.6947 - val_accuracy: 0.7585\n",
            "Epoch 193/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5135 - accuracy: 0.8120 - val_loss: 0.7522 - val_accuracy: 0.7150\n",
            "Epoch 194/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4978 - accuracy: 0.8017 - val_loss: 0.7353 - val_accuracy: 0.7198\n",
            "Epoch 195/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4947 - accuracy: 0.8126 - val_loss: 0.6552 - val_accuracy: 0.7391\n",
            "Epoch 196/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4823 - accuracy: 0.8229 - val_loss: 0.6943 - val_accuracy: 0.7246\n",
            "Epoch 197/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4840 - accuracy: 0.8186 - val_loss: 0.6954 - val_accuracy: 0.7246\n",
            "Epoch 198/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4892 - accuracy: 0.8114 - val_loss: 0.7263 - val_accuracy: 0.6667\n",
            "Epoch 199/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5298 - accuracy: 0.7963 - val_loss: 0.7236 - val_accuracy: 0.6908\n",
            "Epoch 200/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4732 - accuracy: 0.8156 - val_loss: 0.7209 - val_accuracy: 0.7198\n",
            "Epoch 201/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4901 - accuracy: 0.8168 - val_loss: 0.7239 - val_accuracy: 0.7343\n",
            "Epoch 202/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4803 - accuracy: 0.8126 - val_loss: 0.6923 - val_accuracy: 0.7826\n",
            "Epoch 203/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4823 - accuracy: 0.8174 - val_loss: 0.6722 - val_accuracy: 0.7391\n",
            "Epoch 204/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4796 - accuracy: 0.8077 - val_loss: 0.6575 - val_accuracy: 0.7536\n",
            "Epoch 205/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4703 - accuracy: 0.8156 - val_loss: 0.6977 - val_accuracy: 0.7246\n",
            "Epoch 206/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4694 - accuracy: 0.8204 - val_loss: 0.7045 - val_accuracy: 0.7198\n",
            "Epoch 207/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4801 - accuracy: 0.8186 - val_loss: 0.6747 - val_accuracy: 0.7101\n",
            "Epoch 208/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4816 - accuracy: 0.8089 - val_loss: 0.6554 - val_accuracy: 0.7343\n",
            "Epoch 209/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4673 - accuracy: 0.8162 - val_loss: 0.6589 - val_accuracy: 0.7585\n",
            "Epoch 210/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4631 - accuracy: 0.8235 - val_loss: 0.6774 - val_accuracy: 0.7440\n",
            "Epoch 211/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4695 - accuracy: 0.8295 - val_loss: 0.7151 - val_accuracy: 0.7343\n",
            "Epoch 212/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4582 - accuracy: 0.8059 - val_loss: 0.6795 - val_accuracy: 0.7246\n",
            "Epoch 213/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4584 - accuracy: 0.8204 - val_loss: 0.6536 - val_accuracy: 0.7585\n",
            "Epoch 214/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4356 - accuracy: 0.8325 - val_loss: 0.6484 - val_accuracy: 0.7778\n",
            "Epoch 215/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4435 - accuracy: 0.8374 - val_loss: 0.6433 - val_accuracy: 0.7440\n",
            "Epoch 216/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4612 - accuracy: 0.8283 - val_loss: 0.6441 - val_accuracy: 0.7391\n",
            "Epoch 217/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4435 - accuracy: 0.8368 - val_loss: 0.6514 - val_accuracy: 0.7198\n",
            "Epoch 218/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4445 - accuracy: 0.8337 - val_loss: 0.6504 - val_accuracy: 0.7488\n",
            "Epoch 219/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4191 - accuracy: 0.8416 - val_loss: 0.6846 - val_accuracy: 0.7343\n",
            "Epoch 220/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4413 - accuracy: 0.8198 - val_loss: 0.6420 - val_accuracy: 0.7681\n",
            "Epoch 221/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4424 - accuracy: 0.8428 - val_loss: 0.6402 - val_accuracy: 0.7440\n",
            "Epoch 222/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4294 - accuracy: 0.8277 - val_loss: 0.6999 - val_accuracy: 0.7198\n",
            "Epoch 223/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4451 - accuracy: 0.8368 - val_loss: 0.6966 - val_accuracy: 0.7053\n",
            "Epoch 224/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4130 - accuracy: 0.8416 - val_loss: 0.6331 - val_accuracy: 0.7874\n",
            "Epoch 225/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4225 - accuracy: 0.8386 - val_loss: 0.6596 - val_accuracy: 0.7440\n",
            "Epoch 226/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4379 - accuracy: 0.8446 - val_loss: 0.6540 - val_accuracy: 0.7440\n",
            "Epoch 227/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4152 - accuracy: 0.8386 - val_loss: 0.6463 - val_accuracy: 0.7488\n",
            "Epoch 228/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4219 - accuracy: 0.8422 - val_loss: 0.6739 - val_accuracy: 0.7198\n",
            "Epoch 229/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4309 - accuracy: 0.8374 - val_loss: 0.6760 - val_accuracy: 0.7101\n",
            "Epoch 230/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4136 - accuracy: 0.8458 - val_loss: 0.7504 - val_accuracy: 0.6908\n",
            "Epoch 231/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4409 - accuracy: 0.8374 - val_loss: 0.6884 - val_accuracy: 0.7440\n",
            "Epoch 232/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3875 - accuracy: 0.8591 - val_loss: 0.6436 - val_accuracy: 0.7729\n",
            "Epoch 233/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4218 - accuracy: 0.8428 - val_loss: 0.6623 - val_accuracy: 0.7198\n",
            "Epoch 234/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3892 - accuracy: 0.8519 - val_loss: 0.6273 - val_accuracy: 0.7681\n",
            "Epoch 235/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4204 - accuracy: 0.8392 - val_loss: 0.6816 - val_accuracy: 0.7343\n",
            "Epoch 236/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4043 - accuracy: 0.8422 - val_loss: 0.6704 - val_accuracy: 0.7729\n",
            "Epoch 237/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4277 - accuracy: 0.8331 - val_loss: 0.6371 - val_accuracy: 0.7246\n",
            "Epoch 238/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4166 - accuracy: 0.8392 - val_loss: 0.6713 - val_accuracy: 0.7729\n",
            "Epoch 239/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3907 - accuracy: 0.8482 - val_loss: 0.6884 - val_accuracy: 0.7343\n",
            "Epoch 240/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3848 - accuracy: 0.8434 - val_loss: 0.7010 - val_accuracy: 0.7150\n",
            "Epoch 241/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4082 - accuracy: 0.8495 - val_loss: 0.6186 - val_accuracy: 0.7778\n",
            "Epoch 242/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4139 - accuracy: 0.8428 - val_loss: 0.5975 - val_accuracy: 0.7729\n",
            "Epoch 243/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3798 - accuracy: 0.8549 - val_loss: 0.6225 - val_accuracy: 0.7488\n",
            "Epoch 244/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3775 - accuracy: 0.8537 - val_loss: 0.6347 - val_accuracy: 0.7343\n",
            "Epoch 245/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3919 - accuracy: 0.8658 - val_loss: 0.6421 - val_accuracy: 0.7295\n",
            "Epoch 246/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3779 - accuracy: 0.8585 - val_loss: 0.6465 - val_accuracy: 0.7343\n",
            "Epoch 247/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3872 - accuracy: 0.8549 - val_loss: 0.6767 - val_accuracy: 0.7633\n",
            "Epoch 248/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4253 - accuracy: 0.8386 - val_loss: 0.6582 - val_accuracy: 0.7536\n",
            "Epoch 249/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3826 - accuracy: 0.8507 - val_loss: 0.6568 - val_accuracy: 0.7343\n",
            "Epoch 250/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3878 - accuracy: 0.8555 - val_loss: 0.6360 - val_accuracy: 0.7343\n",
            "Epoch 251/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3742 - accuracy: 0.8585 - val_loss: 0.6995 - val_accuracy: 0.7295\n",
            "Epoch 252/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3758 - accuracy: 0.8519 - val_loss: 0.6697 - val_accuracy: 0.7198\n",
            "Epoch 253/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3601 - accuracy: 0.8634 - val_loss: 0.6090 - val_accuracy: 0.7729\n",
            "Epoch 254/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3602 - accuracy: 0.8567 - val_loss: 0.6256 - val_accuracy: 0.7440\n",
            "Epoch 255/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3794 - accuracy: 0.8513 - val_loss: 0.6365 - val_accuracy: 0.7343\n",
            "Epoch 256/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3668 - accuracy: 0.8652 - val_loss: 0.6280 - val_accuracy: 0.7536\n",
            "Epoch 257/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3711 - accuracy: 0.8561 - val_loss: 0.6123 - val_accuracy: 0.7681\n",
            "Epoch 258/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3696 - accuracy: 0.8543 - val_loss: 0.6241 - val_accuracy: 0.7681\n",
            "Epoch 259/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4022 - accuracy: 0.8567 - val_loss: 0.6244 - val_accuracy: 0.7778\n",
            "Epoch 260/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3517 - accuracy: 0.8646 - val_loss: 0.6386 - val_accuracy: 0.7585\n",
            "Epoch 261/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3467 - accuracy: 0.8676 - val_loss: 0.6529 - val_accuracy: 0.7391\n",
            "Epoch 262/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.3758 - accuracy: 0.8513 - val_loss: 0.6030 - val_accuracy: 0.7923\n",
            "Epoch 263/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3542 - accuracy: 0.8603 - val_loss: 0.6439 - val_accuracy: 0.7633\n",
            "Epoch 264/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.3531 - accuracy: 0.8652 - val_loss: 0.6183 - val_accuracy: 0.7440\n",
            "Epoch 265/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3597 - accuracy: 0.8603 - val_loss: 0.6589 - val_accuracy: 0.7729\n",
            "Epoch 266/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3543 - accuracy: 0.8628 - val_loss: 0.6302 - val_accuracy: 0.7343\n",
            "Epoch 267/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3698 - accuracy: 0.8658 - val_loss: 0.6103 - val_accuracy: 0.7633\n",
            "Epoch 268/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3353 - accuracy: 0.8730 - val_loss: 0.6431 - val_accuracy: 0.7585\n",
            "Epoch 269/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.3411 - accuracy: 0.8700 - val_loss: 0.6826 - val_accuracy: 0.7488\n",
            "Epoch 270/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3569 - accuracy: 0.8773 - val_loss: 0.5850 - val_accuracy: 0.8068\n",
            "Epoch 271/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3641 - accuracy: 0.8567 - val_loss: 0.6498 - val_accuracy: 0.7633\n",
            "Epoch 272/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3370 - accuracy: 0.8730 - val_loss: 0.6416 - val_accuracy: 0.7536\n",
            "Epoch 273/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3329 - accuracy: 0.8803 - val_loss: 0.6278 - val_accuracy: 0.7778\n",
            "Epoch 274/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.3279 - accuracy: 0.8676 - val_loss: 0.6317 - val_accuracy: 0.7488\n",
            "Epoch 275/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3128 - accuracy: 0.8785 - val_loss: 0.7354 - val_accuracy: 0.6908\n",
            "Epoch 276/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3137 - accuracy: 0.8900 - val_loss: 0.6247 - val_accuracy: 0.7536\n",
            "Epoch 277/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3442 - accuracy: 0.8706 - val_loss: 0.6728 - val_accuracy: 0.7681\n",
            "Epoch 278/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3695 - accuracy: 0.8609 - val_loss: 0.5483 - val_accuracy: 0.7971\n",
            "Epoch 279/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3370 - accuracy: 0.8742 - val_loss: 0.6202 - val_accuracy: 0.7681\n",
            "Epoch 280/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3467 - accuracy: 0.8682 - val_loss: 0.5756 - val_accuracy: 0.8116\n",
            "Epoch 281/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3191 - accuracy: 0.8730 - val_loss: 0.6115 - val_accuracy: 0.7585\n",
            "Epoch 282/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3307 - accuracy: 0.8700 - val_loss: 0.6290 - val_accuracy: 0.7778\n",
            "Epoch 283/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2937 - accuracy: 0.8875 - val_loss: 0.6928 - val_accuracy: 0.7198\n",
            "Epoch 284/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3145 - accuracy: 0.8809 - val_loss: 0.6103 - val_accuracy: 0.7778\n",
            "Epoch 285/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3283 - accuracy: 0.8827 - val_loss: 0.6085 - val_accuracy: 0.7633\n",
            "Epoch 286/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3333 - accuracy: 0.8712 - val_loss: 0.6554 - val_accuracy: 0.7826\n",
            "Epoch 287/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3288 - accuracy: 0.8869 - val_loss: 0.6407 - val_accuracy: 0.7633\n",
            "Epoch 288/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2965 - accuracy: 0.8948 - val_loss: 0.6179 - val_accuracy: 0.7778\n",
            "Epoch 289/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3106 - accuracy: 0.8863 - val_loss: 0.6422 - val_accuracy: 0.7778\n",
            "Epoch 290/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3269 - accuracy: 0.8742 - val_loss: 0.6349 - val_accuracy: 0.7488\n",
            "Epoch 291/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2942 - accuracy: 0.8857 - val_loss: 0.6179 - val_accuracy: 0.7391\n",
            "Epoch 292/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3058 - accuracy: 0.8869 - val_loss: 0.6147 - val_accuracy: 0.7633\n",
            "Epoch 293/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2991 - accuracy: 0.8972 - val_loss: 0.6506 - val_accuracy: 0.6957\n",
            "Epoch 294/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3144 - accuracy: 0.8869 - val_loss: 0.6048 - val_accuracy: 0.7536\n",
            "Epoch 295/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3206 - accuracy: 0.8827 - val_loss: 0.6652 - val_accuracy: 0.7343\n",
            "Epoch 296/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2832 - accuracy: 0.8875 - val_loss: 0.6686 - val_accuracy: 0.7343\n",
            "Epoch 297/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3038 - accuracy: 0.8881 - val_loss: 0.5956 - val_accuracy: 0.7633\n",
            "Epoch 298/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2943 - accuracy: 0.8972 - val_loss: 0.6270 - val_accuracy: 0.7391\n",
            "Epoch 299/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2810 - accuracy: 0.8906 - val_loss: 0.6665 - val_accuracy: 0.7536\n",
            "Epoch 300/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2753 - accuracy: 0.8954 - val_loss: 0.6252 - val_accuracy: 0.7488\n",
            "Epoch 301/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2885 - accuracy: 0.8863 - val_loss: 0.7075 - val_accuracy: 0.7585\n",
            "Epoch 302/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2885 - accuracy: 0.8960 - val_loss: 0.6175 - val_accuracy: 0.7536\n",
            "Epoch 303/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2948 - accuracy: 0.8797 - val_loss: 0.6913 - val_accuracy: 0.7343\n",
            "Epoch 304/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3127 - accuracy: 0.8875 - val_loss: 0.7011 - val_accuracy: 0.7536\n",
            "Epoch 305/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.3026 - accuracy: 0.8857 - val_loss: 0.6836 - val_accuracy: 0.7633\n",
            "Epoch 306/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3091 - accuracy: 0.8881 - val_loss: 0.6397 - val_accuracy: 0.7391\n",
            "Epoch 307/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2879 - accuracy: 0.9015 - val_loss: 0.5642 - val_accuracy: 0.8019\n",
            "Epoch 308/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2946 - accuracy: 0.8942 - val_loss: 0.6115 - val_accuracy: 0.7729\n",
            "Epoch 309/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2823 - accuracy: 0.8948 - val_loss: 0.6056 - val_accuracy: 0.7585\n",
            "Epoch 310/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2725 - accuracy: 0.9039 - val_loss: 0.6105 - val_accuracy: 0.7391\n",
            "Epoch 311/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2934 - accuracy: 0.8815 - val_loss: 0.6453 - val_accuracy: 0.7585\n",
            "Epoch 312/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2615 - accuracy: 0.9057 - val_loss: 0.6695 - val_accuracy: 0.7536\n",
            "Epoch 313/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2802 - accuracy: 0.8954 - val_loss: 0.5866 - val_accuracy: 0.7971\n",
            "Epoch 314/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2816 - accuracy: 0.8918 - val_loss: 0.6206 - val_accuracy: 0.7440\n",
            "Epoch 315/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2888 - accuracy: 0.8978 - val_loss: 0.6909 - val_accuracy: 0.7488\n",
            "Epoch 316/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2967 - accuracy: 0.8936 - val_loss: 0.5884 - val_accuracy: 0.7971\n",
            "Epoch 317/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2818 - accuracy: 0.8966 - val_loss: 0.6683 - val_accuracy: 0.7440\n",
            "Epoch 318/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2982 - accuracy: 0.8827 - val_loss: 0.5990 - val_accuracy: 0.7585\n",
            "Epoch 319/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2740 - accuracy: 0.8906 - val_loss: 0.6035 - val_accuracy: 0.7681\n",
            "Epoch 320/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2957 - accuracy: 0.8960 - val_loss: 0.6433 - val_accuracy: 0.7488\n",
            "Epoch 321/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2845 - accuracy: 0.8960 - val_loss: 0.6034 - val_accuracy: 0.7971\n",
            "Epoch 322/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2755 - accuracy: 0.9051 - val_loss: 0.5800 - val_accuracy: 0.8019\n",
            "Epoch 323/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2805 - accuracy: 0.8978 - val_loss: 0.6243 - val_accuracy: 0.7874\n",
            "Epoch 324/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2634 - accuracy: 0.8984 - val_loss: 0.6171 - val_accuracy: 0.7246\n",
            "Epoch 325/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2680 - accuracy: 0.9008 - val_loss: 0.6426 - val_accuracy: 0.7488\n",
            "Epoch 326/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2727 - accuracy: 0.8972 - val_loss: 0.6108 - val_accuracy: 0.8019\n",
            "Epoch 327/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2640 - accuracy: 0.9045 - val_loss: 0.5650 - val_accuracy: 0.7971\n",
            "Epoch 328/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2812 - accuracy: 0.9033 - val_loss: 0.6419 - val_accuracy: 0.7585\n",
            "Epoch 329/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2644 - accuracy: 0.9027 - val_loss: 0.6000 - val_accuracy: 0.7681\n",
            "Epoch 330/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2706 - accuracy: 0.9033 - val_loss: 0.5942 - val_accuracy: 0.7923\n",
            "Epoch 331/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2787 - accuracy: 0.8984 - val_loss: 0.6251 - val_accuracy: 0.7440\n",
            "Epoch 332/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2526 - accuracy: 0.8966 - val_loss: 0.6919 - val_accuracy: 0.7391\n",
            "Epoch 333/500\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.2729 - accuracy: 0.8912 - val_loss: 0.6235 - val_accuracy: 0.7874\n",
            "Epoch 334/500\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.2603 - accuracy: 0.9045 - val_loss: 0.6190 - val_accuracy: 0.7826\n",
            "Epoch 335/500\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.2450 - accuracy: 0.9069 - val_loss: 0.6433 - val_accuracy: 0.7488\n",
            "Epoch 336/500\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.2615 - accuracy: 0.8960 - val_loss: 0.6047 - val_accuracy: 0.7585\n",
            "Epoch 337/500\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.2427 - accuracy: 0.9099 - val_loss: 0.6101 - val_accuracy: 0.7729\n",
            "Epoch 338/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2469 - accuracy: 0.9045 - val_loss: 0.6237 - val_accuracy: 0.7681\n",
            "Epoch 339/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2370 - accuracy: 0.9129 - val_loss: 0.5952 - val_accuracy: 0.8068\n",
            "Epoch 340/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2524 - accuracy: 0.9039 - val_loss: 0.6382 - val_accuracy: 0.7150\n",
            "Epoch 341/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2354 - accuracy: 0.9166 - val_loss: 0.6712 - val_accuracy: 0.7633\n",
            "Epoch 342/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2358 - accuracy: 0.9154 - val_loss: 0.6908 - val_accuracy: 0.7343\n",
            "Epoch 343/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2483 - accuracy: 0.9141 - val_loss: 0.5950 - val_accuracy: 0.7971\n",
            "Epoch 344/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2479 - accuracy: 0.9099 - val_loss: 0.6068 - val_accuracy: 0.7778\n",
            "Epoch 345/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2243 - accuracy: 0.9274 - val_loss: 0.6011 - val_accuracy: 0.7923\n",
            "Epoch 346/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2440 - accuracy: 0.9069 - val_loss: 0.6275 - val_accuracy: 0.7826\n",
            "Epoch 347/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2641 - accuracy: 0.9051 - val_loss: 0.5792 - val_accuracy: 0.8019\n",
            "Epoch 348/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2430 - accuracy: 0.9057 - val_loss: 0.6552 - val_accuracy: 0.7488\n",
            "Epoch 349/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2338 - accuracy: 0.9081 - val_loss: 0.5561 - val_accuracy: 0.7681\n",
            "Epoch 350/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2542 - accuracy: 0.9105 - val_loss: 0.5817 - val_accuracy: 0.7971\n",
            "Epoch 351/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2252 - accuracy: 0.9202 - val_loss: 0.6309 - val_accuracy: 0.7826\n",
            "Epoch 352/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2075 - accuracy: 0.9220 - val_loss: 0.6449 - val_accuracy: 0.7633\n",
            "Epoch 353/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2472 - accuracy: 0.9148 - val_loss: 0.6478 - val_accuracy: 0.7729\n",
            "Epoch 354/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2288 - accuracy: 0.9184 - val_loss: 0.7101 - val_accuracy: 0.8213\n",
            "Epoch 355/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2444 - accuracy: 0.9172 - val_loss: 0.6805 - val_accuracy: 0.7391\n",
            "Epoch 356/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2270 - accuracy: 0.9172 - val_loss: 0.7149 - val_accuracy: 0.7488\n",
            "Epoch 357/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2548 - accuracy: 0.9021 - val_loss: 0.6041 - val_accuracy: 0.7729\n",
            "Epoch 358/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2164 - accuracy: 0.9232 - val_loss: 0.6321 - val_accuracy: 0.7778\n",
            "Epoch 359/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2367 - accuracy: 0.9184 - val_loss: 0.6589 - val_accuracy: 0.7343\n",
            "Epoch 360/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2169 - accuracy: 0.9268 - val_loss: 0.6598 - val_accuracy: 0.7246\n",
            "Epoch 361/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2230 - accuracy: 0.9220 - val_loss: 0.6447 - val_accuracy: 0.7778\n",
            "Epoch 362/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2405 - accuracy: 0.9117 - val_loss: 0.6339 - val_accuracy: 0.7536\n",
            "Epoch 363/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2559 - accuracy: 0.9075 - val_loss: 0.5887 - val_accuracy: 0.7874\n",
            "Epoch 364/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2495 - accuracy: 0.9160 - val_loss: 0.5947 - val_accuracy: 0.7874\n",
            "Epoch 365/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2249 - accuracy: 0.9202 - val_loss: 0.6053 - val_accuracy: 0.7681\n",
            "Epoch 366/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2105 - accuracy: 0.9244 - val_loss: 0.6593 - val_accuracy: 0.7681\n",
            "Epoch 367/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2266 - accuracy: 0.9154 - val_loss: 0.6481 - val_accuracy: 0.8019\n",
            "Epoch 368/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2132 - accuracy: 0.9268 - val_loss: 0.6175 - val_accuracy: 0.7874\n",
            "Epoch 369/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2401 - accuracy: 0.9202 - val_loss: 0.6223 - val_accuracy: 0.8116\n",
            "Epoch 370/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2435 - accuracy: 0.9117 - val_loss: 0.6771 - val_accuracy: 0.7729\n",
            "Epoch 371/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2283 - accuracy: 0.9196 - val_loss: 0.6221 - val_accuracy: 0.7923\n",
            "Epoch 372/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2222 - accuracy: 0.9166 - val_loss: 0.6319 - val_accuracy: 0.7536\n",
            "Epoch 373/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2090 - accuracy: 0.9202 - val_loss: 0.7138 - val_accuracy: 0.7729\n",
            "Epoch 374/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2151 - accuracy: 0.9166 - val_loss: 0.6277 - val_accuracy: 0.8019\n",
            "Epoch 375/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2245 - accuracy: 0.9190 - val_loss: 0.7432 - val_accuracy: 0.7391\n",
            "Epoch 376/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2254 - accuracy: 0.9166 - val_loss: 0.6797 - val_accuracy: 0.7633\n",
            "Epoch 377/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2195 - accuracy: 0.9166 - val_loss: 0.6729 - val_accuracy: 0.8116\n",
            "Epoch 378/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2113 - accuracy: 0.9196 - val_loss: 0.6429 - val_accuracy: 0.7585\n",
            "Epoch 379/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2112 - accuracy: 0.9226 - val_loss: 0.6227 - val_accuracy: 0.7778\n",
            "Epoch 380/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2091 - accuracy: 0.9274 - val_loss: 0.6064 - val_accuracy: 0.8068\n",
            "Epoch 381/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2151 - accuracy: 0.9238 - val_loss: 0.6237 - val_accuracy: 0.7826\n",
            "Epoch 382/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2179 - accuracy: 0.9178 - val_loss: 0.6609 - val_accuracy: 0.7778\n",
            "Epoch 383/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2245 - accuracy: 0.9250 - val_loss: 0.7148 - val_accuracy: 0.7681\n",
            "Epoch 384/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2191 - accuracy: 0.9226 - val_loss: 0.6722 - val_accuracy: 0.7633\n",
            "Epoch 385/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2186 - accuracy: 0.9214 - val_loss: 0.5756 - val_accuracy: 0.7826\n",
            "Epoch 386/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2110 - accuracy: 0.9190 - val_loss: 0.5918 - val_accuracy: 0.8019\n",
            "Epoch 387/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2307 - accuracy: 0.9226 - val_loss: 0.5579 - val_accuracy: 0.8213\n",
            "Epoch 388/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2289 - accuracy: 0.9160 - val_loss: 0.6721 - val_accuracy: 0.7585\n",
            "Epoch 389/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2253 - accuracy: 0.9262 - val_loss: 0.6831 - val_accuracy: 0.7729\n",
            "Epoch 390/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2083 - accuracy: 0.9268 - val_loss: 0.6068 - val_accuracy: 0.7971\n",
            "Epoch 391/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2324 - accuracy: 0.9190 - val_loss: 0.5638 - val_accuracy: 0.8068\n",
            "Epoch 392/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2210 - accuracy: 0.9220 - val_loss: 0.6810 - val_accuracy: 0.7923\n",
            "Epoch 393/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1842 - accuracy: 0.9299 - val_loss: 0.6809 - val_accuracy: 0.7729\n",
            "Epoch 394/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2215 - accuracy: 0.9190 - val_loss: 0.6393 - val_accuracy: 0.7536\n",
            "Epoch 395/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2000 - accuracy: 0.9232 - val_loss: 0.5759 - val_accuracy: 0.8213\n",
            "Epoch 396/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2057 - accuracy: 0.9353 - val_loss: 0.5769 - val_accuracy: 0.8068\n",
            "Epoch 397/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2042 - accuracy: 0.9299 - val_loss: 0.6305 - val_accuracy: 0.8068\n",
            "Epoch 398/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2313 - accuracy: 0.9244 - val_loss: 0.6295 - val_accuracy: 0.7681\n",
            "Epoch 399/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1937 - accuracy: 0.9341 - val_loss: 0.6555 - val_accuracy: 0.7971\n",
            "Epoch 400/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1945 - accuracy: 0.9311 - val_loss: 0.5761 - val_accuracy: 0.8019\n",
            "Epoch 401/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2103 - accuracy: 0.9287 - val_loss: 0.6613 - val_accuracy: 0.7729\n",
            "Epoch 402/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2270 - accuracy: 0.9232 - val_loss: 0.5769 - val_accuracy: 0.8068\n",
            "Epoch 403/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2018 - accuracy: 0.9220 - val_loss: 0.6618 - val_accuracy: 0.7971\n",
            "Epoch 404/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1989 - accuracy: 0.9250 - val_loss: 0.6787 - val_accuracy: 0.7826\n",
            "Epoch 405/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2115 - accuracy: 0.9190 - val_loss: 0.6785 - val_accuracy: 0.7923\n",
            "Epoch 406/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1923 - accuracy: 0.9281 - val_loss: 0.6972 - val_accuracy: 0.7923\n",
            "Epoch 407/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2059 - accuracy: 0.9311 - val_loss: 0.7196 - val_accuracy: 0.7440\n",
            "Epoch 408/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2117 - accuracy: 0.9220 - val_loss: 0.7349 - val_accuracy: 0.8068\n",
            "Epoch 409/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1902 - accuracy: 0.9353 - val_loss: 0.6483 - val_accuracy: 0.7729\n",
            "Epoch 410/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1768 - accuracy: 0.9389 - val_loss: 0.6232 - val_accuracy: 0.7874\n",
            "Epoch 411/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1616 - accuracy: 0.9456 - val_loss: 0.7247 - val_accuracy: 0.8019\n",
            "Epoch 412/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1839 - accuracy: 0.9347 - val_loss: 0.5921 - val_accuracy: 0.7874\n",
            "Epoch 413/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1883 - accuracy: 0.9371 - val_loss: 0.6081 - val_accuracy: 0.8068\n",
            "Epoch 414/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1878 - accuracy: 0.9329 - val_loss: 0.6525 - val_accuracy: 0.7971\n",
            "Epoch 415/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1795 - accuracy: 0.9377 - val_loss: 0.6353 - val_accuracy: 0.8164\n",
            "Epoch 416/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2081 - accuracy: 0.9226 - val_loss: 0.6745 - val_accuracy: 0.7681\n",
            "Epoch 417/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2060 - accuracy: 0.9232 - val_loss: 0.7009 - val_accuracy: 0.7681\n",
            "Epoch 418/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2013 - accuracy: 0.9256 - val_loss: 0.6769 - val_accuracy: 0.8019\n",
            "Epoch 419/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2193 - accuracy: 0.9226 - val_loss: 0.6372 - val_accuracy: 0.7729\n",
            "Epoch 420/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1937 - accuracy: 0.9323 - val_loss: 0.6523 - val_accuracy: 0.7971\n",
            "Epoch 421/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1926 - accuracy: 0.9281 - val_loss: 0.6801 - val_accuracy: 0.8019\n",
            "Epoch 422/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2017 - accuracy: 0.9329 - val_loss: 0.6968 - val_accuracy: 0.7585\n",
            "Epoch 423/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1881 - accuracy: 0.9317 - val_loss: 0.6367 - val_accuracy: 0.7826\n",
            "Epoch 424/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1950 - accuracy: 0.9238 - val_loss: 0.6341 - val_accuracy: 0.7778\n",
            "Epoch 425/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1594 - accuracy: 0.9420 - val_loss: 0.6769 - val_accuracy: 0.7343\n",
            "Epoch 426/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1837 - accuracy: 0.9359 - val_loss: 0.6107 - val_accuracy: 0.8019\n",
            "Epoch 427/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1984 - accuracy: 0.9238 - val_loss: 0.6891 - val_accuracy: 0.7681\n",
            "Epoch 428/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1964 - accuracy: 0.9347 - val_loss: 0.6258 - val_accuracy: 0.8261\n",
            "Epoch 429/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1679 - accuracy: 0.9371 - val_loss: 0.7115 - val_accuracy: 0.8213\n",
            "Epoch 430/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1796 - accuracy: 0.9407 - val_loss: 0.5734 - val_accuracy: 0.7971\n",
            "Epoch 431/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1890 - accuracy: 0.9353 - val_loss: 0.6878 - val_accuracy: 0.8116\n",
            "Epoch 432/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1992 - accuracy: 0.9250 - val_loss: 0.6527 - val_accuracy: 0.7536\n",
            "Epoch 433/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1928 - accuracy: 0.9359 - val_loss: 0.6674 - val_accuracy: 0.7874\n",
            "Epoch 434/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1756 - accuracy: 0.9377 - val_loss: 0.7496 - val_accuracy: 0.7874\n",
            "Epoch 435/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1673 - accuracy: 0.9414 - val_loss: 0.6769 - val_accuracy: 0.7729\n",
            "Epoch 436/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1690 - accuracy: 0.9389 - val_loss: 0.6048 - val_accuracy: 0.8068\n",
            "Epoch 437/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1913 - accuracy: 0.9365 - val_loss: 0.6775 - val_accuracy: 0.7826\n",
            "Epoch 438/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1755 - accuracy: 0.9317 - val_loss: 0.7079 - val_accuracy: 0.7633\n",
            "Epoch 439/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1796 - accuracy: 0.9401 - val_loss: 0.6555 - val_accuracy: 0.8164\n",
            "Epoch 440/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1870 - accuracy: 0.9341 - val_loss: 0.6435 - val_accuracy: 0.8019\n",
            "Epoch 441/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1948 - accuracy: 0.9389 - val_loss: 0.6447 - val_accuracy: 0.8261\n",
            "Epoch 442/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1537 - accuracy: 0.9426 - val_loss: 0.6349 - val_accuracy: 0.8164\n",
            "Epoch 443/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1703 - accuracy: 0.9335 - val_loss: 0.6858 - val_accuracy: 0.7923\n",
            "Epoch 444/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1840 - accuracy: 0.9371 - val_loss: 0.7357 - val_accuracy: 0.7874\n",
            "Epoch 445/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1550 - accuracy: 0.9474 - val_loss: 0.7072 - val_accuracy: 0.7681\n",
            "Epoch 446/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2100 - accuracy: 0.9274 - val_loss: 0.7256 - val_accuracy: 0.7585\n",
            "Epoch 447/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1825 - accuracy: 0.9305 - val_loss: 0.6731 - val_accuracy: 0.7874\n",
            "Epoch 448/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2050 - accuracy: 0.9365 - val_loss: 0.6867 - val_accuracy: 0.8164\n",
            "Epoch 449/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1724 - accuracy: 0.9420 - val_loss: 0.6754 - val_accuracy: 0.7923\n",
            "Epoch 450/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1845 - accuracy: 0.9377 - val_loss: 0.6828 - val_accuracy: 0.7874\n",
            "Epoch 451/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1822 - accuracy: 0.9347 - val_loss: 0.6929 - val_accuracy: 0.7923\n",
            "Epoch 452/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1726 - accuracy: 0.9359 - val_loss: 0.5891 - val_accuracy: 0.8068\n",
            "Epoch 453/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1566 - accuracy: 0.9407 - val_loss: 0.7166 - val_accuracy: 0.7923\n",
            "Epoch 454/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1717 - accuracy: 0.9395 - val_loss: 0.5975 - val_accuracy: 0.7971\n",
            "Epoch 455/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1525 - accuracy: 0.9438 - val_loss: 0.6809 - val_accuracy: 0.8019\n",
            "Epoch 456/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1501 - accuracy: 0.9522 - val_loss: 0.7069 - val_accuracy: 0.7923\n",
            "Epoch 457/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1610 - accuracy: 0.9407 - val_loss: 0.6949 - val_accuracy: 0.7681\n",
            "Epoch 458/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1878 - accuracy: 0.9371 - val_loss: 0.7409 - val_accuracy: 0.8116\n",
            "Epoch 459/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1805 - accuracy: 0.9407 - val_loss: 0.6314 - val_accuracy: 0.7874\n",
            "Epoch 460/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1646 - accuracy: 0.9480 - val_loss: 0.6677 - val_accuracy: 0.7778\n",
            "Epoch 461/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1720 - accuracy: 0.9359 - val_loss: 0.5806 - val_accuracy: 0.7874\n",
            "Epoch 462/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1951 - accuracy: 0.9359 - val_loss: 0.6353 - val_accuracy: 0.7874\n",
            "Epoch 463/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1914 - accuracy: 0.9359 - val_loss: 0.7395 - val_accuracy: 0.7971\n",
            "Epoch 464/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1506 - accuracy: 0.9474 - val_loss: 0.6405 - val_accuracy: 0.7633\n",
            "Epoch 465/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1383 - accuracy: 0.9522 - val_loss: 0.6799 - val_accuracy: 0.8164\n",
            "Epoch 466/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1672 - accuracy: 0.9395 - val_loss: 0.6070 - val_accuracy: 0.8213\n",
            "Epoch 467/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1523 - accuracy: 0.9450 - val_loss: 0.6014 - val_accuracy: 0.7826\n",
            "Epoch 468/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1840 - accuracy: 0.9347 - val_loss: 0.6725 - val_accuracy: 0.8213\n",
            "Epoch 469/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1706 - accuracy: 0.9395 - val_loss: 0.6569 - val_accuracy: 0.8213\n",
            "Epoch 470/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1801 - accuracy: 0.9365 - val_loss: 0.6717 - val_accuracy: 0.7971\n",
            "Epoch 471/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1637 - accuracy: 0.9414 - val_loss: 0.6097 - val_accuracy: 0.7874\n",
            "Epoch 472/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2011 - accuracy: 0.9305 - val_loss: 0.7091 - val_accuracy: 0.7440\n",
            "Epoch 473/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1677 - accuracy: 0.9414 - val_loss: 0.7260 - val_accuracy: 0.7971\n",
            "Epoch 474/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1593 - accuracy: 0.9480 - val_loss: 0.6551 - val_accuracy: 0.7923\n",
            "Epoch 475/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1449 - accuracy: 0.9498 - val_loss: 0.6791 - val_accuracy: 0.8213\n",
            "Epoch 476/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1631 - accuracy: 0.9420 - val_loss: 0.7382 - val_accuracy: 0.7971\n",
            "Epoch 477/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1751 - accuracy: 0.9456 - val_loss: 0.6834 - val_accuracy: 0.8019\n",
            "Epoch 478/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1562 - accuracy: 0.9407 - val_loss: 0.6744 - val_accuracy: 0.7971\n",
            "Epoch 479/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1649 - accuracy: 0.9389 - val_loss: 0.6646 - val_accuracy: 0.8019\n",
            "Epoch 480/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1401 - accuracy: 0.9534 - val_loss: 0.6933 - val_accuracy: 0.7923\n",
            "Epoch 481/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1555 - accuracy: 0.9468 - val_loss: 0.8419 - val_accuracy: 0.7440\n",
            "Epoch 482/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1743 - accuracy: 0.9341 - val_loss: 0.6472 - val_accuracy: 0.7729\n",
            "Epoch 483/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1336 - accuracy: 0.9462 - val_loss: 0.6622 - val_accuracy: 0.8213\n",
            "Epoch 484/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1633 - accuracy: 0.9395 - val_loss: 0.7102 - val_accuracy: 0.7826\n",
            "Epoch 485/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1480 - accuracy: 0.9522 - val_loss: 0.7538 - val_accuracy: 0.7729\n",
            "Epoch 486/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1650 - accuracy: 0.9450 - val_loss: 0.6999 - val_accuracy: 0.7778\n",
            "Epoch 487/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1585 - accuracy: 0.9450 - val_loss: 0.6667 - val_accuracy: 0.8068\n",
            "Epoch 488/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1595 - accuracy: 0.9492 - val_loss: 0.6667 - val_accuracy: 0.8019\n",
            "Epoch 489/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1854 - accuracy: 0.9414 - val_loss: 0.6964 - val_accuracy: 0.7971\n",
            "Epoch 490/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1727 - accuracy: 0.9432 - val_loss: 0.7532 - val_accuracy: 0.7971\n",
            "Epoch 491/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1357 - accuracy: 0.9516 - val_loss: 0.6181 - val_accuracy: 0.7923\n",
            "Epoch 492/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1359 - accuracy: 0.9541 - val_loss: 0.7167 - val_accuracy: 0.7923\n",
            "Epoch 493/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1563 - accuracy: 0.9498 - val_loss: 0.7012 - val_accuracy: 0.7778\n",
            "Epoch 494/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1418 - accuracy: 0.9553 - val_loss: 0.6900 - val_accuracy: 0.8116\n",
            "Epoch 495/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1416 - accuracy: 0.9510 - val_loss: 0.6951 - val_accuracy: 0.8019\n",
            "Epoch 496/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1633 - accuracy: 0.9432 - val_loss: 0.7732 - val_accuracy: 0.7874\n",
            "Epoch 497/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1382 - accuracy: 0.9534 - val_loss: 0.7336 - val_accuracy: 0.7923\n",
            "Epoch 498/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1634 - accuracy: 0.9420 - val_loss: 0.7627 - val_accuracy: 0.7971\n",
            "Epoch 499/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1552 - accuracy: 0.9504 - val_loss: 0.6633 - val_accuracy: 0.7874\n",
            "Epoch 500/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1467 - accuracy: 0.9498 - val_loss: 0.6017 - val_accuracy: 0.8019\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(cnnhistory.history['loss'])\n",
        "plt.plot(cnnhistory.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train','test'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "oQYnuaCrDH_A",
        "outputId": "a2edd442-c49a-414d-e895-72280dc1ac55"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(cnnhistory.history['accuracy'])\n",
        "plt.plot(cnnhistory.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train','test'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "IFkTuO8nDNdq",
        "outputId": "4bacd41e-06ef-4b66-d3f3-d22cb24b8f2b"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#predictions = model.predict_classes(x_testcnn)\n",
        "predictions = model.predict(x_testcnn)"
      ],
      "metadata": {
        "id": "A2xtrN5wDQgY"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_f_ohjXKDUpY",
        "outputId": "da54e755-fee4-4902-df47-34a92468983e"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[3.3817546e-11, 5.1348304e-11, 4.7857538e-01, 1.0136532e-05,\n",
              "        2.2799730e-02, 4.9861470e-01],\n",
              "       [1.7718390e-03, 9.9745017e-01, 2.8948483e-04, 4.4951716e-04,\n",
              "        1.5099467e-05, 2.3896875e-05],\n",
              "       [3.7354599e-08, 9.2374121e-06, 9.9841058e-01, 6.5917178e-09,\n",
              "        2.0756219e-04, 1.3725265e-03],\n",
              "       ...,\n",
              "       [2.7437417e-09, 3.0467051e-09, 5.2380060e-06, 3.8137700e-06,\n",
              "        9.9901640e-01, 9.7454188e-04],\n",
              "       [1.3136150e-03, 3.2729164e-04, 1.3697044e-03, 6.1544043e-01,\n",
              "        3.8233009e-04, 3.8116670e-01],\n",
              "       [1.2701667e-02, 3.1856536e-03, 1.2398501e-04, 5.3936638e-02,\n",
              "        9.3004954e-01, 2.5483682e-06]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cmA2bFgsDW3D",
        "outputId": "37429980-db6f-4b57-bc06-30d0f7ccd9f0"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5, 1, 2, 5, 3, 4, 2, 0, 3, 1, 3, 2, 1, 4, 3, 0, 5, 0, 2, 5, 0, 0,\n",
              "       1, 3, 2, 3, 2, 5, 4, 2, 2, 3, 1, 2, 5, 5, 3, 5, 3, 3, 4, 1, 3, 2,\n",
              "       3, 1, 5, 3, 1, 2, 4, 4, 5, 5, 5, 1, 2, 3, 2, 5, 0, 2, 4, 2, 5, 4,\n",
              "       3, 0, 1, 2, 5, 2, 1, 2, 4, 5, 4, 1, 5, 5, 3, 1, 5, 3, 2, 4, 2, 5,\n",
              "       0, 5, 0, 5, 4, 0, 2, 4, 0, 2, 2, 0, 2, 3, 5, 3, 5, 5, 3, 1, 2, 2,\n",
              "       2, 1, 3, 2, 1, 3, 4, 4, 1, 1, 2, 4, 4, 1, 4, 2, 0, 4, 5, 5, 3, 1,\n",
              "       2, 1, 5, 5, 1, 2, 3, 3, 0, 3, 3, 0, 1, 0, 1, 2, 1, 5, 1, 2, 2, 0,\n",
              "       1, 1, 1, 1, 1, 4, 0, 1, 5, 1, 4, 5, 5, 4, 1, 0, 3, 5, 2, 3, 0, 4,\n",
              "       1, 3, 1, 0, 5, 5, 3, 5, 4, 5, 4, 0, 4, 1, 2, 1, 5, 0, 4, 3, 2, 1,\n",
              "       0, 3, 5, 0, 4, 5, 4, 5, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_Ytest = y_test.astype(int)"
      ],
      "metadata": {
        "id": "0PHDKWJWDY3g"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_Ytest"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k68v2i-pDbZE",
        "outputId": "eb2e3e26-361e-4ce1-be56-32f6bae1bd5c"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5, 1, 2, 5, 3, 4, 2, 0, 3, 1, 3, 2, 1, 4, 3, 0, 5, 0, 2, 5, 0, 0,\n",
              "       1, 3, 2, 3, 2, 5, 4, 2, 2, 3, 1, 2, 5, 5, 3, 5, 3, 3, 4, 1, 3, 2,\n",
              "       3, 1, 5, 3, 1, 2, 4, 4, 5, 5, 5, 1, 2, 3, 2, 5, 0, 2, 4, 2, 5, 4,\n",
              "       3, 0, 1, 2, 5, 2, 1, 2, 4, 5, 4, 1, 5, 5, 3, 1, 5, 3, 2, 4, 2, 5,\n",
              "       0, 5, 0, 5, 4, 0, 2, 4, 0, 2, 2, 0, 2, 3, 5, 3, 5, 5, 3, 1, 2, 2,\n",
              "       2, 1, 3, 2, 1, 3, 4, 4, 1, 1, 2, 4, 4, 1, 4, 2, 0, 4, 5, 5, 3, 1,\n",
              "       2, 1, 5, 5, 1, 2, 3, 3, 0, 3, 3, 0, 1, 0, 1, 2, 1, 5, 1, 2, 2, 0,\n",
              "       1, 1, 1, 1, 1, 4, 0, 1, 5, 1, 4, 5, 5, 4, 1, 0, 3, 5, 2, 3, 0, 4,\n",
              "       1, 3, 1, 0, 5, 5, 3, 5, 4, 5, 4, 0, 4, 1, 2, 1, 5, 0, 4, 3, 2, 1,\n",
              "       0, 3, 5, 0, 4, 5, 4, 5, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds1=predictions.argmax(axis=1)\n",
        "preds1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4_cAI39VFhtp",
        "outputId": "03300e57-f16f-45bd-aee0-12d1e44b05b6"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5, 1, 2, 5, 1, 4, 2, 0, 3, 0, 3, 2, 1, 4, 3, 0, 5, 3, 2, 5, 2, 0,\n",
              "       1, 3, 2, 5, 2, 5, 2, 2, 2, 5, 1, 2, 5, 5, 1, 5, 3, 3, 4, 1, 2, 2,\n",
              "       4, 0, 5, 3, 1, 2, 4, 4, 5, 2, 4, 1, 2, 3, 2, 5, 0, 2, 4, 2, 5, 4,\n",
              "       3, 1, 1, 2, 5, 2, 1, 2, 4, 3, 4, 1, 5, 2, 3, 2, 5, 3, 2, 4, 2, 3,\n",
              "       0, 2, 0, 3, 4, 0, 3, 4, 3, 4, 2, 3, 2, 0, 5, 3, 5, 2, 5, 1, 2, 2,\n",
              "       2, 1, 3, 2, 1, 3, 4, 4, 1, 1, 2, 4, 4, 1, 4, 2, 2, 4, 4, 5, 5, 1,\n",
              "       4, 1, 2, 5, 1, 3, 3, 3, 0, 3, 5, 0, 1, 0, 1, 2, 1, 5, 1, 2, 2, 0,\n",
              "       1, 1, 1, 1, 2, 4, 0, 1, 5, 1, 4, 5, 5, 2, 1, 0, 5, 1, 2, 2, 1, 4,\n",
              "       1, 3, 1, 0, 5, 2, 3, 5, 4, 5, 0, 0, 0, 1, 2, 1, 2, 0, 4, 1, 2, 0,\n",
              "       1, 5, 5, 3, 4, 5, 4, 3, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "abc = preds1.astype(int).flatten()"
      ],
      "metadata": {
        "id": "H4WEmM60NfQn"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "c = confusion_matrix(new_Ytest, abc) \n",
        "c"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bKEBeEBlFjB8",
        "outputId": "05fa68b1-1f21-4a48-a444-aac2887a2a1c"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[16,  3,  2,  4,  0,  0],\n",
              "       [ 3, 34,  2,  0,  0,  0],\n",
              "       [ 0,  0, 34,  2,  2,  0],\n",
              "       [ 1,  3,  2, 19,  1,  7],\n",
              "       [ 2,  0,  2,  0, 26,  0],\n",
              "       [ 0,  1,  7,  4,  2, 28]])"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m4RjG7LWLSQx",
        "outputId": "4edec865-2a4c-47c9-f95b-c804d2419ae6"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5, 1, 2, 5, 3, 4, 2, 0, 3, 1, 3, 2, 1, 4, 3, 0, 5, 0, 2, 5, 0, 0,\n",
              "       1, 3, 2, 3, 2, 5, 4, 2, 2, 3, 1, 2, 5, 5, 3, 5, 3, 3, 4, 1, 3, 2,\n",
              "       3, 1, 5, 3, 1, 2, 4, 4, 5, 5, 5, 1, 2, 3, 2, 5, 0, 2, 4, 2, 5, 4,\n",
              "       3, 0, 1, 2, 5, 2, 1, 2, 4, 5, 4, 1, 5, 5, 3, 1, 5, 3, 2, 4, 2, 5,\n",
              "       0, 5, 0, 5, 4, 0, 2, 4, 0, 2, 2, 0, 2, 3, 5, 3, 5, 5, 3, 1, 2, 2,\n",
              "       2, 1, 3, 2, 1, 3, 4, 4, 1, 1, 2, 4, 4, 1, 4, 2, 0, 4, 5, 5, 3, 1,\n",
              "       2, 1, 5, 5, 1, 2, 3, 3, 0, 3, 3, 0, 1, 0, 1, 2, 1, 5, 1, 2, 2, 0,\n",
              "       1, 1, 1, 1, 1, 4, 0, 1, 5, 1, 4, 5, 5, 4, 1, 0, 3, 5, 2, 3, 0, 4,\n",
              "       1, 3, 1, 0, 5, 5, 3, 5, 4, 5, 4, 0, 4, 1, 2, 1, 5, 0, 4, 3, 2, 1,\n",
              "       0, 3, 5, 0, 4, 5, 4, 5, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('/content/drive/My Drive/graduation project/audio/paper_code/mariam/original_500 epoch_with_valid_Adam2_3')\n",
        "print(\"MODEL SAVED\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lsJBNeMWDl6Z",
        "outputId": "fdf913e8-556c-4e26-bcf4-1d47e58f4768"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/graduation project/audio/paper_code/mariam/original_500 epoch_with_valid_Adam2_3/assets\n",
            "MODEL SAVED\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_model=keras.models.load_model('/content/drive/My Drive/graduation project/audio/paper_code/mariam/original_500 epoch_with_valid_Adam2_3')\n",
        "new_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q3KjaO9GDoNl",
        "outputId": "4284d4e7-5f6f-42ec-dd98-4b1a6e029eef"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d (Conv1D)             (None, 40, 128)           1152      \n",
            "                                                                 \n",
            " activation (Activation)     (None, 40, 128)           0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 40, 128)           0         \n",
            "                                                                 \n",
            " max_pooling1d (MaxPooling1D  (None, 8, 128)           0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv1d_1 (Conv1D)           (None, 8, 256)            262400    \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 8, 256)            0         \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 8, 256)            0         \n",
            "                                                                 \n",
            " max_pooling1d_1 (MaxPooling  (None, 1, 256)           0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 256)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 256)               65792     \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 256)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 256)               65792     \n",
            "                                                                 \n",
            " activation_3 (Activation)   (None, 256)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 6)                 1542      \n",
            "                                                                 \n",
            " activation_4 (Activation)   (None, 6)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 396,678\n",
            "Trainable params: 396,678\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss, acc =model.evaluate(x_testcnn, y_test)\n",
        "print(\"Restored model, accuracy: {:5.2f}%\".format(100*acc))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n3kzoqPkDqqS",
        "outputId": "c14c62ac-eb91-47a3-c480-c2408aa95c9e"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7/7 [==============================] - 0s 3ms/step - loss: 0.7311 - accuracy: 0.7585\n",
            "Restored model, accuracy: 75.85%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss, acc =model.evaluate(X_train, y_train)\n",
        "print(\"Restored model train, accuracy: {:5.2f}%\".format(100*acc))"
      ],
      "metadata": {
        "id": "fJDTGH_OUX0z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3dce739-1278-474c-d220-69e56c7642c5"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "52/52 [==============================] - 0s 4ms/step - loss: 0.0597 - accuracy: 0.9921\n",
            "Restored model train, accuracy: 99.21%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix,accuracy_score\n",
        "import seaborn as sn\n",
        "\n",
        "print(classification_report(new_Ytest,abc))\n",
        "\n",
        "acc = float(accuracy_score(new_Ytest,abc))*100\n",
        "print(\"----accuracy score %s ----\" % acc)\n",
        "\n",
        "cm = confusion_matrix(new_Ytest,abc)\n",
        "#df_cm = pd.DataFrame(cm)\n",
        "class_names = ['neutral','calm', 'happy','sad','angry', 'fearful' ]\n",
        "df_cm = pd.DataFrame(cm, index=class_names, columns=class_names,)\n",
        "sn.heatmap(df_cm, annot=True, fmt='')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 517
        },
        "id": "SfSC3El94LZg",
        "outputId": "fbe56d33-e133-44c9-9937-9b66cb9888be"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.73      0.64      0.68        25\n",
            "           1       0.83      0.87      0.85        39\n",
            "           2       0.69      0.89      0.78        38\n",
            "           3       0.66      0.58      0.61        33\n",
            "           4       0.84      0.87      0.85        30\n",
            "           5       0.80      0.67      0.73        42\n",
            "\n",
            "    accuracy                           0.76       207\n",
            "   macro avg       0.76      0.75      0.75       207\n",
            "weighted avg       0.76      0.76      0.75       207\n",
            "\n",
            "----accuracy score 75.84541062801932 ----\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "LGpgwFQqkpyU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}