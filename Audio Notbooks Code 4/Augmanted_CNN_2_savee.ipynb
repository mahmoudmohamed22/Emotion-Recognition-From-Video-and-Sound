{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Augmanted_CNN_2_savee.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9SRCO-a_AlH5",
        "outputId": "1d8975a7-2402-4769-b1e7-52c5495c8376"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HJjcbxwy46bG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "248a62ce-3f5b-4a31-a8c5-e403275e3ca0"
      },
      "source": [
        "# Orignial Notebook: https://github.com/MITESHPUTHRANNEU/Speech-Emotion-Analyzer/blob/master/final_results_gender_test.ipynb\n",
        "# This notebook author: Reza Chu\n",
        "# Last Editing Date: 31st May 2019\n",
        "\n",
        "## Python\n",
        "import os\n",
        "import random\n",
        "import sys\n",
        "\n",
        "import IPython\n",
        "from IPython.display import Audio\n",
        "from IPython.display import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "## Package\n",
        "import glob \n",
        "import keras\n",
        "import IPython.display as ipd\n",
        "import librosa\n",
        "import librosa.display\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import plotly.graph_objs as go\n",
        "import plotly.offline as py\n",
        "import plotly.tools as tls\n",
        "import seaborn as sns\n",
        "import scipy.io.wavfile\n",
        "import tensorflow as tf\n",
        "py.init_notebook_mode(connected=True)\n",
        "\n",
        "## Keras\n",
        "from keras import regularizers\n",
        "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping\n",
        "from keras.callbacks import  History, ReduceLROnPlateau, CSVLogger\n",
        "from keras.models import Model, Sequential\n",
        "from keras.layers import Dense, Embedding, LSTM\n",
        "from keras.layers import Input, Flatten, Dropout, Activation, BatchNormalization\n",
        "from keras.layers import Conv1D, MaxPooling1D, AveragePooling1D\n",
        "from keras.preprocessing import sequence\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.utils import np_utils\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "## Sklearn\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "## Rest\n",
        "from scipy.fftpack import fft\n",
        "from scipy import signal\n",
        "from scipy.io import wavfile\n",
        "from tqdm import tqdm\n",
        "\n",
        "input_duration=3\n",
        "# % pylab inline"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "        <script type=\"text/javascript\">\n",
              "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
              "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
              "        if (typeof require !== 'undefined') {\n",
              "        require.undef(\"plotly\");\n",
              "        requirejs.config({\n",
              "            paths: {\n",
              "                'plotly': ['https://cdn.plot.ly/plotly-2.8.3.min']\n",
              "            }\n",
              "        });\n",
              "        require(['plotly'], function(Plotly) {\n",
              "            window._Plotly = Plotly;\n",
              "        });\n",
              "        }\n",
              "        </script>\n",
              "        "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#only SAVEE data set\n",
        "import time\n",
        "import os\n",
        "import librosa\n",
        "from librosa import display\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "lst = []\n",
        "count=0\n",
        "start_time = time.time()\n",
        "\n",
        "path3 = '/content/drive/My Drive/data_set/SAVEE'\n",
        "for subdir, dirs, files in os.walk(path3):\n",
        "  for file in files:\n",
        "      try:\n",
        "        #0 = neutral,  1 = fearful, 2 = happy, 3 = sad, 4 = angry\n",
        "        if file.startswith('a'):\n",
        "            emotion=4\n",
        "        elif file.startswith('d'):\n",
        "            continue\n",
        "        elif file.startswith('f'):\n",
        "            emotion=1\n",
        "        elif file.startswith('h'):\n",
        "            emotion=2\n",
        "        elif file.startswith('n'):\n",
        "            emotion=0\n",
        "        elif file.startswith('sa'):\n",
        "            emotion=3\n",
        "        elif file.startswith('su'):\n",
        "            continue\n",
        "        else:\n",
        "            continue\n",
        "        #Load librosa array, obtain mfcss, store the file and the mcss information in a new array\n",
        "        X, sample_rate = librosa.load(os.path.join(subdir,file), res_type='kaiser_fast')\n",
        "        #print(sample_rate)\n",
        "       # mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T,axis=0) \n",
        "        count +=1\n",
        "        # The instruction below converts the labels (from 1 to 8) to a series from 0 to 7\n",
        "        # This is because our predictor needs to start from 0 otherwise it will try to predict also 0.\n",
        "        #file = int(file[7:8]) - 1 \n",
        "        #0 = neutral, 1 = calm, 2 = happy, 3 = sad, 4 = angry, 5 = fearful, 6 = disgust, 7 = surprised\n",
        "        arr = X, emotion\n",
        "        lst.append(arr)\n",
        "      # If the file is not valid, skip it\n",
        "      except ValueError:\n",
        "        continue\n",
        "\n",
        "print(\"--- Data loaded. Loading time: %s seconds ---\" % (time.time() - start_time))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tHmuvwzaFA2q",
        "outputId": "918a0c68-d162-4387-8ea8-71974867faac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Data loaded. Loading time: 14.917166709899902 seconds ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating X and y: zip makes a list of all the first elements, and a list of all the second elements.\n",
        "audio_file, emotion = zip(*lst)"
      ],
      "metadata": {
        "id": "QSTRDNOgHLr6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "audio_file=np.asarray(audio_file)\n",
        "emotion=np.asarray(emotion)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ong1QDBXHrvk",
        "outputId": "653ad1c3-851a-415d-9835-afd94afab330"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: VisibleDeprecationWarning:\n",
            "\n",
            "Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "emotion.shape,audio_file.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2sUCtbfMztE5",
        "outputId": "74e33a87-c6e5-4595-c4c1-bb580099d5ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((360,), (360,))"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "signal_train, signal_test, emo_train, emo_test = train_test_split(audio_file,emotion, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "62_CZk5SH_08"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "signal_valid, signal_test, emo_valid, emo_test = train_test_split(signal_test,emo_test, test_size=0.5,train_size=0.5, random_state=42)"
      ],
      "metadata": {
        "id": "3yaCr-AlIhEK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "signal_train.shape,signal_valid.shape,signal_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bmJZBOwkI58f",
        "outputId": "865df058-60be-4d01-a95a-e9e14dc65eaa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((288,), (36,), (36,))"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_valid=[]\n",
        "x_test=[]\n"
      ],
      "metadata": {
        "id": "4suaNiPyLgqh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(signal_valid.size):\n",
        "  x_valid.append(np.mean(librosa.feature.mfcc(y=signal_valid[i], sr=sample_rate, n_mfcc=40).T,axis=0))\n",
        "\n",
        "for i in range(signal_test.size):\n",
        "  x_test.append(np.mean(librosa.feature.mfcc(y=signal_test[i], sr=sample_rate, n_mfcc=40).T,axis=0))"
      ],
      "metadata": {
        "id": "cc-N9EM8KXlq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_valid=np.asarray(x_valid)\n",
        "x_test=np.asarray(x_test)"
      ],
      "metadata": {
        "id": "FjxfamKtNikQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_valid.shape,x_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2BEbwS0hNlvq",
        "outputId": "24ce95d4-4229-4d13-f933-e1c26a94f6db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((36, 40), (36, 40))"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install audiomentations"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W2_aU1eZTUna",
        "outputId": "5a7cac53-4513-4114-bcec-10d1745f4481"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: audiomentations in /usr/local/lib/python3.7/dist-packages (0.22.0)\n",
            "Requirement already satisfied: numpy>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from audiomentations) (1.21.5)\n",
            "Requirement already satisfied: librosa<0.10.0,>0.7.2 in /usr/local/lib/python3.7/dist-packages (from audiomentations) (0.8.1)\n",
            "Requirement already satisfied: scipy<2,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from audiomentations) (1.4.1)\n",
            "Requirement already satisfied: numba>=0.43.0 in /usr/local/lib/python3.7/dist-packages (from librosa<0.10.0,>0.7.2->audiomentations) (0.51.2)\n",
            "Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.7/dist-packages (from librosa<0.10.0,>0.7.2->audiomentations) (1.6.0)\n",
            "Requirement already satisfied: decorator>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa<0.10.0,>0.7.2->audiomentations) (4.4.2)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.7/dist-packages (from librosa<0.10.0,>0.7.2->audiomentations) (1.1.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from librosa<0.10.0,>0.7.2->audiomentations) (21.3)\n",
            "Requirement already satisfied: soundfile>=0.10.2 in /usr/local/lib/python3.7/dist-packages (from librosa<0.10.0,>0.7.2->audiomentations) (0.10.3.post1)\n",
            "Requirement already satisfied: audioread>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa<0.10.0,>0.7.2->audiomentations) (2.1.9)\n",
            "Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from librosa<0.10.0,>0.7.2->audiomentations) (1.0.2)\n",
            "Requirement already satisfied: resampy>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from librosa<0.10.0,>0.7.2->audiomentations) (0.2.2)\n",
            "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba>=0.43.0->librosa<0.10.0,>0.7.2->audiomentations) (0.34.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba>=0.43.0->librosa<0.10.0,>0.7.2->audiomentations) (57.4.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->librosa<0.10.0,>0.7.2->audiomentations) (3.0.7)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from pooch>=1.0->librosa<0.10.0,>0.7.2->audiomentations) (2.23.0)\n",
            "Requirement already satisfied: appdirs>=1.3.0 in /usr/local/lib/python3.7/dist-packages (from pooch>=1.0->librosa<0.10.0,>0.7.2->audiomentations) (1.4.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa<0.10.0,>0.7.2->audiomentations) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa<0.10.0,>0.7.2->audiomentations) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa<0.10.0,>0.7.2->audiomentations) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa<0.10.0,>0.7.2->audiomentations) (2.10)\n",
            "Requirement already satisfied: six>=1.3 in /usr/local/lib/python3.7/dist-packages (from resampy>=0.2.2->librosa<0.10.0,>0.7.2->audiomentations) (1.15.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn!=0.19.0,>=0.14.0->librosa<0.10.0,>0.7.2->audiomentations) (3.1.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.7/dist-packages (from soundfile>=0.10.2->librosa<0.10.0,>0.7.2->audiomentations) (1.15.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.0->soundfile>=0.10.2->librosa<0.10.0,>0.7.2->audiomentations) (2.21)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from audiomentations import AddGaussianNoise\n",
        "train_lst=[]\n",
        "for i in range(signal_train.size):\n",
        "  emo=emo_train[i]\n",
        "  x=signal_train[i]\n",
        "  arr=x,emo\n",
        "  train_lst.append(arr)\n",
        "  x=librosa.effects.time_stretch(signal_train[i],0.5)\n",
        "  arr=x,emo\n",
        "  train_lst.append(arr)\n",
        "  x=librosa.effects.time_stretch(signal_train[i],1.5)\n",
        "  arr=x,emo\n",
        "  train_lst.append(arr)\n",
        "  x=librosa.effects.pitch_shift(signal_train[i],sample_rate,2)\n",
        "  arr=x,emo\n",
        "  train_lst.append(arr)\n",
        "  #x=AddGaussianNoise(min_amplitude=0.001, max_amplitude=0.015, p=0.5)\n",
        "  #arr=x,emo\n",
        "  #train_lst.append(arr)"
      ],
      "metadata": {
        "id": "xf2odgMXQgOH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#from audiomentations import Compose, AddGaussianNoise, TimeStretch, PitchShift numpy as\n",
        " #npaugment = Compose([\n",
        "  ##  AddGaussianNoise(min_amplitude=0.001, max_amplitude=0.015, p=0.5),\n",
        "   # TimeStretch(min_rate=0.8, max_rate=1.25, p=0.5),\n",
        "   # PitchShift(min_semitones=-4, max_semitones=4, p=0.5),\n",
        "   # Shift(min_fraction=-0.5, max_fraction=0.5, p=0.5),\n",
        "#])"
      ],
      "metadata": {
        "id": "I61r5ZapSWjW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def random_gain(signal, min_factor=0.1, max_factor=0.12):\n",
        "    gain_rate = random.uniform(min_factor, max_factor)\n",
        "    augmented_signal = signal * gain_rate\n",
        "    return augmented_signal"
      ],
      "metadata": {
        "id": "Bi7bbtiVbe-Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(signal_train.size):\n",
        "  emo=emo_train[i]\n",
        "  x=random_gain(signal_train[i])\n",
        "  arr=x,emo\n",
        "  train_lst.append(arr)"
      ],
      "metadata": {
        "id": "06ngByidbrZ-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 234
        },
        "outputId": "c27679f5-08d4-44ed-b51d-d532489897e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-02b36602aaf5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msignal_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0memo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0memo_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m   \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrandom_gain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msignal_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m   \u001b[0marr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0memo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mtrain_lst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'random_gain' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "signal, y_train = zip(*train_lst)"
      ],
      "metadata": {
        "id": "CMkZ_U0rZs0z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "signal=np.asarray(signal)\n",
        "y_train=np.asarray(y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IJbOKuiIaBxx",
        "outputId": "d3953390-d641-4ca3-c0b3-19236c3dd126"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: VisibleDeprecationWarning:\n",
            "\n",
            "Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train=[]"
      ],
      "metadata": {
        "id": "iGuQyoqTaKzR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(signal.size):\n",
        "  x_train.append(np.mean(librosa.feature.mfcc(y=signal[i], sr=sample_rate, n_mfcc=40).T,axis=0))"
      ],
      "metadata": {
        "id": "Y_9_-pxcWjtj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train=np.asarray(x_train)"
      ],
      "metadata": {
        "id": "W-giRONHaPnr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TxH7IFawa__X",
        "outputId": "19836572-dc90-4d30-b67f-24011a1bcaed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1152, 40)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AvCXMuBobZAo",
        "outputId": "e3beb730-5941-4cfd-ab07-8704e6938a46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1152,)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#orignal\n",
        "import keras\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from keras.preprocessing import sequence\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from keras.layers import Input, Flatten, Dropout, Activation\n",
        "from keras.layers import Conv1D, MaxPooling1D\n",
        "from keras.models import Model\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.optimizers import schedules\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv1D(64, 5,padding='same', #classifier.add(Convolution2D(64, (3, 3), padding = 'same', input_shape = (128, 128, 3), activation = 'relu'))\n",
        "                 input_shape=(40,1)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.1))\n",
        "model.add(MaxPooling1D(pool_size=(4)))\n",
        "model.add(Conv1D(128, 5,padding='same',))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.1))\n",
        "model.add(MaxPooling1D(pool_size=(4)))\n",
        "model.add(Conv1D(256, 5,padding='same',))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.1))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(6))\n",
        "model.add(Activation('softmax'))\n",
        "lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n",
        "    initial_learning_rate=0.0001,\n",
        "    decay_steps=10000,\n",
        "    decay_rate=0.0)\n",
        "opt = keras.optimizers.SGD(learning_rate=lr_schedule)\n",
        "#opt = tf.keras.optimizers.RMSprop(lr=0.0001, rho=0.9, epsilon=1e-07, decay=0.0)\n",
        "#opt = tf.keras.optimizers.SGD(lr=0.001, momentum=0.0, decay=0.0, nesterov=False)"
      ],
      "metadata": {
        "id": "g74fXWVAC4Cr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#adding new layer\n",
        "import keras\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from keras.preprocessing import sequence\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from keras.layers import Input, Flatten, Dropout, Activation\n",
        "from keras.layers import Conv1D, MaxPooling1D\n",
        "from keras.models import Model\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.optimizers import schedules\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv1D(64, 5,padding='same', #classifier.add(Convolution2D(64, (3, 3), padding = 'same', input_shape = (128, 128, 3), activation = 'relu'))\n",
        "                 input_shape=(40,1)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.1))\n",
        "model.add(MaxPooling1D(pool_size=(4)))\n",
        "model.add(Conv1D(128, 5,padding='same',))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(MaxPooling1D(pool_size=(4)))\n",
        "model.add(Conv1D(128, 5,padding='same',))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(MaxPooling1D(pool_size=(2)))\n",
        "model.add(Conv1D(256, 5,padding='same',))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.4))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(6))\n",
        "model.add(Activation('softmax'))\n",
        "opt = keras.optimizers.Adam(learning_rate=0.0001)\n",
        "#opt = tf.keras.optimizers.RMSprop(lr=0.0001, rho=0.9, epsilon=1e-07, decay=0.0)\n",
        "#opt = tf.keras.optimizers.SGD(lr=0.001, momentum=0.0, decay=0.0, nesterov=False)"
      ],
      "metadata": {
        "id": "psl8rUOZzS5F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#changing dropout\n",
        "import keras\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from keras.preprocessing import sequence\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from keras.layers import Input, Flatten, Dropout, Activation\n",
        "from keras.layers import Conv1D, MaxPooling1D\n",
        "from keras.models import Model\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.optimizers import schedules\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv1D(64, 5,padding='same', #classifier.add(Convolution2D(64, (3, 3), padding = 'same', input_shape = (128, 128, 3), activation = 'relu'))\n",
        "                 input_shape=(40,1)))\n",
        "model.add(Activation('sigmoid'))\n",
        "model.add(Dropout(0.1))\n",
        "model.add(MaxPooling1D(pool_size=(4)))\n",
        "model.add(Conv1D(128, 5,padding='same',))\n",
        "model.add(Activation('sigmoid'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(MaxPooling1D(pool_size=(4)))\n",
        "model.add(Conv1D(256, 5,padding='same',))\n",
        "model.add(Activation('sigmoid'))\n",
        "model.add(Dropout(0.4))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(6))\n",
        "model.add(Activation('softmax'))\n",
        "#lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n",
        "    #initial_learning_rate=0.0001,\n",
        "    #decay_steps=10000,\n",
        "    #decay_rate=0.0)\n",
        "opt = keras.optimizers.Adam(learning_rate=0.0001)\n",
        "#opt = keras.optimizers.SGD(learning_rate=lr_schedule)\n",
        "#opt = tf.keras.optimizers.RMSprop(lr=0.0001, rho=0.9, epsilon=1e-07, decay=0.0)\n",
        "#opt = tf.keras.optimizers.SGD(lr=0.001, momentum=0.0, decay=0.0, nesterov=False)"
      ],
      "metadata": {
        "id": "IAinLAWa0s6D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H6ukOxAGC_I4",
        "outputId": "3b60da96-be64-4858-ba69-6123052056b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d (Conv1D)             (None, 40, 64)            384       \n",
            "                                                                 \n",
            " activation (Activation)     (None, 40, 64)            0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 40, 64)            0         \n",
            "                                                                 \n",
            " max_pooling1d (MaxPooling1D  (None, 10, 64)           0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv1d_1 (Conv1D)           (None, 10, 128)           41088     \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 10, 128)           0         \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 10, 128)           0         \n",
            "                                                                 \n",
            " max_pooling1d_1 (MaxPooling  (None, 2, 128)           0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " conv1d_2 (Conv1D)           (None, 2, 128)            82048     \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 2, 128)            0         \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 2, 128)            0         \n",
            "                                                                 \n",
            " max_pooling1d_2 (MaxPooling  (None, 1, 128)           0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " conv1d_3 (Conv1D)           (None, 1, 256)            164096    \n",
            "                                                                 \n",
            " activation_3 (Activation)   (None, 1, 256)            0         \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 1, 256)            0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 256)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 6)                 1542      \n",
            "                                                                 \n",
            " activation_4 (Activation)   (None, 6)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 289,158\n",
            "Trainable params: 289,158\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='sparse_categorical_crossentropy',\n",
        "              optimizer=opt,\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "AbMlLNk4DCBM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnnhistory=model.fit(x_train, y_train, batch_size=16, epochs=700, validation_data=(x_valid, emo_valid))\n",
        "#cnnhistory=model.fit(x_traincnn, y_train, batch_size=16, epochs=700,validation_split=0.1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RI1v2AuADFhy",
        "outputId": "9640ab78-159e-4325-98d6-ada5a5dc152b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/700\n",
            "72/72 [==============================] - 3s 23ms/step - loss: 3.2111 - accuracy: 0.2578 - val_loss: 1.5636 - val_accuracy: 0.3056\n",
            "Epoch 2/700\n",
            "72/72 [==============================] - 1s 16ms/step - loss: 2.0546 - accuracy: 0.2674 - val_loss: 1.6249 - val_accuracy: 0.2778\n",
            "Epoch 3/700\n",
            "72/72 [==============================] - 1s 16ms/step - loss: 1.8097 - accuracy: 0.2977 - val_loss: 1.5401 - val_accuracy: 0.3889\n",
            "Epoch 4/700\n",
            "72/72 [==============================] - 1s 16ms/step - loss: 1.6471 - accuracy: 0.3264 - val_loss: 1.5312 - val_accuracy: 0.3889\n",
            "Epoch 5/700\n",
            "72/72 [==============================] - 1s 16ms/step - loss: 1.6047 - accuracy: 0.3429 - val_loss: 1.4861 - val_accuracy: 0.3889\n",
            "Epoch 6/700\n",
            "72/72 [==============================] - 1s 16ms/step - loss: 1.5189 - accuracy: 0.3715 - val_loss: 1.4179 - val_accuracy: 0.4444\n",
            "Epoch 7/700\n",
            "72/72 [==============================] - 1s 16ms/step - loss: 1.4750 - accuracy: 0.3898 - val_loss: 1.3972 - val_accuracy: 0.4722\n",
            "Epoch 8/700\n",
            "72/72 [==============================] - 1s 16ms/step - loss: 1.4218 - accuracy: 0.4280 - val_loss: 1.3397 - val_accuracy: 0.4722\n",
            "Epoch 9/700\n",
            "72/72 [==============================] - 1s 16ms/step - loss: 1.3727 - accuracy: 0.4201 - val_loss: 1.3229 - val_accuracy: 0.5278\n",
            "Epoch 10/700\n",
            "72/72 [==============================] - 1s 15ms/step - loss: 1.3220 - accuracy: 0.4557 - val_loss: 1.2637 - val_accuracy: 0.4722\n",
            "Epoch 11/700\n",
            "72/72 [==============================] - 1s 15ms/step - loss: 1.2673 - accuracy: 0.4705 - val_loss: 1.2369 - val_accuracy: 0.5833\n",
            "Epoch 12/700\n",
            "72/72 [==============================] - 1s 16ms/step - loss: 1.2240 - accuracy: 0.4766 - val_loss: 1.1805 - val_accuracy: 0.5556\n",
            "Epoch 13/700\n",
            "72/72 [==============================] - 1s 15ms/step - loss: 1.1897 - accuracy: 0.4905 - val_loss: 1.1520 - val_accuracy: 0.5833\n",
            "Epoch 14/700\n",
            "72/72 [==============================] - 1s 15ms/step - loss: 1.1771 - accuracy: 0.4905 - val_loss: 1.0951 - val_accuracy: 0.6111\n",
            "Epoch 15/700\n",
            "72/72 [==============================] - 1s 15ms/step - loss: 1.1293 - accuracy: 0.5399 - val_loss: 1.0569 - val_accuracy: 0.6667\n",
            "Epoch 16/700\n",
            "72/72 [==============================] - 1s 15ms/step - loss: 1.0642 - accuracy: 0.5425 - val_loss: 1.0590 - val_accuracy: 0.5556\n",
            "Epoch 17/700\n",
            "72/72 [==============================] - 1s 15ms/step - loss: 1.0483 - accuracy: 0.5729 - val_loss: 1.0480 - val_accuracy: 0.5833\n",
            "Epoch 18/700\n",
            "72/72 [==============================] - 1s 15ms/step - loss: 1.0293 - accuracy: 0.5790 - val_loss: 0.9747 - val_accuracy: 0.6389\n",
            "Epoch 19/700\n",
            "72/72 [==============================] - 1s 15ms/step - loss: 1.0115 - accuracy: 0.5894 - val_loss: 0.9593 - val_accuracy: 0.6389\n",
            "Epoch 20/700\n",
            "72/72 [==============================] - 1s 15ms/step - loss: 0.9845 - accuracy: 0.5946 - val_loss: 0.8876 - val_accuracy: 0.7222\n",
            "Epoch 21/700\n",
            "72/72 [==============================] - 1s 15ms/step - loss: 0.9567 - accuracy: 0.6155 - val_loss: 0.8755 - val_accuracy: 0.6944\n",
            "Epoch 22/700\n",
            "72/72 [==============================] - 1s 16ms/step - loss: 0.9275 - accuracy: 0.6233 - val_loss: 0.9427 - val_accuracy: 0.6389\n",
            "Epoch 23/700\n",
            "72/72 [==============================] - 1s 15ms/step - loss: 0.9115 - accuracy: 0.6372 - val_loss: 0.8659 - val_accuracy: 0.6667\n",
            "Epoch 24/700\n",
            "72/72 [==============================] - 1s 15ms/step - loss: 0.8933 - accuracy: 0.6285 - val_loss: 0.8119 - val_accuracy: 0.6944\n",
            "Epoch 25/700\n",
            "72/72 [==============================] - 1s 15ms/step - loss: 0.8693 - accuracy: 0.6406 - val_loss: 0.8216 - val_accuracy: 0.6667\n",
            "Epoch 26/700\n",
            "72/72 [==============================] - 1s 16ms/step - loss: 0.8711 - accuracy: 0.6519 - val_loss: 0.8244 - val_accuracy: 0.6389\n",
            "Epoch 27/700\n",
            "72/72 [==============================] - 1s 16ms/step - loss: 0.8343 - accuracy: 0.6623 - val_loss: 0.8888 - val_accuracy: 0.6944\n",
            "Epoch 28/700\n",
            "72/72 [==============================] - 1s 16ms/step - loss: 0.8516 - accuracy: 0.6589 - val_loss: 0.8543 - val_accuracy: 0.6667\n",
            "Epoch 29/700\n",
            "72/72 [==============================] - 1s 15ms/step - loss: 0.8641 - accuracy: 0.6580 - val_loss: 0.8461 - val_accuracy: 0.6667\n",
            "Epoch 30/700\n",
            "72/72 [==============================] - 1s 16ms/step - loss: 0.8430 - accuracy: 0.6667 - val_loss: 0.8079 - val_accuracy: 0.6944\n",
            "Epoch 31/700\n",
            "72/72 [==============================] - 1s 16ms/step - loss: 0.8162 - accuracy: 0.6693 - val_loss: 0.7298 - val_accuracy: 0.6667\n",
            "Epoch 32/700\n",
            "72/72 [==============================] - 1s 15ms/step - loss: 0.8358 - accuracy: 0.6528 - val_loss: 0.7969 - val_accuracy: 0.6944\n",
            "Epoch 33/700\n",
            "72/72 [==============================] - 1s 15ms/step - loss: 0.7951 - accuracy: 0.6797 - val_loss: 0.7619 - val_accuracy: 0.6944\n",
            "Epoch 34/700\n",
            "72/72 [==============================] - 1s 15ms/step - loss: 0.7965 - accuracy: 0.6771 - val_loss: 0.8388 - val_accuracy: 0.6944\n",
            "Epoch 35/700\n",
            "72/72 [==============================] - 1s 15ms/step - loss: 0.7964 - accuracy: 0.6788 - val_loss: 0.7969 - val_accuracy: 0.6944\n",
            "Epoch 36/700\n",
            "72/72 [==============================] - 1s 15ms/step - loss: 0.7754 - accuracy: 0.6936 - val_loss: 0.8136 - val_accuracy: 0.6667\n",
            "Epoch 37/700\n",
            "72/72 [==============================] - 1s 16ms/step - loss: 0.7517 - accuracy: 0.7049 - val_loss: 0.7935 - val_accuracy: 0.6944\n",
            "Epoch 38/700\n",
            "72/72 [==============================] - 1s 16ms/step - loss: 0.7879 - accuracy: 0.6684 - val_loss: 0.8379 - val_accuracy: 0.6944\n",
            "Epoch 39/700\n",
            "72/72 [==============================] - 1s 16ms/step - loss: 0.7427 - accuracy: 0.6840 - val_loss: 0.8147 - val_accuracy: 0.6944\n",
            "Epoch 40/700\n",
            "72/72 [==============================] - 1s 16ms/step - loss: 0.7246 - accuracy: 0.7127 - val_loss: 0.7202 - val_accuracy: 0.7222\n",
            "Epoch 41/700\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.6965 - accuracy: 0.7248 - val_loss: 0.7913 - val_accuracy: 0.6944\n",
            "Epoch 42/700\n",
            "72/72 [==============================] - 1s 16ms/step - loss: 0.7235 - accuracy: 0.6962 - val_loss: 0.6646 - val_accuracy: 0.7222\n",
            "Epoch 43/700\n",
            "72/72 [==============================] - 1s 16ms/step - loss: 0.7087 - accuracy: 0.7170 - val_loss: 0.7036 - val_accuracy: 0.7222\n",
            "Epoch 44/700\n",
            "72/72 [==============================] - 1s 16ms/step - loss: 0.7093 - accuracy: 0.7049 - val_loss: 0.6421 - val_accuracy: 0.7778\n",
            "Epoch 45/700\n",
            "72/72 [==============================] - 1s 16ms/step - loss: 0.6890 - accuracy: 0.7196 - val_loss: 0.8897 - val_accuracy: 0.6944\n",
            "Epoch 46/700\n",
            "72/72 [==============================] - 1s 16ms/step - loss: 0.6955 - accuracy: 0.7092 - val_loss: 0.7346 - val_accuracy: 0.6944\n",
            "Epoch 47/700\n",
            "72/72 [==============================] - 1s 16ms/step - loss: 0.6938 - accuracy: 0.7300 - val_loss: 0.7907 - val_accuracy: 0.6944\n",
            "Epoch 48/700\n",
            "72/72 [==============================] - 1s 16ms/step - loss: 0.6597 - accuracy: 0.7205 - val_loss: 0.7145 - val_accuracy: 0.6944\n",
            "Epoch 49/700\n",
            "72/72 [==============================] - 1s 16ms/step - loss: 0.6878 - accuracy: 0.7214 - val_loss: 0.7105 - val_accuracy: 0.6667\n",
            "Epoch 50/700\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.6967 - accuracy: 0.7118 - val_loss: 0.7169 - val_accuracy: 0.7222\n",
            "Epoch 51/700\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.6456 - accuracy: 0.7318 - val_loss: 0.6496 - val_accuracy: 0.7778\n",
            "Epoch 52/700\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.6631 - accuracy: 0.7231 - val_loss: 0.6217 - val_accuracy: 0.7778\n",
            "Epoch 53/700\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.6270 - accuracy: 0.7448 - val_loss: 0.7117 - val_accuracy: 0.7222\n",
            "Epoch 54/700\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.6625 - accuracy: 0.7161 - val_loss: 0.6375 - val_accuracy: 0.7500\n",
            "Epoch 55/700\n",
            "72/72 [==============================] - 1s 16ms/step - loss: 0.6421 - accuracy: 0.7205 - val_loss: 0.7788 - val_accuracy: 0.6944\n",
            "Epoch 56/700\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.6347 - accuracy: 0.7396 - val_loss: 0.6808 - val_accuracy: 0.7500\n",
            "Epoch 57/700\n",
            "72/72 [==============================] - 1s 16ms/step - loss: 0.6223 - accuracy: 0.7318 - val_loss: 0.6978 - val_accuracy: 0.7500\n",
            "Epoch 58/700\n",
            "72/72 [==============================] - 1s 16ms/step - loss: 0.6315 - accuracy: 0.7361 - val_loss: 0.6491 - val_accuracy: 0.7500\n",
            "Epoch 59/700\n",
            "72/72 [==============================] - 1s 16ms/step - loss: 0.6058 - accuracy: 0.7639 - val_loss: 0.6274 - val_accuracy: 0.7500\n",
            "Epoch 60/700\n",
            "72/72 [==============================] - 1s 16ms/step - loss: 0.5957 - accuracy: 0.7439 - val_loss: 0.6312 - val_accuracy: 0.8056\n",
            "Epoch 61/700\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.5986 - accuracy: 0.7509 - val_loss: 0.6316 - val_accuracy: 0.8056\n",
            "Epoch 62/700\n",
            "72/72 [==============================] - 1s 16ms/step - loss: 0.5930 - accuracy: 0.7578 - val_loss: 0.6226 - val_accuracy: 0.7500\n",
            "Epoch 63/700\n",
            "72/72 [==============================] - 1s 16ms/step - loss: 0.5740 - accuracy: 0.7578 - val_loss: 0.6458 - val_accuracy: 0.7222\n",
            "Epoch 64/700\n",
            "72/72 [==============================] - 1s 16ms/step - loss: 0.5613 - accuracy: 0.7639 - val_loss: 0.6586 - val_accuracy: 0.7500\n",
            "Epoch 65/700\n",
            "72/72 [==============================] - 1s 16ms/step - loss: 0.5514 - accuracy: 0.7656 - val_loss: 0.6184 - val_accuracy: 0.7500\n",
            "Epoch 66/700\n",
            "72/72 [==============================] - 1s 16ms/step - loss: 0.5778 - accuracy: 0.7578 - val_loss: 0.5224 - val_accuracy: 0.7778\n",
            "Epoch 67/700\n",
            "72/72 [==============================] - 1s 16ms/step - loss: 0.5884 - accuracy: 0.7535 - val_loss: 0.6217 - val_accuracy: 0.7778\n",
            "Epoch 68/700\n",
            "72/72 [==============================] - 1s 16ms/step - loss: 0.5722 - accuracy: 0.7622 - val_loss: 0.6211 - val_accuracy: 0.7778\n",
            "Epoch 69/700\n",
            "72/72 [==============================] - 1s 16ms/step - loss: 0.5538 - accuracy: 0.7674 - val_loss: 0.6545 - val_accuracy: 0.7500\n",
            "Epoch 70/700\n",
            "72/72 [==============================] - 1s 16ms/step - loss: 0.5506 - accuracy: 0.7769 - val_loss: 0.6495 - val_accuracy: 0.7500\n",
            "Epoch 71/700\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.5447 - accuracy: 0.7760 - val_loss: 0.6148 - val_accuracy: 0.7500\n",
            "Epoch 72/700\n",
            "72/72 [==============================] - 1s 16ms/step - loss: 0.5072 - accuracy: 0.7804 - val_loss: 0.5860 - val_accuracy: 0.7778\n",
            "Epoch 73/700\n",
            "72/72 [==============================] - 1s 16ms/step - loss: 0.5208 - accuracy: 0.7786 - val_loss: 0.5758 - val_accuracy: 0.7778\n",
            "Epoch 74/700\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.5025 - accuracy: 0.7812 - val_loss: 0.6009 - val_accuracy: 0.7500\n",
            "Epoch 75/700\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.5305 - accuracy: 0.7786 - val_loss: 0.6352 - val_accuracy: 0.7500\n",
            "Epoch 76/700\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.4990 - accuracy: 0.7899 - val_loss: 0.5346 - val_accuracy: 0.7778\n",
            "Epoch 77/700\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.4827 - accuracy: 0.7977 - val_loss: 0.6138 - val_accuracy: 0.7778\n",
            "Epoch 78/700\n",
            "72/72 [==============================] - 1s 16ms/step - loss: 0.4793 - accuracy: 0.7977 - val_loss: 0.5750 - val_accuracy: 0.7778\n",
            "Epoch 79/700\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.4895 - accuracy: 0.8134 - val_loss: 0.6087 - val_accuracy: 0.7778\n",
            "Epoch 80/700\n",
            "72/72 [==============================] - 1s 16ms/step - loss: 0.4651 - accuracy: 0.7995 - val_loss: 0.5538 - val_accuracy: 0.7778\n",
            "Epoch 81/700\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.4697 - accuracy: 0.8073 - val_loss: 0.6589 - val_accuracy: 0.7222\n",
            "Epoch 82/700\n",
            "72/72 [==============================] - 1s 16ms/step - loss: 0.4839 - accuracy: 0.7960 - val_loss: 0.5859 - val_accuracy: 0.7778\n",
            "Epoch 83/700\n",
            "72/72 [==============================] - 1s 16ms/step - loss: 0.4669 - accuracy: 0.8030 - val_loss: 0.4879 - val_accuracy: 0.8056\n",
            "Epoch 84/700\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.4650 - accuracy: 0.8142 - val_loss: 0.5822 - val_accuracy: 0.7500\n",
            "Epoch 85/700\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.4690 - accuracy: 0.7873 - val_loss: 0.6109 - val_accuracy: 0.7222\n",
            "Epoch 86/700\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.4654 - accuracy: 0.8073 - val_loss: 0.6142 - val_accuracy: 0.7500\n",
            "Epoch 87/700\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.4295 - accuracy: 0.8255 - val_loss: 0.6058 - val_accuracy: 0.7500\n",
            "Epoch 88/700\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.4419 - accuracy: 0.8064 - val_loss: 0.5137 - val_accuracy: 0.8056\n",
            "Epoch 89/700\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.4187 - accuracy: 0.8281 - val_loss: 0.6009 - val_accuracy: 0.7500\n",
            "Epoch 90/700\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.4323 - accuracy: 0.8134 - val_loss: 0.4637 - val_accuracy: 0.7778\n",
            "Epoch 91/700\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.4126 - accuracy: 0.8238 - val_loss: 0.6777 - val_accuracy: 0.7500\n",
            "Epoch 92/700\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.4023 - accuracy: 0.8307 - val_loss: 0.5266 - val_accuracy: 0.7778\n",
            "Epoch 93/700\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.4246 - accuracy: 0.8290 - val_loss: 0.5621 - val_accuracy: 0.7778\n",
            "Epoch 94/700\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.4327 - accuracy: 0.8047 - val_loss: 0.5306 - val_accuracy: 0.7778\n",
            "Epoch 95/700\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.4142 - accuracy: 0.8238 - val_loss: 0.5041 - val_accuracy: 0.7778\n",
            "Epoch 96/700\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.4034 - accuracy: 0.8359 - val_loss: 0.5533 - val_accuracy: 0.7778\n",
            "Epoch 97/700\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.3906 - accuracy: 0.8411 - val_loss: 0.5052 - val_accuracy: 0.7778\n",
            "Epoch 98/700\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.3806 - accuracy: 0.8351 - val_loss: 0.4425 - val_accuracy: 0.7778\n",
            "Epoch 99/700\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.3711 - accuracy: 0.8455 - val_loss: 0.5737 - val_accuracy: 0.7222\n",
            "Epoch 100/700\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.3861 - accuracy: 0.8264 - val_loss: 0.6305 - val_accuracy: 0.7500\n",
            "Epoch 101/700\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.3610 - accuracy: 0.8377 - val_loss: 0.5176 - val_accuracy: 0.7778\n",
            "Epoch 102/700\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.4022 - accuracy: 0.8325 - val_loss: 0.5699 - val_accuracy: 0.7778\n",
            "Epoch 103/700\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.3717 - accuracy: 0.8481 - val_loss: 0.5784 - val_accuracy: 0.7778\n",
            "Epoch 104/700\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.3854 - accuracy: 0.8307 - val_loss: 0.5807 - val_accuracy: 0.7222\n",
            "Epoch 105/700\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.3714 - accuracy: 0.8342 - val_loss: 0.5586 - val_accuracy: 0.7778\n",
            "Epoch 106/700\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.3591 - accuracy: 0.8498 - val_loss: 0.6118 - val_accuracy: 0.7778\n",
            "Epoch 107/700\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.3578 - accuracy: 0.8507 - val_loss: 0.5622 - val_accuracy: 0.7500\n",
            "Epoch 108/700\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.3395 - accuracy: 0.8681 - val_loss: 0.5025 - val_accuracy: 0.7778\n",
            "Epoch 109/700\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.3413 - accuracy: 0.8550 - val_loss: 0.6962 - val_accuracy: 0.6667\n",
            "Epoch 110/700\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.3524 - accuracy: 0.8498 - val_loss: 0.5298 - val_accuracy: 0.7222\n",
            "Epoch 111/700\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.3338 - accuracy: 0.8550 - val_loss: 0.5726 - val_accuracy: 0.7778\n",
            "Epoch 112/700\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.3485 - accuracy: 0.8594 - val_loss: 0.4235 - val_accuracy: 0.7778\n",
            "Epoch 113/700\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.3255 - accuracy: 0.8542 - val_loss: 0.5865 - val_accuracy: 0.7500\n",
            "Epoch 114/700\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.3421 - accuracy: 0.8516 - val_loss: 0.7149 - val_accuracy: 0.7500\n",
            "Epoch 115/700\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.3157 - accuracy: 0.8741 - val_loss: 0.5559 - val_accuracy: 0.7778\n",
            "Epoch 116/700\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.3234 - accuracy: 0.8759 - val_loss: 0.4391 - val_accuracy: 0.8056\n",
            "Epoch 117/700\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.3281 - accuracy: 0.8611 - val_loss: 0.5061 - val_accuracy: 0.7778\n",
            "Epoch 118/700\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.3218 - accuracy: 0.8707 - val_loss: 0.5814 - val_accuracy: 0.7500\n",
            "Epoch 119/700\n",
            "72/72 [==============================] - 1s 20ms/step - loss: 0.3147 - accuracy: 0.8750 - val_loss: 0.5261 - val_accuracy: 0.7500\n",
            "Epoch 120/700\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.3066 - accuracy: 0.8785 - val_loss: 0.5849 - val_accuracy: 0.7500\n",
            "Epoch 121/700\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.2844 - accuracy: 0.8837 - val_loss: 0.5620 - val_accuracy: 0.6944\n",
            "Epoch 122/700\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.2766 - accuracy: 0.8819 - val_loss: 0.6274 - val_accuracy: 0.7500\n",
            "Epoch 123/700\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.3121 - accuracy: 0.8689 - val_loss: 0.7428 - val_accuracy: 0.7222\n",
            "Epoch 124/700\n",
            "72/72 [==============================] - 1s 20ms/step - loss: 0.3001 - accuracy: 0.8811 - val_loss: 0.6729 - val_accuracy: 0.7222\n",
            "Epoch 125/700\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.2865 - accuracy: 0.8837 - val_loss: 0.5431 - val_accuracy: 0.7778\n",
            "Epoch 126/700\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.2866 - accuracy: 0.8845 - val_loss: 0.5463 - val_accuracy: 0.7222\n",
            "Epoch 127/700\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.2804 - accuracy: 0.8776 - val_loss: 0.4502 - val_accuracy: 0.7778\n",
            "Epoch 128/700\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.2904 - accuracy: 0.8785 - val_loss: 0.6127 - val_accuracy: 0.7500\n",
            "Epoch 129/700\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.2746 - accuracy: 0.8828 - val_loss: 0.5311 - val_accuracy: 0.7778\n",
            "Epoch 130/700\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.2739 - accuracy: 0.8898 - val_loss: 0.5202 - val_accuracy: 0.7778\n",
            "Epoch 131/700\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.2710 - accuracy: 0.8845 - val_loss: 0.6447 - val_accuracy: 0.7500\n",
            "Epoch 132/700\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.2548 - accuracy: 0.9010 - val_loss: 0.5207 - val_accuracy: 0.8056\n",
            "Epoch 133/700\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.2803 - accuracy: 0.8741 - val_loss: 0.6018 - val_accuracy: 0.6944\n",
            "Epoch 134/700\n",
            "72/72 [==============================] - 1s 16ms/step - loss: 0.2755 - accuracy: 0.8872 - val_loss: 0.4820 - val_accuracy: 0.7778\n",
            "Epoch 135/700\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.2695 - accuracy: 0.8837 - val_loss: 0.4708 - val_accuracy: 0.8056\n",
            "Epoch 136/700\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.2721 - accuracy: 0.8906 - val_loss: 0.5436 - val_accuracy: 0.7778\n",
            "Epoch 137/700\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.2756 - accuracy: 0.8898 - val_loss: 0.5260 - val_accuracy: 0.8056\n",
            "Epoch 138/700\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.2677 - accuracy: 0.8924 - val_loss: 0.6102 - val_accuracy: 0.7778\n",
            "Epoch 139/700\n",
            "72/72 [==============================] - 1s 16ms/step - loss: 0.2427 - accuracy: 0.9062 - val_loss: 0.5018 - val_accuracy: 0.7222\n",
            "Epoch 140/700\n",
            "72/72 [==============================] - 1s 16ms/step - loss: 0.2674 - accuracy: 0.8828 - val_loss: 0.5935 - val_accuracy: 0.7222\n",
            "Epoch 141/700\n",
            "72/72 [==============================] - 1s 16ms/step - loss: 0.2478 - accuracy: 0.8984 - val_loss: 0.6008 - val_accuracy: 0.7778\n",
            "Epoch 142/700\n",
            "72/72 [==============================] - 1s 16ms/step - loss: 0.2457 - accuracy: 0.8932 - val_loss: 0.5962 - val_accuracy: 0.7778\n",
            "Epoch 143/700\n",
            "72/72 [==============================] - 1s 16ms/step - loss: 0.2322 - accuracy: 0.9132 - val_loss: 0.5361 - val_accuracy: 0.7500\n",
            "Epoch 144/700\n",
            "72/72 [==============================] - 1s 16ms/step - loss: 0.2567 - accuracy: 0.8958 - val_loss: 0.7037 - val_accuracy: 0.7778\n",
            "Epoch 145/700\n",
            "72/72 [==============================] - 1s 16ms/step - loss: 0.2387 - accuracy: 0.9019 - val_loss: 0.4907 - val_accuracy: 0.8056\n",
            "Epoch 146/700\n",
            "72/72 [==============================] - 1s 16ms/step - loss: 0.2547 - accuracy: 0.8906 - val_loss: 0.5128 - val_accuracy: 0.8056\n",
            "Epoch 147/700\n",
            "72/72 [==============================] - 1s 16ms/step - loss: 0.2289 - accuracy: 0.9028 - val_loss: 0.5793 - val_accuracy: 0.7778\n",
            "Epoch 148/700\n",
            "72/72 [==============================] - 1s 16ms/step - loss: 0.2502 - accuracy: 0.8993 - val_loss: 0.5235 - val_accuracy: 0.7222\n",
            "Epoch 149/700\n",
            "72/72 [==============================] - 1s 16ms/step - loss: 0.2300 - accuracy: 0.9045 - val_loss: 0.5082 - val_accuracy: 0.7500\n",
            "Epoch 150/700\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.2260 - accuracy: 0.9028 - val_loss: 0.5871 - val_accuracy: 0.7500\n",
            "Epoch 151/700\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.2347 - accuracy: 0.9019 - val_loss: 0.5180 - val_accuracy: 0.7778\n",
            "Epoch 152/700\n",
            "72/72 [==============================] - 1s 16ms/step - loss: 0.2155 - accuracy: 0.9175 - val_loss: 0.6298 - val_accuracy: 0.7500\n",
            "Epoch 153/700\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.2099 - accuracy: 0.9201 - val_loss: 0.6871 - val_accuracy: 0.7500\n",
            "Epoch 154/700\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.2174 - accuracy: 0.9028 - val_loss: 0.5303 - val_accuracy: 0.8333\n",
            "Epoch 155/700\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.2163 - accuracy: 0.9141 - val_loss: 0.5787 - val_accuracy: 0.7222\n",
            "Epoch 156/700\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.2232 - accuracy: 0.9141 - val_loss: 0.6661 - val_accuracy: 0.7222\n",
            "Epoch 157/700\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.2047 - accuracy: 0.9115 - val_loss: 0.5903 - val_accuracy: 0.7500\n",
            "Epoch 158/700\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.2241 - accuracy: 0.9028 - val_loss: 0.5236 - val_accuracy: 0.7222\n",
            "Epoch 159/700\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.2172 - accuracy: 0.9132 - val_loss: 0.4101 - val_accuracy: 0.8056\n",
            "Epoch 160/700\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.2032 - accuracy: 0.9132 - val_loss: 0.4391 - val_accuracy: 0.8333\n",
            "Epoch 161/700\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.2028 - accuracy: 0.9193 - val_loss: 0.6381 - val_accuracy: 0.8056\n",
            "Epoch 162/700\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.2097 - accuracy: 0.9184 - val_loss: 0.4987 - val_accuracy: 0.8056\n",
            "Epoch 163/700\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.2019 - accuracy: 0.9158 - val_loss: 0.4177 - val_accuracy: 0.8889\n",
            "Epoch 164/700\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.2012 - accuracy: 0.9184 - val_loss: 0.4659 - val_accuracy: 0.8333\n",
            "Epoch 165/700\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.1880 - accuracy: 0.9297 - val_loss: 0.4421 - val_accuracy: 0.8333\n",
            "Epoch 166/700\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.1881 - accuracy: 0.9210 - val_loss: 0.5229 - val_accuracy: 0.8056\n",
            "Epoch 167/700\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.1945 - accuracy: 0.9219 - val_loss: 0.6248 - val_accuracy: 0.7500\n",
            "Epoch 168/700\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.1715 - accuracy: 0.9280 - val_loss: 0.6465 - val_accuracy: 0.7222\n",
            "Epoch 169/700\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.2019 - accuracy: 0.9227 - val_loss: 0.3768 - val_accuracy: 0.8333\n",
            "Epoch 170/700\n",
            "72/72 [==============================] - 1s 16ms/step - loss: 0.2009 - accuracy: 0.9184 - val_loss: 0.5245 - val_accuracy: 0.8056\n",
            "Epoch 171/700\n",
            "72/72 [==============================] - 1s 16ms/step - loss: 0.1876 - accuracy: 0.9271 - val_loss: 0.6811 - val_accuracy: 0.7778\n",
            "Epoch 172/700\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.2227 - accuracy: 0.9115 - val_loss: 0.4995 - val_accuracy: 0.7778\n",
            "Epoch 173/700\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.1869 - accuracy: 0.9219 - val_loss: 0.6808 - val_accuracy: 0.7500\n",
            "Epoch 174/700\n",
            "72/72 [==============================] - 1s 16ms/step - loss: 0.1674 - accuracy: 0.9366 - val_loss: 0.3415 - val_accuracy: 0.9167\n",
            "Epoch 175/700\n",
            "72/72 [==============================] - 1s 16ms/step - loss: 0.1754 - accuracy: 0.9375 - val_loss: 0.5808 - val_accuracy: 0.8056\n",
            "Epoch 176/700\n",
            "72/72 [==============================] - 1s 16ms/step - loss: 0.1773 - accuracy: 0.9323 - val_loss: 0.5013 - val_accuracy: 0.7500\n",
            "Epoch 177/700\n",
            "72/72 [==============================] - 1s 16ms/step - loss: 0.1812 - accuracy: 0.9219 - val_loss: 0.5621 - val_accuracy: 0.8056\n",
            "Epoch 178/700\n",
            "72/72 [==============================] - 1s 16ms/step - loss: 0.1922 - accuracy: 0.9245 - val_loss: 0.5165 - val_accuracy: 0.7500\n",
            "Epoch 179/700\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.1659 - accuracy: 0.9323 - val_loss: 0.6432 - val_accuracy: 0.7222\n",
            "Epoch 180/700\n",
            "72/72 [==============================] - 1s 16ms/step - loss: 0.1759 - accuracy: 0.9306 - val_loss: 0.5803 - val_accuracy: 0.7500\n",
            "Epoch 181/700\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.1781 - accuracy: 0.9271 - val_loss: 0.5716 - val_accuracy: 0.8056\n",
            "Epoch 182/700\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.1798 - accuracy: 0.9280 - val_loss: 0.4752 - val_accuracy: 0.7778\n",
            "Epoch 183/700\n",
            "72/72 [==============================] - 1s 16ms/step - loss: 0.1680 - accuracy: 0.9349 - val_loss: 0.5740 - val_accuracy: 0.6944\n",
            "Epoch 184/700\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.1893 - accuracy: 0.9314 - val_loss: 0.5947 - val_accuracy: 0.7778\n",
            "Epoch 185/700\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.1763 - accuracy: 0.9262 - val_loss: 0.6307 - val_accuracy: 0.7500\n",
            "Epoch 186/700\n",
            "72/72 [==============================] - 1s 16ms/step - loss: 0.1541 - accuracy: 0.9392 - val_loss: 0.4264 - val_accuracy: 0.8056\n",
            "Epoch 187/700\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.1577 - accuracy: 0.9418 - val_loss: 0.6459 - val_accuracy: 0.7500\n",
            "Epoch 188/700\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.1630 - accuracy: 0.9384 - val_loss: 0.7714 - val_accuracy: 0.7222\n",
            "Epoch 189/700\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.1331 - accuracy: 0.9479 - val_loss: 0.5859 - val_accuracy: 0.7500\n",
            "Epoch 190/700\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.1568 - accuracy: 0.9392 - val_loss: 0.5487 - val_accuracy: 0.7778\n",
            "Epoch 191/700\n",
            "72/72 [==============================] - 1s 16ms/step - loss: 0.1647 - accuracy: 0.9340 - val_loss: 0.6339 - val_accuracy: 0.7500\n",
            "Epoch 192/700\n",
            "72/72 [==============================] - 1s 16ms/step - loss: 0.1740 - accuracy: 0.9366 - val_loss: 0.4289 - val_accuracy: 0.8333\n",
            "Epoch 193/700\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.1375 - accuracy: 0.9497 - val_loss: 0.6264 - val_accuracy: 0.7778\n",
            "Epoch 194/700\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.1453 - accuracy: 0.9410 - val_loss: 0.5454 - val_accuracy: 0.8056\n",
            "Epoch 195/700\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.1362 - accuracy: 0.9427 - val_loss: 0.6157 - val_accuracy: 0.7500\n",
            "Epoch 196/700\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.1722 - accuracy: 0.9323 - val_loss: 0.5568 - val_accuracy: 0.7778\n",
            "Epoch 197/700\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.1452 - accuracy: 0.9514 - val_loss: 0.5359 - val_accuracy: 0.7222\n",
            "Epoch 198/700\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.1262 - accuracy: 0.9497 - val_loss: 0.3790 - val_accuracy: 0.8611\n",
            "Epoch 199/700\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.1304 - accuracy: 0.9479 - val_loss: 0.5649 - val_accuracy: 0.7778\n",
            "Epoch 200/700\n",
            "72/72 [==============================] - 1s 16ms/step - loss: 0.1190 - accuracy: 0.9531 - val_loss: 0.4715 - val_accuracy: 0.8056\n",
            "Epoch 201/700\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.1475 - accuracy: 0.9470 - val_loss: 0.6133 - val_accuracy: 0.7778\n",
            "Epoch 202/700\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.1664 - accuracy: 0.9349 - val_loss: 0.5116 - val_accuracy: 0.7778\n",
            "Epoch 203/700\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.1486 - accuracy: 0.9488 - val_loss: 0.7238 - val_accuracy: 0.7500\n",
            "Epoch 204/700\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.1447 - accuracy: 0.9453 - val_loss: 0.6777 - val_accuracy: 0.7222\n",
            "Epoch 205/700\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.1373 - accuracy: 0.9497 - val_loss: 0.6280 - val_accuracy: 0.7500\n",
            "Epoch 206/700\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.1332 - accuracy: 0.9488 - val_loss: 0.4975 - val_accuracy: 0.8056\n",
            "Epoch 207/700\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.1245 - accuracy: 0.9549 - val_loss: 0.6179 - val_accuracy: 0.7500\n",
            "Epoch 208/700\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.1235 - accuracy: 0.9462 - val_loss: 0.6359 - val_accuracy: 0.7500\n",
            "Epoch 209/700\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.1219 - accuracy: 0.9479 - val_loss: 0.5992 - val_accuracy: 0.7778\n",
            "Epoch 210/700\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.1395 - accuracy: 0.9453 - val_loss: 0.6311 - val_accuracy: 0.7500\n",
            "Epoch 211/700\n",
            "72/72 [==============================] - 1s 16ms/step - loss: 0.1341 - accuracy: 0.9436 - val_loss: 0.6419 - val_accuracy: 0.7500\n",
            "Epoch 212/700\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.1077 - accuracy: 0.9618 - val_loss: 0.6421 - val_accuracy: 0.6944\n",
            "Epoch 213/700\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.1356 - accuracy: 0.9453 - val_loss: 0.4657 - val_accuracy: 0.8056\n",
            "Epoch 214/700\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.1283 - accuracy: 0.9462 - val_loss: 0.5506 - val_accuracy: 0.7500\n",
            "Epoch 215/700\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.1074 - accuracy: 0.9618 - val_loss: 0.7342 - val_accuracy: 0.7500\n",
            "Epoch 216/700\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.1412 - accuracy: 0.9479 - val_loss: 0.5822 - val_accuracy: 0.8611\n",
            "Epoch 217/700\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.1171 - accuracy: 0.9601 - val_loss: 0.5574 - val_accuracy: 0.7500\n",
            "Epoch 218/700\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.1215 - accuracy: 0.9566 - val_loss: 0.5770 - val_accuracy: 0.8056\n",
            "Epoch 219/700\n",
            "72/72 [==============================] - 1s 16ms/step - loss: 0.1287 - accuracy: 0.9609 - val_loss: 0.6760 - val_accuracy: 0.7500\n",
            "Epoch 220/700\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.1264 - accuracy: 0.9514 - val_loss: 0.9075 - val_accuracy: 0.6944\n",
            "Epoch 221/700\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.1106 - accuracy: 0.9601 - val_loss: 0.7465 - val_accuracy: 0.7222\n",
            "Epoch 222/700\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.1261 - accuracy: 0.9592 - val_loss: 0.7818 - val_accuracy: 0.7500\n",
            "Epoch 223/700\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.1016 - accuracy: 0.9644 - val_loss: 0.6697 - val_accuracy: 0.7778\n",
            "Epoch 224/700\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.1198 - accuracy: 0.9540 - val_loss: 0.7384 - val_accuracy: 0.7500\n",
            "Epoch 225/700\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.1063 - accuracy: 0.9601 - val_loss: 0.4831 - val_accuracy: 0.7778\n",
            "Epoch 226/700\n",
            "72/72 [==============================] - 1s 16ms/step - loss: 0.1164 - accuracy: 0.9514 - val_loss: 0.4756 - val_accuracy: 0.7500\n",
            "Epoch 227/700\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.1223 - accuracy: 0.9566 - val_loss: 0.7124 - val_accuracy: 0.7500\n",
            "Epoch 228/700\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.0951 - accuracy: 0.9653 - val_loss: 0.4677 - val_accuracy: 0.7778\n",
            "Epoch 229/700\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.1140 - accuracy: 0.9601 - val_loss: 0.5370 - val_accuracy: 0.7222\n",
            "Epoch 230/700\n",
            "72/72 [==============================] - 1s 16ms/step - loss: 0.1083 - accuracy: 0.9583 - val_loss: 0.6187 - val_accuracy: 0.7222\n",
            "Epoch 231/700\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.1053 - accuracy: 0.9618 - val_loss: 0.4842 - val_accuracy: 0.8056\n",
            "Epoch 232/700\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.0991 - accuracy: 0.9644 - val_loss: 0.5195 - val_accuracy: 0.7778\n",
            "Epoch 233/700\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.1067 - accuracy: 0.9601 - val_loss: 0.6348 - val_accuracy: 0.7500\n",
            "Epoch 234/700\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.0908 - accuracy: 0.9670 - val_loss: 0.5788 - val_accuracy: 0.6944\n",
            "Epoch 235/700\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.0780 - accuracy: 0.9653 - val_loss: 0.6475 - val_accuracy: 0.8056\n",
            "Epoch 236/700\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.1226 - accuracy: 0.9523 - val_loss: 0.8258 - val_accuracy: 0.6944\n",
            "Epoch 237/700\n",
            "72/72 [==============================] - 1s 16ms/step - loss: 0.1088 - accuracy: 0.9609 - val_loss: 0.6420 - val_accuracy: 0.7778\n",
            "Epoch 238/700\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.1002 - accuracy: 0.9653 - val_loss: 0.5087 - val_accuracy: 0.8056\n",
            "Epoch 239/700\n",
            "72/72 [==============================] - 2s 28ms/step - loss: 0.0887 - accuracy: 0.9679 - val_loss: 0.4717 - val_accuracy: 0.8056\n",
            "Epoch 240/700\n",
            "72/72 [==============================] - 2s 29ms/step - loss: 0.0929 - accuracy: 0.9635 - val_loss: 0.6866 - val_accuracy: 0.7500\n",
            "Epoch 241/700\n",
            "72/72 [==============================] - 2s 34ms/step - loss: 0.0951 - accuracy: 0.9627 - val_loss: 0.6988 - val_accuracy: 0.8056\n",
            "Epoch 242/700\n",
            "72/72 [==============================] - 2s 27ms/step - loss: 0.0842 - accuracy: 0.9670 - val_loss: 0.5971 - val_accuracy: 0.7222\n",
            "Epoch 243/700\n",
            "72/72 [==============================] - 1s 16ms/step - loss: 0.1190 - accuracy: 0.9592 - val_loss: 0.6851 - val_accuracy: 0.7500\n",
            "Epoch 244/700\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.0872 - accuracy: 0.9722 - val_loss: 0.4372 - val_accuracy: 0.8333\n",
            "Epoch 245/700\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.0739 - accuracy: 0.9757 - val_loss: 0.5185 - val_accuracy: 0.8056\n",
            "Epoch 246/700\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.1012 - accuracy: 0.9601 - val_loss: 0.7221 - val_accuracy: 0.8056\n",
            "Epoch 247/700\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.0788 - accuracy: 0.9757 - val_loss: 0.7073 - val_accuracy: 0.8056\n",
            "Epoch 248/700\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.0996 - accuracy: 0.9627 - val_loss: 0.6475 - val_accuracy: 0.8056\n",
            "Epoch 249/700\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0902 - accuracy: 0.9722 - val_loss: 0.4943 - val_accuracy: 0.8056\n",
            "Epoch 250/700\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.0822 - accuracy: 0.9679 - val_loss: 0.5693 - val_accuracy: 0.7500\n",
            "Epoch 251/700\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.0962 - accuracy: 0.9644 - val_loss: 0.6932 - val_accuracy: 0.7500\n",
            "Epoch 252/700\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.0736 - accuracy: 0.9748 - val_loss: 0.6964 - val_accuracy: 0.7778\n",
            "Epoch 253/700\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0923 - accuracy: 0.9679 - val_loss: 0.7042 - val_accuracy: 0.6944\n",
            "Epoch 254/700\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.0821 - accuracy: 0.9705 - val_loss: 0.6268 - val_accuracy: 0.7222\n",
            "Epoch 255/700\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0910 - accuracy: 0.9653 - val_loss: 0.8864 - val_accuracy: 0.7500\n",
            "Epoch 256/700\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.0739 - accuracy: 0.9714 - val_loss: 0.7662 - val_accuracy: 0.7222\n",
            "Epoch 257/700\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0857 - accuracy: 0.9740 - val_loss: 0.6461 - val_accuracy: 0.7778\n",
            "Epoch 258/700\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0634 - accuracy: 0.9792 - val_loss: 0.9177 - val_accuracy: 0.7500\n",
            "Epoch 259/700\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.0891 - accuracy: 0.9635 - val_loss: 0.6095 - val_accuracy: 0.8056\n",
            "Epoch 260/700\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0878 - accuracy: 0.9688 - val_loss: 0.6163 - val_accuracy: 0.8056\n",
            "Epoch 261/700\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0864 - accuracy: 0.9644 - val_loss: 0.5503 - val_accuracy: 0.8333\n",
            "Epoch 262/700\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0994 - accuracy: 0.9670 - val_loss: 0.5910 - val_accuracy: 0.7778\n",
            "Epoch 263/700\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0839 - accuracy: 0.9722 - val_loss: 0.5337 - val_accuracy: 0.8056\n",
            "Epoch 264/700\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0923 - accuracy: 0.9705 - val_loss: 0.8094 - val_accuracy: 0.7222\n",
            "Epoch 265/700\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0797 - accuracy: 0.9696 - val_loss: 0.5602 - val_accuracy: 0.8056\n",
            "Epoch 266/700\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0977 - accuracy: 0.9644 - val_loss: 0.6104 - val_accuracy: 0.7500\n",
            "Epoch 267/700\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0604 - accuracy: 0.9809 - val_loss: 0.8628 - val_accuracy: 0.7500\n",
            "Epoch 268/700\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0799 - accuracy: 0.9705 - val_loss: 0.7660 - val_accuracy: 0.7778\n",
            "Epoch 269/700\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0716 - accuracy: 0.9731 - val_loss: 0.6127 - val_accuracy: 0.8056\n",
            "Epoch 270/700\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0733 - accuracy: 0.9731 - val_loss: 0.6527 - val_accuracy: 0.7500\n",
            "Epoch 271/700\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0564 - accuracy: 0.9783 - val_loss: 0.7606 - val_accuracy: 0.7500\n",
            "Epoch 272/700\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.0716 - accuracy: 0.9740 - val_loss: 0.6829 - val_accuracy: 0.7778\n",
            "Epoch 273/700\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0683 - accuracy: 0.9800 - val_loss: 0.6699 - val_accuracy: 0.7500\n",
            "Epoch 274/700\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.0683 - accuracy: 0.9714 - val_loss: 0.7028 - val_accuracy: 0.7778\n",
            "Epoch 275/700\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.0755 - accuracy: 0.9714 - val_loss: 0.6870 - val_accuracy: 0.7778\n",
            "Epoch 276/700\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0774 - accuracy: 0.9783 - val_loss: 0.6670 - val_accuracy: 0.8056\n",
            "Epoch 277/700\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.0929 - accuracy: 0.9661 - val_loss: 0.5742 - val_accuracy: 0.8611\n",
            "Epoch 278/700\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.0522 - accuracy: 0.9835 - val_loss: 0.6988 - val_accuracy: 0.7778\n",
            "Epoch 279/700\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.0515 - accuracy: 0.9826 - val_loss: 0.7586 - val_accuracy: 0.7500\n",
            "Epoch 280/700\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0849 - accuracy: 0.9731 - val_loss: 0.6850 - val_accuracy: 0.7778\n",
            "Epoch 281/700\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.0732 - accuracy: 0.9748 - val_loss: 0.7275 - val_accuracy: 0.8056\n",
            "Epoch 282/700\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.0694 - accuracy: 0.9722 - val_loss: 0.7252 - val_accuracy: 0.8056\n",
            "Epoch 283/700\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0800 - accuracy: 0.9757 - val_loss: 0.9997 - val_accuracy: 0.7222\n",
            "Epoch 284/700\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.0744 - accuracy: 0.9731 - val_loss: 0.8429 - val_accuracy: 0.7500\n",
            "Epoch 285/700\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.0487 - accuracy: 0.9774 - val_loss: 0.7494 - val_accuracy: 0.7778\n",
            "Epoch 286/700\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.0952 - accuracy: 0.9609 - val_loss: 0.7618 - val_accuracy: 0.7500\n",
            "Epoch 287/700\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0779 - accuracy: 0.9748 - val_loss: 0.9595 - val_accuracy: 0.7222\n",
            "Epoch 288/700\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0793 - accuracy: 0.9740 - val_loss: 0.6607 - val_accuracy: 0.7222\n",
            "Epoch 289/700\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.0717 - accuracy: 0.9731 - val_loss: 0.7530 - val_accuracy: 0.7778\n",
            "Epoch 290/700\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.0679 - accuracy: 0.9757 - val_loss: 0.6838 - val_accuracy: 0.8333\n",
            "Epoch 291/700\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0861 - accuracy: 0.9661 - val_loss: 0.8642 - val_accuracy: 0.7778\n",
            "Epoch 292/700\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.0489 - accuracy: 0.9835 - val_loss: 0.7279 - val_accuracy: 0.7500\n",
            "Epoch 293/700\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.0619 - accuracy: 0.9792 - val_loss: 0.9950 - val_accuracy: 0.7500\n",
            "Epoch 294/700\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0638 - accuracy: 0.9800 - val_loss: 0.9407 - val_accuracy: 0.7778\n",
            "Epoch 295/700\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0609 - accuracy: 0.9792 - val_loss: 0.8396 - val_accuracy: 0.7500\n",
            "Epoch 296/700\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0649 - accuracy: 0.9792 - val_loss: 0.6313 - val_accuracy: 0.8333\n",
            "Epoch 297/700\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.0401 - accuracy: 0.9878 - val_loss: 0.8081 - val_accuracy: 0.7500\n",
            "Epoch 298/700\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0712 - accuracy: 0.9809 - val_loss: 0.9311 - val_accuracy: 0.7500\n",
            "Epoch 299/700\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0591 - accuracy: 0.9792 - val_loss: 0.6982 - val_accuracy: 0.8056\n",
            "Epoch 300/700\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0581 - accuracy: 0.9792 - val_loss: 0.5100 - val_accuracy: 0.7778\n",
            "Epoch 301/700\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0626 - accuracy: 0.9826 - val_loss: 0.9160 - val_accuracy: 0.7778\n",
            "Epoch 302/700\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0590 - accuracy: 0.9783 - val_loss: 0.6550 - val_accuracy: 0.8333\n",
            "Epoch 303/700\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0719 - accuracy: 0.9722 - val_loss: 0.9681 - val_accuracy: 0.7778\n",
            "Epoch 304/700\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0525 - accuracy: 0.9844 - val_loss: 0.7857 - val_accuracy: 0.7778\n",
            "Epoch 305/700\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0545 - accuracy: 0.9818 - val_loss: 0.7939 - val_accuracy: 0.7500\n",
            "Epoch 306/700\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.0687 - accuracy: 0.9731 - val_loss: 0.9824 - val_accuracy: 0.7500\n",
            "Epoch 307/700\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.0578 - accuracy: 0.9774 - val_loss: 0.7181 - val_accuracy: 0.7778\n",
            "Epoch 308/700\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.0590 - accuracy: 0.9766 - val_loss: 0.6536 - val_accuracy: 0.8056\n",
            "Epoch 309/700\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0570 - accuracy: 0.9783 - val_loss: 1.0896 - val_accuracy: 0.7500\n",
            "Epoch 310/700\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.0621 - accuracy: 0.9766 - val_loss: 0.8300 - val_accuracy: 0.7500\n",
            "Epoch 311/700\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.0501 - accuracy: 0.9826 - val_loss: 0.9128 - val_accuracy: 0.7222\n",
            "Epoch 312/700\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.0499 - accuracy: 0.9818 - val_loss: 0.6943 - val_accuracy: 0.6944\n",
            "Epoch 313/700\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0656 - accuracy: 0.9696 - val_loss: 0.5897 - val_accuracy: 0.7500\n",
            "Epoch 314/700\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0618 - accuracy: 0.9774 - val_loss: 0.6420 - val_accuracy: 0.7500\n",
            "Epoch 315/700\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0402 - accuracy: 0.9905 - val_loss: 0.5532 - val_accuracy: 0.7778\n",
            "Epoch 316/700\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0430 - accuracy: 0.9896 - val_loss: 0.6602 - val_accuracy: 0.7500\n",
            "Epoch 317/700\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0567 - accuracy: 0.9818 - val_loss: 0.8361 - val_accuracy: 0.7778\n",
            "Epoch 318/700\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.0404 - accuracy: 0.9870 - val_loss: 0.9210 - val_accuracy: 0.7222\n",
            "Epoch 319/700\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0524 - accuracy: 0.9800 - val_loss: 0.8089 - val_accuracy: 0.7778\n",
            "Epoch 320/700\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0539 - accuracy: 0.9826 - val_loss: 1.1265 - val_accuracy: 0.7222\n",
            "Epoch 321/700\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.0673 - accuracy: 0.9792 - val_loss: 1.2695 - val_accuracy: 0.7500\n",
            "Epoch 322/700\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.0663 - accuracy: 0.9740 - val_loss: 0.8018 - val_accuracy: 0.7500\n",
            "Epoch 323/700\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.0492 - accuracy: 0.9835 - val_loss: 0.7998 - val_accuracy: 0.7500\n",
            "Epoch 324/700\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0596 - accuracy: 0.9774 - val_loss: 0.8056 - val_accuracy: 0.7778\n",
            "Epoch 325/700\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0489 - accuracy: 0.9818 - val_loss: 0.5390 - val_accuracy: 0.7778\n",
            "Epoch 326/700\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0415 - accuracy: 0.9878 - val_loss: 0.6667 - val_accuracy: 0.7778\n",
            "Epoch 327/700\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0493 - accuracy: 0.9887 - val_loss: 0.5587 - val_accuracy: 0.8056\n",
            "Epoch 328/700\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0693 - accuracy: 0.9740 - val_loss: 0.9757 - val_accuracy: 0.7500\n",
            "Epoch 329/700\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.0563 - accuracy: 0.9800 - val_loss: 0.9634 - val_accuracy: 0.7778\n",
            "Epoch 330/700\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.0470 - accuracy: 0.9818 - val_loss: 0.7046 - val_accuracy: 0.7222\n",
            "Epoch 331/700\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.0553 - accuracy: 0.9826 - val_loss: 0.6277 - val_accuracy: 0.8333\n",
            "Epoch 332/700\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.0283 - accuracy: 0.9896 - val_loss: 0.8780 - val_accuracy: 0.7500\n",
            "Epoch 333/700\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.0525 - accuracy: 0.9809 - val_loss: 0.8146 - val_accuracy: 0.7778\n",
            "Epoch 334/700\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.0497 - accuracy: 0.9818 - val_loss: 0.7900 - val_accuracy: 0.7778\n",
            "Epoch 335/700\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0592 - accuracy: 0.9748 - val_loss: 0.7263 - val_accuracy: 0.8056\n",
            "Epoch 336/700\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0425 - accuracy: 0.9852 - val_loss: 0.8292 - val_accuracy: 0.7778\n",
            "Epoch 337/700\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.0351 - accuracy: 0.9870 - val_loss: 0.7665 - val_accuracy: 0.7500\n",
            "Epoch 338/700\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.0600 - accuracy: 0.9766 - val_loss: 0.8410 - val_accuracy: 0.7500\n",
            "Epoch 339/700\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.0418 - accuracy: 0.9852 - val_loss: 0.9546 - val_accuracy: 0.7778\n",
            "Epoch 340/700\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0524 - accuracy: 0.9826 - val_loss: 0.6932 - val_accuracy: 0.8056\n",
            "Epoch 341/700\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0688 - accuracy: 0.9792 - val_loss: 0.7962 - val_accuracy: 0.7778\n",
            "Epoch 342/700\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0533 - accuracy: 0.9826 - val_loss: 0.9633 - val_accuracy: 0.7778\n",
            "Epoch 343/700\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0346 - accuracy: 0.9826 - val_loss: 0.7508 - val_accuracy: 0.7222\n",
            "Epoch 344/700\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0665 - accuracy: 0.9740 - val_loss: 0.7929 - val_accuracy: 0.7500\n",
            "Epoch 345/700\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0512 - accuracy: 0.9826 - val_loss: 0.8741 - val_accuracy: 0.7778\n",
            "Epoch 346/700\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0588 - accuracy: 0.9766 - val_loss: 1.2157 - val_accuracy: 0.7500\n",
            "Epoch 347/700\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0538 - accuracy: 0.9818 - val_loss: 0.8513 - val_accuracy: 0.7500\n",
            "Epoch 348/700\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0433 - accuracy: 0.9887 - val_loss: 0.8283 - val_accuracy: 0.7500\n",
            "Epoch 349/700\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0399 - accuracy: 0.9878 - val_loss: 0.6793 - val_accuracy: 0.8056\n",
            "Epoch 350/700\n",
            "72/72 [==============================] - 2s 22ms/step - loss: 0.0550 - accuracy: 0.9809 - val_loss: 0.7677 - val_accuracy: 0.7778\n",
            "Epoch 351/700\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0444 - accuracy: 0.9852 - val_loss: 0.8690 - val_accuracy: 0.7500\n",
            "Epoch 352/700\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0354 - accuracy: 0.9896 - val_loss: 0.9087 - val_accuracy: 0.7500\n",
            "Epoch 353/700\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0430 - accuracy: 0.9844 - val_loss: 0.9735 - val_accuracy: 0.7500\n",
            "Epoch 354/700\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0339 - accuracy: 0.9878 - val_loss: 0.7874 - val_accuracy: 0.8056\n",
            "Epoch 355/700\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0809 - accuracy: 0.9740 - val_loss: 0.9967 - val_accuracy: 0.7500\n",
            "Epoch 356/700\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0541 - accuracy: 0.9826 - val_loss: 0.6642 - val_accuracy: 0.8056\n",
            "Epoch 357/700\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0359 - accuracy: 0.9922 - val_loss: 0.7066 - val_accuracy: 0.7778\n",
            "Epoch 358/700\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0453 - accuracy: 0.9870 - val_loss: 0.6656 - val_accuracy: 0.8333\n",
            "Epoch 359/700\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0431 - accuracy: 0.9861 - val_loss: 0.5279 - val_accuracy: 0.8611\n",
            "Epoch 360/700\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0436 - accuracy: 0.9852 - val_loss: 0.9059 - val_accuracy: 0.7500\n",
            "Epoch 361/700\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.0430 - accuracy: 0.9870 - val_loss: 0.7744 - val_accuracy: 0.8056\n",
            "Epoch 362/700\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0382 - accuracy: 0.9870 - val_loss: 0.8092 - val_accuracy: 0.8056\n",
            "Epoch 363/700\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.0355 - accuracy: 0.9887 - val_loss: 0.6343 - val_accuracy: 0.8333\n",
            "Epoch 364/700\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0366 - accuracy: 0.9844 - val_loss: 0.8462 - val_accuracy: 0.7778\n",
            "Epoch 365/700\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.0350 - accuracy: 0.9870 - val_loss: 0.9591 - val_accuracy: 0.7500\n",
            "Epoch 366/700\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.0347 - accuracy: 0.9913 - val_loss: 0.8831 - val_accuracy: 0.7500\n",
            "Epoch 367/700\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.0431 - accuracy: 0.9861 - val_loss: 1.1337 - val_accuracy: 0.7222\n",
            "Epoch 368/700\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0470 - accuracy: 0.9818 - val_loss: 1.0629 - val_accuracy: 0.7500\n",
            "Epoch 369/700\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0280 - accuracy: 0.9939 - val_loss: 0.9916 - val_accuracy: 0.7500\n",
            "Epoch 370/700\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0433 - accuracy: 0.9905 - val_loss: 1.0199 - val_accuracy: 0.7778\n",
            "Epoch 371/700\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0287 - accuracy: 0.9905 - val_loss: 1.0827 - val_accuracy: 0.8056\n",
            "Epoch 372/700\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0327 - accuracy: 0.9896 - val_loss: 0.8164 - val_accuracy: 0.8333\n",
            "Epoch 373/700\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0414 - accuracy: 0.9844 - val_loss: 0.9214 - val_accuracy: 0.7778\n",
            "Epoch 374/700\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0440 - accuracy: 0.9852 - val_loss: 0.6901 - val_accuracy: 0.8056\n",
            "Epoch 375/700\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0372 - accuracy: 0.9861 - val_loss: 0.7641 - val_accuracy: 0.8333\n",
            "Epoch 376/700\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0534 - accuracy: 0.9809 - val_loss: 0.8036 - val_accuracy: 0.7778\n",
            "Epoch 377/700\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0554 - accuracy: 0.9783 - val_loss: 0.9148 - val_accuracy: 0.7222\n",
            "Epoch 378/700\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0304 - accuracy: 0.9878 - val_loss: 0.9756 - val_accuracy: 0.7222\n",
            "Epoch 379/700\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0431 - accuracy: 0.9800 - val_loss: 0.9708 - val_accuracy: 0.7778\n",
            "Epoch 380/700\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0365 - accuracy: 0.9861 - val_loss: 1.1731 - val_accuracy: 0.7222\n",
            "Epoch 381/700\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0468 - accuracy: 0.9852 - val_loss: 0.8704 - val_accuracy: 0.7222\n",
            "Epoch 382/700\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0333 - accuracy: 0.9887 - val_loss: 0.6486 - val_accuracy: 0.8056\n",
            "Epoch 383/700\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0347 - accuracy: 0.9878 - val_loss: 1.1211 - val_accuracy: 0.7500\n",
            "Epoch 384/700\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0499 - accuracy: 0.9826 - val_loss: 0.9655 - val_accuracy: 0.7222\n",
            "Epoch 385/700\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.0418 - accuracy: 0.9844 - val_loss: 1.0211 - val_accuracy: 0.7500\n",
            "Epoch 386/700\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0414 - accuracy: 0.9887 - val_loss: 0.6713 - val_accuracy: 0.8333\n",
            "Epoch 387/700\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0493 - accuracy: 0.9878 - val_loss: 0.8370 - val_accuracy: 0.8056\n",
            "Epoch 388/700\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0437 - accuracy: 0.9861 - val_loss: 0.7304 - val_accuracy: 0.7778\n",
            "Epoch 389/700\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0499 - accuracy: 0.9835 - val_loss: 1.0155 - val_accuracy: 0.7500\n",
            "Epoch 390/700\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0425 - accuracy: 0.9861 - val_loss: 0.6915 - val_accuracy: 0.8333\n",
            "Epoch 391/700\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0440 - accuracy: 0.9861 - val_loss: 0.6263 - val_accuracy: 0.8333\n",
            "Epoch 392/700\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0370 - accuracy: 0.9852 - val_loss: 0.9021 - val_accuracy: 0.7778\n",
            "Epoch 393/700\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.0357 - accuracy: 0.9861 - val_loss: 0.7733 - val_accuracy: 0.8056\n",
            "Epoch 394/700\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.0320 - accuracy: 0.9896 - val_loss: 1.0546 - val_accuracy: 0.7778\n",
            "Epoch 395/700\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0411 - accuracy: 0.9878 - val_loss: 1.2570 - val_accuracy: 0.7778\n",
            "Epoch 396/700\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0274 - accuracy: 0.9887 - val_loss: 0.7938 - val_accuracy: 0.7778\n",
            "Epoch 397/700\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0486 - accuracy: 0.9835 - val_loss: 0.9109 - val_accuracy: 0.7222\n",
            "Epoch 398/700\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0496 - accuracy: 0.9800 - val_loss: 1.0114 - val_accuracy: 0.7500\n",
            "Epoch 399/700\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0392 - accuracy: 0.9870 - val_loss: 0.8292 - val_accuracy: 0.8056\n",
            "Epoch 400/700\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0349 - accuracy: 0.9887 - val_loss: 1.0110 - val_accuracy: 0.7500\n",
            "Epoch 401/700\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0346 - accuracy: 0.9878 - val_loss: 0.8266 - val_accuracy: 0.7778\n",
            "Epoch 402/700\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0312 - accuracy: 0.9913 - val_loss: 0.9849 - val_accuracy: 0.7778\n",
            "Epoch 403/700\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0321 - accuracy: 0.9887 - val_loss: 0.8876 - val_accuracy: 0.7500\n",
            "Epoch 404/700\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0442 - accuracy: 0.9844 - val_loss: 0.7304 - val_accuracy: 0.8056\n",
            "Epoch 405/700\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0419 - accuracy: 0.9844 - val_loss: 0.8573 - val_accuracy: 0.8056\n",
            "Epoch 406/700\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0401 - accuracy: 0.9852 - val_loss: 0.9341 - val_accuracy: 0.7500\n",
            "Epoch 407/700\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0262 - accuracy: 0.9913 - val_loss: 0.8817 - val_accuracy: 0.7500\n",
            "Epoch 408/700\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0449 - accuracy: 0.9887 - val_loss: 0.8081 - val_accuracy: 0.7778\n",
            "Epoch 409/700\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.0302 - accuracy: 0.9913 - val_loss: 0.9114 - val_accuracy: 0.7500\n",
            "Epoch 410/700\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0348 - accuracy: 0.9922 - val_loss: 0.8498 - val_accuracy: 0.8056\n",
            "Epoch 411/700\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0441 - accuracy: 0.9870 - val_loss: 0.9300 - val_accuracy: 0.7778\n",
            "Epoch 412/700\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0337 - accuracy: 0.9896 - val_loss: 0.9255 - val_accuracy: 0.7778\n",
            "Epoch 413/700\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0269 - accuracy: 0.9922 - val_loss: 0.9435 - val_accuracy: 0.8056\n",
            "Epoch 414/700\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0384 - accuracy: 0.9852 - val_loss: 0.9420 - val_accuracy: 0.7500\n",
            "Epoch 415/700\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0437 - accuracy: 0.9852 - val_loss: 0.9426 - val_accuracy: 0.7778\n",
            "Epoch 416/700\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0226 - accuracy: 0.9905 - val_loss: 0.7572 - val_accuracy: 0.8056\n",
            "Epoch 417/700\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0374 - accuracy: 0.9870 - val_loss: 0.5751 - val_accuracy: 0.8333\n",
            "Epoch 418/700\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0293 - accuracy: 0.9939 - val_loss: 0.6969 - val_accuracy: 0.8056\n",
            "Epoch 419/700\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0275 - accuracy: 0.9878 - val_loss: 0.7153 - val_accuracy: 0.7778\n",
            "Epoch 420/700\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0213 - accuracy: 0.9922 - val_loss: 0.8526 - val_accuracy: 0.7778\n",
            "Epoch 421/700\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0302 - accuracy: 0.9913 - val_loss: 0.7829 - val_accuracy: 0.7778\n",
            "Epoch 422/700\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0343 - accuracy: 0.9896 - val_loss: 1.0542 - val_accuracy: 0.7500\n",
            "Epoch 423/700\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0397 - accuracy: 0.9870 - val_loss: 1.1491 - val_accuracy: 0.7500\n",
            "Epoch 424/700\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0370 - accuracy: 0.9887 - val_loss: 0.9777 - val_accuracy: 0.7500\n",
            "Epoch 425/700\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0560 - accuracy: 0.9870 - val_loss: 1.0538 - val_accuracy: 0.7500\n",
            "Epoch 426/700\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0297 - accuracy: 0.9905 - val_loss: 0.8254 - val_accuracy: 0.8056\n",
            "Epoch 427/700\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0383 - accuracy: 0.9870 - val_loss: 1.0727 - val_accuracy: 0.7222\n",
            "Epoch 428/700\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0324 - accuracy: 0.9835 - val_loss: 0.8997 - val_accuracy: 0.7778\n",
            "Epoch 429/700\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0421 - accuracy: 0.9861 - val_loss: 1.2943 - val_accuracy: 0.7778\n",
            "Epoch 430/700\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0357 - accuracy: 0.9896 - val_loss: 0.8439 - val_accuracy: 0.8056\n",
            "Epoch 431/700\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0262 - accuracy: 0.9931 - val_loss: 0.8438 - val_accuracy: 0.7778\n",
            "Epoch 432/700\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0301 - accuracy: 0.9896 - val_loss: 1.2511 - val_accuracy: 0.7778\n",
            "Epoch 433/700\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0426 - accuracy: 0.9870 - val_loss: 1.0510 - val_accuracy: 0.7778\n",
            "Epoch 434/700\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0312 - accuracy: 0.9887 - val_loss: 0.7849 - val_accuracy: 0.8333\n",
            "Epoch 435/700\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0279 - accuracy: 0.9905 - val_loss: 0.7857 - val_accuracy: 0.7778\n",
            "Epoch 436/700\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0283 - accuracy: 0.9922 - val_loss: 0.9612 - val_accuracy: 0.8056\n",
            "Epoch 437/700\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0368 - accuracy: 0.9913 - val_loss: 1.0806 - val_accuracy: 0.7778\n",
            "Epoch 438/700\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0346 - accuracy: 0.9878 - val_loss: 0.8650 - val_accuracy: 0.7778\n",
            "Epoch 439/700\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0172 - accuracy: 0.9939 - val_loss: 1.1776 - val_accuracy: 0.7500\n",
            "Epoch 440/700\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.0234 - accuracy: 0.9922 - val_loss: 1.1795 - val_accuracy: 0.7500\n",
            "Epoch 441/700\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0258 - accuracy: 0.9905 - val_loss: 0.8289 - val_accuracy: 0.8056\n",
            "Epoch 442/700\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0278 - accuracy: 0.9905 - val_loss: 0.9826 - val_accuracy: 0.7778\n",
            "Epoch 443/700\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0256 - accuracy: 0.9922 - val_loss: 0.9702 - val_accuracy: 0.8056\n",
            "Epoch 444/700\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0427 - accuracy: 0.9835 - val_loss: 0.8120 - val_accuracy: 0.8056\n",
            "Epoch 445/700\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0518 - accuracy: 0.9818 - val_loss: 0.9371 - val_accuracy: 0.7778\n",
            "Epoch 446/700\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0384 - accuracy: 0.9852 - val_loss: 0.7182 - val_accuracy: 0.8056\n",
            "Epoch 447/700\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0229 - accuracy: 0.9896 - val_loss: 0.8540 - val_accuracy: 0.8056\n",
            "Epoch 448/700\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0430 - accuracy: 0.9844 - val_loss: 1.4114 - val_accuracy: 0.7500\n",
            "Epoch 449/700\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0228 - accuracy: 0.9905 - val_loss: 1.0236 - val_accuracy: 0.7778\n",
            "Epoch 450/700\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0320 - accuracy: 0.9896 - val_loss: 1.2928 - val_accuracy: 0.7778\n",
            "Epoch 451/700\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0154 - accuracy: 0.9948 - val_loss: 0.9502 - val_accuracy: 0.7778\n",
            "Epoch 452/700\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0338 - accuracy: 0.9870 - val_loss: 0.9262 - val_accuracy: 0.7500\n",
            "Epoch 453/700\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0314 - accuracy: 0.9939 - val_loss: 1.0072 - val_accuracy: 0.7500\n",
            "Epoch 454/700\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0286 - accuracy: 0.9870 - val_loss: 1.1246 - val_accuracy: 0.7778\n",
            "Epoch 455/700\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0269 - accuracy: 0.9896 - val_loss: 1.2443 - val_accuracy: 0.7778\n",
            "Epoch 456/700\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.0226 - accuracy: 0.9913 - val_loss: 0.8114 - val_accuracy: 0.8611\n",
            "Epoch 457/700\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0283 - accuracy: 0.9870 - val_loss: 1.0243 - val_accuracy: 0.8056\n",
            "Epoch 458/700\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0375 - accuracy: 0.9852 - val_loss: 1.0452 - val_accuracy: 0.7500\n",
            "Epoch 459/700\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0218 - accuracy: 0.9931 - val_loss: 1.2329 - val_accuracy: 0.7500\n",
            "Epoch 460/700\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0270 - accuracy: 0.9931 - val_loss: 0.9547 - val_accuracy: 0.7778\n",
            "Epoch 461/700\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0299 - accuracy: 0.9913 - val_loss: 1.1033 - val_accuracy: 0.7778\n",
            "Epoch 462/700\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.0267 - accuracy: 0.9878 - val_loss: 1.4535 - val_accuracy: 0.7500\n",
            "Epoch 463/700\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0341 - accuracy: 0.9878 - val_loss: 0.8937 - val_accuracy: 0.7500\n",
            "Epoch 464/700\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0280 - accuracy: 0.9922 - val_loss: 0.7859 - val_accuracy: 0.8056\n",
            "Epoch 465/700\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0199 - accuracy: 0.9931 - val_loss: 1.2100 - val_accuracy: 0.7500\n",
            "Epoch 466/700\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0294 - accuracy: 0.9896 - val_loss: 0.6357 - val_accuracy: 0.8056\n",
            "Epoch 467/700\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0313 - accuracy: 0.9905 - val_loss: 0.9919 - val_accuracy: 0.7778\n",
            "Epoch 468/700\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0285 - accuracy: 0.9905 - val_loss: 0.8883 - val_accuracy: 0.7778\n",
            "Epoch 469/700\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0332 - accuracy: 0.9905 - val_loss: 1.1471 - val_accuracy: 0.7500\n",
            "Epoch 470/700\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0297 - accuracy: 0.9913 - val_loss: 0.8278 - val_accuracy: 0.8056\n",
            "Epoch 471/700\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0450 - accuracy: 0.9852 - val_loss: 0.7407 - val_accuracy: 0.8333\n",
            "Epoch 472/700\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0391 - accuracy: 0.9870 - val_loss: 1.1117 - val_accuracy: 0.7500\n",
            "Epoch 473/700\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0200 - accuracy: 0.9939 - val_loss: 0.8841 - val_accuracy: 0.8333\n",
            "Epoch 474/700\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0257 - accuracy: 0.9913 - val_loss: 0.7883 - val_accuracy: 0.8333\n",
            "Epoch 475/700\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0435 - accuracy: 0.9835 - val_loss: 1.2086 - val_accuracy: 0.7500\n",
            "Epoch 476/700\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0295 - accuracy: 0.9896 - val_loss: 1.0451 - val_accuracy: 0.7500\n",
            "Epoch 477/700\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0302 - accuracy: 0.9913 - val_loss: 0.7715 - val_accuracy: 0.7778\n",
            "Epoch 478/700\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0294 - accuracy: 0.9896 - val_loss: 1.0877 - val_accuracy: 0.7222\n",
            "Epoch 479/700\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0224 - accuracy: 0.9905 - val_loss: 0.8823 - val_accuracy: 0.7500\n",
            "Epoch 480/700\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0169 - accuracy: 0.9948 - val_loss: 1.0234 - val_accuracy: 0.7500\n",
            "Epoch 481/700\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0359 - accuracy: 0.9905 - val_loss: 0.8801 - val_accuracy: 0.7778\n",
            "Epoch 482/700\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0270 - accuracy: 0.9887 - val_loss: 0.8205 - val_accuracy: 0.7778\n",
            "Epoch 483/700\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0166 - accuracy: 0.9957 - val_loss: 1.0661 - val_accuracy: 0.7500\n",
            "Epoch 484/700\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0281 - accuracy: 0.9896 - val_loss: 1.4024 - val_accuracy: 0.7500\n",
            "Epoch 485/700\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0261 - accuracy: 0.9939 - val_loss: 0.9366 - val_accuracy: 0.7500\n",
            "Epoch 486/700\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0297 - accuracy: 0.9931 - val_loss: 1.0041 - val_accuracy: 0.7778\n",
            "Epoch 487/700\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0212 - accuracy: 0.9939 - val_loss: 1.3262 - val_accuracy: 0.7500\n",
            "Epoch 488/700\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0309 - accuracy: 0.9913 - val_loss: 1.1285 - val_accuracy: 0.7500\n",
            "Epoch 489/700\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0248 - accuracy: 0.9922 - val_loss: 1.0072 - val_accuracy: 0.7778\n",
            "Epoch 490/700\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0284 - accuracy: 0.9931 - val_loss: 0.6666 - val_accuracy: 0.8333\n",
            "Epoch 491/700\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.0267 - accuracy: 0.9922 - val_loss: 0.8052 - val_accuracy: 0.7778\n",
            "Epoch 492/700\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0329 - accuracy: 0.9896 - val_loss: 1.2654 - val_accuracy: 0.7500\n",
            "Epoch 493/700\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0413 - accuracy: 0.9852 - val_loss: 0.8350 - val_accuracy: 0.8056\n",
            "Epoch 494/700\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0259 - accuracy: 0.9896 - val_loss: 0.8929 - val_accuracy: 0.7778\n",
            "Epoch 495/700\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0497 - accuracy: 0.9852 - val_loss: 0.6585 - val_accuracy: 0.8889\n",
            "Epoch 496/700\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0187 - accuracy: 0.9931 - val_loss: 0.7424 - val_accuracy: 0.8333\n",
            "Epoch 497/700\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0159 - accuracy: 0.9939 - val_loss: 1.0274 - val_accuracy: 0.7778\n",
            "Epoch 498/700\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0300 - accuracy: 0.9896 - val_loss: 1.2060 - val_accuracy: 0.7778\n",
            "Epoch 499/700\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.0281 - accuracy: 0.9905 - val_loss: 0.8152 - val_accuracy: 0.8056\n",
            "Epoch 500/700\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0216 - accuracy: 0.9922 - val_loss: 0.9661 - val_accuracy: 0.7500\n",
            "Epoch 501/700\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0256 - accuracy: 0.9887 - val_loss: 0.9655 - val_accuracy: 0.7778\n",
            "Epoch 502/700\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0331 - accuracy: 0.9922 - val_loss: 0.9668 - val_accuracy: 0.8056\n",
            "Epoch 503/700\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0315 - accuracy: 0.9931 - val_loss: 1.1725 - val_accuracy: 0.7500\n",
            "Epoch 504/700\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0233 - accuracy: 0.9931 - val_loss: 0.9796 - val_accuracy: 0.7778\n",
            "Epoch 505/700\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0240 - accuracy: 0.9948 - val_loss: 1.2065 - val_accuracy: 0.7500\n",
            "Epoch 506/700\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0252 - accuracy: 0.9896 - val_loss: 0.7343 - val_accuracy: 0.8333\n",
            "Epoch 507/700\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0270 - accuracy: 0.9896 - val_loss: 0.8433 - val_accuracy: 0.8056\n",
            "Epoch 508/700\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0206 - accuracy: 0.9913 - val_loss: 1.2300 - val_accuracy: 0.7500\n",
            "Epoch 509/700\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0267 - accuracy: 0.9931 - val_loss: 1.1322 - val_accuracy: 0.7500\n",
            "Epoch 510/700\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0284 - accuracy: 0.9922 - val_loss: 0.7905 - val_accuracy: 0.8056\n",
            "Epoch 511/700\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0196 - accuracy: 0.9931 - val_loss: 1.0461 - val_accuracy: 0.7500\n",
            "Epoch 512/700\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0317 - accuracy: 0.9922 - val_loss: 1.0954 - val_accuracy: 0.7500\n",
            "Epoch 513/700\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0334 - accuracy: 0.9870 - val_loss: 1.0032 - val_accuracy: 0.7778\n",
            "Epoch 514/700\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0136 - accuracy: 0.9957 - val_loss: 1.0038 - val_accuracy: 0.7778\n",
            "Epoch 515/700\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0272 - accuracy: 0.9913 - val_loss: 0.8090 - val_accuracy: 0.8333\n",
            "Epoch 516/700\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0147 - accuracy: 0.9948 - val_loss: 1.1352 - val_accuracy: 0.7778\n",
            "Epoch 517/700\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0257 - accuracy: 0.9913 - val_loss: 0.8138 - val_accuracy: 0.8056\n",
            "Epoch 518/700\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0176 - accuracy: 0.9957 - val_loss: 0.9947 - val_accuracy: 0.8056\n",
            "Epoch 519/700\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0221 - accuracy: 0.9913 - val_loss: 0.9663 - val_accuracy: 0.8056\n",
            "Epoch 520/700\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0306 - accuracy: 0.9896 - val_loss: 0.7304 - val_accuracy: 0.8056\n",
            "Epoch 521/700\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0326 - accuracy: 0.9887 - val_loss: 0.8067 - val_accuracy: 0.8333\n",
            "Epoch 522/700\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0340 - accuracy: 0.9887 - val_loss: 0.9659 - val_accuracy: 0.7778\n",
            "Epoch 523/700\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0267 - accuracy: 0.9922 - val_loss: 0.8609 - val_accuracy: 0.8056\n",
            "Epoch 524/700\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0247 - accuracy: 0.9922 - val_loss: 0.9449 - val_accuracy: 0.7778\n",
            "Epoch 525/700\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0119 - accuracy: 0.9965 - val_loss: 1.0668 - val_accuracy: 0.7778\n",
            "Epoch 526/700\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0156 - accuracy: 0.9948 - val_loss: 0.7649 - val_accuracy: 0.8056\n",
            "Epoch 527/700\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0203 - accuracy: 0.9931 - val_loss: 1.3709 - val_accuracy: 0.7500\n",
            "Epoch 528/700\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0277 - accuracy: 0.9905 - val_loss: 1.2797 - val_accuracy: 0.7778\n",
            "Epoch 529/700\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0260 - accuracy: 0.9913 - val_loss: 1.1177 - val_accuracy: 0.7778\n",
            "Epoch 530/700\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0100 - accuracy: 0.9983 - val_loss: 0.9405 - val_accuracy: 0.7778\n",
            "Epoch 531/700\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0174 - accuracy: 0.9974 - val_loss: 0.9870 - val_accuracy: 0.7778\n",
            "Epoch 532/700\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0304 - accuracy: 0.9887 - val_loss: 1.1916 - val_accuracy: 0.7778\n",
            "Epoch 533/700\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0236 - accuracy: 0.9922 - val_loss: 0.8971 - val_accuracy: 0.7778\n",
            "Epoch 534/700\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0299 - accuracy: 0.9905 - val_loss: 0.9688 - val_accuracy: 0.7778\n",
            "Epoch 535/700\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0221 - accuracy: 0.9922 - val_loss: 1.0550 - val_accuracy: 0.7500\n",
            "Epoch 536/700\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0190 - accuracy: 0.9931 - val_loss: 0.5480 - val_accuracy: 0.8333\n",
            "Epoch 537/700\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0301 - accuracy: 0.9913 - val_loss: 0.7015 - val_accuracy: 0.8611\n",
            "Epoch 538/700\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0167 - accuracy: 0.9974 - val_loss: 0.8862 - val_accuracy: 0.8056\n",
            "Epoch 539/700\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0207 - accuracy: 0.9922 - val_loss: 0.9630 - val_accuracy: 0.7778\n",
            "Epoch 540/700\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0227 - accuracy: 0.9922 - val_loss: 1.0586 - val_accuracy: 0.7778\n",
            "Epoch 541/700\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0321 - accuracy: 0.9931 - val_loss: 0.9234 - val_accuracy: 0.7778\n",
            "Epoch 542/700\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0139 - accuracy: 0.9965 - val_loss: 1.2467 - val_accuracy: 0.7500\n",
            "Epoch 543/700\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0461 - accuracy: 0.9844 - val_loss: 1.1063 - val_accuracy: 0.8056\n",
            "Epoch 544/700\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0243 - accuracy: 0.9948 - val_loss: 0.8969 - val_accuracy: 0.8333\n",
            "Epoch 545/700\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0249 - accuracy: 0.9913 - val_loss: 0.8433 - val_accuracy: 0.8056\n",
            "Epoch 546/700\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0199 - accuracy: 0.9922 - val_loss: 0.7103 - val_accuracy: 0.8056\n",
            "Epoch 547/700\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0254 - accuracy: 0.9913 - val_loss: 0.7935 - val_accuracy: 0.7778\n",
            "Epoch 548/700\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0214 - accuracy: 0.9931 - val_loss: 0.8439 - val_accuracy: 0.8056\n",
            "Epoch 549/700\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0181 - accuracy: 0.9939 - val_loss: 0.8317 - val_accuracy: 0.8333\n",
            "Epoch 550/700\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0325 - accuracy: 0.9905 - val_loss: 0.7772 - val_accuracy: 0.8333\n",
            "Epoch 551/700\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0385 - accuracy: 0.9878 - val_loss: 0.7806 - val_accuracy: 0.8056\n",
            "Epoch 552/700\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0202 - accuracy: 0.9922 - val_loss: 0.8108 - val_accuracy: 0.8333\n",
            "Epoch 553/700\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0521 - accuracy: 0.9861 - val_loss: 0.9801 - val_accuracy: 0.7778\n",
            "Epoch 554/700\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0186 - accuracy: 0.9948 - val_loss: 0.9125 - val_accuracy: 0.7778\n",
            "Epoch 555/700\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0189 - accuracy: 0.9948 - val_loss: 1.1363 - val_accuracy: 0.7500\n",
            "Epoch 556/700\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0276 - accuracy: 0.9905 - val_loss: 1.3688 - val_accuracy: 0.7500\n",
            "Epoch 557/700\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0303 - accuracy: 0.9896 - val_loss: 1.0521 - val_accuracy: 0.7778\n",
            "Epoch 558/700\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0259 - accuracy: 0.9887 - val_loss: 1.1770 - val_accuracy: 0.7500\n",
            "Epoch 559/700\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0289 - accuracy: 0.9887 - val_loss: 1.2731 - val_accuracy: 0.7500\n",
            "Epoch 560/700\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0262 - accuracy: 0.9939 - val_loss: 0.8483 - val_accuracy: 0.7778\n",
            "Epoch 561/700\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0277 - accuracy: 0.9878 - val_loss: 0.6954 - val_accuracy: 0.8333\n",
            "Epoch 562/700\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0260 - accuracy: 0.9913 - val_loss: 0.6135 - val_accuracy: 0.8333\n",
            "Epoch 563/700\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0279 - accuracy: 0.9896 - val_loss: 0.7068 - val_accuracy: 0.7778\n",
            "Epoch 564/700\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0227 - accuracy: 0.9931 - val_loss: 1.0330 - val_accuracy: 0.7778\n",
            "Epoch 565/700\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0267 - accuracy: 0.9922 - val_loss: 0.9086 - val_accuracy: 0.8056\n",
            "Epoch 566/700\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0205 - accuracy: 0.9922 - val_loss: 1.0181 - val_accuracy: 0.7778\n",
            "Epoch 567/700\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0233 - accuracy: 0.9913 - val_loss: 1.2589 - val_accuracy: 0.7500\n",
            "Epoch 568/700\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0351 - accuracy: 0.9852 - val_loss: 1.2230 - val_accuracy: 0.7500\n",
            "Epoch 569/700\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0243 - accuracy: 0.9931 - val_loss: 0.8921 - val_accuracy: 0.8333\n",
            "Epoch 570/700\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0149 - accuracy: 0.9948 - val_loss: 0.9991 - val_accuracy: 0.8056\n",
            "Epoch 571/700\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0146 - accuracy: 0.9957 - val_loss: 1.0611 - val_accuracy: 0.7778\n",
            "Epoch 572/700\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0159 - accuracy: 0.9913 - val_loss: 0.9442 - val_accuracy: 0.8056\n",
            "Epoch 573/700\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.0319 - accuracy: 0.9931 - val_loss: 1.1239 - val_accuracy: 0.7500\n",
            "Epoch 574/700\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.0195 - accuracy: 0.9948 - val_loss: 0.8993 - val_accuracy: 0.8056\n",
            "Epoch 575/700\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.0240 - accuracy: 0.9913 - val_loss: 0.7993 - val_accuracy: 0.8056\n",
            "Epoch 576/700\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0221 - accuracy: 0.9913 - val_loss: 1.0836 - val_accuracy: 0.7778\n",
            "Epoch 577/700\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0301 - accuracy: 0.9913 - val_loss: 0.7423 - val_accuracy: 0.8056\n",
            "Epoch 578/700\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0127 - accuracy: 0.9957 - val_loss: 1.0547 - val_accuracy: 0.7500\n",
            "Epoch 579/700\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.0203 - accuracy: 0.9913 - val_loss: 1.0108 - val_accuracy: 0.7500\n",
            "Epoch 580/700\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.0306 - accuracy: 0.9878 - val_loss: 1.0175 - val_accuracy: 0.7778\n",
            "Epoch 581/700\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.0214 - accuracy: 0.9922 - val_loss: 1.3316 - val_accuracy: 0.7500\n",
            "Epoch 582/700\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.0241 - accuracy: 0.9913 - val_loss: 0.8855 - val_accuracy: 0.8056\n",
            "Epoch 583/700\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.0145 - accuracy: 0.9965 - val_loss: 1.2383 - val_accuracy: 0.7222\n",
            "Epoch 584/700\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.0169 - accuracy: 0.9948 - val_loss: 0.9320 - val_accuracy: 0.8056\n",
            "Epoch 585/700\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.0142 - accuracy: 0.9965 - val_loss: 1.2481 - val_accuracy: 0.7778\n",
            "Epoch 586/700\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.0359 - accuracy: 0.9870 - val_loss: 1.0371 - val_accuracy: 0.8056\n",
            "Epoch 587/700\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0164 - accuracy: 0.9922 - val_loss: 1.1966 - val_accuracy: 0.7778\n",
            "Epoch 588/700\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0124 - accuracy: 0.9957 - val_loss: 1.2317 - val_accuracy: 0.7500\n",
            "Epoch 589/700\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0130 - accuracy: 0.9957 - val_loss: 1.4079 - val_accuracy: 0.7500\n",
            "Epoch 590/700\n",
            "72/72 [==============================] - 1s 17ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 1.1037 - val_accuracy: 0.8056\n",
            "Epoch 591/700\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0127 - accuracy: 0.9957 - val_loss: 1.1725 - val_accuracy: 0.7778\n",
            "Epoch 592/700\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0262 - accuracy: 0.9922 - val_loss: 1.1647 - val_accuracy: 0.7500\n",
            "Epoch 593/700\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0261 - accuracy: 0.9922 - val_loss: 1.0545 - val_accuracy: 0.7778\n",
            "Epoch 594/700\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0100 - accuracy: 0.9965 - val_loss: 1.0634 - val_accuracy: 0.7778\n",
            "Epoch 595/700\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0318 - accuracy: 0.9896 - val_loss: 1.1722 - val_accuracy: 0.7778\n",
            "Epoch 596/700\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0200 - accuracy: 0.9939 - val_loss: 1.0543 - val_accuracy: 0.8056\n",
            "Epoch 597/700\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0256 - accuracy: 0.9922 - val_loss: 0.9387 - val_accuracy: 0.8056\n",
            "Epoch 598/700\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0237 - accuracy: 0.9922 - val_loss: 0.7917 - val_accuracy: 0.8333\n",
            "Epoch 599/700\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0225 - accuracy: 0.9939 - val_loss: 1.3901 - val_accuracy: 0.7500\n",
            "Epoch 600/700\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0079 - accuracy: 0.9974 - val_loss: 1.1617 - val_accuracy: 0.7778\n",
            "Epoch 601/700\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0127 - accuracy: 0.9948 - val_loss: 1.0303 - val_accuracy: 0.8056\n",
            "Epoch 602/700\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0068 - accuracy: 0.9991 - val_loss: 1.0333 - val_accuracy: 0.8056\n",
            "Epoch 603/700\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0164 - accuracy: 0.9948 - val_loss: 1.3655 - val_accuracy: 0.7500\n",
            "Epoch 604/700\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0174 - accuracy: 0.9931 - val_loss: 0.9914 - val_accuracy: 0.7778\n",
            "Epoch 605/700\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0211 - accuracy: 0.9939 - val_loss: 1.1731 - val_accuracy: 0.7778\n",
            "Epoch 606/700\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0192 - accuracy: 0.9939 - val_loss: 0.9439 - val_accuracy: 0.8056\n",
            "Epoch 607/700\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0165 - accuracy: 0.9931 - val_loss: 0.9890 - val_accuracy: 0.7778\n",
            "Epoch 608/700\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0092 - accuracy: 0.9991 - val_loss: 1.5030 - val_accuracy: 0.7500\n",
            "Epoch 609/700\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0102 - accuracy: 0.9957 - val_loss: 1.0828 - val_accuracy: 0.8056\n",
            "Epoch 610/700\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0115 - accuracy: 0.9983 - val_loss: 1.0334 - val_accuracy: 0.8056\n",
            "Epoch 611/700\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0192 - accuracy: 0.9922 - val_loss: 1.1489 - val_accuracy: 0.7778\n",
            "Epoch 612/700\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0181 - accuracy: 0.9939 - val_loss: 1.2547 - val_accuracy: 0.7500\n",
            "Epoch 613/700\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0161 - accuracy: 0.9974 - val_loss: 1.3421 - val_accuracy: 0.7500\n",
            "Epoch 614/700\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0124 - accuracy: 0.9974 - val_loss: 1.1702 - val_accuracy: 0.7778\n",
            "Epoch 615/700\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0157 - accuracy: 0.9965 - val_loss: 1.1448 - val_accuracy: 0.8056\n",
            "Epoch 616/700\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0409 - accuracy: 0.9878 - val_loss: 1.3857 - val_accuracy: 0.7222\n",
            "Epoch 617/700\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0138 - accuracy: 0.9948 - val_loss: 1.1834 - val_accuracy: 0.7500\n",
            "Epoch 618/700\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0137 - accuracy: 0.9939 - val_loss: 1.2265 - val_accuracy: 0.7500\n",
            "Epoch 619/700\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0112 - accuracy: 0.9965 - val_loss: 1.3355 - val_accuracy: 0.7222\n",
            "Epoch 620/700\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0136 - accuracy: 0.9957 - val_loss: 1.0643 - val_accuracy: 0.7778\n",
            "Epoch 621/700\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0149 - accuracy: 0.9939 - val_loss: 1.2007 - val_accuracy: 0.7222\n",
            "Epoch 622/700\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0291 - accuracy: 0.9887 - val_loss: 1.7730 - val_accuracy: 0.6944\n",
            "Epoch 623/700\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0208 - accuracy: 0.9948 - val_loss: 1.1454 - val_accuracy: 0.7500\n",
            "Epoch 624/700\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0111 - accuracy: 0.9957 - val_loss: 1.0892 - val_accuracy: 0.7500\n",
            "Epoch 625/700\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0164 - accuracy: 0.9931 - val_loss: 1.5985 - val_accuracy: 0.7778\n",
            "Epoch 626/700\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0415 - accuracy: 0.9878 - val_loss: 1.0344 - val_accuracy: 0.7500\n",
            "Epoch 627/700\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0213 - accuracy: 0.9922 - val_loss: 1.1818 - val_accuracy: 0.7500\n",
            "Epoch 628/700\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0149 - accuracy: 0.9957 - val_loss: 1.2747 - val_accuracy: 0.7500\n",
            "Epoch 629/700\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0134 - accuracy: 0.9939 - val_loss: 1.3414 - val_accuracy: 0.7222\n",
            "Epoch 630/700\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0225 - accuracy: 0.9922 - val_loss: 1.3911 - val_accuracy: 0.7500\n",
            "Epoch 631/700\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0213 - accuracy: 0.9896 - val_loss: 1.5550 - val_accuracy: 0.7500\n",
            "Epoch 632/700\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0275 - accuracy: 0.9922 - val_loss: 1.2571 - val_accuracy: 0.7500\n",
            "Epoch 633/700\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0171 - accuracy: 0.9939 - val_loss: 1.2887 - val_accuracy: 0.7778\n",
            "Epoch 634/700\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0310 - accuracy: 0.9887 - val_loss: 1.0811 - val_accuracy: 0.7500\n",
            "Epoch 635/700\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0285 - accuracy: 0.9948 - val_loss: 0.9788 - val_accuracy: 0.7778\n",
            "Epoch 636/700\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0157 - accuracy: 0.9939 - val_loss: 1.1192 - val_accuracy: 0.7500\n",
            "Epoch 637/700\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0167 - accuracy: 0.9931 - val_loss: 1.0227 - val_accuracy: 0.7778\n",
            "Epoch 638/700\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0239 - accuracy: 0.9905 - val_loss: 1.4045 - val_accuracy: 0.7500\n",
            "Epoch 639/700\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0281 - accuracy: 0.9905 - val_loss: 0.9937 - val_accuracy: 0.7778\n",
            "Epoch 640/700\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0100 - accuracy: 0.9957 - val_loss: 1.0568 - val_accuracy: 0.7778\n",
            "Epoch 641/700\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0135 - accuracy: 0.9965 - val_loss: 1.1587 - val_accuracy: 0.7778\n",
            "Epoch 642/700\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0136 - accuracy: 0.9948 - val_loss: 1.0708 - val_accuracy: 0.8056\n",
            "Epoch 643/700\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0194 - accuracy: 0.9931 - val_loss: 1.1487 - val_accuracy: 0.7222\n",
            "Epoch 644/700\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0052 - accuracy: 0.9991 - val_loss: 1.1091 - val_accuracy: 0.8056\n",
            "Epoch 645/700\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0285 - accuracy: 0.9939 - val_loss: 0.9465 - val_accuracy: 0.8333\n",
            "Epoch 646/700\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0171 - accuracy: 0.9948 - val_loss: 0.7893 - val_accuracy: 0.8056\n",
            "Epoch 647/700\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0292 - accuracy: 0.9948 - val_loss: 0.9769 - val_accuracy: 0.7778\n",
            "Epoch 648/700\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0125 - accuracy: 0.9974 - val_loss: 0.8963 - val_accuracy: 0.8056\n",
            "Epoch 649/700\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0161 - accuracy: 0.9957 - val_loss: 1.0236 - val_accuracy: 0.7778\n",
            "Epoch 650/700\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0344 - accuracy: 0.9931 - val_loss: 1.2840 - val_accuracy: 0.7778\n",
            "Epoch 651/700\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0201 - accuracy: 0.9896 - val_loss: 0.6934 - val_accuracy: 0.8056\n",
            "Epoch 652/700\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0168 - accuracy: 0.9957 - val_loss: 1.1002 - val_accuracy: 0.7778\n",
            "Epoch 653/700\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0145 - accuracy: 0.9939 - val_loss: 0.9969 - val_accuracy: 0.8056\n",
            "Epoch 654/700\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0167 - accuracy: 0.9931 - val_loss: 0.7169 - val_accuracy: 0.8333\n",
            "Epoch 655/700\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0161 - accuracy: 0.9957 - val_loss: 0.7835 - val_accuracy: 0.8333\n",
            "Epoch 656/700\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0197 - accuracy: 0.9948 - val_loss: 1.0405 - val_accuracy: 0.8056\n",
            "Epoch 657/700\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0300 - accuracy: 0.9931 - val_loss: 0.9052 - val_accuracy: 0.8333\n",
            "Epoch 658/700\n",
            "72/72 [==============================] - 1s 20ms/step - loss: 0.0128 - accuracy: 0.9957 - val_loss: 1.1845 - val_accuracy: 0.7778\n",
            "Epoch 659/700\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0190 - accuracy: 0.9931 - val_loss: 1.1171 - val_accuracy: 0.8056\n",
            "Epoch 660/700\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0279 - accuracy: 0.9905 - val_loss: 0.8801 - val_accuracy: 0.8056\n",
            "Epoch 661/700\n",
            "72/72 [==============================] - 1s 20ms/step - loss: 0.0104 - accuracy: 0.9957 - val_loss: 0.9938 - val_accuracy: 0.8056\n",
            "Epoch 662/700\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0150 - accuracy: 0.9965 - val_loss: 0.9304 - val_accuracy: 0.8056\n",
            "Epoch 663/700\n",
            "72/72 [==============================] - 1s 20ms/step - loss: 0.0155 - accuracy: 0.9948 - val_loss: 1.0793 - val_accuracy: 0.8056\n",
            "Epoch 664/700\n",
            "72/72 [==============================] - 1s 20ms/step - loss: 0.0054 - accuracy: 0.9974 - val_loss: 0.8864 - val_accuracy: 0.8333\n",
            "Epoch 665/700\n",
            "72/72 [==============================] - 1s 20ms/step - loss: 0.0147 - accuracy: 0.9948 - val_loss: 0.9031 - val_accuracy: 0.8056\n",
            "Epoch 666/700\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0170 - accuracy: 0.9965 - val_loss: 1.2891 - val_accuracy: 0.8056\n",
            "Epoch 667/700\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0099 - accuracy: 0.9957 - val_loss: 1.0026 - val_accuracy: 0.8056\n",
            "Epoch 668/700\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0169 - accuracy: 0.9948 - val_loss: 1.1709 - val_accuracy: 0.8056\n",
            "Epoch 669/700\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0255 - accuracy: 0.9931 - val_loss: 1.0728 - val_accuracy: 0.8333\n",
            "Epoch 670/700\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0101 - accuracy: 0.9965 - val_loss: 0.9915 - val_accuracy: 0.8056\n",
            "Epoch 671/700\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0114 - accuracy: 0.9957 - val_loss: 1.2817 - val_accuracy: 0.7778\n",
            "Epoch 672/700\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0217 - accuracy: 0.9939 - val_loss: 0.8368 - val_accuracy: 0.8333\n",
            "Epoch 673/700\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0152 - accuracy: 0.9957 - val_loss: 0.8962 - val_accuracy: 0.8333\n",
            "Epoch 674/700\n",
            "72/72 [==============================] - 1s 20ms/step - loss: 0.0147 - accuracy: 0.9948 - val_loss: 1.0600 - val_accuracy: 0.8056\n",
            "Epoch 675/700\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0162 - accuracy: 0.9939 - val_loss: 1.0660 - val_accuracy: 0.8056\n",
            "Epoch 676/700\n",
            "72/72 [==============================] - 1s 20ms/step - loss: 0.0196 - accuracy: 0.9939 - val_loss: 1.3280 - val_accuracy: 0.7778\n",
            "Epoch 677/700\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0281 - accuracy: 0.9922 - val_loss: 1.2261 - val_accuracy: 0.7778\n",
            "Epoch 678/700\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0304 - accuracy: 0.9905 - val_loss: 1.0086 - val_accuracy: 0.8333\n",
            "Epoch 679/700\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0308 - accuracy: 0.9887 - val_loss: 1.1259 - val_accuracy: 0.8056\n",
            "Epoch 680/700\n",
            "72/72 [==============================] - 1s 20ms/step - loss: 0.0260 - accuracy: 0.9913 - val_loss: 0.9335 - val_accuracy: 0.8056\n",
            "Epoch 681/700\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0158 - accuracy: 0.9939 - val_loss: 0.9049 - val_accuracy: 0.8056\n",
            "Epoch 682/700\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0208 - accuracy: 0.9939 - val_loss: 1.5199 - val_accuracy: 0.7778\n",
            "Epoch 683/700\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0091 - accuracy: 0.9974 - val_loss: 1.5017 - val_accuracy: 0.7778\n",
            "Epoch 684/700\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0257 - accuracy: 0.9939 - val_loss: 1.2488 - val_accuracy: 0.7778\n",
            "Epoch 685/700\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0167 - accuracy: 0.9939 - val_loss: 1.0765 - val_accuracy: 0.8056\n",
            "Epoch 686/700\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0175 - accuracy: 0.9931 - val_loss: 1.0883 - val_accuracy: 0.8056\n",
            "Epoch 687/700\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0172 - accuracy: 0.9948 - val_loss: 1.3327 - val_accuracy: 0.7778\n",
            "Epoch 688/700\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0094 - accuracy: 0.9974 - val_loss: 0.8800 - val_accuracy: 0.8333\n",
            "Epoch 689/700\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0164 - accuracy: 0.9913 - val_loss: 1.3174 - val_accuracy: 0.7778\n",
            "Epoch 690/700\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0158 - accuracy: 0.9948 - val_loss: 1.0811 - val_accuracy: 0.8056\n",
            "Epoch 691/700\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0197 - accuracy: 0.9948 - val_loss: 1.3323 - val_accuracy: 0.7222\n",
            "Epoch 692/700\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0233 - accuracy: 0.9905 - val_loss: 1.5269 - val_accuracy: 0.7500\n",
            "Epoch 693/700\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0266 - accuracy: 0.9922 - val_loss: 1.0890 - val_accuracy: 0.7778\n",
            "Epoch 694/700\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0199 - accuracy: 0.9913 - val_loss: 1.0038 - val_accuracy: 0.8056\n",
            "Epoch 695/700\n",
            "72/72 [==============================] - 1s 18ms/step - loss: 0.0187 - accuracy: 0.9922 - val_loss: 1.2953 - val_accuracy: 0.7778\n",
            "Epoch 696/700\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0304 - accuracy: 0.9887 - val_loss: 1.3858 - val_accuracy: 0.7500\n",
            "Epoch 697/700\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0188 - accuracy: 0.9913 - val_loss: 1.3876 - val_accuracy: 0.7778\n",
            "Epoch 698/700\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0172 - accuracy: 0.9948 - val_loss: 0.9712 - val_accuracy: 0.8056\n",
            "Epoch 699/700\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0116 - accuracy: 0.9939 - val_loss: 1.0488 - val_accuracy: 0.8056\n",
            "Epoch 700/700\n",
            "72/72 [==============================] - 1s 19ms/step - loss: 0.0146 - accuracy: 0.9965 - val_loss: 1.1152 - val_accuracy: 0.8056\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ava_acc=np.mean(cnnhistory.history['accuracy']) # numpy assumed imported as np\n",
        "print(ava_acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fu7omyRcaIN3",
        "outputId": "2ac2845d-9bfb-40cb-bdc0-6f24efcb1501"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9304613098927906\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(cnnhistory.history['loss'])\n",
        "plt.plot(cnnhistory.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'valid'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "oQYnuaCrDH_A",
        "outputId": "131c0487-ae64-49b9-fa9e-1596adcdfffe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(cnnhistory.history['accuracy'])\n",
        "plt.plot(cnnhistory.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'valid'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "IFkTuO8nDNdq",
        "outputId": "793a5c3c-0c64-4e66-96ef-f55fca45ebab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#predictions = model.predict_classes(x_testcnn)\n",
        "predictions = model.predict(x_test)"
      ],
      "metadata": {
        "id": "A2xtrN5wDQgY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_f_ohjXKDUpY",
        "outputId": "2a3d39e4-de6e-4e68-f99a-0948500ccaa0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[9.99995828e-01, 1.50233454e-11, 8.93041880e-13, 4.18997161e-06,\n",
              "        4.19453894e-09, 6.80172119e-21],\n",
              "       [2.79511596e-07, 9.39091742e-01, 6.08645789e-02, 9.95799928e-06,\n",
              "        3.34208889e-05, 4.55556477e-14],\n",
              "       [9.99988317e-01, 2.91719704e-11, 3.16520415e-15, 1.17289546e-05,\n",
              "        2.92535052e-10, 8.97098932e-23],\n",
              "       [6.66569686e-05, 4.82215881e-02, 8.77222776e-01, 3.85612278e-04,\n",
              "        7.41034299e-02, 4.37448122e-09],\n",
              "       [4.75397179e-08, 9.96494472e-01, 7.02247149e-08, 3.50513728e-03,\n",
              "        2.16382034e-07, 2.17198819e-17],\n",
              "       [4.68013622e-03, 3.21415097e-01, 8.97467062e-02, 3.57692223e-03,\n",
              "        5.80579042e-01, 2.08227812e-06],\n",
              "       [2.71259708e-08, 4.41075972e-04, 3.87896470e-09, 9.99558628e-01,\n",
              "        2.72982504e-07, 2.28776465e-18],\n",
              "       [5.59545640e-07, 9.99928832e-01, 3.54059339e-05, 3.51868039e-05,\n",
              "        2.39004496e-08, 1.41136875e-15],\n",
              "       [4.92538632e-08, 4.49905019e-05, 9.99951124e-01, 6.65860682e-07,\n",
              "        3.15507782e-06, 4.02716733e-15],\n",
              "       [9.99783099e-01, 4.30041392e-13, 2.42969199e-15, 2.16903602e-04,\n",
              "        3.78687533e-12, 1.98817580e-24],\n",
              "       [2.39754468e-03, 6.46849458e-07, 3.79344058e-08, 2.24449668e-05,\n",
              "        9.97579396e-01, 3.90205344e-14],\n",
              "       [2.52758531e-04, 2.77601719e-01, 4.28718418e-01, 3.22712772e-03,\n",
              "        2.90199727e-01, 1.59972558e-07],\n",
              "       [7.64688710e-04, 1.34667642e-02, 9.55805838e-01, 1.06395837e-02,\n",
              "        1.93225201e-02, 6.03170975e-07],\n",
              "       [8.58049154e-01, 1.03999846e-04, 9.58520900e-07, 1.39836103e-01,\n",
              "        2.00977479e-03, 8.55360560e-10],\n",
              "       [9.19903535e-03, 1.53525244e-03, 4.45654523e-03, 3.41303162e-02,\n",
              "        9.50678885e-01, 4.21420587e-08],\n",
              "       [9.99937415e-01, 4.55894107e-11, 2.17064496e-12, 6.25749599e-05,\n",
              "        6.51258145e-11, 1.22695111e-20],\n",
              "       [6.78675818e-08, 3.30720447e-08, 2.35751713e-06, 1.03960701e-07,\n",
              "        9.99997497e-01, 8.02680350e-18],\n",
              "       [5.69431409e-02, 8.77899211e-08, 1.58323044e-08, 9.43056166e-01,\n",
              "        5.09783320e-07, 4.12066367e-15],\n",
              "       [1.00000000e+00, 2.96452995e-17, 2.12819173e-21, 1.69287784e-08,\n",
              "        5.48921607e-15, 3.99838048e-33],\n",
              "       [3.68436195e-05, 7.36357761e-05, 1.01644276e-02, 3.73098192e-05,\n",
              "        9.89687860e-01, 7.82769197e-11],\n",
              "       [5.08105757e-07, 2.22598846e-05, 8.39131355e-01, 7.99877671e-06,\n",
              "        1.60837874e-01, 2.06406913e-13],\n",
              "       [8.52507714e-04, 8.92607570e-02, 8.90214462e-03, 4.81729308e-04,\n",
              "        9.00502801e-01, 8.08049450e-09],\n",
              "       [8.27013835e-08, 2.39610061e-04, 9.99183595e-01, 3.61652019e-06,\n",
              "        5.73204481e-04, 2.01606906e-13],\n",
              "       [9.99986291e-01, 5.46684720e-14, 2.80507079e-19, 1.37387151e-05,\n",
              "        1.78679483e-14, 5.14239064e-29],\n",
              "       [3.81446007e-05, 8.37676853e-05, 5.46209179e-02, 2.17877736e-04,\n",
              "        9.45039272e-01, 2.93405522e-10],\n",
              "       [9.99978304e-01, 3.51524604e-12, 8.64268035e-15, 2.17355682e-05,\n",
              "        2.11212769e-10, 4.70782406e-23],\n",
              "       [4.37016351e-05, 7.68620521e-04, 5.75565314e-03, 3.95221461e-04,\n",
              "        9.93036807e-01, 1.23743604e-09],\n",
              "       [8.92554235e-04, 4.62379446e-03, 8.80899787e-01, 6.34275936e-03,\n",
              "        1.07239828e-01, 1.21680841e-06],\n",
              "       [8.11303079e-01, 6.65168453e-04, 1.83727821e-06, 1.97928026e-02,\n",
              "        1.68237001e-01, 9.89994531e-10],\n",
              "       [9.99999881e-01, 1.59523087e-14, 8.51347257e-17, 1.65721204e-07,\n",
              "        6.84796534e-12, 8.22039671e-27],\n",
              "       [3.93763445e-02, 1.65229946e-01, 5.25068454e-02, 2.60401666e-01,\n",
              "        4.82458383e-01, 2.67862470e-05],\n",
              "       [3.20328945e-06, 3.17969793e-08, 3.28799121e-09, 9.99996662e-01,\n",
              "        6.96729572e-08, 1.49587714e-18],\n",
              "       [2.02819719e-10, 2.41265376e-03, 5.29088085e-14, 9.97587323e-01,\n",
              "        1.45909021e-10, 2.78941093e-26],\n",
              "       [9.63541879e-06, 1.08368807e-02, 9.71523821e-01, 1.00962578e-04,\n",
              "        1.75286271e-02, 3.17659926e-10],\n",
              "       [5.22960981e-08, 8.56088533e-11, 2.56814209e-10, 2.17095830e-09,\n",
              "        1.00000000e+00, 9.69340211e-24],\n",
              "       [1.26705112e-04, 2.29347759e-08, 4.66875871e-10, 9.99873161e-01,\n",
              "        6.61009665e-08, 3.54197373e-18]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "emo_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cmA2bFgsDW3D",
        "outputId": "12bbff67-0cbd-4341-b5b7-075f397e6f04"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 2, 0, 2, 1, 1, 3, 1, 2, 0, 4, 4, 2, 3, 4, 0, 4, 0, 0, 4, 4, 1,\n",
              "       2, 0, 4, 0, 4, 2, 0, 0, 1, 3, 3, 2, 4, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_Ytest = emo_test.astype(int)"
      ],
      "metadata": {
        "id": "0PHDKWJWDY3g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_Ytest"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k68v2i-pDbZE",
        "outputId": "7dde3b24-933d-4be9-b571-83115582eca0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 2, 0, 2, 1, 1, 3, 1, 2, 0, 4, 4, 2, 3, 4, 0, 4, 0, 0, 4, 4, 1,\n",
              "       2, 0, 4, 0, 4, 2, 0, 0, 1, 3, 3, 2, 4, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds1=predictions.argmax(axis=1)"
      ],
      "metadata": {
        "id": "VEw0FiZFMcOQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vvyRw0M0NBOb",
        "outputId": "771d59b3-ff59-415f-d838-7ee67fe87ec4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 0, 2, 1, 4, 3, 1, 2, 0, 4, 2, 2, 0, 4, 0, 4, 3, 0, 4, 2, 4,\n",
              "       2, 0, 4, 0, 4, 2, 0, 0, 4, 3, 3, 2, 4, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "abc = preds1.astype(int).flatten()"
      ],
      "metadata": {
        "id": "H4WEmM60NfQn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "c = confusion_matrix(new_Ytest, abc) \n",
        "c"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bKEBeEBlFjB8",
        "outputId": "696b7824-7cd8-4141-ed64-3e1da3867f49"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[9, 0, 0, 2, 0],\n",
              "       [0, 2, 0, 0, 3],\n",
              "       [0, 1, 6, 0, 0],\n",
              "       [1, 0, 0, 3, 0],\n",
              "       [0, 0, 2, 0, 7]])"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "emo_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m4RjG7LWLSQx",
        "outputId": "45e169cb-01be-4a00-e512-80add477cc64"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 2, 0, 2, 1, 1, 3, 1, 2, 0, 4, 4, 2, 3, 4, 0, 4, 0, 0, 4, 4, 1,\n",
              "       2, 0, 4, 0, 4, 2, 0, 0, 1, 3, 3, 2, 4, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('/content/drive/My Drive/graduation project/audio/improvement1/mariam/augmanted_savee_dropout_3')\n",
        "print(\"MODEL SAVED\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lsJBNeMWDl6Z",
        "outputId": "f180c95b-f271-4aa4-ffca-0bd7ab4677d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/graduation project/audio/improvement1/mariam/augmanted_savee_dropout_3/assets\n",
            "MODEL SAVED\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_model=keras.models.load_model('/content/drive/My Drive/graduation project/audio/improvement1/mariam/augmanted_savee_dropout_3')\n",
        "new_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q3KjaO9GDoNl",
        "outputId": "23942285-f6e3-4f45-8ff2-0e2487715a26"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d (Conv1D)             (None, 40, 64)            384       \n",
            "                                                                 \n",
            " activation (Activation)     (None, 40, 64)            0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 40, 64)            0         \n",
            "                                                                 \n",
            " max_pooling1d (MaxPooling1D  (None, 10, 64)           0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv1d_1 (Conv1D)           (None, 10, 128)           41088     \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 10, 128)           0         \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 10, 128)           0         \n",
            "                                                                 \n",
            " max_pooling1d_1 (MaxPooling  (None, 2, 128)           0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " conv1d_2 (Conv1D)           (None, 2, 128)            82048     \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 2, 128)            0         \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 2, 128)            0         \n",
            "                                                                 \n",
            " max_pooling1d_2 (MaxPooling  (None, 1, 128)           0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " conv1d_3 (Conv1D)           (None, 1, 256)            164096    \n",
            "                                                                 \n",
            " activation_3 (Activation)   (None, 1, 256)            0         \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 1, 256)            0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 256)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 6)                 1542      \n",
            "                                                                 \n",
            " activation_4 (Activation)   (None, 6)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 289,158\n",
            "Trainable params: 289,158\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss, acc = new_model.evaluate(x_test, emo_test)\n",
        "print(\"Restored model, accuracy: {:5.2f}%\".format(100*acc))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n3kzoqPkDqqS",
        "outputId": "1f9ca131-da06-47ef-b21b-22a54ef4c7a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 6ms/step - loss: 0.7138 - accuracy: 0.7500\n",
            "Restored model, accuracy: 75.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss, acc = new_model.evaluate(x_train, y_train)\n",
        "print(\"Restored model, train accuracy: {:5.2f}%\".format(100*acc))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dg8GxDUHzBSP",
        "outputId": "27b030fa-98c5-4669-a782-222fb96ab990"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "36/36 [==============================] - 1s 8ms/step - loss: 3.9965e-04 - accuracy: 1.0000\n",
            "Restored model, train accuracy: 100.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix,accuracy_score\n",
        "import seaborn as sn\n",
        "\n",
        "print(classification_report(emo_test,abc))\n",
        "\n",
        "acc = float(accuracy_score(emo_test,abc))*100\n",
        "print(\"----accuracy score %s ----\" % acc)\n",
        "\n",
        "cm = confusion_matrix(emo_test,abc)\n",
        "#df_cm = pd.DataFrame(cm)\n",
        "class_names = ['neutral', 'happy','sad','angry', 'fearful' ]\n",
        "df_cm = pd.DataFrame(cm, index=class_names, columns=class_names,)\n",
        "sn.heatmap(df_cm, annot=True, fmt='')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Yx8ogGOnNneV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 494
        },
        "outputId": "023c4519-cc05-420b-f35a-f94c6a44ebc9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.82      0.86        11\n",
            "           1       0.67      0.40      0.50         5\n",
            "           2       0.75      0.86      0.80         7\n",
            "           3       0.60      0.75      0.67         4\n",
            "           4       0.70      0.78      0.74         9\n",
            "\n",
            "    accuracy                           0.75        36\n",
            "   macro avg       0.72      0.72      0.71        36\n",
            "weighted avg       0.76      0.75      0.75        36\n",
            "\n",
            "----accuracy score 75.0 ----\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "fJDTGH_OUX0z"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}