{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "original_adam_0.00002_without decay_500_4.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9SRCO-a_AlH5",
        "outputId": "e3372ab8-43ee-4fe9-d301-4ab43f0bbdf5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install librosa"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Lo4mUwG9RMd",
        "outputId": "64801be4-74fc-4d7c-ed3a-a0c822426776"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.7/dist-packages (0.8.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.21.6)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (21.3)\n",
            "Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.0.2)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.1.0)\n",
            "Requirement already satisfied: soundfile>=0.10.2 in /usr/local/lib/python3.7/dist-packages (from librosa) (0.10.3.post1)\n",
            "Requirement already satisfied: decorator>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied: numba>=0.43.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (0.51.2)\n",
            "Requirement already satisfied: audioread>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (2.1.9)\n",
            "Requirement already satisfied: resampy>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from librosa) (0.2.2)\n",
            "Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.6.0)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.4.1)\n",
            "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba>=0.43.0->librosa) (0.34.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba>=0.43.0->librosa) (57.4.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->librosa) (3.0.9)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from pooch>=1.0->librosa) (2.23.0)\n",
            "Requirement already satisfied: appdirs>=1.3.0 in /usr/local/lib/python3.7/dist-packages (from pooch>=1.0->librosa) (1.4.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2022.5.18.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (1.24.3)\n",
            "Requirement already satisfied: six>=1.3 in /usr/local/lib/python3.7/dist-packages (from resampy>=0.2.2->librosa) (1.15.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn!=0.19.0,>=0.14.0->librosa) (3.1.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.7/dist-packages (from soundfile>=0.10.2->librosa) (1.15.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.0->soundfile>=0.10.2->librosa) (2.21)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HJjcbxwy46bG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "de5efd61-043d-41d7-b6c9-76f5a0961f75"
      },
      "source": [
        "# Orignial Notebook: https://github.com/MITESHPUTHRANNEU/Speech-Emotion-Analyzer/blob/master/final_results_gender_test.ipynb\n",
        "# This notebook author: Reza Chu\n",
        "# Last Editing Date: 31st May 2019\n",
        "\n",
        "## Python\n",
        "import os\n",
        "import random\n",
        "import sys\n",
        "\n",
        "import IPython\n",
        "from IPython.display import Audio\n",
        "from IPython.display import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "## Package\n",
        "import glob \n",
        "import keras\n",
        "import IPython.display as ipd\n",
        "import librosa\n",
        "import librosa.display\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import plotly.graph_objs as go\n",
        "import plotly.offline as py\n",
        "import plotly.tools as tls\n",
        "import seaborn as sns\n",
        "import scipy.io.wavfile\n",
        "import tensorflow as tf\n",
        "py.init_notebook_mode(connected=True)\n",
        "\n",
        "## Keras\n",
        "from keras import regularizers\n",
        "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping\n",
        "from keras.callbacks import  History, ReduceLROnPlateau, CSVLogger\n",
        "from keras.models import Model, Sequential\n",
        "from keras.layers import Dense, Embedding, LSTM\n",
        "from keras.layers import Input, Flatten, Dropout, Activation, BatchNormalization\n",
        "from keras.layers import Conv1D, MaxPooling1D, AveragePooling1D\n",
        "from keras.preprocessing import sequence\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.utils import np_utils\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "## Sklearn\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "## Rest\n",
        "from scipy.fftpack import fft\n",
        "from scipy import signal\n",
        "from scipy.io import wavfile\n",
        "from tqdm import tqdm\n",
        "\n",
        "input_duration=3\n",
        "# % pylab inline"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "        <script type=\"text/javascript\">\n",
              "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
              "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
              "        if (typeof require !== 'undefined') {\n",
              "        require.undef(\"plotly\");\n",
              "        requirejs.config({\n",
              "            paths: {\n",
              "                'plotly': ['https://cdn.plot.ly/plotly-2.8.3.min']\n",
              "            }\n",
              "        });\n",
              "        require(['plotly'], function(Plotly) {\n",
              "            window._Plotly = Plotly;\n",
              "        });\n",
              "        }\n",
              "        </script>\n",
              "        "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Saving joblib files to not load them again with the loop above\n",
        "\n",
        "# import joblib\n",
        "\n",
        "# X_name = 'x.joblib'\n",
        "# y_name = 'y.joblib'\n",
        "# save_dir = '/content/drive/My Drive/graduation project/audio/paper_code/features'\n",
        "\n",
        "# savedX = joblib.dump(X, os.path.join(save_dir, X_name))\n",
        "# savedy = joblib.dump(y, os.path.join(save_dir, y_name))"
      ],
      "metadata": {
        "id": "UCzic8rlDcuk"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Loading saved models\n",
        "import joblib\n",
        "X = joblib.load('/content/drive/My Drive/graduation project/audio/paper_code/features/x.joblib')\n",
        "y = joblib.load('/content/drive/My Drive/graduation project/audio/paper_code/features/y.joblib')"
      ],
      "metadata": {
        "id": "Q35CN6zDrzg1"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7PSTurzjCo5K",
        "outputId": "5c12512a-331e-457c-e9b8-a1b390b61370"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2068, 40)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.1 ,shuffle = True\n",
        "                                                    , random_state=42)\n",
        "X_train , X_valid, y_train, y_valid = train_test_split(X_train,y_train, test_size=0.1112305212 , shuffle = True \n",
        "                                                       , random_state=42)"
      ],
      "metadata": {
        "id": "Ai4Fy5cPCiq1"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "x_traincnn = np.expand_dims(X_train, axis=2)\n",
        "x_testcnn = np.expand_dims(X_test, axis=2)\n",
        "X_valid= np.expand_dims(X_valid, axis=2)"
      ],
      "metadata": {
        "id": "tp1Fm5K3CEXu"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_traincnn.shape, x_testcnn.shape , X_valid.shape\n",
        "#1861"
      ],
      "metadata": {
        "id": "RI0MxoIPBws5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71412a6b-42b9-457c-b128-6ccffe049553"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1654, 40, 1), (207, 40, 1), (207, 40, 1))"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oALhiMUd9G2Y",
        "outputId": "ba42fbaa-b745-4b2f-80da-e3bc9b3e6f64"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (2.8.2+zzzcolab20220527125636)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n",
            "Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.5.3)\n",
            "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n",
            "Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.46.3)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow) (57.4.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.17.3)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.0.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.26.0)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.21.6)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (14.0.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (4.2.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow) (1.5.2)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.6.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.23.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.35.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.8.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (3.3.7)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (4.11.4)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (3.8.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2022.5.18.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (3.2.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from keras.preprocessing import sequence\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from keras.layers import Input, Flatten, Dropout, Activation\n",
        "from keras.layers import Conv1D, MaxPooling1D\n",
        "from keras.models import Model\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras import optimizers\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv1D(128, 8,padding='same', #classifier.add(Convolution2D(64, (3, 3), padding = 'same', input_shape = (128, 128, 3), activation = 'relu'))\n",
        "                 input_shape=(40,1)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(MaxPooling1D(pool_size=(5)))\n",
        "\n",
        "\n",
        "model.add(Conv1D(256,8,padding='same',))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(MaxPooling1D(pool_size=(5)))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(256))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(256))\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "model.add(Dense(6))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "opt = tf.keras.optimizers.Adam(lr=0.00002 , decay=0.0)\n",
        "#opt = tf.keras.optimizers.RMSprop(lr=0.0001, rho=0.9, epsilon=1e-07, decay=0.0)\n",
        "#opt = tf.keras.optimizers.SGD(lr=0.001, momentum=0.0, decay=0.0, nesterov=False)"
      ],
      "metadata": {
        "id": "g74fXWVAC4Cr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1555d2a3-106c-4d10-8505-1a9e9d2c235d"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning:\n",
            "\n",
            "The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H6ukOxAGC_I4",
        "outputId": "0068645d-49b4-449a-c605-634bf390079a"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d (Conv1D)             (None, 40, 128)           1152      \n",
            "                                                                 \n",
            " activation (Activation)     (None, 40, 128)           0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 40, 128)           0         \n",
            "                                                                 \n",
            " max_pooling1d (MaxPooling1D  (None, 8, 128)           0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv1d_1 (Conv1D)           (None, 8, 256)            262400    \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 8, 256)            0         \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 8, 256)            0         \n",
            "                                                                 \n",
            " max_pooling1d_1 (MaxPooling  (None, 1, 256)           0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 256)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 256)               65792     \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 256)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 256)               65792     \n",
            "                                                                 \n",
            " activation_3 (Activation)   (None, 256)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 6)                 1542      \n",
            "                                                                 \n",
            " activation_4 (Activation)   (None, 6)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 396,678\n",
            "Trainable params: 396,678\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='sparse_categorical_crossentropy',\n",
        "              optimizer=opt,\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "AbMlLNk4DCBM"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an Instance of Early Stopping Callback.\n",
        "early_stopping_callback = EarlyStopping(monitor = 'val_loss', patience = 25, mode = 'min', restore_best_weights = True)\n",
        "\n",
        "cnnhistory=model.fit(x_traincnn, y_train, batch_size=16, epochs=500 , shuffle = True, \n",
        "                     validation_data=(X_valid, y_valid) , callbacks = [early_stopping_callback])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RI1v2AuADFhy",
        "outputId": "b03ba491-0398-4cdb-b63e-416be46a957e"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "104/104 [==============================] - 4s 7ms/step - loss: 6.0124 - accuracy: 0.1590 - val_loss: 3.0987 - val_accuracy: 0.1932\n",
            "Epoch 2/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 4.5785 - accuracy: 0.1814 - val_loss: 2.2796 - val_accuracy: 0.1932\n",
            "Epoch 3/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 3.8955 - accuracy: 0.1796 - val_loss: 2.3877 - val_accuracy: 0.1932\n",
            "Epoch 4/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 3.4887 - accuracy: 0.1880 - val_loss: 2.1397 - val_accuracy: 0.1932\n",
            "Epoch 5/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 3.2989 - accuracy: 0.1929 - val_loss: 1.9583 - val_accuracy: 0.1932\n",
            "Epoch 6/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 2.8983 - accuracy: 0.1935 - val_loss: 1.9681 - val_accuracy: 0.1932\n",
            "Epoch 7/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 2.7963 - accuracy: 0.1947 - val_loss: 1.8627 - val_accuracy: 0.1932\n",
            "Epoch 8/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 2.6156 - accuracy: 0.1989 - val_loss: 1.7958 - val_accuracy: 0.2174\n",
            "Epoch 9/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 2.4730 - accuracy: 0.2158 - val_loss: 1.8264 - val_accuracy: 0.1981\n",
            "Epoch 10/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 2.3733 - accuracy: 0.2104 - val_loss: 1.8472 - val_accuracy: 0.2029\n",
            "Epoch 11/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 2.3967 - accuracy: 0.1796 - val_loss: 1.8221 - val_accuracy: 0.2126\n",
            "Epoch 12/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 2.2558 - accuracy: 0.2068 - val_loss: 1.7492 - val_accuracy: 0.2609\n",
            "Epoch 13/500\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 2.2446 - accuracy: 0.2086 - val_loss: 1.7249 - val_accuracy: 0.2560\n",
            "Epoch 14/500\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 2.1865 - accuracy: 0.2068 - val_loss: 1.7268 - val_accuracy: 0.2657\n",
            "Epoch 15/500\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 2.1791 - accuracy: 0.1892 - val_loss: 1.7116 - val_accuracy: 0.2995\n",
            "Epoch 16/500\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 2.1761 - accuracy: 0.1983 - val_loss: 1.7040 - val_accuracy: 0.2802\n",
            "Epoch 17/500\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 2.0866 - accuracy: 0.2273 - val_loss: 1.7381 - val_accuracy: 0.2077\n",
            "Epoch 18/500\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 2.0583 - accuracy: 0.2140 - val_loss: 1.7469 - val_accuracy: 0.1787\n",
            "Epoch 19/500\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 2.0013 - accuracy: 0.2122 - val_loss: 1.7169 - val_accuracy: 0.2222\n",
            "Epoch 20/500\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 1.9694 - accuracy: 0.2164 - val_loss: 1.7101 - val_accuracy: 0.2367\n",
            "Epoch 21/500\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 1.9518 - accuracy: 0.2177 - val_loss: 1.7216 - val_accuracy: 0.2126\n",
            "Epoch 22/500\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 1.9283 - accuracy: 0.2473 - val_loss: 1.6955 - val_accuracy: 0.2754\n",
            "Epoch 23/500\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 1.8978 - accuracy: 0.2491 - val_loss: 1.6955 - val_accuracy: 0.3140\n",
            "Epoch 24/500\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 1.9087 - accuracy: 0.2219 - val_loss: 1.6946 - val_accuracy: 0.2705\n",
            "Epoch 25/500\n",
            "104/104 [==============================] - 1s 9ms/step - loss: 1.9011 - accuracy: 0.2195 - val_loss: 1.6953 - val_accuracy: 0.3575\n",
            "Epoch 26/500\n",
            "104/104 [==============================] - 1s 9ms/step - loss: 1.8882 - accuracy: 0.2340 - val_loss: 1.6941 - val_accuracy: 0.2947\n",
            "Epoch 27/500\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 1.8869 - accuracy: 0.2273 - val_loss: 1.6957 - val_accuracy: 0.3430\n",
            "Epoch 28/500\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 1.8626 - accuracy: 0.2183 - val_loss: 1.6982 - val_accuracy: 0.2899\n",
            "Epoch 29/500\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 1.8641 - accuracy: 0.2358 - val_loss: 1.6866 - val_accuracy: 0.2850\n",
            "Epoch 30/500\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 1.8095 - accuracy: 0.2485 - val_loss: 1.6791 - val_accuracy: 0.3140\n",
            "Epoch 31/500\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 1.8430 - accuracy: 0.2231 - val_loss: 1.6865 - val_accuracy: 0.3092\n",
            "Epoch 32/500\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 1.8283 - accuracy: 0.2328 - val_loss: 1.6768 - val_accuracy: 0.3575\n",
            "Epoch 33/500\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 1.8175 - accuracy: 0.2503 - val_loss: 1.6839 - val_accuracy: 0.3140\n",
            "Epoch 34/500\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 1.7966 - accuracy: 0.2606 - val_loss: 1.6706 - val_accuracy: 0.3575\n",
            "Epoch 35/500\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 1.7870 - accuracy: 0.2503 - val_loss: 1.6702 - val_accuracy: 0.3382\n",
            "Epoch 36/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 1.7658 - accuracy: 0.2642 - val_loss: 1.6734 - val_accuracy: 0.3188\n",
            "Epoch 37/500\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 1.7847 - accuracy: 0.2594 - val_loss: 1.6686 - val_accuracy: 0.3140\n",
            "Epoch 38/500\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 1.7569 - accuracy: 0.2666 - val_loss: 1.6692 - val_accuracy: 0.2899\n",
            "Epoch 39/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 1.7644 - accuracy: 0.2630 - val_loss: 1.6557 - val_accuracy: 0.3720\n",
            "Epoch 40/500\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 1.7656 - accuracy: 0.2660 - val_loss: 1.6528 - val_accuracy: 0.3188\n",
            "Epoch 41/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 1.7370 - accuracy: 0.2563 - val_loss: 1.6547 - val_accuracy: 0.3333\n",
            "Epoch 42/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.7586 - accuracy: 0.2479 - val_loss: 1.6436 - val_accuracy: 0.3188\n",
            "Epoch 43/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.7557 - accuracy: 0.2709 - val_loss: 1.6507 - val_accuracy: 0.3478\n",
            "Epoch 44/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.7331 - accuracy: 0.2739 - val_loss: 1.6614 - val_accuracy: 0.3188\n",
            "Epoch 45/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.7266 - accuracy: 0.2830 - val_loss: 1.6596 - val_accuracy: 0.2995\n",
            "Epoch 46/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.7049 - accuracy: 0.2926 - val_loss: 1.6542 - val_accuracy: 0.3382\n",
            "Epoch 47/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.7161 - accuracy: 0.2787 - val_loss: 1.6389 - val_accuracy: 0.3527\n",
            "Epoch 48/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.7195 - accuracy: 0.2787 - val_loss: 1.6317 - val_accuracy: 0.3092\n",
            "Epoch 49/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.6762 - accuracy: 0.2793 - val_loss: 1.6369 - val_accuracy: 0.3285\n",
            "Epoch 50/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.6840 - accuracy: 0.2956 - val_loss: 1.6308 - val_accuracy: 0.3478\n",
            "Epoch 51/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.6942 - accuracy: 0.2727 - val_loss: 1.6202 - val_accuracy: 0.3285\n",
            "Epoch 52/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.7017 - accuracy: 0.3023 - val_loss: 1.6139 - val_accuracy: 0.3237\n",
            "Epoch 53/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.6875 - accuracy: 0.2817 - val_loss: 1.6028 - val_accuracy: 0.3768\n",
            "Epoch 54/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.6531 - accuracy: 0.3168 - val_loss: 1.6016 - val_accuracy: 0.3430\n",
            "Epoch 55/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.6692 - accuracy: 0.3053 - val_loss: 1.6002 - val_accuracy: 0.3333\n",
            "Epoch 56/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.6632 - accuracy: 0.3089 - val_loss: 1.5943 - val_accuracy: 0.4058\n",
            "Epoch 57/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.6577 - accuracy: 0.2956 - val_loss: 1.5965 - val_accuracy: 0.3623\n",
            "Epoch 58/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.6489 - accuracy: 0.3168 - val_loss: 1.6021 - val_accuracy: 0.3575\n",
            "Epoch 59/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.6496 - accuracy: 0.3023 - val_loss: 1.6031 - val_accuracy: 0.3285\n",
            "Epoch 60/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.6482 - accuracy: 0.3162 - val_loss: 1.5731 - val_accuracy: 0.3913\n",
            "Epoch 61/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.6509 - accuracy: 0.3077 - val_loss: 1.5844 - val_accuracy: 0.3575\n",
            "Epoch 62/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.6595 - accuracy: 0.3144 - val_loss: 1.5733 - val_accuracy: 0.3430\n",
            "Epoch 63/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.6254 - accuracy: 0.3132 - val_loss: 1.5854 - val_accuracy: 0.3430\n",
            "Epoch 64/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.6154 - accuracy: 0.3192 - val_loss: 1.5732 - val_accuracy: 0.3623\n",
            "Epoch 65/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.6152 - accuracy: 0.3132 - val_loss: 1.5607 - val_accuracy: 0.3913\n",
            "Epoch 66/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.6245 - accuracy: 0.3005 - val_loss: 1.5588 - val_accuracy: 0.3671\n",
            "Epoch 67/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.6163 - accuracy: 0.3271 - val_loss: 1.5521 - val_accuracy: 0.3865\n",
            "Epoch 68/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.6188 - accuracy: 0.3313 - val_loss: 1.5458 - val_accuracy: 0.3720\n",
            "Epoch 69/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.5851 - accuracy: 0.3428 - val_loss: 1.5499 - val_accuracy: 0.3575\n",
            "Epoch 70/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.6005 - accuracy: 0.3368 - val_loss: 1.5338 - val_accuracy: 0.3913\n",
            "Epoch 71/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.5924 - accuracy: 0.3416 - val_loss: 1.5332 - val_accuracy: 0.3575\n",
            "Epoch 72/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.5801 - accuracy: 0.3489 - val_loss: 1.5324 - val_accuracy: 0.3671\n",
            "Epoch 73/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.5649 - accuracy: 0.3573 - val_loss: 1.5435 - val_accuracy: 0.3527\n",
            "Epoch 74/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.5749 - accuracy: 0.3458 - val_loss: 1.5286 - val_accuracy: 0.3816\n",
            "Epoch 75/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.5747 - accuracy: 0.3416 - val_loss: 1.5362 - val_accuracy: 0.3478\n",
            "Epoch 76/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.5910 - accuracy: 0.3458 - val_loss: 1.5218 - val_accuracy: 0.3913\n",
            "Epoch 77/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.5686 - accuracy: 0.3495 - val_loss: 1.5181 - val_accuracy: 0.3961\n",
            "Epoch 78/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.5791 - accuracy: 0.3422 - val_loss: 1.5160 - val_accuracy: 0.4251\n",
            "Epoch 79/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.5408 - accuracy: 0.3640 - val_loss: 1.5385 - val_accuracy: 0.3913\n",
            "Epoch 80/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.5471 - accuracy: 0.3664 - val_loss: 1.5216 - val_accuracy: 0.4010\n",
            "Epoch 81/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.5306 - accuracy: 0.3748 - val_loss: 1.5032 - val_accuracy: 0.3961\n",
            "Epoch 82/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.5469 - accuracy: 0.3501 - val_loss: 1.5043 - val_accuracy: 0.4058\n",
            "Epoch 83/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.5242 - accuracy: 0.3501 - val_loss: 1.5012 - val_accuracy: 0.4300\n",
            "Epoch 84/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.5445 - accuracy: 0.3561 - val_loss: 1.4992 - val_accuracy: 0.3865\n",
            "Epoch 85/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.5262 - accuracy: 0.3603 - val_loss: 1.4995 - val_accuracy: 0.3865\n",
            "Epoch 86/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.5160 - accuracy: 0.3712 - val_loss: 1.4790 - val_accuracy: 0.4203\n",
            "Epoch 87/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.5259 - accuracy: 0.3561 - val_loss: 1.4885 - val_accuracy: 0.3913\n",
            "Epoch 88/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.4989 - accuracy: 0.3682 - val_loss: 1.4681 - val_accuracy: 0.4203\n",
            "Epoch 89/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.4796 - accuracy: 0.3839 - val_loss: 1.4740 - val_accuracy: 0.4058\n",
            "Epoch 90/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.4859 - accuracy: 0.3924 - val_loss: 1.4554 - val_accuracy: 0.4396\n",
            "Epoch 91/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.4855 - accuracy: 0.3869 - val_loss: 1.4528 - val_accuracy: 0.4541\n",
            "Epoch 92/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.4997 - accuracy: 0.3815 - val_loss: 1.4458 - val_accuracy: 0.4589\n",
            "Epoch 93/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.4957 - accuracy: 0.3839 - val_loss: 1.4605 - val_accuracy: 0.4155\n",
            "Epoch 94/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.4882 - accuracy: 0.3863 - val_loss: 1.4426 - val_accuracy: 0.4396\n",
            "Epoch 95/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.4617 - accuracy: 0.4021 - val_loss: 1.4427 - val_accuracy: 0.4251\n",
            "Epoch 96/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.4363 - accuracy: 0.4015 - val_loss: 1.4300 - val_accuracy: 0.4493\n",
            "Epoch 97/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.4540 - accuracy: 0.4033 - val_loss: 1.4453 - val_accuracy: 0.4348\n",
            "Epoch 98/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.4624 - accuracy: 0.4015 - val_loss: 1.4160 - val_accuracy: 0.4396\n",
            "Epoch 99/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.4498 - accuracy: 0.4081 - val_loss: 1.4150 - val_accuracy: 0.4444\n",
            "Epoch 100/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.4382 - accuracy: 0.4063 - val_loss: 1.4090 - val_accuracy: 0.4541\n",
            "Epoch 101/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.4440 - accuracy: 0.4129 - val_loss: 1.4121 - val_accuracy: 0.4396\n",
            "Epoch 102/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.4450 - accuracy: 0.3930 - val_loss: 1.4015 - val_accuracy: 0.4589\n",
            "Epoch 103/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.4282 - accuracy: 0.4069 - val_loss: 1.3901 - val_accuracy: 0.4734\n",
            "Epoch 104/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.4149 - accuracy: 0.4305 - val_loss: 1.3751 - val_accuracy: 0.5121\n",
            "Epoch 105/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.4374 - accuracy: 0.4015 - val_loss: 1.3807 - val_accuracy: 0.4589\n",
            "Epoch 106/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.4157 - accuracy: 0.4196 - val_loss: 1.3780 - val_accuracy: 0.4734\n",
            "Epoch 107/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.4114 - accuracy: 0.4287 - val_loss: 1.3725 - val_accuracy: 0.4444\n",
            "Epoch 108/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.3965 - accuracy: 0.4220 - val_loss: 1.3603 - val_accuracy: 0.5072\n",
            "Epoch 109/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.3776 - accuracy: 0.4389 - val_loss: 1.3670 - val_accuracy: 0.4541\n",
            "Epoch 110/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.4115 - accuracy: 0.4129 - val_loss: 1.3603 - val_accuracy: 0.4831\n",
            "Epoch 111/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.3965 - accuracy: 0.4401 - val_loss: 1.3536 - val_accuracy: 0.4879\n",
            "Epoch 112/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.3939 - accuracy: 0.4190 - val_loss: 1.3563 - val_accuracy: 0.4638\n",
            "Epoch 113/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.3853 - accuracy: 0.4293 - val_loss: 1.3390 - val_accuracy: 0.5217\n",
            "Epoch 114/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.3803 - accuracy: 0.4432 - val_loss: 1.3390 - val_accuracy: 0.5507\n",
            "Epoch 115/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.3584 - accuracy: 0.4438 - val_loss: 1.3360 - val_accuracy: 0.5121\n",
            "Epoch 116/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.3694 - accuracy: 0.4420 - val_loss: 1.3153 - val_accuracy: 0.4928\n",
            "Epoch 117/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.3566 - accuracy: 0.4486 - val_loss: 1.3250 - val_accuracy: 0.5121\n",
            "Epoch 118/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.3585 - accuracy: 0.4347 - val_loss: 1.3061 - val_accuracy: 0.5459\n",
            "Epoch 119/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.3622 - accuracy: 0.4329 - val_loss: 1.3027 - val_accuracy: 0.5266\n",
            "Epoch 120/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.3555 - accuracy: 0.4389 - val_loss: 1.3096 - val_accuracy: 0.4879\n",
            "Epoch 121/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.3284 - accuracy: 0.4547 - val_loss: 1.2943 - val_accuracy: 0.5169\n",
            "Epoch 122/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.3227 - accuracy: 0.4631 - val_loss: 1.2849 - val_accuracy: 0.5362\n",
            "Epoch 123/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.3307 - accuracy: 0.4444 - val_loss: 1.2993 - val_accuracy: 0.5169\n",
            "Epoch 124/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.3415 - accuracy: 0.4643 - val_loss: 1.2802 - val_accuracy: 0.5411\n",
            "Epoch 125/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.3339 - accuracy: 0.4559 - val_loss: 1.2761 - val_accuracy: 0.5072\n",
            "Epoch 126/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.3127 - accuracy: 0.4661 - val_loss: 1.2734 - val_accuracy: 0.4879\n",
            "Epoch 127/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.3173 - accuracy: 0.4547 - val_loss: 1.2832 - val_accuracy: 0.4976\n",
            "Epoch 128/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.3221 - accuracy: 0.4613 - val_loss: 1.2621 - val_accuracy: 0.5556\n",
            "Epoch 129/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.3186 - accuracy: 0.4577 - val_loss: 1.2685 - val_accuracy: 0.5459\n",
            "Epoch 130/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.3064 - accuracy: 0.4764 - val_loss: 1.2531 - val_accuracy: 0.5556\n",
            "Epoch 131/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.2915 - accuracy: 0.4807 - val_loss: 1.2735 - val_accuracy: 0.5652\n",
            "Epoch 132/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.2984 - accuracy: 0.4825 - val_loss: 1.2616 - val_accuracy: 0.5121\n",
            "Epoch 133/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.2874 - accuracy: 0.4794 - val_loss: 1.2666 - val_accuracy: 0.5072\n",
            "Epoch 134/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.2797 - accuracy: 0.4758 - val_loss: 1.2553 - val_accuracy: 0.5121\n",
            "Epoch 135/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.2993 - accuracy: 0.4674 - val_loss: 1.2567 - val_accuracy: 0.5169\n",
            "Epoch 136/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.2906 - accuracy: 0.4686 - val_loss: 1.2588 - val_accuracy: 0.4879\n",
            "Epoch 137/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.2732 - accuracy: 0.4855 - val_loss: 1.2578 - val_accuracy: 0.5411\n",
            "Epoch 138/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.2672 - accuracy: 0.4903 - val_loss: 1.2483 - val_accuracy: 0.5217\n",
            "Epoch 139/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.2752 - accuracy: 0.4674 - val_loss: 1.2439 - val_accuracy: 0.5797\n",
            "Epoch 140/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.2450 - accuracy: 0.4958 - val_loss: 1.2331 - val_accuracy: 0.5411\n",
            "Epoch 141/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.2521 - accuracy: 0.4933 - val_loss: 1.2115 - val_accuracy: 0.5652\n",
            "Epoch 142/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.2617 - accuracy: 0.4825 - val_loss: 1.2150 - val_accuracy: 0.5507\n",
            "Epoch 143/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.2469 - accuracy: 0.4897 - val_loss: 1.2176 - val_accuracy: 0.5749\n",
            "Epoch 144/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.2284 - accuracy: 0.5097 - val_loss: 1.2085 - val_accuracy: 0.5556\n",
            "Epoch 145/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.2408 - accuracy: 0.4921 - val_loss: 1.2177 - val_accuracy: 0.5507\n",
            "Epoch 146/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.2360 - accuracy: 0.4940 - val_loss: 1.2070 - val_accuracy: 0.5507\n",
            "Epoch 147/500\n",
            "104/104 [==============================] - 1s 9ms/step - loss: 1.2311 - accuracy: 0.5048 - val_loss: 1.2115 - val_accuracy: 0.5314\n",
            "Epoch 148/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.2306 - accuracy: 0.5018 - val_loss: 1.1942 - val_accuracy: 0.5845\n",
            "Epoch 149/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.2275 - accuracy: 0.4964 - val_loss: 1.1939 - val_accuracy: 0.5652\n",
            "Epoch 150/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.2295 - accuracy: 0.5048 - val_loss: 1.1878 - val_accuracy: 0.5797\n",
            "Epoch 151/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.2270 - accuracy: 0.4994 - val_loss: 1.1944 - val_accuracy: 0.5652\n",
            "Epoch 152/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.2263 - accuracy: 0.5091 - val_loss: 1.1799 - val_accuracy: 0.5749\n",
            "Epoch 153/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.2248 - accuracy: 0.5048 - val_loss: 1.1934 - val_accuracy: 0.5121\n",
            "Epoch 154/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.2141 - accuracy: 0.5054 - val_loss: 1.1804 - val_accuracy: 0.5411\n",
            "Epoch 155/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.2080 - accuracy: 0.5024 - val_loss: 1.1882 - val_accuracy: 0.5411\n",
            "Epoch 156/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.2088 - accuracy: 0.5085 - val_loss: 1.1959 - val_accuracy: 0.5314\n",
            "Epoch 157/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.2076 - accuracy: 0.5248 - val_loss: 1.1734 - val_accuracy: 0.5652\n",
            "Epoch 158/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.1981 - accuracy: 0.5091 - val_loss: 1.1777 - val_accuracy: 0.5507\n",
            "Epoch 159/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.2033 - accuracy: 0.5157 - val_loss: 1.1679 - val_accuracy: 0.5700\n",
            "Epoch 160/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.2029 - accuracy: 0.5030 - val_loss: 1.1726 - val_accuracy: 0.5507\n",
            "Epoch 161/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.1884 - accuracy: 0.5254 - val_loss: 1.1485 - val_accuracy: 0.5942\n",
            "Epoch 162/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.1999 - accuracy: 0.5175 - val_loss: 1.1550 - val_accuracy: 0.5411\n",
            "Epoch 163/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.1783 - accuracy: 0.5351 - val_loss: 1.1617 - val_accuracy: 0.5894\n",
            "Epoch 164/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.1631 - accuracy: 0.5326 - val_loss: 1.1535 - val_accuracy: 0.5942\n",
            "Epoch 165/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.1538 - accuracy: 0.5381 - val_loss: 1.1471 - val_accuracy: 0.5604\n",
            "Epoch 166/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.1837 - accuracy: 0.5236 - val_loss: 1.1315 - val_accuracy: 0.6135\n",
            "Epoch 167/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.1609 - accuracy: 0.5320 - val_loss: 1.1334 - val_accuracy: 0.5652\n",
            "Epoch 168/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.1714 - accuracy: 0.5230 - val_loss: 1.1424 - val_accuracy: 0.5700\n",
            "Epoch 169/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.1576 - accuracy: 0.5399 - val_loss: 1.1443 - val_accuracy: 0.5411\n",
            "Epoch 170/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.1551 - accuracy: 0.5314 - val_loss: 1.1319 - val_accuracy: 0.5700\n",
            "Epoch 171/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.1384 - accuracy: 0.5320 - val_loss: 1.1315 - val_accuracy: 0.5942\n",
            "Epoch 172/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.1362 - accuracy: 0.5538 - val_loss: 1.1453 - val_accuracy: 0.5556\n",
            "Epoch 173/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.1633 - accuracy: 0.5381 - val_loss: 1.1125 - val_accuracy: 0.6087\n",
            "Epoch 174/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.1391 - accuracy: 0.5314 - val_loss: 1.1173 - val_accuracy: 0.5652\n",
            "Epoch 175/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.1382 - accuracy: 0.5417 - val_loss: 1.1123 - val_accuracy: 0.5845\n",
            "Epoch 176/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.1243 - accuracy: 0.5490 - val_loss: 1.1146 - val_accuracy: 0.5652\n",
            "Epoch 177/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.1271 - accuracy: 0.5417 - val_loss: 1.1090 - val_accuracy: 0.5845\n",
            "Epoch 178/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.1279 - accuracy: 0.5496 - val_loss: 1.1003 - val_accuracy: 0.6135\n",
            "Epoch 179/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.1299 - accuracy: 0.5423 - val_loss: 1.1142 - val_accuracy: 0.5652\n",
            "Epoch 180/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.1267 - accuracy: 0.5393 - val_loss: 1.1164 - val_accuracy: 0.5942\n",
            "Epoch 181/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.1098 - accuracy: 0.5568 - val_loss: 1.1070 - val_accuracy: 0.6184\n",
            "Epoch 182/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.1271 - accuracy: 0.5411 - val_loss: 1.1056 - val_accuracy: 0.5990\n",
            "Epoch 183/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0951 - accuracy: 0.5484 - val_loss: 1.0979 - val_accuracy: 0.6087\n",
            "Epoch 184/500\n",
            "104/104 [==============================] - 1s 9ms/step - loss: 1.0990 - accuracy: 0.5568 - val_loss: 1.0940 - val_accuracy: 0.5990\n",
            "Epoch 185/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.0918 - accuracy: 0.5647 - val_loss: 1.0908 - val_accuracy: 0.6135\n",
            "Epoch 186/500\n",
            "104/104 [==============================] - 1s 11ms/step - loss: 1.0957 - accuracy: 0.5586 - val_loss: 1.0929 - val_accuracy: 0.6039\n",
            "Epoch 187/500\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 1.0900 - accuracy: 0.5490 - val_loss: 1.0959 - val_accuracy: 0.5894\n",
            "Epoch 188/500\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 1.1112 - accuracy: 0.5447 - val_loss: 1.0817 - val_accuracy: 0.5942\n",
            "Epoch 189/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 1.0894 - accuracy: 0.5719 - val_loss: 1.0854 - val_accuracy: 0.6135\n",
            "Epoch 190/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 1.0889 - accuracy: 0.5538 - val_loss: 1.0837 - val_accuracy: 0.5894\n",
            "Epoch 191/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0917 - accuracy: 0.5719 - val_loss: 1.0690 - val_accuracy: 0.6039\n",
            "Epoch 192/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0777 - accuracy: 0.5738 - val_loss: 1.0666 - val_accuracy: 0.6087\n",
            "Epoch 193/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0857 - accuracy: 0.5677 - val_loss: 1.0772 - val_accuracy: 0.5990\n",
            "Epoch 194/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0974 - accuracy: 0.5707 - val_loss: 1.0724 - val_accuracy: 0.6039\n",
            "Epoch 195/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.0861 - accuracy: 0.5599 - val_loss: 1.0704 - val_accuracy: 0.6280\n",
            "Epoch 196/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.0791 - accuracy: 0.5574 - val_loss: 1.0660 - val_accuracy: 0.6329\n",
            "Epoch 197/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0691 - accuracy: 0.5719 - val_loss: 1.0591 - val_accuracy: 0.6280\n",
            "Epoch 198/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.0665 - accuracy: 0.5635 - val_loss: 1.0679 - val_accuracy: 0.6280\n",
            "Epoch 199/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.0528 - accuracy: 0.5834 - val_loss: 1.0581 - val_accuracy: 0.5942\n",
            "Epoch 200/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0512 - accuracy: 0.5719 - val_loss: 1.0559 - val_accuracy: 0.6087\n",
            "Epoch 201/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0586 - accuracy: 0.5786 - val_loss: 1.0683 - val_accuracy: 0.6087\n",
            "Epoch 202/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.0579 - accuracy: 0.5883 - val_loss: 1.0694 - val_accuracy: 0.6184\n",
            "Epoch 203/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0405 - accuracy: 0.5865 - val_loss: 1.0445 - val_accuracy: 0.6135\n",
            "Epoch 204/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.0423 - accuracy: 0.5828 - val_loss: 1.0525 - val_accuracy: 0.6425\n",
            "Epoch 205/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.0540 - accuracy: 0.5828 - val_loss: 1.0473 - val_accuracy: 0.6184\n",
            "Epoch 206/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0456 - accuracy: 0.5726 - val_loss: 1.0505 - val_accuracy: 0.6280\n",
            "Epoch 207/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0517 - accuracy: 0.5889 - val_loss: 1.0393 - val_accuracy: 0.6280\n",
            "Epoch 208/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.0567 - accuracy: 0.5750 - val_loss: 1.0398 - val_accuracy: 0.6618\n",
            "Epoch 209/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.0419 - accuracy: 0.5865 - val_loss: 1.0458 - val_accuracy: 0.6184\n",
            "Epoch 210/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.0434 - accuracy: 0.5732 - val_loss: 1.0347 - val_accuracy: 0.6329\n",
            "Epoch 211/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0365 - accuracy: 0.5913 - val_loss: 1.0317 - val_accuracy: 0.6329\n",
            "Epoch 212/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.0231 - accuracy: 0.5901 - val_loss: 1.0280 - val_accuracy: 0.6232\n",
            "Epoch 213/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.0298 - accuracy: 0.5846 - val_loss: 1.0290 - val_accuracy: 0.6425\n",
            "Epoch 214/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0059 - accuracy: 0.5961 - val_loss: 1.0232 - val_accuracy: 0.6135\n",
            "Epoch 215/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9910 - accuracy: 0.6119 - val_loss: 1.0271 - val_accuracy: 0.6087\n",
            "Epoch 216/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0063 - accuracy: 0.5955 - val_loss: 1.0230 - val_accuracy: 0.6473\n",
            "Epoch 217/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.0297 - accuracy: 0.5756 - val_loss: 1.0131 - val_accuracy: 0.6329\n",
            "Epoch 218/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.0092 - accuracy: 0.5998 - val_loss: 1.0273 - val_accuracy: 0.6232\n",
            "Epoch 219/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0165 - accuracy: 0.5895 - val_loss: 1.0167 - val_accuracy: 0.6135\n",
            "Epoch 220/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.0120 - accuracy: 0.5967 - val_loss: 1.0170 - val_accuracy: 0.5990\n",
            "Epoch 221/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0269 - accuracy: 0.5762 - val_loss: 1.0286 - val_accuracy: 0.6377\n",
            "Epoch 222/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0139 - accuracy: 0.5871 - val_loss: 1.0221 - val_accuracy: 0.6087\n",
            "Epoch 223/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9921 - accuracy: 0.6143 - val_loss: 1.0184 - val_accuracy: 0.6232\n",
            "Epoch 224/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0036 - accuracy: 0.6022 - val_loss: 1.0140 - val_accuracy: 0.6377\n",
            "Epoch 225/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.9875 - accuracy: 0.6058 - val_loss: 1.0082 - val_accuracy: 0.6425\n",
            "Epoch 226/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9962 - accuracy: 0.6004 - val_loss: 1.0075 - val_accuracy: 0.6522\n",
            "Epoch 227/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9847 - accuracy: 0.6004 - val_loss: 1.0086 - val_accuracy: 0.6087\n",
            "Epoch 228/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9887 - accuracy: 0.6125 - val_loss: 1.0032 - val_accuracy: 0.6135\n",
            "Epoch 229/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9909 - accuracy: 0.6070 - val_loss: 1.0187 - val_accuracy: 0.6473\n",
            "Epoch 230/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9744 - accuracy: 0.6052 - val_loss: 1.0028 - val_accuracy: 0.6280\n",
            "Epoch 231/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9787 - accuracy: 0.6094 - val_loss: 1.0150 - val_accuracy: 0.6425\n",
            "Epoch 232/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9714 - accuracy: 0.6143 - val_loss: 0.9894 - val_accuracy: 0.6232\n",
            "Epoch 233/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.9654 - accuracy: 0.6161 - val_loss: 0.9881 - val_accuracy: 0.6232\n",
            "Epoch 234/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.9841 - accuracy: 0.6022 - val_loss: 0.9937 - val_accuracy: 0.6232\n",
            "Epoch 235/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.9886 - accuracy: 0.6040 - val_loss: 0.9715 - val_accuracy: 0.6425\n",
            "Epoch 236/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9674 - accuracy: 0.6155 - val_loss: 0.9710 - val_accuracy: 0.6425\n",
            "Epoch 237/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9694 - accuracy: 0.6119 - val_loss: 0.9813 - val_accuracy: 0.6232\n",
            "Epoch 238/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.9828 - accuracy: 0.6179 - val_loss: 0.9710 - val_accuracy: 0.6618\n",
            "Epoch 239/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9655 - accuracy: 0.6046 - val_loss: 0.9643 - val_accuracy: 0.6763\n",
            "Epoch 240/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9851 - accuracy: 0.6125 - val_loss: 0.9755 - val_accuracy: 0.6425\n",
            "Epoch 241/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.9709 - accuracy: 0.6125 - val_loss: 0.9803 - val_accuracy: 0.6425\n",
            "Epoch 242/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.9848 - accuracy: 0.6088 - val_loss: 0.9733 - val_accuracy: 0.6473\n",
            "Epoch 243/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.9662 - accuracy: 0.6119 - val_loss: 0.9729 - val_accuracy: 0.6329\n",
            "Epoch 244/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9491 - accuracy: 0.6270 - val_loss: 0.9625 - val_accuracy: 0.6522\n",
            "Epoch 245/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.9687 - accuracy: 0.6034 - val_loss: 0.9636 - val_accuracy: 0.6570\n",
            "Epoch 246/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.9763 - accuracy: 0.6088 - val_loss: 0.9723 - val_accuracy: 0.6522\n",
            "Epoch 247/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9424 - accuracy: 0.6294 - val_loss: 0.9572 - val_accuracy: 0.6618\n",
            "Epoch 248/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9483 - accuracy: 0.6191 - val_loss: 0.9519 - val_accuracy: 0.6425\n",
            "Epoch 249/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9390 - accuracy: 0.6318 - val_loss: 0.9514 - val_accuracy: 0.6667\n",
            "Epoch 250/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.9339 - accuracy: 0.6342 - val_loss: 0.9541 - val_accuracy: 0.6329\n",
            "Epoch 251/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.9481 - accuracy: 0.6282 - val_loss: 0.9634 - val_accuracy: 0.6425\n",
            "Epoch 252/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9462 - accuracy: 0.6209 - val_loss: 0.9600 - val_accuracy: 0.6473\n",
            "Epoch 253/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.9343 - accuracy: 0.6336 - val_loss: 0.9401 - val_accuracy: 0.6473\n",
            "Epoch 254/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.9303 - accuracy: 0.6427 - val_loss: 0.9625 - val_accuracy: 0.6473\n",
            "Epoch 255/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.9368 - accuracy: 0.6215 - val_loss: 0.9583 - val_accuracy: 0.6473\n",
            "Epoch 256/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.9218 - accuracy: 0.6330 - val_loss: 0.9413 - val_accuracy: 0.6522\n",
            "Epoch 257/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9154 - accuracy: 0.6415 - val_loss: 0.9466 - val_accuracy: 0.6570\n",
            "Epoch 258/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.9150 - accuracy: 0.6354 - val_loss: 0.9408 - val_accuracy: 0.6763\n",
            "Epoch 259/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9145 - accuracy: 0.6366 - val_loss: 0.9337 - val_accuracy: 0.6473\n",
            "Epoch 260/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.9083 - accuracy: 0.6439 - val_loss: 0.9694 - val_accuracy: 0.6329\n",
            "Epoch 261/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9122 - accuracy: 0.6475 - val_loss: 0.9381 - val_accuracy: 0.6522\n",
            "Epoch 262/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.9056 - accuracy: 0.6348 - val_loss: 0.9378 - val_accuracy: 0.6522\n",
            "Epoch 263/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9241 - accuracy: 0.6366 - val_loss: 0.9404 - val_accuracy: 0.6618\n",
            "Epoch 264/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.9065 - accuracy: 0.6421 - val_loss: 0.9236 - val_accuracy: 0.6667\n",
            "Epoch 265/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9034 - accuracy: 0.6378 - val_loss: 0.9281 - val_accuracy: 0.6667\n",
            "Epoch 266/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8861 - accuracy: 0.6469 - val_loss: 0.9352 - val_accuracy: 0.6280\n",
            "Epoch 267/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9116 - accuracy: 0.6524 - val_loss: 0.9322 - val_accuracy: 0.6473\n",
            "Epoch 268/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9165 - accuracy: 0.6445 - val_loss: 0.9295 - val_accuracy: 0.6522\n",
            "Epoch 269/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.9072 - accuracy: 0.6378 - val_loss: 0.9274 - val_accuracy: 0.6812\n",
            "Epoch 270/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8893 - accuracy: 0.6372 - val_loss: 0.9144 - val_accuracy: 0.6570\n",
            "Epoch 271/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9013 - accuracy: 0.6391 - val_loss: 0.9176 - val_accuracy: 0.6667\n",
            "Epoch 272/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8956 - accuracy: 0.6487 - val_loss: 0.9219 - val_accuracy: 0.6425\n",
            "Epoch 273/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8953 - accuracy: 0.6385 - val_loss: 0.9114 - val_accuracy: 0.6570\n",
            "Epoch 274/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.8839 - accuracy: 0.6336 - val_loss: 0.9122 - val_accuracy: 0.6618\n",
            "Epoch 275/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9065 - accuracy: 0.6354 - val_loss: 0.9119 - val_accuracy: 0.6715\n",
            "Epoch 276/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8853 - accuracy: 0.6590 - val_loss: 0.9077 - val_accuracy: 0.6763\n",
            "Epoch 277/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8873 - accuracy: 0.6427 - val_loss: 0.9067 - val_accuracy: 0.6618\n",
            "Epoch 278/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8809 - accuracy: 0.6487 - val_loss: 0.9004 - val_accuracy: 0.6908\n",
            "Epoch 279/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.9009 - accuracy: 0.6330 - val_loss: 0.9245 - val_accuracy: 0.6570\n",
            "Epoch 280/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.8656 - accuracy: 0.6578 - val_loss: 0.9086 - val_accuracy: 0.6763\n",
            "Epoch 281/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8614 - accuracy: 0.6717 - val_loss: 0.9086 - val_accuracy: 0.6522\n",
            "Epoch 282/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8796 - accuracy: 0.6421 - val_loss: 0.9124 - val_accuracy: 0.6377\n",
            "Epoch 283/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8831 - accuracy: 0.6397 - val_loss: 0.9156 - val_accuracy: 0.6618\n",
            "Epoch 284/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.8955 - accuracy: 0.6518 - val_loss: 0.9054 - val_accuracy: 0.6473\n",
            "Epoch 285/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.8754 - accuracy: 0.6475 - val_loss: 0.9036 - val_accuracy: 0.6667\n",
            "Epoch 286/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.8560 - accuracy: 0.6572 - val_loss: 0.9091 - val_accuracy: 0.6763\n",
            "Epoch 287/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8731 - accuracy: 0.6524 - val_loss: 0.9323 - val_accuracy: 0.6522\n",
            "Epoch 288/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8603 - accuracy: 0.6566 - val_loss: 0.9163 - val_accuracy: 0.6425\n",
            "Epoch 289/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.8638 - accuracy: 0.6493 - val_loss: 0.8887 - val_accuracy: 0.6715\n",
            "Epoch 290/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8438 - accuracy: 0.6693 - val_loss: 0.8990 - val_accuracy: 0.6618\n",
            "Epoch 291/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8606 - accuracy: 0.6524 - val_loss: 0.8998 - val_accuracy: 0.6473\n",
            "Epoch 292/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8590 - accuracy: 0.6590 - val_loss: 0.8963 - val_accuracy: 0.6618\n",
            "Epoch 293/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8626 - accuracy: 0.6511 - val_loss: 0.8962 - val_accuracy: 0.6522\n",
            "Epoch 294/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8703 - accuracy: 0.6536 - val_loss: 0.8929 - val_accuracy: 0.6667\n",
            "Epoch 295/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.8541 - accuracy: 0.6717 - val_loss: 0.8815 - val_accuracy: 0.7005\n",
            "Epoch 296/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8553 - accuracy: 0.6536 - val_loss: 0.9091 - val_accuracy: 0.6667\n",
            "Epoch 297/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8581 - accuracy: 0.6542 - val_loss: 0.8891 - val_accuracy: 0.6715\n",
            "Epoch 298/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8500 - accuracy: 0.6657 - val_loss: 0.8881 - val_accuracy: 0.6618\n",
            "Epoch 299/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8662 - accuracy: 0.6602 - val_loss: 0.8763 - val_accuracy: 0.6667\n",
            "Epoch 300/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8384 - accuracy: 0.6596 - val_loss: 0.8714 - val_accuracy: 0.6860\n",
            "Epoch 301/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8541 - accuracy: 0.6548 - val_loss: 0.8732 - val_accuracy: 0.6908\n",
            "Epoch 302/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8581 - accuracy: 0.6524 - val_loss: 0.8824 - val_accuracy: 0.6908\n",
            "Epoch 303/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8372 - accuracy: 0.6614 - val_loss: 0.8761 - val_accuracy: 0.6763\n",
            "Epoch 304/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8506 - accuracy: 0.6681 - val_loss: 0.8722 - val_accuracy: 0.6667\n",
            "Epoch 305/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8411 - accuracy: 0.6723 - val_loss: 0.8648 - val_accuracy: 0.6860\n",
            "Epoch 306/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8082 - accuracy: 0.6862 - val_loss: 0.8564 - val_accuracy: 0.6812\n",
            "Epoch 307/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8411 - accuracy: 0.6693 - val_loss: 0.8676 - val_accuracy: 0.6812\n",
            "Epoch 308/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8245 - accuracy: 0.6838 - val_loss: 0.8744 - val_accuracy: 0.6860\n",
            "Epoch 309/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8289 - accuracy: 0.6723 - val_loss: 0.8651 - val_accuracy: 0.6908\n",
            "Epoch 310/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8055 - accuracy: 0.6759 - val_loss: 0.8774 - val_accuracy: 0.6763\n",
            "Epoch 311/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8302 - accuracy: 0.6784 - val_loss: 0.8659 - val_accuracy: 0.6715\n",
            "Epoch 312/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8283 - accuracy: 0.6753 - val_loss: 0.8653 - val_accuracy: 0.6715\n",
            "Epoch 313/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8098 - accuracy: 0.6826 - val_loss: 0.8504 - val_accuracy: 0.7053\n",
            "Epoch 314/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8231 - accuracy: 0.6687 - val_loss: 0.8483 - val_accuracy: 0.6957\n",
            "Epoch 315/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8111 - accuracy: 0.6747 - val_loss: 0.8466 - val_accuracy: 0.7101\n",
            "Epoch 316/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.8339 - accuracy: 0.6584 - val_loss: 0.8475 - val_accuracy: 0.6860\n",
            "Epoch 317/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8096 - accuracy: 0.6759 - val_loss: 0.8434 - val_accuracy: 0.6908\n",
            "Epoch 318/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8339 - accuracy: 0.6657 - val_loss: 0.8540 - val_accuracy: 0.6812\n",
            "Epoch 319/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.8209 - accuracy: 0.6735 - val_loss: 0.8514 - val_accuracy: 0.6763\n",
            "Epoch 320/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.8193 - accuracy: 0.6741 - val_loss: 0.8468 - val_accuracy: 0.6957\n",
            "Epoch 321/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.8188 - accuracy: 0.6862 - val_loss: 0.8606 - val_accuracy: 0.6715\n",
            "Epoch 322/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8201 - accuracy: 0.6644 - val_loss: 0.8365 - val_accuracy: 0.7246\n",
            "Epoch 323/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7903 - accuracy: 0.6862 - val_loss: 0.8597 - val_accuracy: 0.6715\n",
            "Epoch 324/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8200 - accuracy: 0.6778 - val_loss: 0.8342 - val_accuracy: 0.7101\n",
            "Epoch 325/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7894 - accuracy: 0.6862 - val_loss: 0.8337 - val_accuracy: 0.6908\n",
            "Epoch 326/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.7875 - accuracy: 0.6923 - val_loss: 0.8349 - val_accuracy: 0.6812\n",
            "Epoch 327/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8118 - accuracy: 0.6584 - val_loss: 0.8229 - val_accuracy: 0.7150\n",
            "Epoch 328/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.8203 - accuracy: 0.6844 - val_loss: 0.8325 - val_accuracy: 0.6957\n",
            "Epoch 329/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8118 - accuracy: 0.6747 - val_loss: 0.8346 - val_accuracy: 0.6908\n",
            "Epoch 330/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8145 - accuracy: 0.6868 - val_loss: 0.8472 - val_accuracy: 0.6957\n",
            "Epoch 331/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8092 - accuracy: 0.6784 - val_loss: 0.8482 - val_accuracy: 0.6715\n",
            "Epoch 332/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.8090 - accuracy: 0.6790 - val_loss: 0.8429 - val_accuracy: 0.6908\n",
            "Epoch 333/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7894 - accuracy: 0.6935 - val_loss: 0.8246 - val_accuracy: 0.7246\n",
            "Epoch 334/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.7968 - accuracy: 0.6784 - val_loss: 0.8300 - val_accuracy: 0.7053\n",
            "Epoch 335/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7848 - accuracy: 0.6923 - val_loss: 0.8422 - val_accuracy: 0.6763\n",
            "Epoch 336/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7822 - accuracy: 0.6941 - val_loss: 0.8339 - val_accuracy: 0.6957\n",
            "Epoch 337/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7876 - accuracy: 0.6784 - val_loss: 0.8212 - val_accuracy: 0.7053\n",
            "Epoch 338/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.7669 - accuracy: 0.6995 - val_loss: 0.8379 - val_accuracy: 0.7101\n",
            "Epoch 339/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7782 - accuracy: 0.6911 - val_loss: 0.8212 - val_accuracy: 0.6957\n",
            "Epoch 340/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.7967 - accuracy: 0.6862 - val_loss: 0.8159 - val_accuracy: 0.7150\n",
            "Epoch 341/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7973 - accuracy: 0.6862 - val_loss: 0.8440 - val_accuracy: 0.6860\n",
            "Epoch 342/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7741 - accuracy: 0.6904 - val_loss: 0.8301 - val_accuracy: 0.6957\n",
            "Epoch 343/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8025 - accuracy: 0.6747 - val_loss: 0.8186 - val_accuracy: 0.7053\n",
            "Epoch 344/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7787 - accuracy: 0.6935 - val_loss: 0.8176 - val_accuracy: 0.7005\n",
            "Epoch 345/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7676 - accuracy: 0.7080 - val_loss: 0.8297 - val_accuracy: 0.7101\n",
            "Epoch 346/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7762 - accuracy: 0.6844 - val_loss: 0.8260 - val_accuracy: 0.6908\n",
            "Epoch 347/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7672 - accuracy: 0.6826 - val_loss: 0.8202 - val_accuracy: 0.7005\n",
            "Epoch 348/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7775 - accuracy: 0.6844 - val_loss: 0.8055 - val_accuracy: 0.7101\n",
            "Epoch 349/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7833 - accuracy: 0.6917 - val_loss: 0.8152 - val_accuracy: 0.7391\n",
            "Epoch 350/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7768 - accuracy: 0.7013 - val_loss: 0.8017 - val_accuracy: 0.7101\n",
            "Epoch 351/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.7656 - accuracy: 0.6898 - val_loss: 0.7999 - val_accuracy: 0.7343\n",
            "Epoch 352/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.7721 - accuracy: 0.6856 - val_loss: 0.8139 - val_accuracy: 0.7053\n",
            "Epoch 353/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7790 - accuracy: 0.6814 - val_loss: 0.8163 - val_accuracy: 0.7150\n",
            "Epoch 354/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7626 - accuracy: 0.6983 - val_loss: 0.8077 - val_accuracy: 0.7101\n",
            "Epoch 355/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7645 - accuracy: 0.6880 - val_loss: 0.8328 - val_accuracy: 0.6763\n",
            "Epoch 356/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7610 - accuracy: 0.6977 - val_loss: 0.8093 - val_accuracy: 0.6957\n",
            "Epoch 357/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7518 - accuracy: 0.6959 - val_loss: 0.7994 - val_accuracy: 0.7198\n",
            "Epoch 358/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7754 - accuracy: 0.6929 - val_loss: 0.7965 - val_accuracy: 0.7246\n",
            "Epoch 359/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7564 - accuracy: 0.7050 - val_loss: 0.7925 - val_accuracy: 0.7295\n",
            "Epoch 360/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7415 - accuracy: 0.7128 - val_loss: 0.8008 - val_accuracy: 0.7150\n",
            "Epoch 361/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.7587 - accuracy: 0.6929 - val_loss: 0.7888 - val_accuracy: 0.7150\n",
            "Epoch 362/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7806 - accuracy: 0.6856 - val_loss: 0.8011 - val_accuracy: 0.7150\n",
            "Epoch 363/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7591 - accuracy: 0.7080 - val_loss: 0.7973 - val_accuracy: 0.7101\n",
            "Epoch 364/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7553 - accuracy: 0.6904 - val_loss: 0.8079 - val_accuracy: 0.7101\n",
            "Epoch 365/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7534 - accuracy: 0.6923 - val_loss: 0.8071 - val_accuracy: 0.7101\n",
            "Epoch 366/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7380 - accuracy: 0.7170 - val_loss: 0.7979 - val_accuracy: 0.7198\n",
            "Epoch 367/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7604 - accuracy: 0.7044 - val_loss: 0.7996 - val_accuracy: 0.7150\n",
            "Epoch 368/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7444 - accuracy: 0.7062 - val_loss: 0.7968 - val_accuracy: 0.7101\n",
            "Epoch 369/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7533 - accuracy: 0.7007 - val_loss: 0.8138 - val_accuracy: 0.6908\n",
            "Epoch 370/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7485 - accuracy: 0.7056 - val_loss: 0.7913 - val_accuracy: 0.7391\n",
            "Epoch 371/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7281 - accuracy: 0.7080 - val_loss: 0.7888 - val_accuracy: 0.7246\n",
            "Epoch 372/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7370 - accuracy: 0.7273 - val_loss: 0.7894 - val_accuracy: 0.7343\n",
            "Epoch 373/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7342 - accuracy: 0.7140 - val_loss: 0.7975 - val_accuracy: 0.7101\n",
            "Epoch 374/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7304 - accuracy: 0.7098 - val_loss: 0.7984 - val_accuracy: 0.7295\n",
            "Epoch 375/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7143 - accuracy: 0.7285 - val_loss: 0.7915 - val_accuracy: 0.7150\n",
            "Epoch 376/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7391 - accuracy: 0.7170 - val_loss: 0.8004 - val_accuracy: 0.7053\n",
            "Epoch 377/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7116 - accuracy: 0.7304 - val_loss: 0.7883 - val_accuracy: 0.7150\n",
            "Epoch 378/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7418 - accuracy: 0.7013 - val_loss: 0.7951 - val_accuracy: 0.7101\n",
            "Epoch 379/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.7372 - accuracy: 0.7140 - val_loss: 0.7903 - val_accuracy: 0.7198\n",
            "Epoch 380/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7385 - accuracy: 0.6959 - val_loss: 0.7942 - val_accuracy: 0.7101\n",
            "Epoch 381/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.7289 - accuracy: 0.7068 - val_loss: 0.7859 - val_accuracy: 0.7198\n",
            "Epoch 382/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7186 - accuracy: 0.7134 - val_loss: 0.7863 - val_accuracy: 0.7150\n",
            "Epoch 383/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7282 - accuracy: 0.7237 - val_loss: 0.7734 - val_accuracy: 0.7440\n",
            "Epoch 384/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7150 - accuracy: 0.7158 - val_loss: 0.7934 - val_accuracy: 0.7198\n",
            "Epoch 385/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7164 - accuracy: 0.7255 - val_loss: 0.8090 - val_accuracy: 0.7198\n",
            "Epoch 386/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7274 - accuracy: 0.7170 - val_loss: 0.7831 - val_accuracy: 0.7101\n",
            "Epoch 387/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7138 - accuracy: 0.7146 - val_loss: 0.7777 - val_accuracy: 0.7488\n",
            "Epoch 388/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7487 - accuracy: 0.6995 - val_loss: 0.7926 - val_accuracy: 0.7150\n",
            "Epoch 389/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7123 - accuracy: 0.7140 - val_loss: 0.7753 - val_accuracy: 0.7198\n",
            "Epoch 390/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7226 - accuracy: 0.7116 - val_loss: 0.7700 - val_accuracy: 0.7343\n",
            "Epoch 391/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7104 - accuracy: 0.7219 - val_loss: 0.7716 - val_accuracy: 0.7343\n",
            "Epoch 392/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7164 - accuracy: 0.7116 - val_loss: 0.7657 - val_accuracy: 0.7343\n",
            "Epoch 393/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7166 - accuracy: 0.7170 - val_loss: 0.7652 - val_accuracy: 0.7391\n",
            "Epoch 394/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6907 - accuracy: 0.7189 - val_loss: 0.7647 - val_accuracy: 0.7101\n",
            "Epoch 395/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.7224 - accuracy: 0.7177 - val_loss: 0.7643 - val_accuracy: 0.7391\n",
            "Epoch 396/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6970 - accuracy: 0.7050 - val_loss: 0.7545 - val_accuracy: 0.7440\n",
            "Epoch 397/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7064 - accuracy: 0.7213 - val_loss: 0.7531 - val_accuracy: 0.7246\n",
            "Epoch 398/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6890 - accuracy: 0.7352 - val_loss: 0.7697 - val_accuracy: 0.7005\n",
            "Epoch 399/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7168 - accuracy: 0.7158 - val_loss: 0.7768 - val_accuracy: 0.7101\n",
            "Epoch 400/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7001 - accuracy: 0.7352 - val_loss: 0.7654 - val_accuracy: 0.7681\n",
            "Epoch 401/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6955 - accuracy: 0.7297 - val_loss: 0.7738 - val_accuracy: 0.7198\n",
            "Epoch 402/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6944 - accuracy: 0.7207 - val_loss: 0.7540 - val_accuracy: 0.7391\n",
            "Epoch 403/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7247 - accuracy: 0.7164 - val_loss: 0.7572 - val_accuracy: 0.7488\n",
            "Epoch 404/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6828 - accuracy: 0.7328 - val_loss: 0.7508 - val_accuracy: 0.7391\n",
            "Epoch 405/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7047 - accuracy: 0.7122 - val_loss: 0.7387 - val_accuracy: 0.7391\n",
            "Epoch 406/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7084 - accuracy: 0.7128 - val_loss: 0.7402 - val_accuracy: 0.7295\n",
            "Epoch 407/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7067 - accuracy: 0.7134 - val_loss: 0.7394 - val_accuracy: 0.7343\n",
            "Epoch 408/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7030 - accuracy: 0.7116 - val_loss: 0.7525 - val_accuracy: 0.7343\n",
            "Epoch 409/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7022 - accuracy: 0.7225 - val_loss: 0.7553 - val_accuracy: 0.7343\n",
            "Epoch 410/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6816 - accuracy: 0.7430 - val_loss: 0.7505 - val_accuracy: 0.7101\n",
            "Epoch 411/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6821 - accuracy: 0.7225 - val_loss: 0.7428 - val_accuracy: 0.7440\n",
            "Epoch 412/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6914 - accuracy: 0.7376 - val_loss: 0.7409 - val_accuracy: 0.7343\n",
            "Epoch 413/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6893 - accuracy: 0.7279 - val_loss: 0.7680 - val_accuracy: 0.7246\n",
            "Epoch 414/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6933 - accuracy: 0.7237 - val_loss: 0.7401 - val_accuracy: 0.7440\n",
            "Epoch 415/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7001 - accuracy: 0.7225 - val_loss: 0.7483 - val_accuracy: 0.7391\n",
            "Epoch 416/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6885 - accuracy: 0.7370 - val_loss: 0.7527 - val_accuracy: 0.7295\n",
            "Epoch 417/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6867 - accuracy: 0.7207 - val_loss: 0.7493 - val_accuracy: 0.7488\n",
            "Epoch 418/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6872 - accuracy: 0.7207 - val_loss: 0.7593 - val_accuracy: 0.7295\n",
            "Epoch 419/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6735 - accuracy: 0.7382 - val_loss: 0.7478 - val_accuracy: 0.7246\n",
            "Epoch 420/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6727 - accuracy: 0.7291 - val_loss: 0.7541 - val_accuracy: 0.7343\n",
            "Epoch 421/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6958 - accuracy: 0.7352 - val_loss: 0.7481 - val_accuracy: 0.7295\n",
            "Epoch 422/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6801 - accuracy: 0.7322 - val_loss: 0.7479 - val_accuracy: 0.7391\n",
            "Epoch 423/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6767 - accuracy: 0.7249 - val_loss: 0.7397 - val_accuracy: 0.7488\n",
            "Epoch 424/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6480 - accuracy: 0.7364 - val_loss: 0.7432 - val_accuracy: 0.7343\n",
            "Epoch 425/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6684 - accuracy: 0.7340 - val_loss: 0.7376 - val_accuracy: 0.7585\n",
            "Epoch 426/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6710 - accuracy: 0.7437 - val_loss: 0.7481 - val_accuracy: 0.7585\n",
            "Epoch 427/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.6740 - accuracy: 0.7297 - val_loss: 0.7488 - val_accuracy: 0.7343\n",
            "Epoch 428/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6819 - accuracy: 0.7346 - val_loss: 0.7483 - val_accuracy: 0.7198\n",
            "Epoch 429/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6809 - accuracy: 0.7273 - val_loss: 0.7495 - val_accuracy: 0.7536\n",
            "Epoch 430/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6652 - accuracy: 0.7340 - val_loss: 0.7510 - val_accuracy: 0.7536\n",
            "Epoch 431/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6484 - accuracy: 0.7424 - val_loss: 0.7364 - val_accuracy: 0.7246\n",
            "Epoch 432/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6686 - accuracy: 0.7479 - val_loss: 0.7393 - val_accuracy: 0.7246\n",
            "Epoch 433/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6763 - accuracy: 0.7219 - val_loss: 0.7657 - val_accuracy: 0.7101\n",
            "Epoch 434/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6683 - accuracy: 0.7479 - val_loss: 0.7474 - val_accuracy: 0.7440\n",
            "Epoch 435/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6616 - accuracy: 0.7346 - val_loss: 0.7549 - val_accuracy: 0.7295\n",
            "Epoch 436/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6604 - accuracy: 0.7449 - val_loss: 0.7402 - val_accuracy: 0.7246\n",
            "Epoch 437/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6452 - accuracy: 0.7473 - val_loss: 0.7413 - val_accuracy: 0.7440\n",
            "Epoch 438/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6533 - accuracy: 0.7388 - val_loss: 0.7420 - val_accuracy: 0.7295\n",
            "Epoch 439/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6584 - accuracy: 0.7437 - val_loss: 0.7348 - val_accuracy: 0.7440\n",
            "Epoch 440/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6577 - accuracy: 0.7358 - val_loss: 0.7312 - val_accuracy: 0.7391\n",
            "Epoch 441/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6347 - accuracy: 0.7430 - val_loss: 0.7361 - val_accuracy: 0.7440\n",
            "Epoch 442/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6539 - accuracy: 0.7473 - val_loss: 0.7401 - val_accuracy: 0.7053\n",
            "Epoch 443/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6238 - accuracy: 0.7606 - val_loss: 0.7449 - val_accuracy: 0.7391\n",
            "Epoch 444/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6758 - accuracy: 0.7334 - val_loss: 0.7514 - val_accuracy: 0.7198\n",
            "Epoch 445/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6342 - accuracy: 0.7485 - val_loss: 0.7336 - val_accuracy: 0.7343\n",
            "Epoch 446/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6356 - accuracy: 0.7437 - val_loss: 0.7500 - val_accuracy: 0.7101\n",
            "Epoch 447/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.6544 - accuracy: 0.7449 - val_loss: 0.7483 - val_accuracy: 0.7343\n",
            "Epoch 448/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6545 - accuracy: 0.7376 - val_loss: 0.7631 - val_accuracy: 0.7101\n",
            "Epoch 449/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 0.6540 - accuracy: 0.7370 - val_loss: 0.7437 - val_accuracy: 0.7343\n",
            "Epoch 450/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6493 - accuracy: 0.7491 - val_loss: 0.7322 - val_accuracy: 0.7488\n",
            "Epoch 451/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6356 - accuracy: 0.7479 - val_loss: 0.7405 - val_accuracy: 0.7053\n",
            "Epoch 452/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6477 - accuracy: 0.7394 - val_loss: 0.7264 - val_accuracy: 0.7343\n",
            "Epoch 453/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6421 - accuracy: 0.7376 - val_loss: 0.7174 - val_accuracy: 0.7633\n",
            "Epoch 454/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6428 - accuracy: 0.7479 - val_loss: 0.7289 - val_accuracy: 0.7440\n",
            "Epoch 455/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6287 - accuracy: 0.7654 - val_loss: 0.7157 - val_accuracy: 0.7536\n",
            "Epoch 456/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6211 - accuracy: 0.7551 - val_loss: 0.7321 - val_accuracy: 0.7343\n",
            "Epoch 457/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6426 - accuracy: 0.7503 - val_loss: 0.7253 - val_accuracy: 0.7440\n",
            "Epoch 458/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6398 - accuracy: 0.7358 - val_loss: 0.7333 - val_accuracy: 0.7343\n",
            "Epoch 459/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6353 - accuracy: 0.7443 - val_loss: 0.7382 - val_accuracy: 0.7343\n",
            "Epoch 460/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6294 - accuracy: 0.7406 - val_loss: 0.7244 - val_accuracy: 0.7295\n",
            "Epoch 461/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6232 - accuracy: 0.7503 - val_loss: 0.7148 - val_accuracy: 0.7440\n",
            "Epoch 462/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6339 - accuracy: 0.7479 - val_loss: 0.7164 - val_accuracy: 0.7536\n",
            "Epoch 463/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6233 - accuracy: 0.7527 - val_loss: 0.7189 - val_accuracy: 0.7536\n",
            "Epoch 464/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6337 - accuracy: 0.7412 - val_loss: 0.7156 - val_accuracy: 0.7391\n",
            "Epoch 465/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6287 - accuracy: 0.7600 - val_loss: 0.7133 - val_accuracy: 0.7488\n",
            "Epoch 466/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6163 - accuracy: 0.7588 - val_loss: 0.7243 - val_accuracy: 0.7343\n",
            "Epoch 467/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6137 - accuracy: 0.7533 - val_loss: 0.7181 - val_accuracy: 0.7391\n",
            "Epoch 468/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6369 - accuracy: 0.7418 - val_loss: 0.7160 - val_accuracy: 0.7488\n",
            "Epoch 469/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6286 - accuracy: 0.7570 - val_loss: 0.7110 - val_accuracy: 0.7536\n",
            "Epoch 470/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6121 - accuracy: 0.7570 - val_loss: 0.7129 - val_accuracy: 0.7681\n",
            "Epoch 471/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6212 - accuracy: 0.7509 - val_loss: 0.7241 - val_accuracy: 0.7440\n",
            "Epoch 472/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6457 - accuracy: 0.7509 - val_loss: 0.7161 - val_accuracy: 0.7295\n",
            "Epoch 473/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6253 - accuracy: 0.7545 - val_loss: 0.7117 - val_accuracy: 0.7343\n",
            "Epoch 474/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6198 - accuracy: 0.7533 - val_loss: 0.7158 - val_accuracy: 0.7246\n",
            "Epoch 475/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6239 - accuracy: 0.7576 - val_loss: 0.7192 - val_accuracy: 0.7391\n",
            "Epoch 476/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5998 - accuracy: 0.7672 - val_loss: 0.7018 - val_accuracy: 0.7391\n",
            "Epoch 477/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6118 - accuracy: 0.7570 - val_loss: 0.7091 - val_accuracy: 0.7488\n",
            "Epoch 478/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6281 - accuracy: 0.7400 - val_loss: 0.7092 - val_accuracy: 0.7729\n",
            "Epoch 479/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6187 - accuracy: 0.7545 - val_loss: 0.6964 - val_accuracy: 0.7633\n",
            "Epoch 480/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6198 - accuracy: 0.7509 - val_loss: 0.7024 - val_accuracy: 0.7681\n",
            "Epoch 481/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6030 - accuracy: 0.7709 - val_loss: 0.6913 - val_accuracy: 0.7585\n",
            "Epoch 482/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6304 - accuracy: 0.7467 - val_loss: 0.7101 - val_accuracy: 0.7488\n",
            "Epoch 483/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6276 - accuracy: 0.7551 - val_loss: 0.7065 - val_accuracy: 0.7585\n",
            "Epoch 484/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6093 - accuracy: 0.7715 - val_loss: 0.7164 - val_accuracy: 0.7391\n",
            "Epoch 485/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6155 - accuracy: 0.7443 - val_loss: 0.7169 - val_accuracy: 0.7440\n",
            "Epoch 486/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.5845 - accuracy: 0.7739 - val_loss: 0.7035 - val_accuracy: 0.7681\n",
            "Epoch 487/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6060 - accuracy: 0.7576 - val_loss: 0.7068 - val_accuracy: 0.7585\n",
            "Epoch 488/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5876 - accuracy: 0.7757 - val_loss: 0.6931 - val_accuracy: 0.7536\n",
            "Epoch 489/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6118 - accuracy: 0.7570 - val_loss: 0.6915 - val_accuracy: 0.7633\n",
            "Epoch 490/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6071 - accuracy: 0.7588 - val_loss: 0.7023 - val_accuracy: 0.7488\n",
            "Epoch 491/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6075 - accuracy: 0.7461 - val_loss: 0.7025 - val_accuracy: 0.7488\n",
            "Epoch 492/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6164 - accuracy: 0.7533 - val_loss: 0.6996 - val_accuracy: 0.7488\n",
            "Epoch 493/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5898 - accuracy: 0.7715 - val_loss: 0.6986 - val_accuracy: 0.7633\n",
            "Epoch 494/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.5777 - accuracy: 0.7817 - val_loss: 0.6842 - val_accuracy: 0.7778\n",
            "Epoch 495/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6019 - accuracy: 0.7636 - val_loss: 0.7111 - val_accuracy: 0.7391\n",
            "Epoch 496/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6058 - accuracy: 0.7594 - val_loss: 0.6979 - val_accuracy: 0.7488\n",
            "Epoch 497/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5851 - accuracy: 0.7606 - val_loss: 0.6984 - val_accuracy: 0.7585\n",
            "Epoch 498/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6045 - accuracy: 0.7703 - val_loss: 0.6930 - val_accuracy: 0.7536\n",
            "Epoch 499/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.6045 - accuracy: 0.7533 - val_loss: 0.6939 - val_accuracy: 0.7536\n",
            "Epoch 500/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5890 - accuracy: 0.7721 - val_loss: 0.6948 - val_accuracy: 0.7488\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(cnnhistory.history['loss'])\n",
        "plt.plot(cnnhistory.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train','test'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "oQYnuaCrDH_A",
        "outputId": "be716e85-c729-4707-957f-f4627134461f"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXgAAAEWCAYAAABsY4yMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dd3xd9Z3n/9fnFvViNVdZlnuj2LjTS3CAEJIMCSGB7CzJYvLY/FJ2WAaYTRmyszPZnXkkDAkTQgYmBYYJoUwIEEI13eAKuDdc5KZiy+rSLd/fH+dIlizZ2DLXVzp6Px8PPe69p9zzPdfy+371Oed8jznnEBGR4AmluwEiIpIaCngRkYBSwIuIBJQCXkQkoBTwIiIBpYAXEQkoBbwIYGa/MrO/O8Fld5jZJ071fURSTQEvIhJQCngRkYBSwMug4ZdGbjOz982s2cweMLMRZvYnM2s0sxfNrKjb8teY2TozqzezpWY2vdu82Wa2yl/vd0DWUdu62szW+Ou+ZWZn9bPNN5vZVjM7aGZPmdlof7qZ2U/MrNrMGszsAzM7w593lZmt99u2x8z+Z78+MBnyFPAy2FwLXA5MAT4N/An4G6AM7/f5WwBmNgV4BPiOP+9Z4I9mlmFmGcB/Ar8FioHf+++Lv+5s4EHgFqAE+AXwlJllnkxDzexS4B+A64BRwE7gP/zZi4EL/f0o9Jep8+c9ANzinMsHzgBePpntinRSwMtg81Pn3AHn3B7gdeAd59xq51wb8CQw21/ui8AzzrkXnHMx4J+AbOBcYCEQBe52zsWcc48By7ttYwnwC+fcO865hHPu10C7v97JuAF40Dm3yjnXDtwJLDKzSiAG5APTAHPObXDO7fPXiwEzzKzAOXfIObfqJLcrAijgZfA50O15ax+v8/zno/F6zAA455LAbmCMP2+P6znS3s5uz8cBt/rlmXozqwfG+uudjKPb0ITXSx/jnHsZ+BlwL1BtZvebWYG/6LXAVcBOM3vVzBad5HZFAAW8BNdevKAGvJo3XkjvAfYBY/xpnSq6Pd8N/B/n3LBuPznOuUdOsQ25eCWfPQDOuXucc3OAGXilmtv86cudc58BhuOVkh49ye2KAAp4Ca5HgU+Z2WVmFgVuxSuzvAW8DcSBb5lZ1Mz+Apjfbd1fAl83swX+wdBcM/uUmeWfZBseAW4ys1l+/f7v8UpKO8xsnv/+UaAZaAOS/jGCG8ys0C8tNQDJU/gcZAhTwEsgOec2ATcCPwVq8Q7Ifto51+Gc6wD+AvivwEG8ev0T3dZdAdyMV0I5BGz1lz3ZNrwIfA94HO+vhonA9f7sArwvkkN4ZZw64B/9eV8BdphZA/B1vFq+yEkz3fBDRCSY1IMXEQkoBbyISEAp4EVEAkoBLyISUJF0N6C70tJSV1lZme5miIgMGitXrqx1zpX1NW9ABXxlZSUrVqxIdzNERAYNM9t5rHkq0YiIBJQCXkQkoBTwIiIBNaBq8H2JxWJUVVXR1taW7qakVFZWFuXl5USj0XQ3RUQCYsAHfFVVFfn5+VRWVtJz8L/gcM5RV1dHVVUV48ePT3dzRCQgBnyJpq2tjZKSksCGO4CZUVJSEvi/UkTk9EppwJvZMDN7zMw2mtmG/t64IMjh3mko7KOInF6pLtH8M/Ccc+7z/n0wc1KxkQMNbeRkhMnPUv1aRKRTynrwZlaId1PhBwD8cbjrU7GtmsZ2mtriqXhr6uvr+Zd/+ZeTXu+qq66ivj4luysickJSWaIZD9QA/2Zmq83sX/1blvVgZkvMbIWZraipqenXhgxI1aj2xwr4ePz4XyjPPvssw4YNS1GrREQ+WioDPgKcA/zcOTcb77Zkdxy9kHPufufcXOfc3LKyPodT+GgpLF/fcccdbNu2jVmzZjFv3jwuuOACrrnmGmbMmAHAZz/7WebMmcPMmTO5//77u9arrKyktraWHTt2MH36dG6++WZmzpzJ4sWLaW1tTV2DRUR8qazBVwFVzrl3/NeP0UfAn4y7/riO9Xsbek1v6YgTCYXIiJz899WM0QX84NMzjzn/Rz/6EWvXrmXNmjUsXbqUT33qU6xdu7brdMYHH3yQ4uJiWltbmTdvHtdeey0lJSU93mPLli088sgj/PKXv+S6667j8ccf58YbbzzptoqInIyU9eCdc/uB3WY21Z90GbA+NVuzlJVojjZ//vwe56rfc889nH322SxcuJDdu3ezZcuWXuuMHz+eWbNmATBnzhx27NhxmlorIkNZqs+i+SbwsH8GzXbgplN5s2P1tDfsayA/K0J5UUpO0ukhN/fIYYSlS5fy4osv8vbbb5OTk8PFF1/c57nsmZmZXc/D4bBKNCJyWqQ04J1za4C5qdzGkW2l5n3z8/NpbGzsc97hw4cpKioiJyeHjRs3smzZstQ0QkSkHwb8UAUnIpWXCJWUlHDeeedxxhlnkJ2dzYgRI7rmXXHFFdx3331Mnz6dqVOnsnDhwhS2RETk5JhLVde3H+bOneuOvuHHhg0bmD59+nHX27i/gZyMCBXFqS/RpNKJ7KuISHdmttI512elZMCPRXMiDEvdifAiIoNUIAIewCnhRUR6CETAa5wuEZHeAhHwkLqzaEREBqtABLw68CIivQUi4HWMVUSkt0AEvGGk6nTP/g4XDHD33XfT0tLyMbdIROTEBCLgU0kBLyKDVWCuZE1Viab7cMGXX345w4cP59FHH6W9vZ3Pfe5z3HXXXTQ3N3PddddRVVVFIpHge9/7HgcOHGDv3r1ccskllJaW8sorr6SohSIifRtcAf+nO2D/B70mj44lvCfR8Mm/58gz4cofHXN29+GCn3/+eR577DHeffddnHNcc801vPbaa9TU1DB69GieeeYZwBujprCwkB//+Me88sorlJaWnny7REROkUo0J+H555/n+eefZ/bs2Zxzzjls3LiRLVu2cOaZZ/LCCy9w++238/rrr1NYWJjupoqIDLIe/DF62vtqmkg6mDQ8L6Wbd85x5513csstt/Sat2rVKp599lm++93vctlll/H9738/pW0REfkogejBm1nKhiroPlzwJz/5SR588EGampoA2LNnD9XV1ezdu5ecnBxuvPFGbrvtNlatWtVrXRGR021w9eCPwSBlR1m7Dxd85ZVX8uUvf5lFixYBkJeXx0MPPcTWrVu57bbbCIVCRKNRfv7znwOwZMkSrrjiCkaPHq2DrCJy2gViuOAdtc10JJJMGZGfyualnIYLFpGTFfzhgjVWgYhIL4EIeNBgYyIiRxsUAf9RZSQLwHBjA6lUJiLBMOADPisri7q6uuMHoA3uG34456irqyMrKyvdTRGRABnwZ9GUl5dTVVVFTU3NMZc52NxBRzyJOzR4AzIrK4vy8vJ0N0NEAmTAB3w0GmX8+PHHXea237/HG1sP8vadl52mVomIDHwDvkRzIsIhI5EcvCUaEZFUCETAh0JGUgcpRUR6CETAh009eBGRowUj4FWiERHpJaUHWc1sB9AIJID4sS6nPVUhM5TvIiI9nY6zaC5xztWmcgPhEOrBi4gcJRAlmpAZCR1kFRHpIdUB74DnzWylmS3pawEzW2JmK8xsxfEuZjqeUMhIqgcvItJDqgP+fOfcOcCVwDfM7MKjF3DO3e+cm+ucm1tWVtavjYTVgxcR6SWlAe+c2+M/VgNPAvNTsZ1QyHBOA3aJiHSXsoA3s1wzy+98DiwG1qZiW2F/QHgdaBUROSKVZ9GMAJ40L3wjwL87555LxYbC/teU8l1E5IiUBbxzbjtwdqrev7tQyOvBa7gCEZEjAnGapEo0IiK9BSPg/R68zqQRETkiEAEf8nvwOhdeROSIQAR8Vw9eAS8i0iUQAR9SiUZEpJdABHy4q0ST5oaIiAwgwQh4fy/UgxcROSIQAa+DrCIivQUi4HWQVUSkt0AFfFwBLyLSJRABn+EX4WMJHWUVEekUiICPKuBFRHoJRMBnRBTwIiJHC0TAd/bg2+MKeBGRToEI+IyId5A1ltBBVhGRTsEI+HAYgJh68CIiXQIR8NGuHrwCXkSkUzAC3q/BdyjgRUS6BCLgO8+D71CJRkSkSzACvus0SR1kFRHpFIiA14VOIiK9BSTgvYOsKtGIiBwRiIDvLNHoIKuIyBGBCPhoSCUaEZGjBSLgQyEjEjKVaEREuglEwIN3oFU9eBGRIwIT8BmRkE6TFBHpJuUBb2ZhM1ttZk+ncjvRcEgHWUVEujkdPfhvAxtSvZGMsGrwIiLdpTTgzawc+BTwr6ncDkA0ohq8iEh3qe7B3w38NXDM5DWzJWa2wsxW1NTU9HtDGTrIKiLSQ8oC3syuBqqdcyuPt5xz7n7n3Fzn3NyysrJ+by8aDqlEIyLSTSp78OcB15jZDuA/gEvN7KFUbSwaCdGhs2hERLqkLOCdc3c658qdc5XA9cDLzrkbU7W9zHBId3QSEekmUOfBt8cT6W6GiMiAcVoC3jm31Dl3dSq3kRUN0xpTD15EpFNgevA5GWFaO+LpboaIyIARmIDPjoZpjalEIyLSKTgBnxGmpUMBLyLSKTAB75VoFPAiIp0CE/DZ0TDxpNPVrCIivuAEfEYYQGUaERFf4AK+TQdaRUSAAAV8jnrwIiI9BCbgs6MRAB1oFRHxBSfg/R58a0wXO4mIQIACXiUaEZGeAhPw2VG/B6+AFxEBghTwXSUaBbyICAQo4AuyogA0tMbS3BIRkYHhhALezL5tZgXmecDMVpnZ4lQ37mQU5UQxg5qmjnQ3RURkQDjRHvxXnXMNwGKgCPgK8KOUtaofIuEQxTkZ1Da1p7spIiIDwokGvPmPVwG/dc6t6zZtwCjJy6BOAS8iApx4wK80s+fxAv7PZpYPDLhRvUrzMqlViUZEBIDICS73NWAWsN0512JmxcBNqWtW/5TmZfJ+VX26myEiMiCcaA9+EbDJOVdvZjcC3wUOp65Z/VOSl6EevIiI70QD/udAi5mdDdwKbAN+k7JW9VNhdpSm9jjJpEt3U0RE0u5EAz7unHPAZ4CfOefuBfJT16z+6bqaVRc7iYiccMA3mtmdeKdHPmNmISCaumb1j8ajERE54kQD/otAO9758PuBcuAfU9aqfsrO0JDBIiKdTijg/VB/GCg0s6uBNufcgKvBq0QjInLEiQ5VcB3wLvAF4DrgHTP7fCob1h9HSjQaE15E5ETPg/9fwDznXDWAmZUBLwKPpaphJ+Xlv4Py+WRnzAFUohERgROvwYc6w91XdxLrpt7b98KHr3b14FWiERE58R78c2b2Z+AR//UXgWePt4KZZQGvAZn+dh5zzv2gvw09rnAUErGuGrzOohEROcGAd87dZmbXAuf5k+53zj35Eau1A5c655rMLAq8YWZ/cs4tO4X29i0UhWTsyE0/FPAiIifcg8c59zjw+Eks74Am/2XU/0nNJaZ+Dz7HP01SB1lFRD4i4M2skb5D2fAyvOAj1g8DK4FJwL3OuXf6WGYJsASgoqLiBJt9lFAUkvFuNfgBN9CliMhpd9wDpc65fOdcQR8/+R8V7v76CefcLLwLo+ab2Rl9LHO/c26uc25uWVlZ//YiHIVEB5mREGbQqh68iMjpORPGOVcPvAJckZIN+CUaMyM7GtZBVhERUhjwZlZmZsP859nA5cDGlGzML9EA5GZGaGjTjbdFRE74IGs/jAJ+7dfhQ8CjzrmnU7KlcAQSXqiPL8nlw9rmlGxGRGQwSVnAO+feB2an6v17CGdAwrvRx6QReTzz/j6cc5gNuNvGioicNgPnatRT0a1EM3l4HodbY7qzk4gMecEI+O4lmtJcAHbWqUwjIkNbMALev5IVYHh+FgC1Te3pbJGISNoFI+DDGZDwSjSl+RkA1DQq4EVkaAtIwEe6DrKW5GYSMgW8iEgwAr5biSYcMopzM6lRiUZEhrhgBHw42lWiASjLz1QPXkSGvGAEfCjS1YMHBbyICAQl4Ltd6AQwsiCTfYfb0tggEZH0C0jA9yzRjB6WTXVjO+1xDTomIkNXMAL+qBLNmGHZABw4rDKNiAxdwQh4f7jgTp0Bv6e+NV0tEhFJu4AEfIbXg3fezadGK+BFRAIS8KGo9+gPODZ6WDaRkPFhbdNxVhIRCbZgBHzYH/XYL9NkREJUluay+YACXkSGrmAEfGcPfu1jXZPGFefwwvoD/PSlLWlqlIhIegUj4MPeAGM89c2uSZOG5wFw/2vb09EiEZG0C0bAh3rvxjcvm8yYYdmU5memoUEiIukXjIBvPNBrUl5mhKvPGsWe+laSSZeGRomIpFdAAn7fkefJZNfTMUXZdMST1DXr9n0iMvQEI+Avuv3I8/aGrqejC73z4Z/9YN/Ra4iIBF4wAn7YWPjMv3jPWw91TT53UglTRuTxT89vIpZIHmNlEZFgCkbAA2QP8x7b6rsm5WRE+KvLp9DYFmfpppo0NUxEJD2CE/BZfsC31veYfN6kUvKzItz8mxX8/bMb0tAwEZH0CE7AZxd5j209Az4/K8qz37qAktwMXtrQ+2wbEZGgCk7A5xR7j821vWaNLc7hxoXj2F7bTEtHvNd8EZEgClDAlwIGzX3X2meMLsA5WL+3oc/5IiJBk7KAN7OxZvaKma03s3Vm9u1UbQvwBhzLLYWmvssw8yqLyc0Ic9+rGrpARIaGVPbg48CtzrkZwELgG2Y2I4Xbg9zh0FTd56zi3Ay+ev54Xtp4gLom3elJRIIvZQHvnNvnnFvlP28ENgBjUrU9APKOHfAAi2eMxDl4RadMisgQcFpq8GZWCcwG3ulj3hIzW2FmK2pqTjF484bDnhXQuL/P2TNHFzCuJId/e/NDEhqfRkQCLuUBb2Z5wOPAd5xzvY5wOufud87Ndc7NLSsrO7WN5Y3wHl+8q8/ZoZBx6+KprNvbwF1/XHdq2xIRGeBSGvBmFsUL94edc0+kclsAnPst77F6/TEXuebs0fy388fzm7d38rvluzjcGjvmsiIig1kqz6Ix4AFgg3Pux6naTg95ZTDvZqjb1nUD7r789RXTGFucze2Pf8B5P3qZu1/crKAXkcBJZQ/+POArwKVmtsb/uSqF2/OUTYWORq8Of4yQz4iEuOf62Xxl4Timjczn7he3cOXdr7Fse13KmycicrpEUvXGzrk3AEvV+x/TiDO8x8du8s6Jv+lPkD+y12KzK4qYXeENb/Do8t389ePvc/39y/jsrNH8n8+dSW5myj4aEZHTIjhXsnYac473uOttOLgdlv7DR65y3byxfP2iiQD855q9fPlf3+GQbhIiIoNc8AI+kgkF5d7zygtg+6sntNoNCyqYV1nE3356Bhv2NXDNvW9w829W8M72OuIaS15EBiFzxzkYebrNnTvXrVix4tTf6HAVxFph05/ghe/BrZshfwQc2glth2HUWcddfdn2Oq6/f1mPafmZES6fMYK//cxMCrKip95GEZGPgZmtdM7N7WteMAvNhX4PPtbqPT70FzB/CfzxW2Bh+MzPYMRMGHV2n6svnFDCS7dexPPrDrBy50Fe3FBNY3ucJ1bvYXN1I7dfMY1YIsklU4fjnSwkIjLwBLMH390r/wCv/qj39HAmnPv/QbwdEh2QWwZzvwbRbO+nW3DvPtjC+n0NtHTE+Zsn1tIaSwDwt5+ewfbaZiYPz+PGheMU9iJy2h2vBx/8gAdvjPg3fgKjZ8PIM+G9R2D5g9DR5NXsw1GvdNMpqxCmXAHhDCid7J1bH82G5lo2bFrP43uK+Ne3dvfYxAWTS/nq+eO5cHIZ4ZDR1B7HQGfjiEhKKeD74lyPXjpVK2Ddk95Nu/es8saVT8Sg/TBgkFkAiXaIt0FBOaunfIv3mwq4bPE1XHXPGzS0eTcSGVGQSV5mhF0HW5g5upAn//u56tmLSMoo4E/Fh6/Dludhz0pvrJuJl8Irfw+Ne735Yxewc/otrA6fQSQ7n9fe20ScKC9sa6axLc4Fk0upbepgbFE2f7V4CtNGFqR3f0QkUBTwH7f2Jqh61xsS4c1/hsN+uSZ/FDTuAwuTuOwHPLO+jp/tP4O2rDJ2HWwBYPqoAn583dk4B4+8u4srzxzJnHFFZEbCadwhERmsFPCpFG+H9U/BoR1Qs8E7ePvevx+Zn1MCc7/Kn2Oz+eFbrRxyebR0JHq8xQ0LKrjrmpk4IBoO3qUJIpI6CvjTbcsL0LDHq/Ovedgr77gkLhSlbdpf0LzldRKZheyu+Bz/b3WY/xJ5gR/GvkI1RYRDxs++NJvK0lymj1I5R0SOTwGfbs21sP4PsPZxqNkILb0HNdvjSvh94iKqXBkrklPY4Ubx9DfPZ2xxDit3HmT22CKKcjPS0HgRGcgU8ANRrA22vQwH1kFuCe7lv8O6Bf8+V8wD8Sv5XehKGmMhcjLC/PZrCzinYhiAzswREUABP3jE2mDvKnj6f3g9fWBP5kTyIwmWtZZzb+tiKvJgz7A5XL9gHMU5GVw6bTjxpCMjotq9yFCkgB+MDn7o1e/XPgEHt/WY9c+JL/Cf8YXsdmXEiVCcm8EDfzmXWWOH0dQeJ19j5YgMGQr4wcw570ydg9vZ89J9jNn8665Zddnj+Wr9TbzvJuAIMb+ymBU7D/K188dzw4JxVJbmprHhInI6KOCDpKPZu+p23xp495dweDcunMGmyDSWNo/jreQMNjCBmmQ+IwuyuPnCCYwZlsW0kQUKfJEAUsAHVctBeOPHEGvFrX8Ka67umrU0/9M8UjeRPyfnAUZGOMQD/3Uu71cdZlRhFp+bPUYHakUCQAE/FMRaobUedr8Dq34D217qmrVz1q08+H4HD7XMByBBmJmjC2hqj/PFeWP5+oUTCYWMWCKpC61EBhkF/FAU74DnbocVD/aYHMsu4+HS79BYW8V7eRexdHcHERLk5OZzsLmDa88p5/YrppKTGSFPI2GKDHgK+KEs3gF7Vnj3qH3zHmir77VIghDrmMBb8emESfBa8iwOj1zEzPJiLp46nE/O7H3TchEZGBTwckRbgzd0wt5V8N7voHYT5JTiLAwtNTiMkEuwJTmGm2N/RY0bRkcoi/kTSpk8PJ+CrAh5WRFGFGTxyZkjyYpqkDSRdFLAy7HFOyCS4Z2OCRBvx617kviztxPtOHITlBor4Rm3iEc7zqXDRYgRIZJbwvzCejpGzCYvM8yYomzmVRYzu6IoTTsjMvQo4OXk7VoGG/4IyQQc3O6NlFm/q89F30zO5PXkmTydWMReV8I/XHs2j62s4uKpw/nS/AqKczNoiyXU2xdJAQW8nDrnYO9qr7Sz4w04tBNGzPCuuN35JgCtkWFkxBtYkZzCP8auo8QayImGGFU5hXUf7mXkWZfz3aun60pbkY+RAl5SK9YGax+Dt35K66j5dGz4E4Wxml6L/Tj2eXZFxrE//wxmtK1mZ7KUsunn8/fXnkMoZFQ3tlGQFVVPX+QkKODl9GquhdUPQdlUkq311Kx9mRFbH+1z0XqXy1vheWTlFrDzUDvb8uYwcdaFFJSN5eVN1Vw/byznTyrVRVkix5CWgDezB4GrgWrn3Bknso4CPsDqd3vDLDRXw8ZncBWL2LW/mupVzzCxZTXZro1s2gFoclnUuQIMxxvJMwhnFzJ9QiXDOUg42UbJp/837ZmlHGqNkR0Na5x8GdLSFfAXAk3AbxTwckKqN9Jeu4PEsp/TVn+AvJLR2O53iMabei2acMYHbgIJwlQVLaDszEuZWFHBiLJStrflMb4AWmKOUKKN7JKxadgZkdMjbSUaM6sEnlbAS78l4sRb6nltzXoSoSgtm5aSWfMBhRmOye3rCMVaKE70rvd3uDCOEJkWo6FgMpmVC4kWjiS0801o2g+zvgwX3paGHRL5eCngJdCaa3fx3NJXWb56Dbm0cWX4XULhKHXhMta3FTPLtjIrtJVCa+mxXmu0iDXRWeRO/wTvtw0n2VSLtdVz1oLLGDl+OvUHa5k6ccKxN5yIQSgCOj4gaTSgA97MlgBLACoqKubs3LkzZe2RYFu75zB/WruPb1wyiZwMbxyd96vque/VbdQ1ttPe1kyUBAcO7OVr4We5KvwOZdbQ53s1u0wiJNkx9auMz4vT8eEysiNJwrmlXu+/fD786lMw5y/hojsgpEHaJD0GdMB3px68pJpzjg9rm9lS3cSu2iauzFnP+/taKGn5kFBOEcniiax97UlGt3/IRLeTKaE9xF2IgxQw3HqP4wOQDEVxo2YTSnbQkTuK6Ng5hMbOg5wSGHmmt1DbYe8evNOvgY4myMiHHa/B+qfg8h9CZt5p/BQkSBTwIiehPZ7AOVi3t4GNO/fxwb5mpo3MJf7BkzxaW8k5sVWMtWqKrJlDLpeZtpNF4fW8xxRKkgeZGNrX9V5JQrRkDievfT8ALpqDxVpoyRtHTpP/12pmAcy9CfJGQt5wb7jnqVfB3K96w0iIHEe6zqJ5BLgYKAUOAD9wzj1wvHUU8DLQOed4e1sdO+pa2FbTRF1TO3vrW9lXV8/uRscFk0uJf/gmBcnDVFg1hdbMWKthpu2giWxqsiewqz2HmcnNZOQWkVVYxoz9f+hzW+35FWRMOA/2rsYmXw5nXOtdRbzvPQhF4awvwPiLe5aHEjHvqmMzCOuK4aFAFzqJpFhTe5zXN9eweOZIttU0kZsZ4UBDGx9UHSYzEmLTgUb+7c0dAJxTMYzGtjhbqpsIkWRhaD3Lk9PIo4ULQmspDjfTlMzgpvBzVFg1Va6MyaE9REj03nD5PBLDxkPbIWjYR7hht1cOyhsJ1z8MJZO8m7Yvf9ArA827GXa9BRMu9pYLZ3hDUJx53bGPI8TbIZKZqo9OTpECXmQAONwaY/3eBuaMK8IM/v2dXZTmZfLQsp20dMT54rwKzGDT/kYaWmM8sXoPGeEQSecYlqznk+HlbEhWUM0w2lwm10eXclV4OQWugTxa+ZAxzLbNfW47HsoiRIJQMtbnfDdqFta4DwrHwtj5MOkTEArD2idg1a/hglvhsu8fWSHWBrWboWyqdyex6nUw8dLjfwCt9eCSkFPc349Q+qCAFxmE4okkLbEELgkHWzq45J+W9pgfDhmJZM//v+VF2bhDu8ixdmbYDi4Pr2JFcgpPJxZRYQf4UnQp2ZPOZ1bja4ysX01b3PGMO5dLWUFeWTnZrt27R0Af3IiZWL08nVAAAAuuSURBVDKBO7wbYm2YS0A0F2LN3gKzboC6bdB60PsCGFYBuaUwbCwUjYeXfggZud6B5kmfgMmf6GMjTqedniQFvEgA7KproSjXq6tvPtDE9FH5NLXHiYZCtMeTjCzMAuDhd3Zy11PrMYOFE0q4+4uzqG+N8bvlu3nwzQ/piCePuY1MOrg4tIaJto9wOMwfYvNYMK6AebEVjK19g5nZdcTaWngvPJPysy+hqGEzyVgrJXUrCMdbsPxRkF0EdVsBAxw0974QDYBh42D4dMjM90pJNZtg/R+8awtmfAYW3AJj5kB7I+xbA2XTYPtSOLTD/zLZ4v1VUDIJSqccua9BewN0tHjHIBr3wXv/AdM+BWMX9ixDtTV426rfBRufhgVfH5RnMyngRYagZNIRCvXuDVcdamHZ9oM8v24/ty6eyuYDjWRFwzz9/l4a2+KcVV6IYazYeZDm9jg761qoa+74yO0V52bwudljmFiWx9q9h9m8v5Hi3AwWjApxeeINiqZdyJ7D7Tz47Ot8pngXCwvqCB/chos1Y533GqhYBLvfBecfbxg92wvglrrjb9xCXtC3HISW2r6XKZsGOaVQsQCqlsPOtyAZPzK/cKy3/UX/3Ts+cWgHNNV4f1Gc+03vOIRz3jZyir3pbQ2QVfCRn00qKeBF5JRs2t9IVjTEr9/ayUVTy5hdMYzXNtfwm7d2UlGSA8BjK6t6rRcJGXG/jGR25MZhna9HF2azp76VKaG9fPrMUl46OJybzq3gt394jgttFV/IWUV7pIC9E69nbn4dGQfeo6OtmcNl8ygbXQmJDmLxGOGD2wjVbPDOIpp0mfdXxN7V3s/kxdBUDQ1V0LDPK0GVTfMONG/4ozc/bzi8c58X7H3JLPAaH83y/iLJHQ4ZOd6XQNl0b72cYhhzDow4w/sy2PGG92VVPAFmfg7GLvDak1vqfUnUboaZn4XCcu/Oavkj+vVvo4AXkZTbW9/K8PxM7nt1Gx/sOUxFcQ5/c9V0lm0/yCubqqltbKe5I040HOJwa4yG1hj7DrdR3dh+3PcNGSQdjCzIoj2eoL41hnMwtjibqSMK2Li/gYxIiO9fPYNxJbks//Agq3fX85lZoxlZkMWGfQ1cPHU42Rn+fQY6WiAjh63VTYBj0vD8Ixur3ggrf+UF9vgLYdwiqN0CHzzm9dQb90FuGSQ6oPGAV15qqYNIFmz5s1fy6f5XQfk87x7I7thlMcA76+l/9n3s46Mo4EVkQGpuj/PEqiqmjyrgvarDjBmWDThqmzpYuqmGWy6awOyxw3h8VRX3vrKNaSPzmTaqgFgiyfaaJl7eWE0s8dEZlpcZYeboAsryM2lqj1NelM1Dy7yy0N9cNY3NB5oYXZjF7HFFZEXCTBuZjxnEEo6y/GOfInqouYPmjjjlRTnQXOf13D981TvYPOsGyC3xeuebn/NOV5282Bs6e/Vv4ewveccLWg9BdjHM+lK/PkMFvIgEUnVDG/GkIzsa5qp7XmduZTG3XDiB8qJsvvqr5TS2xfn2Jybz8sZq/rBmL7kZYRra4r3eZ3h+Zo+/JLqXliaU5VKYHeVQcwdFuRksnFDCf67ew4xRBazeXc/B5g7+xyemsGBCMS9vrGZEQRbOOZZtr+Pac8o5d1IphdlROuJJks5R29TufSF8TBTwIhJ4HfEkGZEjZ8k450gkHZGwN21vfSvFuRls2t/IT1/ewvtVh7loShlnlhfylYXj2LCvkVc2VTN6WBa/fXsnmw80seTCCby9rY5Vuw7hnHcgeX9DW7/bGA17B71vvmACr26u4UBDO+NKcrjjymnMq+zf9QEKeBGRk+CcoyORJDMS7jEtkXS8vb2OUYXZ1DW1Mywng0nD81i16xD/77mN3HTeeEpyM/jd8t3csLCCf/zzJpZtPwh44X7lGaN46r29PbZlBsOyo7xx+6XkZkZOuq0KeBGRNHDO8fqWWkrzMqkoySEvM8LW6kYeWraLm86rpOpQK9NG5rO1uokFE0r6tQ0FvIhIQB0v4HWXAhGRgFLAi4gElAJeRCSgFPAiIgGlgBcRCSgFvIhIQCngRUQCSgEvIhJQA+pCJzOrAXb2c/VS4Bgj/QeW9nlo0D4PDf3d53HOubK+ZgyogD8VZrbiWFdzBZX2eWjQPg8NqdhnlWhERAJKAS8iElBBCvj7092ANNA+Dw3a56HhY9/nwNTgRUSkpyD14EVEpBsFvIhIQA36gDezK8xsk5ltNbM70t2ej4uZPWhm1Wa2ttu0YjN7wcy2+I9F/nQzs3v8z+B9MzsnfS3vPzMba2avmNl6M1tnZt/2pwd2v80sy8zeNbP3/H2+y58+3sze8fftd2aW4U/P9F9v9edXprP9p8LMwma22sye9l8Hep/NbIeZfWBma8xshT8tpb/bgzrgzSwM3AtcCcwAvmRmM9Lbqo/Nr4Arjpp2B/CSc24y8JL/Grz9n+z/LAF+fpra+HGLA7c652YAC4Fv+P+eQd7vduBS59zZwCzgCjNbCPxf4CfOuUnAIeBr/vJfAw7503/iLzdYfRvY0O31UNjnS5xzs7qd757a323n3KD9ARYBf+72+k7gznS362Pcv0pgbbfXm4BR/vNRwCb/+S+AL/W13GD+Af4AXD5U9hvIAVYBC/CuaIz407t+z4E/A4v85xF/OUt32/uxr+V+oF0KPA3YENjnHUDpUdNS+rs9qHvwwBhgd7fXVf60oBrhnNvnP98PjPCfB+5z8P8Mnw28Q8D32y9VrAGqgReAbUC9cy7uL9J9v7r22Z9/GOjf3ZrT627gr4Gk/7qE4O+zA543s5VmtsSfltLf7Uh/Wyrp5ZxzZhbIc1zNLA94HPiOc67BzLrmBXG/nXMJYJaZDQOeBKaluUkpZWZXA9XOuZVmdnG623Mane+c22Nmw4EXzGxj95mp+N0e7D34PcDYbq/L/WlBdcDMRgH4j9X+9MB8DmYWxQv3h51zT/iTA7/fAM65euAVvPLEMDPr7IB136+uffbnFwJ1p7mpp+o84Boz2wH8B16Z5p8J9j7jnNvjP1bjfZHPJ8W/24M94JcDk/2j7xnA9cBTaW5TKj0F/KX//C/xatSd0/+Lf+R9IXC42599g4Z5XfUHgA3OuR93mxXY/TazMr/njpll4x1z2IAX9J/3Fzt6nzs/i88DLzu/SDtYOOfudM6VO+cq8f7Pvuycu4EA77OZ5ZpZfudzYDGwllT/bqf7wMPHcODiKmAzXt3yf6W7PR/jfj0C7ANiePW3r+HVHV8CtgAvAsX+soZ3NtE24ANgbrrb3899Ph+vTvk+sMb/uSrI+w2cBaz293kt8H1/+gTgXWAr8Hsg05+e5b/e6s+fkO59OMX9vxh4Ouj77O/be/7Pus6sSvXvtoYqEBEJqMFeohERkWNQwIuIBJQCXkQkoBTwIiIBpYAXEQkoBbzIx8DMLu4cFVFkoFDAi4gElAJehhQzu9Eff32Nmf3CH+irycx+4o/H/pKZlfnLzjKzZf543E92G6t7kpm96I/hvsrMJvpvn2dmj5nZRjN72LoPoiOSBgp4GTLMbDrwReA859wsIAHcAOQCK5xzM4FXgR/4q/wGuN05dxbe1YSd0x8G7nXeGO7n4l1xDN7ol9/BuzfBBLwxV0TSRqNJylByGTAHWO53rrPxBndKAr/zl3kIeMLMCoFhzrlX/em/Bn7vjycyxjn3JIBzrg3Af793nXNV/us1eOP5v5H63RLpmwJehhIDfu2cu7PHRLPvHbVcf8fvaO/2PIH+f0maqUQjQ8lLwOf98bg774c5Du//Qecohl8G3nDOHQYOmdkF/vSvAK865xqBKjP7rP8emWaWc1r3QuQEqYchQ4Zzbr2ZfRfvrjohvJE6vwE0A/P9edV4dXrwhm+9zw/w7cBN/vSvAL8wsx/67/GF07gbIidMo0nKkGdmTc65vHS3Q+TjphKNiEhAqQcvIhJQ6sGLiASUAl5EJKAU8CIiAaWAFxEJKAW8iEhA/f9dQlia8Rj5lAAAAABJRU5ErkJggg==\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(cnnhistory.history['accuracy'])\n",
        "plt.plot(cnnhistory.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train','test'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "IFkTuO8nDNdq",
        "outputId": "7bfc0578-eb65-46f0-91de-1ad6e0c6178f"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model.predict(x_testcnn)"
      ],
      "metadata": {
        "id": "A2xtrN5wDQgY"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_f_ohjXKDUpY",
        "outputId": "0dc7987a-f741-4987-ccb6-8ea186c1868c"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.94619566e-01, 1.27445951e-01, 2.30418235e-01, 1.82493076e-01,\n",
              "        2.03725666e-01, 6.12975396e-02],\n",
              "       [1.19991740e-03, 9.64427381e-05, 5.94733638e-06, 9.36669290e-01,\n",
              "        4.87920217e-04, 6.15404472e-02],\n",
              "       [1.70446217e-01, 1.00591369e-01, 1.19809918e-01, 2.31969804e-01,\n",
              "        6.60017729e-02, 3.11180979e-01],\n",
              "       ...,\n",
              "       [7.40598887e-04, 1.58065541e-06, 2.41124746e-03, 1.66178891e-03,\n",
              "        9.86181974e-01, 9.00273118e-03],\n",
              "       [3.04434634e-05, 3.71335328e-01, 5.96419215e-01, 1.68735757e-02,\n",
              "        2.97886133e-03, 1.23625295e-02],\n",
              "       [6.59646830e-05, 6.96906573e-05, 2.61305831e-02, 5.86121285e-04,\n",
              "        9.57880437e-01, 1.52671784e-02]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cmA2bFgsDW3D",
        "outputId": "d21c654e-e7c6-496e-8c0c-b27e97776347"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([3, 3, 3, 0, 4, 4, 1, 2, 5, 0, 5, 3, 2, 2, 1, 4, 4, 5, 2, 4, 1, 2,\n",
              "       3, 5, 4, 2, 1, 2, 2, 2, 2, 5, 2, 5, 3, 1, 2, 0, 4, 5, 2, 3, 2, 2,\n",
              "       5, 2, 0, 1, 3, 4, 4, 5, 1, 1, 4, 4, 5, 1, 1, 1, 0, 1, 5, 0, 4, 1,\n",
              "       1, 0, 1, 4, 1, 0, 4, 1, 3, 1, 2, 2, 1, 2, 3, 0, 5, 3, 5, 5, 2, 4,\n",
              "       5, 1, 5, 1, 5, 3, 4, 1, 4, 1, 5, 4, 5, 1, 2, 1, 1, 5, 1, 3, 2, 5,\n",
              "       2, 1, 3, 5, 4, 4, 0, 0, 3, 1, 2, 2, 3, 5, 1, 5, 3, 4, 2, 2, 0, 2,\n",
              "       2, 5, 5, 0, 3, 3, 2, 2, 0, 3, 4, 0, 4, 2, 4, 5, 4, 1, 5, 3, 2, 2,\n",
              "       5, 4, 3, 3, 4, 3, 3, 4, 1, 5, 2, 3, 2, 2, 0, 2, 1, 3, 1, 2, 2, 5,\n",
              "       5, 1, 4, 2, 2, 1, 1, 3, 3, 5, 5, 2, 5, 1, 5, 0, 3, 3, 0, 5, 1, 4,\n",
              "       1, 4, 2, 5, 5, 1, 4, 2, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_Ytest = y_test.astype(int)"
      ],
      "metadata": {
        "id": "0PHDKWJWDY3g"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_Ytest"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k68v2i-pDbZE",
        "outputId": "f061ed54-6255-44bc-a2fa-439fec36531e"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([3, 3, 3, 0, 4, 4, 1, 2, 5, 0, 5, 3, 2, 2, 1, 4, 4, 5, 2, 4, 1, 2,\n",
              "       3, 5, 4, 2, 1, 2, 2, 2, 2, 5, 2, 5, 3, 1, 2, 0, 4, 5, 2, 3, 2, 2,\n",
              "       5, 2, 0, 1, 3, 4, 4, 5, 1, 1, 4, 4, 5, 1, 1, 1, 0, 1, 5, 0, 4, 1,\n",
              "       1, 0, 1, 4, 1, 0, 4, 1, 3, 1, 2, 2, 1, 2, 3, 0, 5, 3, 5, 5, 2, 4,\n",
              "       5, 1, 5, 1, 5, 3, 4, 1, 4, 1, 5, 4, 5, 1, 2, 1, 1, 5, 1, 3, 2, 5,\n",
              "       2, 1, 3, 5, 4, 4, 0, 0, 3, 1, 2, 2, 3, 5, 1, 5, 3, 4, 2, 2, 0, 2,\n",
              "       2, 5, 5, 0, 3, 3, 2, 2, 0, 3, 4, 0, 4, 2, 4, 5, 4, 1, 5, 3, 2, 2,\n",
              "       5, 4, 3, 3, 4, 3, 3, 4, 1, 5, 2, 3, 2, 2, 0, 2, 1, 3, 1, 2, 2, 5,\n",
              "       5, 1, 4, 2, 2, 1, 1, 3, 3, 5, 5, 2, 5, 1, 5, 0, 3, 3, 0, 5, 1, 4,\n",
              "       1, 4, 2, 5, 5, 1, 4, 2, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds1=predictions.argmax(axis=1)\n",
        "preds1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4_cAI39VFhtp",
        "outputId": "9cec4841-96cd-4902-9ce0-ba76a81d64d7"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2, 3, 5, 1, 4, 4, 1, 2, 5, 1, 4, 3, 2, 2, 0, 5, 4, 3, 3, 4, 2, 2,\n",
              "       2, 5, 5, 2, 2, 0, 2, 2, 2, 5, 2, 5, 3, 1, 2, 0, 4, 5, 2, 5, 2, 2,\n",
              "       3, 2, 1, 1, 3, 4, 4, 5, 1, 1, 4, 4, 5, 1, 1, 1, 3, 1, 5, 1, 4, 1,\n",
              "       1, 1, 1, 4, 0, 5, 4, 3, 5, 5, 2, 2, 1, 4, 1, 0, 5, 3, 5, 5, 2, 5,\n",
              "       3, 1, 5, 2, 5, 3, 2, 2, 4, 1, 5, 4, 5, 1, 5, 2, 1, 5, 1, 5, 2, 5,\n",
              "       1, 2, 3, 5, 4, 4, 2, 0, 3, 1, 1, 2, 3, 5, 1, 5, 3, 5, 2, 2, 1, 4,\n",
              "       2, 3, 5, 0, 5, 3, 2, 4, 0, 5, 4, 1, 4, 4, 4, 2, 4, 1, 5, 3, 2, 2,\n",
              "       5, 4, 4, 5, 4, 5, 3, 4, 1, 5, 2, 5, 2, 2, 0, 2, 1, 1, 1, 4, 4, 5,\n",
              "       5, 1, 4, 2, 4, 1, 1, 3, 3, 5, 5, 2, 5, 1, 4, 1, 3, 3, 2, 5, 1, 4,\n",
              "       1, 3, 5, 5, 4, 1, 4, 2, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "abc = preds1.astype(int).flatten()"
      ],
      "metadata": {
        "id": "H4WEmM60NfQn"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "c = confusion_matrix(new_Ytest, abc) \n",
        "c"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bKEBeEBlFjB8",
        "outputId": "4175ea74-422f-49b9-d82f-cccee4340f37"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 6,  8,  2,  1,  0,  1],\n",
              "       [ 2, 31,  6,  1,  0,  1],\n",
              "       [ 1,  2, 32,  1,  7,  2],\n",
              "       [ 0,  2,  2, 17,  1,  9],\n",
              "       [ 0,  0,  1,  1, 27,  4],\n",
              "       [ 0,  0,  1,  4,  3, 31]])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m4RjG7LWLSQx",
        "outputId": "1d1eb353-2fe7-4962-9d5b-c32722769321"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([3, 3, 3, 0, 4, 4, 1, 2, 5, 0, 5, 3, 2, 2, 1, 4, 4, 5, 2, 4, 1, 2,\n",
              "       3, 5, 4, 2, 1, 2, 2, 2, 2, 5, 2, 5, 3, 1, 2, 0, 4, 5, 2, 3, 2, 2,\n",
              "       5, 2, 0, 1, 3, 4, 4, 5, 1, 1, 4, 4, 5, 1, 1, 1, 0, 1, 5, 0, 4, 1,\n",
              "       1, 0, 1, 4, 1, 0, 4, 1, 3, 1, 2, 2, 1, 2, 3, 0, 5, 3, 5, 5, 2, 4,\n",
              "       5, 1, 5, 1, 5, 3, 4, 1, 4, 1, 5, 4, 5, 1, 2, 1, 1, 5, 1, 3, 2, 5,\n",
              "       2, 1, 3, 5, 4, 4, 0, 0, 3, 1, 2, 2, 3, 5, 1, 5, 3, 4, 2, 2, 0, 2,\n",
              "       2, 5, 5, 0, 3, 3, 2, 2, 0, 3, 4, 0, 4, 2, 4, 5, 4, 1, 5, 3, 2, 2,\n",
              "       5, 4, 3, 3, 4, 3, 3, 4, 1, 5, 2, 3, 2, 2, 0, 2, 1, 3, 1, 2, 2, 5,\n",
              "       5, 1, 4, 2, 2, 1, 1, 3, 3, 5, 5, 2, 5, 1, 5, 0, 3, 3, 0, 5, 1, 4,\n",
              "       1, 4, 2, 5, 5, 1, 4, 2, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss, acc =model.evaluate(x_testcnn, y_test)\n",
        "print(\"Restored model, accuracy: {:5.2f}%\".format(100*acc))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n3kzoqPkDqqS",
        "outputId": "31b7d138-e415-40e4-aac3-ed7f45a7627c"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7/7 [==============================] - 0s 3ms/step - loss: 0.7273 - accuracy: 0.6957\n",
            "Restored model, accuracy: 69.57%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss, acc =model.evaluate(X_train, y_train)\n",
        "print(\"Restored model train, accuracy: {:5.2f}%\".format(100*acc))"
      ],
      "metadata": {
        "id": "fJDTGH_OUX0z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50eb0a36-53d7-4e53-ce8d-a608a609cfd5"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5332 - accuracy: 0.8380\n",
            "Restored model train, accuracy: 83.80%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix,accuracy_score\n",
        "import seaborn as sn\n",
        "\n",
        "print(classification_report(new_Ytest,abc))\n",
        "\n",
        "acc = float(accuracy_score(new_Ytest,abc))*100\n",
        "print(\"----accuracy score %s ----\" % acc)\n",
        "\n",
        "cm = confusion_matrix(new_Ytest,abc)\n",
        "#df_cm = pd.DataFrame(cm)\n",
        "class_names = ['neutral','calm', 'happy','sad','angry', 'fearful' ]\n",
        "df_cm = pd.DataFrame(cm, index=class_names, columns=class_names,)\n",
        "sn.heatmap(df_cm, annot=True, fmt='')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 508
        },
        "id": "SfSC3El94LZg",
        "outputId": "3627d7ba-1655-4217-b826-eef427867394"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      0.33      0.44        18\n",
            "           1       0.72      0.76      0.74        41\n",
            "           2       0.73      0.71      0.72        45\n",
            "           3       0.68      0.55      0.61        31\n",
            "           4       0.71      0.82      0.76        33\n",
            "           5       0.65      0.79      0.71        39\n",
            "\n",
            "    accuracy                           0.70       207\n",
            "   macro avg       0.69      0.66      0.66       207\n",
            "weighted avg       0.70      0.70      0.69       207\n",
            "\n",
            "----accuracy score 69.56521739130434 ----\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}