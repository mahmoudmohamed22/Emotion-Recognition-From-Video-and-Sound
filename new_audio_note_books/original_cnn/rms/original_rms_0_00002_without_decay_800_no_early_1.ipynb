{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "original_rms_0.00002_without decay_800_no_early_1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9SRCO-a_AlH5",
        "outputId": "f64005da-caf4-47e6-bb3d-bad5dcf762db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install librosa"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Lo4mUwG9RMd",
        "outputId": "63101d75-ddbf-4ab3-8753-5c9a4c9cb463"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.7/dist-packages (0.8.1)\n",
            "Requirement already satisfied: resampy>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from librosa) (0.2.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (21.3)\n",
            "Requirement already satisfied: numba>=0.43.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (0.51.2)\n",
            "Requirement already satisfied: soundfile>=0.10.2 in /usr/local/lib/python3.7/dist-packages (from librosa) (0.10.3.post1)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.1.0)\n",
            "Requirement already satisfied: audioread>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (2.1.9)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.4.1)\n",
            "Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.6.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.21.6)\n",
            "Requirement already satisfied: decorator>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.0.2)\n",
            "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba>=0.43.0->librosa) (0.34.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba>=0.43.0->librosa) (57.4.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->librosa) (3.0.9)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from pooch>=1.0->librosa) (2.23.0)\n",
            "Requirement already satisfied: appdirs>=1.3.0 in /usr/local/lib/python3.7/dist-packages (from pooch>=1.0->librosa) (1.4.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2022.5.18.1)\n",
            "Requirement already satisfied: six>=1.3 in /usr/local/lib/python3.7/dist-packages (from resampy>=0.2.2->librosa) (1.15.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn!=0.19.0,>=0.14.0->librosa) (3.1.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.7/dist-packages (from soundfile>=0.10.2->librosa) (1.15.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.0->soundfile>=0.10.2->librosa) (2.21)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HJjcbxwy46bG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "060a6332-9d10-41e8-e3e8-919ddd824a7e"
      },
      "source": [
        "# Orignial Notebook: https://github.com/MITESHPUTHRANNEU/Speech-Emotion-Analyzer/blob/master/final_results_gender_test.ipynb\n",
        "# This notebook author: Reza Chu\n",
        "# Last Editing Date: 31st May 2019\n",
        "\n",
        "## Python\n",
        "import os\n",
        "import random\n",
        "import sys\n",
        "\n",
        "import IPython\n",
        "from IPython.display import Audio\n",
        "from IPython.display import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "## Package\n",
        "import glob \n",
        "import keras\n",
        "import IPython.display as ipd\n",
        "import librosa\n",
        "import librosa.display\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import plotly.graph_objs as go\n",
        "import plotly.offline as py\n",
        "import plotly.tools as tls\n",
        "import seaborn as sns\n",
        "import scipy.io.wavfile\n",
        "import tensorflow as tf\n",
        "py.init_notebook_mode(connected=True)\n",
        "\n",
        "## Keras\n",
        "from keras import regularizers\n",
        "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping\n",
        "from keras.callbacks import  History, ReduceLROnPlateau, CSVLogger\n",
        "from keras.models import Model, Sequential\n",
        "from keras.layers import Dense, Embedding, LSTM\n",
        "from keras.layers import Input, Flatten, Dropout, Activation, BatchNormalization\n",
        "from keras.layers import Conv1D, MaxPooling1D, AveragePooling1D\n",
        "from keras.preprocessing import sequence\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.utils import np_utils\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "## Sklearn\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "## Rest\n",
        "from scipy.fftpack import fft\n",
        "from scipy import signal\n",
        "from scipy.io import wavfile\n",
        "from tqdm import tqdm\n",
        "\n",
        "input_duration=3\n",
        "# % pylab inline"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "        <script type=\"text/javascript\">\n",
              "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
              "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
              "        if (typeof require !== 'undefined') {\n",
              "        require.undef(\"plotly\");\n",
              "        requirejs.config({\n",
              "            paths: {\n",
              "                'plotly': ['https://cdn.plot.ly/plotly-2.8.3.min']\n",
              "            }\n",
              "        });\n",
              "        require(['plotly'], function(Plotly) {\n",
              "            window._Plotly = Plotly;\n",
              "        });\n",
              "        }\n",
              "        </script>\n",
              "        "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Saving joblib files to not load them again with the loop above\n",
        "\n",
        "# import joblib\n",
        "\n",
        "# X_name = 'x.joblib'\n",
        "# y_name = 'y.joblib'\n",
        "# save_dir = '/content/drive/My Drive/graduation project/audio/paper_code/features'\n",
        "\n",
        "# savedX = joblib.dump(X, os.path.join(save_dir, X_name))\n",
        "# savedy = joblib.dump(y, os.path.join(save_dir, y_name))"
      ],
      "metadata": {
        "id": "UCzic8rlDcuk"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Loading saved models\n",
        "import joblib\n",
        "X = joblib.load('/content/drive/My Drive/graduation project/audio/paper_code/features/x.joblib')\n",
        "y = joblib.load('/content/drive/My Drive/graduation project/audio/paper_code/features/y.joblib')"
      ],
      "metadata": {
        "id": "Q35CN6zDrzg1"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7PSTurzjCo5K",
        "outputId": "36dedeb6-7b51-4080-f90f-bb2e24f6c51c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2068, 40)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.1 ,shuffle = True\n",
        "                                                    , random_state=42)\n",
        "X_train , X_valid, y_train, y_valid = train_test_split(X_train,y_train, test_size=0.1112305212 , shuffle = True \n",
        "                                                       , random_state=42)"
      ],
      "metadata": {
        "id": "Ai4Fy5cPCiq1"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "x_traincnn = np.expand_dims(X_train, axis=2)\n",
        "x_testcnn = np.expand_dims(X_test, axis=2)\n",
        "X_valid= np.expand_dims(X_valid, axis=2)"
      ],
      "metadata": {
        "id": "tp1Fm5K3CEXu"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_traincnn.shape, x_testcnn.shape , X_valid.shape\n",
        "#1861"
      ],
      "metadata": {
        "id": "RI0MxoIPBws5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d2cd9e60-dab1-48b5-fba9-bc266d58fed1"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1654, 40, 1), (207, 40, 1), (207, 40, 1))"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oALhiMUd9G2Y",
        "outputId": "3cff1fd1-ccba-4e6c-843c-a5f724093250"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (2.8.2+zzzcolab20220527125636)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (14.0.1)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.21.6)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.0.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n",
            "Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.5.3)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.26.0)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.46.3)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow) (57.4.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.17.3)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (4.2.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow) (1.5.2)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (3.3.7)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.23.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.35.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.6.1)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (4.11.4)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (3.8.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2022.5.18.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (3.2.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from keras.preprocessing import sequence\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from keras.layers import Input, Flatten, Dropout, Activation\n",
        "from keras.layers import Conv1D, MaxPooling1D\n",
        "from keras.models import Model\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras import optimizers\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv1D(128, 8,padding='same', #classifier.add(Convolution2D(64, (3, 3), padding = 'same', input_shape = (128, 128, 3), activation = 'relu'))\n",
        "                 input_shape=(40,1)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(MaxPooling1D(pool_size=(5)))\n",
        "\n",
        "\n",
        "model.add(Conv1D(256,8,padding='same',))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(MaxPooling1D(pool_size=(5)))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(256))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(256))\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "model.add(Dense(6))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "opt = tf.keras.optimizers.RMSprop(lr=0.00002 , decay=0.0)\n",
        "#opt = tf.keras.optimizers.RMSprop(lr=0.0001, rho=0.9, epsilon=1e-07, decay=0.0)\n",
        "#opt = tf.keras.optimizers.SGD(lr=0.001, momentum=0.0, decay=0.0, nesterov=False)"
      ],
      "metadata": {
        "id": "g74fXWVAC4Cr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09460591-8a80-43f4-cbc6-cc556fa2dd77"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/rmsprop.py:130: UserWarning:\n",
            "\n",
            "The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H6ukOxAGC_I4",
        "outputId": "bdb347c7-25dd-4175-ab1a-87f1fbfaa4fc"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d (Conv1D)             (None, 40, 128)           1152      \n",
            "                                                                 \n",
            " activation (Activation)     (None, 40, 128)           0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 40, 128)           0         \n",
            "                                                                 \n",
            " max_pooling1d (MaxPooling1D  (None, 8, 128)           0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv1d_1 (Conv1D)           (None, 8, 256)            262400    \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 8, 256)            0         \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 8, 256)            0         \n",
            "                                                                 \n",
            " max_pooling1d_1 (MaxPooling  (None, 1, 256)           0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 256)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 256)               65792     \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 256)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 256)               65792     \n",
            "                                                                 \n",
            " activation_3 (Activation)   (None, 256)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 6)                 1542      \n",
            "                                                                 \n",
            " activation_4 (Activation)   (None, 6)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 396,678\n",
            "Trainable params: 396,678\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='sparse_categorical_crossentropy',\n",
        "              optimizer=opt,\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "AbMlLNk4DCBM"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an Instance of Early Stopping Callback.\n",
        "#early_stopping_callback = EarlyStopping(monitor = 'val_loss', patience = 25, mode = 'min', restore_best_weights = True)\n",
        "\n",
        "cnnhistory=model.fit(x_traincnn, y_train, batch_size=16, epochs=800 , shuffle = True, \n",
        "                     validation_data=(X_valid, y_valid) , #callbacks = [early_stopping_callback]\n",
        "                     )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RI1v2AuADFhy",
        "outputId": "bcc6b2a6-ce69-4105-ceeb-f9df8901b214"
      },
      "execution_count": 14,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/800\n",
            "104/104 [==============================] - 7s 9ms/step - loss: 5.0428 - accuracy: 0.1723 - val_loss: 2.4701 - val_accuracy: 0.1932\n",
            "Epoch 2/800\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 4.0818 - accuracy: 0.1826 - val_loss: 2.1231 - val_accuracy: 0.1981\n",
            "Epoch 3/800\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 3.5856 - accuracy: 0.1693 - val_loss: 1.9727 - val_accuracy: 0.1643\n",
            "Epoch 4/800\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 3.1457 - accuracy: 0.1850 - val_loss: 2.0509 - val_accuracy: 0.1932\n",
            "Epoch 5/800\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 2.8515 - accuracy: 0.1850 - val_loss: 1.9169 - val_accuracy: 0.1981\n",
            "Epoch 6/800\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 2.6488 - accuracy: 0.1947 - val_loss: 1.8666 - val_accuracy: 0.2271\n",
            "Epoch 7/800\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 2.5025 - accuracy: 0.1941 - val_loss: 1.8522 - val_accuracy: 0.2174\n",
            "Epoch 8/800\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 2.4338 - accuracy: 0.1874 - val_loss: 1.7854 - val_accuracy: 0.2174\n",
            "Epoch 9/800\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 2.2826 - accuracy: 0.2128 - val_loss: 1.7816 - val_accuracy: 0.2367\n",
            "Epoch 10/800\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 2.2137 - accuracy: 0.2001 - val_loss: 1.7355 - val_accuracy: 0.2077\n",
            "Epoch 11/800\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 2.1688 - accuracy: 0.2025 - val_loss: 1.7339 - val_accuracy: 0.2512\n",
            "Epoch 12/800\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 2.1209 - accuracy: 0.2025 - val_loss: 1.7679 - val_accuracy: 0.2464\n",
            "Epoch 13/800\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 2.0918 - accuracy: 0.2104 - val_loss: 1.7476 - val_accuracy: 0.1932\n",
            "Epoch 14/800\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 2.0753 - accuracy: 0.1904 - val_loss: 1.7372 - val_accuracy: 0.2367\n",
            "Epoch 15/800\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 2.0032 - accuracy: 0.2164 - val_loss: 1.7147 - val_accuracy: 0.2754\n",
            "Epoch 16/800\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 2.0402 - accuracy: 0.1971 - val_loss: 1.7343 - val_accuracy: 0.2271\n",
            "Epoch 17/800\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.9642 - accuracy: 0.2243 - val_loss: 1.7028 - val_accuracy: 0.3188\n",
            "Epoch 18/800\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.9191 - accuracy: 0.2261 - val_loss: 1.7107 - val_accuracy: 0.3092\n",
            "Epoch 19/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.9157 - accuracy: 0.2340 - val_loss: 1.7176 - val_accuracy: 0.3285\n",
            "Epoch 20/800\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.9143 - accuracy: 0.2291 - val_loss: 1.6970 - val_accuracy: 0.2802\n",
            "Epoch 21/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.8747 - accuracy: 0.2370 - val_loss: 1.7246 - val_accuracy: 0.2464\n",
            "Epoch 22/800\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.8799 - accuracy: 0.2388 - val_loss: 1.6880 - val_accuracy: 0.2947\n",
            "Epoch 23/800\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.8459 - accuracy: 0.2509 - val_loss: 1.6868 - val_accuracy: 0.2899\n",
            "Epoch 24/800\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.8547 - accuracy: 0.2455 - val_loss: 1.6827 - val_accuracy: 0.3237\n",
            "Epoch 25/800\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.8347 - accuracy: 0.2412 - val_loss: 1.6855 - val_accuracy: 0.2609\n",
            "Epoch 26/800\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.8346 - accuracy: 0.2551 - val_loss: 1.6851 - val_accuracy: 0.3043\n",
            "Epoch 27/800\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.7801 - accuracy: 0.2612 - val_loss: 1.6842 - val_accuracy: 0.3140\n",
            "Epoch 28/800\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.7965 - accuracy: 0.2557 - val_loss: 1.6691 - val_accuracy: 0.2995\n",
            "Epoch 29/800\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.7920 - accuracy: 0.2551 - val_loss: 1.6748 - val_accuracy: 0.4058\n",
            "Epoch 30/800\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.7742 - accuracy: 0.2618 - val_loss: 1.6668 - val_accuracy: 0.3188\n",
            "Epoch 31/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.7835 - accuracy: 0.2497 - val_loss: 1.6634 - val_accuracy: 0.3478\n",
            "Epoch 32/800\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.7571 - accuracy: 0.2630 - val_loss: 1.6801 - val_accuracy: 0.2850\n",
            "Epoch 33/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.7515 - accuracy: 0.2624 - val_loss: 1.6795 - val_accuracy: 0.3478\n",
            "Epoch 34/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.7602 - accuracy: 0.2533 - val_loss: 1.6554 - val_accuracy: 0.3527\n",
            "Epoch 35/800\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.7225 - accuracy: 0.2745 - val_loss: 1.6502 - val_accuracy: 0.3720\n",
            "Epoch 36/800\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.7388 - accuracy: 0.2854 - val_loss: 1.6422 - val_accuracy: 0.3623\n",
            "Epoch 37/800\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.7190 - accuracy: 0.2727 - val_loss: 1.6516 - val_accuracy: 0.3285\n",
            "Epoch 38/800\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.7139 - accuracy: 0.2823 - val_loss: 1.6476 - val_accuracy: 0.3671\n",
            "Epoch 39/800\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.7289 - accuracy: 0.2733 - val_loss: 1.6504 - val_accuracy: 0.3430\n",
            "Epoch 40/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.7100 - accuracy: 0.2956 - val_loss: 1.6431 - val_accuracy: 0.3865\n",
            "Epoch 41/800\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.7100 - accuracy: 0.2817 - val_loss: 1.6406 - val_accuracy: 0.3623\n",
            "Epoch 42/800\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.6916 - accuracy: 0.2944 - val_loss: 1.6408 - val_accuracy: 0.3478\n",
            "Epoch 43/800\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.6932 - accuracy: 0.2975 - val_loss: 1.6425 - val_accuracy: 0.3382\n",
            "Epoch 44/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.6798 - accuracy: 0.2908 - val_loss: 1.6320 - val_accuracy: 0.3285\n",
            "Epoch 45/800\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.6893 - accuracy: 0.2975 - val_loss: 1.6196 - val_accuracy: 0.3671\n",
            "Epoch 46/800\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.6598 - accuracy: 0.2969 - val_loss: 1.6194 - val_accuracy: 0.3527\n",
            "Epoch 47/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.6593 - accuracy: 0.3114 - val_loss: 1.6091 - val_accuracy: 0.3671\n",
            "Epoch 48/800\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.6604 - accuracy: 0.3156 - val_loss: 1.6122 - val_accuracy: 0.4300\n",
            "Epoch 49/800\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.6410 - accuracy: 0.3253 - val_loss: 1.6094 - val_accuracy: 0.4106\n",
            "Epoch 50/800\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.6363 - accuracy: 0.3096 - val_loss: 1.6032 - val_accuracy: 0.3768\n",
            "Epoch 51/800\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.6508 - accuracy: 0.3059 - val_loss: 1.6054 - val_accuracy: 0.3865\n",
            "Epoch 52/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.6656 - accuracy: 0.2993 - val_loss: 1.5885 - val_accuracy: 0.3478\n",
            "Epoch 53/800\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.6511 - accuracy: 0.3198 - val_loss: 1.5990 - val_accuracy: 0.3913\n",
            "Epoch 54/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.6379 - accuracy: 0.3108 - val_loss: 1.5771 - val_accuracy: 0.4734\n",
            "Epoch 55/800\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.6304 - accuracy: 0.3186 - val_loss: 1.5735 - val_accuracy: 0.4396\n",
            "Epoch 56/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.6011 - accuracy: 0.3380 - val_loss: 1.5723 - val_accuracy: 0.3768\n",
            "Epoch 57/800\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.6192 - accuracy: 0.3168 - val_loss: 1.5710 - val_accuracy: 0.3623\n",
            "Epoch 58/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.5803 - accuracy: 0.3640 - val_loss: 1.5612 - val_accuracy: 0.3913\n",
            "Epoch 59/800\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.6070 - accuracy: 0.3458 - val_loss: 1.5483 - val_accuracy: 0.4106\n",
            "Epoch 60/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.5939 - accuracy: 0.3319 - val_loss: 1.5546 - val_accuracy: 0.3961\n",
            "Epoch 61/800\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.5860 - accuracy: 0.3434 - val_loss: 1.5353 - val_accuracy: 0.4106\n",
            "Epoch 62/800\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.5782 - accuracy: 0.3470 - val_loss: 1.5582 - val_accuracy: 0.4251\n",
            "Epoch 63/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.5881 - accuracy: 0.3416 - val_loss: 1.5469 - val_accuracy: 0.3816\n",
            "Epoch 64/800\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.5878 - accuracy: 0.3319 - val_loss: 1.5446 - val_accuracy: 0.4638\n",
            "Epoch 65/800\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.5855 - accuracy: 0.3356 - val_loss: 1.5455 - val_accuracy: 0.4348\n",
            "Epoch 66/800\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.5585 - accuracy: 0.3658 - val_loss: 1.5493 - val_accuracy: 0.3768\n",
            "Epoch 67/800\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.5730 - accuracy: 0.3579 - val_loss: 1.5324 - val_accuracy: 0.3913\n",
            "Epoch 68/800\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.5686 - accuracy: 0.3567 - val_loss: 1.5140 - val_accuracy: 0.4493\n",
            "Epoch 69/800\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.5477 - accuracy: 0.3640 - val_loss: 1.5069 - val_accuracy: 0.4106\n",
            "Epoch 70/800\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.5468 - accuracy: 0.3579 - val_loss: 1.5085 - val_accuracy: 0.4058\n",
            "Epoch 71/800\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.5422 - accuracy: 0.3646 - val_loss: 1.5219 - val_accuracy: 0.3913\n",
            "Epoch 72/800\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.5187 - accuracy: 0.3767 - val_loss: 1.4979 - val_accuracy: 0.4541\n",
            "Epoch 73/800\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.5369 - accuracy: 0.3567 - val_loss: 1.5000 - val_accuracy: 0.4251\n",
            "Epoch 74/800\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.5175 - accuracy: 0.3628 - val_loss: 1.4839 - val_accuracy: 0.4155\n",
            "Epoch 75/800\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.5350 - accuracy: 0.3609 - val_loss: 1.4810 - val_accuracy: 0.4348\n",
            "Epoch 76/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.5155 - accuracy: 0.3706 - val_loss: 1.4783 - val_accuracy: 0.4251\n",
            "Epoch 77/800\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.5005 - accuracy: 0.3742 - val_loss: 1.4778 - val_accuracy: 0.4589\n",
            "Epoch 78/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.4854 - accuracy: 0.3936 - val_loss: 1.4621 - val_accuracy: 0.4589\n",
            "Epoch 79/800\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.5167 - accuracy: 0.3694 - val_loss: 1.4730 - val_accuracy: 0.4444\n",
            "Epoch 80/800\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.4962 - accuracy: 0.3863 - val_loss: 1.4704 - val_accuracy: 0.4541\n",
            "Epoch 81/800\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.4982 - accuracy: 0.3972 - val_loss: 1.4572 - val_accuracy: 0.4879\n",
            "Epoch 82/800\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.4928 - accuracy: 0.4045 - val_loss: 1.4608 - val_accuracy: 0.4396\n",
            "Epoch 83/800\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.4790 - accuracy: 0.3851 - val_loss: 1.4538 - val_accuracy: 0.4396\n",
            "Epoch 84/800\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.4701 - accuracy: 0.4021 - val_loss: 1.4478 - val_accuracy: 0.4783\n",
            "Epoch 85/800\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.4691 - accuracy: 0.4021 - val_loss: 1.4462 - val_accuracy: 0.5024\n",
            "Epoch 86/800\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.4499 - accuracy: 0.4063 - val_loss: 1.4273 - val_accuracy: 0.4444\n",
            "Epoch 87/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.4524 - accuracy: 0.4129 - val_loss: 1.4646 - val_accuracy: 0.3961\n",
            "Epoch 88/800\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.4551 - accuracy: 0.4141 - val_loss: 1.4517 - val_accuracy: 0.4783\n",
            "Epoch 89/800\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.4584 - accuracy: 0.4057 - val_loss: 1.4296 - val_accuracy: 0.4928\n",
            "Epoch 90/800\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.4240 - accuracy: 0.4244 - val_loss: 1.4354 - val_accuracy: 0.4541\n",
            "Epoch 91/800\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.4541 - accuracy: 0.3996 - val_loss: 1.4404 - val_accuracy: 0.4976\n",
            "Epoch 92/800\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.4525 - accuracy: 0.3912 - val_loss: 1.4461 - val_accuracy: 0.4444\n",
            "Epoch 93/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.4320 - accuracy: 0.4178 - val_loss: 1.4264 - val_accuracy: 0.4734\n",
            "Epoch 94/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.4289 - accuracy: 0.4196 - val_loss: 1.4321 - val_accuracy: 0.4444\n",
            "Epoch 95/800\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.4208 - accuracy: 0.4268 - val_loss: 1.4105 - val_accuracy: 0.4638\n",
            "Epoch 96/800\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.4493 - accuracy: 0.4184 - val_loss: 1.3903 - val_accuracy: 0.5217\n",
            "Epoch 97/800\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.4224 - accuracy: 0.4172 - val_loss: 1.4037 - val_accuracy: 0.4638\n",
            "Epoch 98/800\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.4033 - accuracy: 0.4268 - val_loss: 1.3817 - val_accuracy: 0.4831\n",
            "Epoch 99/800\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.4040 - accuracy: 0.4287 - val_loss: 1.3907 - val_accuracy: 0.4589\n",
            "Epoch 100/800\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.3943 - accuracy: 0.4547 - val_loss: 1.3813 - val_accuracy: 0.4734\n",
            "Epoch 101/800\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.4046 - accuracy: 0.4395 - val_loss: 1.3799 - val_accuracy: 0.4879\n",
            "Epoch 102/800\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.3967 - accuracy: 0.4377 - val_loss: 1.3762 - val_accuracy: 0.5217\n",
            "Epoch 103/800\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.3914 - accuracy: 0.4456 - val_loss: 1.3650 - val_accuracy: 0.4783\n",
            "Epoch 104/800\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.3866 - accuracy: 0.4389 - val_loss: 1.3764 - val_accuracy: 0.5169\n",
            "Epoch 105/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.3743 - accuracy: 0.4492 - val_loss: 1.3461 - val_accuracy: 0.5121\n",
            "Epoch 106/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.3456 - accuracy: 0.4565 - val_loss: 1.3486 - val_accuracy: 0.4928\n",
            "Epoch 107/800\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.3820 - accuracy: 0.4274 - val_loss: 1.3683 - val_accuracy: 0.5314\n",
            "Epoch 108/800\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.3840 - accuracy: 0.4317 - val_loss: 1.3587 - val_accuracy: 0.5169\n",
            "Epoch 109/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.3709 - accuracy: 0.4456 - val_loss: 1.3435 - val_accuracy: 0.5314\n",
            "Epoch 110/800\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.3572 - accuracy: 0.4462 - val_loss: 1.3321 - val_accuracy: 0.5411\n",
            "Epoch 111/800\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.3631 - accuracy: 0.4504 - val_loss: 1.3666 - val_accuracy: 0.4783\n",
            "Epoch 112/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.3563 - accuracy: 0.4353 - val_loss: 1.3381 - val_accuracy: 0.4879\n",
            "Epoch 113/800\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.3598 - accuracy: 0.4528 - val_loss: 1.3352 - val_accuracy: 0.4976\n",
            "Epoch 114/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.3423 - accuracy: 0.4613 - val_loss: 1.3180 - val_accuracy: 0.5169\n",
            "Epoch 115/800\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.3183 - accuracy: 0.4716 - val_loss: 1.3126 - val_accuracy: 0.5121\n",
            "Epoch 116/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.3319 - accuracy: 0.4522 - val_loss: 1.3222 - val_accuracy: 0.5217\n",
            "Epoch 117/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.3332 - accuracy: 0.4661 - val_loss: 1.3289 - val_accuracy: 0.5072\n",
            "Epoch 118/800\n",
            "104/104 [==============================] - 1s 9ms/step - loss: 1.3287 - accuracy: 0.4698 - val_loss: 1.3083 - val_accuracy: 0.5266\n",
            "Epoch 119/800\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 1.3078 - accuracy: 0.4728 - val_loss: 1.3212 - val_accuracy: 0.4976\n",
            "Epoch 120/800\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 1.3291 - accuracy: 0.4643 - val_loss: 1.2973 - val_accuracy: 0.5266\n",
            "Epoch 121/800\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 1.3207 - accuracy: 0.4631 - val_loss: 1.2937 - val_accuracy: 0.5266\n",
            "Epoch 122/800\n",
            "104/104 [==============================] - 1s 10ms/step - loss: 1.3237 - accuracy: 0.4649 - val_loss: 1.3126 - val_accuracy: 0.5121\n",
            "Epoch 123/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.3043 - accuracy: 0.4800 - val_loss: 1.2993 - val_accuracy: 0.4976\n",
            "Epoch 124/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.3094 - accuracy: 0.4667 - val_loss: 1.3192 - val_accuracy: 0.4976\n",
            "Epoch 125/800\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.2828 - accuracy: 0.4794 - val_loss: 1.2966 - val_accuracy: 0.5024\n",
            "Epoch 126/800\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.3018 - accuracy: 0.4788 - val_loss: 1.2821 - val_accuracy: 0.4976\n",
            "Epoch 127/800\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.2747 - accuracy: 0.4825 - val_loss: 1.2835 - val_accuracy: 0.5604\n",
            "Epoch 128/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.2887 - accuracy: 0.4782 - val_loss: 1.2973 - val_accuracy: 0.5362\n",
            "Epoch 129/800\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.2910 - accuracy: 0.4807 - val_loss: 1.2730 - val_accuracy: 0.5169\n",
            "Epoch 130/800\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.2729 - accuracy: 0.4722 - val_loss: 1.2816 - val_accuracy: 0.5217\n",
            "Epoch 131/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.2933 - accuracy: 0.4903 - val_loss: 1.2907 - val_accuracy: 0.5169\n",
            "Epoch 132/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.2536 - accuracy: 0.4909 - val_loss: 1.2565 - val_accuracy: 0.5411\n",
            "Epoch 133/800\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.2664 - accuracy: 0.4903 - val_loss: 1.2615 - val_accuracy: 0.5556\n",
            "Epoch 134/800\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.2742 - accuracy: 0.4891 - val_loss: 1.2684 - val_accuracy: 0.5217\n",
            "Epoch 135/800\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.2734 - accuracy: 0.4873 - val_loss: 1.2483 - val_accuracy: 0.5652\n",
            "Epoch 136/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.2538 - accuracy: 0.4891 - val_loss: 1.2388 - val_accuracy: 0.5556\n",
            "Epoch 137/800\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.2492 - accuracy: 0.4879 - val_loss: 1.2542 - val_accuracy: 0.5169\n",
            "Epoch 138/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.2654 - accuracy: 0.5091 - val_loss: 1.2636 - val_accuracy: 0.5556\n",
            "Epoch 139/800\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.2565 - accuracy: 0.4927 - val_loss: 1.2494 - val_accuracy: 0.5459\n",
            "Epoch 140/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.2551 - accuracy: 0.5079 - val_loss: 1.2388 - val_accuracy: 0.5314\n",
            "Epoch 141/800\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.2534 - accuracy: 0.5042 - val_loss: 1.2391 - val_accuracy: 0.5749\n",
            "Epoch 142/800\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.2271 - accuracy: 0.4988 - val_loss: 1.2157 - val_accuracy: 0.5652\n",
            "Epoch 143/800\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.2194 - accuracy: 0.5175 - val_loss: 1.2302 - val_accuracy: 0.5411\n",
            "Epoch 144/800\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.2409 - accuracy: 0.5103 - val_loss: 1.2324 - val_accuracy: 0.5749\n",
            "Epoch 145/800\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.2324 - accuracy: 0.5103 - val_loss: 1.2252 - val_accuracy: 0.5604\n",
            "Epoch 146/800\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.2198 - accuracy: 0.5103 - val_loss: 1.2172 - val_accuracy: 0.5749\n",
            "Epoch 147/800\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.2343 - accuracy: 0.4982 - val_loss: 1.2075 - val_accuracy: 0.5942\n",
            "Epoch 148/800\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.2460 - accuracy: 0.5006 - val_loss: 1.2039 - val_accuracy: 0.5749\n",
            "Epoch 149/800\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.2191 - accuracy: 0.5085 - val_loss: 1.2009 - val_accuracy: 0.5652\n",
            "Epoch 150/800\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.2198 - accuracy: 0.5169 - val_loss: 1.1946 - val_accuracy: 0.5604\n",
            "Epoch 151/800\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.2118 - accuracy: 0.5145 - val_loss: 1.2061 - val_accuracy: 0.5652\n",
            "Epoch 152/800\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.2040 - accuracy: 0.5224 - val_loss: 1.2204 - val_accuracy: 0.5121\n",
            "Epoch 153/800\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.2114 - accuracy: 0.5091 - val_loss: 1.1794 - val_accuracy: 0.5749\n",
            "Epoch 154/800\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.2003 - accuracy: 0.5127 - val_loss: 1.1778 - val_accuracy: 0.5652\n",
            "Epoch 155/800\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.2103 - accuracy: 0.5284 - val_loss: 1.1810 - val_accuracy: 0.5652\n",
            "Epoch 156/800\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.2042 - accuracy: 0.5054 - val_loss: 1.2066 - val_accuracy: 0.5507\n",
            "Epoch 157/800\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.2058 - accuracy: 0.5133 - val_loss: 1.1825 - val_accuracy: 0.5845\n",
            "Epoch 158/800\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.2057 - accuracy: 0.5169 - val_loss: 1.1837 - val_accuracy: 0.5749\n",
            "Epoch 159/800\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.1897 - accuracy: 0.5308 - val_loss: 1.1879 - val_accuracy: 0.5459\n",
            "Epoch 160/800\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.2108 - accuracy: 0.5254 - val_loss: 1.1831 - val_accuracy: 0.5652\n",
            "Epoch 161/800\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.1863 - accuracy: 0.5248 - val_loss: 1.2041 - val_accuracy: 0.5362\n",
            "Epoch 162/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.1992 - accuracy: 0.5326 - val_loss: 1.1674 - val_accuracy: 0.5700\n",
            "Epoch 163/800\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.1647 - accuracy: 0.5260 - val_loss: 1.1878 - val_accuracy: 0.5507\n",
            "Epoch 164/800\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.1745 - accuracy: 0.5314 - val_loss: 1.1512 - val_accuracy: 0.5652\n",
            "Epoch 165/800\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.1808 - accuracy: 0.5145 - val_loss: 1.1719 - val_accuracy: 0.5556\n",
            "Epoch 166/800\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.1772 - accuracy: 0.5320 - val_loss: 1.1507 - val_accuracy: 0.5845\n",
            "Epoch 167/800\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.1749 - accuracy: 0.5139 - val_loss: 1.1607 - val_accuracy: 0.5797\n",
            "Epoch 168/800\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 1.1706 - accuracy: 0.5375 - val_loss: 1.1514 - val_accuracy: 0.5556\n",
            "Epoch 169/800\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 1.1584 - accuracy: 0.5363 - val_loss: 1.1581 - val_accuracy: 0.5845\n",
            "Epoch 170/800\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 1.1472 - accuracy: 0.5399 - val_loss: 1.1476 - val_accuracy: 0.5797\n",
            "Epoch 171/800\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 1.1608 - accuracy: 0.5314 - val_loss: 1.1299 - val_accuracy: 0.5845\n",
            "Epoch 172/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.1358 - accuracy: 0.5478 - val_loss: 1.1559 - val_accuracy: 0.5556\n",
            "Epoch 173/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.1394 - accuracy: 0.5405 - val_loss: 1.1258 - val_accuracy: 0.5894\n",
            "Epoch 174/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.1424 - accuracy: 0.5381 - val_loss: 1.1311 - val_accuracy: 0.5894\n",
            "Epoch 175/800\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.1360 - accuracy: 0.5538 - val_loss: 1.1468 - val_accuracy: 0.5411\n",
            "Epoch 176/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.1525 - accuracy: 0.5381 - val_loss: 1.1383 - val_accuracy: 0.6087\n",
            "Epoch 177/800\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.1271 - accuracy: 0.5399 - val_loss: 1.1292 - val_accuracy: 0.5797\n",
            "Epoch 178/800\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.1301 - accuracy: 0.5411 - val_loss: 1.1127 - val_accuracy: 0.6039\n",
            "Epoch 179/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.1238 - accuracy: 0.5478 - val_loss: 1.1290 - val_accuracy: 0.5942\n",
            "Epoch 180/800\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.1315 - accuracy: 0.5363 - val_loss: 1.1084 - val_accuracy: 0.5749\n",
            "Epoch 181/800\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.1459 - accuracy: 0.5381 - val_loss: 1.1151 - val_accuracy: 0.5942\n",
            "Epoch 182/800\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.1326 - accuracy: 0.5435 - val_loss: 1.1264 - val_accuracy: 0.5990\n",
            "Epoch 183/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.1232 - accuracy: 0.5508 - val_loss: 1.1133 - val_accuracy: 0.5942\n",
            "Epoch 184/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.1156 - accuracy: 0.5550 - val_loss: 1.0957 - val_accuracy: 0.5894\n",
            "Epoch 185/800\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.1294 - accuracy: 0.5296 - val_loss: 1.0965 - val_accuracy: 0.6087\n",
            "Epoch 186/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.1004 - accuracy: 0.5574 - val_loss: 1.1002 - val_accuracy: 0.6135\n",
            "Epoch 187/800\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.1104 - accuracy: 0.5538 - val_loss: 1.0928 - val_accuracy: 0.6039\n",
            "Epoch 188/800\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.1082 - accuracy: 0.5508 - val_loss: 1.1038 - val_accuracy: 0.6087\n",
            "Epoch 189/800\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.1198 - accuracy: 0.5502 - val_loss: 1.1066 - val_accuracy: 0.5700\n",
            "Epoch 190/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0981 - accuracy: 0.5635 - val_loss: 1.0986 - val_accuracy: 0.5990\n",
            "Epoch 191/800\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0964 - accuracy: 0.5574 - val_loss: 1.0954 - val_accuracy: 0.5942\n",
            "Epoch 192/800\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.1210 - accuracy: 0.5447 - val_loss: 1.0758 - val_accuracy: 0.5797\n",
            "Epoch 193/800\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.0854 - accuracy: 0.5556 - val_loss: 1.0708 - val_accuracy: 0.5845\n",
            "Epoch 194/800\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.1040 - accuracy: 0.5526 - val_loss: 1.0934 - val_accuracy: 0.5942\n",
            "Epoch 195/800\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.0854 - accuracy: 0.5580 - val_loss: 1.0803 - val_accuracy: 0.6087\n",
            "Epoch 196/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0814 - accuracy: 0.5611 - val_loss: 1.0918 - val_accuracy: 0.5990\n",
            "Epoch 197/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0870 - accuracy: 0.5562 - val_loss: 1.0728 - val_accuracy: 0.6329\n",
            "Epoch 198/800\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0933 - accuracy: 0.5689 - val_loss: 1.0767 - val_accuracy: 0.5942\n",
            "Epoch 199/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0815 - accuracy: 0.5750 - val_loss: 1.0650 - val_accuracy: 0.6232\n",
            "Epoch 200/800\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0729 - accuracy: 0.5701 - val_loss: 1.0730 - val_accuracy: 0.6329\n",
            "Epoch 201/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0828 - accuracy: 0.5659 - val_loss: 1.0593 - val_accuracy: 0.6280\n",
            "Epoch 202/800\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0775 - accuracy: 0.5738 - val_loss: 1.0579 - val_accuracy: 0.6329\n",
            "Epoch 203/800\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0984 - accuracy: 0.5611 - val_loss: 1.0770 - val_accuracy: 0.5942\n",
            "Epoch 204/800\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0804 - accuracy: 0.5599 - val_loss: 1.0643 - val_accuracy: 0.6425\n",
            "Epoch 205/800\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0553 - accuracy: 0.5768 - val_loss: 1.0675 - val_accuracy: 0.6522\n",
            "Epoch 206/800\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0713 - accuracy: 0.5738 - val_loss: 1.0557 - val_accuracy: 0.6232\n",
            "Epoch 207/800\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0719 - accuracy: 0.5683 - val_loss: 1.0423 - val_accuracy: 0.6184\n",
            "Epoch 208/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0662 - accuracy: 0.5611 - val_loss: 1.0580 - val_accuracy: 0.6184\n",
            "Epoch 209/800\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0467 - accuracy: 0.5689 - val_loss: 1.0699 - val_accuracy: 0.5894\n",
            "Epoch 210/800\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0493 - accuracy: 0.5828 - val_loss: 1.0573 - val_accuracy: 0.6039\n",
            "Epoch 211/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0493 - accuracy: 0.5683 - val_loss: 1.0476 - val_accuracy: 0.6184\n",
            "Epoch 212/800\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0452 - accuracy: 0.5865 - val_loss: 1.0224 - val_accuracy: 0.6570\n",
            "Epoch 213/800\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0489 - accuracy: 0.5883 - val_loss: 1.0390 - val_accuracy: 0.6329\n",
            "Epoch 214/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0501 - accuracy: 0.5804 - val_loss: 1.0282 - val_accuracy: 0.6039\n",
            "Epoch 215/800\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0414 - accuracy: 0.5846 - val_loss: 1.0184 - val_accuracy: 0.6135\n",
            "Epoch 216/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0498 - accuracy: 0.5865 - val_loss: 1.0293 - val_accuracy: 0.6522\n",
            "Epoch 217/800\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0273 - accuracy: 0.5786 - val_loss: 1.0057 - val_accuracy: 0.6570\n",
            "Epoch 218/800\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0501 - accuracy: 0.5859 - val_loss: 1.0337 - val_accuracy: 0.6280\n",
            "Epoch 219/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0364 - accuracy: 0.5871 - val_loss: 1.0105 - val_accuracy: 0.6570\n",
            "Epoch 220/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0145 - accuracy: 0.5925 - val_loss: 1.0188 - val_accuracy: 0.6329\n",
            "Epoch 221/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0266 - accuracy: 0.5895 - val_loss: 0.9951 - val_accuracy: 0.6377\n",
            "Epoch 222/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0327 - accuracy: 0.5943 - val_loss: 1.0040 - val_accuracy: 0.6473\n",
            "Epoch 223/800\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0270 - accuracy: 0.5852 - val_loss: 1.0156 - val_accuracy: 0.6570\n",
            "Epoch 224/800\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0307 - accuracy: 0.6082 - val_loss: 0.9978 - val_accuracy: 0.6377\n",
            "Epoch 225/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0307 - accuracy: 0.5822 - val_loss: 1.0092 - val_accuracy: 0.6087\n",
            "Epoch 226/800\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0235 - accuracy: 0.5925 - val_loss: 0.9909 - val_accuracy: 0.6618\n",
            "Epoch 227/800\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0116 - accuracy: 0.5967 - val_loss: 1.0094 - val_accuracy: 0.6522\n",
            "Epoch 228/800\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0035 - accuracy: 0.6088 - val_loss: 1.0259 - val_accuracy: 0.6039\n",
            "Epoch 229/800\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0352 - accuracy: 0.5883 - val_loss: 1.0214 - val_accuracy: 0.6570\n",
            "Epoch 230/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0123 - accuracy: 0.5865 - val_loss: 0.9993 - val_accuracy: 0.6570\n",
            "Epoch 231/800\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0229 - accuracy: 0.5931 - val_loss: 1.0050 - val_accuracy: 0.6329\n",
            "Epoch 232/800\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0285 - accuracy: 0.5889 - val_loss: 0.9907 - val_accuracy: 0.6329\n",
            "Epoch 233/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0173 - accuracy: 0.5919 - val_loss: 0.9906 - val_accuracy: 0.6473\n",
            "Epoch 234/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0098 - accuracy: 0.5913 - val_loss: 0.9822 - val_accuracy: 0.6715\n",
            "Epoch 235/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0083 - accuracy: 0.5913 - val_loss: 0.9895 - val_accuracy: 0.6522\n",
            "Epoch 236/800\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9892 - accuracy: 0.6034 - val_loss: 0.9927 - val_accuracy: 0.6715\n",
            "Epoch 237/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0105 - accuracy: 0.5931 - val_loss: 0.9880 - val_accuracy: 0.6618\n",
            "Epoch 238/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0069 - accuracy: 0.5961 - val_loss: 0.9831 - val_accuracy: 0.6377\n",
            "Epoch 239/800\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9978 - accuracy: 0.5985 - val_loss: 0.9881 - val_accuracy: 0.6763\n",
            "Epoch 240/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0072 - accuracy: 0.5901 - val_loss: 0.9923 - val_accuracy: 0.6763\n",
            "Epoch 241/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9891 - accuracy: 0.6161 - val_loss: 0.9892 - val_accuracy: 0.6763\n",
            "Epoch 242/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9857 - accuracy: 0.6112 - val_loss: 0.9742 - val_accuracy: 0.6618\n",
            "Epoch 243/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9808 - accuracy: 0.6082 - val_loss: 0.9736 - val_accuracy: 0.6860\n",
            "Epoch 244/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9923 - accuracy: 0.6046 - val_loss: 0.9882 - val_accuracy: 0.6377\n",
            "Epoch 245/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9952 - accuracy: 0.5889 - val_loss: 0.9730 - val_accuracy: 0.6715\n",
            "Epoch 246/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9909 - accuracy: 0.5943 - val_loss: 0.9592 - val_accuracy: 0.7005\n",
            "Epoch 247/800\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9982 - accuracy: 0.6004 - val_loss: 0.9706 - val_accuracy: 0.6377\n",
            "Epoch 248/800\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9753 - accuracy: 0.6119 - val_loss: 0.9746 - val_accuracy: 0.6812\n",
            "Epoch 249/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9642 - accuracy: 0.6209 - val_loss: 0.9610 - val_accuracy: 0.6715\n",
            "Epoch 250/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9735 - accuracy: 0.6088 - val_loss: 0.9739 - val_accuracy: 0.6715\n",
            "Epoch 251/800\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9754 - accuracy: 0.5955 - val_loss: 0.9456 - val_accuracy: 0.6812\n",
            "Epoch 252/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9743 - accuracy: 0.6209 - val_loss: 0.9580 - val_accuracy: 0.6570\n",
            "Epoch 253/800\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9777 - accuracy: 0.5979 - val_loss: 0.9393 - val_accuracy: 0.6908\n",
            "Epoch 254/800\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9789 - accuracy: 0.6179 - val_loss: 0.9724 - val_accuracy: 0.6908\n",
            "Epoch 255/800\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9853 - accuracy: 0.6040 - val_loss: 0.9579 - val_accuracy: 0.6473\n",
            "Epoch 256/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9688 - accuracy: 0.5967 - val_loss: 0.9432 - val_accuracy: 0.6860\n",
            "Epoch 257/800\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9684 - accuracy: 0.6094 - val_loss: 0.9456 - val_accuracy: 0.6860\n",
            "Epoch 258/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9565 - accuracy: 0.6215 - val_loss: 0.9377 - val_accuracy: 0.6667\n",
            "Epoch 259/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9383 - accuracy: 0.6360 - val_loss: 0.9412 - val_accuracy: 0.6667\n",
            "Epoch 260/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9782 - accuracy: 0.5967 - val_loss: 0.9375 - val_accuracy: 0.6860\n",
            "Epoch 261/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9642 - accuracy: 0.6070 - val_loss: 0.9390 - val_accuracy: 0.6957\n",
            "Epoch 262/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9855 - accuracy: 0.5943 - val_loss: 0.9470 - val_accuracy: 0.6812\n",
            "Epoch 263/800\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9587 - accuracy: 0.6100 - val_loss: 0.9551 - val_accuracy: 0.6570\n",
            "Epoch 264/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9590 - accuracy: 0.6209 - val_loss: 0.9301 - val_accuracy: 0.7101\n",
            "Epoch 265/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9469 - accuracy: 0.6264 - val_loss: 0.9300 - val_accuracy: 0.6570\n",
            "Epoch 266/800\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9355 - accuracy: 0.6294 - val_loss: 0.9195 - val_accuracy: 0.6860\n",
            "Epoch 267/800\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9558 - accuracy: 0.6167 - val_loss: 0.9310 - val_accuracy: 0.6715\n",
            "Epoch 268/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9307 - accuracy: 0.6258 - val_loss: 0.9212 - val_accuracy: 0.6957\n",
            "Epoch 269/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9434 - accuracy: 0.6245 - val_loss: 0.9455 - val_accuracy: 0.6570\n",
            "Epoch 270/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9325 - accuracy: 0.6288 - val_loss: 0.9134 - val_accuracy: 0.7005\n",
            "Epoch 271/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9388 - accuracy: 0.6215 - val_loss: 0.9283 - val_accuracy: 0.6667\n",
            "Epoch 272/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9429 - accuracy: 0.6131 - val_loss: 0.9189 - val_accuracy: 0.6908\n",
            "Epoch 273/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9291 - accuracy: 0.6282 - val_loss: 0.9183 - val_accuracy: 0.7005\n",
            "Epoch 274/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9628 - accuracy: 0.6185 - val_loss: 0.9303 - val_accuracy: 0.6812\n",
            "Epoch 275/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9393 - accuracy: 0.6288 - val_loss: 0.9425 - val_accuracy: 0.6715\n",
            "Epoch 276/800\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9248 - accuracy: 0.6276 - val_loss: 0.9333 - val_accuracy: 0.6667\n",
            "Epoch 277/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9516 - accuracy: 0.6264 - val_loss: 0.9246 - val_accuracy: 0.6812\n",
            "Epoch 278/800\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9213 - accuracy: 0.6403 - val_loss: 0.9475 - val_accuracy: 0.6715\n",
            "Epoch 279/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9582 - accuracy: 0.6288 - val_loss: 0.9118 - val_accuracy: 0.7005\n",
            "Epoch 280/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9380 - accuracy: 0.6294 - val_loss: 0.9185 - val_accuracy: 0.6667\n",
            "Epoch 281/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9355 - accuracy: 0.6300 - val_loss: 0.9051 - val_accuracy: 0.7005\n",
            "Epoch 282/800\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9178 - accuracy: 0.6245 - val_loss: 0.9304 - val_accuracy: 0.6667\n",
            "Epoch 283/800\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.9129 - accuracy: 0.6475 - val_loss: 0.9064 - val_accuracy: 0.6812\n",
            "Epoch 284/800\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9129 - accuracy: 0.6318 - val_loss: 0.9170 - val_accuracy: 0.7005\n",
            "Epoch 285/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9049 - accuracy: 0.6397 - val_loss: 0.9188 - val_accuracy: 0.7005\n",
            "Epoch 286/800\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9219 - accuracy: 0.6378 - val_loss: 0.9218 - val_accuracy: 0.7005\n",
            "Epoch 287/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9208 - accuracy: 0.6391 - val_loss: 0.9237 - val_accuracy: 0.6812\n",
            "Epoch 288/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9254 - accuracy: 0.6258 - val_loss: 0.8953 - val_accuracy: 0.7295\n",
            "Epoch 289/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9023 - accuracy: 0.6409 - val_loss: 0.8961 - val_accuracy: 0.7150\n",
            "Epoch 290/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9104 - accuracy: 0.6415 - val_loss: 0.8997 - val_accuracy: 0.6860\n",
            "Epoch 291/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9063 - accuracy: 0.6475 - val_loss: 0.9267 - val_accuracy: 0.6860\n",
            "Epoch 292/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9164 - accuracy: 0.6348 - val_loss: 0.9140 - val_accuracy: 0.7198\n",
            "Epoch 293/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9146 - accuracy: 0.6306 - val_loss: 0.9320 - val_accuracy: 0.6618\n",
            "Epoch 294/800\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9274 - accuracy: 0.6354 - val_loss: 0.9026 - val_accuracy: 0.7246\n",
            "Epoch 295/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8993 - accuracy: 0.6499 - val_loss: 0.8931 - val_accuracy: 0.7053\n",
            "Epoch 296/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9251 - accuracy: 0.6239 - val_loss: 0.8960 - val_accuracy: 0.7246\n",
            "Epoch 297/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9157 - accuracy: 0.6378 - val_loss: 0.9089 - val_accuracy: 0.7005\n",
            "Epoch 298/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8860 - accuracy: 0.6433 - val_loss: 0.8847 - val_accuracy: 0.7246\n",
            "Epoch 299/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9041 - accuracy: 0.6403 - val_loss: 0.8982 - val_accuracy: 0.6715\n",
            "Epoch 300/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8978 - accuracy: 0.6475 - val_loss: 0.8843 - val_accuracy: 0.7101\n",
            "Epoch 301/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8925 - accuracy: 0.6397 - val_loss: 0.8972 - val_accuracy: 0.6812\n",
            "Epoch 302/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9083 - accuracy: 0.6415 - val_loss: 0.8908 - val_accuracy: 0.6957\n",
            "Epoch 303/800\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.8986 - accuracy: 0.6518 - val_loss: 0.8740 - val_accuracy: 0.7053\n",
            "Epoch 304/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8955 - accuracy: 0.6481 - val_loss: 0.8920 - val_accuracy: 0.7005\n",
            "Epoch 305/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8723 - accuracy: 0.6638 - val_loss: 0.8926 - val_accuracy: 0.6957\n",
            "Epoch 306/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8931 - accuracy: 0.6397 - val_loss: 0.8977 - val_accuracy: 0.7101\n",
            "Epoch 307/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9010 - accuracy: 0.6415 - val_loss: 0.8776 - val_accuracy: 0.7150\n",
            "Epoch 308/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8758 - accuracy: 0.6511 - val_loss: 0.8738 - val_accuracy: 0.6957\n",
            "Epoch 309/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8659 - accuracy: 0.6584 - val_loss: 0.8897 - val_accuracy: 0.6957\n",
            "Epoch 310/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8717 - accuracy: 0.6548 - val_loss: 0.8948 - val_accuracy: 0.6715\n",
            "Epoch 311/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9059 - accuracy: 0.6203 - val_loss: 0.8603 - val_accuracy: 0.7295\n",
            "Epoch 312/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9009 - accuracy: 0.6391 - val_loss: 0.8993 - val_accuracy: 0.6957\n",
            "Epoch 313/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8955 - accuracy: 0.6409 - val_loss: 0.8819 - val_accuracy: 0.7150\n",
            "Epoch 314/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8993 - accuracy: 0.6391 - val_loss: 0.8653 - val_accuracy: 0.7440\n",
            "Epoch 315/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8943 - accuracy: 0.6475 - val_loss: 0.8742 - val_accuracy: 0.7101\n",
            "Epoch 316/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8813 - accuracy: 0.6415 - val_loss: 0.8903 - val_accuracy: 0.7005\n",
            "Epoch 317/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8868 - accuracy: 0.6385 - val_loss: 0.8768 - val_accuracy: 0.6957\n",
            "Epoch 318/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8795 - accuracy: 0.6536 - val_loss: 0.8753 - val_accuracy: 0.7053\n",
            "Epoch 319/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8741 - accuracy: 0.6451 - val_loss: 0.8637 - val_accuracy: 0.7150\n",
            "Epoch 320/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8489 - accuracy: 0.6554 - val_loss: 0.8684 - val_accuracy: 0.7005\n",
            "Epoch 321/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8730 - accuracy: 0.6530 - val_loss: 0.8729 - val_accuracy: 0.6957\n",
            "Epoch 322/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8786 - accuracy: 0.6530 - val_loss: 0.8689 - val_accuracy: 0.7246\n",
            "Epoch 323/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8526 - accuracy: 0.6651 - val_loss: 0.8685 - val_accuracy: 0.7101\n",
            "Epoch 324/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8578 - accuracy: 0.6663 - val_loss: 0.8847 - val_accuracy: 0.7053\n",
            "Epoch 325/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8692 - accuracy: 0.6409 - val_loss: 0.8689 - val_accuracy: 0.7150\n",
            "Epoch 326/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8618 - accuracy: 0.6590 - val_loss: 0.8785 - val_accuracy: 0.7005\n",
            "Epoch 327/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8558 - accuracy: 0.6584 - val_loss: 0.8611 - val_accuracy: 0.6957\n",
            "Epoch 328/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8548 - accuracy: 0.6626 - val_loss: 0.8631 - val_accuracy: 0.7246\n",
            "Epoch 329/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8397 - accuracy: 0.6717 - val_loss: 0.8680 - val_accuracy: 0.7198\n",
            "Epoch 330/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8699 - accuracy: 0.6536 - val_loss: 0.8803 - val_accuracy: 0.7005\n",
            "Epoch 331/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8689 - accuracy: 0.6620 - val_loss: 0.8589 - val_accuracy: 0.7150\n",
            "Epoch 332/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8566 - accuracy: 0.6602 - val_loss: 0.8643 - val_accuracy: 0.7101\n",
            "Epoch 333/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8468 - accuracy: 0.6511 - val_loss: 0.8693 - val_accuracy: 0.6957\n",
            "Epoch 334/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8616 - accuracy: 0.6566 - val_loss: 0.8473 - val_accuracy: 0.7150\n",
            "Epoch 335/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8618 - accuracy: 0.6614 - val_loss: 0.8750 - val_accuracy: 0.6763\n",
            "Epoch 336/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8776 - accuracy: 0.6536 - val_loss: 0.8575 - val_accuracy: 0.7150\n",
            "Epoch 337/800\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8492 - accuracy: 0.6632 - val_loss: 0.8549 - val_accuracy: 0.7150\n",
            "Epoch 338/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8481 - accuracy: 0.6578 - val_loss: 0.8452 - val_accuracy: 0.7198\n",
            "Epoch 339/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8460 - accuracy: 0.6608 - val_loss: 0.8720 - val_accuracy: 0.7005\n",
            "Epoch 340/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8482 - accuracy: 0.6681 - val_loss: 0.8655 - val_accuracy: 0.6957\n",
            "Epoch 341/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8515 - accuracy: 0.6693 - val_loss: 0.8530 - val_accuracy: 0.7101\n",
            "Epoch 342/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8558 - accuracy: 0.6590 - val_loss: 0.8580 - val_accuracy: 0.7150\n",
            "Epoch 343/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8380 - accuracy: 0.6632 - val_loss: 0.8635 - val_accuracy: 0.7150\n",
            "Epoch 344/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8374 - accuracy: 0.6657 - val_loss: 0.8700 - val_accuracy: 0.7053\n",
            "Epoch 345/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8474 - accuracy: 0.6608 - val_loss: 0.8289 - val_accuracy: 0.7150\n",
            "Epoch 346/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8478 - accuracy: 0.6681 - val_loss: 0.8604 - val_accuracy: 0.6957\n",
            "Epoch 347/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8486 - accuracy: 0.6620 - val_loss: 0.8671 - val_accuracy: 0.6812\n",
            "Epoch 348/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8503 - accuracy: 0.6505 - val_loss: 0.8411 - val_accuracy: 0.7198\n",
            "Epoch 349/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8380 - accuracy: 0.6657 - val_loss: 0.8314 - val_accuracy: 0.7295\n",
            "Epoch 350/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8418 - accuracy: 0.6421 - val_loss: 0.8322 - val_accuracy: 0.7005\n",
            "Epoch 351/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8248 - accuracy: 0.6723 - val_loss: 0.8281 - val_accuracy: 0.7101\n",
            "Epoch 352/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8578 - accuracy: 0.6584 - val_loss: 0.8360 - val_accuracy: 0.7005\n",
            "Epoch 353/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8123 - accuracy: 0.6741 - val_loss: 0.8399 - val_accuracy: 0.7150\n",
            "Epoch 354/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8224 - accuracy: 0.6741 - val_loss: 0.8284 - val_accuracy: 0.7150\n",
            "Epoch 355/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8334 - accuracy: 0.6657 - val_loss: 0.8371 - val_accuracy: 0.7246\n",
            "Epoch 356/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8226 - accuracy: 0.6808 - val_loss: 0.8281 - val_accuracy: 0.7198\n",
            "Epoch 357/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8368 - accuracy: 0.6669 - val_loss: 0.8391 - val_accuracy: 0.7005\n",
            "Epoch 358/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8398 - accuracy: 0.6644 - val_loss: 0.8262 - val_accuracy: 0.7246\n",
            "Epoch 359/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8054 - accuracy: 0.6838 - val_loss: 0.8361 - val_accuracy: 0.7198\n",
            "Epoch 360/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8168 - accuracy: 0.6759 - val_loss: 0.8372 - val_accuracy: 0.7198\n",
            "Epoch 361/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8125 - accuracy: 0.6747 - val_loss: 0.8190 - val_accuracy: 0.7343\n",
            "Epoch 362/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8296 - accuracy: 0.6729 - val_loss: 0.8321 - val_accuracy: 0.7150\n",
            "Epoch 363/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8171 - accuracy: 0.6778 - val_loss: 0.8238 - val_accuracy: 0.7343\n",
            "Epoch 364/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8248 - accuracy: 0.6632 - val_loss: 0.8296 - val_accuracy: 0.7246\n",
            "Epoch 365/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8261 - accuracy: 0.6693 - val_loss: 0.8345 - val_accuracy: 0.7101\n",
            "Epoch 366/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8243 - accuracy: 0.6687 - val_loss: 0.8416 - val_accuracy: 0.7198\n",
            "Epoch 367/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8253 - accuracy: 0.6675 - val_loss: 0.8432 - val_accuracy: 0.7053\n",
            "Epoch 368/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8206 - accuracy: 0.6784 - val_loss: 0.8268 - val_accuracy: 0.7053\n",
            "Epoch 369/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8266 - accuracy: 0.6820 - val_loss: 0.8337 - val_accuracy: 0.7246\n",
            "Epoch 370/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8142 - accuracy: 0.6808 - val_loss: 0.8359 - val_accuracy: 0.7198\n",
            "Epoch 371/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8079 - accuracy: 0.6705 - val_loss: 0.8227 - val_accuracy: 0.7295\n",
            "Epoch 372/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7882 - accuracy: 0.6844 - val_loss: 0.8481 - val_accuracy: 0.7198\n",
            "Epoch 373/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7979 - accuracy: 0.6898 - val_loss: 0.8116 - val_accuracy: 0.7295\n",
            "Epoch 374/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7927 - accuracy: 0.6771 - val_loss: 0.8188 - val_accuracy: 0.7150\n",
            "Epoch 375/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8039 - accuracy: 0.6826 - val_loss: 0.8200 - val_accuracy: 0.7246\n",
            "Epoch 376/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8182 - accuracy: 0.6753 - val_loss: 0.8304 - val_accuracy: 0.7101\n",
            "Epoch 377/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8066 - accuracy: 0.6771 - val_loss: 0.8194 - val_accuracy: 0.7198\n",
            "Epoch 378/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7837 - accuracy: 0.6929 - val_loss: 0.8319 - val_accuracy: 0.6860\n",
            "Epoch 379/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8015 - accuracy: 0.6771 - val_loss: 0.8301 - val_accuracy: 0.7198\n",
            "Epoch 380/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7923 - accuracy: 0.6923 - val_loss: 0.8420 - val_accuracy: 0.7053\n",
            "Epoch 381/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7843 - accuracy: 0.6941 - val_loss: 0.8234 - val_accuracy: 0.7246\n",
            "Epoch 382/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7888 - accuracy: 0.6917 - val_loss: 0.8279 - val_accuracy: 0.7150\n",
            "Epoch 383/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8088 - accuracy: 0.6898 - val_loss: 0.8136 - val_accuracy: 0.7198\n",
            "Epoch 384/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7906 - accuracy: 0.6820 - val_loss: 0.8174 - val_accuracy: 0.7198\n",
            "Epoch 385/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8102 - accuracy: 0.6759 - val_loss: 0.8056 - val_accuracy: 0.7295\n",
            "Epoch 386/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7959 - accuracy: 0.6711 - val_loss: 0.8059 - val_accuracy: 0.7440\n",
            "Epoch 387/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8000 - accuracy: 0.6729 - val_loss: 0.8286 - val_accuracy: 0.7150\n",
            "Epoch 388/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7989 - accuracy: 0.6765 - val_loss: 0.8019 - val_accuracy: 0.7198\n",
            "Epoch 389/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8005 - accuracy: 0.6814 - val_loss: 0.8140 - val_accuracy: 0.7246\n",
            "Epoch 390/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8036 - accuracy: 0.6796 - val_loss: 0.8077 - val_accuracy: 0.7150\n",
            "Epoch 391/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7983 - accuracy: 0.6826 - val_loss: 0.8168 - val_accuracy: 0.7150\n",
            "Epoch 392/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7940 - accuracy: 0.6947 - val_loss: 0.8088 - val_accuracy: 0.7198\n",
            "Epoch 393/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7869 - accuracy: 0.6874 - val_loss: 0.8081 - val_accuracy: 0.7488\n",
            "Epoch 394/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7925 - accuracy: 0.6850 - val_loss: 0.8210 - val_accuracy: 0.7391\n",
            "Epoch 395/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7755 - accuracy: 0.6917 - val_loss: 0.8154 - val_accuracy: 0.7343\n",
            "Epoch 396/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7816 - accuracy: 0.6868 - val_loss: 0.8147 - val_accuracy: 0.7198\n",
            "Epoch 397/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7826 - accuracy: 0.6917 - val_loss: 0.8251 - val_accuracy: 0.7343\n",
            "Epoch 398/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7699 - accuracy: 0.6995 - val_loss: 0.7976 - val_accuracy: 0.7343\n",
            "Epoch 399/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7851 - accuracy: 0.6898 - val_loss: 0.8133 - val_accuracy: 0.7053\n",
            "Epoch 400/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7771 - accuracy: 0.6953 - val_loss: 0.8020 - val_accuracy: 0.7101\n",
            "Epoch 401/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7729 - accuracy: 0.6898 - val_loss: 0.8083 - val_accuracy: 0.6908\n",
            "Epoch 402/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7972 - accuracy: 0.6917 - val_loss: 0.8063 - val_accuracy: 0.7391\n",
            "Epoch 403/800\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.7854 - accuracy: 0.6874 - val_loss: 0.7983 - val_accuracy: 0.7295\n",
            "Epoch 404/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7916 - accuracy: 0.6862 - val_loss: 0.8170 - val_accuracy: 0.7101\n",
            "Epoch 405/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7690 - accuracy: 0.6959 - val_loss: 0.8025 - val_accuracy: 0.7198\n",
            "Epoch 406/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7821 - accuracy: 0.6971 - val_loss: 0.8078 - val_accuracy: 0.7391\n",
            "Epoch 407/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7755 - accuracy: 0.6941 - val_loss: 0.7987 - val_accuracy: 0.7005\n",
            "Epoch 408/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7920 - accuracy: 0.6814 - val_loss: 0.8187 - val_accuracy: 0.7246\n",
            "Epoch 409/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7764 - accuracy: 0.6917 - val_loss: 0.7918 - val_accuracy: 0.7295\n",
            "Epoch 410/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7946 - accuracy: 0.6874 - val_loss: 0.8088 - val_accuracy: 0.7343\n",
            "Epoch 411/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7792 - accuracy: 0.6814 - val_loss: 0.7888 - val_accuracy: 0.7246\n",
            "Epoch 412/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7569 - accuracy: 0.6953 - val_loss: 0.8031 - val_accuracy: 0.7198\n",
            "Epoch 413/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7595 - accuracy: 0.6965 - val_loss: 0.7899 - val_accuracy: 0.7295\n",
            "Epoch 414/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7633 - accuracy: 0.6911 - val_loss: 0.7951 - val_accuracy: 0.7101\n",
            "Epoch 415/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7683 - accuracy: 0.6983 - val_loss: 0.8046 - val_accuracy: 0.7295\n",
            "Epoch 416/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7835 - accuracy: 0.6844 - val_loss: 0.8060 - val_accuracy: 0.7246\n",
            "Epoch 417/800\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.7770 - accuracy: 0.6886 - val_loss: 0.7951 - val_accuracy: 0.7391\n",
            "Epoch 418/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7578 - accuracy: 0.7007 - val_loss: 0.8165 - val_accuracy: 0.6957\n",
            "Epoch 419/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7742 - accuracy: 0.6935 - val_loss: 0.7768 - val_accuracy: 0.7295\n",
            "Epoch 420/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7782 - accuracy: 0.6941 - val_loss: 0.7973 - val_accuracy: 0.7198\n",
            "Epoch 421/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7494 - accuracy: 0.7050 - val_loss: 0.7980 - val_accuracy: 0.7150\n",
            "Epoch 422/800\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.7574 - accuracy: 0.6904 - val_loss: 0.7849 - val_accuracy: 0.7391\n",
            "Epoch 423/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7492 - accuracy: 0.6977 - val_loss: 0.8008 - val_accuracy: 0.7246\n",
            "Epoch 424/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7702 - accuracy: 0.6989 - val_loss: 0.7715 - val_accuracy: 0.7246\n",
            "Epoch 425/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7732 - accuracy: 0.6929 - val_loss: 0.8045 - val_accuracy: 0.7198\n",
            "Epoch 426/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7574 - accuracy: 0.6880 - val_loss: 0.7907 - val_accuracy: 0.7343\n",
            "Epoch 427/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7501 - accuracy: 0.6947 - val_loss: 0.7808 - val_accuracy: 0.7246\n",
            "Epoch 428/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7678 - accuracy: 0.7019 - val_loss: 0.7742 - val_accuracy: 0.7246\n",
            "Epoch 429/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7548 - accuracy: 0.7007 - val_loss: 0.7928 - val_accuracy: 0.7198\n",
            "Epoch 430/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7613 - accuracy: 0.7080 - val_loss: 0.7841 - val_accuracy: 0.7295\n",
            "Epoch 431/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7475 - accuracy: 0.6965 - val_loss: 0.7785 - val_accuracy: 0.7295\n",
            "Epoch 432/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7569 - accuracy: 0.7110 - val_loss: 0.7914 - val_accuracy: 0.7198\n",
            "Epoch 433/800\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.7571 - accuracy: 0.6989 - val_loss: 0.7930 - val_accuracy: 0.7343\n",
            "Epoch 434/800\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.7443 - accuracy: 0.7044 - val_loss: 0.7791 - val_accuracy: 0.7343\n",
            "Epoch 435/800\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.7490 - accuracy: 0.7044 - val_loss: 0.7912 - val_accuracy: 0.7198\n",
            "Epoch 436/800\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.7397 - accuracy: 0.6965 - val_loss: 0.7911 - val_accuracy: 0.7246\n",
            "Epoch 437/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7393 - accuracy: 0.7013 - val_loss: 0.7871 - val_accuracy: 0.7150\n",
            "Epoch 438/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7410 - accuracy: 0.7062 - val_loss: 0.7741 - val_accuracy: 0.7391\n",
            "Epoch 439/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7195 - accuracy: 0.7164 - val_loss: 0.7732 - val_accuracy: 0.7101\n",
            "Epoch 440/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7405 - accuracy: 0.7074 - val_loss: 0.8143 - val_accuracy: 0.7150\n",
            "Epoch 441/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7571 - accuracy: 0.7062 - val_loss: 0.7853 - val_accuracy: 0.7343\n",
            "Epoch 442/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7262 - accuracy: 0.7140 - val_loss: 0.7978 - val_accuracy: 0.7150\n",
            "Epoch 443/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7518 - accuracy: 0.6941 - val_loss: 0.7673 - val_accuracy: 0.7488\n",
            "Epoch 444/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7463 - accuracy: 0.7001 - val_loss: 0.8187 - val_accuracy: 0.7101\n",
            "Epoch 445/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7551 - accuracy: 0.6917 - val_loss: 0.7833 - val_accuracy: 0.7295\n",
            "Epoch 446/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7278 - accuracy: 0.7104 - val_loss: 0.7819 - val_accuracy: 0.7005\n",
            "Epoch 447/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7349 - accuracy: 0.7050 - val_loss: 0.7838 - val_accuracy: 0.7101\n",
            "Epoch 448/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7414 - accuracy: 0.7201 - val_loss: 0.7921 - val_accuracy: 0.7246\n",
            "Epoch 449/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7343 - accuracy: 0.7177 - val_loss: 0.7572 - val_accuracy: 0.7488\n",
            "Epoch 450/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7443 - accuracy: 0.7044 - val_loss: 0.7747 - val_accuracy: 0.7391\n",
            "Epoch 451/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7167 - accuracy: 0.7146 - val_loss: 0.7742 - val_accuracy: 0.7246\n",
            "Epoch 452/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7409 - accuracy: 0.7007 - val_loss: 0.7739 - val_accuracy: 0.7198\n",
            "Epoch 453/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7665 - accuracy: 0.6917 - val_loss: 0.7675 - val_accuracy: 0.7295\n",
            "Epoch 454/800\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6998 - accuracy: 0.7285 - val_loss: 0.7600 - val_accuracy: 0.7391\n",
            "Epoch 455/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7453 - accuracy: 0.6965 - val_loss: 0.7846 - val_accuracy: 0.7150\n",
            "Epoch 456/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7459 - accuracy: 0.7056 - val_loss: 0.7757 - val_accuracy: 0.7343\n",
            "Epoch 457/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7427 - accuracy: 0.7019 - val_loss: 0.7707 - val_accuracy: 0.7053\n",
            "Epoch 458/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7464 - accuracy: 0.7068 - val_loss: 0.7772 - val_accuracy: 0.7150\n",
            "Epoch 459/800\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.7387 - accuracy: 0.7104 - val_loss: 0.7817 - val_accuracy: 0.7150\n",
            "Epoch 460/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7212 - accuracy: 0.7110 - val_loss: 0.7651 - val_accuracy: 0.7053\n",
            "Epoch 461/800\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.7204 - accuracy: 0.7140 - val_loss: 0.7803 - val_accuracy: 0.7295\n",
            "Epoch 462/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7308 - accuracy: 0.7116 - val_loss: 0.7671 - val_accuracy: 0.7198\n",
            "Epoch 463/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7181 - accuracy: 0.7110 - val_loss: 0.7550 - val_accuracy: 0.7343\n",
            "Epoch 464/800\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.7273 - accuracy: 0.7056 - val_loss: 0.7629 - val_accuracy: 0.7343\n",
            "Epoch 465/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7119 - accuracy: 0.7104 - val_loss: 0.7628 - val_accuracy: 0.7053\n",
            "Epoch 466/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7292 - accuracy: 0.7140 - val_loss: 0.7673 - val_accuracy: 0.7053\n",
            "Epoch 467/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7492 - accuracy: 0.7068 - val_loss: 0.7681 - val_accuracy: 0.7198\n",
            "Epoch 468/800\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.7365 - accuracy: 0.7128 - val_loss: 0.7549 - val_accuracy: 0.7343\n",
            "Epoch 469/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7011 - accuracy: 0.7316 - val_loss: 0.7735 - val_accuracy: 0.7295\n",
            "Epoch 470/800\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.7266 - accuracy: 0.7146 - val_loss: 0.7538 - val_accuracy: 0.7391\n",
            "Epoch 471/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7064 - accuracy: 0.7122 - val_loss: 0.7507 - val_accuracy: 0.7440\n",
            "Epoch 472/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7152 - accuracy: 0.7225 - val_loss: 0.7467 - val_accuracy: 0.7488\n",
            "Epoch 473/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7246 - accuracy: 0.7037 - val_loss: 0.7730 - val_accuracy: 0.7246\n",
            "Epoch 474/800\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.7005 - accuracy: 0.7201 - val_loss: 0.7453 - val_accuracy: 0.7391\n",
            "Epoch 475/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7155 - accuracy: 0.7037 - val_loss: 0.7558 - val_accuracy: 0.7295\n",
            "Epoch 476/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6951 - accuracy: 0.7352 - val_loss: 0.7575 - val_accuracy: 0.7440\n",
            "Epoch 477/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7018 - accuracy: 0.7297 - val_loss: 0.7545 - val_accuracy: 0.7295\n",
            "Epoch 478/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6885 - accuracy: 0.7316 - val_loss: 0.7357 - val_accuracy: 0.7391\n",
            "Epoch 479/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7134 - accuracy: 0.7110 - val_loss: 0.7504 - val_accuracy: 0.7150\n",
            "Epoch 480/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7071 - accuracy: 0.7322 - val_loss: 0.7509 - val_accuracy: 0.7391\n",
            "Epoch 481/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7138 - accuracy: 0.7122 - val_loss: 0.7527 - val_accuracy: 0.7391\n",
            "Epoch 482/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6826 - accuracy: 0.7261 - val_loss: 0.7518 - val_accuracy: 0.7488\n",
            "Epoch 483/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7171 - accuracy: 0.7164 - val_loss: 0.7725 - val_accuracy: 0.7053\n",
            "Epoch 484/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6963 - accuracy: 0.7261 - val_loss: 0.7556 - val_accuracy: 0.7246\n",
            "Epoch 485/800\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6910 - accuracy: 0.7291 - val_loss: 0.7414 - val_accuracy: 0.7536\n",
            "Epoch 486/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7156 - accuracy: 0.7213 - val_loss: 0.7515 - val_accuracy: 0.7440\n",
            "Epoch 487/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6963 - accuracy: 0.7334 - val_loss: 0.7492 - val_accuracy: 0.7295\n",
            "Epoch 488/800\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.7204 - accuracy: 0.7122 - val_loss: 0.7612 - val_accuracy: 0.7488\n",
            "Epoch 489/800\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6914 - accuracy: 0.7261 - val_loss: 0.7463 - val_accuracy: 0.7391\n",
            "Epoch 490/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7107 - accuracy: 0.7225 - val_loss: 0.7522 - val_accuracy: 0.7585\n",
            "Epoch 491/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7173 - accuracy: 0.7116 - val_loss: 0.7645 - val_accuracy: 0.7150\n",
            "Epoch 492/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7028 - accuracy: 0.7207 - val_loss: 0.7681 - val_accuracy: 0.7101\n",
            "Epoch 493/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7025 - accuracy: 0.7152 - val_loss: 0.7769 - val_accuracy: 0.7391\n",
            "Epoch 494/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6933 - accuracy: 0.7370 - val_loss: 0.7656 - val_accuracy: 0.7246\n",
            "Epoch 495/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7159 - accuracy: 0.7183 - val_loss: 0.7524 - val_accuracy: 0.7585\n",
            "Epoch 496/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7219 - accuracy: 0.7086 - val_loss: 0.7603 - val_accuracy: 0.7295\n",
            "Epoch 497/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6620 - accuracy: 0.7437 - val_loss: 0.7338 - val_accuracy: 0.7585\n",
            "Epoch 498/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7483 - accuracy: 0.7134 - val_loss: 0.7452 - val_accuracy: 0.7633\n",
            "Epoch 499/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6986 - accuracy: 0.7219 - val_loss: 0.7656 - val_accuracy: 0.7343\n",
            "Epoch 500/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6823 - accuracy: 0.7207 - val_loss: 0.7344 - val_accuracy: 0.7440\n",
            "Epoch 501/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6697 - accuracy: 0.7279 - val_loss: 0.7257 - val_accuracy: 0.7633\n",
            "Epoch 502/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6975 - accuracy: 0.7273 - val_loss: 0.7256 - val_accuracy: 0.7536\n",
            "Epoch 503/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6964 - accuracy: 0.7328 - val_loss: 0.7434 - val_accuracy: 0.7488\n",
            "Epoch 504/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6774 - accuracy: 0.7310 - val_loss: 0.7331 - val_accuracy: 0.7488\n",
            "Epoch 505/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6874 - accuracy: 0.7273 - val_loss: 0.7331 - val_accuracy: 0.7488\n",
            "Epoch 506/800\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6860 - accuracy: 0.7261 - val_loss: 0.7382 - val_accuracy: 0.7343\n",
            "Epoch 507/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6964 - accuracy: 0.7334 - val_loss: 0.7433 - val_accuracy: 0.7343\n",
            "Epoch 508/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6900 - accuracy: 0.7237 - val_loss: 0.7377 - val_accuracy: 0.7440\n",
            "Epoch 509/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6904 - accuracy: 0.7195 - val_loss: 0.7470 - val_accuracy: 0.7391\n",
            "Epoch 510/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6699 - accuracy: 0.7310 - val_loss: 0.7403 - val_accuracy: 0.7488\n",
            "Epoch 511/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6742 - accuracy: 0.7237 - val_loss: 0.7517 - val_accuracy: 0.7343\n",
            "Epoch 512/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6678 - accuracy: 0.7352 - val_loss: 0.7492 - val_accuracy: 0.7246\n",
            "Epoch 513/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6623 - accuracy: 0.7491 - val_loss: 0.7514 - val_accuracy: 0.7391\n",
            "Epoch 514/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7040 - accuracy: 0.7183 - val_loss: 0.7445 - val_accuracy: 0.7391\n",
            "Epoch 515/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6744 - accuracy: 0.7467 - val_loss: 0.7454 - val_accuracy: 0.7585\n",
            "Epoch 516/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6972 - accuracy: 0.7334 - val_loss: 0.7518 - val_accuracy: 0.7440\n",
            "Epoch 517/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6615 - accuracy: 0.7437 - val_loss: 0.7305 - val_accuracy: 0.7585\n",
            "Epoch 518/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6911 - accuracy: 0.7170 - val_loss: 0.7592 - val_accuracy: 0.7391\n",
            "Epoch 519/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6781 - accuracy: 0.7340 - val_loss: 0.7324 - val_accuracy: 0.7536\n",
            "Epoch 520/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6676 - accuracy: 0.7406 - val_loss: 0.7548 - val_accuracy: 0.7343\n",
            "Epoch 521/800\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6690 - accuracy: 0.7352 - val_loss: 0.7426 - val_accuracy: 0.7488\n",
            "Epoch 522/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6788 - accuracy: 0.7255 - val_loss: 0.7344 - val_accuracy: 0.7343\n",
            "Epoch 523/800\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6545 - accuracy: 0.7539 - val_loss: 0.7383 - val_accuracy: 0.7101\n",
            "Epoch 524/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6632 - accuracy: 0.7358 - val_loss: 0.7247 - val_accuracy: 0.7295\n",
            "Epoch 525/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6654 - accuracy: 0.7388 - val_loss: 0.7304 - val_accuracy: 0.7198\n",
            "Epoch 526/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6738 - accuracy: 0.7279 - val_loss: 0.7194 - val_accuracy: 0.7681\n",
            "Epoch 527/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6657 - accuracy: 0.7316 - val_loss: 0.7356 - val_accuracy: 0.7246\n",
            "Epoch 528/800\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.7031 - accuracy: 0.7261 - val_loss: 0.7275 - val_accuracy: 0.7585\n",
            "Epoch 529/800\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6736 - accuracy: 0.7364 - val_loss: 0.7633 - val_accuracy: 0.7150\n",
            "Epoch 530/800\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6801 - accuracy: 0.7273 - val_loss: 0.7409 - val_accuracy: 0.7488\n",
            "Epoch 531/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6533 - accuracy: 0.7412 - val_loss: 0.7215 - val_accuracy: 0.7440\n",
            "Epoch 532/800\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6806 - accuracy: 0.7231 - val_loss: 0.7149 - val_accuracy: 0.7681\n",
            "Epoch 533/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6702 - accuracy: 0.7364 - val_loss: 0.7401 - val_accuracy: 0.7391\n",
            "Epoch 534/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6783 - accuracy: 0.7304 - val_loss: 0.7389 - val_accuracy: 0.7343\n",
            "Epoch 535/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6635 - accuracy: 0.7412 - val_loss: 0.7377 - val_accuracy: 0.7440\n",
            "Epoch 536/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6654 - accuracy: 0.7418 - val_loss: 0.7329 - val_accuracy: 0.7536\n",
            "Epoch 537/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6770 - accuracy: 0.7249 - val_loss: 0.7407 - val_accuracy: 0.7440\n",
            "Epoch 538/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6770 - accuracy: 0.7340 - val_loss: 0.7363 - val_accuracy: 0.7488\n",
            "Epoch 539/800\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6613 - accuracy: 0.7443 - val_loss: 0.7260 - val_accuracy: 0.7440\n",
            "Epoch 540/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6683 - accuracy: 0.7406 - val_loss: 0.7202 - val_accuracy: 0.7681\n",
            "Epoch 541/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6539 - accuracy: 0.7461 - val_loss: 0.7462 - val_accuracy: 0.7343\n",
            "Epoch 542/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6666 - accuracy: 0.7273 - val_loss: 0.7156 - val_accuracy: 0.7681\n",
            "Epoch 543/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6827 - accuracy: 0.7279 - val_loss: 0.7228 - val_accuracy: 0.7585\n",
            "Epoch 544/800\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6621 - accuracy: 0.7461 - val_loss: 0.7196 - val_accuracy: 0.7585\n",
            "Epoch 545/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6853 - accuracy: 0.7183 - val_loss: 0.7306 - val_accuracy: 0.7295\n",
            "Epoch 546/800\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6587 - accuracy: 0.7521 - val_loss: 0.7460 - val_accuracy: 0.7536\n",
            "Epoch 547/800\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6389 - accuracy: 0.7467 - val_loss: 0.7298 - val_accuracy: 0.7488\n",
            "Epoch 548/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6432 - accuracy: 0.7527 - val_loss: 0.7253 - val_accuracy: 0.7440\n",
            "Epoch 549/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6629 - accuracy: 0.7509 - val_loss: 0.7164 - val_accuracy: 0.7536\n",
            "Epoch 550/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6428 - accuracy: 0.7467 - val_loss: 0.7405 - val_accuracy: 0.7536\n",
            "Epoch 551/800\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6437 - accuracy: 0.7370 - val_loss: 0.7122 - val_accuracy: 0.7633\n",
            "Epoch 552/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6741 - accuracy: 0.7340 - val_loss: 0.7277 - val_accuracy: 0.7488\n",
            "Epoch 553/800\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6625 - accuracy: 0.7388 - val_loss: 0.7567 - val_accuracy: 0.7150\n",
            "Epoch 554/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6452 - accuracy: 0.7503 - val_loss: 0.7206 - val_accuracy: 0.7536\n",
            "Epoch 555/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6453 - accuracy: 0.7473 - val_loss: 0.7211 - val_accuracy: 0.7391\n",
            "Epoch 556/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6310 - accuracy: 0.7497 - val_loss: 0.7370 - val_accuracy: 0.7343\n",
            "Epoch 557/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6638 - accuracy: 0.7545 - val_loss: 0.7261 - val_accuracy: 0.7391\n",
            "Epoch 558/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6451 - accuracy: 0.7479 - val_loss: 0.7113 - val_accuracy: 0.7585\n",
            "Epoch 559/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6534 - accuracy: 0.7527 - val_loss: 0.7448 - val_accuracy: 0.7585\n",
            "Epoch 560/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6429 - accuracy: 0.7588 - val_loss: 0.7439 - val_accuracy: 0.7343\n",
            "Epoch 561/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6555 - accuracy: 0.7328 - val_loss: 0.7126 - val_accuracy: 0.7778\n",
            "Epoch 562/800\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6457 - accuracy: 0.7352 - val_loss: 0.7183 - val_accuracy: 0.7536\n",
            "Epoch 563/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6417 - accuracy: 0.7449 - val_loss: 0.7205 - val_accuracy: 0.7633\n",
            "Epoch 564/800\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6306 - accuracy: 0.7672 - val_loss: 0.7295 - val_accuracy: 0.7488\n",
            "Epoch 565/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6217 - accuracy: 0.7545 - val_loss: 0.7230 - val_accuracy: 0.7488\n",
            "Epoch 566/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6351 - accuracy: 0.7376 - val_loss: 0.7152 - val_accuracy: 0.7536\n",
            "Epoch 567/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6440 - accuracy: 0.7582 - val_loss: 0.7244 - val_accuracy: 0.7488\n",
            "Epoch 568/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6386 - accuracy: 0.7527 - val_loss: 0.7185 - val_accuracy: 0.7488\n",
            "Epoch 569/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6443 - accuracy: 0.7539 - val_loss: 0.7414 - val_accuracy: 0.7440\n",
            "Epoch 570/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6497 - accuracy: 0.7467 - val_loss: 0.7063 - val_accuracy: 0.7536\n",
            "Epoch 571/800\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6309 - accuracy: 0.7509 - val_loss: 0.7057 - val_accuracy: 0.7778\n",
            "Epoch 572/800\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6377 - accuracy: 0.7545 - val_loss: 0.7207 - val_accuracy: 0.7440\n",
            "Epoch 573/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6214 - accuracy: 0.7551 - val_loss: 0.6974 - val_accuracy: 0.7729\n",
            "Epoch 574/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6467 - accuracy: 0.7340 - val_loss: 0.7202 - val_accuracy: 0.7536\n",
            "Epoch 575/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6346 - accuracy: 0.7557 - val_loss: 0.7147 - val_accuracy: 0.7585\n",
            "Epoch 576/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6276 - accuracy: 0.7557 - val_loss: 0.7312 - val_accuracy: 0.7440\n",
            "Epoch 577/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6217 - accuracy: 0.7521 - val_loss: 0.7092 - val_accuracy: 0.7536\n",
            "Epoch 578/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6133 - accuracy: 0.7672 - val_loss: 0.6995 - val_accuracy: 0.7585\n",
            "Epoch 579/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6282 - accuracy: 0.7497 - val_loss: 0.6965 - val_accuracy: 0.7729\n",
            "Epoch 580/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6109 - accuracy: 0.7557 - val_loss: 0.7169 - val_accuracy: 0.7585\n",
            "Epoch 581/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6389 - accuracy: 0.7503 - val_loss: 0.7030 - val_accuracy: 0.7826\n",
            "Epoch 582/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6108 - accuracy: 0.7630 - val_loss: 0.7225 - val_accuracy: 0.7295\n",
            "Epoch 583/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6053 - accuracy: 0.7654 - val_loss: 0.7237 - val_accuracy: 0.7440\n",
            "Epoch 584/800\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6324 - accuracy: 0.7557 - val_loss: 0.7079 - val_accuracy: 0.7440\n",
            "Epoch 585/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6292 - accuracy: 0.7545 - val_loss: 0.7018 - val_accuracy: 0.7440\n",
            "Epoch 586/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6270 - accuracy: 0.7527 - val_loss: 0.7112 - val_accuracy: 0.7440\n",
            "Epoch 587/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6226 - accuracy: 0.7449 - val_loss: 0.6952 - val_accuracy: 0.7585\n",
            "Epoch 588/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6168 - accuracy: 0.7594 - val_loss: 0.7088 - val_accuracy: 0.7488\n",
            "Epoch 589/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6304 - accuracy: 0.7582 - val_loss: 0.7070 - val_accuracy: 0.7585\n",
            "Epoch 590/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5966 - accuracy: 0.7660 - val_loss: 0.7087 - val_accuracy: 0.7633\n",
            "Epoch 591/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6241 - accuracy: 0.7515 - val_loss: 0.7019 - val_accuracy: 0.7536\n",
            "Epoch 592/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6084 - accuracy: 0.7648 - val_loss: 0.7240 - val_accuracy: 0.7391\n",
            "Epoch 593/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6096 - accuracy: 0.7648 - val_loss: 0.7187 - val_accuracy: 0.7391\n",
            "Epoch 594/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6024 - accuracy: 0.7703 - val_loss: 0.6929 - val_accuracy: 0.7633\n",
            "Epoch 595/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6148 - accuracy: 0.7594 - val_loss: 0.7168 - val_accuracy: 0.7440\n",
            "Epoch 596/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6146 - accuracy: 0.7551 - val_loss: 0.7251 - val_accuracy: 0.7488\n",
            "Epoch 597/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6172 - accuracy: 0.7690 - val_loss: 0.6955 - val_accuracy: 0.7778\n",
            "Epoch 598/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6279 - accuracy: 0.7606 - val_loss: 0.7231 - val_accuracy: 0.7343\n",
            "Epoch 599/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6237 - accuracy: 0.7600 - val_loss: 0.6980 - val_accuracy: 0.7440\n",
            "Epoch 600/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6292 - accuracy: 0.7594 - val_loss: 0.6889 - val_accuracy: 0.7585\n",
            "Epoch 601/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6188 - accuracy: 0.7545 - val_loss: 0.7155 - val_accuracy: 0.7246\n",
            "Epoch 602/800\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6353 - accuracy: 0.7527 - val_loss: 0.7117 - val_accuracy: 0.7633\n",
            "Epoch 603/800\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6019 - accuracy: 0.7606 - val_loss: 0.7086 - val_accuracy: 0.7343\n",
            "Epoch 604/800\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5922 - accuracy: 0.7696 - val_loss: 0.6956 - val_accuracy: 0.7391\n",
            "Epoch 605/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6197 - accuracy: 0.7576 - val_loss: 0.6877 - val_accuracy: 0.7585\n",
            "Epoch 606/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5882 - accuracy: 0.7642 - val_loss: 0.7071 - val_accuracy: 0.7536\n",
            "Epoch 607/800\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6079 - accuracy: 0.7618 - val_loss: 0.6968 - val_accuracy: 0.7536\n",
            "Epoch 608/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6152 - accuracy: 0.7696 - val_loss: 0.6853 - val_accuracy: 0.7681\n",
            "Epoch 609/800\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6067 - accuracy: 0.7654 - val_loss: 0.6976 - val_accuracy: 0.7488\n",
            "Epoch 610/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5995 - accuracy: 0.7684 - val_loss: 0.7077 - val_accuracy: 0.7488\n",
            "Epoch 611/800\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6072 - accuracy: 0.7660 - val_loss: 0.6852 - val_accuracy: 0.7923\n",
            "Epoch 612/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5821 - accuracy: 0.7684 - val_loss: 0.6871 - val_accuracy: 0.7729\n",
            "Epoch 613/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6223 - accuracy: 0.7521 - val_loss: 0.7025 - val_accuracy: 0.7681\n",
            "Epoch 614/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6032 - accuracy: 0.7684 - val_loss: 0.6798 - val_accuracy: 0.7681\n",
            "Epoch 615/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6111 - accuracy: 0.7630 - val_loss: 0.6971 - val_accuracy: 0.7729\n",
            "Epoch 616/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6234 - accuracy: 0.7521 - val_loss: 0.6916 - val_accuracy: 0.7826\n",
            "Epoch 617/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6288 - accuracy: 0.7455 - val_loss: 0.6990 - val_accuracy: 0.7585\n",
            "Epoch 618/800\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5903 - accuracy: 0.7690 - val_loss: 0.6956 - val_accuracy: 0.7729\n",
            "Epoch 619/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6109 - accuracy: 0.7624 - val_loss: 0.6870 - val_accuracy: 0.7585\n",
            "Epoch 620/800\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5931 - accuracy: 0.7727 - val_loss: 0.6861 - val_accuracy: 0.7681\n",
            "Epoch 621/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5998 - accuracy: 0.7696 - val_loss: 0.7102 - val_accuracy: 0.7343\n",
            "Epoch 622/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6114 - accuracy: 0.7715 - val_loss: 0.6894 - val_accuracy: 0.7488\n",
            "Epoch 623/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5961 - accuracy: 0.7648 - val_loss: 0.7034 - val_accuracy: 0.7488\n",
            "Epoch 624/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5813 - accuracy: 0.7715 - val_loss: 0.7092 - val_accuracy: 0.7585\n",
            "Epoch 625/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5994 - accuracy: 0.7690 - val_loss: 0.6922 - val_accuracy: 0.7826\n",
            "Epoch 626/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5932 - accuracy: 0.7696 - val_loss: 0.7115 - val_accuracy: 0.7633\n",
            "Epoch 627/800\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5852 - accuracy: 0.7733 - val_loss: 0.6936 - val_accuracy: 0.7778\n",
            "Epoch 628/800\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5875 - accuracy: 0.7799 - val_loss: 0.6949 - val_accuracy: 0.7681\n",
            "Epoch 629/800\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6111 - accuracy: 0.7479 - val_loss: 0.7077 - val_accuracy: 0.7633\n",
            "Epoch 630/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5872 - accuracy: 0.7823 - val_loss: 0.6995 - val_accuracy: 0.7488\n",
            "Epoch 631/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5937 - accuracy: 0.7612 - val_loss: 0.6868 - val_accuracy: 0.7585\n",
            "Epoch 632/800\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5680 - accuracy: 0.7793 - val_loss: 0.6917 - val_accuracy: 0.7585\n",
            "Epoch 633/800\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5850 - accuracy: 0.7727 - val_loss: 0.6785 - val_accuracy: 0.7585\n",
            "Epoch 634/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5771 - accuracy: 0.7703 - val_loss: 0.6938 - val_accuracy: 0.7440\n",
            "Epoch 635/800\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6082 - accuracy: 0.7666 - val_loss: 0.7096 - val_accuracy: 0.7488\n",
            "Epoch 636/800\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5949 - accuracy: 0.7751 - val_loss: 0.6754 - val_accuracy: 0.7681\n",
            "Epoch 637/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5895 - accuracy: 0.7606 - val_loss: 0.7020 - val_accuracy: 0.7585\n",
            "Epoch 638/800\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5613 - accuracy: 0.7884 - val_loss: 0.6773 - val_accuracy: 0.7536\n",
            "Epoch 639/800\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6015 - accuracy: 0.7733 - val_loss: 0.7025 - val_accuracy: 0.7536\n",
            "Epoch 640/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5682 - accuracy: 0.7733 - val_loss: 0.6690 - val_accuracy: 0.7633\n",
            "Epoch 641/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5849 - accuracy: 0.7690 - val_loss: 0.7177 - val_accuracy: 0.7488\n",
            "Epoch 642/800\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6060 - accuracy: 0.7509 - val_loss: 0.7090 - val_accuracy: 0.7391\n",
            "Epoch 643/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5718 - accuracy: 0.7781 - val_loss: 0.7063 - val_accuracy: 0.7440\n",
            "Epoch 644/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6007 - accuracy: 0.7557 - val_loss: 0.7023 - val_accuracy: 0.7391\n",
            "Epoch 645/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5731 - accuracy: 0.7811 - val_loss: 0.6776 - val_accuracy: 0.7536\n",
            "Epoch 646/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5666 - accuracy: 0.7842 - val_loss: 0.7025 - val_accuracy: 0.7440\n",
            "Epoch 647/800\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5645 - accuracy: 0.7793 - val_loss: 0.7078 - val_accuracy: 0.7488\n",
            "Epoch 648/800\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5647 - accuracy: 0.7654 - val_loss: 0.7033 - val_accuracy: 0.7343\n",
            "Epoch 649/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5821 - accuracy: 0.7775 - val_loss: 0.7003 - val_accuracy: 0.7488\n",
            "Epoch 650/800\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5784 - accuracy: 0.7793 - val_loss: 0.6943 - val_accuracy: 0.7536\n",
            "Epoch 651/800\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5919 - accuracy: 0.7727 - val_loss: 0.6874 - val_accuracy: 0.7391\n",
            "Epoch 652/800\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5840 - accuracy: 0.7660 - val_loss: 0.7021 - val_accuracy: 0.7633\n",
            "Epoch 653/800\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5795 - accuracy: 0.7842 - val_loss: 0.7004 - val_accuracy: 0.7585\n",
            "Epoch 654/800\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5676 - accuracy: 0.7860 - val_loss: 0.6906 - val_accuracy: 0.7585\n",
            "Epoch 655/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5905 - accuracy: 0.7515 - val_loss: 0.6790 - val_accuracy: 0.7681\n",
            "Epoch 656/800\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5599 - accuracy: 0.7890 - val_loss: 0.6819 - val_accuracy: 0.7585\n",
            "Epoch 657/800\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5815 - accuracy: 0.7769 - val_loss: 0.6793 - val_accuracy: 0.7633\n",
            "Epoch 658/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5651 - accuracy: 0.7817 - val_loss: 0.6865 - val_accuracy: 0.7585\n",
            "Epoch 659/800\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5655 - accuracy: 0.7787 - val_loss: 0.6903 - val_accuracy: 0.7440\n",
            "Epoch 660/800\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5724 - accuracy: 0.7733 - val_loss: 0.6685 - val_accuracy: 0.7874\n",
            "Epoch 661/800\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5981 - accuracy: 0.7557 - val_loss: 0.6848 - val_accuracy: 0.7729\n",
            "Epoch 662/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5667 - accuracy: 0.7787 - val_loss: 0.6943 - val_accuracy: 0.7729\n",
            "Epoch 663/800\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5708 - accuracy: 0.7678 - val_loss: 0.6862 - val_accuracy: 0.7681\n",
            "Epoch 664/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5759 - accuracy: 0.7769 - val_loss: 0.7015 - val_accuracy: 0.7633\n",
            "Epoch 665/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5857 - accuracy: 0.7775 - val_loss: 0.6761 - val_accuracy: 0.7681\n",
            "Epoch 666/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5453 - accuracy: 0.8023 - val_loss: 0.6844 - val_accuracy: 0.7585\n",
            "Epoch 667/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5622 - accuracy: 0.7739 - val_loss: 0.6846 - val_accuracy: 0.7440\n",
            "Epoch 668/800\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5763 - accuracy: 0.7709 - val_loss: 0.6732 - val_accuracy: 0.7585\n",
            "Epoch 669/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5817 - accuracy: 0.7757 - val_loss: 0.6697 - val_accuracy: 0.7633\n",
            "Epoch 670/800\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5538 - accuracy: 0.7817 - val_loss: 0.6752 - val_accuracy: 0.7585\n",
            "Epoch 671/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5809 - accuracy: 0.7793 - val_loss: 0.6901 - val_accuracy: 0.7729\n",
            "Epoch 672/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5533 - accuracy: 0.7890 - val_loss: 0.6818 - val_accuracy: 0.7681\n",
            "Epoch 673/800\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5641 - accuracy: 0.7745 - val_loss: 0.6932 - val_accuracy: 0.7536\n",
            "Epoch 674/800\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5680 - accuracy: 0.7696 - val_loss: 0.6697 - val_accuracy: 0.7585\n",
            "Epoch 675/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5531 - accuracy: 0.7836 - val_loss: 0.6673 - val_accuracy: 0.7488\n",
            "Epoch 676/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5476 - accuracy: 0.7854 - val_loss: 0.6943 - val_accuracy: 0.7585\n",
            "Epoch 677/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5583 - accuracy: 0.7751 - val_loss: 0.6655 - val_accuracy: 0.7826\n",
            "Epoch 678/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5597 - accuracy: 0.7733 - val_loss: 0.6739 - val_accuracy: 0.7633\n",
            "Epoch 679/800\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5596 - accuracy: 0.7799 - val_loss: 0.6698 - val_accuracy: 0.7778\n",
            "Epoch 680/800\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.5600 - accuracy: 0.7793 - val_loss: 0.6420 - val_accuracy: 0.7923\n",
            "Epoch 681/800\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.5555 - accuracy: 0.7854 - val_loss: 0.6500 - val_accuracy: 0.7874\n",
            "Epoch 682/800\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.5861 - accuracy: 0.7642 - val_loss: 0.6767 - val_accuracy: 0.7874\n",
            "Epoch 683/800\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.5746 - accuracy: 0.7823 - val_loss: 0.6814 - val_accuracy: 0.7585\n",
            "Epoch 684/800\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5552 - accuracy: 0.7854 - val_loss: 0.6919 - val_accuracy: 0.7633\n",
            "Epoch 685/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5532 - accuracy: 0.7836 - val_loss: 0.6822 - val_accuracy: 0.7585\n",
            "Epoch 686/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5537 - accuracy: 0.7854 - val_loss: 0.6909 - val_accuracy: 0.7440\n",
            "Epoch 687/800\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5459 - accuracy: 0.7926 - val_loss: 0.6476 - val_accuracy: 0.7681\n",
            "Epoch 688/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5687 - accuracy: 0.7823 - val_loss: 0.6599 - val_accuracy: 0.7729\n",
            "Epoch 689/800\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5529 - accuracy: 0.7817 - val_loss: 0.6570 - val_accuracy: 0.7633\n",
            "Epoch 690/800\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5401 - accuracy: 0.7836 - val_loss: 0.6664 - val_accuracy: 0.7585\n",
            "Epoch 691/800\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5694 - accuracy: 0.7805 - val_loss: 0.6822 - val_accuracy: 0.7536\n",
            "Epoch 692/800\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5382 - accuracy: 0.7920 - val_loss: 0.6687 - val_accuracy: 0.7681\n",
            "Epoch 693/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5549 - accuracy: 0.7866 - val_loss: 0.7005 - val_accuracy: 0.7488\n",
            "Epoch 694/800\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5667 - accuracy: 0.7866 - val_loss: 0.6857 - val_accuracy: 0.7440\n",
            "Epoch 695/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5671 - accuracy: 0.7854 - val_loss: 0.6683 - val_accuracy: 0.7923\n",
            "Epoch 696/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5379 - accuracy: 0.7823 - val_loss: 0.6678 - val_accuracy: 0.7729\n",
            "Epoch 697/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5480 - accuracy: 0.7920 - val_loss: 0.6718 - val_accuracy: 0.7729\n",
            "Epoch 698/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5372 - accuracy: 0.7981 - val_loss: 0.6609 - val_accuracy: 0.7778\n",
            "Epoch 699/800\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5026 - accuracy: 0.8071 - val_loss: 0.6518 - val_accuracy: 0.7826\n",
            "Epoch 700/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5598 - accuracy: 0.7884 - val_loss: 0.6575 - val_accuracy: 0.7826\n",
            "Epoch 701/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5251 - accuracy: 0.8017 - val_loss: 0.6769 - val_accuracy: 0.7440\n",
            "Epoch 702/800\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5632 - accuracy: 0.7763 - val_loss: 0.6785 - val_accuracy: 0.7585\n",
            "Epoch 703/800\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5445 - accuracy: 0.7944 - val_loss: 0.6722 - val_accuracy: 0.7536\n",
            "Epoch 704/800\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5398 - accuracy: 0.7932 - val_loss: 0.6690 - val_accuracy: 0.7585\n",
            "Epoch 705/800\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5451 - accuracy: 0.7872 - val_loss: 0.6635 - val_accuracy: 0.7729\n",
            "Epoch 706/800\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5522 - accuracy: 0.7817 - val_loss: 0.6697 - val_accuracy: 0.7729\n",
            "Epoch 707/800\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5406 - accuracy: 0.7848 - val_loss: 0.6575 - val_accuracy: 0.7681\n",
            "Epoch 708/800\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5608 - accuracy: 0.7733 - val_loss: 0.6778 - val_accuracy: 0.7585\n",
            "Epoch 709/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5633 - accuracy: 0.7763 - val_loss: 0.6611 - val_accuracy: 0.7778\n",
            "Epoch 710/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5320 - accuracy: 0.7860 - val_loss: 0.7004 - val_accuracy: 0.7585\n",
            "Epoch 711/800\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5224 - accuracy: 0.8035 - val_loss: 0.6612 - val_accuracy: 0.7778\n",
            "Epoch 712/800\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5223 - accuracy: 0.7950 - val_loss: 0.6818 - val_accuracy: 0.7633\n",
            "Epoch 713/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5383 - accuracy: 0.7836 - val_loss: 0.6996 - val_accuracy: 0.7440\n",
            "Epoch 714/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5214 - accuracy: 0.8029 - val_loss: 0.6666 - val_accuracy: 0.7681\n",
            "Epoch 715/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5575 - accuracy: 0.7884 - val_loss: 0.6810 - val_accuracy: 0.7633\n",
            "Epoch 716/800\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5637 - accuracy: 0.7787 - val_loss: 0.6877 - val_accuracy: 0.7729\n",
            "Epoch 717/800\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5333 - accuracy: 0.8011 - val_loss: 0.7133 - val_accuracy: 0.7343\n",
            "Epoch 718/800\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5617 - accuracy: 0.7805 - val_loss: 0.6538 - val_accuracy: 0.8068\n",
            "Epoch 719/800\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5515 - accuracy: 0.7848 - val_loss: 0.6682 - val_accuracy: 0.7778\n",
            "Epoch 720/800\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5294 - accuracy: 0.7956 - val_loss: 0.6803 - val_accuracy: 0.7681\n",
            "Epoch 721/800\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5291 - accuracy: 0.7920 - val_loss: 0.6644 - val_accuracy: 0.7729\n",
            "Epoch 722/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5317 - accuracy: 0.7938 - val_loss: 0.6537 - val_accuracy: 0.7778\n",
            "Epoch 723/800\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5237 - accuracy: 0.7932 - val_loss: 0.6405 - val_accuracy: 0.7826\n",
            "Epoch 724/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5337 - accuracy: 0.7963 - val_loss: 0.6624 - val_accuracy: 0.7826\n",
            "Epoch 725/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5236 - accuracy: 0.8041 - val_loss: 0.6472 - val_accuracy: 0.7729\n",
            "Epoch 726/800\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5361 - accuracy: 0.7938 - val_loss: 0.6425 - val_accuracy: 0.7874\n",
            "Epoch 727/800\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5264 - accuracy: 0.8017 - val_loss: 0.6560 - val_accuracy: 0.7778\n",
            "Epoch 728/800\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5174 - accuracy: 0.8011 - val_loss: 0.6452 - val_accuracy: 0.7778\n",
            "Epoch 729/800\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5230 - accuracy: 0.7926 - val_loss: 0.6648 - val_accuracy: 0.7633\n",
            "Epoch 730/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5366 - accuracy: 0.7926 - val_loss: 0.6423 - val_accuracy: 0.7971\n",
            "Epoch 731/800\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5232 - accuracy: 0.7926 - val_loss: 0.6576 - val_accuracy: 0.7681\n",
            "Epoch 732/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5263 - accuracy: 0.8035 - val_loss: 0.6654 - val_accuracy: 0.7778\n",
            "Epoch 733/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5044 - accuracy: 0.7987 - val_loss: 0.6482 - val_accuracy: 0.7729\n",
            "Epoch 734/800\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5238 - accuracy: 0.7987 - val_loss: 0.6704 - val_accuracy: 0.7826\n",
            "Epoch 735/800\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.4994 - accuracy: 0.8047 - val_loss: 0.6757 - val_accuracy: 0.7681\n",
            "Epoch 736/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5038 - accuracy: 0.8005 - val_loss: 0.6468 - val_accuracy: 0.7778\n",
            "Epoch 737/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5183 - accuracy: 0.7944 - val_loss: 0.6682 - val_accuracy: 0.7729\n",
            "Epoch 738/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5126 - accuracy: 0.8017 - val_loss: 0.6696 - val_accuracy: 0.7729\n",
            "Epoch 739/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5369 - accuracy: 0.7805 - val_loss: 0.6452 - val_accuracy: 0.7874\n",
            "Epoch 740/800\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5364 - accuracy: 0.7914 - val_loss: 0.6483 - val_accuracy: 0.7874\n",
            "Epoch 741/800\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5106 - accuracy: 0.7830 - val_loss: 0.6401 - val_accuracy: 0.8068\n",
            "Epoch 742/800\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5123 - accuracy: 0.8005 - val_loss: 0.6681 - val_accuracy: 0.7585\n",
            "Epoch 743/800\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5224 - accuracy: 0.7981 - val_loss: 0.6531 - val_accuracy: 0.7488\n",
            "Epoch 744/800\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5042 - accuracy: 0.8096 - val_loss: 0.6505 - val_accuracy: 0.7923\n",
            "Epoch 745/800\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5104 - accuracy: 0.8017 - val_loss: 0.6538 - val_accuracy: 0.7729\n",
            "Epoch 746/800\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5153 - accuracy: 0.7981 - val_loss: 0.6432 - val_accuracy: 0.7971\n",
            "Epoch 747/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5256 - accuracy: 0.8041 - val_loss: 0.6502 - val_accuracy: 0.7778\n",
            "Epoch 748/800\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5074 - accuracy: 0.8023 - val_loss: 0.6461 - val_accuracy: 0.7874\n",
            "Epoch 749/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5118 - accuracy: 0.7896 - val_loss: 0.6580 - val_accuracy: 0.7826\n",
            "Epoch 750/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5056 - accuracy: 0.8138 - val_loss: 0.6331 - val_accuracy: 0.7826\n",
            "Epoch 751/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5128 - accuracy: 0.8023 - val_loss: 0.6512 - val_accuracy: 0.7923\n",
            "Epoch 752/800\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5318 - accuracy: 0.7848 - val_loss: 0.6688 - val_accuracy: 0.7874\n",
            "Epoch 753/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5278 - accuracy: 0.7848 - val_loss: 0.6529 - val_accuracy: 0.7826\n",
            "Epoch 754/800\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5086 - accuracy: 0.7963 - val_loss: 0.6685 - val_accuracy: 0.7536\n",
            "Epoch 755/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5037 - accuracy: 0.7993 - val_loss: 0.6862 - val_accuracy: 0.7633\n",
            "Epoch 756/800\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5116 - accuracy: 0.8017 - val_loss: 0.6586 - val_accuracy: 0.7729\n",
            "Epoch 757/800\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5187 - accuracy: 0.7908 - val_loss: 0.6847 - val_accuracy: 0.7488\n",
            "Epoch 758/800\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.4953 - accuracy: 0.8150 - val_loss: 0.6547 - val_accuracy: 0.7729\n",
            "Epoch 759/800\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.4938 - accuracy: 0.8102 - val_loss: 0.6415 - val_accuracy: 0.7826\n",
            "Epoch 760/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4875 - accuracy: 0.8089 - val_loss: 0.6428 - val_accuracy: 0.8068\n",
            "Epoch 761/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4931 - accuracy: 0.8108 - val_loss: 0.6347 - val_accuracy: 0.7778\n",
            "Epoch 762/800\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.4963 - accuracy: 0.8035 - val_loss: 0.6368 - val_accuracy: 0.7874\n",
            "Epoch 763/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5135 - accuracy: 0.7938 - val_loss: 0.6338 - val_accuracy: 0.7826\n",
            "Epoch 764/800\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5087 - accuracy: 0.8017 - val_loss: 0.6447 - val_accuracy: 0.7681\n",
            "Epoch 765/800\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.4868 - accuracy: 0.8126 - val_loss: 0.6566 - val_accuracy: 0.7585\n",
            "Epoch 766/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4819 - accuracy: 0.8077 - val_loss: 0.6426 - val_accuracy: 0.7874\n",
            "Epoch 767/800\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.4972 - accuracy: 0.8083 - val_loss: 0.6573 - val_accuracy: 0.7585\n",
            "Epoch 768/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4972 - accuracy: 0.8126 - val_loss: 0.6410 - val_accuracy: 0.7923\n",
            "Epoch 769/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4693 - accuracy: 0.8138 - val_loss: 0.6482 - val_accuracy: 0.7971\n",
            "Epoch 770/800\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.4923 - accuracy: 0.8174 - val_loss: 0.6323 - val_accuracy: 0.8068\n",
            "Epoch 771/800\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5030 - accuracy: 0.8144 - val_loss: 0.6465 - val_accuracy: 0.7681\n",
            "Epoch 772/800\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.4890 - accuracy: 0.8210 - val_loss: 0.6484 - val_accuracy: 0.7971\n",
            "Epoch 773/800\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5120 - accuracy: 0.7999 - val_loss: 0.6428 - val_accuracy: 0.7826\n",
            "Epoch 774/800\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.4934 - accuracy: 0.8126 - val_loss: 0.6578 - val_accuracy: 0.7778\n",
            "Epoch 775/800\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5047 - accuracy: 0.8005 - val_loss: 0.6372 - val_accuracy: 0.8068\n",
            "Epoch 776/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5052 - accuracy: 0.8041 - val_loss: 0.6382 - val_accuracy: 0.7874\n",
            "Epoch 777/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5039 - accuracy: 0.8047 - val_loss: 0.6514 - val_accuracy: 0.7874\n",
            "Epoch 778/800\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5077 - accuracy: 0.8023 - val_loss: 0.6615 - val_accuracy: 0.7826\n",
            "Epoch 779/800\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.4758 - accuracy: 0.8138 - val_loss: 0.6409 - val_accuracy: 0.7971\n",
            "Epoch 780/800\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.4900 - accuracy: 0.8241 - val_loss: 0.6429 - val_accuracy: 0.7729\n",
            "Epoch 781/800\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.4890 - accuracy: 0.8083 - val_loss: 0.6830 - val_accuracy: 0.7633\n",
            "Epoch 782/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4765 - accuracy: 0.8210 - val_loss: 0.6589 - val_accuracy: 0.7488\n",
            "Epoch 783/800\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.4959 - accuracy: 0.8138 - val_loss: 0.6815 - val_accuracy: 0.7633\n",
            "Epoch 784/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4813 - accuracy: 0.8186 - val_loss: 0.6574 - val_accuracy: 0.7874\n",
            "Epoch 785/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4763 - accuracy: 0.8138 - val_loss: 0.6535 - val_accuracy: 0.7826\n",
            "Epoch 786/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5152 - accuracy: 0.7969 - val_loss: 0.6460 - val_accuracy: 0.7778\n",
            "Epoch 787/800\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.4923 - accuracy: 0.8108 - val_loss: 0.6532 - val_accuracy: 0.7681\n",
            "Epoch 788/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4944 - accuracy: 0.8180 - val_loss: 0.6262 - val_accuracy: 0.8068\n",
            "Epoch 789/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4865 - accuracy: 0.8023 - val_loss: 0.6539 - val_accuracy: 0.7729\n",
            "Epoch 790/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4511 - accuracy: 0.8319 - val_loss: 0.6418 - val_accuracy: 0.8019\n",
            "Epoch 791/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5012 - accuracy: 0.7969 - val_loss: 0.6355 - val_accuracy: 0.7923\n",
            "Epoch 792/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5030 - accuracy: 0.8114 - val_loss: 0.6403 - val_accuracy: 0.7874\n",
            "Epoch 793/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4788 - accuracy: 0.8156 - val_loss: 0.6613 - val_accuracy: 0.7729\n",
            "Epoch 794/800\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.4647 - accuracy: 0.8192 - val_loss: 0.6591 - val_accuracy: 0.7633\n",
            "Epoch 795/800\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.4846 - accuracy: 0.8083 - val_loss: 0.6456 - val_accuracy: 0.7923\n",
            "Epoch 796/800\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5115 - accuracy: 0.8005 - val_loss: 0.6468 - val_accuracy: 0.7874\n",
            "Epoch 797/800\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.4809 - accuracy: 0.8114 - val_loss: 0.6260 - val_accuracy: 0.7971\n",
            "Epoch 798/800\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4861 - accuracy: 0.8174 - val_loss: 0.6451 - val_accuracy: 0.7633\n",
            "Epoch 799/800\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5119 - accuracy: 0.8011 - val_loss: 0.6315 - val_accuracy: 0.7826\n",
            "Epoch 800/800\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.4835 - accuracy: 0.8235 - val_loss: 0.6576 - val_accuracy: 0.7874\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(cnnhistory.history['loss'])\n",
        "plt.plot(cnnhistory.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train','test'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "oQYnuaCrDH_A",
        "outputId": "b1b0e1ef-74d6-4dcd-c5ee-c9cb2807ece2"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(cnnhistory.history['accuracy'])\n",
        "plt.plot(cnnhistory.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train','test'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "IFkTuO8nDNdq",
        "outputId": "fec55fc0-87a3-4a51-cfbd-7f221b60339e"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model.predict(x_testcnn)"
      ],
      "metadata": {
        "id": "A2xtrN5wDQgY"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_f_ohjXKDUpY",
        "outputId": "8d60c558-8ceb-48b8-d840-471dd016d0f9"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[3.21671367e-01, 4.61586192e-02, 2.16636345e-01, 2.26798147e-01,\n",
              "        1.44024879e-01, 4.47106324e-02],\n",
              "       [9.22504478e-05, 1.64802270e-06, 1.03054866e-07, 9.95670915e-01,\n",
              "        1.98508883e-06, 4.23306227e-03],\n",
              "       [1.79607198e-01, 6.25934154e-02, 6.97917938e-02, 3.88143808e-01,\n",
              "        4.73409668e-02, 2.52522826e-01],\n",
              "       ...,\n",
              "       [2.64038135e-05, 1.37092385e-07, 2.08342259e-04, 7.37509516e-04,\n",
              "        9.90129411e-01, 8.89823120e-03],\n",
              "       [1.31088127e-05, 6.01498306e-01, 3.96223754e-01, 1.44367979e-03,\n",
              "        3.43709078e-04, 4.77382622e-04],\n",
              "       [3.35429097e-04, 1.59875999e-04, 1.15272090e-01, 1.10953243e-03,\n",
              "        8.55063736e-01, 2.80593000e-02]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cmA2bFgsDW3D",
        "outputId": "8eb006e7-8ad5-4bc1-b54c-fcb72e221fd9"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([3, 3, 3, 0, 4, 4, 1, 2, 5, 0, 5, 3, 2, 2, 1, 4, 4, 5, 2, 4, 1, 2,\n",
              "       3, 5, 4, 2, 1, 2, 2, 2, 2, 5, 2, 5, 3, 1, 2, 0, 4, 5, 2, 3, 2, 2,\n",
              "       5, 2, 0, 1, 3, 4, 4, 5, 1, 1, 4, 4, 5, 1, 1, 1, 0, 1, 5, 0, 4, 1,\n",
              "       1, 0, 1, 4, 1, 0, 4, 1, 3, 1, 2, 2, 1, 2, 3, 0, 5, 3, 5, 5, 2, 4,\n",
              "       5, 1, 5, 1, 5, 3, 4, 1, 4, 1, 5, 4, 5, 1, 2, 1, 1, 5, 1, 3, 2, 5,\n",
              "       2, 1, 3, 5, 4, 4, 0, 0, 3, 1, 2, 2, 3, 5, 1, 5, 3, 4, 2, 2, 0, 2,\n",
              "       2, 5, 5, 0, 3, 3, 2, 2, 0, 3, 4, 0, 4, 2, 4, 5, 4, 1, 5, 3, 2, 2,\n",
              "       5, 4, 3, 3, 4, 3, 3, 4, 1, 5, 2, 3, 2, 2, 0, 2, 1, 3, 1, 2, 2, 5,\n",
              "       5, 1, 4, 2, 2, 1, 1, 3, 3, 5, 5, 2, 5, 1, 5, 0, 3, 3, 0, 5, 1, 4,\n",
              "       1, 4, 2, 5, 5, 1, 4, 2, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_Ytest = y_test.astype(int)"
      ],
      "metadata": {
        "id": "0PHDKWJWDY3g"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_Ytest"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k68v2i-pDbZE",
        "outputId": "dfd52da2-4cc8-4746-9ea4-7addf60ea7b9"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([3, 3, 3, 0, 4, 4, 1, 2, 5, 0, 5, 3, 2, 2, 1, 4, 4, 5, 2, 4, 1, 2,\n",
              "       3, 5, 4, 2, 1, 2, 2, 2, 2, 5, 2, 5, 3, 1, 2, 0, 4, 5, 2, 3, 2, 2,\n",
              "       5, 2, 0, 1, 3, 4, 4, 5, 1, 1, 4, 4, 5, 1, 1, 1, 0, 1, 5, 0, 4, 1,\n",
              "       1, 0, 1, 4, 1, 0, 4, 1, 3, 1, 2, 2, 1, 2, 3, 0, 5, 3, 5, 5, 2, 4,\n",
              "       5, 1, 5, 1, 5, 3, 4, 1, 4, 1, 5, 4, 5, 1, 2, 1, 1, 5, 1, 3, 2, 5,\n",
              "       2, 1, 3, 5, 4, 4, 0, 0, 3, 1, 2, 2, 3, 5, 1, 5, 3, 4, 2, 2, 0, 2,\n",
              "       2, 5, 5, 0, 3, 3, 2, 2, 0, 3, 4, 0, 4, 2, 4, 5, 4, 1, 5, 3, 2, 2,\n",
              "       5, 4, 3, 3, 4, 3, 3, 4, 1, 5, 2, 3, 2, 2, 0, 2, 1, 3, 1, 2, 2, 5,\n",
              "       5, 1, 4, 2, 2, 1, 1, 3, 3, 5, 5, 2, 5, 1, 5, 0, 3, 3, 0, 5, 1, 4,\n",
              "       1, 4, 2, 5, 5, 1, 4, 2, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds1=predictions.argmax(axis=1)\n",
        "preds1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4_cAI39VFhtp",
        "outputId": "c742c9ab-eeef-47e7-f595-a9dddfdfb4fa"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 3, 3, 2, 4, 4, 1, 2, 5, 1, 4, 3, 2, 2, 0, 4, 4, 3, 2, 4, 2, 2,\n",
              "       3, 3, 5, 2, 1, 0, 2, 2, 2, 5, 2, 5, 3, 1, 2, 0, 4, 5, 2, 3, 2, 2,\n",
              "       5, 2, 1, 1, 3, 4, 4, 2, 1, 1, 4, 4, 5, 1, 1, 1, 3, 1, 2, 0, 4, 1,\n",
              "       1, 1, 1, 4, 0, 2, 4, 1, 5, 5, 2, 2, 2, 2, 1, 0, 5, 3, 5, 5, 2, 3,\n",
              "       5, 1, 5, 1, 5, 3, 2, 2, 4, 0, 5, 4, 5, 1, 2, 1, 1, 5, 1, 5, 2, 5,\n",
              "       0, 0, 3, 5, 4, 4, 3, 0, 3, 3, 1, 2, 3, 5, 1, 5, 3, 3, 2, 2, 0, 2,\n",
              "       2, 3, 5, 0, 3, 3, 2, 4, 0, 5, 4, 0, 4, 4, 4, 2, 4, 1, 5, 3, 2, 2,\n",
              "       5, 4, 4, 3, 5, 5, 3, 4, 2, 5, 2, 3, 2, 2, 0, 2, 0, 3, 1, 2, 2, 5,\n",
              "       5, 1, 4, 2, 4, 1, 1, 3, 3, 5, 5, 2, 5, 1, 4, 1, 3, 3, 2, 5, 1, 4,\n",
              "       1, 3, 5, 5, 5, 1, 4, 1, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "abc = preds1.astype(int).flatten()"
      ],
      "metadata": {
        "id": "H4WEmM60NfQn"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "c = confusion_matrix(new_Ytest, abc) \n",
        "c"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bKEBeEBlFjB8",
        "outputId": "2abd736c-cf45-477a-b4f7-e2f3dc2efca9"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 9,  4,  3,  2,  0,  0],\n",
              "       [ 5, 30,  4,  1,  0,  1],\n",
              "       [ 2,  2, 37,  0,  3,  1],\n",
              "       [ 1,  1,  0, 24,  1,  4],\n",
              "       [ 0,  0,  1,  3, 27,  2],\n",
              "       [ 0,  0,  3,  3,  2, 31]])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m4RjG7LWLSQx",
        "outputId": "2a41ccb3-42c3-401d-c49a-e1f9eacbd13f"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([3, 3, 3, 0, 4, 4, 1, 2, 5, 0, 5, 3, 2, 2, 1, 4, 4, 5, 2, 4, 1, 2,\n",
              "       3, 5, 4, 2, 1, 2, 2, 2, 2, 5, 2, 5, 3, 1, 2, 0, 4, 5, 2, 3, 2, 2,\n",
              "       5, 2, 0, 1, 3, 4, 4, 5, 1, 1, 4, 4, 5, 1, 1, 1, 0, 1, 5, 0, 4, 1,\n",
              "       1, 0, 1, 4, 1, 0, 4, 1, 3, 1, 2, 2, 1, 2, 3, 0, 5, 3, 5, 5, 2, 4,\n",
              "       5, 1, 5, 1, 5, 3, 4, 1, 4, 1, 5, 4, 5, 1, 2, 1, 1, 5, 1, 3, 2, 5,\n",
              "       2, 1, 3, 5, 4, 4, 0, 0, 3, 1, 2, 2, 3, 5, 1, 5, 3, 4, 2, 2, 0, 2,\n",
              "       2, 5, 5, 0, 3, 3, 2, 2, 0, 3, 4, 0, 4, 2, 4, 5, 4, 1, 5, 3, 2, 2,\n",
              "       5, 4, 3, 3, 4, 3, 3, 4, 1, 5, 2, 3, 2, 2, 0, 2, 1, 3, 1, 2, 2, 5,\n",
              "       5, 1, 4, 2, 2, 1, 1, 3, 3, 5, 5, 2, 5, 1, 5, 0, 3, 3, 0, 5, 1, 4,\n",
              "       1, 4, 2, 5, 5, 1, 4, 2, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss, acc =model.evaluate(x_testcnn, y_test)\n",
        "print(\"Restored model, accuracy: {:5.2f}%\".format(100*acc))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n3kzoqPkDqqS",
        "outputId": "9e849a3f-0f62-475e-cfb6-e68a1afb4c44"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7/7 [==============================] - 0s 3ms/step - loss: 0.6328 - accuracy: 0.7633\n",
            "Restored model, accuracy: 76.33%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss, acc =model.evaluate(X_train, y_train)\n",
        "print(\"Restored model train, accuracy: {:5.2f}%\".format(100*acc))"
      ],
      "metadata": {
        "id": "fJDTGH_OUX0z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "698114e9-0a6c-4dfe-db8f-66be2e66ceb1"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "52/52 [==============================] - 0s 4ms/step - loss: 0.3812 - accuracy: 0.9045\n",
            "Restored model train, accuracy: 90.45%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix,accuracy_score\n",
        "import seaborn as sn\n",
        "\n",
        "print(classification_report(new_Ytest,abc))\n",
        "\n",
        "acc = float(accuracy_score(new_Ytest,abc))*100\n",
        "print(\"----accuracy score %s ----\" % acc)\n",
        "\n",
        "cm = confusion_matrix(new_Ytest,abc)\n",
        "#df_cm = pd.DataFrame(cm)\n",
        "class_names = ['neutral','calm', 'happy','sad','angry', 'fearful' ]\n",
        "df_cm = pd.DataFrame(cm, index=class_names, columns=class_names,)\n",
        "sn.heatmap(df_cm, annot=True, fmt='')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 508
        },
        "id": "SfSC3El94LZg",
        "outputId": "60f8025a-93f8-4b48-951d-6df121d6a581"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.53      0.50      0.51        18\n",
            "           1       0.81      0.73      0.77        41\n",
            "           2       0.77      0.82      0.80        45\n",
            "           3       0.73      0.77      0.75        31\n",
            "           4       0.82      0.82      0.82        33\n",
            "           5       0.79      0.79      0.79        39\n",
            "\n",
            "    accuracy                           0.76       207\n",
            "   macro avg       0.74      0.74      0.74       207\n",
            "weighted avg       0.76      0.76      0.76       207\n",
            "\n",
            "----accuracy score 76.32850241545893 ----\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "A6UOIsB2xKek"
      },
      "execution_count": 28,
      "outputs": []
    }
  ]
}