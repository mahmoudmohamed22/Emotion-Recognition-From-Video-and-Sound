{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "original_rms_0.00002_without decay_1000_3.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9SRCO-a_AlH5",
        "outputId": "be0eaab1-9e28-4b24-fb0f-4047b2d33c42"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install librosa"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Lo4mUwG9RMd",
        "outputId": "b893c7df-70ca-4f63-8f7e-34c1ca28b9db"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.7/dist-packages (0.8.1)\n",
            "Requirement already satisfied: soundfile>=0.10.2 in /usr/local/lib/python3.7/dist-packages (from librosa) (0.10.3.post1)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.4.1)\n",
            "Requirement already satisfied: decorator>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied: numba>=0.43.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (0.51.2)\n",
            "Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.0.2)\n",
            "Requirement already satisfied: resampy>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from librosa) (0.2.2)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.1.0)\n",
            "Requirement already satisfied: audioread>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (2.1.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (21.3)\n",
            "Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.6.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.21.6)\n",
            "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba>=0.43.0->librosa) (0.34.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba>=0.43.0->librosa) (57.4.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->librosa) (3.0.9)\n",
            "Requirement already satisfied: appdirs>=1.3.0 in /usr/local/lib/python3.7/dist-packages (from pooch>=1.0->librosa) (1.4.4)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from pooch>=1.0->librosa) (2.23.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2022.5.18.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2.10)\n",
            "Requirement already satisfied: six>=1.3 in /usr/local/lib/python3.7/dist-packages (from resampy>=0.2.2->librosa) (1.15.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn!=0.19.0,>=0.14.0->librosa) (3.1.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.7/dist-packages (from soundfile>=0.10.2->librosa) (1.15.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.0->soundfile>=0.10.2->librosa) (2.21)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HJjcbxwy46bG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "5ffc2bf3-b775-4e15-feed-76c140849824"
      },
      "source": [
        "# Orignial Notebook: https://github.com/MITESHPUTHRANNEU/Speech-Emotion-Analyzer/blob/master/final_results_gender_test.ipynb\n",
        "# This notebook author: Reza Chu\n",
        "# Last Editing Date: 31st May 2019\n",
        "\n",
        "## Python\n",
        "import os\n",
        "import random\n",
        "import sys\n",
        "\n",
        "import IPython\n",
        "from IPython.display import Audio\n",
        "from IPython.display import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "## Package\n",
        "import glob \n",
        "import keras\n",
        "import IPython.display as ipd\n",
        "import librosa\n",
        "import librosa.display\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import plotly.graph_objs as go\n",
        "import plotly.offline as py\n",
        "import plotly.tools as tls\n",
        "import seaborn as sns\n",
        "import scipy.io.wavfile\n",
        "import tensorflow as tf\n",
        "py.init_notebook_mode(connected=True)\n",
        "\n",
        "## Keras\n",
        "from keras import regularizers\n",
        "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping\n",
        "from keras.callbacks import  History, ReduceLROnPlateau, CSVLogger\n",
        "from keras.models import Model, Sequential\n",
        "from keras.layers import Dense, Embedding, LSTM\n",
        "from keras.layers import Input, Flatten, Dropout, Activation, BatchNormalization\n",
        "from keras.layers import Conv1D, MaxPooling1D, AveragePooling1D\n",
        "from keras.preprocessing import sequence\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.utils import np_utils\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "## Sklearn\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "## Rest\n",
        "from scipy.fftpack import fft\n",
        "from scipy import signal\n",
        "from scipy.io import wavfile\n",
        "from tqdm import tqdm\n",
        "\n",
        "input_duration=3\n",
        "# % pylab inline"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "        <script type=\"text/javascript\">\n",
              "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
              "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
              "        if (typeof require !== 'undefined') {\n",
              "        require.undef(\"plotly\");\n",
              "        requirejs.config({\n",
              "            paths: {\n",
              "                'plotly': ['https://cdn.plot.ly/plotly-2.8.3.min']\n",
              "            }\n",
              "        });\n",
              "        require(['plotly'], function(Plotly) {\n",
              "            window._Plotly = Plotly;\n",
              "        });\n",
              "        }\n",
              "        </script>\n",
              "        "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Saving joblib files to not load them again with the loop above\n",
        "\n",
        "# import joblib\n",
        "\n",
        "# X_name = 'x.joblib'\n",
        "# y_name = 'y.joblib'\n",
        "# save_dir = '/content/drive/My Drive/graduation project/audio/paper_code/features'\n",
        "\n",
        "# savedX = joblib.dump(X, os.path.join(save_dir, X_name))\n",
        "# savedy = joblib.dump(y, os.path.join(save_dir, y_name))"
      ],
      "metadata": {
        "id": "UCzic8rlDcuk"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Loading saved models\n",
        "import joblib\n",
        "X = joblib.load('/content/drive/My Drive/graduation project/audio/paper_code/features/x.joblib')\n",
        "y = joblib.load('/content/drive/My Drive/graduation project/audio/paper_code/features/y.joblib')"
      ],
      "metadata": {
        "id": "Q35CN6zDrzg1"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7PSTurzjCo5K",
        "outputId": "7947a378-5952-4255-8730-97cdf8ef8b6c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2068, 40)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.1 ,shuffle = True\n",
        "                                                    , random_state=42)\n",
        "X_train , X_valid, y_train, y_valid = train_test_split(X_train,y_train, test_size=0.1112305212 , shuffle = True \n",
        "                                                       , random_state=42)"
      ],
      "metadata": {
        "id": "Ai4Fy5cPCiq1"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "x_traincnn = np.expand_dims(X_train, axis=2)\n",
        "x_testcnn = np.expand_dims(X_test, axis=2)\n",
        "X_valid= np.expand_dims(X_valid, axis=2)"
      ],
      "metadata": {
        "id": "tp1Fm5K3CEXu"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_traincnn.shape, x_testcnn.shape , X_valid.shape\n",
        "#1861"
      ],
      "metadata": {
        "id": "RI0MxoIPBws5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d7c1af2-cd09-4a6c-aa7a-17c8de3e443a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1654, 40, 1), (207, 40, 1), (207, 40, 1))"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oALhiMUd9G2Y",
        "outputId": "47bdb9ab-a79f-44d7-8eb5-1e7cd4254e0c"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (2.8.2+zzzcolab20220527125636)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.26.0)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (14.0.1)\n",
            "Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.5.3)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.17.3)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (4.2.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.21.6)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow) (57.4.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.46.3)\n",
            "Requirement already satisfied: tensorflow-estimator<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.0.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow) (1.5.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.6.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.4.6)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.35.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (3.3.7)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.23.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.8.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.2.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (4.11.4)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (3.8.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2022.5.18.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (3.2.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from keras.preprocessing import sequence\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from keras.layers import Input, Flatten, Dropout, Activation\n",
        "from keras.layers import Conv1D, MaxPooling1D\n",
        "from keras.models import Model\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras import optimizers\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv1D(128, 8,padding='same', #classifier.add(Convolution2D(64, (3, 3), padding = 'same', input_shape = (128, 128, 3), activation = 'relu'))\n",
        "                 input_shape=(40,1)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(MaxPooling1D(pool_size=(5)))\n",
        "\n",
        "\n",
        "model.add(Conv1D(256,8,padding='same',))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(MaxPooling1D(pool_size=(5)))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(256))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(256))\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "model.add(Dense(6))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "opt = tf.keras.optimizers.RMSprop(lr=0.00002 , decay=0.0)\n",
        "#opt = tf.keras.optimizers.RMSprop(lr=0.0001, rho=0.9, epsilon=1e-07, decay=0.0)\n",
        "#opt = tf.keras.optimizers.SGD(lr=0.001, momentum=0.0, decay=0.0, nesterov=False)"
      ],
      "metadata": {
        "id": "g74fXWVAC4Cr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "110e0272-831b-4d32-b31d-8f0e24010b7a"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/rmsprop.py:130: UserWarning:\n",
            "\n",
            "The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H6ukOxAGC_I4",
        "outputId": "9c172dee-f691-491f-e907-0ee55894fa5a"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d (Conv1D)             (None, 40, 128)           1152      \n",
            "                                                                 \n",
            " activation (Activation)     (None, 40, 128)           0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 40, 128)           0         \n",
            "                                                                 \n",
            " max_pooling1d (MaxPooling1D  (None, 8, 128)           0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv1d_1 (Conv1D)           (None, 8, 256)            262400    \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 8, 256)            0         \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 8, 256)            0         \n",
            "                                                                 \n",
            " max_pooling1d_1 (MaxPooling  (None, 1, 256)           0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 256)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 256)               65792     \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 256)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 256)               65792     \n",
            "                                                                 \n",
            " activation_3 (Activation)   (None, 256)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 6)                 1542      \n",
            "                                                                 \n",
            " activation_4 (Activation)   (None, 6)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 396,678\n",
            "Trainable params: 396,678\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='sparse_categorical_crossentropy',\n",
        "              optimizer=opt,\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "AbMlLNk4DCBM"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an Instance of Early Stopping Callback.\n",
        "early_stopping_callback = EarlyStopping(monitor = 'val_loss', patience = 25, mode = 'min', restore_best_weights = True)\n",
        "\n",
        "cnnhistory=model.fit(x_traincnn, y_train, batch_size=16, epochs=1000 , shuffle = True, \n",
        "                     validation_data=(X_valid, y_valid) \n",
        "                     , callbacks = [early_stopping_callback]\n",
        "                     )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RI1v2AuADFhy",
        "outputId": "ded3d936-9c35-4337-ac2e-282991e7d2a0"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "104/104 [==============================] - 4s 8ms/step - loss: 6.2842 - accuracy: 0.1808 - val_loss: 3.4131 - val_accuracy: 0.1932\n",
            "Epoch 2/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 4.6585 - accuracy: 0.1735 - val_loss: 2.7346 - val_accuracy: 0.1932\n",
            "Epoch 3/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 3.9835 - accuracy: 0.1977 - val_loss: 2.0900 - val_accuracy: 0.1932\n",
            "Epoch 4/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 3.5628 - accuracy: 0.1880 - val_loss: 2.1779 - val_accuracy: 0.1932\n",
            "Epoch 5/1000\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 2.9921 - accuracy: 0.2080 - val_loss: 1.9283 - val_accuracy: 0.1932\n",
            "Epoch 6/1000\n",
            "104/104 [==============================] - 1s 9ms/step - loss: 2.9083 - accuracy: 0.1977 - val_loss: 1.8339 - val_accuracy: 0.2077\n",
            "Epoch 7/1000\n",
            "104/104 [==============================] - 1s 9ms/step - loss: 2.7346 - accuracy: 0.1947 - val_loss: 1.7411 - val_accuracy: 0.2126\n",
            "Epoch 8/1000\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 2.6111 - accuracy: 0.2013 - val_loss: 1.7383 - val_accuracy: 0.2319\n",
            "Epoch 9/1000\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 2.4758 - accuracy: 0.1953 - val_loss: 1.7099 - val_accuracy: 0.2271\n",
            "Epoch 10/1000\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 2.3457 - accuracy: 0.2110 - val_loss: 1.7150 - val_accuracy: 0.2415\n",
            "Epoch 11/1000\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 2.3255 - accuracy: 0.2019 - val_loss: 1.6924 - val_accuracy: 0.3285\n",
            "Epoch 12/1000\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 2.2277 - accuracy: 0.2044 - val_loss: 1.7067 - val_accuracy: 0.3092\n",
            "Epoch 13/1000\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 2.1432 - accuracy: 0.2249 - val_loss: 1.7026 - val_accuracy: 0.2512\n",
            "Epoch 14/1000\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 2.1210 - accuracy: 0.2207 - val_loss: 1.6884 - val_accuracy: 0.3671\n",
            "Epoch 15/1000\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 2.1070 - accuracy: 0.2231 - val_loss: 1.7277 - val_accuracy: 0.2077\n",
            "Epoch 16/1000\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 2.0848 - accuracy: 0.2104 - val_loss: 1.6945 - val_accuracy: 0.2657\n",
            "Epoch 17/1000\n",
            "104/104 [==============================] - 1s 9ms/step - loss: 2.0443 - accuracy: 0.2195 - val_loss: 1.6970 - val_accuracy: 0.2512\n",
            "Epoch 18/1000\n",
            "104/104 [==============================] - 1s 9ms/step - loss: 2.0004 - accuracy: 0.2418 - val_loss: 1.6907 - val_accuracy: 0.2657\n",
            "Epoch 19/1000\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 1.9476 - accuracy: 0.2255 - val_loss: 1.6932 - val_accuracy: 0.2657\n",
            "Epoch 20/1000\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 1.9579 - accuracy: 0.2255 - val_loss: 1.6757 - val_accuracy: 0.3816\n",
            "Epoch 21/1000\n",
            "104/104 [==============================] - 1s 9ms/step - loss: 1.9569 - accuracy: 0.2340 - val_loss: 1.6860 - val_accuracy: 0.3333\n",
            "Epoch 22/1000\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 1.9408 - accuracy: 0.2098 - val_loss: 1.6808 - val_accuracy: 0.3237\n",
            "Epoch 23/1000\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 1.8724 - accuracy: 0.2467 - val_loss: 1.6832 - val_accuracy: 0.3478\n",
            "Epoch 24/1000\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 1.9012 - accuracy: 0.2255 - val_loss: 1.6813 - val_accuracy: 0.3237\n",
            "Epoch 25/1000\n",
            "104/104 [==============================] - 1s 13ms/step - loss: 1.8767 - accuracy: 0.2394 - val_loss: 1.6912 - val_accuracy: 0.2899\n",
            "Epoch 26/1000\n",
            "104/104 [==============================] - 1s 11ms/step - loss: 1.8714 - accuracy: 0.2406 - val_loss: 1.6911 - val_accuracy: 0.2850\n",
            "Epoch 27/1000\n",
            "104/104 [==============================] - 1s 12ms/step - loss: 1.8526 - accuracy: 0.2400 - val_loss: 1.6696 - val_accuracy: 0.3478\n",
            "Epoch 28/1000\n",
            "104/104 [==============================] - 1s 9ms/step - loss: 1.8051 - accuracy: 0.2449 - val_loss: 1.6689 - val_accuracy: 0.3285\n",
            "Epoch 29/1000\n",
            "104/104 [==============================] - 1s 10ms/step - loss: 1.8510 - accuracy: 0.2358 - val_loss: 1.6791 - val_accuracy: 0.2754\n",
            "Epoch 30/1000\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 1.8137 - accuracy: 0.2600 - val_loss: 1.6797 - val_accuracy: 0.2995\n",
            "Epoch 31/1000\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 1.8340 - accuracy: 0.2406 - val_loss: 1.6902 - val_accuracy: 0.3237\n",
            "Epoch 32/1000\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 1.8173 - accuracy: 0.2418 - val_loss: 1.6666 - val_accuracy: 0.3092\n",
            "Epoch 33/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.7846 - accuracy: 0.2551 - val_loss: 1.6712 - val_accuracy: 0.3333\n",
            "Epoch 34/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.8063 - accuracy: 0.2576 - val_loss: 1.6584 - val_accuracy: 0.3430\n",
            "Epoch 35/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.7942 - accuracy: 0.2527 - val_loss: 1.6552 - val_accuracy: 0.3478\n",
            "Epoch 36/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.7855 - accuracy: 0.2527 - val_loss: 1.6519 - val_accuracy: 0.3671\n",
            "Epoch 37/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.7645 - accuracy: 0.2467 - val_loss: 1.6478 - val_accuracy: 0.3575\n",
            "Epoch 38/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.7373 - accuracy: 0.2830 - val_loss: 1.6371 - val_accuracy: 0.3913\n",
            "Epoch 39/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.7373 - accuracy: 0.2775 - val_loss: 1.6414 - val_accuracy: 0.3623\n",
            "Epoch 40/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.7421 - accuracy: 0.2654 - val_loss: 1.6433 - val_accuracy: 0.3671\n",
            "Epoch 41/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.7293 - accuracy: 0.2854 - val_loss: 1.6335 - val_accuracy: 0.3961\n",
            "Epoch 42/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.7283 - accuracy: 0.2787 - val_loss: 1.6340 - val_accuracy: 0.4106\n",
            "Epoch 43/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.7355 - accuracy: 0.2666 - val_loss: 1.6291 - val_accuracy: 0.3623\n",
            "Epoch 44/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.7109 - accuracy: 0.2823 - val_loss: 1.6295 - val_accuracy: 0.3333\n",
            "Epoch 45/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.6960 - accuracy: 0.2926 - val_loss: 1.6383 - val_accuracy: 0.3671\n",
            "Epoch 46/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.7337 - accuracy: 0.2836 - val_loss: 1.6207 - val_accuracy: 0.3768\n",
            "Epoch 47/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.7077 - accuracy: 0.2866 - val_loss: 1.6088 - val_accuracy: 0.4444\n",
            "Epoch 48/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.6910 - accuracy: 0.2981 - val_loss: 1.6034 - val_accuracy: 0.3961\n",
            "Epoch 49/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.6694 - accuracy: 0.3077 - val_loss: 1.6070 - val_accuracy: 0.3816\n",
            "Epoch 50/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.6651 - accuracy: 0.3265 - val_loss: 1.6078 - val_accuracy: 0.3671\n",
            "Epoch 51/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.6780 - accuracy: 0.2999 - val_loss: 1.5870 - val_accuracy: 0.3285\n",
            "Epoch 52/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.6671 - accuracy: 0.2999 - val_loss: 1.5854 - val_accuracy: 0.3768\n",
            "Epoch 53/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.6602 - accuracy: 0.3204 - val_loss: 1.6372 - val_accuracy: 0.2995\n",
            "Epoch 54/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.6446 - accuracy: 0.3174 - val_loss: 1.5897 - val_accuracy: 0.3913\n",
            "Epoch 55/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.6440 - accuracy: 0.3162 - val_loss: 1.5833 - val_accuracy: 0.4155\n",
            "Epoch 56/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.6492 - accuracy: 0.3053 - val_loss: 1.5777 - val_accuracy: 0.4010\n",
            "Epoch 57/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.6433 - accuracy: 0.3108 - val_loss: 1.5727 - val_accuracy: 0.3865\n",
            "Epoch 58/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.6571 - accuracy: 0.2975 - val_loss: 1.5619 - val_accuracy: 0.4541\n",
            "Epoch 59/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.6211 - accuracy: 0.3192 - val_loss: 1.5613 - val_accuracy: 0.4300\n",
            "Epoch 60/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.6223 - accuracy: 0.3253 - val_loss: 1.5817 - val_accuracy: 0.3478\n",
            "Epoch 61/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.6173 - accuracy: 0.3398 - val_loss: 1.5511 - val_accuracy: 0.3913\n",
            "Epoch 62/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.6261 - accuracy: 0.3253 - val_loss: 1.5620 - val_accuracy: 0.3865\n",
            "Epoch 63/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.6046 - accuracy: 0.3331 - val_loss: 1.5585 - val_accuracy: 0.4106\n",
            "Epoch 64/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.6265 - accuracy: 0.3156 - val_loss: 1.5488 - val_accuracy: 0.4203\n",
            "Epoch 65/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.5912 - accuracy: 0.3428 - val_loss: 1.5578 - val_accuracy: 0.4444\n",
            "Epoch 66/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.5965 - accuracy: 0.3476 - val_loss: 1.5392 - val_accuracy: 0.4251\n",
            "Epoch 67/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.5977 - accuracy: 0.3380 - val_loss: 1.5187 - val_accuracy: 0.4493\n",
            "Epoch 68/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.5948 - accuracy: 0.3652 - val_loss: 1.5282 - val_accuracy: 0.4251\n",
            "Epoch 69/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.5976 - accuracy: 0.3440 - val_loss: 1.5345 - val_accuracy: 0.3913\n",
            "Epoch 70/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.5936 - accuracy: 0.3410 - val_loss: 1.5147 - val_accuracy: 0.4734\n",
            "Epoch 71/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.5947 - accuracy: 0.3440 - val_loss: 1.5216 - val_accuracy: 0.4541\n",
            "Epoch 72/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.5760 - accuracy: 0.3603 - val_loss: 1.5091 - val_accuracy: 0.4493\n",
            "Epoch 73/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.5664 - accuracy: 0.3495 - val_loss: 1.5277 - val_accuracy: 0.4589\n",
            "Epoch 74/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.5620 - accuracy: 0.3458 - val_loss: 1.5132 - val_accuracy: 0.4493\n",
            "Epoch 75/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.5681 - accuracy: 0.3531 - val_loss: 1.5062 - val_accuracy: 0.4444\n",
            "Epoch 76/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.5623 - accuracy: 0.3706 - val_loss: 1.5179 - val_accuracy: 0.3816\n",
            "Epoch 77/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.5535 - accuracy: 0.3742 - val_loss: 1.4974 - val_accuracy: 0.4783\n",
            "Epoch 78/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.5334 - accuracy: 0.3694 - val_loss: 1.4991 - val_accuracy: 0.4396\n",
            "Epoch 79/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.5352 - accuracy: 0.3543 - val_loss: 1.4968 - val_accuracy: 0.4010\n",
            "Epoch 80/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.5188 - accuracy: 0.3755 - val_loss: 1.4974 - val_accuracy: 0.4493\n",
            "Epoch 81/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.5567 - accuracy: 0.3543 - val_loss: 1.4828 - val_accuracy: 0.4493\n",
            "Epoch 82/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.5342 - accuracy: 0.3724 - val_loss: 1.4844 - val_accuracy: 0.4203\n",
            "Epoch 83/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.5090 - accuracy: 0.3664 - val_loss: 1.4652 - val_accuracy: 0.4638\n",
            "Epoch 84/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.5330 - accuracy: 0.3767 - val_loss: 1.4849 - val_accuracy: 0.4831\n",
            "Epoch 85/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.5030 - accuracy: 0.3803 - val_loss: 1.4712 - val_accuracy: 0.4493\n",
            "Epoch 86/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.5232 - accuracy: 0.3622 - val_loss: 1.4620 - val_accuracy: 0.4348\n",
            "Epoch 87/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.5182 - accuracy: 0.3712 - val_loss: 1.4923 - val_accuracy: 0.3720\n",
            "Epoch 88/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.5075 - accuracy: 0.3888 - val_loss: 1.4639 - val_accuracy: 0.4348\n",
            "Epoch 89/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.4869 - accuracy: 0.3906 - val_loss: 1.4508 - val_accuracy: 0.4348\n",
            "Epoch 90/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.4884 - accuracy: 0.4015 - val_loss: 1.4629 - val_accuracy: 0.4155\n",
            "Epoch 91/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 1.4781 - accuracy: 0.3960 - val_loss: 1.4274 - val_accuracy: 0.4493\n",
            "Epoch 92/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.4903 - accuracy: 0.3845 - val_loss: 1.4524 - val_accuracy: 0.4493\n",
            "Epoch 93/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.4846 - accuracy: 0.4033 - val_loss: 1.4503 - val_accuracy: 0.4638\n",
            "Epoch 94/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.4809 - accuracy: 0.4015 - val_loss: 1.4422 - val_accuracy: 0.4396\n",
            "Epoch 95/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.4832 - accuracy: 0.3924 - val_loss: 1.4232 - val_accuracy: 0.4444\n",
            "Epoch 96/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.4808 - accuracy: 0.3857 - val_loss: 1.4179 - val_accuracy: 0.4396\n",
            "Epoch 97/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.4736 - accuracy: 0.3966 - val_loss: 1.4245 - val_accuracy: 0.4879\n",
            "Epoch 98/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.4627 - accuracy: 0.3906 - val_loss: 1.4185 - val_accuracy: 0.4734\n",
            "Epoch 99/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.4709 - accuracy: 0.3918 - val_loss: 1.4110 - val_accuracy: 0.4734\n",
            "Epoch 100/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.4710 - accuracy: 0.4002 - val_loss: 1.4288 - val_accuracy: 0.4589\n",
            "Epoch 101/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.4386 - accuracy: 0.4008 - val_loss: 1.4404 - val_accuracy: 0.4444\n",
            "Epoch 102/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.4463 - accuracy: 0.4027 - val_loss: 1.4066 - val_accuracy: 0.4783\n",
            "Epoch 103/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.4326 - accuracy: 0.4063 - val_loss: 1.4125 - val_accuracy: 0.4734\n",
            "Epoch 104/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.4337 - accuracy: 0.4081 - val_loss: 1.3986 - val_accuracy: 0.4783\n",
            "Epoch 105/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.4269 - accuracy: 0.4250 - val_loss: 1.3821 - val_accuracy: 0.4976\n",
            "Epoch 106/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.4315 - accuracy: 0.4238 - val_loss: 1.3769 - val_accuracy: 0.5411\n",
            "Epoch 107/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.4184 - accuracy: 0.4087 - val_loss: 1.3752 - val_accuracy: 0.5024\n",
            "Epoch 108/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.4229 - accuracy: 0.4105 - val_loss: 1.3846 - val_accuracy: 0.5121\n",
            "Epoch 109/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.4346 - accuracy: 0.4232 - val_loss: 1.3796 - val_accuracy: 0.4783\n",
            "Epoch 110/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.4189 - accuracy: 0.4172 - val_loss: 1.3751 - val_accuracy: 0.4783\n",
            "Epoch 111/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.4078 - accuracy: 0.4238 - val_loss: 1.3663 - val_accuracy: 0.4734\n",
            "Epoch 112/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.4046 - accuracy: 0.4262 - val_loss: 1.3484 - val_accuracy: 0.4686\n",
            "Epoch 113/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.4227 - accuracy: 0.4148 - val_loss: 1.3561 - val_accuracy: 0.5314\n",
            "Epoch 114/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.4235 - accuracy: 0.4105 - val_loss: 1.3590 - val_accuracy: 0.4879\n",
            "Epoch 115/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.3867 - accuracy: 0.4432 - val_loss: 1.3461 - val_accuracy: 0.5121\n",
            "Epoch 116/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.3745 - accuracy: 0.4528 - val_loss: 1.3537 - val_accuracy: 0.4976\n",
            "Epoch 117/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.3696 - accuracy: 0.4571 - val_loss: 1.3488 - val_accuracy: 0.5121\n",
            "Epoch 118/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.3918 - accuracy: 0.4281 - val_loss: 1.3411 - val_accuracy: 0.4879\n",
            "Epoch 119/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.3538 - accuracy: 0.4565 - val_loss: 1.3276 - val_accuracy: 0.5266\n",
            "Epoch 120/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.3792 - accuracy: 0.4347 - val_loss: 1.3401 - val_accuracy: 0.4928\n",
            "Epoch 121/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.3489 - accuracy: 0.4547 - val_loss: 1.3243 - val_accuracy: 0.5217\n",
            "Epoch 122/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.3602 - accuracy: 0.4486 - val_loss: 1.3278 - val_accuracy: 0.5121\n",
            "Epoch 123/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.3610 - accuracy: 0.4516 - val_loss: 1.3055 - val_accuracy: 0.5362\n",
            "Epoch 124/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.3408 - accuracy: 0.4619 - val_loss: 1.3043 - val_accuracy: 0.4928\n",
            "Epoch 125/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.3457 - accuracy: 0.4553 - val_loss: 1.2976 - val_accuracy: 0.5217\n",
            "Epoch 126/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.3255 - accuracy: 0.4667 - val_loss: 1.3312 - val_accuracy: 0.4976\n",
            "Epoch 127/1000\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.3373 - accuracy: 0.4589 - val_loss: 1.2997 - val_accuracy: 0.5362\n",
            "Epoch 128/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.3339 - accuracy: 0.4504 - val_loss: 1.2887 - val_accuracy: 0.5169\n",
            "Epoch 129/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.3432 - accuracy: 0.4589 - val_loss: 1.3128 - val_accuracy: 0.5314\n",
            "Epoch 130/1000\n",
            "104/104 [==============================] - 1s 9ms/step - loss: 1.3551 - accuracy: 0.4468 - val_loss: 1.2901 - val_accuracy: 0.4879\n",
            "Epoch 131/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.3341 - accuracy: 0.4504 - val_loss: 1.3078 - val_accuracy: 0.5411\n",
            "Epoch 132/1000\n",
            "104/104 [==============================] - 1s 9ms/step - loss: 1.3391 - accuracy: 0.4462 - val_loss: 1.2916 - val_accuracy: 0.5121\n",
            "Epoch 133/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.3277 - accuracy: 0.4480 - val_loss: 1.2748 - val_accuracy: 0.5652\n",
            "Epoch 134/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.3195 - accuracy: 0.4432 - val_loss: 1.2682 - val_accuracy: 0.4976\n",
            "Epoch 135/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.3258 - accuracy: 0.4583 - val_loss: 1.2794 - val_accuracy: 0.5266\n",
            "Epoch 136/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.3162 - accuracy: 0.4661 - val_loss: 1.2790 - val_accuracy: 0.5362\n",
            "Epoch 137/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.2898 - accuracy: 0.4782 - val_loss: 1.2648 - val_accuracy: 0.5459\n",
            "Epoch 138/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.2905 - accuracy: 0.4740 - val_loss: 1.2684 - val_accuracy: 0.4879\n",
            "Epoch 139/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.3049 - accuracy: 0.4607 - val_loss: 1.2525 - val_accuracy: 0.5314\n",
            "Epoch 140/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.2909 - accuracy: 0.4704 - val_loss: 1.2362 - val_accuracy: 0.5556\n",
            "Epoch 141/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.2863 - accuracy: 0.4819 - val_loss: 1.2487 - val_accuracy: 0.5266\n",
            "Epoch 142/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.2855 - accuracy: 0.4813 - val_loss: 1.2529 - val_accuracy: 0.5121\n",
            "Epoch 143/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.2823 - accuracy: 0.4855 - val_loss: 1.2645 - val_accuracy: 0.5024\n",
            "Epoch 144/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.2701 - accuracy: 0.4909 - val_loss: 1.2540 - val_accuracy: 0.5121\n",
            "Epoch 145/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.2905 - accuracy: 0.4764 - val_loss: 1.2367 - val_accuracy: 0.5507\n",
            "Epoch 146/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.2820 - accuracy: 0.4861 - val_loss: 1.2479 - val_accuracy: 0.5169\n",
            "Epoch 147/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.2624 - accuracy: 0.4837 - val_loss: 1.2324 - val_accuracy: 0.5411\n",
            "Epoch 148/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.2965 - accuracy: 0.4746 - val_loss: 1.2376 - val_accuracy: 0.5749\n",
            "Epoch 149/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.2752 - accuracy: 0.4873 - val_loss: 1.2412 - val_accuracy: 0.5266\n",
            "Epoch 150/1000\n",
            "104/104 [==============================] - 1s 9ms/step - loss: 1.2421 - accuracy: 0.4940 - val_loss: 1.2364 - val_accuracy: 0.5217\n",
            "Epoch 151/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.2529 - accuracy: 0.5054 - val_loss: 1.2076 - val_accuracy: 0.5411\n",
            "Epoch 152/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.2445 - accuracy: 0.4927 - val_loss: 1.2120 - val_accuracy: 0.5411\n",
            "Epoch 153/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.2268 - accuracy: 0.5200 - val_loss: 1.2103 - val_accuracy: 0.5797\n",
            "Epoch 154/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.2534 - accuracy: 0.5030 - val_loss: 1.2342 - val_accuracy: 0.5266\n",
            "Epoch 155/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.2527 - accuracy: 0.5048 - val_loss: 1.2159 - val_accuracy: 0.5314\n",
            "Epoch 156/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.2623 - accuracy: 0.4903 - val_loss: 1.2422 - val_accuracy: 0.4976\n",
            "Epoch 157/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.2535 - accuracy: 0.5036 - val_loss: 1.2071 - val_accuracy: 0.5700\n",
            "Epoch 158/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.2473 - accuracy: 0.4879 - val_loss: 1.2038 - val_accuracy: 0.5652\n",
            "Epoch 159/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.2283 - accuracy: 0.5175 - val_loss: 1.1936 - val_accuracy: 0.5942\n",
            "Epoch 160/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.2439 - accuracy: 0.4970 - val_loss: 1.1953 - val_accuracy: 0.5942\n",
            "Epoch 161/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.2261 - accuracy: 0.5139 - val_loss: 1.1996 - val_accuracy: 0.5797\n",
            "Epoch 162/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.2095 - accuracy: 0.5091 - val_loss: 1.1901 - val_accuracy: 0.5266\n",
            "Epoch 163/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.2175 - accuracy: 0.5206 - val_loss: 1.1820 - val_accuracy: 0.5604\n",
            "Epoch 164/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.2193 - accuracy: 0.5121 - val_loss: 1.1847 - val_accuracy: 0.5411\n",
            "Epoch 165/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.2058 - accuracy: 0.5224 - val_loss: 1.1709 - val_accuracy: 0.5700\n",
            "Epoch 166/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.2061 - accuracy: 0.5151 - val_loss: 1.1699 - val_accuracy: 0.5749\n",
            "Epoch 167/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.2121 - accuracy: 0.5169 - val_loss: 1.1644 - val_accuracy: 0.5749\n",
            "Epoch 168/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.2045 - accuracy: 0.5169 - val_loss: 1.1672 - val_accuracy: 0.5749\n",
            "Epoch 169/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.2056 - accuracy: 0.5091 - val_loss: 1.1675 - val_accuracy: 0.5700\n",
            "Epoch 170/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.2135 - accuracy: 0.5133 - val_loss: 1.1635 - val_accuracy: 0.5700\n",
            "Epoch 171/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.1869 - accuracy: 0.5296 - val_loss: 1.1724 - val_accuracy: 0.5556\n",
            "Epoch 172/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.1885 - accuracy: 0.5187 - val_loss: 1.1554 - val_accuracy: 0.5845\n",
            "Epoch 173/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.1855 - accuracy: 0.5079 - val_loss: 1.1532 - val_accuracy: 0.5749\n",
            "Epoch 174/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.2011 - accuracy: 0.5012 - val_loss: 1.1506 - val_accuracy: 0.5845\n",
            "Epoch 175/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.1929 - accuracy: 0.5121 - val_loss: 1.1644 - val_accuracy: 0.5652\n",
            "Epoch 176/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.1759 - accuracy: 0.5236 - val_loss: 1.1530 - val_accuracy: 0.5749\n",
            "Epoch 177/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.1813 - accuracy: 0.5357 - val_loss: 1.1549 - val_accuracy: 0.5604\n",
            "Epoch 178/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.1672 - accuracy: 0.5345 - val_loss: 1.1385 - val_accuracy: 0.5604\n",
            "Epoch 179/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.1783 - accuracy: 0.5266 - val_loss: 1.1438 - val_accuracy: 0.5797\n",
            "Epoch 180/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.1796 - accuracy: 0.5290 - val_loss: 1.1238 - val_accuracy: 0.5652\n",
            "Epoch 181/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.1586 - accuracy: 0.5333 - val_loss: 1.1315 - val_accuracy: 0.5894\n",
            "Epoch 182/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.1742 - accuracy: 0.5187 - val_loss: 1.1505 - val_accuracy: 0.5700\n",
            "Epoch 183/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.1755 - accuracy: 0.5441 - val_loss: 1.1451 - val_accuracy: 0.5362\n",
            "Epoch 184/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.1683 - accuracy: 0.5459 - val_loss: 1.1405 - val_accuracy: 0.5749\n",
            "Epoch 185/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.1467 - accuracy: 0.5387 - val_loss: 1.1089 - val_accuracy: 0.6377\n",
            "Epoch 186/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.1502 - accuracy: 0.5369 - val_loss: 1.1191 - val_accuracy: 0.6184\n",
            "Epoch 187/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.1665 - accuracy: 0.5369 - val_loss: 1.1316 - val_accuracy: 0.5556\n",
            "Epoch 188/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.1457 - accuracy: 0.5447 - val_loss: 1.1011 - val_accuracy: 0.6039\n",
            "Epoch 189/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.1521 - accuracy: 0.5405 - val_loss: 1.1242 - val_accuracy: 0.5749\n",
            "Epoch 190/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.1546 - accuracy: 0.5260 - val_loss: 1.1091 - val_accuracy: 0.5990\n",
            "Epoch 191/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.1358 - accuracy: 0.5417 - val_loss: 1.1189 - val_accuracy: 0.6039\n",
            "Epoch 192/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.1324 - accuracy: 0.5381 - val_loss: 1.1160 - val_accuracy: 0.5700\n",
            "Epoch 193/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.1457 - accuracy: 0.5441 - val_loss: 1.1145 - val_accuracy: 0.5990\n",
            "Epoch 194/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.1502 - accuracy: 0.5284 - val_loss: 1.0901 - val_accuracy: 0.6184\n",
            "Epoch 195/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.1450 - accuracy: 0.5496 - val_loss: 1.1254 - val_accuracy: 0.5362\n",
            "Epoch 196/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.1231 - accuracy: 0.5453 - val_loss: 1.1062 - val_accuracy: 0.5894\n",
            "Epoch 197/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.1214 - accuracy: 0.5556 - val_loss: 1.0994 - val_accuracy: 0.5942\n",
            "Epoch 198/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.1182 - accuracy: 0.5490 - val_loss: 1.1131 - val_accuracy: 0.5362\n",
            "Epoch 199/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.1297 - accuracy: 0.5490 - val_loss: 1.1223 - val_accuracy: 0.5411\n",
            "Epoch 200/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.1238 - accuracy: 0.5441 - val_loss: 1.1118 - val_accuracy: 0.5990\n",
            "Epoch 201/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.1211 - accuracy: 0.5363 - val_loss: 1.0997 - val_accuracy: 0.5652\n",
            "Epoch 202/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.1202 - accuracy: 0.5393 - val_loss: 1.1070 - val_accuracy: 0.5749\n",
            "Epoch 203/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.1189 - accuracy: 0.5466 - val_loss: 1.0931 - val_accuracy: 0.5845\n",
            "Epoch 204/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.1026 - accuracy: 0.5611 - val_loss: 1.0716 - val_accuracy: 0.6232\n",
            "Epoch 205/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0997 - accuracy: 0.5665 - val_loss: 1.1077 - val_accuracy: 0.5797\n",
            "Epoch 206/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.1188 - accuracy: 0.5466 - val_loss: 1.0940 - val_accuracy: 0.5990\n",
            "Epoch 207/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.1119 - accuracy: 0.5508 - val_loss: 1.0837 - val_accuracy: 0.6039\n",
            "Epoch 208/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.1184 - accuracy: 0.5459 - val_loss: 1.1082 - val_accuracy: 0.5556\n",
            "Epoch 209/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0996 - accuracy: 0.5520 - val_loss: 1.0932 - val_accuracy: 0.5990\n",
            "Epoch 210/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.1074 - accuracy: 0.5611 - val_loss: 1.0874 - val_accuracy: 0.6039\n",
            "Epoch 211/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0974 - accuracy: 0.5544 - val_loss: 1.0710 - val_accuracy: 0.6329\n",
            "Epoch 212/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0763 - accuracy: 0.5677 - val_loss: 1.0715 - val_accuracy: 0.6087\n",
            "Epoch 213/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0871 - accuracy: 0.5695 - val_loss: 1.0817 - val_accuracy: 0.5749\n",
            "Epoch 214/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0889 - accuracy: 0.5550 - val_loss: 1.0788 - val_accuracy: 0.6184\n",
            "Epoch 215/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.1050 - accuracy: 0.5629 - val_loss: 1.0628 - val_accuracy: 0.6377\n",
            "Epoch 216/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0975 - accuracy: 0.5568 - val_loss: 1.0719 - val_accuracy: 0.6135\n",
            "Epoch 217/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0793 - accuracy: 0.5677 - val_loss: 1.0719 - val_accuracy: 0.6087\n",
            "Epoch 218/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0839 - accuracy: 0.5774 - val_loss: 1.0773 - val_accuracy: 0.5749\n",
            "Epoch 219/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0727 - accuracy: 0.5768 - val_loss: 1.0376 - val_accuracy: 0.6184\n",
            "Epoch 220/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0642 - accuracy: 0.5695 - val_loss: 1.0585 - val_accuracy: 0.6184\n",
            "Epoch 221/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0703 - accuracy: 0.5683 - val_loss: 1.0409 - val_accuracy: 0.6329\n",
            "Epoch 222/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0512 - accuracy: 0.5695 - val_loss: 1.0298 - val_accuracy: 0.6135\n",
            "Epoch 223/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0612 - accuracy: 0.5792 - val_loss: 1.0369 - val_accuracy: 0.6473\n",
            "Epoch 224/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0612 - accuracy: 0.5919 - val_loss: 1.0349 - val_accuracy: 0.6232\n",
            "Epoch 225/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0743 - accuracy: 0.5641 - val_loss: 1.0387 - val_accuracy: 0.6184\n",
            "Epoch 226/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0534 - accuracy: 0.5816 - val_loss: 1.0345 - val_accuracy: 0.6329\n",
            "Epoch 227/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0796 - accuracy: 0.5635 - val_loss: 1.0591 - val_accuracy: 0.6087\n",
            "Epoch 228/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0397 - accuracy: 0.5816 - val_loss: 1.0471 - val_accuracy: 0.6329\n",
            "Epoch 229/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0278 - accuracy: 0.5913 - val_loss: 1.0245 - val_accuracy: 0.6522\n",
            "Epoch 230/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0342 - accuracy: 0.5931 - val_loss: 1.0096 - val_accuracy: 0.6473\n",
            "Epoch 231/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0358 - accuracy: 0.5786 - val_loss: 1.0128 - val_accuracy: 0.6618\n",
            "Epoch 232/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0411 - accuracy: 0.6022 - val_loss: 1.0336 - val_accuracy: 0.6232\n",
            "Epoch 233/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0535 - accuracy: 0.5671 - val_loss: 1.0097 - val_accuracy: 0.6329\n",
            "Epoch 234/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0335 - accuracy: 0.5883 - val_loss: 1.0269 - val_accuracy: 0.6329\n",
            "Epoch 235/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0294 - accuracy: 0.5883 - val_loss: 1.0242 - val_accuracy: 0.6135\n",
            "Epoch 236/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0415 - accuracy: 0.5865 - val_loss: 1.0227 - val_accuracy: 0.6329\n",
            "Epoch 237/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0360 - accuracy: 0.5732 - val_loss: 1.0089 - val_accuracy: 0.6232\n",
            "Epoch 238/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0390 - accuracy: 0.5913 - val_loss: 1.0078 - val_accuracy: 0.6377\n",
            "Epoch 239/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0581 - accuracy: 0.5732 - val_loss: 1.0239 - val_accuracy: 0.6329\n",
            "Epoch 240/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0188 - accuracy: 0.5907 - val_loss: 1.0261 - val_accuracy: 0.6329\n",
            "Epoch 241/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0283 - accuracy: 0.5828 - val_loss: 1.0190 - val_accuracy: 0.6280\n",
            "Epoch 242/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0077 - accuracy: 0.6173 - val_loss: 1.0163 - val_accuracy: 0.6135\n",
            "Epoch 243/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0284 - accuracy: 0.5901 - val_loss: 1.0083 - val_accuracy: 0.6570\n",
            "Epoch 244/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0031 - accuracy: 0.6112 - val_loss: 1.0313 - val_accuracy: 0.6087\n",
            "Epoch 245/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0271 - accuracy: 0.5810 - val_loss: 1.0182 - val_accuracy: 0.6280\n",
            "Epoch 246/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0248 - accuracy: 0.5913 - val_loss: 0.9962 - val_accuracy: 0.6522\n",
            "Epoch 247/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0153 - accuracy: 0.5865 - val_loss: 1.0093 - val_accuracy: 0.6184\n",
            "Epoch 248/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0149 - accuracy: 0.5901 - val_loss: 0.9973 - val_accuracy: 0.6618\n",
            "Epoch 249/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0113 - accuracy: 0.5889 - val_loss: 1.0321 - val_accuracy: 0.5845\n",
            "Epoch 250/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0152 - accuracy: 0.6016 - val_loss: 0.9827 - val_accuracy: 0.6522\n",
            "Epoch 251/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0196 - accuracy: 0.6034 - val_loss: 0.9874 - val_accuracy: 0.6570\n",
            "Epoch 252/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9960 - accuracy: 0.6064 - val_loss: 0.9750 - val_accuracy: 0.6908\n",
            "Epoch 253/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0095 - accuracy: 0.5919 - val_loss: 0.9786 - val_accuracy: 0.6812\n",
            "Epoch 254/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9954 - accuracy: 0.6034 - val_loss: 0.9740 - val_accuracy: 0.6763\n",
            "Epoch 255/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9741 - accuracy: 0.6215 - val_loss: 0.9782 - val_accuracy: 0.6232\n",
            "Epoch 256/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9729 - accuracy: 0.6100 - val_loss: 0.9965 - val_accuracy: 0.6280\n",
            "Epoch 257/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9886 - accuracy: 0.6052 - val_loss: 0.9928 - val_accuracy: 0.6377\n",
            "Epoch 258/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9991 - accuracy: 0.6112 - val_loss: 0.9597 - val_accuracy: 0.6812\n",
            "Epoch 259/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9970 - accuracy: 0.6070 - val_loss: 0.9597 - val_accuracy: 0.6908\n",
            "Epoch 260/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9830 - accuracy: 0.5985 - val_loss: 0.9643 - val_accuracy: 0.6667\n",
            "Epoch 261/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9890 - accuracy: 0.6209 - val_loss: 0.9668 - val_accuracy: 0.6570\n",
            "Epoch 262/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9848 - accuracy: 0.5979 - val_loss: 0.9567 - val_accuracy: 0.6667\n",
            "Epoch 263/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9720 - accuracy: 0.6215 - val_loss: 0.9639 - val_accuracy: 0.6812\n",
            "Epoch 264/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0114 - accuracy: 0.6010 - val_loss: 0.9629 - val_accuracy: 0.6860\n",
            "Epoch 265/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0093 - accuracy: 0.5931 - val_loss: 0.9755 - val_accuracy: 0.6763\n",
            "Epoch 266/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9708 - accuracy: 0.6233 - val_loss: 0.9574 - val_accuracy: 0.6812\n",
            "Epoch 267/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9798 - accuracy: 0.5985 - val_loss: 0.9784 - val_accuracy: 0.6522\n",
            "Epoch 268/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9717 - accuracy: 0.6276 - val_loss: 0.9547 - val_accuracy: 0.6715\n",
            "Epoch 269/1000\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.9663 - accuracy: 0.6131 - val_loss: 0.9864 - val_accuracy: 0.6377\n",
            "Epoch 270/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.9850 - accuracy: 0.6040 - val_loss: 0.9773 - val_accuracy: 0.6329\n",
            "Epoch 271/1000\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.9737 - accuracy: 0.6119 - val_loss: 0.9380 - val_accuracy: 0.6715\n",
            "Epoch 272/1000\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 0.9633 - accuracy: 0.6221 - val_loss: 0.9492 - val_accuracy: 0.6522\n",
            "Epoch 273/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.9762 - accuracy: 0.6233 - val_loss: 0.9596 - val_accuracy: 0.6522\n",
            "Epoch 274/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9851 - accuracy: 0.6112 - val_loss: 0.9415 - val_accuracy: 0.6812\n",
            "Epoch 275/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9673 - accuracy: 0.6143 - val_loss: 1.0007 - val_accuracy: 0.6425\n",
            "Epoch 276/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9651 - accuracy: 0.6185 - val_loss: 0.9500 - val_accuracy: 0.6570\n",
            "Epoch 277/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9607 - accuracy: 0.6161 - val_loss: 0.9643 - val_accuracy: 0.6812\n",
            "Epoch 278/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9732 - accuracy: 0.6215 - val_loss: 0.9408 - val_accuracy: 0.6522\n",
            "Epoch 279/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9764 - accuracy: 0.6064 - val_loss: 0.9429 - val_accuracy: 0.6715\n",
            "Epoch 280/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9571 - accuracy: 0.6258 - val_loss: 0.9402 - val_accuracy: 0.6763\n",
            "Epoch 281/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9605 - accuracy: 0.6088 - val_loss: 0.9461 - val_accuracy: 0.6570\n",
            "Epoch 282/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9534 - accuracy: 0.6179 - val_loss: 0.9461 - val_accuracy: 0.6812\n",
            "Epoch 283/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9392 - accuracy: 0.6421 - val_loss: 0.9377 - val_accuracy: 0.6425\n",
            "Epoch 284/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9377 - accuracy: 0.6173 - val_loss: 0.9473 - val_accuracy: 0.6667\n",
            "Epoch 285/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9553 - accuracy: 0.6094 - val_loss: 0.9278 - val_accuracy: 0.6715\n",
            "Epoch 286/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9224 - accuracy: 0.6463 - val_loss: 0.9276 - val_accuracy: 0.6715\n",
            "Epoch 287/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9571 - accuracy: 0.6064 - val_loss: 0.9441 - val_accuracy: 0.6522\n",
            "Epoch 288/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9586 - accuracy: 0.6258 - val_loss: 0.9216 - val_accuracy: 0.6715\n",
            "Epoch 289/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9603 - accuracy: 0.6088 - val_loss: 0.9340 - val_accuracy: 0.6667\n",
            "Epoch 290/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9427 - accuracy: 0.6306 - val_loss: 0.9228 - val_accuracy: 0.6860\n",
            "Epoch 291/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9164 - accuracy: 0.6391 - val_loss: 0.9288 - val_accuracy: 0.6667\n",
            "Epoch 292/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9351 - accuracy: 0.6270 - val_loss: 0.9231 - val_accuracy: 0.6860\n",
            "Epoch 293/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9400 - accuracy: 0.6354 - val_loss: 0.9414 - val_accuracy: 0.6763\n",
            "Epoch 294/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9294 - accuracy: 0.6276 - val_loss: 0.9053 - val_accuracy: 0.6763\n",
            "Epoch 295/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9171 - accuracy: 0.6445 - val_loss: 0.9184 - val_accuracy: 0.6763\n",
            "Epoch 296/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9298 - accuracy: 0.6336 - val_loss: 0.8967 - val_accuracy: 0.7150\n",
            "Epoch 297/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9033 - accuracy: 0.6457 - val_loss: 0.9072 - val_accuracy: 0.7005\n",
            "Epoch 298/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9316 - accuracy: 0.6324 - val_loss: 0.9136 - val_accuracy: 0.7101\n",
            "Epoch 299/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8905 - accuracy: 0.6427 - val_loss: 0.9578 - val_accuracy: 0.6667\n",
            "Epoch 300/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9145 - accuracy: 0.6445 - val_loss: 0.9330 - val_accuracy: 0.6715\n",
            "Epoch 301/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9183 - accuracy: 0.6511 - val_loss: 0.9282 - val_accuracy: 0.6667\n",
            "Epoch 302/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9098 - accuracy: 0.6306 - val_loss: 0.9106 - val_accuracy: 0.7101\n",
            "Epoch 303/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9215 - accuracy: 0.6403 - val_loss: 0.9100 - val_accuracy: 0.6812\n",
            "Epoch 304/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9002 - accuracy: 0.6493 - val_loss: 0.9185 - val_accuracy: 0.6522\n",
            "Epoch 305/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9063 - accuracy: 0.6421 - val_loss: 0.8892 - val_accuracy: 0.7101\n",
            "Epoch 306/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9322 - accuracy: 0.6336 - val_loss: 0.9048 - val_accuracy: 0.6715\n",
            "Epoch 307/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8970 - accuracy: 0.6530 - val_loss: 0.8997 - val_accuracy: 0.6908\n",
            "Epoch 308/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9003 - accuracy: 0.6451 - val_loss: 0.8902 - val_accuracy: 0.6908\n",
            "Epoch 309/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8970 - accuracy: 0.6475 - val_loss: 0.8855 - val_accuracy: 0.7150\n",
            "Epoch 310/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9069 - accuracy: 0.6493 - val_loss: 0.9084 - val_accuracy: 0.6667\n",
            "Epoch 311/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9075 - accuracy: 0.6511 - val_loss: 0.8840 - val_accuracy: 0.7150\n",
            "Epoch 312/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9215 - accuracy: 0.6366 - val_loss: 0.8907 - val_accuracy: 0.7198\n",
            "Epoch 313/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9090 - accuracy: 0.6330 - val_loss: 0.9105 - val_accuracy: 0.6812\n",
            "Epoch 314/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8968 - accuracy: 0.6439 - val_loss: 0.8813 - val_accuracy: 0.7150\n",
            "Epoch 315/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9025 - accuracy: 0.6366 - val_loss: 0.8676 - val_accuracy: 0.7343\n",
            "Epoch 316/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9078 - accuracy: 0.6427 - val_loss: 0.8907 - val_accuracy: 0.6763\n",
            "Epoch 317/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8940 - accuracy: 0.6360 - val_loss: 0.9105 - val_accuracy: 0.6618\n",
            "Epoch 318/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.8790 - accuracy: 0.6530 - val_loss: 0.8816 - val_accuracy: 0.7005\n",
            "Epoch 319/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8935 - accuracy: 0.6511 - val_loss: 0.8940 - val_accuracy: 0.6763\n",
            "Epoch 320/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8890 - accuracy: 0.6415 - val_loss: 0.8938 - val_accuracy: 0.6667\n",
            "Epoch 321/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8999 - accuracy: 0.6336 - val_loss: 0.8743 - val_accuracy: 0.6957\n",
            "Epoch 322/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.8786 - accuracy: 0.6421 - val_loss: 0.8948 - val_accuracy: 0.6908\n",
            "Epoch 323/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9260 - accuracy: 0.6372 - val_loss: 0.8830 - val_accuracy: 0.6763\n",
            "Epoch 324/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8764 - accuracy: 0.6578 - val_loss: 0.8752 - val_accuracy: 0.6957\n",
            "Epoch 325/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8950 - accuracy: 0.6421 - val_loss: 0.8979 - val_accuracy: 0.6667\n",
            "Epoch 326/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9022 - accuracy: 0.6511 - val_loss: 0.8944 - val_accuracy: 0.6957\n",
            "Epoch 327/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8780 - accuracy: 0.6518 - val_loss: 0.8835 - val_accuracy: 0.6715\n",
            "Epoch 328/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8897 - accuracy: 0.6493 - val_loss: 0.8903 - val_accuracy: 0.6715\n",
            "Epoch 329/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8669 - accuracy: 0.6614 - val_loss: 0.8706 - val_accuracy: 0.7053\n",
            "Epoch 330/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8839 - accuracy: 0.6451 - val_loss: 0.8651 - val_accuracy: 0.7295\n",
            "Epoch 331/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8727 - accuracy: 0.6505 - val_loss: 0.8737 - val_accuracy: 0.7343\n",
            "Epoch 332/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8800 - accuracy: 0.6518 - val_loss: 0.8906 - val_accuracy: 0.6763\n",
            "Epoch 333/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8674 - accuracy: 0.6548 - val_loss: 0.8604 - val_accuracy: 0.7101\n",
            "Epoch 334/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8480 - accuracy: 0.6747 - val_loss: 0.8722 - val_accuracy: 0.6908\n",
            "Epoch 335/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8654 - accuracy: 0.6578 - val_loss: 0.8538 - val_accuracy: 0.6957\n",
            "Epoch 336/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8688 - accuracy: 0.6602 - val_loss: 0.8811 - val_accuracy: 0.6812\n",
            "Epoch 337/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8681 - accuracy: 0.6632 - val_loss: 0.8950 - val_accuracy: 0.6812\n",
            "Epoch 338/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8769 - accuracy: 0.6608 - val_loss: 0.8631 - val_accuracy: 0.7005\n",
            "Epoch 339/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8653 - accuracy: 0.6596 - val_loss: 0.8850 - val_accuracy: 0.6570\n",
            "Epoch 340/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8398 - accuracy: 0.6699 - val_loss: 0.8943 - val_accuracy: 0.6618\n",
            "Epoch 341/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8566 - accuracy: 0.6729 - val_loss: 0.8595 - val_accuracy: 0.6957\n",
            "Epoch 342/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8427 - accuracy: 0.6705 - val_loss: 0.8551 - val_accuracy: 0.7005\n",
            "Epoch 343/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8639 - accuracy: 0.6705 - val_loss: 0.8507 - val_accuracy: 0.7005\n",
            "Epoch 344/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8696 - accuracy: 0.6608 - val_loss: 0.8617 - val_accuracy: 0.7053\n",
            "Epoch 345/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8632 - accuracy: 0.6620 - val_loss: 0.8645 - val_accuracy: 0.6812\n",
            "Epoch 346/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8442 - accuracy: 0.6735 - val_loss: 0.8532 - val_accuracy: 0.7053\n",
            "Epoch 347/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8274 - accuracy: 0.6693 - val_loss: 0.8727 - val_accuracy: 0.7005\n",
            "Epoch 348/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8492 - accuracy: 0.6711 - val_loss: 0.8398 - val_accuracy: 0.7198\n",
            "Epoch 349/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8402 - accuracy: 0.6669 - val_loss: 0.8531 - val_accuracy: 0.6715\n",
            "Epoch 350/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8388 - accuracy: 0.6608 - val_loss: 0.8701 - val_accuracy: 0.6715\n",
            "Epoch 351/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8537 - accuracy: 0.6499 - val_loss: 0.8414 - val_accuracy: 0.7343\n",
            "Epoch 352/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8551 - accuracy: 0.6632 - val_loss: 0.8474 - val_accuracy: 0.7343\n",
            "Epoch 353/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8732 - accuracy: 0.6457 - val_loss: 0.8455 - val_accuracy: 0.7150\n",
            "Epoch 354/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8363 - accuracy: 0.6651 - val_loss: 0.8498 - val_accuracy: 0.6957\n",
            "Epoch 355/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8391 - accuracy: 0.6753 - val_loss: 0.8335 - val_accuracy: 0.7053\n",
            "Epoch 356/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8577 - accuracy: 0.6626 - val_loss: 0.8458 - val_accuracy: 0.7150\n",
            "Epoch 357/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8307 - accuracy: 0.6705 - val_loss: 0.8298 - val_accuracy: 0.7295\n",
            "Epoch 358/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8278 - accuracy: 0.6681 - val_loss: 0.8339 - val_accuracy: 0.7150\n",
            "Epoch 359/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8340 - accuracy: 0.6705 - val_loss: 0.8254 - val_accuracy: 0.7101\n",
            "Epoch 360/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8418 - accuracy: 0.6717 - val_loss: 0.8250 - val_accuracy: 0.7295\n",
            "Epoch 361/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8466 - accuracy: 0.6572 - val_loss: 0.8489 - val_accuracy: 0.7101\n",
            "Epoch 362/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8138 - accuracy: 0.6693 - val_loss: 0.8349 - val_accuracy: 0.6812\n",
            "Epoch 363/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8324 - accuracy: 0.6705 - val_loss: 0.8411 - val_accuracy: 0.7198\n",
            "Epoch 364/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8346 - accuracy: 0.6675 - val_loss: 0.8482 - val_accuracy: 0.7101\n",
            "Epoch 365/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8208 - accuracy: 0.6747 - val_loss: 0.8446 - val_accuracy: 0.7101\n",
            "Epoch 366/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8393 - accuracy: 0.6614 - val_loss: 0.8350 - val_accuracy: 0.7295\n",
            "Epoch 367/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8413 - accuracy: 0.6602 - val_loss: 0.8350 - val_accuracy: 0.7198\n",
            "Epoch 368/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8299 - accuracy: 0.6820 - val_loss: 0.8372 - val_accuracy: 0.7150\n",
            "Epoch 369/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7942 - accuracy: 0.6802 - val_loss: 0.8175 - val_accuracy: 0.7246\n",
            "Epoch 370/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8216 - accuracy: 0.6765 - val_loss: 0.8536 - val_accuracy: 0.6618\n",
            "Epoch 371/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8286 - accuracy: 0.6880 - val_loss: 0.8363 - val_accuracy: 0.6860\n",
            "Epoch 372/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8442 - accuracy: 0.6584 - val_loss: 0.8402 - val_accuracy: 0.7053\n",
            "Epoch 373/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8158 - accuracy: 0.6663 - val_loss: 0.8327 - val_accuracy: 0.7198\n",
            "Epoch 374/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8175 - accuracy: 0.6880 - val_loss: 0.8077 - val_accuracy: 0.7198\n",
            "Epoch 375/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8102 - accuracy: 0.6747 - val_loss: 0.8215 - val_accuracy: 0.6957\n",
            "Epoch 376/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8137 - accuracy: 0.6778 - val_loss: 0.8158 - val_accuracy: 0.7101\n",
            "Epoch 377/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8191 - accuracy: 0.6826 - val_loss: 0.8301 - val_accuracy: 0.7101\n",
            "Epoch 378/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8110 - accuracy: 0.6747 - val_loss: 0.8085 - val_accuracy: 0.6957\n",
            "Epoch 379/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8153 - accuracy: 0.6747 - val_loss: 0.8070 - val_accuracy: 0.7150\n",
            "Epoch 380/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.8125 - accuracy: 0.6693 - val_loss: 0.8228 - val_accuracy: 0.7005\n",
            "Epoch 381/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8022 - accuracy: 0.6941 - val_loss: 0.8089 - val_accuracy: 0.7005\n",
            "Epoch 382/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8055 - accuracy: 0.6923 - val_loss: 0.8083 - val_accuracy: 0.7053\n",
            "Epoch 383/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8124 - accuracy: 0.6717 - val_loss: 0.8158 - val_accuracy: 0.7198\n",
            "Epoch 384/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8068 - accuracy: 0.6844 - val_loss: 0.7855 - val_accuracy: 0.7633\n",
            "Epoch 385/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8100 - accuracy: 0.6802 - val_loss: 0.8000 - val_accuracy: 0.7198\n",
            "Epoch 386/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7949 - accuracy: 0.6838 - val_loss: 0.8108 - val_accuracy: 0.7053\n",
            "Epoch 387/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7881 - accuracy: 0.6880 - val_loss: 0.8077 - val_accuracy: 0.7150\n",
            "Epoch 388/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8173 - accuracy: 0.6675 - val_loss: 0.8033 - val_accuracy: 0.7246\n",
            "Epoch 389/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7963 - accuracy: 0.6826 - val_loss: 0.8104 - val_accuracy: 0.7246\n",
            "Epoch 390/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7831 - accuracy: 0.6868 - val_loss: 0.8097 - val_accuracy: 0.7246\n",
            "Epoch 391/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.8048 - accuracy: 0.6693 - val_loss: 0.7937 - val_accuracy: 0.7246\n",
            "Epoch 392/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8017 - accuracy: 0.6850 - val_loss: 0.8002 - val_accuracy: 0.7150\n",
            "Epoch 393/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7905 - accuracy: 0.6790 - val_loss: 0.7897 - val_accuracy: 0.7295\n",
            "Epoch 394/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8292 - accuracy: 0.6687 - val_loss: 0.8020 - val_accuracy: 0.7198\n",
            "Epoch 395/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8014 - accuracy: 0.6874 - val_loss: 0.7868 - val_accuracy: 0.7198\n",
            "Epoch 396/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7920 - accuracy: 0.6814 - val_loss: 0.8089 - val_accuracy: 0.7005\n",
            "Epoch 397/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.7912 - accuracy: 0.6929 - val_loss: 0.7827 - val_accuracy: 0.7391\n",
            "Epoch 398/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.7984 - accuracy: 0.6832 - val_loss: 0.8094 - val_accuracy: 0.7150\n",
            "Epoch 399/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7963 - accuracy: 0.6923 - val_loss: 0.7945 - val_accuracy: 0.7343\n",
            "Epoch 400/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7844 - accuracy: 0.7037 - val_loss: 0.7999 - val_accuracy: 0.7198\n",
            "Epoch 401/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.7833 - accuracy: 0.6953 - val_loss: 0.7933 - val_accuracy: 0.7101\n",
            "Epoch 402/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7712 - accuracy: 0.6989 - val_loss: 0.7906 - val_accuracy: 0.7343\n",
            "Epoch 403/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7897 - accuracy: 0.6965 - val_loss: 0.7936 - val_accuracy: 0.7053\n",
            "Epoch 404/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7837 - accuracy: 0.6977 - val_loss: 0.8061 - val_accuracy: 0.7198\n",
            "Epoch 405/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8019 - accuracy: 0.6729 - val_loss: 0.8239 - val_accuracy: 0.6908\n",
            "Epoch 406/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7821 - accuracy: 0.6850 - val_loss: 0.8073 - val_accuracy: 0.7150\n",
            "Epoch 407/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.7896 - accuracy: 0.6874 - val_loss: 0.8061 - val_accuracy: 0.7053\n",
            "Epoch 408/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7784 - accuracy: 0.6923 - val_loss: 0.8001 - val_accuracy: 0.7246\n",
            "Epoch 409/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7783 - accuracy: 0.7044 - val_loss: 0.7891 - val_accuracy: 0.7343\n",
            "Epoch 410/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7808 - accuracy: 0.6838 - val_loss: 0.7853 - val_accuracy: 0.7295\n",
            "Epoch 411/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.7770 - accuracy: 0.6886 - val_loss: 0.7910 - val_accuracy: 0.7440\n",
            "Epoch 412/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7831 - accuracy: 0.6941 - val_loss: 0.7889 - val_accuracy: 0.7295\n",
            "Epoch 413/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7735 - accuracy: 0.6886 - val_loss: 0.7919 - val_accuracy: 0.7101\n",
            "Epoch 414/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.7725 - accuracy: 0.6995 - val_loss: 0.7862 - val_accuracy: 0.7150\n",
            "Epoch 415/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.7475 - accuracy: 0.7104 - val_loss: 0.8009 - val_accuracy: 0.7053\n",
            "Epoch 416/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7620 - accuracy: 0.6995 - val_loss: 0.7936 - val_accuracy: 0.7246\n",
            "Epoch 417/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7759 - accuracy: 0.6995 - val_loss: 0.8018 - val_accuracy: 0.7295\n",
            "Epoch 418/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7660 - accuracy: 0.6923 - val_loss: 0.7898 - val_accuracy: 0.7246\n",
            "Epoch 419/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7458 - accuracy: 0.6953 - val_loss: 0.8098 - val_accuracy: 0.6957\n",
            "Epoch 420/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7391 - accuracy: 0.7183 - val_loss: 0.7840 - val_accuracy: 0.7295\n",
            "Epoch 421/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7671 - accuracy: 0.6844 - val_loss: 0.7696 - val_accuracy: 0.7391\n",
            "Epoch 422/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7808 - accuracy: 0.6796 - val_loss: 0.7979 - val_accuracy: 0.7053\n",
            "Epoch 423/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.7410 - accuracy: 0.7001 - val_loss: 0.7693 - val_accuracy: 0.7343\n",
            "Epoch 424/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7683 - accuracy: 0.7031 - val_loss: 0.7811 - val_accuracy: 0.7150\n",
            "Epoch 425/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7801 - accuracy: 0.6856 - val_loss: 0.7875 - val_accuracy: 0.7101\n",
            "Epoch 426/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7625 - accuracy: 0.6965 - val_loss: 0.8007 - val_accuracy: 0.7198\n",
            "Epoch 427/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7755 - accuracy: 0.6929 - val_loss: 0.7790 - val_accuracy: 0.7150\n",
            "Epoch 428/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7737 - accuracy: 0.6844 - val_loss: 0.7692 - val_accuracy: 0.7391\n",
            "Epoch 429/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7477 - accuracy: 0.7037 - val_loss: 0.7789 - val_accuracy: 0.7391\n",
            "Epoch 430/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7728 - accuracy: 0.6898 - val_loss: 0.7774 - val_accuracy: 0.7343\n",
            "Epoch 431/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7597 - accuracy: 0.7056 - val_loss: 0.8165 - val_accuracy: 0.7005\n",
            "Epoch 432/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7565 - accuracy: 0.6971 - val_loss: 0.7720 - val_accuracy: 0.7295\n",
            "Epoch 433/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7514 - accuracy: 0.7092 - val_loss: 0.7657 - val_accuracy: 0.7391\n",
            "Epoch 434/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.7311 - accuracy: 0.7128 - val_loss: 0.7606 - val_accuracy: 0.7440\n",
            "Epoch 435/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7697 - accuracy: 0.6983 - val_loss: 0.7637 - val_accuracy: 0.7343\n",
            "Epoch 436/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.7309 - accuracy: 0.7164 - val_loss: 0.7799 - val_accuracy: 0.7295\n",
            "Epoch 437/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7528 - accuracy: 0.6935 - val_loss: 0.7745 - val_accuracy: 0.7295\n",
            "Epoch 438/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7426 - accuracy: 0.7146 - val_loss: 0.7841 - val_accuracy: 0.7198\n",
            "Epoch 439/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7478 - accuracy: 0.6923 - val_loss: 0.7636 - val_accuracy: 0.7488\n",
            "Epoch 440/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.7313 - accuracy: 0.7219 - val_loss: 0.7522 - val_accuracy: 0.7440\n",
            "Epoch 441/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7555 - accuracy: 0.6959 - val_loss: 0.7593 - val_accuracy: 0.7295\n",
            "Epoch 442/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7304 - accuracy: 0.7116 - val_loss: 0.7558 - val_accuracy: 0.7488\n",
            "Epoch 443/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.7473 - accuracy: 0.7116 - val_loss: 0.7579 - val_accuracy: 0.7536\n",
            "Epoch 444/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7365 - accuracy: 0.7013 - val_loss: 0.7703 - val_accuracy: 0.7440\n",
            "Epoch 445/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7401 - accuracy: 0.7152 - val_loss: 0.7569 - val_accuracy: 0.7440\n",
            "Epoch 446/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.7407 - accuracy: 0.7158 - val_loss: 0.7688 - val_accuracy: 0.7343\n",
            "Epoch 447/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.7438 - accuracy: 0.7019 - val_loss: 0.7490 - val_accuracy: 0.7488\n",
            "Epoch 448/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.7597 - accuracy: 0.6935 - val_loss: 0.7541 - val_accuracy: 0.7391\n",
            "Epoch 449/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.7361 - accuracy: 0.7164 - val_loss: 0.7652 - val_accuracy: 0.7391\n",
            "Epoch 450/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7133 - accuracy: 0.7261 - val_loss: 0.7588 - val_accuracy: 0.7488\n",
            "Epoch 451/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.7480 - accuracy: 0.7037 - val_loss: 0.7955 - val_accuracy: 0.6957\n",
            "Epoch 452/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7331 - accuracy: 0.7013 - val_loss: 0.7852 - val_accuracy: 0.7101\n",
            "Epoch 453/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.7461 - accuracy: 0.7013 - val_loss: 0.7696 - val_accuracy: 0.7295\n",
            "Epoch 454/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7348 - accuracy: 0.7080 - val_loss: 0.7598 - val_accuracy: 0.7295\n",
            "Epoch 455/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7248 - accuracy: 0.7044 - val_loss: 0.7728 - val_accuracy: 0.7246\n",
            "Epoch 456/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.7143 - accuracy: 0.7195 - val_loss: 0.7754 - val_accuracy: 0.7295\n",
            "Epoch 457/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7048 - accuracy: 0.7304 - val_loss: 0.7743 - val_accuracy: 0.7150\n",
            "Epoch 458/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7169 - accuracy: 0.7189 - val_loss: 0.7694 - val_accuracy: 0.7246\n",
            "Epoch 459/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7064 - accuracy: 0.7297 - val_loss: 0.7673 - val_accuracy: 0.7295\n",
            "Epoch 460/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7066 - accuracy: 0.7334 - val_loss: 0.7624 - val_accuracy: 0.7198\n",
            "Epoch 461/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7299 - accuracy: 0.7074 - val_loss: 0.7515 - val_accuracy: 0.7343\n",
            "Epoch 462/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.7325 - accuracy: 0.6989 - val_loss: 0.7702 - val_accuracy: 0.7343\n",
            "Epoch 463/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.7057 - accuracy: 0.7231 - val_loss: 0.7707 - val_accuracy: 0.7343\n",
            "Epoch 464/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7283 - accuracy: 0.7146 - val_loss: 0.7684 - val_accuracy: 0.7343\n",
            "Epoch 465/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.7202 - accuracy: 0.7050 - val_loss: 0.7559 - val_accuracy: 0.7150\n",
            "Epoch 466/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.7087 - accuracy: 0.7189 - val_loss: 0.7736 - val_accuracy: 0.7246\n",
            "Epoch 467/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.7182 - accuracy: 0.7152 - val_loss: 0.7462 - val_accuracy: 0.7246\n",
            "Epoch 468/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6999 - accuracy: 0.7213 - val_loss: 0.7830 - val_accuracy: 0.7101\n",
            "Epoch 469/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.7207 - accuracy: 0.7104 - val_loss: 0.7635 - val_accuracy: 0.7198\n",
            "Epoch 470/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.7237 - accuracy: 0.7177 - val_loss: 0.7653 - val_accuracy: 0.7198\n",
            "Epoch 471/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7077 - accuracy: 0.7255 - val_loss: 0.7571 - val_accuracy: 0.7391\n",
            "Epoch 472/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6854 - accuracy: 0.7273 - val_loss: 0.7613 - val_accuracy: 0.7295\n",
            "Epoch 473/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7142 - accuracy: 0.7183 - val_loss: 0.7556 - val_accuracy: 0.7343\n",
            "Epoch 474/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7159 - accuracy: 0.7092 - val_loss: 0.7457 - val_accuracy: 0.7343\n",
            "Epoch 475/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7222 - accuracy: 0.7177 - val_loss: 0.7616 - val_accuracy: 0.7391\n",
            "Epoch 476/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.7034 - accuracy: 0.7164 - val_loss: 0.7583 - val_accuracy: 0.7343\n",
            "Epoch 477/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7149 - accuracy: 0.7116 - val_loss: 0.7360 - val_accuracy: 0.7343\n",
            "Epoch 478/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6773 - accuracy: 0.7316 - val_loss: 0.7367 - val_accuracy: 0.7246\n",
            "Epoch 479/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6968 - accuracy: 0.7207 - val_loss: 0.7515 - val_accuracy: 0.7343\n",
            "Epoch 480/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.7092 - accuracy: 0.7164 - val_loss: 0.7639 - val_accuracy: 0.7343\n",
            "Epoch 481/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.7202 - accuracy: 0.7243 - val_loss: 0.7304 - val_accuracy: 0.7536\n",
            "Epoch 482/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6891 - accuracy: 0.7273 - val_loss: 0.7453 - val_accuracy: 0.7440\n",
            "Epoch 483/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6978 - accuracy: 0.7213 - val_loss: 0.7362 - val_accuracy: 0.7536\n",
            "Epoch 484/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6906 - accuracy: 0.7225 - val_loss: 0.7478 - val_accuracy: 0.7440\n",
            "Epoch 485/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6730 - accuracy: 0.7437 - val_loss: 0.7723 - val_accuracy: 0.6957\n",
            "Epoch 486/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7182 - accuracy: 0.7249 - val_loss: 0.7669 - val_accuracy: 0.7101\n",
            "Epoch 487/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6860 - accuracy: 0.7310 - val_loss: 0.7352 - val_accuracy: 0.7391\n",
            "Epoch 488/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6907 - accuracy: 0.7207 - val_loss: 0.7482 - val_accuracy: 0.7246\n",
            "Epoch 489/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6906 - accuracy: 0.7358 - val_loss: 0.7573 - val_accuracy: 0.7488\n",
            "Epoch 490/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.7015 - accuracy: 0.7304 - val_loss: 0.7475 - val_accuracy: 0.7440\n",
            "Epoch 491/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.7331 - accuracy: 0.7122 - val_loss: 0.7432 - val_accuracy: 0.7343\n",
            "Epoch 492/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.7073 - accuracy: 0.7285 - val_loss: 0.7371 - val_accuracy: 0.7391\n",
            "Epoch 493/1000\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.6691 - accuracy: 0.7334 - val_loss: 0.7336 - val_accuracy: 0.7343\n",
            "Epoch 494/1000\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.6803 - accuracy: 0.7346 - val_loss: 0.7403 - val_accuracy: 0.7343\n",
            "Epoch 495/1000\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.6815 - accuracy: 0.7291 - val_loss: 0.7386 - val_accuracy: 0.7150\n",
            "Epoch 496/1000\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.6870 - accuracy: 0.7340 - val_loss: 0.7319 - val_accuracy: 0.7295\n",
            "Epoch 497/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6976 - accuracy: 0.7285 - val_loss: 0.7345 - val_accuracy: 0.7488\n",
            "Epoch 498/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6809 - accuracy: 0.7316 - val_loss: 0.7505 - val_accuracy: 0.7343\n",
            "Epoch 499/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.7060 - accuracy: 0.7285 - val_loss: 0.7391 - val_accuracy: 0.7295\n",
            "Epoch 500/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.7036 - accuracy: 0.7207 - val_loss: 0.7305 - val_accuracy: 0.7391\n",
            "Epoch 501/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6831 - accuracy: 0.7334 - val_loss: 0.7448 - val_accuracy: 0.7295\n",
            "Epoch 502/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.7106 - accuracy: 0.7140 - val_loss: 0.7349 - val_accuracy: 0.7536\n",
            "Epoch 503/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6652 - accuracy: 0.7376 - val_loss: 0.7350 - val_accuracy: 0.7440\n",
            "Epoch 504/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6844 - accuracy: 0.7340 - val_loss: 0.7304 - val_accuracy: 0.7536\n",
            "Epoch 505/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6817 - accuracy: 0.7364 - val_loss: 0.7285 - val_accuracy: 0.7536\n",
            "Epoch 506/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6955 - accuracy: 0.7304 - val_loss: 0.7336 - val_accuracy: 0.7391\n",
            "Epoch 507/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6914 - accuracy: 0.7140 - val_loss: 0.7298 - val_accuracy: 0.7488\n",
            "Epoch 508/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6805 - accuracy: 0.7304 - val_loss: 0.7560 - val_accuracy: 0.7343\n",
            "Epoch 509/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6661 - accuracy: 0.7370 - val_loss: 0.7203 - val_accuracy: 0.7440\n",
            "Epoch 510/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6557 - accuracy: 0.7388 - val_loss: 0.7141 - val_accuracy: 0.7488\n",
            "Epoch 511/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6765 - accuracy: 0.7346 - val_loss: 0.7442 - val_accuracy: 0.7295\n",
            "Epoch 512/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6653 - accuracy: 0.7297 - val_loss: 0.7146 - val_accuracy: 0.7633\n",
            "Epoch 513/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6833 - accuracy: 0.7267 - val_loss: 0.7314 - val_accuracy: 0.7391\n",
            "Epoch 514/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6690 - accuracy: 0.7352 - val_loss: 0.7436 - val_accuracy: 0.7391\n",
            "Epoch 515/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6555 - accuracy: 0.7539 - val_loss: 0.7269 - val_accuracy: 0.7391\n",
            "Epoch 516/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6752 - accuracy: 0.7382 - val_loss: 0.7317 - val_accuracy: 0.7440\n",
            "Epoch 517/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6563 - accuracy: 0.7328 - val_loss: 0.7245 - val_accuracy: 0.7440\n",
            "Epoch 518/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6472 - accuracy: 0.7449 - val_loss: 0.7130 - val_accuracy: 0.7488\n",
            "Epoch 519/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6880 - accuracy: 0.7297 - val_loss: 0.7276 - val_accuracy: 0.7440\n",
            "Epoch 520/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6658 - accuracy: 0.7334 - val_loss: 0.7184 - val_accuracy: 0.7246\n",
            "Epoch 521/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6835 - accuracy: 0.7195 - val_loss: 0.7237 - val_accuracy: 0.7729\n",
            "Epoch 522/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6618 - accuracy: 0.7449 - val_loss: 0.7252 - val_accuracy: 0.7391\n",
            "Epoch 523/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6496 - accuracy: 0.7467 - val_loss: 0.7323 - val_accuracy: 0.7343\n",
            "Epoch 524/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6498 - accuracy: 0.7563 - val_loss: 0.7475 - val_accuracy: 0.7198\n",
            "Epoch 525/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6512 - accuracy: 0.7527 - val_loss: 0.7231 - val_accuracy: 0.7440\n",
            "Epoch 526/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6552 - accuracy: 0.7443 - val_loss: 0.7352 - val_accuracy: 0.7391\n",
            "Epoch 527/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6766 - accuracy: 0.7328 - val_loss: 0.7397 - val_accuracy: 0.7488\n",
            "Epoch 528/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6593 - accuracy: 0.7430 - val_loss: 0.7434 - val_accuracy: 0.7343\n",
            "Epoch 529/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6791 - accuracy: 0.7291 - val_loss: 0.7323 - val_accuracy: 0.7440\n",
            "Epoch 530/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6656 - accuracy: 0.7213 - val_loss: 0.7297 - val_accuracy: 0.7536\n",
            "Epoch 531/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6778 - accuracy: 0.7388 - val_loss: 0.7193 - val_accuracy: 0.7391\n",
            "Epoch 532/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6546 - accuracy: 0.7515 - val_loss: 0.7319 - val_accuracy: 0.7295\n",
            "Epoch 533/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6152 - accuracy: 0.7612 - val_loss: 0.7259 - val_accuracy: 0.7246\n",
            "Epoch 534/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6690 - accuracy: 0.7364 - val_loss: 0.7453 - val_accuracy: 0.7343\n",
            "Epoch 535/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6573 - accuracy: 0.7503 - val_loss: 0.7413 - val_accuracy: 0.7391\n",
            "Epoch 536/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6731 - accuracy: 0.7231 - val_loss: 0.7342 - val_accuracy: 0.7440\n",
            "Epoch 537/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6535 - accuracy: 0.7364 - val_loss: 0.7271 - val_accuracy: 0.7488\n",
            "Epoch 538/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6375 - accuracy: 0.7503 - val_loss: 0.7210 - val_accuracy: 0.7440\n",
            "Epoch 539/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6553 - accuracy: 0.7388 - val_loss: 0.7298 - val_accuracy: 0.7343\n",
            "Epoch 540/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6576 - accuracy: 0.7473 - val_loss: 0.7239 - val_accuracy: 0.7681\n",
            "Epoch 541/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6362 - accuracy: 0.7503 - val_loss: 0.7252 - val_accuracy: 0.7391\n",
            "Epoch 542/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6385 - accuracy: 0.7545 - val_loss: 0.7120 - val_accuracy: 0.7391\n",
            "Epoch 543/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6439 - accuracy: 0.7394 - val_loss: 0.7166 - val_accuracy: 0.7440\n",
            "Epoch 544/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6473 - accuracy: 0.7352 - val_loss: 0.7304 - val_accuracy: 0.7391\n",
            "Epoch 545/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6341 - accuracy: 0.7551 - val_loss: 0.7283 - val_accuracy: 0.7440\n",
            "Epoch 546/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6396 - accuracy: 0.7497 - val_loss: 0.7121 - val_accuracy: 0.7681\n",
            "Epoch 547/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6362 - accuracy: 0.7503 - val_loss: 0.7231 - val_accuracy: 0.7440\n",
            "Epoch 548/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6513 - accuracy: 0.7437 - val_loss: 0.6992 - val_accuracy: 0.7536\n",
            "Epoch 549/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6435 - accuracy: 0.7515 - val_loss: 0.7240 - val_accuracy: 0.7343\n",
            "Epoch 550/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6627 - accuracy: 0.7370 - val_loss: 0.7214 - val_accuracy: 0.7536\n",
            "Epoch 551/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6416 - accuracy: 0.7455 - val_loss: 0.7369 - val_accuracy: 0.7440\n",
            "Epoch 552/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6396 - accuracy: 0.7588 - val_loss: 0.7167 - val_accuracy: 0.7343\n",
            "Epoch 553/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6408 - accuracy: 0.7455 - val_loss: 0.7359 - val_accuracy: 0.7246\n",
            "Epoch 554/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5953 - accuracy: 0.7588 - val_loss: 0.7039 - val_accuracy: 0.7391\n",
            "Epoch 555/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6301 - accuracy: 0.7497 - val_loss: 0.7147 - val_accuracy: 0.7488\n",
            "Epoch 556/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6347 - accuracy: 0.7461 - val_loss: 0.7294 - val_accuracy: 0.7246\n",
            "Epoch 557/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6203 - accuracy: 0.7570 - val_loss: 0.7160 - val_accuracy: 0.7391\n",
            "Epoch 558/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6340 - accuracy: 0.7455 - val_loss: 0.7123 - val_accuracy: 0.7536\n",
            "Epoch 559/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6166 - accuracy: 0.7479 - val_loss: 0.7211 - val_accuracy: 0.7536\n",
            "Epoch 560/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6228 - accuracy: 0.7527 - val_loss: 0.6998 - val_accuracy: 0.7488\n",
            "Epoch 561/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6255 - accuracy: 0.7684 - val_loss: 0.7021 - val_accuracy: 0.7536\n",
            "Epoch 562/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6281 - accuracy: 0.7412 - val_loss: 0.7030 - val_accuracy: 0.7391\n",
            "Epoch 563/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6437 - accuracy: 0.7582 - val_loss: 0.7256 - val_accuracy: 0.7488\n",
            "Epoch 564/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6349 - accuracy: 0.7539 - val_loss: 0.6950 - val_accuracy: 0.7536\n",
            "Epoch 565/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6281 - accuracy: 0.7576 - val_loss: 0.7084 - val_accuracy: 0.7343\n",
            "Epoch 566/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6373 - accuracy: 0.7515 - val_loss: 0.7514 - val_accuracy: 0.7440\n",
            "Epoch 567/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6356 - accuracy: 0.7672 - val_loss: 0.7155 - val_accuracy: 0.7440\n",
            "Epoch 568/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6005 - accuracy: 0.7570 - val_loss: 0.7156 - val_accuracy: 0.7488\n",
            "Epoch 569/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6260 - accuracy: 0.7594 - val_loss: 0.7090 - val_accuracy: 0.7536\n",
            "Epoch 570/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6169 - accuracy: 0.7612 - val_loss: 0.7117 - val_accuracy: 0.7391\n",
            "Epoch 571/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5959 - accuracy: 0.7618 - val_loss: 0.7176 - val_accuracy: 0.7440\n",
            "Epoch 572/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6311 - accuracy: 0.7551 - val_loss: 0.7172 - val_accuracy: 0.7488\n",
            "Epoch 573/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6106 - accuracy: 0.7660 - val_loss: 0.6967 - val_accuracy: 0.7585\n",
            "Epoch 574/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6219 - accuracy: 0.7521 - val_loss: 0.7235 - val_accuracy: 0.7536\n",
            "Epoch 575/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6107 - accuracy: 0.7600 - val_loss: 0.7015 - val_accuracy: 0.7633\n",
            "Epoch 576/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6278 - accuracy: 0.7539 - val_loss: 0.7046 - val_accuracy: 0.7536\n",
            "Epoch 577/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6103 - accuracy: 0.7642 - val_loss: 0.7267 - val_accuracy: 0.7391\n",
            "Epoch 578/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6181 - accuracy: 0.7594 - val_loss: 0.7220 - val_accuracy: 0.7536\n",
            "Epoch 579/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6147 - accuracy: 0.7709 - val_loss: 0.7178 - val_accuracy: 0.7295\n",
            "Epoch 580/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6146 - accuracy: 0.7606 - val_loss: 0.7165 - val_accuracy: 0.7536\n",
            "Epoch 581/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6088 - accuracy: 0.7678 - val_loss: 0.7195 - val_accuracy: 0.7536\n",
            "Epoch 582/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6054 - accuracy: 0.7739 - val_loss: 0.7121 - val_accuracy: 0.7536\n",
            "Epoch 583/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6143 - accuracy: 0.7582 - val_loss: 0.6988 - val_accuracy: 0.7585\n",
            "Epoch 584/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6028 - accuracy: 0.7672 - val_loss: 0.7299 - val_accuracy: 0.7391\n",
            "Epoch 585/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6379 - accuracy: 0.7491 - val_loss: 0.7020 - val_accuracy: 0.7585\n",
            "Epoch 586/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6063 - accuracy: 0.7660 - val_loss: 0.7336 - val_accuracy: 0.7246\n",
            "Epoch 587/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6126 - accuracy: 0.7557 - val_loss: 0.7181 - val_accuracy: 0.7585\n",
            "Epoch 588/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6096 - accuracy: 0.7612 - val_loss: 0.7073 - val_accuracy: 0.7536\n",
            "Epoch 589/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6169 - accuracy: 0.7727 - val_loss: 0.7296 - val_accuracy: 0.7391\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(cnnhistory.history['loss'])\n",
        "plt.plot(cnnhistory.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train','test'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "oQYnuaCrDH_A",
        "outputId": "3796aefb-08c4-4034-f9ed-2ea44a263035"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(cnnhistory.history['accuracy'])\n",
        "plt.plot(cnnhistory.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train','test'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "IFkTuO8nDNdq",
        "outputId": "d8d7b31d-2b4f-446f-9655-caf313b6afa4"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model.predict(x_testcnn)"
      ],
      "metadata": {
        "id": "A2xtrN5wDQgY"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_f_ohjXKDUpY",
        "outputId": "213e1a11-5dda-4ca2-adf7-d626de5a7d01"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.9826967e-01, 9.1830865e-02, 2.1537334e-01, 2.7873304e-01,\n",
              "        1.3722652e-01, 7.8566574e-02],\n",
              "       [3.3484909e-04, 2.3189232e-05, 5.5865366e-06, 9.9021101e-01,\n",
              "        8.8835100e-04, 8.5370969e-03],\n",
              "       [1.5618402e-01, 1.0971424e-01, 1.6980305e-01, 2.5324002e-01,\n",
              "        7.0408158e-02, 2.4065046e-01],\n",
              "       ...,\n",
              "       [1.0547664e-03, 1.4675185e-06, 1.6876971e-03, 2.9982380e-03,\n",
              "        9.8761708e-01, 6.6406946e-03],\n",
              "       [8.0330596e-05, 6.0536999e-01, 3.7016228e-01, 1.4838907e-02,\n",
              "        4.3552602e-03, 5.1933071e-03],\n",
              "       [6.9067151e-05, 6.4784523e-05, 1.3429062e-02, 7.2116754e-04,\n",
              "        9.7629637e-01, 9.4195195e-03]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cmA2bFgsDW3D",
        "outputId": "89c753d0-1e63-4c3e-93cc-d71550a45bc7"
      },
      "execution_count": 19,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([3, 3, 3, 0, 4, 4, 1, 2, 5, 0, 5, 3, 2, 2, 1, 4, 4, 5, 2, 4, 1, 2,\n",
              "       3, 5, 4, 2, 1, 2, 2, 2, 2, 5, 2, 5, 3, 1, 2, 0, 4, 5, 2, 3, 2, 2,\n",
              "       5, 2, 0, 1, 3, 4, 4, 5, 1, 1, 4, 4, 5, 1, 1, 1, 0, 1, 5, 0, 4, 1,\n",
              "       1, 0, 1, 4, 1, 0, 4, 1, 3, 1, 2, 2, 1, 2, 3, 0, 5, 3, 5, 5, 2, 4,\n",
              "       5, 1, 5, 1, 5, 3, 4, 1, 4, 1, 5, 4, 5, 1, 2, 1, 1, 5, 1, 3, 2, 5,\n",
              "       2, 1, 3, 5, 4, 4, 0, 0, 3, 1, 2, 2, 3, 5, 1, 5, 3, 4, 2, 2, 0, 2,\n",
              "       2, 5, 5, 0, 3, 3, 2, 2, 0, 3, 4, 0, 4, 2, 4, 5, 4, 1, 5, 3, 2, 2,\n",
              "       5, 4, 3, 3, 4, 3, 3, 4, 1, 5, 2, 3, 2, 2, 0, 2, 1, 3, 1, 2, 2, 5,\n",
              "       5, 1, 4, 2, 2, 1, 1, 3, 3, 5, 5, 2, 5, 1, 5, 0, 3, 3, 0, 5, 1, 4,\n",
              "       1, 4, 2, 5, 5, 1, 4, 2, 4])"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_Ytest = y_test.astype(int)"
      ],
      "metadata": {
        "id": "0PHDKWJWDY3g"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_Ytest"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k68v2i-pDbZE",
        "outputId": "b1671022-8876-451e-cc94-40f93919191e"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([3, 3, 3, 0, 4, 4, 1, 2, 5, 0, 5, 3, 2, 2, 1, 4, 4, 5, 2, 4, 1, 2,\n",
              "       3, 5, 4, 2, 1, 2, 2, 2, 2, 5, 2, 5, 3, 1, 2, 0, 4, 5, 2, 3, 2, 2,\n",
              "       5, 2, 0, 1, 3, 4, 4, 5, 1, 1, 4, 4, 5, 1, 1, 1, 0, 1, 5, 0, 4, 1,\n",
              "       1, 0, 1, 4, 1, 0, 4, 1, 3, 1, 2, 2, 1, 2, 3, 0, 5, 3, 5, 5, 2, 4,\n",
              "       5, 1, 5, 1, 5, 3, 4, 1, 4, 1, 5, 4, 5, 1, 2, 1, 1, 5, 1, 3, 2, 5,\n",
              "       2, 1, 3, 5, 4, 4, 0, 0, 3, 1, 2, 2, 3, 5, 1, 5, 3, 4, 2, 2, 0, 2,\n",
              "       2, 5, 5, 0, 3, 3, 2, 2, 0, 3, 4, 0, 4, 2, 4, 5, 4, 1, 5, 3, 2, 2,\n",
              "       5, 4, 3, 3, 4, 3, 3, 4, 1, 5, 2, 3, 2, 2, 0, 2, 1, 3, 1, 2, 2, 5,\n",
              "       5, 1, 4, 2, 2, 1, 1, 3, 3, 5, 5, 2, 5, 1, 5, 0, 3, 3, 0, 5, 1, 4,\n",
              "       1, 4, 2, 5, 5, 1, 4, 2, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds1=predictions.argmax(axis=1)\n",
        "preds1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4_cAI39VFhtp",
        "outputId": "59e28f20-503e-4101-82dc-46fbf3fde478"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([3, 3, 3, 0, 4, 4, 1, 2, 5, 1, 4, 3, 2, 2, 0, 3, 4, 3, 3, 4, 0, 2,\n",
              "       2, 3, 4, 2, 1, 0, 4, 2, 2, 5, 2, 5, 3, 1, 2, 0, 4, 5, 2, 3, 2, 2,\n",
              "       3, 2, 1, 1, 3, 4, 4, 2, 1, 1, 4, 4, 5, 1, 1, 1, 3, 1, 2, 0, 4, 1,\n",
              "       1, 1, 1, 4, 0, 5, 4, 3, 5, 5, 2, 2, 2, 2, 1, 0, 5, 3, 5, 5, 2, 5,\n",
              "       3, 1, 5, 1, 3, 3, 2, 2, 4, 1, 5, 4, 5, 1, 2, 1, 1, 5, 1, 5, 2, 5,\n",
              "       5, 0, 3, 5, 4, 4, 3, 0, 3, 1, 1, 2, 1, 3, 1, 3, 3, 5, 2, 2, 1, 4,\n",
              "       2, 3, 3, 0, 3, 3, 2, 4, 0, 5, 4, 0, 4, 4, 4, 5, 4, 1, 5, 3, 2, 2,\n",
              "       5, 4, 4, 3, 4, 5, 3, 4, 2, 5, 2, 3, 2, 2, 0, 2, 1, 3, 1, 4, 4, 5,\n",
              "       5, 1, 4, 2, 4, 1, 1, 3, 3, 5, 5, 2, 3, 1, 4, 1, 3, 3, 5, 4, 1, 4,\n",
              "       1, 3, 3, 2, 4, 2, 4, 1, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "abc = preds1.astype(int).flatten()"
      ],
      "metadata": {
        "id": "H4WEmM60NfQn"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "c = confusion_matrix(new_Ytest, abc) \n",
        "c"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bKEBeEBlFjB8",
        "outputId": "e074008b-465a-41a1-cfbb-5eda5d7ac6d5"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 9,  5,  0,  2,  0,  2],\n",
              "       [ 4, 31,  4,  1,  0,  1],\n",
              "       [ 1,  2, 32,  2,  7,  1],\n",
              "       [ 0,  2,  1, 23,  1,  4],\n",
              "       [ 0,  0,  1,  2, 28,  2],\n",
              "       [ 0,  0,  3, 10,  4, 22]])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m4RjG7LWLSQx",
        "outputId": "defd93bd-64a4-49a9-fd1f-5b117f36579f"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([3, 3, 3, 0, 4, 4, 1, 2, 5, 0, 5, 3, 2, 2, 1, 4, 4, 5, 2, 4, 1, 2,\n",
              "       3, 5, 4, 2, 1, 2, 2, 2, 2, 5, 2, 5, 3, 1, 2, 0, 4, 5, 2, 3, 2, 2,\n",
              "       5, 2, 0, 1, 3, 4, 4, 5, 1, 1, 4, 4, 5, 1, 1, 1, 0, 1, 5, 0, 4, 1,\n",
              "       1, 0, 1, 4, 1, 0, 4, 1, 3, 1, 2, 2, 1, 2, 3, 0, 5, 3, 5, 5, 2, 4,\n",
              "       5, 1, 5, 1, 5, 3, 4, 1, 4, 1, 5, 4, 5, 1, 2, 1, 1, 5, 1, 3, 2, 5,\n",
              "       2, 1, 3, 5, 4, 4, 0, 0, 3, 1, 2, 2, 3, 5, 1, 5, 3, 4, 2, 2, 0, 2,\n",
              "       2, 5, 5, 0, 3, 3, 2, 2, 0, 3, 4, 0, 4, 2, 4, 5, 4, 1, 5, 3, 2, 2,\n",
              "       5, 4, 3, 3, 4, 3, 3, 4, 1, 5, 2, 3, 2, 2, 0, 2, 1, 3, 1, 2, 2, 5,\n",
              "       5, 1, 4, 2, 2, 1, 1, 3, 3, 5, 5, 2, 5, 1, 5, 0, 3, 3, 0, 5, 1, 4,\n",
              "       1, 4, 2, 5, 5, 1, 4, 2, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss, acc =model.evaluate(x_testcnn, y_test)\n",
        "print(\"Restored model, accuracy: {:5.2f}%\".format(100*acc))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n3kzoqPkDqqS",
        "outputId": "dd6c115a-a2d5-4479-e64d-c8e5607a58f3"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7/7 [==============================] - 0s 3ms/step - loss: 0.7343 - accuracy: 0.7005\n",
            "Restored model, accuracy: 70.05%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss, acc =model.evaluate(X_train, y_train)\n",
        "print(\"Restored model train, accuracy: {:5.2f}%\".format(100*acc))"
      ],
      "metadata": {
        "id": "fJDTGH_OUX0z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09bd475d-467c-4393-f79b-6c76c42cad57"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5296 - accuracy: 0.8422\n",
            "Restored model train, accuracy: 84.22%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix,accuracy_score\n",
        "import seaborn as sn\n",
        "\n",
        "print(classification_report(new_Ytest,abc))\n",
        "\n",
        "acc = float(accuracy_score(new_Ytest,abc))*100\n",
        "print(\"----accuracy score %s ----\" % acc)\n",
        "\n",
        "cm = confusion_matrix(new_Ytest,abc)\n",
        "#df_cm = pd.DataFrame(cm)\n",
        "class_names = ['neutral','calm', 'happy','sad','angry', 'fearful' ]\n",
        "df_cm = pd.DataFrame(cm, index=class_names, columns=class_names,)\n",
        "sn.heatmap(df_cm, annot=True, fmt='')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 508
        },
        "id": "SfSC3El94LZg",
        "outputId": "2879aa77-9591-4bd6-8912-28d75ded6b34"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.64      0.50      0.56        18\n",
            "           1       0.78      0.76      0.77        41\n",
            "           2       0.78      0.71      0.74        45\n",
            "           3       0.57      0.74      0.65        31\n",
            "           4       0.70      0.85      0.77        33\n",
            "           5       0.69      0.56      0.62        39\n",
            "\n",
            "    accuracy                           0.70       207\n",
            "   macro avg       0.69      0.69      0.68       207\n",
            "weighted avg       0.71      0.70      0.70       207\n",
            "\n",
            "----accuracy score 70.04830917874396 ----\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "A6UOIsB2xKek"
      },
      "execution_count": 28,
      "outputs": []
    }
  ]
}