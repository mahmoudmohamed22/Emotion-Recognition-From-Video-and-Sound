{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "original_rms_0.00002_without decay_1000_3.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9SRCO-a_AlH5",
        "outputId": "8d54cad2-b616-4e4b-8784-099a88685c51"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install librosa"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Lo4mUwG9RMd",
        "outputId": "d53d0cf1-88fb-4b21-a9de-ba508535a521"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.7/dist-packages (0.8.1)\n",
            "Requirement already satisfied: decorator>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied: soundfile>=0.10.2 in /usr/local/lib/python3.7/dist-packages (from librosa) (0.10.3.post1)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.1.0)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.4.1)\n",
            "Requirement already satisfied: audioread>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (2.1.9)\n",
            "Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.0.2)\n",
            "Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.6.0)\n",
            "Requirement already satisfied: numba>=0.43.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (0.51.2)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.21.6)\n",
            "Requirement already satisfied: resampy>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from librosa) (0.2.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (21.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba>=0.43.0->librosa) (57.4.0)\n",
            "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba>=0.43.0->librosa) (0.34.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->librosa) (3.0.9)\n",
            "Requirement already satisfied: appdirs>=1.3.0 in /usr/local/lib/python3.7/dist-packages (from pooch>=1.0->librosa) (1.4.4)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from pooch>=1.0->librosa) (2.23.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2022.5.18.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2.10)\n",
            "Requirement already satisfied: six>=1.3 in /usr/local/lib/python3.7/dist-packages (from resampy>=0.2.2->librosa) (1.15.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn!=0.19.0,>=0.14.0->librosa) (3.1.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.7/dist-packages (from soundfile>=0.10.2->librosa) (1.15.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.0->soundfile>=0.10.2->librosa) (2.21)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HJjcbxwy46bG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "719890f0-d605-43b4-b713-ab048e4def4d"
      },
      "source": [
        "# Orignial Notebook: https://github.com/MITESHPUTHRANNEU/Speech-Emotion-Analyzer/blob/master/final_results_gender_test.ipynb\n",
        "# This notebook author: Reza Chu\n",
        "# Last Editing Date: 31st May 2019\n",
        "\n",
        "## Python\n",
        "import os\n",
        "import random\n",
        "import sys\n",
        "\n",
        "import IPython\n",
        "from IPython.display import Audio\n",
        "from IPython.display import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "## Package\n",
        "import glob \n",
        "import keras\n",
        "import IPython.display as ipd\n",
        "import librosa\n",
        "import librosa.display\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import plotly.graph_objs as go\n",
        "import plotly.offline as py\n",
        "import plotly.tools as tls\n",
        "import seaborn as sns\n",
        "import scipy.io.wavfile\n",
        "import tensorflow as tf\n",
        "py.init_notebook_mode(connected=True)\n",
        "\n",
        "## Keras\n",
        "from keras import regularizers\n",
        "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping\n",
        "from keras.callbacks import  History, ReduceLROnPlateau, CSVLogger\n",
        "from keras.models import Model, Sequential\n",
        "from keras.layers import Dense, Embedding, LSTM\n",
        "from keras.layers import Input, Flatten, Dropout, Activation, BatchNormalization\n",
        "from keras.layers import Conv1D, MaxPooling1D, AveragePooling1D\n",
        "from keras.preprocessing import sequence\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.utils import np_utils\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "## Sklearn\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "## Rest\n",
        "from scipy.fftpack import fft\n",
        "from scipy import signal\n",
        "from scipy.io import wavfile\n",
        "from tqdm import tqdm\n",
        "\n",
        "input_duration=3\n",
        "# % pylab inline"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "        <script type=\"text/javascript\">\n",
              "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
              "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
              "        if (typeof require !== 'undefined') {\n",
              "        require.undef(\"plotly\");\n",
              "        requirejs.config({\n",
              "            paths: {\n",
              "                'plotly': ['https://cdn.plot.ly/plotly-2.8.3.min']\n",
              "            }\n",
              "        });\n",
              "        require(['plotly'], function(Plotly) {\n",
              "            window._Plotly = Plotly;\n",
              "        });\n",
              "        }\n",
              "        </script>\n",
              "        "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Saving joblib files to not load them again with the loop above\n",
        "\n",
        "# import joblib\n",
        "\n",
        "# X_name = 'x.joblib'\n",
        "# y_name = 'y.joblib'\n",
        "# save_dir = '/content/drive/My Drive/graduation project/audio/paper_code/features'\n",
        "\n",
        "# savedX = joblib.dump(X, os.path.join(save_dir, X_name))\n",
        "# savedy = joblib.dump(y, os.path.join(save_dir, y_name))"
      ],
      "metadata": {
        "id": "UCzic8rlDcuk"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Loading saved models\n",
        "import joblib\n",
        "X = joblib.load('/content/drive/My Drive/graduation project/audio/paper_code/features/x.joblib')\n",
        "y = joblib.load('/content/drive/My Drive/graduation project/audio/paper_code/features/y.joblib')"
      ],
      "metadata": {
        "id": "Q35CN6zDrzg1"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7PSTurzjCo5K",
        "outputId": "7435bf93-ca76-4a84-a205-4e9eacba2892"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2068, 40)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.1 ,shuffle = True\n",
        "                                                    , random_state=42)\n",
        "X_train , X_valid, y_train, y_valid = train_test_split(X_train,y_train, test_size=0.1112305212 , shuffle = True \n",
        "                                                       , random_state=42)"
      ],
      "metadata": {
        "id": "Ai4Fy5cPCiq1"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "x_traincnn = np.expand_dims(X_train, axis=2)\n",
        "x_testcnn = np.expand_dims(X_test, axis=2)\n",
        "X_valid= np.expand_dims(X_valid, axis=2)"
      ],
      "metadata": {
        "id": "tp1Fm5K3CEXu"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_traincnn.shape, x_testcnn.shape , X_valid.shape\n",
        "#1861"
      ],
      "metadata": {
        "id": "RI0MxoIPBws5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b853131-7ee4-48ec-cae2-e01b8663cbe0"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1654, 40, 1), (207, 40, 1), (207, 40, 1))"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oALhiMUd9G2Y",
        "outputId": "71aee7bf-825a-455b-ad2a-ed0272e23f19"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (2.8.2+zzzcolab20220527125636)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.17.3)\n",
            "Requirement already satisfied: tensorflow-estimator<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.46.3)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.26.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (4.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (14.0.1)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.21.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow) (57.4.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.0)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.0.0)\n",
            "Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.5.3)\n",
            "Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow) (1.5.2)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.8.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (3.3.7)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.35.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.4.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.23.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.6.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (4.11.4)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (3.8.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2022.5.18.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (3.2.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from keras.preprocessing import sequence\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from keras.layers import Input, Flatten, Dropout, Activation\n",
        "from keras.layers import Conv1D, MaxPooling1D\n",
        "from keras.models import Model\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras import optimizers\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv1D(128, 8,padding='same', #classifier.add(Convolution2D(64, (3, 3), padding = 'same', input_shape = (128, 128, 3), activation = 'relu'))\n",
        "                 input_shape=(40,1)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(MaxPooling1D(pool_size=(5)))\n",
        "\n",
        "\n",
        "model.add(Conv1D(256,8,padding='same',))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(MaxPooling1D(pool_size=(5)))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(256))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(256))\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "model.add(Dense(6))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "opt = tf.keras.optimizers.RMSprop(lr=0.00002 , decay=0.0)\n",
        "#opt = tf.keras.optimizers.RMSprop(lr=0.0001, rho=0.9, epsilon=1e-07, decay=0.0)\n",
        "#opt = tf.keras.optimizers.SGD(lr=0.001, momentum=0.0, decay=0.0, nesterov=False)"
      ],
      "metadata": {
        "id": "g74fXWVAC4Cr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "61c64803-18ec-49eb-9ffa-39526971745a"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/rmsprop.py:130: UserWarning:\n",
            "\n",
            "The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H6ukOxAGC_I4",
        "outputId": "cbb481ac-6d79-443d-c8f6-ed895c8081c5"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d (Conv1D)             (None, 40, 128)           1152      \n",
            "                                                                 \n",
            " activation (Activation)     (None, 40, 128)           0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 40, 128)           0         \n",
            "                                                                 \n",
            " max_pooling1d (MaxPooling1D  (None, 8, 128)           0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv1d_1 (Conv1D)           (None, 8, 256)            262400    \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 8, 256)            0         \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 8, 256)            0         \n",
            "                                                                 \n",
            " max_pooling1d_1 (MaxPooling  (None, 1, 256)           0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 256)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 256)               65792     \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 256)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 256)               65792     \n",
            "                                                                 \n",
            " activation_3 (Activation)   (None, 256)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 6)                 1542      \n",
            "                                                                 \n",
            " activation_4 (Activation)   (None, 6)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 396,678\n",
            "Trainable params: 396,678\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='sparse_categorical_crossentropy',\n",
        "              optimizer=opt,\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "AbMlLNk4DCBM"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an Instance of Early Stopping Callback.\n",
        "early_stopping_callback = EarlyStopping(monitor = 'val_loss', patience = 25, mode = 'min', restore_best_weights = True)\n",
        "\n",
        "cnnhistory=model.fit(x_traincnn, y_train, batch_size=16, epochs=1000 , shuffle = True, \n",
        "                     validation_data=(X_valid, y_valid) \n",
        "                     , callbacks = [early_stopping_callback]\n",
        "                     )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RI1v2AuADFhy",
        "outputId": "1001fb0a-875f-460f-d8dd-36d616f78854"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "104/104 [==============================] - 4s 8ms/step - loss: 5.4730 - accuracy: 0.1778 - val_loss: 1.9770 - val_accuracy: 0.1739\n",
            "Epoch 2/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 4.3435 - accuracy: 0.1947 - val_loss: 1.8118 - val_accuracy: 0.1981\n",
            "Epoch 3/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 3.7696 - accuracy: 0.1862 - val_loss: 1.9348 - val_accuracy: 0.1884\n",
            "Epoch 4/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 3.3006 - accuracy: 0.1989 - val_loss: 1.8147 - val_accuracy: 0.2174\n",
            "Epoch 5/1000\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 3.1506 - accuracy: 0.1838 - val_loss: 1.7990 - val_accuracy: 0.2222\n",
            "Epoch 6/1000\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 2.9267 - accuracy: 0.1892 - val_loss: 1.8245 - val_accuracy: 0.2464\n",
            "Epoch 7/1000\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 2.7021 - accuracy: 0.2092 - val_loss: 1.8068 - val_accuracy: 0.2609\n",
            "Epoch 8/1000\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 2.6093 - accuracy: 0.1911 - val_loss: 1.7374 - val_accuracy: 0.2367\n",
            "Epoch 9/1000\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 2.4106 - accuracy: 0.2177 - val_loss: 1.8941 - val_accuracy: 0.1932\n",
            "Epoch 10/1000\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 2.3207 - accuracy: 0.2237 - val_loss: 1.7435 - val_accuracy: 0.2029\n",
            "Epoch 11/1000\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 2.2784 - accuracy: 0.2249 - val_loss: 1.7065 - val_accuracy: 0.3043\n",
            "Epoch 12/1000\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 2.1826 - accuracy: 0.2201 - val_loss: 1.7068 - val_accuracy: 0.3140\n",
            "Epoch 13/1000\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 2.2040 - accuracy: 0.2092 - val_loss: 1.7255 - val_accuracy: 0.2174\n",
            "Epoch 14/1000\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 2.0914 - accuracy: 0.2376 - val_loss: 1.7316 - val_accuracy: 0.1981\n",
            "Epoch 15/1000\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 2.0952 - accuracy: 0.2104 - val_loss: 1.6921 - val_accuracy: 0.2802\n",
            "Epoch 16/1000\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 2.0493 - accuracy: 0.2418 - val_loss: 1.7614 - val_accuracy: 0.1787\n",
            "Epoch 17/1000\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 2.0077 - accuracy: 0.2455 - val_loss: 1.6870 - val_accuracy: 0.3092\n",
            "Epoch 18/1000\n",
            "104/104 [==============================] - 1s 9ms/step - loss: 1.9623 - accuracy: 0.2418 - val_loss: 1.7408 - val_accuracy: 0.2222\n",
            "Epoch 19/1000\n",
            "104/104 [==============================] - 1s 9ms/step - loss: 1.9715 - accuracy: 0.2261 - val_loss: 1.7024 - val_accuracy: 0.3285\n",
            "Epoch 20/1000\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 1.9435 - accuracy: 0.2400 - val_loss: 1.6747 - val_accuracy: 0.2995\n",
            "Epoch 21/1000\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 1.9151 - accuracy: 0.2394 - val_loss: 1.6586 - val_accuracy: 0.3865\n",
            "Epoch 22/1000\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 1.8863 - accuracy: 0.2515 - val_loss: 1.6436 - val_accuracy: 0.3623\n",
            "Epoch 23/1000\n",
            "104/104 [==============================] - 1s 9ms/step - loss: 1.9068 - accuracy: 0.2406 - val_loss: 1.6308 - val_accuracy: 0.4106\n",
            "Epoch 24/1000\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 1.8936 - accuracy: 0.2352 - val_loss: 1.6387 - val_accuracy: 0.3865\n",
            "Epoch 25/1000\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 1.8696 - accuracy: 0.2503 - val_loss: 1.6489 - val_accuracy: 0.3720\n",
            "Epoch 26/1000\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 1.8138 - accuracy: 0.2582 - val_loss: 1.6503 - val_accuracy: 0.3430\n",
            "Epoch 27/1000\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 1.8187 - accuracy: 0.2636 - val_loss: 1.6322 - val_accuracy: 0.4106\n",
            "Epoch 28/1000\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 1.8098 - accuracy: 0.2715 - val_loss: 1.6249 - val_accuracy: 0.3671\n",
            "Epoch 29/1000\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 1.8039 - accuracy: 0.2727 - val_loss: 1.6200 - val_accuracy: 0.4106\n",
            "Epoch 30/1000\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 1.8072 - accuracy: 0.2618 - val_loss: 1.6313 - val_accuracy: 0.3237\n",
            "Epoch 31/1000\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 1.7893 - accuracy: 0.2642 - val_loss: 1.6338 - val_accuracy: 0.3623\n",
            "Epoch 32/1000\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 1.7626 - accuracy: 0.2793 - val_loss: 1.6236 - val_accuracy: 0.3623\n",
            "Epoch 33/1000\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 1.7354 - accuracy: 0.2751 - val_loss: 1.6341 - val_accuracy: 0.3043\n",
            "Epoch 34/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.7570 - accuracy: 0.2872 - val_loss: 1.6296 - val_accuracy: 0.2850\n",
            "Epoch 35/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.7117 - accuracy: 0.2842 - val_loss: 1.6168 - val_accuracy: 0.3478\n",
            "Epoch 36/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.7381 - accuracy: 0.2739 - val_loss: 1.6229 - val_accuracy: 0.3816\n",
            "Epoch 37/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.7287 - accuracy: 0.2678 - val_loss: 1.6125 - val_accuracy: 0.3043\n",
            "Epoch 38/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.7341 - accuracy: 0.2721 - val_loss: 1.5853 - val_accuracy: 0.4058\n",
            "Epoch 39/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.7287 - accuracy: 0.2896 - val_loss: 1.5970 - val_accuracy: 0.4058\n",
            "Epoch 40/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.7151 - accuracy: 0.3023 - val_loss: 1.5968 - val_accuracy: 0.3623\n",
            "Epoch 41/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.6813 - accuracy: 0.3144 - val_loss: 1.5854 - val_accuracy: 0.4155\n",
            "Epoch 42/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.6944 - accuracy: 0.3089 - val_loss: 1.5833 - val_accuracy: 0.3816\n",
            "Epoch 43/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.6735 - accuracy: 0.3198 - val_loss: 1.5892 - val_accuracy: 0.3527\n",
            "Epoch 44/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.7042 - accuracy: 0.2908 - val_loss: 1.5786 - val_accuracy: 0.3865\n",
            "Epoch 45/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.6673 - accuracy: 0.3150 - val_loss: 1.5691 - val_accuracy: 0.4444\n",
            "Epoch 46/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.6556 - accuracy: 0.3174 - val_loss: 1.5672 - val_accuracy: 0.4203\n",
            "Epoch 47/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.6367 - accuracy: 0.3138 - val_loss: 1.5595 - val_accuracy: 0.3961\n",
            "Epoch 48/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.6398 - accuracy: 0.3204 - val_loss: 1.5578 - val_accuracy: 0.3720\n",
            "Epoch 49/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.6373 - accuracy: 0.3210 - val_loss: 1.5546 - val_accuracy: 0.3961\n",
            "Epoch 50/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.6471 - accuracy: 0.3156 - val_loss: 1.5585 - val_accuracy: 0.4348\n",
            "Epoch 51/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.6310 - accuracy: 0.3174 - val_loss: 1.5733 - val_accuracy: 0.3430\n",
            "Epoch 52/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.6184 - accuracy: 0.3434 - val_loss: 1.5474 - val_accuracy: 0.3865\n",
            "Epoch 53/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.6222 - accuracy: 0.3398 - val_loss: 1.5509 - val_accuracy: 0.3913\n",
            "Epoch 54/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.6113 - accuracy: 0.3259 - val_loss: 1.5233 - val_accuracy: 0.4734\n",
            "Epoch 55/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.5900 - accuracy: 0.3458 - val_loss: 1.5298 - val_accuracy: 0.4348\n",
            "Epoch 56/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.6073 - accuracy: 0.3374 - val_loss: 1.5251 - val_accuracy: 0.4686\n",
            "Epoch 57/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.6081 - accuracy: 0.3513 - val_loss: 1.5373 - val_accuracy: 0.4058\n",
            "Epoch 58/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.5739 - accuracy: 0.3658 - val_loss: 1.5358 - val_accuracy: 0.4589\n",
            "Epoch 59/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.5782 - accuracy: 0.3706 - val_loss: 1.5177 - val_accuracy: 0.4106\n",
            "Epoch 60/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.5699 - accuracy: 0.3561 - val_loss: 1.5192 - val_accuracy: 0.4541\n",
            "Epoch 61/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.5758 - accuracy: 0.3489 - val_loss: 1.5186 - val_accuracy: 0.4300\n",
            "Epoch 62/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.5627 - accuracy: 0.3543 - val_loss: 1.4977 - val_accuracy: 0.4831\n",
            "Epoch 63/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.5638 - accuracy: 0.3549 - val_loss: 1.5189 - val_accuracy: 0.4155\n",
            "Epoch 64/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.5697 - accuracy: 0.3585 - val_loss: 1.5050 - val_accuracy: 0.4106\n",
            "Epoch 65/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.5436 - accuracy: 0.3615 - val_loss: 1.4848 - val_accuracy: 0.4783\n",
            "Epoch 66/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.5551 - accuracy: 0.3585 - val_loss: 1.4872 - val_accuracy: 0.4300\n",
            "Epoch 67/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.5416 - accuracy: 0.3755 - val_loss: 1.4871 - val_accuracy: 0.4734\n",
            "Epoch 68/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.5272 - accuracy: 0.3670 - val_loss: 1.4777 - val_accuracy: 0.5072\n",
            "Epoch 69/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.5588 - accuracy: 0.3458 - val_loss: 1.4694 - val_accuracy: 0.5024\n",
            "Epoch 70/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.5245 - accuracy: 0.3712 - val_loss: 1.4741 - val_accuracy: 0.4589\n",
            "Epoch 71/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.5053 - accuracy: 0.3767 - val_loss: 1.4691 - val_accuracy: 0.4444\n",
            "Epoch 72/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.5022 - accuracy: 0.3700 - val_loss: 1.4583 - val_accuracy: 0.4928\n",
            "Epoch 73/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.5046 - accuracy: 0.3833 - val_loss: 1.4495 - val_accuracy: 0.4493\n",
            "Epoch 74/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.4868 - accuracy: 0.3930 - val_loss: 1.4784 - val_accuracy: 0.4155\n",
            "Epoch 75/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.4989 - accuracy: 0.3851 - val_loss: 1.4541 - val_accuracy: 0.4589\n",
            "Epoch 76/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.5227 - accuracy: 0.3712 - val_loss: 1.4551 - val_accuracy: 0.4589\n",
            "Epoch 77/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.4698 - accuracy: 0.4051 - val_loss: 1.4420 - val_accuracy: 0.4928\n",
            "Epoch 78/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.4580 - accuracy: 0.3930 - val_loss: 1.4400 - val_accuracy: 0.4541\n",
            "Epoch 79/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.4844 - accuracy: 0.3954 - val_loss: 1.4488 - val_accuracy: 0.4541\n",
            "Epoch 80/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.4464 - accuracy: 0.4111 - val_loss: 1.4332 - val_accuracy: 0.4879\n",
            "Epoch 81/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.4605 - accuracy: 0.4015 - val_loss: 1.4250 - val_accuracy: 0.4686\n",
            "Epoch 82/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.4594 - accuracy: 0.4135 - val_loss: 1.4257 - val_accuracy: 0.4493\n",
            "Epoch 83/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.4485 - accuracy: 0.4178 - val_loss: 1.4218 - val_accuracy: 0.4734\n",
            "Epoch 84/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.4656 - accuracy: 0.3942 - val_loss: 1.4251 - val_accuracy: 0.4638\n",
            "Epoch 85/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.4512 - accuracy: 0.4232 - val_loss: 1.4076 - val_accuracy: 0.4879\n",
            "Epoch 86/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.4502 - accuracy: 0.4021 - val_loss: 1.4183 - val_accuracy: 0.4541\n",
            "Epoch 87/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.4319 - accuracy: 0.3954 - val_loss: 1.4073 - val_accuracy: 0.4783\n",
            "Epoch 88/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.4458 - accuracy: 0.4135 - val_loss: 1.4008 - val_accuracy: 0.4783\n",
            "Epoch 89/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.4410 - accuracy: 0.4135 - val_loss: 1.3941 - val_accuracy: 0.4734\n",
            "Epoch 90/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.4138 - accuracy: 0.4250 - val_loss: 1.3845 - val_accuracy: 0.5217\n",
            "Epoch 91/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.4350 - accuracy: 0.4027 - val_loss: 1.3782 - val_accuracy: 0.5411\n",
            "Epoch 92/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.4110 - accuracy: 0.4323 - val_loss: 1.3769 - val_accuracy: 0.5121\n",
            "Epoch 93/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.3957 - accuracy: 0.4377 - val_loss: 1.3764 - val_accuracy: 0.4831\n",
            "Epoch 94/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.4024 - accuracy: 0.4232 - val_loss: 1.3656 - val_accuracy: 0.4879\n",
            "Epoch 95/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.3947 - accuracy: 0.4432 - val_loss: 1.3634 - val_accuracy: 0.4976\n",
            "Epoch 96/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.3976 - accuracy: 0.4347 - val_loss: 1.3512 - val_accuracy: 0.5121\n",
            "Epoch 97/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.3954 - accuracy: 0.4389 - val_loss: 1.3711 - val_accuracy: 0.4348\n",
            "Epoch 98/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.4009 - accuracy: 0.4293 - val_loss: 1.3574 - val_accuracy: 0.5362\n",
            "Epoch 99/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.3840 - accuracy: 0.4293 - val_loss: 1.3827 - val_accuracy: 0.4493\n",
            "Epoch 100/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.3905 - accuracy: 0.4456 - val_loss: 1.3556 - val_accuracy: 0.5121\n",
            "Epoch 101/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.3747 - accuracy: 0.4383 - val_loss: 1.3437 - val_accuracy: 0.5024\n",
            "Epoch 102/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.3844 - accuracy: 0.4341 - val_loss: 1.3448 - val_accuracy: 0.5121\n",
            "Epoch 103/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.3514 - accuracy: 0.4577 - val_loss: 1.3382 - val_accuracy: 0.4686\n",
            "Epoch 104/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.3698 - accuracy: 0.4462 - val_loss: 1.3285 - val_accuracy: 0.5362\n",
            "Epoch 105/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.3599 - accuracy: 0.4534 - val_loss: 1.3303 - val_accuracy: 0.4734\n",
            "Epoch 106/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.3646 - accuracy: 0.4553 - val_loss: 1.3247 - val_accuracy: 0.5362\n",
            "Epoch 107/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.3504 - accuracy: 0.4643 - val_loss: 1.3404 - val_accuracy: 0.5169\n",
            "Epoch 108/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.3453 - accuracy: 0.4637 - val_loss: 1.3089 - val_accuracy: 0.4928\n",
            "Epoch 109/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.3327 - accuracy: 0.4601 - val_loss: 1.3114 - val_accuracy: 0.4928\n",
            "Epoch 110/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.3364 - accuracy: 0.4577 - val_loss: 1.3028 - val_accuracy: 0.5556\n",
            "Epoch 111/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.3415 - accuracy: 0.4571 - val_loss: 1.3039 - val_accuracy: 0.5362\n",
            "Epoch 112/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.3314 - accuracy: 0.4655 - val_loss: 1.3326 - val_accuracy: 0.4493\n",
            "Epoch 113/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.3234 - accuracy: 0.4613 - val_loss: 1.2946 - val_accuracy: 0.5169\n",
            "Epoch 114/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.3326 - accuracy: 0.4698 - val_loss: 1.3003 - val_accuracy: 0.5507\n",
            "Epoch 115/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.3033 - accuracy: 0.4891 - val_loss: 1.2925 - val_accuracy: 0.5072\n",
            "Epoch 116/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.3191 - accuracy: 0.4559 - val_loss: 1.2824 - val_accuracy: 0.5459\n",
            "Epoch 117/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.3028 - accuracy: 0.4534 - val_loss: 1.3063 - val_accuracy: 0.4879\n",
            "Epoch 118/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.3175 - accuracy: 0.4686 - val_loss: 1.2796 - val_accuracy: 0.5169\n",
            "Epoch 119/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.2918 - accuracy: 0.4831 - val_loss: 1.2751 - val_accuracy: 0.5362\n",
            "Epoch 120/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.2990 - accuracy: 0.4788 - val_loss: 1.2802 - val_accuracy: 0.4928\n",
            "Epoch 121/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.2873 - accuracy: 0.4873 - val_loss: 1.2637 - val_accuracy: 0.5217\n",
            "Epoch 122/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.2654 - accuracy: 0.5085 - val_loss: 1.2802 - val_accuracy: 0.4928\n",
            "Epoch 123/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.2911 - accuracy: 0.4776 - val_loss: 1.2641 - val_accuracy: 0.5169\n",
            "Epoch 124/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.2489 - accuracy: 0.5109 - val_loss: 1.2563 - val_accuracy: 0.5217\n",
            "Epoch 125/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.2522 - accuracy: 0.4994 - val_loss: 1.2563 - val_accuracy: 0.5411\n",
            "Epoch 126/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.2920 - accuracy: 0.4661 - val_loss: 1.2646 - val_accuracy: 0.5121\n",
            "Epoch 127/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.2740 - accuracy: 0.4909 - val_loss: 1.2575 - val_accuracy: 0.5411\n",
            "Epoch 128/1000\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 1.2718 - accuracy: 0.4921 - val_loss: 1.2577 - val_accuracy: 0.5169\n",
            "Epoch 129/1000\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 1.2494 - accuracy: 0.5036 - val_loss: 1.2362 - val_accuracy: 0.5507\n",
            "Epoch 130/1000\n",
            "104/104 [==============================] - 1s 9ms/step - loss: 1.2589 - accuracy: 0.4994 - val_loss: 1.2370 - val_accuracy: 0.5749\n",
            "Epoch 131/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.2467 - accuracy: 0.4988 - val_loss: 1.2223 - val_accuracy: 0.5556\n",
            "Epoch 132/1000\n",
            "104/104 [==============================] - 1s 9ms/step - loss: 1.2450 - accuracy: 0.4964 - val_loss: 1.2279 - val_accuracy: 0.5217\n",
            "Epoch 133/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.2543 - accuracy: 0.5012 - val_loss: 1.2152 - val_accuracy: 0.5652\n",
            "Epoch 134/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.2427 - accuracy: 0.5048 - val_loss: 1.2275 - val_accuracy: 0.5556\n",
            "Epoch 135/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.2324 - accuracy: 0.5024 - val_loss: 1.2189 - val_accuracy: 0.5556\n",
            "Epoch 136/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.2491 - accuracy: 0.5060 - val_loss: 1.2461 - val_accuracy: 0.5556\n",
            "Epoch 137/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.2445 - accuracy: 0.5067 - val_loss: 1.2200 - val_accuracy: 0.5121\n",
            "Epoch 138/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.2338 - accuracy: 0.4982 - val_loss: 1.2034 - val_accuracy: 0.5652\n",
            "Epoch 139/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.2279 - accuracy: 0.5036 - val_loss: 1.2109 - val_accuracy: 0.5459\n",
            "Epoch 140/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.2421 - accuracy: 0.5042 - val_loss: 1.2085 - val_accuracy: 0.5652\n",
            "Epoch 141/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.2267 - accuracy: 0.5060 - val_loss: 1.1998 - val_accuracy: 0.5507\n",
            "Epoch 142/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.2278 - accuracy: 0.5006 - val_loss: 1.2091 - val_accuracy: 0.5266\n",
            "Epoch 143/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.1948 - accuracy: 0.5248 - val_loss: 1.1865 - val_accuracy: 0.5942\n",
            "Epoch 144/1000\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 1.2131 - accuracy: 0.5151 - val_loss: 1.2056 - val_accuracy: 0.5121\n",
            "Epoch 145/1000\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 1.1955 - accuracy: 0.5193 - val_loss: 1.1829 - val_accuracy: 0.5749\n",
            "Epoch 146/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 1.2161 - accuracy: 0.5242 - val_loss: 1.2020 - val_accuracy: 0.5652\n",
            "Epoch 147/1000\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 1.2163 - accuracy: 0.5091 - val_loss: 1.1810 - val_accuracy: 0.5362\n",
            "Epoch 148/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 1.1873 - accuracy: 0.5212 - val_loss: 1.1925 - val_accuracy: 0.5652\n",
            "Epoch 149/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.1761 - accuracy: 0.5254 - val_loss: 1.1658 - val_accuracy: 0.5797\n",
            "Epoch 150/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.1928 - accuracy: 0.5326 - val_loss: 1.1729 - val_accuracy: 0.5362\n",
            "Epoch 151/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.1934 - accuracy: 0.5151 - val_loss: 1.1675 - val_accuracy: 0.6135\n",
            "Epoch 152/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.1769 - accuracy: 0.5405 - val_loss: 1.1700 - val_accuracy: 0.5700\n",
            "Epoch 153/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.1906 - accuracy: 0.5296 - val_loss: 1.1666 - val_accuracy: 0.5169\n",
            "Epoch 154/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.2210 - accuracy: 0.5133 - val_loss: 1.1637 - val_accuracy: 0.5556\n",
            "Epoch 155/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.1655 - accuracy: 0.5296 - val_loss: 1.1904 - val_accuracy: 0.5507\n",
            "Epoch 156/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.1870 - accuracy: 0.5278 - val_loss: 1.1844 - val_accuracy: 0.5700\n",
            "Epoch 157/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.1873 - accuracy: 0.5375 - val_loss: 1.1701 - val_accuracy: 0.5990\n",
            "Epoch 158/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.1630 - accuracy: 0.5284 - val_loss: 1.1532 - val_accuracy: 0.5749\n",
            "Epoch 159/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.1559 - accuracy: 0.5435 - val_loss: 1.1473 - val_accuracy: 0.5749\n",
            "Epoch 160/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.1646 - accuracy: 0.5308 - val_loss: 1.1365 - val_accuracy: 0.6184\n",
            "Epoch 161/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.1817 - accuracy: 0.5248 - val_loss: 1.1438 - val_accuracy: 0.6232\n",
            "Epoch 162/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.1566 - accuracy: 0.5314 - val_loss: 1.1612 - val_accuracy: 0.5942\n",
            "Epoch 163/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.1737 - accuracy: 0.5302 - val_loss: 1.1394 - val_accuracy: 0.5749\n",
            "Epoch 164/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.1716 - accuracy: 0.5411 - val_loss: 1.1537 - val_accuracy: 0.5797\n",
            "Epoch 165/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.1253 - accuracy: 0.5611 - val_loss: 1.1546 - val_accuracy: 0.5894\n",
            "Epoch 166/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.1535 - accuracy: 0.5502 - val_loss: 1.1375 - val_accuracy: 0.5894\n",
            "Epoch 167/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.1505 - accuracy: 0.5532 - val_loss: 1.1378 - val_accuracy: 0.5556\n",
            "Epoch 168/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.1436 - accuracy: 0.5496 - val_loss: 1.1282 - val_accuracy: 0.5894\n",
            "Epoch 169/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.1327 - accuracy: 0.5550 - val_loss: 1.1486 - val_accuracy: 0.5459\n",
            "Epoch 170/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.1121 - accuracy: 0.5544 - val_loss: 1.1268 - val_accuracy: 0.5942\n",
            "Epoch 171/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.1412 - accuracy: 0.5472 - val_loss: 1.1238 - val_accuracy: 0.5990\n",
            "Epoch 172/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.1271 - accuracy: 0.5453 - val_loss: 1.1290 - val_accuracy: 0.5990\n",
            "Epoch 173/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.1430 - accuracy: 0.5423 - val_loss: 1.1262 - val_accuracy: 0.5894\n",
            "Epoch 174/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.1365 - accuracy: 0.5466 - val_loss: 1.1217 - val_accuracy: 0.6184\n",
            "Epoch 175/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.1182 - accuracy: 0.5574 - val_loss: 1.1102 - val_accuracy: 0.5845\n",
            "Epoch 176/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 1.1442 - accuracy: 0.5429 - val_loss: 1.1011 - val_accuracy: 0.6135\n",
            "Epoch 177/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 1.1352 - accuracy: 0.5302 - val_loss: 1.1080 - val_accuracy: 0.6039\n",
            "Epoch 178/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.1283 - accuracy: 0.5490 - val_loss: 1.1326 - val_accuracy: 0.5990\n",
            "Epoch 179/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.1164 - accuracy: 0.5647 - val_loss: 1.0942 - val_accuracy: 0.6135\n",
            "Epoch 180/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.1249 - accuracy: 0.5538 - val_loss: 1.1284 - val_accuracy: 0.5700\n",
            "Epoch 181/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.1186 - accuracy: 0.5508 - val_loss: 1.0962 - val_accuracy: 0.5845\n",
            "Epoch 182/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0805 - accuracy: 0.5786 - val_loss: 1.0990 - val_accuracy: 0.5797\n",
            "Epoch 183/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.1046 - accuracy: 0.5611 - val_loss: 1.0971 - val_accuracy: 0.6232\n",
            "Epoch 184/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.1140 - accuracy: 0.5707 - val_loss: 1.0883 - val_accuracy: 0.6425\n",
            "Epoch 185/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.1182 - accuracy: 0.5466 - val_loss: 1.0897 - val_accuracy: 0.6087\n",
            "Epoch 186/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.1045 - accuracy: 0.5665 - val_loss: 1.1192 - val_accuracy: 0.5990\n",
            "Epoch 187/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.1011 - accuracy: 0.5544 - val_loss: 1.0950 - val_accuracy: 0.6329\n",
            "Epoch 188/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.1072 - accuracy: 0.5647 - val_loss: 1.0857 - val_accuracy: 0.6329\n",
            "Epoch 189/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0960 - accuracy: 0.5665 - val_loss: 1.0939 - val_accuracy: 0.6280\n",
            "Epoch 190/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0871 - accuracy: 0.5665 - val_loss: 1.0899 - val_accuracy: 0.6425\n",
            "Epoch 191/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0889 - accuracy: 0.5726 - val_loss: 1.0715 - val_accuracy: 0.6184\n",
            "Epoch 192/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0786 - accuracy: 0.5792 - val_loss: 1.0800 - val_accuracy: 0.6280\n",
            "Epoch 193/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0552 - accuracy: 0.5695 - val_loss: 1.0895 - val_accuracy: 0.5942\n",
            "Epoch 194/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0813 - accuracy: 0.5611 - val_loss: 1.0611 - val_accuracy: 0.6473\n",
            "Epoch 195/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0708 - accuracy: 0.5713 - val_loss: 1.0693 - val_accuracy: 0.6135\n",
            "Epoch 196/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0617 - accuracy: 0.5750 - val_loss: 1.0771 - val_accuracy: 0.6039\n",
            "Epoch 197/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0728 - accuracy: 0.5738 - val_loss: 1.0955 - val_accuracy: 0.5700\n",
            "Epoch 198/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0701 - accuracy: 0.5859 - val_loss: 1.0727 - val_accuracy: 0.6425\n",
            "Epoch 199/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0600 - accuracy: 0.5750 - val_loss: 1.0841 - val_accuracy: 0.5845\n",
            "Epoch 200/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0528 - accuracy: 0.5810 - val_loss: 1.0773 - val_accuracy: 0.5749\n",
            "Epoch 201/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0672 - accuracy: 0.5756 - val_loss: 1.0953 - val_accuracy: 0.5700\n",
            "Epoch 202/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0653 - accuracy: 0.5605 - val_loss: 1.0894 - val_accuracy: 0.5990\n",
            "Epoch 203/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0591 - accuracy: 0.5846 - val_loss: 1.0788 - val_accuracy: 0.6377\n",
            "Epoch 204/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0464 - accuracy: 0.5883 - val_loss: 1.0572 - val_accuracy: 0.6232\n",
            "Epoch 205/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0401 - accuracy: 0.5816 - val_loss: 1.0618 - val_accuracy: 0.6473\n",
            "Epoch 206/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0593 - accuracy: 0.5804 - val_loss: 1.0568 - val_accuracy: 0.6135\n",
            "Epoch 207/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0490 - accuracy: 0.5895 - val_loss: 1.0620 - val_accuracy: 0.6329\n",
            "Epoch 208/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0590 - accuracy: 0.5750 - val_loss: 1.0628 - val_accuracy: 0.6570\n",
            "Epoch 209/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0599 - accuracy: 0.5792 - val_loss: 1.0410 - val_accuracy: 0.6377\n",
            "Epoch 210/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0495 - accuracy: 0.5834 - val_loss: 1.0466 - val_accuracy: 0.6377\n",
            "Epoch 211/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0496 - accuracy: 0.5768 - val_loss: 1.0388 - val_accuracy: 0.6473\n",
            "Epoch 212/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0215 - accuracy: 0.5937 - val_loss: 1.0575 - val_accuracy: 0.6087\n",
            "Epoch 213/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0417 - accuracy: 0.5919 - val_loss: 1.0470 - val_accuracy: 0.6135\n",
            "Epoch 214/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0308 - accuracy: 0.5949 - val_loss: 1.0561 - val_accuracy: 0.5990\n",
            "Epoch 215/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0132 - accuracy: 0.6076 - val_loss: 1.0370 - val_accuracy: 0.6280\n",
            "Epoch 216/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0390 - accuracy: 0.5998 - val_loss: 1.0594 - val_accuracy: 0.5990\n",
            "Epoch 217/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0270 - accuracy: 0.6034 - val_loss: 1.0595 - val_accuracy: 0.6377\n",
            "Epoch 218/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0182 - accuracy: 0.5973 - val_loss: 1.0157 - val_accuracy: 0.6473\n",
            "Epoch 219/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0403 - accuracy: 0.5907 - val_loss: 1.0209 - val_accuracy: 0.6184\n",
            "Epoch 220/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0085 - accuracy: 0.6270 - val_loss: 1.0198 - val_accuracy: 0.6329\n",
            "Epoch 221/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0103 - accuracy: 0.6052 - val_loss: 1.0169 - val_accuracy: 0.6425\n",
            "Epoch 222/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0204 - accuracy: 0.5931 - val_loss: 1.0297 - val_accuracy: 0.6184\n",
            "Epoch 223/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0104 - accuracy: 0.6082 - val_loss: 1.0235 - val_accuracy: 0.6618\n",
            "Epoch 224/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9974 - accuracy: 0.6100 - val_loss: 0.9996 - val_accuracy: 0.6522\n",
            "Epoch 225/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0093 - accuracy: 0.5937 - val_loss: 1.0278 - val_accuracy: 0.6184\n",
            "Epoch 226/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9928 - accuracy: 0.6046 - val_loss: 1.0071 - val_accuracy: 0.6377\n",
            "Epoch 227/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0251 - accuracy: 0.5913 - val_loss: 1.0147 - val_accuracy: 0.6232\n",
            "Epoch 228/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9901 - accuracy: 0.6010 - val_loss: 1.0258 - val_accuracy: 0.6039\n",
            "Epoch 229/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0260 - accuracy: 0.6010 - val_loss: 1.0118 - val_accuracy: 0.6280\n",
            "Epoch 230/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0066 - accuracy: 0.6064 - val_loss: 0.9889 - val_accuracy: 0.6473\n",
            "Epoch 231/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9911 - accuracy: 0.6064 - val_loss: 1.0125 - val_accuracy: 0.6377\n",
            "Epoch 232/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0051 - accuracy: 0.6106 - val_loss: 1.0186 - val_accuracy: 0.6232\n",
            "Epoch 233/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9817 - accuracy: 0.6179 - val_loss: 0.9993 - val_accuracy: 0.6039\n",
            "Epoch 234/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9873 - accuracy: 0.6082 - val_loss: 0.9853 - val_accuracy: 0.6570\n",
            "Epoch 235/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9815 - accuracy: 0.6076 - val_loss: 1.0008 - val_accuracy: 0.6425\n",
            "Epoch 236/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9809 - accuracy: 0.6076 - val_loss: 0.9836 - val_accuracy: 0.6522\n",
            "Epoch 237/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9606 - accuracy: 0.6155 - val_loss: 0.9841 - val_accuracy: 0.6473\n",
            "Epoch 238/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9657 - accuracy: 0.6191 - val_loss: 0.9820 - val_accuracy: 0.6329\n",
            "Epoch 239/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9748 - accuracy: 0.6209 - val_loss: 0.9953 - val_accuracy: 0.6135\n",
            "Epoch 240/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0003 - accuracy: 0.6203 - val_loss: 0.9648 - val_accuracy: 0.6763\n",
            "Epoch 241/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9778 - accuracy: 0.6076 - val_loss: 0.9814 - val_accuracy: 0.6715\n",
            "Epoch 242/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9765 - accuracy: 0.6082 - val_loss: 0.9931 - val_accuracy: 0.6377\n",
            "Epoch 243/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9721 - accuracy: 0.6149 - val_loss: 0.9648 - val_accuracy: 0.6667\n",
            "Epoch 244/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9835 - accuracy: 0.6119 - val_loss: 0.9850 - val_accuracy: 0.6425\n",
            "Epoch 245/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9662 - accuracy: 0.6288 - val_loss: 0.9904 - val_accuracy: 0.6329\n",
            "Epoch 246/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9854 - accuracy: 0.6106 - val_loss: 0.9892 - val_accuracy: 0.6232\n",
            "Epoch 247/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9873 - accuracy: 0.6161 - val_loss: 0.9811 - val_accuracy: 0.6715\n",
            "Epoch 248/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9652 - accuracy: 0.6191 - val_loss: 0.9486 - val_accuracy: 0.6715\n",
            "Epoch 249/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9473 - accuracy: 0.6245 - val_loss: 0.9832 - val_accuracy: 0.6522\n",
            "Epoch 250/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9620 - accuracy: 0.6221 - val_loss: 0.9653 - val_accuracy: 0.6715\n",
            "Epoch 251/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9526 - accuracy: 0.6342 - val_loss: 0.9784 - val_accuracy: 0.6522\n",
            "Epoch 252/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9641 - accuracy: 0.6215 - val_loss: 0.9653 - val_accuracy: 0.6377\n",
            "Epoch 253/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9497 - accuracy: 0.6179 - val_loss: 0.9443 - val_accuracy: 0.6667\n",
            "Epoch 254/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9494 - accuracy: 0.6179 - val_loss: 0.9444 - val_accuracy: 0.6570\n",
            "Epoch 255/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9477 - accuracy: 0.6282 - val_loss: 1.0035 - val_accuracy: 0.6232\n",
            "Epoch 256/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9519 - accuracy: 0.6149 - val_loss: 0.9938 - val_accuracy: 0.6425\n",
            "Epoch 257/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9296 - accuracy: 0.6415 - val_loss: 0.9816 - val_accuracy: 0.6667\n",
            "Epoch 258/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9501 - accuracy: 0.6245 - val_loss: 0.9549 - val_accuracy: 0.6618\n",
            "Epoch 259/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9416 - accuracy: 0.6173 - val_loss: 0.9759 - val_accuracy: 0.6812\n",
            "Epoch 260/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9315 - accuracy: 0.6312 - val_loss: 0.9485 - val_accuracy: 0.6763\n",
            "Epoch 261/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9522 - accuracy: 0.6336 - val_loss: 0.9576 - val_accuracy: 0.6618\n",
            "Epoch 262/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9302 - accuracy: 0.6433 - val_loss: 0.9506 - val_accuracy: 0.6812\n",
            "Epoch 263/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9348 - accuracy: 0.6385 - val_loss: 0.9642 - val_accuracy: 0.6667\n",
            "Epoch 264/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9478 - accuracy: 0.6209 - val_loss: 0.9588 - val_accuracy: 0.6329\n",
            "Epoch 265/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9443 - accuracy: 0.6360 - val_loss: 0.9509 - val_accuracy: 0.6425\n",
            "Epoch 266/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9375 - accuracy: 0.6342 - val_loss: 0.9514 - val_accuracy: 0.6329\n",
            "Epoch 267/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9453 - accuracy: 0.6372 - val_loss: 0.9875 - val_accuracy: 0.6425\n",
            "Epoch 268/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9237 - accuracy: 0.6330 - val_loss: 0.9481 - val_accuracy: 0.6570\n",
            "Epoch 269/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9185 - accuracy: 0.6397 - val_loss: 0.9521 - val_accuracy: 0.6329\n",
            "Epoch 270/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9310 - accuracy: 0.6227 - val_loss: 0.9447 - val_accuracy: 0.6618\n",
            "Epoch 271/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9337 - accuracy: 0.6282 - val_loss: 0.9315 - val_accuracy: 0.6618\n",
            "Epoch 272/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9030 - accuracy: 0.6421 - val_loss: 0.9413 - val_accuracy: 0.6425\n",
            "Epoch 273/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9095 - accuracy: 0.6433 - val_loss: 0.9431 - val_accuracy: 0.6377\n",
            "Epoch 274/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9240 - accuracy: 0.6403 - val_loss: 0.9215 - val_accuracy: 0.6763\n",
            "Epoch 275/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9162 - accuracy: 0.6360 - val_loss: 0.9158 - val_accuracy: 0.6570\n",
            "Epoch 276/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8953 - accuracy: 0.6572 - val_loss: 0.9326 - val_accuracy: 0.6812\n",
            "Epoch 277/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9090 - accuracy: 0.6342 - val_loss: 0.9047 - val_accuracy: 0.6715\n",
            "Epoch 278/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9263 - accuracy: 0.6330 - val_loss: 0.9283 - val_accuracy: 0.6763\n",
            "Epoch 279/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9101 - accuracy: 0.6378 - val_loss: 0.9503 - val_accuracy: 0.6329\n",
            "Epoch 280/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9083 - accuracy: 0.6536 - val_loss: 0.9259 - val_accuracy: 0.6812\n",
            "Epoch 281/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9194 - accuracy: 0.6324 - val_loss: 0.9577 - val_accuracy: 0.6377\n",
            "Epoch 282/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9012 - accuracy: 0.6385 - val_loss: 0.9303 - val_accuracy: 0.6522\n",
            "Epoch 283/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9054 - accuracy: 0.6427 - val_loss: 0.9076 - val_accuracy: 0.6618\n",
            "Epoch 284/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9032 - accuracy: 0.6439 - val_loss: 0.9110 - val_accuracy: 0.6715\n",
            "Epoch 285/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8982 - accuracy: 0.6511 - val_loss: 0.9199 - val_accuracy: 0.6763\n",
            "Epoch 286/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8903 - accuracy: 0.6445 - val_loss: 0.9131 - val_accuracy: 0.6425\n",
            "Epoch 287/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9040 - accuracy: 0.6336 - val_loss: 0.9095 - val_accuracy: 0.7101\n",
            "Epoch 288/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8864 - accuracy: 0.6584 - val_loss: 0.9103 - val_accuracy: 0.6618\n",
            "Epoch 289/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9138 - accuracy: 0.6294 - val_loss: 0.8928 - val_accuracy: 0.6812\n",
            "Epoch 290/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9015 - accuracy: 0.6505 - val_loss: 0.9085 - val_accuracy: 0.7005\n",
            "Epoch 291/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8952 - accuracy: 0.6457 - val_loss: 0.8958 - val_accuracy: 0.6860\n",
            "Epoch 292/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8883 - accuracy: 0.6330 - val_loss: 0.9024 - val_accuracy: 0.6667\n",
            "Epoch 293/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8806 - accuracy: 0.6481 - val_loss: 0.9062 - val_accuracy: 0.6763\n",
            "Epoch 294/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8775 - accuracy: 0.6524 - val_loss: 0.8954 - val_accuracy: 0.6667\n",
            "Epoch 295/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8831 - accuracy: 0.6548 - val_loss: 0.8879 - val_accuracy: 0.6618\n",
            "Epoch 296/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8803 - accuracy: 0.6505 - val_loss: 0.9024 - val_accuracy: 0.6570\n",
            "Epoch 297/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8844 - accuracy: 0.6560 - val_loss: 0.8830 - val_accuracy: 0.6860\n",
            "Epoch 298/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8958 - accuracy: 0.6548 - val_loss: 0.8914 - val_accuracy: 0.6667\n",
            "Epoch 299/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8773 - accuracy: 0.6505 - val_loss: 0.8876 - val_accuracy: 0.6715\n",
            "Epoch 300/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8833 - accuracy: 0.6499 - val_loss: 0.8781 - val_accuracy: 0.6812\n",
            "Epoch 301/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9103 - accuracy: 0.6336 - val_loss: 0.8747 - val_accuracy: 0.7005\n",
            "Epoch 302/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8672 - accuracy: 0.6572 - val_loss: 0.8762 - val_accuracy: 0.6812\n",
            "Epoch 303/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8935 - accuracy: 0.6366 - val_loss: 0.8912 - val_accuracy: 0.6812\n",
            "Epoch 304/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8881 - accuracy: 0.6348 - val_loss: 0.8803 - val_accuracy: 0.7005\n",
            "Epoch 305/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8481 - accuracy: 0.6723 - val_loss: 0.8704 - val_accuracy: 0.6957\n",
            "Epoch 306/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8855 - accuracy: 0.6511 - val_loss: 0.8672 - val_accuracy: 0.6957\n",
            "Epoch 307/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8627 - accuracy: 0.6663 - val_loss: 0.8915 - val_accuracy: 0.7150\n",
            "Epoch 308/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8701 - accuracy: 0.6499 - val_loss: 0.9015 - val_accuracy: 0.6473\n",
            "Epoch 309/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8933 - accuracy: 0.6439 - val_loss: 0.8990 - val_accuracy: 0.6473\n",
            "Epoch 310/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8474 - accuracy: 0.6675 - val_loss: 0.9033 - val_accuracy: 0.6860\n",
            "Epoch 311/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8600 - accuracy: 0.6741 - val_loss: 0.8727 - val_accuracy: 0.6812\n",
            "Epoch 312/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8816 - accuracy: 0.6475 - val_loss: 0.8701 - val_accuracy: 0.7005\n",
            "Epoch 313/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8676 - accuracy: 0.6681 - val_loss: 0.8789 - val_accuracy: 0.6618\n",
            "Epoch 314/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8673 - accuracy: 0.6735 - val_loss: 0.8960 - val_accuracy: 0.6715\n",
            "Epoch 315/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8760 - accuracy: 0.6493 - val_loss: 0.8872 - val_accuracy: 0.6763\n",
            "Epoch 316/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8533 - accuracy: 0.6699 - val_loss: 0.8700 - val_accuracy: 0.6860\n",
            "Epoch 317/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8532 - accuracy: 0.6735 - val_loss: 0.8941 - val_accuracy: 0.6618\n",
            "Epoch 318/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8460 - accuracy: 0.6723 - val_loss: 0.8724 - val_accuracy: 0.6908\n",
            "Epoch 319/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8674 - accuracy: 0.6542 - val_loss: 0.8848 - val_accuracy: 0.6763\n",
            "Epoch 320/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8354 - accuracy: 0.6669 - val_loss: 0.8917 - val_accuracy: 0.6473\n",
            "Epoch 321/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8474 - accuracy: 0.6717 - val_loss: 0.8698 - val_accuracy: 0.6908\n",
            "Epoch 322/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8587 - accuracy: 0.6681 - val_loss: 0.8650 - val_accuracy: 0.6812\n",
            "Epoch 323/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8451 - accuracy: 0.6651 - val_loss: 0.8805 - val_accuracy: 0.6618\n",
            "Epoch 324/1000\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8668 - accuracy: 0.6536 - val_loss: 0.8669 - val_accuracy: 0.6812\n",
            "Epoch 325/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8550 - accuracy: 0.6651 - val_loss: 0.8525 - val_accuracy: 0.7101\n",
            "Epoch 326/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8612 - accuracy: 0.6638 - val_loss: 0.8478 - val_accuracy: 0.6908\n",
            "Epoch 327/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8533 - accuracy: 0.6596 - val_loss: 0.8697 - val_accuracy: 0.6763\n",
            "Epoch 328/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8509 - accuracy: 0.6663 - val_loss: 0.8606 - val_accuracy: 0.6667\n",
            "Epoch 329/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8174 - accuracy: 0.6735 - val_loss: 0.8634 - val_accuracy: 0.6812\n",
            "Epoch 330/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8460 - accuracy: 0.6681 - val_loss: 0.8456 - val_accuracy: 0.6908\n",
            "Epoch 331/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.8552 - accuracy: 0.6657 - val_loss: 0.8702 - val_accuracy: 0.6908\n",
            "Epoch 332/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8413 - accuracy: 0.6711 - val_loss: 0.8519 - val_accuracy: 0.6763\n",
            "Epoch 333/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8594 - accuracy: 0.6687 - val_loss: 0.8703 - val_accuracy: 0.6957\n",
            "Epoch 334/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8336 - accuracy: 0.6699 - val_loss: 0.8679 - val_accuracy: 0.6957\n",
            "Epoch 335/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8574 - accuracy: 0.6493 - val_loss: 0.8598 - val_accuracy: 0.6763\n",
            "Epoch 336/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8279 - accuracy: 0.6632 - val_loss: 0.8427 - val_accuracy: 0.7053\n",
            "Epoch 337/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8150 - accuracy: 0.6693 - val_loss: 0.8756 - val_accuracy: 0.6763\n",
            "Epoch 338/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8417 - accuracy: 0.6729 - val_loss: 0.8574 - val_accuracy: 0.6812\n",
            "Epoch 339/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8155 - accuracy: 0.6814 - val_loss: 0.8460 - val_accuracy: 0.6812\n",
            "Epoch 340/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8533 - accuracy: 0.6493 - val_loss: 0.8953 - val_accuracy: 0.6618\n",
            "Epoch 341/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8360 - accuracy: 0.6699 - val_loss: 0.8495 - val_accuracy: 0.6667\n",
            "Epoch 342/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8093 - accuracy: 0.6874 - val_loss: 0.8480 - val_accuracy: 0.6860\n",
            "Epoch 343/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8252 - accuracy: 0.6705 - val_loss: 0.8529 - val_accuracy: 0.6860\n",
            "Epoch 344/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8401 - accuracy: 0.6681 - val_loss: 0.8354 - val_accuracy: 0.6908\n",
            "Epoch 345/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8199 - accuracy: 0.6735 - val_loss: 0.8429 - val_accuracy: 0.7053\n",
            "Epoch 346/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8155 - accuracy: 0.6778 - val_loss: 0.8346 - val_accuracy: 0.7101\n",
            "Epoch 347/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8219 - accuracy: 0.6784 - val_loss: 0.8382 - val_accuracy: 0.6908\n",
            "Epoch 348/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8303 - accuracy: 0.6735 - val_loss: 0.8290 - val_accuracy: 0.6812\n",
            "Epoch 349/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8036 - accuracy: 0.6735 - val_loss: 0.8356 - val_accuracy: 0.6957\n",
            "Epoch 350/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8007 - accuracy: 0.6947 - val_loss: 0.8535 - val_accuracy: 0.6667\n",
            "Epoch 351/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8118 - accuracy: 0.6850 - val_loss: 0.8210 - val_accuracy: 0.7005\n",
            "Epoch 352/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8075 - accuracy: 0.6753 - val_loss: 0.8253 - val_accuracy: 0.6957\n",
            "Epoch 353/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7973 - accuracy: 0.6898 - val_loss: 0.8317 - val_accuracy: 0.7295\n",
            "Epoch 354/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8075 - accuracy: 0.6862 - val_loss: 0.8280 - val_accuracy: 0.7101\n",
            "Epoch 355/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8274 - accuracy: 0.6753 - val_loss: 0.8390 - val_accuracy: 0.6763\n",
            "Epoch 356/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.7976 - accuracy: 0.6844 - val_loss: 0.8604 - val_accuracy: 0.6763\n",
            "Epoch 357/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8168 - accuracy: 0.6681 - val_loss: 0.8144 - val_accuracy: 0.7053\n",
            "Epoch 358/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8155 - accuracy: 0.6832 - val_loss: 0.8276 - val_accuracy: 0.7150\n",
            "Epoch 359/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8208 - accuracy: 0.6717 - val_loss: 0.8282 - val_accuracy: 0.7150\n",
            "Epoch 360/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8049 - accuracy: 0.6844 - val_loss: 0.8327 - val_accuracy: 0.6860\n",
            "Epoch 361/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8085 - accuracy: 0.6669 - val_loss: 0.8099 - val_accuracy: 0.7005\n",
            "Epoch 362/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7983 - accuracy: 0.6796 - val_loss: 0.8179 - val_accuracy: 0.7053\n",
            "Epoch 363/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8155 - accuracy: 0.6808 - val_loss: 0.8326 - val_accuracy: 0.7005\n",
            "Epoch 364/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7935 - accuracy: 0.6741 - val_loss: 0.8329 - val_accuracy: 0.6908\n",
            "Epoch 365/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7956 - accuracy: 0.6874 - val_loss: 0.8315 - val_accuracy: 0.6763\n",
            "Epoch 366/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8156 - accuracy: 0.6735 - val_loss: 0.8566 - val_accuracy: 0.6812\n",
            "Epoch 367/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7891 - accuracy: 0.6856 - val_loss: 0.8146 - val_accuracy: 0.7005\n",
            "Epoch 368/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8151 - accuracy: 0.6620 - val_loss: 0.8373 - val_accuracy: 0.7150\n",
            "Epoch 369/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8015 - accuracy: 0.6771 - val_loss: 0.8359 - val_accuracy: 0.6763\n",
            "Epoch 370/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7893 - accuracy: 0.6904 - val_loss: 0.8124 - val_accuracy: 0.6908\n",
            "Epoch 371/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8062 - accuracy: 0.6808 - val_loss: 0.8377 - val_accuracy: 0.7053\n",
            "Epoch 372/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7706 - accuracy: 0.6923 - val_loss: 0.8088 - val_accuracy: 0.6957\n",
            "Epoch 373/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8030 - accuracy: 0.6911 - val_loss: 0.7977 - val_accuracy: 0.7053\n",
            "Epoch 374/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7732 - accuracy: 0.6941 - val_loss: 0.8050 - val_accuracy: 0.7150\n",
            "Epoch 375/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7847 - accuracy: 0.6880 - val_loss: 0.8101 - val_accuracy: 0.7005\n",
            "Epoch 376/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7719 - accuracy: 0.7001 - val_loss: 0.8410 - val_accuracy: 0.6908\n",
            "Epoch 377/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7839 - accuracy: 0.6935 - val_loss: 0.8288 - val_accuracy: 0.7053\n",
            "Epoch 378/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7717 - accuracy: 0.7044 - val_loss: 0.8093 - val_accuracy: 0.7101\n",
            "Epoch 379/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7865 - accuracy: 0.6862 - val_loss: 0.8200 - val_accuracy: 0.7150\n",
            "Epoch 380/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.7977 - accuracy: 0.6911 - val_loss: 0.8001 - val_accuracy: 0.7053\n",
            "Epoch 381/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7972 - accuracy: 0.6826 - val_loss: 0.8008 - val_accuracy: 0.7295\n",
            "Epoch 382/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7848 - accuracy: 0.6947 - val_loss: 0.8005 - val_accuracy: 0.7246\n",
            "Epoch 383/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7749 - accuracy: 0.6814 - val_loss: 0.8122 - val_accuracy: 0.7053\n",
            "Epoch 384/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7657 - accuracy: 0.6977 - val_loss: 0.8098 - val_accuracy: 0.7150\n",
            "Epoch 385/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7833 - accuracy: 0.6850 - val_loss: 0.8323 - val_accuracy: 0.6957\n",
            "Epoch 386/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.7681 - accuracy: 0.6965 - val_loss: 0.8026 - val_accuracy: 0.7101\n",
            "Epoch 387/1000\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.7824 - accuracy: 0.6965 - val_loss: 0.7925 - val_accuracy: 0.7005\n",
            "Epoch 388/1000\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.7734 - accuracy: 0.6929 - val_loss: 0.7830 - val_accuracy: 0.7295\n",
            "Epoch 389/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.7693 - accuracy: 0.7019 - val_loss: 0.8084 - val_accuracy: 0.6957\n",
            "Epoch 390/1000\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.7839 - accuracy: 0.7013 - val_loss: 0.8027 - val_accuracy: 0.7101\n",
            "Epoch 391/1000\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.7685 - accuracy: 0.6892 - val_loss: 0.7985 - val_accuracy: 0.7150\n",
            "Epoch 392/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.7566 - accuracy: 0.7013 - val_loss: 0.7913 - val_accuracy: 0.7053\n",
            "Epoch 393/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7554 - accuracy: 0.7128 - val_loss: 0.7905 - val_accuracy: 0.7246\n",
            "Epoch 394/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7781 - accuracy: 0.6965 - val_loss: 0.7849 - val_accuracy: 0.6908\n",
            "Epoch 395/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7729 - accuracy: 0.6941 - val_loss: 0.8056 - val_accuracy: 0.7198\n",
            "Epoch 396/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7598 - accuracy: 0.6923 - val_loss: 0.8008 - val_accuracy: 0.7101\n",
            "Epoch 397/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7634 - accuracy: 0.6995 - val_loss: 0.7901 - val_accuracy: 0.7005\n",
            "Epoch 398/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7558 - accuracy: 0.6959 - val_loss: 0.8081 - val_accuracy: 0.6860\n",
            "Epoch 399/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7811 - accuracy: 0.6898 - val_loss: 0.8068 - val_accuracy: 0.7101\n",
            "Epoch 400/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7368 - accuracy: 0.7134 - val_loss: 0.7820 - val_accuracy: 0.6957\n",
            "Epoch 401/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7545 - accuracy: 0.7104 - val_loss: 0.7800 - val_accuracy: 0.7440\n",
            "Epoch 402/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7496 - accuracy: 0.6995 - val_loss: 0.7793 - val_accuracy: 0.7150\n",
            "Epoch 403/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7640 - accuracy: 0.7062 - val_loss: 0.7923 - val_accuracy: 0.7343\n",
            "Epoch 404/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7433 - accuracy: 0.7074 - val_loss: 0.7920 - val_accuracy: 0.6860\n",
            "Epoch 405/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.7405 - accuracy: 0.7207 - val_loss: 0.7800 - val_accuracy: 0.6957\n",
            "Epoch 406/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7721 - accuracy: 0.6935 - val_loss: 0.8053 - val_accuracy: 0.6860\n",
            "Epoch 407/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7700 - accuracy: 0.6965 - val_loss: 0.7735 - val_accuracy: 0.7198\n",
            "Epoch 408/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7603 - accuracy: 0.7037 - val_loss: 0.7850 - val_accuracy: 0.7150\n",
            "Epoch 409/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.7534 - accuracy: 0.6947 - val_loss: 0.7787 - val_accuracy: 0.7198\n",
            "Epoch 410/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7385 - accuracy: 0.7152 - val_loss: 0.7843 - val_accuracy: 0.7198\n",
            "Epoch 411/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7554 - accuracy: 0.6965 - val_loss: 0.7626 - val_accuracy: 0.7101\n",
            "Epoch 412/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7562 - accuracy: 0.7068 - val_loss: 0.7849 - val_accuracy: 0.7053\n",
            "Epoch 413/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7531 - accuracy: 0.6953 - val_loss: 0.7776 - val_accuracy: 0.7198\n",
            "Epoch 414/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7423 - accuracy: 0.6965 - val_loss: 0.7912 - val_accuracy: 0.7005\n",
            "Epoch 415/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7305 - accuracy: 0.7056 - val_loss: 0.7787 - val_accuracy: 0.6908\n",
            "Epoch 416/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7619 - accuracy: 0.7074 - val_loss: 0.7775 - val_accuracy: 0.6908\n",
            "Epoch 417/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7442 - accuracy: 0.6989 - val_loss: 0.7817 - val_accuracy: 0.7005\n",
            "Epoch 418/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7423 - accuracy: 0.6989 - val_loss: 0.7731 - val_accuracy: 0.7246\n",
            "Epoch 419/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7335 - accuracy: 0.7183 - val_loss: 0.7794 - val_accuracy: 0.7150\n",
            "Epoch 420/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7226 - accuracy: 0.7116 - val_loss: 0.7798 - val_accuracy: 0.7198\n",
            "Epoch 421/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7427 - accuracy: 0.6977 - val_loss: 0.7784 - val_accuracy: 0.7295\n",
            "Epoch 422/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7443 - accuracy: 0.7104 - val_loss: 0.7689 - val_accuracy: 0.7295\n",
            "Epoch 423/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7378 - accuracy: 0.7104 - val_loss: 0.7979 - val_accuracy: 0.7005\n",
            "Epoch 424/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7334 - accuracy: 0.7170 - val_loss: 0.7991 - val_accuracy: 0.7101\n",
            "Epoch 425/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7234 - accuracy: 0.7140 - val_loss: 0.7893 - val_accuracy: 0.7343\n",
            "Epoch 426/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7496 - accuracy: 0.7013 - val_loss: 0.7816 - val_accuracy: 0.7053\n",
            "Epoch 427/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7415 - accuracy: 0.7128 - val_loss: 0.7801 - val_accuracy: 0.7005\n",
            "Epoch 428/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7466 - accuracy: 0.7007 - val_loss: 0.7932 - val_accuracy: 0.7198\n",
            "Epoch 429/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.7402 - accuracy: 0.7074 - val_loss: 0.7879 - val_accuracy: 0.7101\n",
            "Epoch 430/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7497 - accuracy: 0.6989 - val_loss: 0.7787 - val_accuracy: 0.7005\n",
            "Epoch 431/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7292 - accuracy: 0.7007 - val_loss: 0.7572 - val_accuracy: 0.7391\n",
            "Epoch 432/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7438 - accuracy: 0.7025 - val_loss: 0.7645 - val_accuracy: 0.7295\n",
            "Epoch 433/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7482 - accuracy: 0.6977 - val_loss: 0.7674 - val_accuracy: 0.7343\n",
            "Epoch 434/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.7451 - accuracy: 0.6965 - val_loss: 0.7862 - val_accuracy: 0.6957\n",
            "Epoch 435/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7187 - accuracy: 0.7249 - val_loss: 0.7839 - val_accuracy: 0.7053\n",
            "Epoch 436/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7277 - accuracy: 0.7098 - val_loss: 0.7780 - val_accuracy: 0.7391\n",
            "Epoch 437/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7359 - accuracy: 0.7092 - val_loss: 0.7840 - val_accuracy: 0.7198\n",
            "Epoch 438/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7378 - accuracy: 0.7037 - val_loss: 0.7689 - val_accuracy: 0.7343\n",
            "Epoch 439/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7283 - accuracy: 0.7122 - val_loss: 0.7628 - val_accuracy: 0.7391\n",
            "Epoch 440/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.7222 - accuracy: 0.7134 - val_loss: 0.7524 - val_accuracy: 0.7488\n",
            "Epoch 441/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.7101 - accuracy: 0.7134 - val_loss: 0.7662 - val_accuracy: 0.7488\n",
            "Epoch 442/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7100 - accuracy: 0.7213 - val_loss: 0.7586 - val_accuracy: 0.7295\n",
            "Epoch 443/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7164 - accuracy: 0.7219 - val_loss: 0.7586 - val_accuracy: 0.7440\n",
            "Epoch 444/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7271 - accuracy: 0.7062 - val_loss: 0.7351 - val_accuracy: 0.7440\n",
            "Epoch 445/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7190 - accuracy: 0.7068 - val_loss: 0.7545 - val_accuracy: 0.7198\n",
            "Epoch 446/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6875 - accuracy: 0.7279 - val_loss: 0.7667 - val_accuracy: 0.7005\n",
            "Epoch 447/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7163 - accuracy: 0.7140 - val_loss: 0.7623 - val_accuracy: 0.7198\n",
            "Epoch 448/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.7195 - accuracy: 0.7177 - val_loss: 0.7696 - val_accuracy: 0.7391\n",
            "Epoch 449/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7210 - accuracy: 0.7183 - val_loss: 0.7815 - val_accuracy: 0.6957\n",
            "Epoch 450/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.7128 - accuracy: 0.7183 - val_loss: 0.7628 - val_accuracy: 0.7391\n",
            "Epoch 451/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7277 - accuracy: 0.7098 - val_loss: 0.7636 - val_accuracy: 0.7198\n",
            "Epoch 452/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7192 - accuracy: 0.7019 - val_loss: 0.7481 - val_accuracy: 0.7488\n",
            "Epoch 453/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6963 - accuracy: 0.7285 - val_loss: 0.7633 - val_accuracy: 0.7343\n",
            "Epoch 454/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7084 - accuracy: 0.7164 - val_loss: 0.7616 - val_accuracy: 0.7440\n",
            "Epoch 455/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7013 - accuracy: 0.7104 - val_loss: 0.7595 - val_accuracy: 0.7295\n",
            "Epoch 456/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6941 - accuracy: 0.7328 - val_loss: 0.7537 - val_accuracy: 0.7295\n",
            "Epoch 457/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7068 - accuracy: 0.7183 - val_loss: 0.7548 - val_accuracy: 0.7391\n",
            "Epoch 458/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6925 - accuracy: 0.7291 - val_loss: 0.7409 - val_accuracy: 0.7585\n",
            "Epoch 459/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7105 - accuracy: 0.7140 - val_loss: 0.7477 - val_accuracy: 0.7391\n",
            "Epoch 460/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6883 - accuracy: 0.7346 - val_loss: 0.7509 - val_accuracy: 0.7150\n",
            "Epoch 461/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6912 - accuracy: 0.7213 - val_loss: 0.7476 - val_accuracy: 0.7440\n",
            "Epoch 462/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6824 - accuracy: 0.7243 - val_loss: 0.7259 - val_accuracy: 0.7633\n",
            "Epoch 463/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.7145 - accuracy: 0.7225 - val_loss: 0.7299 - val_accuracy: 0.7536\n",
            "Epoch 464/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6933 - accuracy: 0.7297 - val_loss: 0.7532 - val_accuracy: 0.7246\n",
            "Epoch 465/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6852 - accuracy: 0.7316 - val_loss: 0.7365 - val_accuracy: 0.7343\n",
            "Epoch 466/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7053 - accuracy: 0.7050 - val_loss: 0.7621 - val_accuracy: 0.7391\n",
            "Epoch 467/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6994 - accuracy: 0.7213 - val_loss: 0.7653 - val_accuracy: 0.7101\n",
            "Epoch 468/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6927 - accuracy: 0.7328 - val_loss: 0.7359 - val_accuracy: 0.7440\n",
            "Epoch 469/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6903 - accuracy: 0.7243 - val_loss: 0.7405 - val_accuracy: 0.7343\n",
            "Epoch 470/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7010 - accuracy: 0.7207 - val_loss: 0.7769 - val_accuracy: 0.7150\n",
            "Epoch 471/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6824 - accuracy: 0.7340 - val_loss: 0.7504 - val_accuracy: 0.7440\n",
            "Epoch 472/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6681 - accuracy: 0.7340 - val_loss: 0.7443 - val_accuracy: 0.7246\n",
            "Epoch 473/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6933 - accuracy: 0.7237 - val_loss: 0.7553 - val_accuracy: 0.7633\n",
            "Epoch 474/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6920 - accuracy: 0.7424 - val_loss: 0.7467 - val_accuracy: 0.7246\n",
            "Epoch 475/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6878 - accuracy: 0.7285 - val_loss: 0.7359 - val_accuracy: 0.7343\n",
            "Epoch 476/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6865 - accuracy: 0.7394 - val_loss: 0.7356 - val_accuracy: 0.7391\n",
            "Epoch 477/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6954 - accuracy: 0.7316 - val_loss: 0.7572 - val_accuracy: 0.7295\n",
            "Epoch 478/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6965 - accuracy: 0.7243 - val_loss: 0.7580 - val_accuracy: 0.7246\n",
            "Epoch 479/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6741 - accuracy: 0.7334 - val_loss: 0.7367 - val_accuracy: 0.7585\n",
            "Epoch 480/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6856 - accuracy: 0.7285 - val_loss: 0.7392 - val_accuracy: 0.7440\n",
            "Epoch 481/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6700 - accuracy: 0.7503 - val_loss: 0.7558 - val_accuracy: 0.7246\n",
            "Epoch 482/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6494 - accuracy: 0.7418 - val_loss: 0.7137 - val_accuracy: 0.7681\n",
            "Epoch 483/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6723 - accuracy: 0.7376 - val_loss: 0.7366 - val_accuracy: 0.7488\n",
            "Epoch 484/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6788 - accuracy: 0.7207 - val_loss: 0.7303 - val_accuracy: 0.7681\n",
            "Epoch 485/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6783 - accuracy: 0.7382 - val_loss: 0.7536 - val_accuracy: 0.7246\n",
            "Epoch 486/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6957 - accuracy: 0.7310 - val_loss: 0.7386 - val_accuracy: 0.7440\n",
            "Epoch 487/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6891 - accuracy: 0.7358 - val_loss: 0.7587 - val_accuracy: 0.6957\n",
            "Epoch 488/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6669 - accuracy: 0.7443 - val_loss: 0.7258 - val_accuracy: 0.7585\n",
            "Epoch 489/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6726 - accuracy: 0.7424 - val_loss: 0.7533 - val_accuracy: 0.7343\n",
            "Epoch 490/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6711 - accuracy: 0.7267 - val_loss: 0.7251 - val_accuracy: 0.7343\n",
            "Epoch 491/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6859 - accuracy: 0.7255 - val_loss: 0.7188 - val_accuracy: 0.7343\n",
            "Epoch 492/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6704 - accuracy: 0.7485 - val_loss: 0.7194 - val_accuracy: 0.7295\n",
            "Epoch 493/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6819 - accuracy: 0.7310 - val_loss: 0.7336 - val_accuracy: 0.7440\n",
            "Epoch 494/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6814 - accuracy: 0.7285 - val_loss: 0.7293 - val_accuracy: 0.7295\n",
            "Epoch 495/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6715 - accuracy: 0.7370 - val_loss: 0.7277 - val_accuracy: 0.7488\n",
            "Epoch 496/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6654 - accuracy: 0.7437 - val_loss: 0.7286 - val_accuracy: 0.7343\n",
            "Epoch 497/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6557 - accuracy: 0.7364 - val_loss: 0.7271 - val_accuracy: 0.7488\n",
            "Epoch 498/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6565 - accuracy: 0.7443 - val_loss: 0.7255 - val_accuracy: 0.7488\n",
            "Epoch 499/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6520 - accuracy: 0.7394 - val_loss: 0.7191 - val_accuracy: 0.7536\n",
            "Epoch 500/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6700 - accuracy: 0.7382 - val_loss: 0.7317 - val_accuracy: 0.7246\n",
            "Epoch 501/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6659 - accuracy: 0.7418 - val_loss: 0.7261 - val_accuracy: 0.7343\n",
            "Epoch 502/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6490 - accuracy: 0.7352 - val_loss: 0.7291 - val_accuracy: 0.7585\n",
            "Epoch 503/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6241 - accuracy: 0.7503 - val_loss: 0.7271 - val_accuracy: 0.7198\n",
            "Epoch 504/1000\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6699 - accuracy: 0.7316 - val_loss: 0.7180 - val_accuracy: 0.7343\n",
            "Epoch 505/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6622 - accuracy: 0.7291 - val_loss: 0.7283 - val_accuracy: 0.7536\n",
            "Epoch 506/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6603 - accuracy: 0.7461 - val_loss: 0.7371 - val_accuracy: 0.7101\n",
            "Epoch 507/1000\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6444 - accuracy: 0.7394 - val_loss: 0.7260 - val_accuracy: 0.7488\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(cnnhistory.history['loss'])\n",
        "plt.plot(cnnhistory.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train','test'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "oQYnuaCrDH_A",
        "outputId": "88e9be2b-47b2-485f-ad89-d26e26b894f5"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(cnnhistory.history['accuracy'])\n",
        "plt.plot(cnnhistory.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train','test'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "IFkTuO8nDNdq",
        "outputId": "8b66a79c-4a6c-4506-a77d-b927ea4a3da0"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model.predict(x_testcnn)"
      ],
      "metadata": {
        "id": "A2xtrN5wDQgY"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_f_ohjXKDUpY",
        "outputId": "95c788d6-fd8e-4101-dab4-939f0d249dbb"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[2.1742056e-01, 1.3071696e-01, 2.4430093e-01, 1.9434135e-01,\n",
              "        1.5879294e-01, 5.4427344e-02],\n",
              "       [4.8768320e-03, 8.4340390e-06, 3.9446525e-07, 9.6713579e-01,\n",
              "        2.4710057e-04, 2.7731529e-02],\n",
              "       [1.7268875e-01, 1.0076423e-01, 1.1549445e-01, 2.9837939e-01,\n",
              "        6.9660582e-02, 2.4301262e-01],\n",
              "       ...,\n",
              "       [2.8672151e-04, 1.4685545e-06, 1.4204462e-03, 1.7175865e-03,\n",
              "        9.9131984e-01, 5.2538975e-03],\n",
              "       [1.5713411e-04, 4.3721241e-01, 5.0024325e-01, 1.1932647e-02,\n",
              "        1.0620275e-02, 3.9834250e-02],\n",
              "       [4.4302587e-04, 2.4262865e-03, 7.4472420e-02, 5.2696420e-03,\n",
              "        8.5008544e-01, 6.7303173e-02]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cmA2bFgsDW3D",
        "outputId": "40870c73-ece8-4e77-8da3-9b72cc2280a3"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([3, 3, 3, 0, 4, 4, 1, 2, 5, 0, 5, 3, 2, 2, 1, 4, 4, 5, 2, 4, 1, 2,\n",
              "       3, 5, 4, 2, 1, 2, 2, 2, 2, 5, 2, 5, 3, 1, 2, 0, 4, 5, 2, 3, 2, 2,\n",
              "       5, 2, 0, 1, 3, 4, 4, 5, 1, 1, 4, 4, 5, 1, 1, 1, 0, 1, 5, 0, 4, 1,\n",
              "       1, 0, 1, 4, 1, 0, 4, 1, 3, 1, 2, 2, 1, 2, 3, 0, 5, 3, 5, 5, 2, 4,\n",
              "       5, 1, 5, 1, 5, 3, 4, 1, 4, 1, 5, 4, 5, 1, 2, 1, 1, 5, 1, 3, 2, 5,\n",
              "       2, 1, 3, 5, 4, 4, 0, 0, 3, 1, 2, 2, 3, 5, 1, 5, 3, 4, 2, 2, 0, 2,\n",
              "       2, 5, 5, 0, 3, 3, 2, 2, 0, 3, 4, 0, 4, 2, 4, 5, 4, 1, 5, 3, 2, 2,\n",
              "       5, 4, 3, 3, 4, 3, 3, 4, 1, 5, 2, 3, 2, 2, 0, 2, 1, 3, 1, 2, 2, 5,\n",
              "       5, 1, 4, 2, 2, 1, 1, 3, 3, 5, 5, 2, 5, 1, 5, 0, 3, 3, 0, 5, 1, 4,\n",
              "       1, 4, 2, 5, 5, 1, 4, 2, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_Ytest = y_test.astype(int)"
      ],
      "metadata": {
        "id": "0PHDKWJWDY3g"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_Ytest"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k68v2i-pDbZE",
        "outputId": "c08c531b-043d-4f6f-9fff-33d7a669d17e"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([3, 3, 3, 0, 4, 4, 1, 2, 5, 0, 5, 3, 2, 2, 1, 4, 4, 5, 2, 4, 1, 2,\n",
              "       3, 5, 4, 2, 1, 2, 2, 2, 2, 5, 2, 5, 3, 1, 2, 0, 4, 5, 2, 3, 2, 2,\n",
              "       5, 2, 0, 1, 3, 4, 4, 5, 1, 1, 4, 4, 5, 1, 1, 1, 0, 1, 5, 0, 4, 1,\n",
              "       1, 0, 1, 4, 1, 0, 4, 1, 3, 1, 2, 2, 1, 2, 3, 0, 5, 3, 5, 5, 2, 4,\n",
              "       5, 1, 5, 1, 5, 3, 4, 1, 4, 1, 5, 4, 5, 1, 2, 1, 1, 5, 1, 3, 2, 5,\n",
              "       2, 1, 3, 5, 4, 4, 0, 0, 3, 1, 2, 2, 3, 5, 1, 5, 3, 4, 2, 2, 0, 2,\n",
              "       2, 5, 5, 0, 3, 3, 2, 2, 0, 3, 4, 0, 4, 2, 4, 5, 4, 1, 5, 3, 2, 2,\n",
              "       5, 4, 3, 3, 4, 3, 3, 4, 1, 5, 2, 3, 2, 2, 0, 2, 1, 3, 1, 2, 2, 5,\n",
              "       5, 1, 4, 2, 2, 1, 1, 3, 3, 5, 5, 2, 5, 1, 5, 0, 3, 3, 0, 5, 1, 4,\n",
              "       1, 4, 2, 5, 5, 1, 4, 2, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds1=predictions.argmax(axis=1)\n",
        "preds1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4_cAI39VFhtp",
        "outputId": "6a4a15c6-5c33-49c2-e7fa-fcc8babbf02d"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2, 3, 3, 0, 4, 4, 1, 2, 5, 1, 4, 3, 2, 2, 0, 5, 4, 3, 2, 4, 1, 2,\n",
              "       2, 5, 5, 2, 1, 3, 4, 2, 2, 5, 2, 5, 3, 1, 2, 0, 4, 5, 2, 5, 2, 2,\n",
              "       3, 2, 1, 1, 3, 4, 4, 5, 1, 1, 4, 4, 5, 1, 1, 1, 0, 1, 2, 0, 5, 1,\n",
              "       1, 1, 1, 4, 0, 5, 4, 3, 5, 5, 2, 2, 5, 2, 1, 0, 5, 3, 5, 5, 2, 5,\n",
              "       3, 1, 5, 1, 5, 3, 2, 2, 4, 1, 5, 4, 5, 1, 2, 1, 1, 5, 1, 5, 2, 5,\n",
              "       1, 3, 3, 5, 4, 4, 3, 0, 3, 0, 1, 2, 1, 5, 1, 3, 3, 5, 2, 2, 1, 4,\n",
              "       2, 3, 5, 0, 3, 3, 2, 5, 0, 5, 4, 1, 4, 4, 4, 2, 4, 1, 5, 3, 2, 2,\n",
              "       5, 4, 4, 3, 5, 5, 5, 4, 1, 5, 2, 5, 2, 2, 0, 2, 1, 5, 1, 4, 4, 5,\n",
              "       5, 1, 4, 2, 4, 1, 1, 3, 3, 5, 5, 2, 5, 1, 5, 1, 3, 3, 3, 4, 1, 4,\n",
              "       1, 4, 5, 5, 4, 1, 4, 2, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "abc = preds1.astype(int).flatten()"
      ],
      "metadata": {
        "id": "H4WEmM60NfQn"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "c = confusion_matrix(new_Ytest, abc) \n",
        "c"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bKEBeEBlFjB8",
        "outputId": "922b6391-1d64-4e39-a28d-0b620f91b558"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 9,  6,  0,  2,  0,  1],\n",
              "       [ 3, 33,  1,  2,  0,  2],\n",
              "       [ 0,  2, 34,  1,  6,  2],\n",
              "       [ 0,  2,  2, 18,  1,  8],\n",
              "       [ 0,  0,  1,  0, 26,  6],\n",
              "       [ 0,  0,  2,  5,  3, 29]])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m4RjG7LWLSQx",
        "outputId": "99d13a63-32e1-4053-90bf-27b09c2468b6"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([3, 3, 3, 0, 4, 4, 1, 2, 5, 0, 5, 3, 2, 2, 1, 4, 4, 5, 2, 4, 1, 2,\n",
              "       3, 5, 4, 2, 1, 2, 2, 2, 2, 5, 2, 5, 3, 1, 2, 0, 4, 5, 2, 3, 2, 2,\n",
              "       5, 2, 0, 1, 3, 4, 4, 5, 1, 1, 4, 4, 5, 1, 1, 1, 0, 1, 5, 0, 4, 1,\n",
              "       1, 0, 1, 4, 1, 0, 4, 1, 3, 1, 2, 2, 1, 2, 3, 0, 5, 3, 5, 5, 2, 4,\n",
              "       5, 1, 5, 1, 5, 3, 4, 1, 4, 1, 5, 4, 5, 1, 2, 1, 1, 5, 1, 3, 2, 5,\n",
              "       2, 1, 3, 5, 4, 4, 0, 0, 3, 1, 2, 2, 3, 5, 1, 5, 3, 4, 2, 2, 0, 2,\n",
              "       2, 5, 5, 0, 3, 3, 2, 2, 0, 3, 4, 0, 4, 2, 4, 5, 4, 1, 5, 3, 2, 2,\n",
              "       5, 4, 3, 3, 4, 3, 3, 4, 1, 5, 2, 3, 2, 2, 0, 2, 1, 3, 1, 2, 2, 5,\n",
              "       5, 1, 4, 2, 2, 1, 1, 3, 3, 5, 5, 2, 5, 1, 5, 0, 3, 3, 0, 5, 1, 4,\n",
              "       1, 4, 2, 5, 5, 1, 4, 2, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss, acc =model.evaluate(x_testcnn, y_test)\n",
        "print(\"Restored model, accuracy: {:5.2f}%\".format(100*acc))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n3kzoqPkDqqS",
        "outputId": "5459d75b-b254-4965-c372-acfd64167070"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7/7 [==============================] - 0s 3ms/step - loss: 0.7314 - accuracy: 0.7198\n",
            "Restored model, accuracy: 71.98%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss, acc =model.evaluate(X_train, y_train)\n",
        "print(\"Restored model train, accuracy: {:5.2f}%\".format(100*acc))"
      ],
      "metadata": {
        "id": "fJDTGH_OUX0z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de3257d7-032d-4cc2-d4d3-78c94241110d"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "52/52 [==============================] - 0s 4ms/step - loss: 0.5667 - accuracy: 0.8235\n",
            "Restored model train, accuracy: 82.35%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix,accuracy_score\n",
        "import seaborn as sn\n",
        "\n",
        "print(classification_report(new_Ytest,abc))\n",
        "\n",
        "acc = float(accuracy_score(new_Ytest,abc))*100\n",
        "print(\"----accuracy score %s ----\" % acc)\n",
        "\n",
        "cm = confusion_matrix(new_Ytest,abc)\n",
        "#df_cm = pd.DataFrame(cm)\n",
        "class_names = ['neutral','calm', 'happy','sad','angry', 'fearful' ]\n",
        "df_cm = pd.DataFrame(cm, index=class_names, columns=class_names,)\n",
        "sn.heatmap(df_cm, annot=True, fmt='')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 508
        },
        "id": "SfSC3El94LZg",
        "outputId": "3ffc49cd-17cb-4896-c0c0-5a4c4d3d3d14"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.50      0.60        18\n",
            "           1       0.77      0.80      0.79        41\n",
            "           2       0.85      0.76      0.80        45\n",
            "           3       0.64      0.58      0.61        31\n",
            "           4       0.72      0.79      0.75        33\n",
            "           5       0.60      0.74      0.67        39\n",
            "\n",
            "    accuracy                           0.72       207\n",
            "   macro avg       0.72      0.70      0.70       207\n",
            "weighted avg       0.73      0.72      0.72       207\n",
            "\n",
            "----accuracy score 71.98067632850241 ----\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "A6UOIsB2xKek"
      },
      "execution_count": 28,
      "outputs": []
    }
  ]
}