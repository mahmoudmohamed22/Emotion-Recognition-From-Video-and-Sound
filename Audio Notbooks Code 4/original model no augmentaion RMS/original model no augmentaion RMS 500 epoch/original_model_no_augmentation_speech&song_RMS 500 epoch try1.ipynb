{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "original model no augmentation speech&song RMS.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9SRCO-a_AlH5",
        "outputId": "7a47c551-4728-45d0-8436-7f79ac1c25f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install librosa"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oi8pWV3yBVjO",
        "outputId": "1967e16c-0823-4ec4-a049-5facc502132f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.7/dist-packages (0.8.1)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.1.0)\n",
            "Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (21.3)\n",
            "Requirement already satisfied: decorator>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.21.6)\n",
            "Requirement already satisfied: numba>=0.43.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (0.51.2)\n",
            "Requirement already satisfied: resampy>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from librosa) (0.2.2)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.4.1)\n",
            "Requirement already satisfied: soundfile>=0.10.2 in /usr/local/lib/python3.7/dist-packages (from librosa) (0.10.3.post1)\n",
            "Requirement already satisfied: audioread>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (2.1.9)\n",
            "Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.6.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba>=0.43.0->librosa) (57.4.0)\n",
            "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba>=0.43.0->librosa) (0.34.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->librosa) (3.0.9)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from pooch>=1.0->librosa) (2.23.0)\n",
            "Requirement already satisfied: appdirs>=1.3.0 in /usr/local/lib/python3.7/dist-packages (from pooch>=1.0->librosa) (1.4.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2022.5.18.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (1.24.3)\n",
            "Requirement already satisfied: six>=1.3 in /usr/local/lib/python3.7/dist-packages (from resampy>=0.2.2->librosa) (1.15.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn!=0.19.0,>=0.14.0->librosa) (3.1.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.7/dist-packages (from soundfile>=0.10.2->librosa) (1.15.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.0->soundfile>=0.10.2->librosa) (2.21)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HJjcbxwy46bG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "3bc2ac4d-c5d0-4427-a498-188d8799f088"
      },
      "source": [
        "# Orignial Notebook: https://github.com/MITESHPUTHRANNEU/Speech-Emotion-Analyzer/blob/master/final_results_gender_test.ipynb\n",
        "# This notebook author: Reza Chu\n",
        "# Last Editing Date: 31st May 2019\n",
        "\n",
        "## Python\n",
        "import os\n",
        "import random\n",
        "import sys\n",
        "\n",
        "import IPython\n",
        "from IPython.display import Audio\n",
        "from IPython.display import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "## Package\n",
        "import glob \n",
        "import keras\n",
        "import IPython.display as ipd\n",
        "import librosa\n",
        "import librosa.display\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import plotly.graph_objs as go\n",
        "import plotly.offline as py\n",
        "import plotly.tools as tls\n",
        "import seaborn as sns\n",
        "import scipy.io.wavfile\n",
        "import tensorflow as tf\n",
        "py.init_notebook_mode(connected=True)\n",
        "\n",
        "## Keras\n",
        "from keras import regularizers\n",
        "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping\n",
        "from keras.callbacks import  History, ReduceLROnPlateau, CSVLogger\n",
        "from keras.models import Model, Sequential\n",
        "from keras.layers import Dense, Embedding, LSTM\n",
        "from keras.layers import Input, Flatten, Dropout, Activation, BatchNormalization\n",
        "from keras.layers import Conv1D, MaxPooling1D, AveragePooling1D\n",
        "from keras.preprocessing import sequence\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.utils import np_utils\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "## Sklearn\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "## Rest\n",
        "from scipy.fftpack import fft\n",
        "from scipy import signal\n",
        "from scipy.io import wavfile\n",
        "from tqdm import tqdm\n",
        "\n",
        "input_duration=3\n",
        "# % pylab inline"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "        <script type=\"text/javascript\">\n",
              "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
              "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
              "        if (typeof require !== 'undefined') {\n",
              "        require.undef(\"plotly\");\n",
              "        requirejs.config({\n",
              "            paths: {\n",
              "                'plotly': ['https://cdn.plot.ly/plotly-2.8.3.min']\n",
              "            }\n",
              "        });\n",
              "        require(['plotly'], function(Plotly) {\n",
              "            window._Plotly = Plotly;\n",
              "        });\n",
              "        }\n",
              "        </script>\n",
              "        "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#radvass speech and song\n",
        "import time\n",
        "import os\n",
        "import librosa\n",
        "from librosa import display\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "count=0\n",
        "path1 = '/content/drive/MyDrive/RAVDESS_speech'\n",
        "path2 = '/content/drive/MyDrive/RAVDESS_song'\n",
        "\n",
        "lst = []\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "for subdir, dirs, files in os.walk(path2):\n",
        "  #print(dirs)\n",
        "  #print(subdir)\n",
        "  #print(files)\n",
        "  for file in files:\n",
        "      try:\n",
        "        count +=1\n",
        "        #Load librosa array, obtain mfcss, store the file and the mcss information in a new array\n",
        "        X, sample_rate = librosa.load(os.path.join(subdir,file), res_type='kaiser_fast')\n",
        "        mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T,axis=0) \n",
        "        # The instruction below converts the labels (from 1 to 8) to a series from 0 to 7\n",
        "        # This is because our predictor needs to start from 0 otherwise it will try to predict also 0.\n",
        "        file = int(file[7:8]) - 1 \n",
        "        arr = mfccs, file\n",
        "        lst.append(arr)\n",
        "      # If the file is not valid, skip it\n",
        "      except ValueError:\n",
        "        continue\n",
        "\n",
        "for subdir, dirs, files in os.walk(path1):\n",
        "  #print(dirs)\n",
        "  #print(subdir)\n",
        " # print(files)\n",
        "  for file in files:\n",
        "      try:\n",
        "        #Load librosa array, obtain mfcss, store the file and the mcss information in a new array\n",
        "        X, sample_rate = librosa.load(os.path.join(subdir,file), res_type='kaiser_fast')\n",
        "        mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T,axis=0) \n",
        "        # The instruction below converts the labels (from 1 to 8) to a series from 0 to 7\n",
        "        # This is because our predictor needs to start from 0 otherwise it will try to predict also 0.\n",
        "        file = int(file[7:8]) - 1 \n",
        "        if(file ==6 or file==7):\n",
        "          continue\n",
        "        count +=1\n",
        "        arr = mfccs, file\n",
        "        lst.append(arr)\n",
        "      # If the file is not valid, skip it\n",
        "      except ValueError:\n",
        "        continue\n",
        "\n",
        "\n",
        "\n",
        "print(\"--- Data loaded. Loading time: %s seconds ---\" % (time.time() - start_time))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IfuyRZl42ccZ",
        "outputId": "7a1aad67-156f-42e2-c01d-8905d55fe61b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Data loaded. Loading time: 388.71568989753723 seconds ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "count"
      ],
      "metadata": {
        "id": "Ltlhi25L2AI5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5c32fd4-1b17-4fad-edd8-d57fbfc0d516"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2068"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy.core.fromnumeric import size\n",
        "size(lst)"
      ],
      "metadata": {
        "id": "HMOH7d7mzHB7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7921778d-7e9a-4f25-f2e5-09caa41ef9e6"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/core/fromnumeric.py:3208: VisibleDeprecationWarning:\n",
            "\n",
            "Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4136"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating X and y: zip makes a list of all the first elements, and a list of all the second elements.\n",
        "X, y = zip(*lst)"
      ],
      "metadata": {
        "id": "ocdL7tSTBoMt"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "X = np.asarray(X)\n",
        "y = np.asarray(y)\n",
        "X.shape, y.shape"
      ],
      "metadata": {
        "id": "vHKwUGTbBtnF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "93429a2d-fc2e-4c0a-9d99-a57a177a8538"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((2068, 40), (2068,))"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "id": "2sUCtbfMztE5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce381845-24b3-4e08-f46b-a52281428487"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2068, 40)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7PSTurzjCo5K",
        "outputId": "beafe53c-2a00-4369-d749-7dad7f0b634d"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2068, 40)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2,train_size=0.8, random_state=42)\n",
        "X_valid, X_test, y_valid, y_test = train_test_split(X_test,y_test, test_size=0.5,train_size=0.5, random_state=42)"
      ],
      "metadata": {
        "id": "Ai4Fy5cPCiq1"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "x_traincnn = np.expand_dims(X_train, axis=2)\n",
        "x_testcnn = np.expand_dims(X_test, axis=2)\n",
        "X_valid= np.expand_dims(X_valid, axis=2)"
      ],
      "metadata": {
        "id": "tp1Fm5K3CEXu"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_traincnn.shape, x_testcnn.shape , X_valid.shape"
      ],
      "metadata": {
        "id": "RI0MxoIPBws5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bfa0769e-abed-4594-9264-27f6ec45f3a2"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1654, 40, 1), (207, 40, 1), (207, 40, 1))"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow"
      ],
      "metadata": {
        "id": "goxL4Y3jKICC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "68d986a6-4921-4e7d-c6cc-2af5a53280dd"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (2.8.2+zzzcolab20220527125636)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.17.3)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (14.0.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow) (57.4.0)\n",
            "Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.5.3)\n",
            "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.46.3)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.26.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.21.6)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (4.2.0)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.0.0)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow) (1.5.2)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.4.6)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (3.3.7)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.6.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.8.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.23.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.35.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (4.11.4)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (3.8.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2022.5.18.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (1.24.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (3.2.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keras"
      ],
      "metadata": {
        "id": "EkcmN9UrKSxj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ecafd7d-30b1-469c-bbbf-065247bf581c"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.7/dist-packages (2.8.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from keras.preprocessing import sequence\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from keras.layers import Input, Flatten, Dropout, Activation\n",
        "from keras.layers import Conv1D, MaxPooling1D\n",
        "from keras.models import Model\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras import optimizers\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv1D(128, 8,padding='same', #classifier.add(Convolution2D(64, (3, 3), padding = 'same', input_shape = (128, 128, 3), activation = 'relu'))\n",
        "                 input_shape=(40,1)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(MaxPooling1D(pool_size=(5)))\n",
        "\n",
        "\n",
        "model.add(Conv1D(256,8,padding='same',))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(MaxPooling1D(pool_size=(5)))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(256))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(256))\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "model.add(Dense(6))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "#opt = tf.keras.optimizers.Adam(lr=0.00002)\n",
        "opt = tf.keras.optimizers.RMSprop(lr=0.00002, rho=0.9, epsilon=1e-07, decay=0.0)\n",
        "#opt = tf.keras.optimizers.SGD(lr=0.001, momentum=0.0, decay=0.0, nesterov=False)"
      ],
      "metadata": {
        "id": "g74fXWVAC4Cr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c021041-4974-48e8-90a7-f0712c48deaf"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/rmsprop.py:130: UserWarning:\n",
            "\n",
            "The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H6ukOxAGC_I4",
        "outputId": "77247d31-4bcd-4d8d-b48f-f6407cf7193e"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d (Conv1D)             (None, 40, 128)           1152      \n",
            "                                                                 \n",
            " activation (Activation)     (None, 40, 128)           0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 40, 128)           0         \n",
            "                                                                 \n",
            " max_pooling1d (MaxPooling1D  (None, 8, 128)           0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv1d_1 (Conv1D)           (None, 8, 256)            262400    \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 8, 256)            0         \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 8, 256)            0         \n",
            "                                                                 \n",
            " max_pooling1d_1 (MaxPooling  (None, 1, 256)           0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 256)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 256)               65792     \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 256)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 256)               65792     \n",
            "                                                                 \n",
            " activation_3 (Activation)   (None, 256)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 6)                 1542      \n",
            "                                                                 \n",
            " activation_4 (Activation)   (None, 6)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 396,678\n",
            "Trainable params: 396,678\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='sparse_categorical_crossentropy',\n",
        "              optimizer=opt,\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "AbMlLNk4DCBM"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#cnnhistory=model.fit(x_traincnn, y_train, batch_size=16, epochs=700, validation_data=(x_testcnn, y_test))\n",
        "cnnhistory=model.fit(x_traincnn, y_train, batch_size=16, epochs=500 , validation_data=(X_valid, y_valid))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RI1v2AuADFhy",
        "outputId": "240ea787-0176-492d-e85f-5b0c5e2bf89a"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "104/104 [==============================] - 17s 15ms/step - loss: 6.4515 - accuracy: 0.1753 - val_loss: 2.1655 - val_accuracy: 0.1594\n",
            "Epoch 2/500\n",
            "104/104 [==============================] - 1s 9ms/step - loss: 4.5519 - accuracy: 0.1778 - val_loss: 2.2568 - val_accuracy: 0.2415\n",
            "Epoch 3/500\n",
            "104/104 [==============================] - 1s 9ms/step - loss: 3.8357 - accuracy: 0.1838 - val_loss: 1.8511 - val_accuracy: 0.1836\n",
            "Epoch 4/500\n",
            "104/104 [==============================] - 1s 10ms/step - loss: 3.4937 - accuracy: 0.1995 - val_loss: 1.9413 - val_accuracy: 0.1884\n",
            "Epoch 5/500\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 3.2071 - accuracy: 0.1850 - val_loss: 2.2168 - val_accuracy: 0.1594\n",
            "Epoch 6/500\n",
            "104/104 [==============================] - 1s 9ms/step - loss: 3.0471 - accuracy: 0.1983 - val_loss: 1.8242 - val_accuracy: 0.2415\n",
            "Epoch 7/500\n",
            "104/104 [==============================] - 1s 9ms/step - loss: 2.8169 - accuracy: 0.1977 - val_loss: 1.7388 - val_accuracy: 0.2512\n",
            "Epoch 8/500\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 2.6182 - accuracy: 0.2164 - val_loss: 1.7184 - val_accuracy: 0.2560\n",
            "Epoch 9/500\n",
            "104/104 [==============================] - 1s 9ms/step - loss: 2.5132 - accuracy: 0.2037 - val_loss: 1.6923 - val_accuracy: 0.2705\n",
            "Epoch 10/500\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 2.5033 - accuracy: 0.1911 - val_loss: 1.6671 - val_accuracy: 0.3140\n",
            "Epoch 11/500\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 2.3464 - accuracy: 0.2056 - val_loss: 1.6451 - val_accuracy: 0.2609\n",
            "Epoch 12/500\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 2.2884 - accuracy: 0.1983 - val_loss: 1.6849 - val_accuracy: 0.2657\n",
            "Epoch 13/500\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 2.2718 - accuracy: 0.1953 - val_loss: 1.6455 - val_accuracy: 0.3575\n",
            "Epoch 14/500\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 2.1202 - accuracy: 0.2243 - val_loss: 1.6417 - val_accuracy: 0.3092\n",
            "Epoch 15/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 2.1193 - accuracy: 0.2080 - val_loss: 1.6523 - val_accuracy: 0.3237\n",
            "Epoch 16/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 2.0620 - accuracy: 0.2146 - val_loss: 1.6475 - val_accuracy: 0.3237\n",
            "Epoch 17/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 2.0187 - accuracy: 0.2231 - val_loss: 1.6871 - val_accuracy: 0.3430\n",
            "Epoch 18/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.9813 - accuracy: 0.2509 - val_loss: 1.6971 - val_accuracy: 0.2802\n",
            "Epoch 19/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.9875 - accuracy: 0.2376 - val_loss: 1.6735 - val_accuracy: 0.3188\n",
            "Epoch 20/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.9687 - accuracy: 0.2183 - val_loss: 1.6664 - val_accuracy: 0.3430\n",
            "Epoch 21/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.9677 - accuracy: 0.2164 - val_loss: 1.7164 - val_accuracy: 0.2609\n",
            "Epoch 22/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.9409 - accuracy: 0.2152 - val_loss: 1.6827 - val_accuracy: 0.3043\n",
            "Epoch 23/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.9291 - accuracy: 0.2237 - val_loss: 1.6774 - val_accuracy: 0.2657\n",
            "Epoch 24/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.8826 - accuracy: 0.2273 - val_loss: 1.6730 - val_accuracy: 0.3285\n",
            "Epoch 25/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.8805 - accuracy: 0.2509 - val_loss: 1.6832 - val_accuracy: 0.2560\n",
            "Epoch 26/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.8710 - accuracy: 0.2539 - val_loss: 1.7167 - val_accuracy: 0.2464\n",
            "Epoch 27/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.8825 - accuracy: 0.2461 - val_loss: 1.6487 - val_accuracy: 0.3478\n",
            "Epoch 28/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.8658 - accuracy: 0.2328 - val_loss: 1.7461 - val_accuracy: 0.2512\n",
            "Epoch 29/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.8324 - accuracy: 0.2654 - val_loss: 1.6991 - val_accuracy: 0.2657\n",
            "Epoch 30/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.8025 - accuracy: 0.2527 - val_loss: 1.6775 - val_accuracy: 0.2657\n",
            "Epoch 31/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.8120 - accuracy: 0.2485 - val_loss: 1.6717 - val_accuracy: 0.2802\n",
            "Epoch 32/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.8099 - accuracy: 0.2394 - val_loss: 1.6763 - val_accuracy: 0.2705\n",
            "Epoch 33/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.7802 - accuracy: 0.2793 - val_loss: 1.6417 - val_accuracy: 0.3527\n",
            "Epoch 34/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.7918 - accuracy: 0.2848 - val_loss: 1.6485 - val_accuracy: 0.3430\n",
            "Epoch 35/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.7648 - accuracy: 0.2727 - val_loss: 1.6352 - val_accuracy: 0.3285\n",
            "Epoch 36/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.7724 - accuracy: 0.2703 - val_loss: 1.6653 - val_accuracy: 0.3188\n",
            "Epoch 37/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.7441 - accuracy: 0.2582 - val_loss: 1.6129 - val_accuracy: 0.3478\n",
            "Epoch 38/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.7481 - accuracy: 0.2775 - val_loss: 1.6212 - val_accuracy: 0.2947\n",
            "Epoch 39/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.7322 - accuracy: 0.2866 - val_loss: 1.6348 - val_accuracy: 0.3671\n",
            "Epoch 40/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.7249 - accuracy: 0.2987 - val_loss: 1.6348 - val_accuracy: 0.3237\n",
            "Epoch 41/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.7305 - accuracy: 0.2823 - val_loss: 1.6352 - val_accuracy: 0.2754\n",
            "Epoch 42/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.7057 - accuracy: 0.2890 - val_loss: 1.6027 - val_accuracy: 0.3575\n",
            "Epoch 43/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.7099 - accuracy: 0.2902 - val_loss: 1.6134 - val_accuracy: 0.3913\n",
            "Epoch 44/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.7006 - accuracy: 0.2848 - val_loss: 1.5776 - val_accuracy: 0.3768\n",
            "Epoch 45/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.7148 - accuracy: 0.2963 - val_loss: 1.5833 - val_accuracy: 0.3623\n",
            "Epoch 46/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.6971 - accuracy: 0.2914 - val_loss: 1.5987 - val_accuracy: 0.3768\n",
            "Epoch 47/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.7139 - accuracy: 0.2956 - val_loss: 1.5821 - val_accuracy: 0.4058\n",
            "Epoch 48/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.6809 - accuracy: 0.2963 - val_loss: 1.5865 - val_accuracy: 0.3720\n",
            "Epoch 49/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.6573 - accuracy: 0.3126 - val_loss: 1.5966 - val_accuracy: 0.3816\n",
            "Epoch 50/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.6689 - accuracy: 0.3041 - val_loss: 1.5673 - val_accuracy: 0.3961\n",
            "Epoch 51/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.6888 - accuracy: 0.2963 - val_loss: 1.5578 - val_accuracy: 0.4106\n",
            "Epoch 52/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.6830 - accuracy: 0.2884 - val_loss: 1.5895 - val_accuracy: 0.3865\n",
            "Epoch 53/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.6623 - accuracy: 0.3210 - val_loss: 1.5956 - val_accuracy: 0.3527\n",
            "Epoch 54/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.6638 - accuracy: 0.3035 - val_loss: 1.5658 - val_accuracy: 0.3913\n",
            "Epoch 55/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.6568 - accuracy: 0.3120 - val_loss: 1.5734 - val_accuracy: 0.4203\n",
            "Epoch 56/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.6593 - accuracy: 0.3120 - val_loss: 1.5604 - val_accuracy: 0.4010\n",
            "Epoch 57/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.6530 - accuracy: 0.3126 - val_loss: 1.5490 - val_accuracy: 0.3865\n",
            "Epoch 58/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.6380 - accuracy: 0.3138 - val_loss: 1.5673 - val_accuracy: 0.4010\n",
            "Epoch 59/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.6195 - accuracy: 0.3325 - val_loss: 1.5493 - val_accuracy: 0.3575\n",
            "Epoch 60/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.6415 - accuracy: 0.3259 - val_loss: 1.5494 - val_accuracy: 0.3382\n",
            "Epoch 61/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.6152 - accuracy: 0.3204 - val_loss: 1.5342 - val_accuracy: 0.4444\n",
            "Epoch 62/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.6173 - accuracy: 0.3343 - val_loss: 1.5363 - val_accuracy: 0.4058\n",
            "Epoch 63/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.6005 - accuracy: 0.3489 - val_loss: 1.5231 - val_accuracy: 0.4638\n",
            "Epoch 64/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.6061 - accuracy: 0.3410 - val_loss: 1.5077 - val_accuracy: 0.4396\n",
            "Epoch 65/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.5808 - accuracy: 0.3404 - val_loss: 1.5478 - val_accuracy: 0.3816\n",
            "Epoch 66/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.5932 - accuracy: 0.3313 - val_loss: 1.4930 - val_accuracy: 0.4203\n",
            "Epoch 67/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.5798 - accuracy: 0.3452 - val_loss: 1.5196 - val_accuracy: 0.3623\n",
            "Epoch 68/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.5716 - accuracy: 0.3519 - val_loss: 1.5125 - val_accuracy: 0.4106\n",
            "Epoch 69/500\n",
            "104/104 [==============================] - 0s 4ms/step - loss: 1.5877 - accuracy: 0.3495 - val_loss: 1.4927 - val_accuracy: 0.4444\n",
            "Epoch 70/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.5793 - accuracy: 0.3531 - val_loss: 1.4800 - val_accuracy: 0.4396\n",
            "Epoch 71/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.5783 - accuracy: 0.3343 - val_loss: 1.5044 - val_accuracy: 0.3768\n",
            "Epoch 72/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.5517 - accuracy: 0.3634 - val_loss: 1.4677 - val_accuracy: 0.4493\n",
            "Epoch 73/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.5594 - accuracy: 0.3573 - val_loss: 1.4654 - val_accuracy: 0.4203\n",
            "Epoch 74/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.5612 - accuracy: 0.3573 - val_loss: 1.4788 - val_accuracy: 0.4300\n",
            "Epoch 75/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.5284 - accuracy: 0.3670 - val_loss: 1.4751 - val_accuracy: 0.4396\n",
            "Epoch 76/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.5188 - accuracy: 0.3906 - val_loss: 1.4478 - val_accuracy: 0.5024\n",
            "Epoch 77/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.5357 - accuracy: 0.3706 - val_loss: 1.4975 - val_accuracy: 0.3768\n",
            "Epoch 78/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.5189 - accuracy: 0.3755 - val_loss: 1.4683 - val_accuracy: 0.4638\n",
            "Epoch 79/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.5083 - accuracy: 0.3785 - val_loss: 1.4654 - val_accuracy: 0.4106\n",
            "Epoch 80/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.5126 - accuracy: 0.3676 - val_loss: 1.4705 - val_accuracy: 0.4396\n",
            "Epoch 81/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.5097 - accuracy: 0.3761 - val_loss: 1.4212 - val_accuracy: 0.4638\n",
            "Epoch 82/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.5171 - accuracy: 0.3863 - val_loss: 1.4298 - val_accuracy: 0.4879\n",
            "Epoch 83/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.5034 - accuracy: 0.3936 - val_loss: 1.4314 - val_accuracy: 0.4831\n",
            "Epoch 84/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.4850 - accuracy: 0.3894 - val_loss: 1.4252 - val_accuracy: 0.4831\n",
            "Epoch 85/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.5162 - accuracy: 0.3748 - val_loss: 1.4083 - val_accuracy: 0.4831\n",
            "Epoch 86/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.4989 - accuracy: 0.4002 - val_loss: 1.4299 - val_accuracy: 0.4734\n",
            "Epoch 87/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.5043 - accuracy: 0.3821 - val_loss: 1.4137 - val_accuracy: 0.4879\n",
            "Epoch 88/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.4773 - accuracy: 0.3972 - val_loss: 1.4222 - val_accuracy: 0.5121\n",
            "Epoch 89/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.4721 - accuracy: 0.4015 - val_loss: 1.4155 - val_accuracy: 0.4686\n",
            "Epoch 90/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.4651 - accuracy: 0.3857 - val_loss: 1.4243 - val_accuracy: 0.4444\n",
            "Epoch 91/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.5042 - accuracy: 0.3912 - val_loss: 1.4072 - val_accuracy: 0.4976\n",
            "Epoch 92/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.4672 - accuracy: 0.3960 - val_loss: 1.4106 - val_accuracy: 0.4589\n",
            "Epoch 93/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.4534 - accuracy: 0.4075 - val_loss: 1.4118 - val_accuracy: 0.4444\n",
            "Epoch 94/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.4571 - accuracy: 0.4033 - val_loss: 1.3799 - val_accuracy: 0.5072\n",
            "Epoch 95/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.4665 - accuracy: 0.4166 - val_loss: 1.3842 - val_accuracy: 0.5072\n",
            "Epoch 96/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.4347 - accuracy: 0.4160 - val_loss: 1.3805 - val_accuracy: 0.5217\n",
            "Epoch 97/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.4310 - accuracy: 0.4196 - val_loss: 1.3615 - val_accuracy: 0.5121\n",
            "Epoch 98/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.4247 - accuracy: 0.4214 - val_loss: 1.3738 - val_accuracy: 0.5217\n",
            "Epoch 99/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.4300 - accuracy: 0.3990 - val_loss: 1.3673 - val_accuracy: 0.4879\n",
            "Epoch 100/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.4351 - accuracy: 0.4069 - val_loss: 1.3629 - val_accuracy: 0.5362\n",
            "Epoch 101/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.4432 - accuracy: 0.4141 - val_loss: 1.3613 - val_accuracy: 0.5169\n",
            "Epoch 102/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.4407 - accuracy: 0.4135 - val_loss: 1.3667 - val_accuracy: 0.5024\n",
            "Epoch 103/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.3962 - accuracy: 0.4329 - val_loss: 1.3593 - val_accuracy: 0.5169\n",
            "Epoch 104/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.4046 - accuracy: 0.4287 - val_loss: 1.3613 - val_accuracy: 0.4928\n",
            "Epoch 105/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.4224 - accuracy: 0.4250 - val_loss: 1.3470 - val_accuracy: 0.5169\n",
            "Epoch 106/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.3935 - accuracy: 0.4347 - val_loss: 1.3470 - val_accuracy: 0.5169\n",
            "Epoch 107/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.3917 - accuracy: 0.4414 - val_loss: 1.3328 - val_accuracy: 0.5411\n",
            "Epoch 108/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.3937 - accuracy: 0.4438 - val_loss: 1.3244 - val_accuracy: 0.5507\n",
            "Epoch 109/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.3877 - accuracy: 0.4256 - val_loss: 1.3470 - val_accuracy: 0.4783\n",
            "Epoch 110/500\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 1.3974 - accuracy: 0.4329 - val_loss: 1.3319 - val_accuracy: 0.5169\n",
            "Epoch 111/500\n",
            "104/104 [==============================] - 1s 9ms/step - loss: 1.3644 - accuracy: 0.4323 - val_loss: 1.3336 - val_accuracy: 0.4976\n",
            "Epoch 112/500\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 1.3810 - accuracy: 0.4335 - val_loss: 1.3421 - val_accuracy: 0.4783\n",
            "Epoch 113/500\n",
            "104/104 [==============================] - 1s 12ms/step - loss: 1.3861 - accuracy: 0.4432 - val_loss: 1.3539 - val_accuracy: 0.5072\n",
            "Epoch 114/500\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 1.3690 - accuracy: 0.4486 - val_loss: 1.3287 - val_accuracy: 0.5314\n",
            "Epoch 115/500\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 1.3594 - accuracy: 0.4492 - val_loss: 1.3355 - val_accuracy: 0.5266\n",
            "Epoch 116/500\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 1.3868 - accuracy: 0.4468 - val_loss: 1.3300 - val_accuracy: 0.5362\n",
            "Epoch 117/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 1.3508 - accuracy: 0.4504 - val_loss: 1.2983 - val_accuracy: 0.5362\n",
            "Epoch 118/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.3520 - accuracy: 0.4547 - val_loss: 1.3039 - val_accuracy: 0.5362\n",
            "Epoch 119/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.3452 - accuracy: 0.4637 - val_loss: 1.3116 - val_accuracy: 0.5024\n",
            "Epoch 120/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.3446 - accuracy: 0.4547 - val_loss: 1.2827 - val_accuracy: 0.5556\n",
            "Epoch 121/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.3541 - accuracy: 0.4486 - val_loss: 1.3147 - val_accuracy: 0.5217\n",
            "Epoch 122/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.3279 - accuracy: 0.4601 - val_loss: 1.2709 - val_accuracy: 0.5459\n",
            "Epoch 123/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.3477 - accuracy: 0.4498 - val_loss: 1.2920 - val_accuracy: 0.5266\n",
            "Epoch 124/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.3186 - accuracy: 0.4764 - val_loss: 1.2961 - val_accuracy: 0.5314\n",
            "Epoch 125/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.3161 - accuracy: 0.4698 - val_loss: 1.2750 - val_accuracy: 0.5652\n",
            "Epoch 126/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.2900 - accuracy: 0.4879 - val_loss: 1.2573 - val_accuracy: 0.5700\n",
            "Epoch 127/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.3108 - accuracy: 0.4643 - val_loss: 1.2671 - val_accuracy: 0.5459\n",
            "Epoch 128/500\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 1.3234 - accuracy: 0.4722 - val_loss: 1.2633 - val_accuracy: 0.5411\n",
            "Epoch 129/500\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 1.3078 - accuracy: 0.4692 - val_loss: 1.2533 - val_accuracy: 0.5604\n",
            "Epoch 130/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.3198 - accuracy: 0.4710 - val_loss: 1.2681 - val_accuracy: 0.5362\n",
            "Epoch 131/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.3053 - accuracy: 0.4764 - val_loss: 1.2579 - val_accuracy: 0.5652\n",
            "Epoch 132/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.2725 - accuracy: 0.4843 - val_loss: 1.2437 - val_accuracy: 0.5217\n",
            "Epoch 133/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.2986 - accuracy: 0.4988 - val_loss: 1.2688 - val_accuracy: 0.5266\n",
            "Epoch 134/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.2841 - accuracy: 0.4861 - val_loss: 1.2606 - val_accuracy: 0.5072\n",
            "Epoch 135/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.2880 - accuracy: 0.4794 - val_loss: 1.2478 - val_accuracy: 0.5411\n",
            "Epoch 136/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.2999 - accuracy: 0.4758 - val_loss: 1.2694 - val_accuracy: 0.5072\n",
            "Epoch 137/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.2613 - accuracy: 0.4903 - val_loss: 1.2060 - val_accuracy: 0.5749\n",
            "Epoch 138/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.2675 - accuracy: 0.4940 - val_loss: 1.2574 - val_accuracy: 0.5411\n",
            "Epoch 139/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.2604 - accuracy: 0.4879 - val_loss: 1.2163 - val_accuracy: 0.5700\n",
            "Epoch 140/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.2714 - accuracy: 0.4831 - val_loss: 1.2163 - val_accuracy: 0.5797\n",
            "Epoch 141/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.2620 - accuracy: 0.4958 - val_loss: 1.2395 - val_accuracy: 0.5507\n",
            "Epoch 142/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.2781 - accuracy: 0.4825 - val_loss: 1.2153 - val_accuracy: 0.5507\n",
            "Epoch 143/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.2822 - accuracy: 0.4794 - val_loss: 1.2259 - val_accuracy: 0.5556\n",
            "Epoch 144/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.2623 - accuracy: 0.4903 - val_loss: 1.2355 - val_accuracy: 0.5604\n",
            "Epoch 145/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.2394 - accuracy: 0.5042 - val_loss: 1.2146 - val_accuracy: 0.5797\n",
            "Epoch 146/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.2465 - accuracy: 0.5000 - val_loss: 1.2313 - val_accuracy: 0.5797\n",
            "Epoch 147/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.2588 - accuracy: 0.4982 - val_loss: 1.2081 - val_accuracy: 0.5459\n",
            "Epoch 148/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.2616 - accuracy: 0.4885 - val_loss: 1.2097 - val_accuracy: 0.5700\n",
            "Epoch 149/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.2303 - accuracy: 0.5145 - val_loss: 1.1951 - val_accuracy: 0.5507\n",
            "Epoch 150/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.2168 - accuracy: 0.5024 - val_loss: 1.2152 - val_accuracy: 0.5604\n",
            "Epoch 151/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.2139 - accuracy: 0.5127 - val_loss: 1.1784 - val_accuracy: 0.5797\n",
            "Epoch 152/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.2530 - accuracy: 0.5103 - val_loss: 1.2092 - val_accuracy: 0.5700\n",
            "Epoch 153/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.2211 - accuracy: 0.5115 - val_loss: 1.1956 - val_accuracy: 0.5556\n",
            "Epoch 154/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.2354 - accuracy: 0.5018 - val_loss: 1.1752 - val_accuracy: 0.5845\n",
            "Epoch 155/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.2400 - accuracy: 0.5067 - val_loss: 1.1776 - val_accuracy: 0.6039\n",
            "Epoch 156/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.2199 - accuracy: 0.5060 - val_loss: 1.1845 - val_accuracy: 0.6087\n",
            "Epoch 157/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.1992 - accuracy: 0.5314 - val_loss: 1.1954 - val_accuracy: 0.5845\n",
            "Epoch 158/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.2190 - accuracy: 0.4952 - val_loss: 1.1650 - val_accuracy: 0.5942\n",
            "Epoch 159/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.1953 - accuracy: 0.5193 - val_loss: 1.1730 - val_accuracy: 0.6039\n",
            "Epoch 160/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.2087 - accuracy: 0.5067 - val_loss: 1.1725 - val_accuracy: 0.5797\n",
            "Epoch 161/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.2225 - accuracy: 0.4909 - val_loss: 1.1528 - val_accuracy: 0.5894\n",
            "Epoch 162/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.1899 - accuracy: 0.5320 - val_loss: 1.1552 - val_accuracy: 0.5749\n",
            "Epoch 163/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.2066 - accuracy: 0.5121 - val_loss: 1.1491 - val_accuracy: 0.5845\n",
            "Epoch 164/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.2032 - accuracy: 0.5272 - val_loss: 1.1653 - val_accuracy: 0.5990\n",
            "Epoch 165/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.1934 - accuracy: 0.5157 - val_loss: 1.1619 - val_accuracy: 0.5797\n",
            "Epoch 166/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.1912 - accuracy: 0.5206 - val_loss: 1.1302 - val_accuracy: 0.5990\n",
            "Epoch 167/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.1761 - accuracy: 0.5417 - val_loss: 1.1607 - val_accuracy: 0.5894\n",
            "Epoch 168/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.1754 - accuracy: 0.5181 - val_loss: 1.1694 - val_accuracy: 0.5700\n",
            "Epoch 169/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.1674 - accuracy: 0.5230 - val_loss: 1.1449 - val_accuracy: 0.5942\n",
            "Epoch 170/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.1674 - accuracy: 0.5290 - val_loss: 1.1393 - val_accuracy: 0.5749\n",
            "Epoch 171/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.1603 - accuracy: 0.5278 - val_loss: 1.1374 - val_accuracy: 0.5845\n",
            "Epoch 172/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.1644 - accuracy: 0.5326 - val_loss: 1.1426 - val_accuracy: 0.5652\n",
            "Epoch 173/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.1569 - accuracy: 0.5381 - val_loss: 1.1515 - val_accuracy: 0.6039\n",
            "Epoch 174/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.1633 - accuracy: 0.5326 - val_loss: 1.1272 - val_accuracy: 0.5990\n",
            "Epoch 175/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.1667 - accuracy: 0.5260 - val_loss: 1.1656 - val_accuracy: 0.5845\n",
            "Epoch 176/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.1629 - accuracy: 0.5266 - val_loss: 1.1440 - val_accuracy: 0.5652\n",
            "Epoch 177/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.1732 - accuracy: 0.5466 - val_loss: 1.1208 - val_accuracy: 0.5990\n",
            "Epoch 178/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.1461 - accuracy: 0.5466 - val_loss: 1.1308 - val_accuracy: 0.6135\n",
            "Epoch 179/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.1738 - accuracy: 0.5387 - val_loss: 1.1377 - val_accuracy: 0.5990\n",
            "Epoch 180/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.1668 - accuracy: 0.5308 - val_loss: 1.1221 - val_accuracy: 0.5942\n",
            "Epoch 181/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.1375 - accuracy: 0.5520 - val_loss: 1.1502 - val_accuracy: 0.5749\n",
            "Epoch 182/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.1532 - accuracy: 0.5417 - val_loss: 1.1239 - val_accuracy: 0.5990\n",
            "Epoch 183/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.1642 - accuracy: 0.5296 - val_loss: 1.1456 - val_accuracy: 0.5894\n",
            "Epoch 184/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.1469 - accuracy: 0.5405 - val_loss: 1.1022 - val_accuracy: 0.6329\n",
            "Epoch 185/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.1080 - accuracy: 0.5593 - val_loss: 1.1214 - val_accuracy: 0.5894\n",
            "Epoch 186/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.1262 - accuracy: 0.5423 - val_loss: 1.0908 - val_accuracy: 0.5894\n",
            "Epoch 187/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.1420 - accuracy: 0.5490 - val_loss: 1.1177 - val_accuracy: 0.6039\n",
            "Epoch 188/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.1274 - accuracy: 0.5593 - val_loss: 1.0986 - val_accuracy: 0.6184\n",
            "Epoch 189/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.1391 - accuracy: 0.5508 - val_loss: 1.0842 - val_accuracy: 0.6425\n",
            "Epoch 190/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.1243 - accuracy: 0.5478 - val_loss: 1.0871 - val_accuracy: 0.6039\n",
            "Epoch 191/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.1213 - accuracy: 0.5514 - val_loss: 1.0869 - val_accuracy: 0.5990\n",
            "Epoch 192/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.1250 - accuracy: 0.5496 - val_loss: 1.0733 - val_accuracy: 0.6184\n",
            "Epoch 193/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.1127 - accuracy: 0.5496 - val_loss: 1.0912 - val_accuracy: 0.6039\n",
            "Epoch 194/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.1175 - accuracy: 0.5508 - val_loss: 1.1004 - val_accuracy: 0.6039\n",
            "Epoch 195/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.1193 - accuracy: 0.5593 - val_loss: 1.0904 - val_accuracy: 0.5990\n",
            "Epoch 196/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.1183 - accuracy: 0.5508 - val_loss: 1.0743 - val_accuracy: 0.6184\n",
            "Epoch 197/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.1068 - accuracy: 0.5629 - val_loss: 1.0754 - val_accuracy: 0.6232\n",
            "Epoch 198/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0880 - accuracy: 0.5738 - val_loss: 1.0665 - val_accuracy: 0.6425\n",
            "Epoch 199/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0899 - accuracy: 0.5623 - val_loss: 1.0710 - val_accuracy: 0.6425\n",
            "Epoch 200/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.1147 - accuracy: 0.5574 - val_loss: 1.0739 - val_accuracy: 0.6329\n",
            "Epoch 201/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0888 - accuracy: 0.5605 - val_loss: 1.0628 - val_accuracy: 0.6135\n",
            "Epoch 202/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0750 - accuracy: 0.5719 - val_loss: 1.0492 - val_accuracy: 0.6473\n",
            "Epoch 203/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0857 - accuracy: 0.5707 - val_loss: 1.0594 - val_accuracy: 0.6280\n",
            "Epoch 204/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.1067 - accuracy: 0.5647 - val_loss: 1.0547 - val_accuracy: 0.6377\n",
            "Epoch 205/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0911 - accuracy: 0.5526 - val_loss: 1.0783 - val_accuracy: 0.6329\n",
            "Epoch 206/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0937 - accuracy: 0.5605 - val_loss: 1.0542 - val_accuracy: 0.6715\n",
            "Epoch 207/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.1039 - accuracy: 0.5520 - val_loss: 1.0816 - val_accuracy: 0.6232\n",
            "Epoch 208/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0850 - accuracy: 0.5792 - val_loss: 1.0682 - val_accuracy: 0.6473\n",
            "Epoch 209/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0824 - accuracy: 0.5659 - val_loss: 1.0527 - val_accuracy: 0.6522\n",
            "Epoch 210/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0804 - accuracy: 0.5695 - val_loss: 1.0761 - val_accuracy: 0.5845\n",
            "Epoch 211/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0742 - accuracy: 0.5810 - val_loss: 1.0476 - val_accuracy: 0.6232\n",
            "Epoch 212/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0813 - accuracy: 0.5780 - val_loss: 1.0498 - val_accuracy: 0.6280\n",
            "Epoch 213/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0823 - accuracy: 0.5732 - val_loss: 1.0790 - val_accuracy: 0.6087\n",
            "Epoch 214/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0616 - accuracy: 0.5859 - val_loss: 1.0593 - val_accuracy: 0.6329\n",
            "Epoch 215/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0568 - accuracy: 0.5774 - val_loss: 1.0241 - val_accuracy: 0.6715\n",
            "Epoch 216/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0616 - accuracy: 0.5719 - val_loss: 1.0662 - val_accuracy: 0.6039\n",
            "Epoch 217/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0683 - accuracy: 0.5744 - val_loss: 1.0563 - val_accuracy: 0.6087\n",
            "Epoch 218/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0633 - accuracy: 0.5677 - val_loss: 1.0587 - val_accuracy: 0.6184\n",
            "Epoch 219/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0577 - accuracy: 0.5768 - val_loss: 1.1021 - val_accuracy: 0.5942\n",
            "Epoch 220/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0379 - accuracy: 0.5883 - val_loss: 1.0345 - val_accuracy: 0.6377\n",
            "Epoch 221/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0409 - accuracy: 0.5992 - val_loss: 1.0165 - val_accuracy: 0.6377\n",
            "Epoch 222/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0739 - accuracy: 0.5732 - val_loss: 1.0442 - val_accuracy: 0.6087\n",
            "Epoch 223/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0481 - accuracy: 0.5695 - val_loss: 1.0277 - val_accuracy: 0.6232\n",
            "Epoch 224/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0378 - accuracy: 0.5937 - val_loss: 1.0322 - val_accuracy: 0.6570\n",
            "Epoch 225/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0436 - accuracy: 0.5907 - val_loss: 1.0424 - val_accuracy: 0.6232\n",
            "Epoch 226/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0592 - accuracy: 0.5834 - val_loss: 1.0278 - val_accuracy: 0.6618\n",
            "Epoch 227/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0148 - accuracy: 0.6016 - val_loss: 1.0220 - val_accuracy: 0.6473\n",
            "Epoch 228/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0224 - accuracy: 0.5967 - val_loss: 1.0451 - val_accuracy: 0.6329\n",
            "Epoch 229/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0394 - accuracy: 0.5919 - val_loss: 1.0249 - val_accuracy: 0.6329\n",
            "Epoch 230/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0295 - accuracy: 0.5877 - val_loss: 1.0066 - val_accuracy: 0.6473\n",
            "Epoch 231/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0506 - accuracy: 0.5871 - val_loss: 1.0538 - val_accuracy: 0.6039\n",
            "Epoch 232/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0233 - accuracy: 0.5925 - val_loss: 1.0281 - val_accuracy: 0.6425\n",
            "Epoch 233/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0380 - accuracy: 0.5955 - val_loss: 1.0114 - val_accuracy: 0.6425\n",
            "Epoch 234/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0193 - accuracy: 0.5992 - val_loss: 1.0187 - val_accuracy: 0.6232\n",
            "Epoch 235/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0121 - accuracy: 0.6022 - val_loss: 1.0558 - val_accuracy: 0.6135\n",
            "Epoch 236/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0292 - accuracy: 0.5937 - val_loss: 1.0110 - val_accuracy: 0.6618\n",
            "Epoch 237/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0447 - accuracy: 0.5919 - val_loss: 1.0812 - val_accuracy: 0.5797\n",
            "Epoch 238/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0234 - accuracy: 0.5961 - val_loss: 1.0160 - val_accuracy: 0.6473\n",
            "Epoch 239/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0151 - accuracy: 0.5907 - val_loss: 1.0150 - val_accuracy: 0.6329\n",
            "Epoch 240/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0182 - accuracy: 0.5967 - val_loss: 1.0294 - val_accuracy: 0.6039\n",
            "Epoch 241/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0188 - accuracy: 0.6064 - val_loss: 0.9962 - val_accuracy: 0.6570\n",
            "Epoch 242/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9891 - accuracy: 0.6046 - val_loss: 0.9877 - val_accuracy: 0.6715\n",
            "Epoch 243/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0219 - accuracy: 0.5937 - val_loss: 0.9950 - val_accuracy: 0.6329\n",
            "Epoch 244/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9901 - accuracy: 0.6209 - val_loss: 0.9982 - val_accuracy: 0.6473\n",
            "Epoch 245/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9978 - accuracy: 0.6004 - val_loss: 1.0146 - val_accuracy: 0.6522\n",
            "Epoch 246/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9910 - accuracy: 0.6155 - val_loss: 0.9919 - val_accuracy: 0.6377\n",
            "Epoch 247/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9946 - accuracy: 0.6064 - val_loss: 1.0007 - val_accuracy: 0.6377\n",
            "Epoch 248/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0000 - accuracy: 0.6010 - val_loss: 1.0174 - val_accuracy: 0.6329\n",
            "Epoch 249/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0045 - accuracy: 0.5973 - val_loss: 1.0087 - val_accuracy: 0.6377\n",
            "Epoch 250/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9907 - accuracy: 0.6046 - val_loss: 1.0009 - val_accuracy: 0.6570\n",
            "Epoch 251/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9776 - accuracy: 0.6185 - val_loss: 0.9751 - val_accuracy: 0.6667\n",
            "Epoch 252/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9997 - accuracy: 0.6004 - val_loss: 0.9891 - val_accuracy: 0.6570\n",
            "Epoch 253/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9777 - accuracy: 0.6131 - val_loss: 0.9691 - val_accuracy: 0.6667\n",
            "Epoch 254/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9774 - accuracy: 0.6245 - val_loss: 0.9957 - val_accuracy: 0.6377\n",
            "Epoch 255/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9889 - accuracy: 0.6076 - val_loss: 0.9779 - val_accuracy: 0.6715\n",
            "Epoch 256/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9837 - accuracy: 0.5907 - val_loss: 0.9809 - val_accuracy: 0.6425\n",
            "Epoch 257/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9632 - accuracy: 0.6046 - val_loss: 0.9647 - val_accuracy: 0.6860\n",
            "Epoch 258/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9661 - accuracy: 0.6252 - val_loss: 0.9574 - val_accuracy: 0.6618\n",
            "Epoch 259/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9855 - accuracy: 0.6119 - val_loss: 0.9614 - val_accuracy: 0.6667\n",
            "Epoch 260/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9724 - accuracy: 0.6252 - val_loss: 0.9683 - val_accuracy: 0.6618\n",
            "Epoch 261/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9672 - accuracy: 0.6161 - val_loss: 0.9818 - val_accuracy: 0.6473\n",
            "Epoch 262/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9597 - accuracy: 0.6233 - val_loss: 0.9551 - val_accuracy: 0.6570\n",
            "Epoch 263/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9722 - accuracy: 0.6112 - val_loss: 0.9950 - val_accuracy: 0.6329\n",
            "Epoch 264/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9661 - accuracy: 0.6191 - val_loss: 0.9620 - val_accuracy: 0.6280\n",
            "Epoch 265/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9651 - accuracy: 0.6276 - val_loss: 1.0060 - val_accuracy: 0.6425\n",
            "Epoch 266/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9733 - accuracy: 0.6270 - val_loss: 0.9604 - val_accuracy: 0.6860\n",
            "Epoch 267/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9516 - accuracy: 0.6451 - val_loss: 0.9466 - val_accuracy: 0.6908\n",
            "Epoch 268/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.9621 - accuracy: 0.6143 - val_loss: 0.9579 - val_accuracy: 0.6570\n",
            "Epoch 269/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9676 - accuracy: 0.6294 - val_loss: 0.9317 - val_accuracy: 0.6812\n",
            "Epoch 270/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9507 - accuracy: 0.6233 - val_loss: 0.9684 - val_accuracy: 0.6473\n",
            "Epoch 271/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9639 - accuracy: 0.6173 - val_loss: 0.9740 - val_accuracy: 0.6377\n",
            "Epoch 272/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9696 - accuracy: 0.6258 - val_loss: 0.9466 - val_accuracy: 0.6715\n",
            "Epoch 273/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9478 - accuracy: 0.6282 - val_loss: 0.9629 - val_accuracy: 0.6570\n",
            "Epoch 274/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9528 - accuracy: 0.6264 - val_loss: 0.9556 - val_accuracy: 0.6715\n",
            "Epoch 275/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9520 - accuracy: 0.6270 - val_loss: 0.9456 - val_accuracy: 0.6473\n",
            "Epoch 276/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9492 - accuracy: 0.6245 - val_loss: 0.9413 - val_accuracy: 0.6812\n",
            "Epoch 277/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9401 - accuracy: 0.6245 - val_loss: 0.9346 - val_accuracy: 0.6908\n",
            "Epoch 278/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9257 - accuracy: 0.6397 - val_loss: 0.9291 - val_accuracy: 0.6715\n",
            "Epoch 279/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9357 - accuracy: 0.6300 - val_loss: 0.9504 - val_accuracy: 0.6570\n",
            "Epoch 280/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9344 - accuracy: 0.6336 - val_loss: 0.9485 - val_accuracy: 0.6667\n",
            "Epoch 281/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9186 - accuracy: 0.6378 - val_loss: 0.9450 - val_accuracy: 0.6763\n",
            "Epoch 282/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9167 - accuracy: 0.6330 - val_loss: 0.9701 - val_accuracy: 0.6329\n",
            "Epoch 283/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9635 - accuracy: 0.6233 - val_loss: 0.9371 - val_accuracy: 0.6908\n",
            "Epoch 284/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9352 - accuracy: 0.6288 - val_loss: 0.9434 - val_accuracy: 0.6473\n",
            "Epoch 285/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9461 - accuracy: 0.6397 - val_loss: 0.9231 - val_accuracy: 0.6860\n",
            "Epoch 286/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9166 - accuracy: 0.6348 - val_loss: 0.9441 - val_accuracy: 0.6425\n",
            "Epoch 287/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9261 - accuracy: 0.6342 - val_loss: 0.9123 - val_accuracy: 0.7005\n",
            "Epoch 288/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9275 - accuracy: 0.6330 - val_loss: 0.9369 - val_accuracy: 0.6667\n",
            "Epoch 289/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9039 - accuracy: 0.6385 - val_loss: 0.9117 - val_accuracy: 0.6570\n",
            "Epoch 290/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9271 - accuracy: 0.6324 - val_loss: 0.9355 - val_accuracy: 0.6715\n",
            "Epoch 291/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9222 - accuracy: 0.6330 - val_loss: 0.9216 - val_accuracy: 0.6667\n",
            "Epoch 292/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9245 - accuracy: 0.6360 - val_loss: 0.9316 - val_accuracy: 0.6570\n",
            "Epoch 293/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8951 - accuracy: 0.6505 - val_loss: 0.9347 - val_accuracy: 0.6763\n",
            "Epoch 294/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9201 - accuracy: 0.6288 - val_loss: 0.9131 - val_accuracy: 0.6715\n",
            "Epoch 295/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9246 - accuracy: 0.6197 - val_loss: 0.9162 - val_accuracy: 0.6908\n",
            "Epoch 296/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9211 - accuracy: 0.6300 - val_loss: 0.9284 - val_accuracy: 0.6522\n",
            "Epoch 297/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9156 - accuracy: 0.6421 - val_loss: 0.9167 - val_accuracy: 0.6957\n",
            "Epoch 298/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9052 - accuracy: 0.6445 - val_loss: 0.9278 - val_accuracy: 0.6908\n",
            "Epoch 299/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9086 - accuracy: 0.6469 - val_loss: 0.9140 - val_accuracy: 0.6763\n",
            "Epoch 300/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9120 - accuracy: 0.6391 - val_loss: 0.9263 - val_accuracy: 0.6618\n",
            "Epoch 301/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8982 - accuracy: 0.6475 - val_loss: 0.9165 - val_accuracy: 0.6812\n",
            "Epoch 302/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8838 - accuracy: 0.6578 - val_loss: 0.9382 - val_accuracy: 0.6715\n",
            "Epoch 303/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9189 - accuracy: 0.6421 - val_loss: 0.9142 - val_accuracy: 0.7101\n",
            "Epoch 304/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8950 - accuracy: 0.6487 - val_loss: 0.9199 - val_accuracy: 0.6812\n",
            "Epoch 305/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9051 - accuracy: 0.6372 - val_loss: 0.9051 - val_accuracy: 0.6812\n",
            "Epoch 306/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.8899 - accuracy: 0.6457 - val_loss: 0.9341 - val_accuracy: 0.6570\n",
            "Epoch 307/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8917 - accuracy: 0.6391 - val_loss: 0.9085 - val_accuracy: 0.7053\n",
            "Epoch 308/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9017 - accuracy: 0.6433 - val_loss: 0.9155 - val_accuracy: 0.6570\n",
            "Epoch 309/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9011 - accuracy: 0.6433 - val_loss: 0.8999 - val_accuracy: 0.6812\n",
            "Epoch 310/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8781 - accuracy: 0.6717 - val_loss: 0.9137 - val_accuracy: 0.6618\n",
            "Epoch 311/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8810 - accuracy: 0.6530 - val_loss: 0.9061 - val_accuracy: 0.6908\n",
            "Epoch 312/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8876 - accuracy: 0.6536 - val_loss: 0.9062 - val_accuracy: 0.6763\n",
            "Epoch 313/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8795 - accuracy: 0.6657 - val_loss: 0.8908 - val_accuracy: 0.6812\n",
            "Epoch 314/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8963 - accuracy: 0.6663 - val_loss: 0.8956 - val_accuracy: 0.6812\n",
            "Epoch 315/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8806 - accuracy: 0.6566 - val_loss: 0.8918 - val_accuracy: 0.6908\n",
            "Epoch 316/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8977 - accuracy: 0.6548 - val_loss: 0.9169 - val_accuracy: 0.6763\n",
            "Epoch 317/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.8795 - accuracy: 0.6457 - val_loss: 0.9046 - val_accuracy: 0.6715\n",
            "Epoch 318/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8773 - accuracy: 0.6602 - val_loss: 0.8987 - val_accuracy: 0.6908\n",
            "Epoch 319/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8927 - accuracy: 0.6578 - val_loss: 0.8870 - val_accuracy: 0.6860\n",
            "Epoch 320/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8973 - accuracy: 0.6457 - val_loss: 0.9112 - val_accuracy: 0.6715\n",
            "Epoch 321/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.8839 - accuracy: 0.6427 - val_loss: 0.9048 - val_accuracy: 0.6715\n",
            "Epoch 322/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8905 - accuracy: 0.6481 - val_loss: 0.9369 - val_accuracy: 0.6377\n",
            "Epoch 323/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8906 - accuracy: 0.6524 - val_loss: 0.8882 - val_accuracy: 0.7101\n",
            "Epoch 324/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8934 - accuracy: 0.6463 - val_loss: 0.8872 - val_accuracy: 0.7005\n",
            "Epoch 325/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8784 - accuracy: 0.6596 - val_loss: 0.9106 - val_accuracy: 0.6908\n",
            "Epoch 326/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8656 - accuracy: 0.6681 - val_loss: 0.9030 - val_accuracy: 0.7005\n",
            "Epoch 327/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8691 - accuracy: 0.6445 - val_loss: 0.8936 - val_accuracy: 0.7150\n",
            "Epoch 328/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8586 - accuracy: 0.6723 - val_loss: 0.8849 - val_accuracy: 0.6957\n",
            "Epoch 329/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8632 - accuracy: 0.6663 - val_loss: 0.8826 - val_accuracy: 0.6957\n",
            "Epoch 330/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.8782 - accuracy: 0.6638 - val_loss: 0.9117 - val_accuracy: 0.6860\n",
            "Epoch 331/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8820 - accuracy: 0.6578 - val_loss: 0.8971 - val_accuracy: 0.6812\n",
            "Epoch 332/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8562 - accuracy: 0.6536 - val_loss: 0.9037 - val_accuracy: 0.6715\n",
            "Epoch 333/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8633 - accuracy: 0.6505 - val_loss: 0.9004 - val_accuracy: 0.6957\n",
            "Epoch 334/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8606 - accuracy: 0.6518 - val_loss: 0.8810 - val_accuracy: 0.6860\n",
            "Epoch 335/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8548 - accuracy: 0.6596 - val_loss: 0.8933 - val_accuracy: 0.6908\n",
            "Epoch 336/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8703 - accuracy: 0.6651 - val_loss: 0.9075 - val_accuracy: 0.6908\n",
            "Epoch 337/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8532 - accuracy: 0.6644 - val_loss: 0.8820 - val_accuracy: 0.7150\n",
            "Epoch 338/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8659 - accuracy: 0.6644 - val_loss: 0.8639 - val_accuracy: 0.7101\n",
            "Epoch 339/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8418 - accuracy: 0.6602 - val_loss: 0.8986 - val_accuracy: 0.6908\n",
            "Epoch 340/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8562 - accuracy: 0.6681 - val_loss: 0.8761 - val_accuracy: 0.6957\n",
            "Epoch 341/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8356 - accuracy: 0.6747 - val_loss: 0.8746 - val_accuracy: 0.6763\n",
            "Epoch 342/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8459 - accuracy: 0.6729 - val_loss: 0.8784 - val_accuracy: 0.6957\n",
            "Epoch 343/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8618 - accuracy: 0.6644 - val_loss: 0.8744 - val_accuracy: 0.7005\n",
            "Epoch 344/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8541 - accuracy: 0.6638 - val_loss: 0.8711 - val_accuracy: 0.7198\n",
            "Epoch 345/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8427 - accuracy: 0.6681 - val_loss: 0.8611 - val_accuracy: 0.7150\n",
            "Epoch 346/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8393 - accuracy: 0.6729 - val_loss: 0.8806 - val_accuracy: 0.6812\n",
            "Epoch 347/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8393 - accuracy: 0.6759 - val_loss: 0.8951 - val_accuracy: 0.6715\n",
            "Epoch 348/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.8259 - accuracy: 0.6771 - val_loss: 0.8944 - val_accuracy: 0.6812\n",
            "Epoch 349/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8410 - accuracy: 0.6717 - val_loss: 0.8565 - val_accuracy: 0.7150\n",
            "Epoch 350/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8240 - accuracy: 0.6729 - val_loss: 0.8927 - val_accuracy: 0.6763\n",
            "Epoch 351/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8485 - accuracy: 0.6741 - val_loss: 0.8905 - val_accuracy: 0.6570\n",
            "Epoch 352/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8275 - accuracy: 0.6705 - val_loss: 0.8795 - val_accuracy: 0.6667\n",
            "Epoch 353/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8564 - accuracy: 0.6596 - val_loss: 0.8708 - val_accuracy: 0.7053\n",
            "Epoch 354/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.8357 - accuracy: 0.6614 - val_loss: 0.8624 - val_accuracy: 0.7198\n",
            "Epoch 355/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8103 - accuracy: 0.6838 - val_loss: 0.8468 - val_accuracy: 0.7150\n",
            "Epoch 356/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8321 - accuracy: 0.6699 - val_loss: 0.8515 - val_accuracy: 0.7101\n",
            "Epoch 357/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8409 - accuracy: 0.6814 - val_loss: 0.8481 - val_accuracy: 0.7005\n",
            "Epoch 358/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8161 - accuracy: 0.6778 - val_loss: 0.8634 - val_accuracy: 0.6860\n",
            "Epoch 359/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8230 - accuracy: 0.6778 - val_loss: 0.8410 - val_accuracy: 0.7053\n",
            "Epoch 360/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8307 - accuracy: 0.6693 - val_loss: 0.8550 - val_accuracy: 0.7053\n",
            "Epoch 361/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8079 - accuracy: 0.6947 - val_loss: 0.8633 - val_accuracy: 0.6957\n",
            "Epoch 362/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8353 - accuracy: 0.6753 - val_loss: 0.8769 - val_accuracy: 0.6667\n",
            "Epoch 363/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8159 - accuracy: 0.6820 - val_loss: 0.8585 - val_accuracy: 0.6908\n",
            "Epoch 364/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.8470 - accuracy: 0.6753 - val_loss: 0.8751 - val_accuracy: 0.6618\n",
            "Epoch 365/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8454 - accuracy: 0.6638 - val_loss: 0.8662 - val_accuracy: 0.6908\n",
            "Epoch 366/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8268 - accuracy: 0.6735 - val_loss: 0.8703 - val_accuracy: 0.6763\n",
            "Epoch 367/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.8301 - accuracy: 0.6735 - val_loss: 0.8602 - val_accuracy: 0.6957\n",
            "Epoch 368/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8200 - accuracy: 0.6778 - val_loss: 0.8782 - val_accuracy: 0.6860\n",
            "Epoch 369/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8251 - accuracy: 0.6765 - val_loss: 0.8804 - val_accuracy: 0.6667\n",
            "Epoch 370/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8168 - accuracy: 0.6790 - val_loss: 0.8910 - val_accuracy: 0.6522\n",
            "Epoch 371/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.8037 - accuracy: 0.6880 - val_loss: 0.8483 - val_accuracy: 0.7101\n",
            "Epoch 372/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7917 - accuracy: 0.6892 - val_loss: 0.8661 - val_accuracy: 0.6618\n",
            "Epoch 373/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8344 - accuracy: 0.6669 - val_loss: 0.8647 - val_accuracy: 0.6667\n",
            "Epoch 374/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8343 - accuracy: 0.6481 - val_loss: 0.8652 - val_accuracy: 0.6908\n",
            "Epoch 375/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8242 - accuracy: 0.6759 - val_loss: 0.8537 - val_accuracy: 0.6957\n",
            "Epoch 376/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8290 - accuracy: 0.6778 - val_loss: 0.8391 - val_accuracy: 0.7005\n",
            "Epoch 377/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8139 - accuracy: 0.6681 - val_loss: 0.8411 - val_accuracy: 0.7053\n",
            "Epoch 378/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7979 - accuracy: 0.6747 - val_loss: 0.8385 - val_accuracy: 0.7005\n",
            "Epoch 379/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8084 - accuracy: 0.6844 - val_loss: 0.8367 - val_accuracy: 0.6957\n",
            "Epoch 380/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.7781 - accuracy: 0.6977 - val_loss: 0.8699 - val_accuracy: 0.6763\n",
            "Epoch 381/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8125 - accuracy: 0.6838 - val_loss: 0.8551 - val_accuracy: 0.6957\n",
            "Epoch 382/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8015 - accuracy: 0.6886 - val_loss: 0.8443 - val_accuracy: 0.6860\n",
            "Epoch 383/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7896 - accuracy: 0.6898 - val_loss: 0.8445 - val_accuracy: 0.7198\n",
            "Epoch 384/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7992 - accuracy: 0.7019 - val_loss: 0.8560 - val_accuracy: 0.6957\n",
            "Epoch 385/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7913 - accuracy: 0.6941 - val_loss: 0.8267 - val_accuracy: 0.7198\n",
            "Epoch 386/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8003 - accuracy: 0.7056 - val_loss: 0.8402 - val_accuracy: 0.6860\n",
            "Epoch 387/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.7912 - accuracy: 0.6947 - val_loss: 0.8288 - val_accuracy: 0.7150\n",
            "Epoch 388/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7677 - accuracy: 0.6935 - val_loss: 0.8429 - val_accuracy: 0.7440\n",
            "Epoch 389/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8058 - accuracy: 0.6790 - val_loss: 0.8430 - val_accuracy: 0.6812\n",
            "Epoch 390/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7922 - accuracy: 0.6989 - val_loss: 0.8244 - val_accuracy: 0.7101\n",
            "Epoch 391/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7831 - accuracy: 0.6898 - val_loss: 0.8370 - val_accuracy: 0.6957\n",
            "Epoch 392/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8026 - accuracy: 0.6850 - val_loss: 0.8107 - val_accuracy: 0.7246\n",
            "Epoch 393/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7953 - accuracy: 0.6947 - val_loss: 0.8364 - val_accuracy: 0.7005\n",
            "Epoch 394/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7968 - accuracy: 0.6699 - val_loss: 0.8233 - val_accuracy: 0.7246\n",
            "Epoch 395/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7942 - accuracy: 0.6874 - val_loss: 0.8141 - val_accuracy: 0.7295\n",
            "Epoch 396/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7768 - accuracy: 0.6983 - val_loss: 0.8362 - val_accuracy: 0.7053\n",
            "Epoch 397/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7863 - accuracy: 0.6923 - val_loss: 0.8312 - val_accuracy: 0.7246\n",
            "Epoch 398/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.7787 - accuracy: 0.6977 - val_loss: 0.8288 - val_accuracy: 0.7198\n",
            "Epoch 399/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.7876 - accuracy: 0.6808 - val_loss: 0.8291 - val_accuracy: 0.7053\n",
            "Epoch 400/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.7992 - accuracy: 0.6856 - val_loss: 0.8724 - val_accuracy: 0.6667\n",
            "Epoch 401/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7838 - accuracy: 0.6911 - val_loss: 0.8316 - val_accuracy: 0.6908\n",
            "Epoch 402/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7847 - accuracy: 0.6911 - val_loss: 0.8207 - val_accuracy: 0.7198\n",
            "Epoch 403/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8016 - accuracy: 0.6868 - val_loss: 0.8476 - val_accuracy: 0.6715\n",
            "Epoch 404/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7822 - accuracy: 0.6911 - val_loss: 0.8429 - val_accuracy: 0.6812\n",
            "Epoch 405/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.7883 - accuracy: 0.6929 - val_loss: 0.8199 - val_accuracy: 0.7101\n",
            "Epoch 406/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7900 - accuracy: 0.6904 - val_loss: 0.8273 - val_accuracy: 0.6908\n",
            "Epoch 407/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.7717 - accuracy: 0.7110 - val_loss: 0.8248 - val_accuracy: 0.7053\n",
            "Epoch 408/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7772 - accuracy: 0.6886 - val_loss: 0.8329 - val_accuracy: 0.6812\n",
            "Epoch 409/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8032 - accuracy: 0.6959 - val_loss: 0.8310 - val_accuracy: 0.6957\n",
            "Epoch 410/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.7661 - accuracy: 0.7086 - val_loss: 0.8419 - val_accuracy: 0.7005\n",
            "Epoch 411/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.7749 - accuracy: 0.6935 - val_loss: 0.8234 - val_accuracy: 0.7246\n",
            "Epoch 412/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.7752 - accuracy: 0.6886 - val_loss: 0.8202 - val_accuracy: 0.6860\n",
            "Epoch 413/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7578 - accuracy: 0.7007 - val_loss: 0.8569 - val_accuracy: 0.6860\n",
            "Epoch 414/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7745 - accuracy: 0.6959 - val_loss: 0.8255 - val_accuracy: 0.6763\n",
            "Epoch 415/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7514 - accuracy: 0.7092 - val_loss: 0.8042 - val_accuracy: 0.7198\n",
            "Epoch 416/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7631 - accuracy: 0.6971 - val_loss: 0.8434 - val_accuracy: 0.6667\n",
            "Epoch 417/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7717 - accuracy: 0.7086 - val_loss: 0.8034 - val_accuracy: 0.7150\n",
            "Epoch 418/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7650 - accuracy: 0.7025 - val_loss: 0.8114 - val_accuracy: 0.7053\n",
            "Epoch 419/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7632 - accuracy: 0.6995 - val_loss: 0.8132 - val_accuracy: 0.7053\n",
            "Epoch 420/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7703 - accuracy: 0.6923 - val_loss: 0.7971 - val_accuracy: 0.7343\n",
            "Epoch 421/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7785 - accuracy: 0.6935 - val_loss: 0.8040 - val_accuracy: 0.7005\n",
            "Epoch 422/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7541 - accuracy: 0.7056 - val_loss: 0.8098 - val_accuracy: 0.6570\n",
            "Epoch 423/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7612 - accuracy: 0.7007 - val_loss: 0.8346 - val_accuracy: 0.6618\n",
            "Epoch 424/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7615 - accuracy: 0.7056 - val_loss: 0.8027 - val_accuracy: 0.7005\n",
            "Epoch 425/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.7597 - accuracy: 0.7056 - val_loss: 0.8030 - val_accuracy: 0.7053\n",
            "Epoch 426/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.7499 - accuracy: 0.7013 - val_loss: 0.8126 - val_accuracy: 0.7391\n",
            "Epoch 427/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.7490 - accuracy: 0.7116 - val_loss: 0.8378 - val_accuracy: 0.6812\n",
            "Epoch 428/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7552 - accuracy: 0.7013 - val_loss: 0.7997 - val_accuracy: 0.6812\n",
            "Epoch 429/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7597 - accuracy: 0.7062 - val_loss: 0.8071 - val_accuracy: 0.6957\n",
            "Epoch 430/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7574 - accuracy: 0.7122 - val_loss: 0.8172 - val_accuracy: 0.6860\n",
            "Epoch 431/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7590 - accuracy: 0.7128 - val_loss: 0.8180 - val_accuracy: 0.6763\n",
            "Epoch 432/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.7246 - accuracy: 0.7122 - val_loss: 0.8006 - val_accuracy: 0.7101\n",
            "Epoch 433/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7622 - accuracy: 0.7037 - val_loss: 0.8165 - val_accuracy: 0.6908\n",
            "Epoch 434/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7548 - accuracy: 0.7110 - val_loss: 0.8033 - val_accuracy: 0.6812\n",
            "Epoch 435/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7577 - accuracy: 0.7001 - val_loss: 0.7994 - val_accuracy: 0.6957\n",
            "Epoch 436/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7496 - accuracy: 0.7019 - val_loss: 0.8002 - val_accuracy: 0.6860\n",
            "Epoch 437/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7519 - accuracy: 0.7031 - val_loss: 0.8066 - val_accuracy: 0.7150\n",
            "Epoch 438/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7534 - accuracy: 0.7044 - val_loss: 0.8118 - val_accuracy: 0.6812\n",
            "Epoch 439/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7291 - accuracy: 0.7146 - val_loss: 0.8110 - val_accuracy: 0.6860\n",
            "Epoch 440/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.7634 - accuracy: 0.6953 - val_loss: 0.8271 - val_accuracy: 0.6425\n",
            "Epoch 441/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.7228 - accuracy: 0.7146 - val_loss: 0.8101 - val_accuracy: 0.6812\n",
            "Epoch 442/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.7530 - accuracy: 0.7189 - val_loss: 0.8232 - val_accuracy: 0.6812\n",
            "Epoch 443/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7466 - accuracy: 0.7068 - val_loss: 0.8022 - val_accuracy: 0.6860\n",
            "Epoch 444/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.7368 - accuracy: 0.7086 - val_loss: 0.8129 - val_accuracy: 0.6860\n",
            "Epoch 445/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.7471 - accuracy: 0.7013 - val_loss: 0.8210 - val_accuracy: 0.7005\n",
            "Epoch 446/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.7456 - accuracy: 0.7068 - val_loss: 0.7928 - val_accuracy: 0.7053\n",
            "Epoch 447/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7446 - accuracy: 0.6965 - val_loss: 0.8074 - val_accuracy: 0.6908\n",
            "Epoch 448/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7214 - accuracy: 0.7152 - val_loss: 0.8045 - val_accuracy: 0.7101\n",
            "Epoch 449/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7363 - accuracy: 0.7201 - val_loss: 0.7955 - val_accuracy: 0.7053\n",
            "Epoch 450/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7237 - accuracy: 0.7086 - val_loss: 0.7876 - val_accuracy: 0.6908\n",
            "Epoch 451/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7436 - accuracy: 0.7056 - val_loss: 0.7958 - val_accuracy: 0.7391\n",
            "Epoch 452/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.7299 - accuracy: 0.7195 - val_loss: 0.8015 - val_accuracy: 0.6715\n",
            "Epoch 453/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7301 - accuracy: 0.7213 - val_loss: 0.7853 - val_accuracy: 0.7343\n",
            "Epoch 454/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7036 - accuracy: 0.7291 - val_loss: 0.8042 - val_accuracy: 0.7101\n",
            "Epoch 455/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7362 - accuracy: 0.7092 - val_loss: 0.7734 - val_accuracy: 0.7005\n",
            "Epoch 456/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7091 - accuracy: 0.7249 - val_loss: 0.7844 - val_accuracy: 0.7198\n",
            "Epoch 457/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7134 - accuracy: 0.7219 - val_loss: 0.7787 - val_accuracy: 0.7198\n",
            "Epoch 458/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.7192 - accuracy: 0.7170 - val_loss: 0.7786 - val_accuracy: 0.7005\n",
            "Epoch 459/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7276 - accuracy: 0.7140 - val_loss: 0.7901 - val_accuracy: 0.6860\n",
            "Epoch 460/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7094 - accuracy: 0.7116 - val_loss: 0.7874 - val_accuracy: 0.6957\n",
            "Epoch 461/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7230 - accuracy: 0.7195 - val_loss: 0.8059 - val_accuracy: 0.6812\n",
            "Epoch 462/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.7271 - accuracy: 0.7086 - val_loss: 0.8025 - val_accuracy: 0.6812\n",
            "Epoch 463/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7232 - accuracy: 0.7195 - val_loss: 0.7817 - val_accuracy: 0.7391\n",
            "Epoch 464/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.7177 - accuracy: 0.7316 - val_loss: 0.8102 - val_accuracy: 0.6763\n",
            "Epoch 465/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7026 - accuracy: 0.7213 - val_loss: 0.7879 - val_accuracy: 0.7198\n",
            "Epoch 466/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.7162 - accuracy: 0.7158 - val_loss: 0.7847 - val_accuracy: 0.7246\n",
            "Epoch 467/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6923 - accuracy: 0.7400 - val_loss: 0.8140 - val_accuracy: 0.6860\n",
            "Epoch 468/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7002 - accuracy: 0.7358 - val_loss: 0.7881 - val_accuracy: 0.7246\n",
            "Epoch 469/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7057 - accuracy: 0.7310 - val_loss: 0.7706 - val_accuracy: 0.7150\n",
            "Epoch 470/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6826 - accuracy: 0.7340 - val_loss: 0.7912 - val_accuracy: 0.6812\n",
            "Epoch 471/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7416 - accuracy: 0.7195 - val_loss: 0.7950 - val_accuracy: 0.6957\n",
            "Epoch 472/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6984 - accuracy: 0.7273 - val_loss: 0.7742 - val_accuracy: 0.7150\n",
            "Epoch 473/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.7107 - accuracy: 0.7279 - val_loss: 0.7857 - val_accuracy: 0.7101\n",
            "Epoch 474/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7049 - accuracy: 0.7237 - val_loss: 0.8058 - val_accuracy: 0.7198\n",
            "Epoch 475/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.7093 - accuracy: 0.7195 - val_loss: 0.7857 - val_accuracy: 0.7295\n",
            "Epoch 476/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7027 - accuracy: 0.7358 - val_loss: 0.8005 - val_accuracy: 0.7053\n",
            "Epoch 477/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6940 - accuracy: 0.7334 - val_loss: 0.7974 - val_accuracy: 0.7053\n",
            "Epoch 478/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.7035 - accuracy: 0.7249 - val_loss: 0.7849 - val_accuracy: 0.6908\n",
            "Epoch 479/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.7103 - accuracy: 0.7358 - val_loss: 0.7928 - val_accuracy: 0.6618\n",
            "Epoch 480/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.7099 - accuracy: 0.7201 - val_loss: 0.8039 - val_accuracy: 0.6618\n",
            "Epoch 481/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7112 - accuracy: 0.7273 - val_loss: 0.7890 - val_accuracy: 0.6908\n",
            "Epoch 482/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6798 - accuracy: 0.7267 - val_loss: 0.7784 - val_accuracy: 0.7053\n",
            "Epoch 483/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6977 - accuracy: 0.7273 - val_loss: 0.7873 - val_accuracy: 0.6908\n",
            "Epoch 484/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6877 - accuracy: 0.7291 - val_loss: 0.7807 - val_accuracy: 0.6715\n",
            "Epoch 485/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.7221 - accuracy: 0.7213 - val_loss: 0.7753 - val_accuracy: 0.7101\n",
            "Epoch 486/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6805 - accuracy: 0.7297 - val_loss: 0.8075 - val_accuracy: 0.6908\n",
            "Epoch 487/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7246 - accuracy: 0.7158 - val_loss: 0.7705 - val_accuracy: 0.7343\n",
            "Epoch 488/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6989 - accuracy: 0.7195 - val_loss: 0.7848 - val_accuracy: 0.6908\n",
            "Epoch 489/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6908 - accuracy: 0.7285 - val_loss: 0.8082 - val_accuracy: 0.6908\n",
            "Epoch 490/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6842 - accuracy: 0.7364 - val_loss: 0.7552 - val_accuracy: 0.7295\n",
            "Epoch 491/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6801 - accuracy: 0.7364 - val_loss: 0.7701 - val_accuracy: 0.7005\n",
            "Epoch 492/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6999 - accuracy: 0.7328 - val_loss: 0.7709 - val_accuracy: 0.7101\n",
            "Epoch 493/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7018 - accuracy: 0.7183 - val_loss: 0.7690 - val_accuracy: 0.7198\n",
            "Epoch 494/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6757 - accuracy: 0.7297 - val_loss: 0.7578 - val_accuracy: 0.7246\n",
            "Epoch 495/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6867 - accuracy: 0.7328 - val_loss: 0.7657 - val_accuracy: 0.6957\n",
            "Epoch 496/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6887 - accuracy: 0.7400 - val_loss: 0.7550 - val_accuracy: 0.7198\n",
            "Epoch 497/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6756 - accuracy: 0.7297 - val_loss: 0.7607 - val_accuracy: 0.7150\n",
            "Epoch 498/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6910 - accuracy: 0.7146 - val_loss: 0.7692 - val_accuracy: 0.7053\n",
            "Epoch 499/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6733 - accuracy: 0.7310 - val_loss: 0.7737 - val_accuracy: 0.7005\n",
            "Epoch 500/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6903 - accuracy: 0.7376 - val_loss: 0.7942 - val_accuracy: 0.7053\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(cnnhistory.history['loss'])\n",
        "plt.plot(cnnhistory.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train','test'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "oQYnuaCrDH_A",
        "outputId": "e41d8591-4084-4d1f-abbf-685b40c12f82"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(cnnhistory.history['accuracy'])\n",
        "plt.plot(cnnhistory.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train','test'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "IFkTuO8nDNdq",
        "outputId": "f4319e20-12a9-4ced-ccbc-b89960b512b4"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#predictions = model.predict_classes(x_testcnn)\n",
        "predictions = model.predict(x_testcnn)"
      ],
      "metadata": {
        "id": "A2xtrN5wDQgY"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_f_ohjXKDUpY",
        "outputId": "8d5e9469-ed8e-4b57-dc4d-4b7af4261f98"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.85435259e-04, 7.07351574e-05, 2.02663783e-02, 1.47818625e-02,\n",
              "        3.26853096e-02, 9.32010293e-01],\n",
              "       [1.83774367e-01, 4.58934069e-01, 9.44179371e-02, 1.25581026e-01,\n",
              "        5.17759025e-02, 8.55167955e-02],\n",
              "       [1.75502698e-03, 3.50298313e-03, 5.60124397e-01, 1.38516733e-02,\n",
              "        2.10480392e-01, 2.10285559e-01],\n",
              "       ...,\n",
              "       [5.24158077e-03, 8.63997964e-04, 1.28408782e-02, 5.96904159e-02,\n",
              "        5.64095914e-01, 3.57267290e-01],\n",
              "       [3.03563215e-02, 8.66899919e-03, 5.68918930e-03, 5.84085584e-01,\n",
              "        7.60859624e-03, 3.63591254e-01],\n",
              "       [1.41903654e-01, 7.70210251e-02, 2.79814035e-01, 1.20150432e-01,\n",
              "        3.45161051e-01, 3.59498002e-02]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cmA2bFgsDW3D",
        "outputId": "9ff4ee49-d25c-4926-8771-aa1e46e032c7"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5, 1, 2, 5, 3, 4, 2, 0, 3, 1, 3, 2, 1, 4, 3, 0, 5, 0, 2, 5, 0, 0,\n",
              "       1, 3, 2, 3, 2, 5, 4, 2, 2, 3, 1, 2, 5, 5, 3, 5, 3, 3, 4, 1, 3, 2,\n",
              "       3, 1, 5, 3, 1, 2, 4, 4, 5, 5, 5, 1, 2, 3, 2, 5, 0, 2, 4, 2, 5, 4,\n",
              "       3, 0, 1, 2, 5, 2, 1, 2, 4, 5, 4, 1, 5, 5, 3, 1, 5, 3, 2, 4, 2, 5,\n",
              "       0, 5, 0, 5, 4, 0, 2, 4, 0, 2, 2, 0, 2, 3, 5, 3, 5, 5, 3, 1, 2, 2,\n",
              "       2, 1, 3, 2, 1, 3, 4, 4, 1, 1, 2, 4, 4, 1, 4, 2, 0, 4, 5, 5, 3, 1,\n",
              "       2, 1, 5, 5, 1, 2, 3, 3, 0, 3, 3, 0, 1, 0, 1, 2, 1, 5, 1, 2, 2, 0,\n",
              "       1, 1, 1, 1, 1, 4, 0, 1, 5, 1, 4, 5, 5, 4, 1, 0, 3, 5, 2, 3, 0, 4,\n",
              "       1, 3, 1, 0, 5, 5, 3, 5, 4, 5, 4, 0, 4, 1, 2, 1, 5, 0, 4, 3, 2, 1,\n",
              "       0, 3, 5, 0, 4, 5, 4, 5, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_Ytest = y_test.astype(int)"
      ],
      "metadata": {
        "id": "0PHDKWJWDY3g"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_Ytest"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k68v2i-pDbZE",
        "outputId": "8a3bbd6a-dfa3-4454-d3cd-5af6daeb6ff9"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5, 1, 2, 5, 3, 4, 2, 0, 3, 1, 3, 2, 1, 4, 3, 0, 5, 0, 2, 5, 0, 0,\n",
              "       1, 3, 2, 3, 2, 5, 4, 2, 2, 3, 1, 2, 5, 5, 3, 5, 3, 3, 4, 1, 3, 2,\n",
              "       3, 1, 5, 3, 1, 2, 4, 4, 5, 5, 5, 1, 2, 3, 2, 5, 0, 2, 4, 2, 5, 4,\n",
              "       3, 0, 1, 2, 5, 2, 1, 2, 4, 5, 4, 1, 5, 5, 3, 1, 5, 3, 2, 4, 2, 5,\n",
              "       0, 5, 0, 5, 4, 0, 2, 4, 0, 2, 2, 0, 2, 3, 5, 3, 5, 5, 3, 1, 2, 2,\n",
              "       2, 1, 3, 2, 1, 3, 4, 4, 1, 1, 2, 4, 4, 1, 4, 2, 0, 4, 5, 5, 3, 1,\n",
              "       2, 1, 5, 5, 1, 2, 3, 3, 0, 3, 3, 0, 1, 0, 1, 2, 1, 5, 1, 2, 2, 0,\n",
              "       1, 1, 1, 1, 1, 4, 0, 1, 5, 1, 4, 5, 5, 4, 1, 0, 3, 5, 2, 3, 0, 4,\n",
              "       1, 3, 1, 0, 5, 5, 3, 5, 4, 5, 4, 0, 4, 1, 2, 1, 5, 0, 4, 3, 2, 1,\n",
              "       0, 3, 5, 0, 4, 5, 4, 5, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds1=predictions.argmax(axis=1)\n",
        "preds1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4_cAI39VFhtp",
        "outputId": "a0e2494e-ae17-4d39-8e45-e44d88059206"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5, 1, 2, 5, 3, 4, 2, 0, 3, 0, 3, 4, 2, 4, 3, 0, 5, 3, 2, 5, 3, 0,\n",
              "       2, 3, 2, 3, 2, 0, 2, 4, 2, 3, 0, 2, 5, 4, 0, 5, 3, 2, 4, 1, 0, 2,\n",
              "       3, 1, 3, 3, 1, 3, 4, 4, 5, 5, 3, 3, 2, 3, 2, 5, 0, 2, 4, 4, 5, 4,\n",
              "       3, 0, 0, 2, 5, 2, 0, 0, 5, 3, 4, 3, 5, 5, 3, 2, 5, 3, 2, 4, 2, 3,\n",
              "       0, 4, 0, 3, 4, 0, 3, 4, 3, 2, 2, 3, 2, 3, 5, 3, 5, 5, 5, 1, 2, 2,\n",
              "       2, 1, 3, 2, 2, 4, 4, 4, 0, 3, 2, 4, 4, 1, 4, 2, 3, 4, 4, 5, 5, 1,\n",
              "       2, 1, 5, 4, 2, 3, 3, 3, 0, 3, 3, 0, 0, 0, 1, 2, 0, 2, 0, 2, 4, 0,\n",
              "       1, 4, 1, 1, 3, 4, 0, 1, 5, 3, 4, 5, 4, 2, 1, 0, 5, 3, 2, 3, 3, 4,\n",
              "       1, 3, 1, 3, 5, 2, 3, 5, 4, 3, 4, 0, 0, 0, 2, 3, 3, 0, 4, 3, 2, 1,\n",
              "       1, 5, 5, 0, 5, 5, 4, 3, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "abc = preds1.astype(int).flatten()"
      ],
      "metadata": {
        "id": "H4WEmM60NfQn"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "c = confusion_matrix(new_Ytest, abc) \n",
        "c"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bKEBeEBlFjB8",
        "outputId": "2b13a080-83c9-4f6f-c236-e12a7fd2c394"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[17,  1,  0,  7,  0,  0],\n",
              "       [ 9, 18,  5,  6,  1,  0],\n",
              "       [ 1,  0, 30,  3,  4,  0],\n",
              "       [ 2,  0,  1, 25,  1,  4],\n",
              "       [ 1,  0,  2,  0, 25,  2],\n",
              "       [ 1,  0,  2,  9,  5, 25]])"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m4RjG7LWLSQx",
        "outputId": "e84738c3-5d0a-4ba0-c590-09b0a95bb3ca"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5, 1, 2, 5, 3, 4, 2, 0, 3, 1, 3, 2, 1, 4, 3, 0, 5, 0, 2, 5, 0, 0,\n",
              "       1, 3, 2, 3, 2, 5, 4, 2, 2, 3, 1, 2, 5, 5, 3, 5, 3, 3, 4, 1, 3, 2,\n",
              "       3, 1, 5, 3, 1, 2, 4, 4, 5, 5, 5, 1, 2, 3, 2, 5, 0, 2, 4, 2, 5, 4,\n",
              "       3, 0, 1, 2, 5, 2, 1, 2, 4, 5, 4, 1, 5, 5, 3, 1, 5, 3, 2, 4, 2, 5,\n",
              "       0, 5, 0, 5, 4, 0, 2, 4, 0, 2, 2, 0, 2, 3, 5, 3, 5, 5, 3, 1, 2, 2,\n",
              "       2, 1, 3, 2, 1, 3, 4, 4, 1, 1, 2, 4, 4, 1, 4, 2, 0, 4, 5, 5, 3, 1,\n",
              "       2, 1, 5, 5, 1, 2, 3, 3, 0, 3, 3, 0, 1, 0, 1, 2, 1, 5, 1, 2, 2, 0,\n",
              "       1, 1, 1, 1, 1, 4, 0, 1, 5, 1, 4, 5, 5, 4, 1, 0, 3, 5, 2, 3, 0, 4,\n",
              "       1, 3, 1, 0, 5, 5, 3, 5, 4, 5, 4, 0, 4, 1, 2, 1, 5, 0, 4, 3, 2, 1,\n",
              "       0, 3, 5, 0, 4, 5, 4, 5, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('/content/drive/MyDrive/model2')\n",
        "print(\"MODEL SAVED\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lsJBNeMWDl6Z",
        "outputId": "8924dba4-0780-45fd-a1c6-fdfb783c5d2c"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/model2/assets\n",
            "MODEL SAVED\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_model=keras.models.load_model('/content/drive/MyDrive/model2')\n",
        "new_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q3KjaO9GDoNl",
        "outputId": "f7d68527-cfb3-4a52-d461-4a0859270f83"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d (Conv1D)             (None, 40, 128)           1152      \n",
            "                                                                 \n",
            " activation (Activation)     (None, 40, 128)           0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 40, 128)           0         \n",
            "                                                                 \n",
            " max_pooling1d (MaxPooling1D  (None, 8, 128)           0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv1d_1 (Conv1D)           (None, 8, 256)            262400    \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 8, 256)            0         \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 8, 256)            0         \n",
            "                                                                 \n",
            " max_pooling1d_1 (MaxPooling  (None, 1, 256)           0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 256)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 256)               65792     \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 256)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 256)               65792     \n",
            "                                                                 \n",
            " activation_3 (Activation)   (None, 256)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 6)                 1542      \n",
            "                                                                 \n",
            " activation_4 (Activation)   (None, 6)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 396,678\n",
            "Trainable params: 396,678\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss, acc =model.evaluate(x_testcnn, y_test)\n",
        "print(\"Restored model, accuracy: {:5.2f}%\".format(100*acc))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n3kzoqPkDqqS",
        "outputId": "ece9f98e-9ae8-4eb4-bc19-4a6082a08da0"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7/7 [==============================] - 0s 3ms/step - loss: 0.7961 - accuracy: 0.6763\n",
            "Restored model, accuracy: 67.63%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss, acc =model.evaluate(X_train, y_train)\n",
        "print(\"Restored model train, accuracy: {:5.2f}%\".format(100*acc))"
      ],
      "metadata": {
        "id": "fJDTGH_OUX0z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76e4865e-9fe2-417c-927b-b01785e3b496"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "52/52 [==============================] - 0s 4ms/step - loss: 0.6028 - accuracy: 0.8077\n",
            "Restored model train, accuracy: 80.77%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix,accuracy_score\n",
        "import seaborn as sn\n",
        "\n",
        "print(classification_report(new_Ytest,abc))\n",
        "\n",
        "acc = float(accuracy_score(new_Ytest,abc))*100\n",
        "print(\"----accuracy score %s ----\" % acc)\n",
        "\n",
        "cm = confusion_matrix(new_Ytest,abc)\n",
        "#df_cm = pd.DataFrame(cm)\n",
        "class_names = ['neutral','calm', 'happy','sad','angry', 'fearful' ]\n",
        "df_cm = pd.DataFrame(cm, index=class_names, columns=class_names,)\n",
        "sn.heatmap(df_cm, annot=True, fmt='')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 512
        },
        "id": "SfSC3El94LZg",
        "outputId": "fe62175d-1392-446e-960a-9dccbf97b82d"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.55      0.68      0.61        25\n",
            "           1       0.95      0.46      0.62        39\n",
            "           2       0.75      0.79      0.77        38\n",
            "           3       0.50      0.76      0.60        33\n",
            "           4       0.69      0.83      0.76        30\n",
            "           5       0.81      0.60      0.68        42\n",
            "\n",
            "    accuracy                           0.68       207\n",
            "   macro avg       0.71      0.69      0.67       207\n",
            "weighted avg       0.73      0.68      0.68       207\n",
            "\n",
            "----accuracy score 67.6328502415459 ----\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}