{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ramadan adam 0.0002 2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9SRCO-a_AlH5",
        "outputId": "ad98545a-06ae-4562-e418-3ba94ed3576b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install librosa"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oi8pWV3yBVjO",
        "outputId": "2b93d322-3cfd-4858-ee13-4993c03a8d78"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.7/dist-packages (0.8.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (21.3)\n",
            "Requirement already satisfied: resampy>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from librosa) (0.2.2)\n",
            "Requirement already satisfied: decorator>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.6.0)\n",
            "Requirement already satisfied: audioread>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (2.1.9)\n",
            "Requirement already satisfied: numba>=0.43.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (0.51.2)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.21.6)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.0.2)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.1.0)\n",
            "Requirement already satisfied: soundfile>=0.10.2 in /usr/local/lib/python3.7/dist-packages (from librosa) (0.10.3.post1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba>=0.43.0->librosa) (57.4.0)\n",
            "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba>=0.43.0->librosa) (0.34.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->librosa) (3.0.9)\n",
            "Requirement already satisfied: appdirs>=1.3.0 in /usr/local/lib/python3.7/dist-packages (from pooch>=1.0->librosa) (1.4.4)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from pooch>=1.0->librosa) (2.23.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2022.5.18.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (3.0.4)\n",
            "Requirement already satisfied: six>=1.3 in /usr/local/lib/python3.7/dist-packages (from resampy>=0.2.2->librosa) (1.15.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn!=0.19.0,>=0.14.0->librosa) (3.1.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.7/dist-packages (from soundfile>=0.10.2->librosa) (1.15.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.0->soundfile>=0.10.2->librosa) (2.21)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HJjcbxwy46bG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "0fa5ee51-50ce-4138-d845-f56b575f9721"
      },
      "source": [
        "# Orignial Notebook: https://github.com/MITESHPUTHRANNEU/Speech-Emotion-Analyzer/blob/master/final_results_gender_test.ipynb\n",
        "# This notebook author: Reza Chu\n",
        "# Last Editing Date: 31st May 2019\n",
        "\n",
        "## Python\n",
        "import os\n",
        "import random\n",
        "import sys\n",
        "\n",
        "import IPython\n",
        "from IPython.display import Audio\n",
        "from IPython.display import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "## Package\n",
        "import glob \n",
        "import keras\n",
        "import IPython.display as ipd\n",
        "import librosa\n",
        "import librosa.display\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import plotly.graph_objs as go\n",
        "import plotly.offline as py\n",
        "import plotly.tools as tls\n",
        "import seaborn as sns\n",
        "import scipy.io.wavfile\n",
        "import tensorflow as tf\n",
        "py.init_notebook_mode(connected=True)\n",
        "\n",
        "## Keras\n",
        "from keras import regularizers\n",
        "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping\n",
        "from keras.callbacks import  History, ReduceLROnPlateau, CSVLogger\n",
        "from keras.models import Model, Sequential\n",
        "from keras.layers import Dense, Embedding, LSTM\n",
        "from keras.layers import Input, Flatten, Dropout, Activation, BatchNormalization\n",
        "from keras.layers import Conv1D, MaxPooling1D, AveragePooling1D\n",
        "from keras.preprocessing import sequence\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.utils import np_utils\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "## Sklearn\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "## Rest\n",
        "from scipy.fftpack import fft\n",
        "from scipy import signal\n",
        "from scipy.io import wavfile\n",
        "from tqdm import tqdm\n",
        "\n",
        "input_duration=3\n",
        "# % pylab inline"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "        <script type=\"text/javascript\">\n",
              "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
              "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
              "        if (typeof require !== 'undefined') {\n",
              "        require.undef(\"plotly\");\n",
              "        requirejs.config({\n",
              "            paths: {\n",
              "                'plotly': ['https://cdn.plot.ly/plotly-2.8.3.min']\n",
              "            }\n",
              "        });\n",
              "        require(['plotly'], function(Plotly) {\n",
              "            window._Plotly = Plotly;\n",
              "        });\n",
              "        }\n",
              "        </script>\n",
              "        "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#radvass speech and song\n",
        "import time\n",
        "import os\n",
        "import librosa\n",
        "from librosa import display\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "count=0\n",
        "path1 = '/content/drive/MyDrive/RAVDESS_speech'\n",
        "path2 = '/content/drive/MyDrive/RAVDESS_song'\n",
        "\n",
        "lst = []\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "for subdir, dirs, files in os.walk(path2):\n",
        "  print(dirs)\n",
        "  print(subdir)\n",
        "  #print(files)\n",
        "  for file in files:\n",
        "      try:\n",
        "        count +=1\n",
        "        #Load librosa array, obtain mfcss, store the file and the mcss information in a new array\n",
        "        X, sample_rate = librosa.load(os.path.join(subdir,file), res_type='kaiser_fast')\n",
        "        mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T,axis=0) \n",
        "        # The instruction below converts the labels (from 1 to 8) to a series from 0 to 7\n",
        "        # This is because our predictor needs to start from 0 otherwise it will try to predict also 0.\n",
        "        file = int(file[7:8]) - 1 \n",
        "        arr = mfccs, file\n",
        "        lst.append(arr)\n",
        "      # If the file is not valid, skip it\n",
        "      except ValueError:\n",
        "        continue\n",
        "\n",
        "for subdir, dirs, files in os.walk(path1):\n",
        "  print(dirs)\n",
        "  print(subdir)\n",
        " # print(files)\n",
        "  for file in files:\n",
        "      try:\n",
        "        #Load librosa array, obtain mfcss, store the file and the mcss information in a new array\n",
        "        X, sample_rate = librosa.load(os.path.join(subdir,file), res_type='kaiser_fast')\n",
        "        mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T,axis=0) \n",
        "        # The instruction below converts the labels (from 1 to 8) to a series from 0 to 7\n",
        "        # This is because our predictor needs to start from 0 otherwise it will try to predict also 0.\n",
        "        file = int(file[7:8]) - 1 \n",
        "        if(file ==6 or file==7):\n",
        "          continue\n",
        "        count +=1\n",
        "        arr = mfccs, file\n",
        "        lst.append(arr)\n",
        "      # If the file is not valid, skip it\n",
        "      except ValueError:\n",
        "        continue\n",
        "\n",
        "\n",
        "\n",
        "print(\"--- Data loaded. Loading time: %s seconds ---\" % (time.time() - start_time))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IfuyRZl42ccZ",
        "outputId": "66f8cdc3-5d6d-41ee-e6bc-b798dbbdf203"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Actor_10', 'Actor_11', 'Actor_13', 'Actor_12', 'Actor_14', 'Actor_15', 'Actor_16', 'Actor_17', 'Actor_18', 'Actor_19', 'Actor_21', 'Actor_22', 'Actor_23', 'Actor_09', 'Actor_24', 'Actor_04', 'Actor_08', 'Actor_03', 'Actor_02', 'Actor_06', 'Actor_05', 'Actor_01', 'Actor_07', 'Actor_20']\n",
            "/content/drive/MyDrive/RAVDESS_song\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_10\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_11\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_13\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_12\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_14\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_15\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_16\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_17\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_18\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_19\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_21\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_22\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_23\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_09\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_24\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_04\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_08\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_03\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_02\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_06\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_05\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_01\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_07\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_song/Actor_20\n",
            "['Actor_05', 'Actor_08', 'Actor_10', 'Actor_04', 'Actor_09', 'Actor_14', 'Actor_12', 'Actor_13', 'Actor_11', 'Actor_06', 'Actor_24', 'Actor_07', 'Actor_23', 'Actor_22', 'Actor_21', 'Actor_20', 'Actor_02', 'Actor_19', 'Actor_18', 'Actor_17', 'Actor_16', 'Actor_15', 'Actor_03', 'Actor_01']\n",
            "/content/drive/MyDrive/RAVDESS_speech\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_05\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_08\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_10\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_04\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_09\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_14\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_12\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_13\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_11\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_06\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_24\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_07\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_23\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_22\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_21\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_20\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_02\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_19\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_18\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_17\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_16\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_15\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_03\n",
            "[]\n",
            "/content/drive/MyDrive/RAVDESS_speech/Actor_01\n",
            "--- Data loaded. Loading time: 206.6898136138916 seconds ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "count"
      ],
      "metadata": {
        "id": "Ltlhi25L2AI5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3a59640-307a-4d52-d23c-749ab7626954"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2068"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy.core.fromnumeric import size\n",
        "size(lst)"
      ],
      "metadata": {
        "id": "HMOH7d7mzHB7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ad65242-5263-4653-ba93-6e06c071efdc"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/core/fromnumeric.py:3208: VisibleDeprecationWarning:\n",
            "\n",
            "Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4136"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating X and y: zip makes a list of all the first elements, and a list of all the second elements.\n",
        "X, y = zip(*lst)"
      ],
      "metadata": {
        "id": "ocdL7tSTBoMt"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "X = np.asarray(X)\n",
        "y = np.asarray(y)\n",
        "X.shape, y.shape"
      ],
      "metadata": {
        "id": "vHKwUGTbBtnF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "420f098f-0ac3-47e1-afb7-c4dedb757991"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((2068, 40), (2068,))"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "id": "2sUCtbfMztE5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "929a233d-645b-47b6-a608-3dc0281e6af8"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2068, 40)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Saving joblib files to not load them again with the loop above\n",
        "\n",
        "# import joblib\n",
        "\n",
        "# X_name = 'x.joblib'\n",
        "# y_name = 'y.joblib'\n",
        "# save_dir = '/content/drive/My Drive/graduation project/audio/paper_code/features'\n",
        "\n",
        "# savedX = joblib.dump(X, os.path.join(save_dir, X_name))\n",
        "# savedy = joblib.dump(y, os.path.join(save_dir, y_name))"
      ],
      "metadata": {
        "id": "UCzic8rlDcuk"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Loading saved models\n",
        "# import joblib\n",
        "# X = joblib.load('/content/drive/My Drive/graduation project/audio/paper_code/features/x.joblib')\n",
        "# y = joblib.load('/content/drive/My Drive/graduation project/audio/paper_code/features/y.joblib')"
      ],
      "metadata": {
        "id": "Q35CN6zDrzg1"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7PSTurzjCo5K",
        "outputId": "6104bcdb-1dfc-40c5-c86d-8356a8c00444"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2068, 40)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2,train_size=0.8, random_state=42)\n",
        "X_valid, X_test, y_valid, y_test = train_test_split(X_test,y_test, test_size=0.5,train_size=0.5, random_state=42)"
      ],
      "metadata": {
        "id": "Ai4Fy5cPCiq1"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "x_traincnn = np.expand_dims(X_train, axis=2)\n",
        "x_testcnn = np.expand_dims(X_test, axis=2)\n",
        "X_valid= np.expand_dims(X_valid, axis=2)"
      ],
      "metadata": {
        "id": "tp1Fm5K3CEXu"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_traincnn.shape, x_testcnn.shape , X_valid.shape"
      ],
      "metadata": {
        "id": "RI0MxoIPBws5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9093537b-65c8-43a0-861d-360750aef9a1"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1654, 40, 1), (207, 40, 1), (207, 40, 1))"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow"
      ],
      "metadata": {
        "id": "goxL4Y3jKICC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21c133f4-3f98-4cf8-8c18-975ae6b2d403"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (2.8.2+zzzcolab20220527125636)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.17.3)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.5.3)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (4.2.0)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.0.0)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (14.0.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.46.3)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.21.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow) (57.4.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.26.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow) (1.5.2)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.8.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.6.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.35.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (3.3.7)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.23.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.8)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (4.11.4)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (3.8.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2022.5.18.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (3.2.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keras"
      ],
      "metadata": {
        "id": "EkcmN9UrKSxj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3ec1dc4-6f4a-40eb-906c-d63ef78d9f56"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.7/dist-packages (2.8.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from keras.preprocessing import sequence\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from keras.layers import Input, Flatten, Dropout, Activation\n",
        "from keras.layers import Conv1D, MaxPooling1D\n",
        "from keras.models import Model\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras import optimizers\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv1D(128, 8,padding='same', #classifier.add(Convolution2D(64, (3, 3), padding = 'same', input_shape = (128, 128, 3), activation = 'relu'))\n",
        "                 input_shape=(40,1)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(MaxPooling1D(pool_size=(5)))\n",
        "\n",
        "\n",
        "model.add(Conv1D(256,8,padding='same',))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(MaxPooling1D(pool_size=(5)))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(256))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(256))\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "model.add(Dense(6))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "#opt = tf.keras.optimizers.Adam(lr=0.00002)\n",
        "opt = tf.keras.optimizers.RMSprop(lr=0.0001, rho=0.9, epsilon=1e-07, decay=0.0)\n",
        "#opt = tf.keras.optimizers.SGD(lr=0.001, momentum=0.0, decay=0.0, nesterov=False)"
      ],
      "metadata": {
        "id": "g74fXWVAC4Cr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9e70559-cbb7-431b-f058-d84751a779d3"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/rmsprop.py:130: UserWarning:\n",
            "\n",
            "The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H6ukOxAGC_I4",
        "outputId": "0b838b2c-2155-4a35-ed2a-ef4e066ac5fe"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d (Conv1D)             (None, 40, 128)           1152      \n",
            "                                                                 \n",
            " activation (Activation)     (None, 40, 128)           0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 40, 128)           0         \n",
            "                                                                 \n",
            " max_pooling1d (MaxPooling1D  (None, 8, 128)           0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv1d_1 (Conv1D)           (None, 8, 256)            262400    \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 8, 256)            0         \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 8, 256)            0         \n",
            "                                                                 \n",
            " max_pooling1d_1 (MaxPooling  (None, 1, 256)           0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 256)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 256)               65792     \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 256)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 256)               65792     \n",
            "                                                                 \n",
            " activation_3 (Activation)   (None, 256)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 6)                 1542      \n",
            "                                                                 \n",
            " activation_4 (Activation)   (None, 6)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 396,678\n",
            "Trainable params: 396,678\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='sparse_categorical_crossentropy',\n",
        "              optimizer=opt,\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "AbMlLNk4DCBM"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#cnnhistory=model.fit(x_traincnn, y_train, batch_size=16, epochs=700, validation_data=(x_testcnn, y_test))\n",
        "cnnhistory=model.fit(x_traincnn, y_train, batch_size=16, epochs=500 , validation_data=(X_valid, y_valid))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RI1v2AuADFhy",
        "outputId": "86bdac70-6407-415d-b494-2b4f14a9f53a"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "104/104 [==============================] - 4s 11ms/step - loss: 5.0731 - accuracy: 0.1923 - val_loss: 2.3661 - val_accuracy: 0.2029\n",
            "Epoch 2/500\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 3.0654 - accuracy: 0.1941 - val_loss: 1.8426 - val_accuracy: 0.1594\n",
            "Epoch 3/500\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 2.5686 - accuracy: 0.2056 - val_loss: 1.8305 - val_accuracy: 0.1787\n",
            "Epoch 4/500\n",
            "104/104 [==============================] - 1s 9ms/step - loss: 2.3045 - accuracy: 0.2044 - val_loss: 1.8270 - val_accuracy: 0.2029\n",
            "Epoch 5/500\n",
            "104/104 [==============================] - 1s 9ms/step - loss: 2.1098 - accuracy: 0.2273 - val_loss: 1.9737 - val_accuracy: 0.1739\n",
            "Epoch 6/500\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 2.0377 - accuracy: 0.2195 - val_loss: 1.7036 - val_accuracy: 0.2899\n",
            "Epoch 7/500\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 1.9658 - accuracy: 0.2297 - val_loss: 1.6915 - val_accuracy: 0.2319\n",
            "Epoch 8/500\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 1.9222 - accuracy: 0.2443 - val_loss: 1.6391 - val_accuracy: 0.3333\n",
            "Epoch 9/500\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 1.8577 - accuracy: 0.2497 - val_loss: 1.6606 - val_accuracy: 0.2319\n",
            "Epoch 10/500\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 1.8396 - accuracy: 0.2539 - val_loss: 1.7429 - val_accuracy: 0.1932\n",
            "Epoch 11/500\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 1.8437 - accuracy: 0.2376 - val_loss: 1.6858 - val_accuracy: 0.2512\n",
            "Epoch 12/500\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 1.8091 - accuracy: 0.2642 - val_loss: 1.7722 - val_accuracy: 0.2464\n",
            "Epoch 13/500\n",
            "104/104 [==============================] - 1s 11ms/step - loss: 1.7821 - accuracy: 0.2684 - val_loss: 1.6331 - val_accuracy: 0.3140\n",
            "Epoch 14/500\n",
            "104/104 [==============================] - 1s 13ms/step - loss: 1.7439 - accuracy: 0.2830 - val_loss: 1.6758 - val_accuracy: 0.2464\n",
            "Epoch 15/500\n",
            "104/104 [==============================] - 1s 12ms/step - loss: 1.7193 - accuracy: 0.2950 - val_loss: 1.6153 - val_accuracy: 0.3043\n",
            "Epoch 16/500\n",
            "104/104 [==============================] - 1s 14ms/step - loss: 1.7031 - accuracy: 0.3102 - val_loss: 1.6033 - val_accuracy: 0.3575\n",
            "Epoch 17/500\n",
            "104/104 [==============================] - 1s 11ms/step - loss: 1.7079 - accuracy: 0.2902 - val_loss: 1.5421 - val_accuracy: 0.3092\n",
            "Epoch 18/500\n",
            "104/104 [==============================] - 1s 9ms/step - loss: 1.6514 - accuracy: 0.3235 - val_loss: 1.5210 - val_accuracy: 0.3382\n",
            "Epoch 19/500\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 1.6447 - accuracy: 0.3138 - val_loss: 1.6061 - val_accuracy: 0.3092\n",
            "Epoch 20/500\n",
            "104/104 [==============================] - 1s 9ms/step - loss: 1.6082 - accuracy: 0.3368 - val_loss: 1.5671 - val_accuracy: 0.3913\n",
            "Epoch 21/500\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 1.6041 - accuracy: 0.3422 - val_loss: 1.5184 - val_accuracy: 0.4106\n",
            "Epoch 22/500\n",
            "104/104 [==============================] - 1s 9ms/step - loss: 1.5801 - accuracy: 0.3652 - val_loss: 1.6230 - val_accuracy: 0.2802\n",
            "Epoch 23/500\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 1.5738 - accuracy: 0.3573 - val_loss: 1.5183 - val_accuracy: 0.3527\n",
            "Epoch 24/500\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 1.5421 - accuracy: 0.3797 - val_loss: 1.4715 - val_accuracy: 0.4396\n",
            "Epoch 25/500\n",
            "104/104 [==============================] - 1s 9ms/step - loss: 1.5211 - accuracy: 0.3857 - val_loss: 1.4373 - val_accuracy: 0.4251\n",
            "Epoch 26/500\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 1.5034 - accuracy: 0.3839 - val_loss: 1.4681 - val_accuracy: 0.3961\n",
            "Epoch 27/500\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 1.4987 - accuracy: 0.3797 - val_loss: 1.3669 - val_accuracy: 0.4589\n",
            "Epoch 28/500\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 1.4693 - accuracy: 0.3918 - val_loss: 1.4269 - val_accuracy: 0.4348\n",
            "Epoch 29/500\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 1.4259 - accuracy: 0.4135 - val_loss: 1.3587 - val_accuracy: 0.4686\n",
            "Epoch 30/500\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 1.4344 - accuracy: 0.4105 - val_loss: 1.3629 - val_accuracy: 0.4734\n",
            "Epoch 31/500\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 1.4393 - accuracy: 0.4039 - val_loss: 1.3730 - val_accuracy: 0.4589\n",
            "Epoch 32/500\n",
            "104/104 [==============================] - 1s 8ms/step - loss: 1.4065 - accuracy: 0.4389 - val_loss: 1.3681 - val_accuracy: 0.4928\n",
            "Epoch 33/500\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 1.3692 - accuracy: 0.4407 - val_loss: 1.3059 - val_accuracy: 0.4928\n",
            "Epoch 34/500\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 1.3708 - accuracy: 0.4480 - val_loss: 1.2718 - val_accuracy: 0.5169\n",
            "Epoch 35/500\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 1.3553 - accuracy: 0.4462 - val_loss: 1.2294 - val_accuracy: 0.5024\n",
            "Epoch 36/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.3470 - accuracy: 0.4510 - val_loss: 1.2278 - val_accuracy: 0.5411\n",
            "Epoch 37/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.3410 - accuracy: 0.4347 - val_loss: 1.3536 - val_accuracy: 0.4686\n",
            "Epoch 38/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.3158 - accuracy: 0.4704 - val_loss: 1.2282 - val_accuracy: 0.5169\n",
            "Epoch 39/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.3043 - accuracy: 0.4583 - val_loss: 1.1920 - val_accuracy: 0.5556\n",
            "Epoch 40/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.2790 - accuracy: 0.4740 - val_loss: 1.2258 - val_accuracy: 0.4783\n",
            "Epoch 41/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.2863 - accuracy: 0.4825 - val_loss: 1.3139 - val_accuracy: 0.4686\n",
            "Epoch 42/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.2752 - accuracy: 0.4819 - val_loss: 1.1794 - val_accuracy: 0.4879\n",
            "Epoch 43/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.2499 - accuracy: 0.5036 - val_loss: 1.1646 - val_accuracy: 0.5990\n",
            "Epoch 44/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.2332 - accuracy: 0.4970 - val_loss: 1.1480 - val_accuracy: 0.5894\n",
            "Epoch 45/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.2183 - accuracy: 0.5109 - val_loss: 1.2958 - val_accuracy: 0.4396\n",
            "Epoch 46/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.2063 - accuracy: 0.4976 - val_loss: 1.1769 - val_accuracy: 0.4928\n",
            "Epoch 47/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.2233 - accuracy: 0.5036 - val_loss: 1.1707 - val_accuracy: 0.5266\n",
            "Epoch 48/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.1837 - accuracy: 0.5091 - val_loss: 1.1502 - val_accuracy: 0.5314\n",
            "Epoch 49/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.1913 - accuracy: 0.5097 - val_loss: 1.1323 - val_accuracy: 0.5700\n",
            "Epoch 50/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.1952 - accuracy: 0.5193 - val_loss: 1.1678 - val_accuracy: 0.5121\n",
            "Epoch 51/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.1431 - accuracy: 0.5284 - val_loss: 1.0936 - val_accuracy: 0.6184\n",
            "Epoch 52/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.1654 - accuracy: 0.5139 - val_loss: 1.0528 - val_accuracy: 0.6377\n",
            "Epoch 53/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.1329 - accuracy: 0.5453 - val_loss: 1.0386 - val_accuracy: 0.6280\n",
            "Epoch 54/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.1210 - accuracy: 0.5387 - val_loss: 1.0433 - val_accuracy: 0.5942\n",
            "Epoch 55/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.1427 - accuracy: 0.5381 - val_loss: 1.0250 - val_accuracy: 0.6184\n",
            "Epoch 56/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.1296 - accuracy: 0.5405 - val_loss: 1.0121 - val_accuracy: 0.6522\n",
            "Epoch 57/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.1012 - accuracy: 0.5580 - val_loss: 1.0789 - val_accuracy: 0.5459\n",
            "Epoch 58/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.1078 - accuracy: 0.5423 - val_loss: 1.0718 - val_accuracy: 0.6039\n",
            "Epoch 59/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0763 - accuracy: 0.5659 - val_loss: 1.0219 - val_accuracy: 0.5894\n",
            "Epoch 60/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0646 - accuracy: 0.5732 - val_loss: 1.0406 - val_accuracy: 0.5845\n",
            "Epoch 61/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0868 - accuracy: 0.5623 - val_loss: 1.0133 - val_accuracy: 0.5845\n",
            "Epoch 62/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0805 - accuracy: 0.5508 - val_loss: 1.0129 - val_accuracy: 0.6039\n",
            "Epoch 63/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0651 - accuracy: 0.5647 - val_loss: 0.9786 - val_accuracy: 0.6280\n",
            "Epoch 64/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0154 - accuracy: 0.5889 - val_loss: 1.0496 - val_accuracy: 0.5411\n",
            "Epoch 65/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0598 - accuracy: 0.5526 - val_loss: 0.9937 - val_accuracy: 0.5845\n",
            "Epoch 66/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0339 - accuracy: 0.5877 - val_loss: 1.0170 - val_accuracy: 0.5942\n",
            "Epoch 67/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0356 - accuracy: 0.5907 - val_loss: 0.9871 - val_accuracy: 0.5942\n",
            "Epoch 68/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0063 - accuracy: 0.5871 - val_loss: 1.0168 - val_accuracy: 0.6184\n",
            "Epoch 69/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 1.0131 - accuracy: 0.5846 - val_loss: 1.0059 - val_accuracy: 0.6618\n",
            "Epoch 70/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9947 - accuracy: 0.5943 - val_loss: 0.9253 - val_accuracy: 0.6618\n",
            "Epoch 71/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 1.0083 - accuracy: 0.6082 - val_loss: 0.9621 - val_accuracy: 0.6184\n",
            "Epoch 72/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9853 - accuracy: 0.6034 - val_loss: 0.9318 - val_accuracy: 0.6812\n",
            "Epoch 73/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9711 - accuracy: 0.6004 - val_loss: 0.9212 - val_accuracy: 0.6425\n",
            "Epoch 74/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9467 - accuracy: 0.6233 - val_loss: 1.0022 - val_accuracy: 0.5942\n",
            "Epoch 75/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9373 - accuracy: 0.6475 - val_loss: 0.8985 - val_accuracy: 0.6522\n",
            "Epoch 76/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9699 - accuracy: 0.6106 - val_loss: 0.9470 - val_accuracy: 0.6232\n",
            "Epoch 77/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9387 - accuracy: 0.6167 - val_loss: 0.9729 - val_accuracy: 0.6184\n",
            "Epoch 78/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9393 - accuracy: 0.6245 - val_loss: 0.9176 - val_accuracy: 0.6667\n",
            "Epoch 79/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9345 - accuracy: 0.6209 - val_loss: 0.8979 - val_accuracy: 0.6425\n",
            "Epoch 80/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9449 - accuracy: 0.6209 - val_loss: 0.9728 - val_accuracy: 0.6329\n",
            "Epoch 81/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9193 - accuracy: 0.6342 - val_loss: 0.9574 - val_accuracy: 0.6232\n",
            "Epoch 82/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9447 - accuracy: 0.6227 - val_loss: 0.9368 - val_accuracy: 0.6280\n",
            "Epoch 83/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8978 - accuracy: 0.6342 - val_loss: 0.8993 - val_accuracy: 0.6715\n",
            "Epoch 84/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.9047 - accuracy: 0.6415 - val_loss: 0.9074 - val_accuracy: 0.6715\n",
            "Epoch 85/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8944 - accuracy: 0.6391 - val_loss: 0.8696 - val_accuracy: 0.6908\n",
            "Epoch 86/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.9116 - accuracy: 0.6433 - val_loss: 0.8727 - val_accuracy: 0.7005\n",
            "Epoch 87/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8946 - accuracy: 0.6372 - val_loss: 0.9194 - val_accuracy: 0.6425\n",
            "Epoch 88/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8975 - accuracy: 0.6499 - val_loss: 0.8968 - val_accuracy: 0.6522\n",
            "Epoch 89/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8841 - accuracy: 0.6481 - val_loss: 0.9083 - val_accuracy: 0.6425\n",
            "Epoch 90/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8570 - accuracy: 0.6445 - val_loss: 0.8630 - val_accuracy: 0.6715\n",
            "Epoch 91/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8544 - accuracy: 0.6578 - val_loss: 0.8878 - val_accuracy: 0.6473\n",
            "Epoch 92/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8614 - accuracy: 0.6554 - val_loss: 0.8901 - val_accuracy: 0.6618\n",
            "Epoch 93/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8676 - accuracy: 0.6499 - val_loss: 0.9336 - val_accuracy: 0.6087\n",
            "Epoch 94/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8624 - accuracy: 0.6590 - val_loss: 0.8831 - val_accuracy: 0.6570\n",
            "Epoch 95/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8688 - accuracy: 0.6620 - val_loss: 0.8869 - val_accuracy: 0.6473\n",
            "Epoch 96/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8376 - accuracy: 0.6651 - val_loss: 0.9106 - val_accuracy: 0.6377\n",
            "Epoch 97/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8248 - accuracy: 0.6771 - val_loss: 0.8861 - val_accuracy: 0.6377\n",
            "Epoch 98/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.8143 - accuracy: 0.6663 - val_loss: 0.9177 - val_accuracy: 0.5990\n",
            "Epoch 99/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8243 - accuracy: 0.6808 - val_loss: 0.8673 - val_accuracy: 0.6667\n",
            "Epoch 100/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8382 - accuracy: 0.6566 - val_loss: 0.9035 - val_accuracy: 0.6425\n",
            "Epoch 101/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8159 - accuracy: 0.6620 - val_loss: 0.8320 - val_accuracy: 0.6667\n",
            "Epoch 102/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8027 - accuracy: 0.6886 - val_loss: 0.8529 - val_accuracy: 0.6812\n",
            "Epoch 103/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8203 - accuracy: 0.6826 - val_loss: 0.8358 - val_accuracy: 0.6957\n",
            "Epoch 104/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7879 - accuracy: 0.6862 - val_loss: 0.8817 - val_accuracy: 0.6618\n",
            "Epoch 105/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.8098 - accuracy: 0.6705 - val_loss: 0.8590 - val_accuracy: 0.6570\n",
            "Epoch 106/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7935 - accuracy: 0.6838 - val_loss: 0.8372 - val_accuracy: 0.7101\n",
            "Epoch 107/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7770 - accuracy: 0.6947 - val_loss: 0.9636 - val_accuracy: 0.5797\n",
            "Epoch 108/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7656 - accuracy: 0.6953 - val_loss: 0.8360 - val_accuracy: 0.6667\n",
            "Epoch 109/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7606 - accuracy: 0.6850 - val_loss: 0.8209 - val_accuracy: 0.7005\n",
            "Epoch 110/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7728 - accuracy: 0.6959 - val_loss: 0.8380 - val_accuracy: 0.6377\n",
            "Epoch 111/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7816 - accuracy: 0.6820 - val_loss: 0.8262 - val_accuracy: 0.6667\n",
            "Epoch 112/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7849 - accuracy: 0.6917 - val_loss: 0.8037 - val_accuracy: 0.6957\n",
            "Epoch 113/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7907 - accuracy: 0.6935 - val_loss: 0.8104 - val_accuracy: 0.6957\n",
            "Epoch 114/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7516 - accuracy: 0.7001 - val_loss: 0.8082 - val_accuracy: 0.7005\n",
            "Epoch 115/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7558 - accuracy: 0.7056 - val_loss: 0.7840 - val_accuracy: 0.6812\n",
            "Epoch 116/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7320 - accuracy: 0.6989 - val_loss: 0.8137 - val_accuracy: 0.6618\n",
            "Epoch 117/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7395 - accuracy: 0.6995 - val_loss: 0.8745 - val_accuracy: 0.6377\n",
            "Epoch 118/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7551 - accuracy: 0.6989 - val_loss: 0.7875 - val_accuracy: 0.7053\n",
            "Epoch 119/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7290 - accuracy: 0.7098 - val_loss: 0.8821 - val_accuracy: 0.6184\n",
            "Epoch 120/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7319 - accuracy: 0.7098 - val_loss: 0.9103 - val_accuracy: 0.6618\n",
            "Epoch 121/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7361 - accuracy: 0.7086 - val_loss: 0.7972 - val_accuracy: 0.6957\n",
            "Epoch 122/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7424 - accuracy: 0.6971 - val_loss: 0.8186 - val_accuracy: 0.6860\n",
            "Epoch 123/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7139 - accuracy: 0.7122 - val_loss: 0.8013 - val_accuracy: 0.6860\n",
            "Epoch 124/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7207 - accuracy: 0.7201 - val_loss: 0.8127 - val_accuracy: 0.6763\n",
            "Epoch 125/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7204 - accuracy: 0.7086 - val_loss: 0.8099 - val_accuracy: 0.7053\n",
            "Epoch 126/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.7155 - accuracy: 0.7080 - val_loss: 0.7977 - val_accuracy: 0.6908\n",
            "Epoch 127/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.7178 - accuracy: 0.7037 - val_loss: 0.7697 - val_accuracy: 0.6860\n",
            "Epoch 128/500\n",
            "104/104 [==============================] - 1s 10ms/step - loss: 0.6940 - accuracy: 0.7291 - val_loss: 0.7903 - val_accuracy: 0.7053\n",
            "Epoch 129/500\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.7068 - accuracy: 0.7195 - val_loss: 0.8167 - val_accuracy: 0.6425\n",
            "Epoch 130/500\n",
            "104/104 [==============================] - 1s 10ms/step - loss: 0.6851 - accuracy: 0.7273 - val_loss: 0.8003 - val_accuracy: 0.6860\n",
            "Epoch 131/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.6760 - accuracy: 0.7346 - val_loss: 0.7603 - val_accuracy: 0.7198\n",
            "Epoch 132/500\n",
            "104/104 [==============================] - 1s 9ms/step - loss: 0.7229 - accuracy: 0.7122 - val_loss: 0.8225 - val_accuracy: 0.6667\n",
            "Epoch 133/500\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.6833 - accuracy: 0.7285 - val_loss: 0.7801 - val_accuracy: 0.6763\n",
            "Epoch 134/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6918 - accuracy: 0.7364 - val_loss: 0.7786 - val_accuracy: 0.6908\n",
            "Epoch 135/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6917 - accuracy: 0.7364 - val_loss: 0.8573 - val_accuracy: 0.6618\n",
            "Epoch 136/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6929 - accuracy: 0.7316 - val_loss: 0.8490 - val_accuracy: 0.6763\n",
            "Epoch 137/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6616 - accuracy: 0.7400 - val_loss: 0.7627 - val_accuracy: 0.6908\n",
            "Epoch 138/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6631 - accuracy: 0.7267 - val_loss: 0.8273 - val_accuracy: 0.6473\n",
            "Epoch 139/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6788 - accuracy: 0.7267 - val_loss: 0.7955 - val_accuracy: 0.7150\n",
            "Epoch 140/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6466 - accuracy: 0.7364 - val_loss: 0.7658 - val_accuracy: 0.6957\n",
            "Epoch 141/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6425 - accuracy: 0.7521 - val_loss: 0.7495 - val_accuracy: 0.7246\n",
            "Epoch 142/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6391 - accuracy: 0.7600 - val_loss: 0.8095 - val_accuracy: 0.6667\n",
            "Epoch 143/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6540 - accuracy: 0.7412 - val_loss: 0.7870 - val_accuracy: 0.6812\n",
            "Epoch 144/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6384 - accuracy: 0.7563 - val_loss: 0.7547 - val_accuracy: 0.6812\n",
            "Epoch 145/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6452 - accuracy: 0.7400 - val_loss: 0.8040 - val_accuracy: 0.6522\n",
            "Epoch 146/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6369 - accuracy: 0.7563 - val_loss: 0.7613 - val_accuracy: 0.7005\n",
            "Epoch 147/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6253 - accuracy: 0.7491 - val_loss: 0.7394 - val_accuracy: 0.7053\n",
            "Epoch 148/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6423 - accuracy: 0.7449 - val_loss: 0.8087 - val_accuracy: 0.6522\n",
            "Epoch 149/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6521 - accuracy: 0.7340 - val_loss: 0.8007 - val_accuracy: 0.6812\n",
            "Epoch 150/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6258 - accuracy: 0.7588 - val_loss: 0.7536 - val_accuracy: 0.7150\n",
            "Epoch 151/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6080 - accuracy: 0.7672 - val_loss: 0.7596 - val_accuracy: 0.6860\n",
            "Epoch 152/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5873 - accuracy: 0.7551 - val_loss: 0.7303 - val_accuracy: 0.7198\n",
            "Epoch 153/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6216 - accuracy: 0.7666 - val_loss: 0.7751 - val_accuracy: 0.6667\n",
            "Epoch 154/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6151 - accuracy: 0.7648 - val_loss: 0.7698 - val_accuracy: 0.6908\n",
            "Epoch 155/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6115 - accuracy: 0.7509 - val_loss: 0.7995 - val_accuracy: 0.6908\n",
            "Epoch 156/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.6029 - accuracy: 0.7618 - val_loss: 0.8067 - val_accuracy: 0.6763\n",
            "Epoch 157/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5893 - accuracy: 0.7636 - val_loss: 0.7173 - val_accuracy: 0.7391\n",
            "Epoch 158/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5888 - accuracy: 0.7709 - val_loss: 0.7774 - val_accuracy: 0.6860\n",
            "Epoch 159/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5991 - accuracy: 0.7709 - val_loss: 0.7531 - val_accuracy: 0.6957\n",
            "Epoch 160/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5757 - accuracy: 0.7684 - val_loss: 0.7592 - val_accuracy: 0.6860\n",
            "Epoch 161/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5755 - accuracy: 0.7823 - val_loss: 0.7396 - val_accuracy: 0.7198\n",
            "Epoch 162/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5727 - accuracy: 0.7811 - val_loss: 0.7187 - val_accuracy: 0.7246\n",
            "Epoch 163/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5849 - accuracy: 0.7763 - val_loss: 0.7841 - val_accuracy: 0.6860\n",
            "Epoch 164/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5750 - accuracy: 0.7733 - val_loss: 0.7560 - val_accuracy: 0.6957\n",
            "Epoch 165/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5783 - accuracy: 0.7763 - val_loss: 0.7381 - val_accuracy: 0.7005\n",
            "Epoch 166/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5896 - accuracy: 0.7709 - val_loss: 0.7531 - val_accuracy: 0.7150\n",
            "Epoch 167/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5627 - accuracy: 0.7830 - val_loss: 0.7103 - val_accuracy: 0.6715\n",
            "Epoch 168/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5590 - accuracy: 0.7769 - val_loss: 0.7311 - val_accuracy: 0.7150\n",
            "Epoch 169/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5367 - accuracy: 0.7932 - val_loss: 0.7687 - val_accuracy: 0.6860\n",
            "Epoch 170/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5275 - accuracy: 0.8071 - val_loss: 0.7148 - val_accuracy: 0.7101\n",
            "Epoch 171/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5560 - accuracy: 0.7715 - val_loss: 0.6969 - val_accuracy: 0.7295\n",
            "Epoch 172/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5509 - accuracy: 0.7902 - val_loss: 0.7119 - val_accuracy: 0.6763\n",
            "Epoch 173/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5622 - accuracy: 0.7769 - val_loss: 0.7127 - val_accuracy: 0.7343\n",
            "Epoch 174/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.5446 - accuracy: 0.7842 - val_loss: 0.7319 - val_accuracy: 0.7295\n",
            "Epoch 175/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5303 - accuracy: 0.7956 - val_loss: 0.7014 - val_accuracy: 0.7246\n",
            "Epoch 176/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5374 - accuracy: 0.7944 - val_loss: 0.7315 - val_accuracy: 0.7053\n",
            "Epoch 177/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5383 - accuracy: 0.7866 - val_loss: 0.7444 - val_accuracy: 0.6908\n",
            "Epoch 178/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5372 - accuracy: 0.7926 - val_loss: 0.6906 - val_accuracy: 0.7343\n",
            "Epoch 179/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.5335 - accuracy: 0.7932 - val_loss: 0.7105 - val_accuracy: 0.6957\n",
            "Epoch 180/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5346 - accuracy: 0.7944 - val_loss: 0.7733 - val_accuracy: 0.6618\n",
            "Epoch 181/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5002 - accuracy: 0.8041 - val_loss: 0.6815 - val_accuracy: 0.7101\n",
            "Epoch 182/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5205 - accuracy: 0.7920 - val_loss: 0.6771 - val_accuracy: 0.7150\n",
            "Epoch 183/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5110 - accuracy: 0.8035 - val_loss: 0.7199 - val_accuracy: 0.7343\n",
            "Epoch 184/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5307 - accuracy: 0.7932 - val_loss: 0.6934 - val_accuracy: 0.7101\n",
            "Epoch 185/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5253 - accuracy: 0.7981 - val_loss: 0.6688 - val_accuracy: 0.7198\n",
            "Epoch 186/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5040 - accuracy: 0.8096 - val_loss: 0.6873 - val_accuracy: 0.7343\n",
            "Epoch 187/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4854 - accuracy: 0.8041 - val_loss: 0.6926 - val_accuracy: 0.7536\n",
            "Epoch 188/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4969 - accuracy: 0.8065 - val_loss: 0.7291 - val_accuracy: 0.7053\n",
            "Epoch 189/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5068 - accuracy: 0.8053 - val_loss: 0.7221 - val_accuracy: 0.7198\n",
            "Epoch 190/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4882 - accuracy: 0.8120 - val_loss: 0.7356 - val_accuracy: 0.7150\n",
            "Epoch 191/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.5113 - accuracy: 0.8071 - val_loss: 0.6706 - val_accuracy: 0.7488\n",
            "Epoch 192/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4904 - accuracy: 0.8120 - val_loss: 0.7261 - val_accuracy: 0.7005\n",
            "Epoch 193/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4678 - accuracy: 0.8235 - val_loss: 0.6958 - val_accuracy: 0.6908\n",
            "Epoch 194/500\n",
            "104/104 [==============================] - 0s 5ms/step - loss: 0.4921 - accuracy: 0.8005 - val_loss: 0.7477 - val_accuracy: 0.6812\n",
            "Epoch 195/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4870 - accuracy: 0.8102 - val_loss: 0.6719 - val_accuracy: 0.7101\n",
            "Epoch 196/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4728 - accuracy: 0.8216 - val_loss: 0.7264 - val_accuracy: 0.6957\n",
            "Epoch 197/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4830 - accuracy: 0.8259 - val_loss: 0.7523 - val_accuracy: 0.6715\n",
            "Epoch 198/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4807 - accuracy: 0.8156 - val_loss: 0.6891 - val_accuracy: 0.7440\n",
            "Epoch 199/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4654 - accuracy: 0.8132 - val_loss: 0.7078 - val_accuracy: 0.6957\n",
            "Epoch 200/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4763 - accuracy: 0.8156 - val_loss: 0.6642 - val_accuracy: 0.7633\n",
            "Epoch 201/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4673 - accuracy: 0.8192 - val_loss: 0.7257 - val_accuracy: 0.7150\n",
            "Epoch 202/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4522 - accuracy: 0.8271 - val_loss: 0.6446 - val_accuracy: 0.7536\n",
            "Epoch 203/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4658 - accuracy: 0.8319 - val_loss: 0.6481 - val_accuracy: 0.7440\n",
            "Epoch 204/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4529 - accuracy: 0.8277 - val_loss: 0.6602 - val_accuracy: 0.7585\n",
            "Epoch 205/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4348 - accuracy: 0.8368 - val_loss: 0.7246 - val_accuracy: 0.7198\n",
            "Epoch 206/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4472 - accuracy: 0.8241 - val_loss: 0.7179 - val_accuracy: 0.7246\n",
            "Epoch 207/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4662 - accuracy: 0.8198 - val_loss: 0.6783 - val_accuracy: 0.7585\n",
            "Epoch 208/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4437 - accuracy: 0.8307 - val_loss: 0.7580 - val_accuracy: 0.7053\n",
            "Epoch 209/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4324 - accuracy: 0.8386 - val_loss: 0.7041 - val_accuracy: 0.7150\n",
            "Epoch 210/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4524 - accuracy: 0.8247 - val_loss: 0.7004 - val_accuracy: 0.7150\n",
            "Epoch 211/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4536 - accuracy: 0.8277 - val_loss: 0.6386 - val_accuracy: 0.7536\n",
            "Epoch 212/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4383 - accuracy: 0.8349 - val_loss: 0.6938 - val_accuracy: 0.7101\n",
            "Epoch 213/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4204 - accuracy: 0.8349 - val_loss: 0.6919 - val_accuracy: 0.7101\n",
            "Epoch 214/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4349 - accuracy: 0.8247 - val_loss: 0.6231 - val_accuracy: 0.7633\n",
            "Epoch 215/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4160 - accuracy: 0.8356 - val_loss: 0.7009 - val_accuracy: 0.7343\n",
            "Epoch 216/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4396 - accuracy: 0.8301 - val_loss: 0.6435 - val_accuracy: 0.7440\n",
            "Epoch 217/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4188 - accuracy: 0.8392 - val_loss: 0.6375 - val_accuracy: 0.7681\n",
            "Epoch 218/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4172 - accuracy: 0.8537 - val_loss: 0.6947 - val_accuracy: 0.7295\n",
            "Epoch 219/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4412 - accuracy: 0.8277 - val_loss: 0.6567 - val_accuracy: 0.7391\n",
            "Epoch 220/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4119 - accuracy: 0.8404 - val_loss: 0.6307 - val_accuracy: 0.7391\n",
            "Epoch 221/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4086 - accuracy: 0.8386 - val_loss: 0.6491 - val_accuracy: 0.7633\n",
            "Epoch 222/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.4215 - accuracy: 0.8386 - val_loss: 0.6605 - val_accuracy: 0.7536\n",
            "Epoch 223/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.4235 - accuracy: 0.8398 - val_loss: 0.6283 - val_accuracy: 0.7343\n",
            "Epoch 224/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4102 - accuracy: 0.8537 - val_loss: 0.6657 - val_accuracy: 0.7440\n",
            "Epoch 225/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4165 - accuracy: 0.8392 - val_loss: 0.7655 - val_accuracy: 0.6860\n",
            "Epoch 226/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.3938 - accuracy: 0.8573 - val_loss: 0.6301 - val_accuracy: 0.7343\n",
            "Epoch 227/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.3948 - accuracy: 0.8404 - val_loss: 0.6565 - val_accuracy: 0.7391\n",
            "Epoch 228/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4118 - accuracy: 0.8416 - val_loss: 0.7069 - val_accuracy: 0.7488\n",
            "Epoch 229/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4117 - accuracy: 0.8337 - val_loss: 0.6461 - val_accuracy: 0.7295\n",
            "Epoch 230/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3799 - accuracy: 0.8555 - val_loss: 0.7287 - val_accuracy: 0.6957\n",
            "Epoch 231/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4065 - accuracy: 0.8440 - val_loss: 0.6888 - val_accuracy: 0.7246\n",
            "Epoch 232/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3899 - accuracy: 0.8507 - val_loss: 0.6726 - val_accuracy: 0.7536\n",
            "Epoch 233/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3801 - accuracy: 0.8549 - val_loss: 0.6344 - val_accuracy: 0.7343\n",
            "Epoch 234/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.4203 - accuracy: 0.8422 - val_loss: 0.6299 - val_accuracy: 0.7729\n",
            "Epoch 235/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3860 - accuracy: 0.8567 - val_loss: 0.6175 - val_accuracy: 0.7536\n",
            "Epoch 236/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3964 - accuracy: 0.8507 - val_loss: 0.6328 - val_accuracy: 0.7440\n",
            "Epoch 237/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3799 - accuracy: 0.8549 - val_loss: 0.6322 - val_accuracy: 0.7391\n",
            "Epoch 238/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3842 - accuracy: 0.8464 - val_loss: 0.6271 - val_accuracy: 0.7633\n",
            "Epoch 239/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3688 - accuracy: 0.8676 - val_loss: 0.6338 - val_accuracy: 0.7923\n",
            "Epoch 240/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3709 - accuracy: 0.8555 - val_loss: 0.6686 - val_accuracy: 0.7101\n",
            "Epoch 241/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3809 - accuracy: 0.8591 - val_loss: 0.6382 - val_accuracy: 0.7729\n",
            "Epoch 242/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3672 - accuracy: 0.8658 - val_loss: 0.6538 - val_accuracy: 0.7536\n",
            "Epoch 243/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3595 - accuracy: 0.8634 - val_loss: 0.6411 - val_accuracy: 0.7246\n",
            "Epoch 244/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3681 - accuracy: 0.8682 - val_loss: 0.7056 - val_accuracy: 0.7440\n",
            "Epoch 245/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3727 - accuracy: 0.8682 - val_loss: 0.6583 - val_accuracy: 0.7681\n",
            "Epoch 246/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3586 - accuracy: 0.8652 - val_loss: 0.6250 - val_accuracy: 0.7633\n",
            "Epoch 247/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3608 - accuracy: 0.8615 - val_loss: 0.6495 - val_accuracy: 0.7826\n",
            "Epoch 248/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3425 - accuracy: 0.8712 - val_loss: 0.7040 - val_accuracy: 0.7150\n",
            "Epoch 249/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3688 - accuracy: 0.8646 - val_loss: 0.6441 - val_accuracy: 0.7778\n",
            "Epoch 250/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3691 - accuracy: 0.8549 - val_loss: 0.6691 - val_accuracy: 0.7633\n",
            "Epoch 251/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3368 - accuracy: 0.8791 - val_loss: 0.6992 - val_accuracy: 0.7343\n",
            "Epoch 252/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3577 - accuracy: 0.8694 - val_loss: 0.6977 - val_accuracy: 0.7246\n",
            "Epoch 253/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3562 - accuracy: 0.8682 - val_loss: 0.6473 - val_accuracy: 0.7729\n",
            "Epoch 254/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3505 - accuracy: 0.8561 - val_loss: 0.6328 - val_accuracy: 0.7778\n",
            "Epoch 255/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3478 - accuracy: 0.8767 - val_loss: 0.6210 - val_accuracy: 0.7729\n",
            "Epoch 256/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3352 - accuracy: 0.8609 - val_loss: 0.6396 - val_accuracy: 0.7729\n",
            "Epoch 257/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3602 - accuracy: 0.8664 - val_loss: 0.6651 - val_accuracy: 0.7488\n",
            "Epoch 258/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3363 - accuracy: 0.8742 - val_loss: 0.6620 - val_accuracy: 0.7633\n",
            "Epoch 259/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3635 - accuracy: 0.8573 - val_loss: 0.6407 - val_accuracy: 0.7681\n",
            "Epoch 260/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3312 - accuracy: 0.8785 - val_loss: 0.6648 - val_accuracy: 0.7343\n",
            "Epoch 261/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3367 - accuracy: 0.8785 - val_loss: 0.6877 - val_accuracy: 0.7101\n",
            "Epoch 262/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3621 - accuracy: 0.8706 - val_loss: 0.6581 - val_accuracy: 0.7826\n",
            "Epoch 263/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3108 - accuracy: 0.8833 - val_loss: 0.6180 - val_accuracy: 0.8019\n",
            "Epoch 264/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3245 - accuracy: 0.8700 - val_loss: 0.6378 - val_accuracy: 0.7585\n",
            "Epoch 265/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3194 - accuracy: 0.8900 - val_loss: 0.6505 - val_accuracy: 0.7246\n",
            "Epoch 266/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3457 - accuracy: 0.8646 - val_loss: 0.7558 - val_accuracy: 0.7005\n",
            "Epoch 267/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3437 - accuracy: 0.8670 - val_loss: 0.6748 - val_accuracy: 0.7488\n",
            "Epoch 268/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3433 - accuracy: 0.8815 - val_loss: 0.6173 - val_accuracy: 0.7778\n",
            "Epoch 269/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3208 - accuracy: 0.8676 - val_loss: 0.6983 - val_accuracy: 0.7246\n",
            "Epoch 270/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3409 - accuracy: 0.8797 - val_loss: 0.6460 - val_accuracy: 0.7488\n",
            "Epoch 271/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.3013 - accuracy: 0.8869 - val_loss: 0.6429 - val_accuracy: 0.7295\n",
            "Epoch 272/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3076 - accuracy: 0.8912 - val_loss: 0.6521 - val_accuracy: 0.7729\n",
            "Epoch 273/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.3076 - accuracy: 0.8803 - val_loss: 0.6095 - val_accuracy: 0.7923\n",
            "Epoch 274/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2837 - accuracy: 0.9002 - val_loss: 0.6483 - val_accuracy: 0.7536\n",
            "Epoch 275/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3159 - accuracy: 0.8821 - val_loss: 0.6493 - val_accuracy: 0.7488\n",
            "Epoch 276/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2825 - accuracy: 0.8990 - val_loss: 0.6745 - val_accuracy: 0.7488\n",
            "Epoch 277/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2891 - accuracy: 0.8936 - val_loss: 0.6614 - val_accuracy: 0.7585\n",
            "Epoch 278/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.3250 - accuracy: 0.8803 - val_loss: 0.6883 - val_accuracy: 0.7585\n",
            "Epoch 279/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3093 - accuracy: 0.8906 - val_loss: 0.6835 - val_accuracy: 0.7585\n",
            "Epoch 280/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2954 - accuracy: 0.8863 - val_loss: 0.6219 - val_accuracy: 0.8068\n",
            "Epoch 281/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2867 - accuracy: 0.8906 - val_loss: 0.6333 - val_accuracy: 0.7729\n",
            "Epoch 282/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3029 - accuracy: 0.8815 - val_loss: 0.5871 - val_accuracy: 0.7778\n",
            "Epoch 283/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3077 - accuracy: 0.8851 - val_loss: 0.6359 - val_accuracy: 0.7488\n",
            "Epoch 284/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3025 - accuracy: 0.8948 - val_loss: 0.6068 - val_accuracy: 0.7874\n",
            "Epoch 285/500\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.3039 - accuracy: 0.8742 - val_loss: 0.6268 - val_accuracy: 0.7536\n",
            "Epoch 286/500\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.2987 - accuracy: 0.8881 - val_loss: 0.5877 - val_accuracy: 0.7971\n",
            "Epoch 287/500\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.2770 - accuracy: 0.8972 - val_loss: 0.6592 - val_accuracy: 0.7391\n",
            "Epoch 288/500\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.2924 - accuracy: 0.8875 - val_loss: 0.6670 - val_accuracy: 0.7826\n",
            "Epoch 289/500\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.3140 - accuracy: 0.8851 - val_loss: 0.6535 - val_accuracy: 0.7536\n",
            "Epoch 290/500\n",
            "104/104 [==============================] - 1s 7ms/step - loss: 0.2915 - accuracy: 0.8815 - val_loss: 0.6756 - val_accuracy: 0.7488\n",
            "Epoch 291/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2893 - accuracy: 0.9008 - val_loss: 0.6212 - val_accuracy: 0.7729\n",
            "Epoch 292/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2976 - accuracy: 0.8881 - val_loss: 0.6143 - val_accuracy: 0.7633\n",
            "Epoch 293/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2883 - accuracy: 0.8930 - val_loss: 0.6332 - val_accuracy: 0.7585\n",
            "Epoch 294/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2983 - accuracy: 0.8936 - val_loss: 0.6396 - val_accuracy: 0.7440\n",
            "Epoch 295/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.3049 - accuracy: 0.8827 - val_loss: 0.6340 - val_accuracy: 0.7923\n",
            "Epoch 296/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3072 - accuracy: 0.8845 - val_loss: 0.6144 - val_accuracy: 0.7923\n",
            "Epoch 297/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2771 - accuracy: 0.8912 - val_loss: 0.6047 - val_accuracy: 0.7874\n",
            "Epoch 298/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2598 - accuracy: 0.8960 - val_loss: 0.5846 - val_accuracy: 0.8019\n",
            "Epoch 299/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2878 - accuracy: 0.8984 - val_loss: 0.6241 - val_accuracy: 0.7681\n",
            "Epoch 300/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2909 - accuracy: 0.8857 - val_loss: 0.5841 - val_accuracy: 0.7778\n",
            "Epoch 301/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2781 - accuracy: 0.8918 - val_loss: 0.6099 - val_accuracy: 0.7874\n",
            "Epoch 302/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2821 - accuracy: 0.9021 - val_loss: 0.6221 - val_accuracy: 0.7826\n",
            "Epoch 303/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2845 - accuracy: 0.8900 - val_loss: 0.6376 - val_accuracy: 0.7246\n",
            "Epoch 304/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2685 - accuracy: 0.9051 - val_loss: 0.6488 - val_accuracy: 0.7633\n",
            "Epoch 305/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2803 - accuracy: 0.8942 - val_loss: 0.7023 - val_accuracy: 0.7488\n",
            "Epoch 306/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2914 - accuracy: 0.8984 - val_loss: 0.6945 - val_accuracy: 0.7343\n",
            "Epoch 307/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3022 - accuracy: 0.8809 - val_loss: 0.6253 - val_accuracy: 0.7923\n",
            "Epoch 308/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2877 - accuracy: 0.8869 - val_loss: 0.6151 - val_accuracy: 0.7874\n",
            "Epoch 309/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2741 - accuracy: 0.8912 - val_loss: 0.6213 - val_accuracy: 0.7585\n",
            "Epoch 310/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.3003 - accuracy: 0.8761 - val_loss: 0.6399 - val_accuracy: 0.7440\n",
            "Epoch 311/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2813 - accuracy: 0.8972 - val_loss: 0.6780 - val_accuracy: 0.7971\n",
            "Epoch 312/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2762 - accuracy: 0.9051 - val_loss: 0.5842 - val_accuracy: 0.8116\n",
            "Epoch 313/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2744 - accuracy: 0.8900 - val_loss: 0.5534 - val_accuracy: 0.8068\n",
            "Epoch 314/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2237 - accuracy: 0.9129 - val_loss: 0.6445 - val_accuracy: 0.7778\n",
            "Epoch 315/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2790 - accuracy: 0.9008 - val_loss: 0.6356 - val_accuracy: 0.7633\n",
            "Epoch 316/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2517 - accuracy: 0.9051 - val_loss: 0.6700 - val_accuracy: 0.7633\n",
            "Epoch 317/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2613 - accuracy: 0.9015 - val_loss: 0.6548 - val_accuracy: 0.7874\n",
            "Epoch 318/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2696 - accuracy: 0.9099 - val_loss: 0.5874 - val_accuracy: 0.7729\n",
            "Epoch 319/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2752 - accuracy: 0.9021 - val_loss: 0.6770 - val_accuracy: 0.7633\n",
            "Epoch 320/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2533 - accuracy: 0.9015 - val_loss: 0.6889 - val_accuracy: 0.7488\n",
            "Epoch 321/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2501 - accuracy: 0.9033 - val_loss: 0.6042 - val_accuracy: 0.7874\n",
            "Epoch 322/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2859 - accuracy: 0.8960 - val_loss: 0.5920 - val_accuracy: 0.7681\n",
            "Epoch 323/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2611 - accuracy: 0.9015 - val_loss: 0.6728 - val_accuracy: 0.7585\n",
            "Epoch 324/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2414 - accuracy: 0.9160 - val_loss: 0.6595 - val_accuracy: 0.7585\n",
            "Epoch 325/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2395 - accuracy: 0.9154 - val_loss: 0.6957 - val_accuracy: 0.7729\n",
            "Epoch 326/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2365 - accuracy: 0.9184 - val_loss: 0.6659 - val_accuracy: 0.7633\n",
            "Epoch 327/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2344 - accuracy: 0.9105 - val_loss: 0.6712 - val_accuracy: 0.7778\n",
            "Epoch 328/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2420 - accuracy: 0.9123 - val_loss: 0.7446 - val_accuracy: 0.7198\n",
            "Epoch 329/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2514 - accuracy: 0.9087 - val_loss: 0.7143 - val_accuracy: 0.7536\n",
            "Epoch 330/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2513 - accuracy: 0.9051 - val_loss: 0.6443 - val_accuracy: 0.7923\n",
            "Epoch 331/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2561 - accuracy: 0.9002 - val_loss: 0.7115 - val_accuracy: 0.7536\n",
            "Epoch 332/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2267 - accuracy: 0.9081 - val_loss: 0.7017 - val_accuracy: 0.7343\n",
            "Epoch 333/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2438 - accuracy: 0.9087 - val_loss: 0.7057 - val_accuracy: 0.7778\n",
            "Epoch 334/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2471 - accuracy: 0.9111 - val_loss: 0.6206 - val_accuracy: 0.7874\n",
            "Epoch 335/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2436 - accuracy: 0.9129 - val_loss: 0.6815 - val_accuracy: 0.7295\n",
            "Epoch 336/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2530 - accuracy: 0.9039 - val_loss: 0.6050 - val_accuracy: 0.7923\n",
            "Epoch 337/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2534 - accuracy: 0.9075 - val_loss: 0.6201 - val_accuracy: 0.7729\n",
            "Epoch 338/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2423 - accuracy: 0.9069 - val_loss: 0.6055 - val_accuracy: 0.7923\n",
            "Epoch 339/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2395 - accuracy: 0.9051 - val_loss: 0.6016 - val_accuracy: 0.7971\n",
            "Epoch 340/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2484 - accuracy: 0.9021 - val_loss: 0.6572 - val_accuracy: 0.7826\n",
            "Epoch 341/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2271 - accuracy: 0.9141 - val_loss: 0.6564 - val_accuracy: 0.7874\n",
            "Epoch 342/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2781 - accuracy: 0.9045 - val_loss: 0.5966 - val_accuracy: 0.7971\n",
            "Epoch 343/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2281 - accuracy: 0.9148 - val_loss: 0.6797 - val_accuracy: 0.7778\n",
            "Epoch 344/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2405 - accuracy: 0.9087 - val_loss: 0.5722 - val_accuracy: 0.8213\n",
            "Epoch 345/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2225 - accuracy: 0.9226 - val_loss: 0.6100 - val_accuracy: 0.8116\n",
            "Epoch 346/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2599 - accuracy: 0.9123 - val_loss: 0.6499 - val_accuracy: 0.7778\n",
            "Epoch 347/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2553 - accuracy: 0.8978 - val_loss: 0.6715 - val_accuracy: 0.7536\n",
            "Epoch 348/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2436 - accuracy: 0.9081 - val_loss: 0.6597 - val_accuracy: 0.7923\n",
            "Epoch 349/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2737 - accuracy: 0.9008 - val_loss: 0.6303 - val_accuracy: 0.7681\n",
            "Epoch 350/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2318 - accuracy: 0.9117 - val_loss: 0.5747 - val_accuracy: 0.7923\n",
            "Epoch 351/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2495 - accuracy: 0.9069 - val_loss: 0.6539 - val_accuracy: 0.7923\n",
            "Epoch 352/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2222 - accuracy: 0.9214 - val_loss: 0.6792 - val_accuracy: 0.7585\n",
            "Epoch 353/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2282 - accuracy: 0.9172 - val_loss: 0.6112 - val_accuracy: 0.8068\n",
            "Epoch 354/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2238 - accuracy: 0.9196 - val_loss: 0.6394 - val_accuracy: 0.7971\n",
            "Epoch 355/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2305 - accuracy: 0.9208 - val_loss: 0.6378 - val_accuracy: 0.7826\n",
            "Epoch 356/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2258 - accuracy: 0.9214 - val_loss: 0.6555 - val_accuracy: 0.7874\n",
            "Epoch 357/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2323 - accuracy: 0.9238 - val_loss: 0.6851 - val_accuracy: 0.7826\n",
            "Epoch 358/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2194 - accuracy: 0.9208 - val_loss: 0.6861 - val_accuracy: 0.7729\n",
            "Epoch 359/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2288 - accuracy: 0.9160 - val_loss: 0.6578 - val_accuracy: 0.7971\n",
            "Epoch 360/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2513 - accuracy: 0.9087 - val_loss: 0.6948 - val_accuracy: 0.7633\n",
            "Epoch 361/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2179 - accuracy: 0.9190 - val_loss: 0.7050 - val_accuracy: 0.7729\n",
            "Epoch 362/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2246 - accuracy: 0.9148 - val_loss: 0.6423 - val_accuracy: 0.8019\n",
            "Epoch 363/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2309 - accuracy: 0.9244 - val_loss: 0.6454 - val_accuracy: 0.7826\n",
            "Epoch 364/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2383 - accuracy: 0.9099 - val_loss: 0.6357 - val_accuracy: 0.7585\n",
            "Epoch 365/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2180 - accuracy: 0.9196 - val_loss: 0.6817 - val_accuracy: 0.7536\n",
            "Epoch 366/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2163 - accuracy: 0.9232 - val_loss: 0.6749 - val_accuracy: 0.7536\n",
            "Epoch 367/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2002 - accuracy: 0.9268 - val_loss: 0.6927 - val_accuracy: 0.7681\n",
            "Epoch 368/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2023 - accuracy: 0.9244 - val_loss: 0.6208 - val_accuracy: 0.7874\n",
            "Epoch 369/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2129 - accuracy: 0.9256 - val_loss: 0.6007 - val_accuracy: 0.8116\n",
            "Epoch 370/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1885 - accuracy: 0.9250 - val_loss: 0.6189 - val_accuracy: 0.7971\n",
            "Epoch 371/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2314 - accuracy: 0.9202 - val_loss: 0.6028 - val_accuracy: 0.8068\n",
            "Epoch 372/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2098 - accuracy: 0.9293 - val_loss: 0.6092 - val_accuracy: 0.7874\n",
            "Epoch 373/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1953 - accuracy: 0.9335 - val_loss: 0.6561 - val_accuracy: 0.7971\n",
            "Epoch 374/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2145 - accuracy: 0.9250 - val_loss: 0.6050 - val_accuracy: 0.7971\n",
            "Epoch 375/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2075 - accuracy: 0.9299 - val_loss: 0.8520 - val_accuracy: 0.7633\n",
            "Epoch 376/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2158 - accuracy: 0.9178 - val_loss: 0.5897 - val_accuracy: 0.7874\n",
            "Epoch 377/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1978 - accuracy: 0.9299 - val_loss: 0.6904 - val_accuracy: 0.7633\n",
            "Epoch 378/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1748 - accuracy: 0.9341 - val_loss: 0.6799 - val_accuracy: 0.7729\n",
            "Epoch 379/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2096 - accuracy: 0.9214 - val_loss: 0.6795 - val_accuracy: 0.7633\n",
            "Epoch 380/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2083 - accuracy: 0.9208 - val_loss: 0.5849 - val_accuracy: 0.7923\n",
            "Epoch 381/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2038 - accuracy: 0.9238 - val_loss: 0.6831 - val_accuracy: 0.7729\n",
            "Epoch 382/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2112 - accuracy: 0.9238 - val_loss: 0.6495 - val_accuracy: 0.7874\n",
            "Epoch 383/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2101 - accuracy: 0.9287 - val_loss: 0.7283 - val_accuracy: 0.7343\n",
            "Epoch 384/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1953 - accuracy: 0.9371 - val_loss: 0.6657 - val_accuracy: 0.8019\n",
            "Epoch 385/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1986 - accuracy: 0.9214 - val_loss: 0.6832 - val_accuracy: 0.7923\n",
            "Epoch 386/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2250 - accuracy: 0.9154 - val_loss: 0.6273 - val_accuracy: 0.7971\n",
            "Epoch 387/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1947 - accuracy: 0.9274 - val_loss: 0.6050 - val_accuracy: 0.7778\n",
            "Epoch 388/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2026 - accuracy: 0.9329 - val_loss: 0.6511 - val_accuracy: 0.7971\n",
            "Epoch 389/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1866 - accuracy: 0.9317 - val_loss: 0.6674 - val_accuracy: 0.7923\n",
            "Epoch 390/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1804 - accuracy: 0.9329 - val_loss: 0.7042 - val_accuracy: 0.8019\n",
            "Epoch 391/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2029 - accuracy: 0.9281 - val_loss: 0.7810 - val_accuracy: 0.7681\n",
            "Epoch 392/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2092 - accuracy: 0.9214 - val_loss: 0.6267 - val_accuracy: 0.8116\n",
            "Epoch 393/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1864 - accuracy: 0.9299 - val_loss: 0.6578 - val_accuracy: 0.7874\n",
            "Epoch 394/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2198 - accuracy: 0.9196 - val_loss: 0.6795 - val_accuracy: 0.7971\n",
            "Epoch 395/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1958 - accuracy: 0.9329 - val_loss: 0.6142 - val_accuracy: 0.8164\n",
            "Epoch 396/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1946 - accuracy: 0.9274 - val_loss: 0.5951 - val_accuracy: 0.7923\n",
            "Epoch 397/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1770 - accuracy: 0.9335 - val_loss: 0.6981 - val_accuracy: 0.7681\n",
            "Epoch 398/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2005 - accuracy: 0.9293 - val_loss: 0.6736 - val_accuracy: 0.8019\n",
            "Epoch 399/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1934 - accuracy: 0.9274 - val_loss: 0.5839 - val_accuracy: 0.8261\n",
            "Epoch 400/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2128 - accuracy: 0.9274 - val_loss: 0.6227 - val_accuracy: 0.7923\n",
            "Epoch 401/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1901 - accuracy: 0.9365 - val_loss: 0.6076 - val_accuracy: 0.8068\n",
            "Epoch 402/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2077 - accuracy: 0.9305 - val_loss: 0.5834 - val_accuracy: 0.7874\n",
            "Epoch 403/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1966 - accuracy: 0.9274 - val_loss: 0.6252 - val_accuracy: 0.8164\n",
            "Epoch 404/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1928 - accuracy: 0.9262 - val_loss: 0.6051 - val_accuracy: 0.7826\n",
            "Epoch 405/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1929 - accuracy: 0.9262 - val_loss: 0.6114 - val_accuracy: 0.7488\n",
            "Epoch 406/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1892 - accuracy: 0.9287 - val_loss: 0.6392 - val_accuracy: 0.8213\n",
            "Epoch 407/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2011 - accuracy: 0.9262 - val_loss: 0.6693 - val_accuracy: 0.7971\n",
            "Epoch 408/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1715 - accuracy: 0.9347 - val_loss: 0.6567 - val_accuracy: 0.8164\n",
            "Epoch 409/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1824 - accuracy: 0.9371 - val_loss: 0.7444 - val_accuracy: 0.7488\n",
            "Epoch 410/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1818 - accuracy: 0.9311 - val_loss: 0.5879 - val_accuracy: 0.8116\n",
            "Epoch 411/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2014 - accuracy: 0.9293 - val_loss: 0.6991 - val_accuracy: 0.7633\n",
            "Epoch 412/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1900 - accuracy: 0.9268 - val_loss: 0.6641 - val_accuracy: 0.8019\n",
            "Epoch 413/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1935 - accuracy: 0.9353 - val_loss: 0.6641 - val_accuracy: 0.7488\n",
            "Epoch 414/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1598 - accuracy: 0.9395 - val_loss: 0.5861 - val_accuracy: 0.8261\n",
            "Epoch 415/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1899 - accuracy: 0.9353 - val_loss: 0.6344 - val_accuracy: 0.8019\n",
            "Epoch 416/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1908 - accuracy: 0.9341 - val_loss: 0.6158 - val_accuracy: 0.8213\n",
            "Epoch 417/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1880 - accuracy: 0.9299 - val_loss: 0.6713 - val_accuracy: 0.7778\n",
            "Epoch 418/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1647 - accuracy: 0.9383 - val_loss: 0.6478 - val_accuracy: 0.7923\n",
            "Epoch 419/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.2091 - accuracy: 0.9377 - val_loss: 0.6083 - val_accuracy: 0.7826\n",
            "Epoch 420/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1948 - accuracy: 0.9371 - val_loss: 0.6613 - val_accuracy: 0.7874\n",
            "Epoch 421/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.2016 - accuracy: 0.9287 - val_loss: 0.5643 - val_accuracy: 0.8357\n",
            "Epoch 422/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1678 - accuracy: 0.9438 - val_loss: 0.7015 - val_accuracy: 0.7778\n",
            "Epoch 423/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1523 - accuracy: 0.9420 - val_loss: 0.5935 - val_accuracy: 0.8068\n",
            "Epoch 424/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1851 - accuracy: 0.9353 - val_loss: 0.7600 - val_accuracy: 0.7923\n",
            "Epoch 425/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1862 - accuracy: 0.9335 - val_loss: 0.6250 - val_accuracy: 0.8019\n",
            "Epoch 426/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1763 - accuracy: 0.9365 - val_loss: 0.7061 - val_accuracy: 0.7633\n",
            "Epoch 427/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1803 - accuracy: 0.9377 - val_loss: 0.6614 - val_accuracy: 0.8019\n",
            "Epoch 428/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1790 - accuracy: 0.9377 - val_loss: 0.5990 - val_accuracy: 0.7923\n",
            "Epoch 429/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1889 - accuracy: 0.9335 - val_loss: 0.6334 - val_accuracy: 0.8116\n",
            "Epoch 430/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1819 - accuracy: 0.9389 - val_loss: 0.6543 - val_accuracy: 0.7778\n",
            "Epoch 431/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1524 - accuracy: 0.9480 - val_loss: 0.6900 - val_accuracy: 0.7971\n",
            "Epoch 432/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1899 - accuracy: 0.9365 - val_loss: 0.6602 - val_accuracy: 0.7971\n",
            "Epoch 433/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1494 - accuracy: 0.9468 - val_loss: 0.6513 - val_accuracy: 0.7778\n",
            "Epoch 434/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1944 - accuracy: 0.9329 - val_loss: 0.6668 - val_accuracy: 0.7923\n",
            "Epoch 435/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1891 - accuracy: 0.9389 - val_loss: 0.6834 - val_accuracy: 0.7681\n",
            "Epoch 436/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1882 - accuracy: 0.9317 - val_loss: 0.7367 - val_accuracy: 0.8068\n",
            "Epoch 437/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1721 - accuracy: 0.9395 - val_loss: 0.6009 - val_accuracy: 0.7923\n",
            "Epoch 438/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1944 - accuracy: 0.9226 - val_loss: 0.7596 - val_accuracy: 0.7729\n",
            "Epoch 439/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1684 - accuracy: 0.9450 - val_loss: 0.7916 - val_accuracy: 0.7681\n",
            "Epoch 440/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1781 - accuracy: 0.9329 - val_loss: 0.7945 - val_accuracy: 0.7585\n",
            "Epoch 441/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1680 - accuracy: 0.9401 - val_loss: 0.6819 - val_accuracy: 0.7874\n",
            "Epoch 442/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1507 - accuracy: 0.9468 - val_loss: 0.7699 - val_accuracy: 0.7681\n",
            "Epoch 443/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1641 - accuracy: 0.9389 - val_loss: 0.6913 - val_accuracy: 0.7923\n",
            "Epoch 444/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1679 - accuracy: 0.9395 - val_loss: 0.7956 - val_accuracy: 0.7729\n",
            "Epoch 445/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1703 - accuracy: 0.9371 - val_loss: 0.6175 - val_accuracy: 0.8213\n",
            "Epoch 446/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1710 - accuracy: 0.9414 - val_loss: 0.7332 - val_accuracy: 0.7633\n",
            "Epoch 447/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1734 - accuracy: 0.9462 - val_loss: 0.6631 - val_accuracy: 0.8164\n",
            "Epoch 448/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1663 - accuracy: 0.9456 - val_loss: 0.6341 - val_accuracy: 0.7971\n",
            "Epoch 449/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1727 - accuracy: 0.9426 - val_loss: 0.6214 - val_accuracy: 0.8019\n",
            "Epoch 450/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1617 - accuracy: 0.9462 - val_loss: 0.6394 - val_accuracy: 0.8019\n",
            "Epoch 451/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1826 - accuracy: 0.9371 - val_loss: 0.7011 - val_accuracy: 0.8357\n",
            "Epoch 452/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1573 - accuracy: 0.9444 - val_loss: 0.7359 - val_accuracy: 0.7874\n",
            "Epoch 453/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1640 - accuracy: 0.9377 - val_loss: 0.6936 - val_accuracy: 0.8019\n",
            "Epoch 454/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1618 - accuracy: 0.9450 - val_loss: 0.7849 - val_accuracy: 0.7923\n",
            "Epoch 455/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1664 - accuracy: 0.9414 - val_loss: 0.6646 - val_accuracy: 0.8261\n",
            "Epoch 456/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1744 - accuracy: 0.9438 - val_loss: 0.7441 - val_accuracy: 0.8068\n",
            "Epoch 457/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1380 - accuracy: 0.9486 - val_loss: 0.6674 - val_accuracy: 0.8068\n",
            "Epoch 458/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1685 - accuracy: 0.9401 - val_loss: 0.7057 - val_accuracy: 0.8019\n",
            "Epoch 459/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1554 - accuracy: 0.9444 - val_loss: 0.5669 - val_accuracy: 0.8309\n",
            "Epoch 460/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1568 - accuracy: 0.9414 - val_loss: 0.7080 - val_accuracy: 0.7729\n",
            "Epoch 461/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1849 - accuracy: 0.9323 - val_loss: 0.6779 - val_accuracy: 0.8213\n",
            "Epoch 462/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1661 - accuracy: 0.9407 - val_loss: 0.6466 - val_accuracy: 0.8019\n",
            "Epoch 463/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1447 - accuracy: 0.9438 - val_loss: 0.7915 - val_accuracy: 0.7826\n",
            "Epoch 464/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1444 - accuracy: 0.9480 - val_loss: 0.6969 - val_accuracy: 0.7874\n",
            "Epoch 465/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1789 - accuracy: 0.9323 - val_loss: 0.6619 - val_accuracy: 0.8164\n",
            "Epoch 466/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1494 - accuracy: 0.9450 - val_loss: 0.7360 - val_accuracy: 0.8164\n",
            "Epoch 467/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1670 - accuracy: 0.9401 - val_loss: 0.6704 - val_accuracy: 0.8116\n",
            "Epoch 468/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1802 - accuracy: 0.9377 - val_loss: 0.6946 - val_accuracy: 0.7826\n",
            "Epoch 469/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1538 - accuracy: 0.9462 - val_loss: 0.6230 - val_accuracy: 0.8019\n",
            "Epoch 470/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1427 - accuracy: 0.9492 - val_loss: 0.7084 - val_accuracy: 0.8019\n",
            "Epoch 471/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1513 - accuracy: 0.9462 - val_loss: 0.6333 - val_accuracy: 0.8116\n",
            "Epoch 472/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1566 - accuracy: 0.9383 - val_loss: 0.7140 - val_accuracy: 0.8164\n",
            "Epoch 473/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1459 - accuracy: 0.9480 - val_loss: 0.6562 - val_accuracy: 0.7971\n",
            "Epoch 474/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1666 - accuracy: 0.9389 - val_loss: 0.6516 - val_accuracy: 0.8116\n",
            "Epoch 475/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1444 - accuracy: 0.9456 - val_loss: 0.7569 - val_accuracy: 0.7971\n",
            "Epoch 476/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1740 - accuracy: 0.9456 - val_loss: 0.7693 - val_accuracy: 0.7633\n",
            "Epoch 477/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1546 - accuracy: 0.9438 - val_loss: 0.6490 - val_accuracy: 0.8164\n",
            "Epoch 478/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1519 - accuracy: 0.9414 - val_loss: 0.7176 - val_accuracy: 0.7923\n",
            "Epoch 479/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1590 - accuracy: 0.9480 - val_loss: 0.8046 - val_accuracy: 0.7633\n",
            "Epoch 480/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1519 - accuracy: 0.9522 - val_loss: 0.7251 - val_accuracy: 0.8213\n",
            "Epoch 481/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1717 - accuracy: 0.9432 - val_loss: 0.7422 - val_accuracy: 0.7971\n",
            "Epoch 482/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1498 - accuracy: 0.9456 - val_loss: 0.7477 - val_accuracy: 0.7778\n",
            "Epoch 483/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1424 - accuracy: 0.9444 - val_loss: 0.7380 - val_accuracy: 0.8213\n",
            "Epoch 484/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1846 - accuracy: 0.9359 - val_loss: 0.7794 - val_accuracy: 0.7729\n",
            "Epoch 485/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1438 - accuracy: 0.9498 - val_loss: 0.7731 - val_accuracy: 0.7826\n",
            "Epoch 486/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1320 - accuracy: 0.9534 - val_loss: 0.6929 - val_accuracy: 0.8116\n",
            "Epoch 487/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1869 - accuracy: 0.9407 - val_loss: 0.6647 - val_accuracy: 0.7923\n",
            "Epoch 488/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1519 - accuracy: 0.9486 - val_loss: 0.6394 - val_accuracy: 0.8309\n",
            "Epoch 489/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1725 - accuracy: 0.9407 - val_loss: 0.6113 - val_accuracy: 0.8068\n",
            "Epoch 490/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1392 - accuracy: 0.9541 - val_loss: 0.7131 - val_accuracy: 0.7874\n",
            "Epoch 491/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1435 - accuracy: 0.9474 - val_loss: 0.6562 - val_accuracy: 0.8164\n",
            "Epoch 492/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1588 - accuracy: 0.9414 - val_loss: 0.6680 - val_accuracy: 0.8068\n",
            "Epoch 493/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1529 - accuracy: 0.9510 - val_loss: 0.6520 - val_accuracy: 0.8164\n",
            "Epoch 494/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1690 - accuracy: 0.9438 - val_loss: 0.6289 - val_accuracy: 0.7778\n",
            "Epoch 495/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1525 - accuracy: 0.9450 - val_loss: 0.6362 - val_accuracy: 0.8164\n",
            "Epoch 496/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1232 - accuracy: 0.9559 - val_loss: 0.7442 - val_accuracy: 0.7681\n",
            "Epoch 497/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1547 - accuracy: 0.9450 - val_loss: 0.7483 - val_accuracy: 0.7826\n",
            "Epoch 498/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1460 - accuracy: 0.9534 - val_loss: 0.8028 - val_accuracy: 0.7729\n",
            "Epoch 499/500\n",
            "104/104 [==============================] - 1s 6ms/step - loss: 0.1743 - accuracy: 0.9486 - val_loss: 0.6623 - val_accuracy: 0.8116\n",
            "Epoch 500/500\n",
            "104/104 [==============================] - 1s 5ms/step - loss: 0.1505 - accuracy: 0.9462 - val_loss: 0.7386 - val_accuracy: 0.7971\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(cnnhistory.history['loss'])\n",
        "plt.plot(cnnhistory.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train','test'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "oQYnuaCrDH_A",
        "outputId": "5da032d9-9283-4773-c988-d7c3e6ae389a"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(cnnhistory.history['accuracy'])\n",
        "plt.plot(cnnhistory.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train','test'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "IFkTuO8nDNdq",
        "outputId": "dba24a63-5281-484f-da1d-2c75e582cd8a"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#predictions = model.predict_classes(x_testcnn)\n",
        "predictions = model.predict(x_testcnn)"
      ],
      "metadata": {
        "id": "A2xtrN5wDQgY"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_f_ohjXKDUpY",
        "outputId": "07217691-a104-42f9-c583-6e9c6a6c5570"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.0481136e-08, 1.6625776e-10, 4.6514539e-04, 1.9980959e-08,\n",
              "        2.1111784e-03, 9.9742365e-01],\n",
              "       [1.4171186e-04, 9.9416405e-01, 9.5748364e-06, 7.6478362e-05,\n",
              "        2.8408184e-07, 5.6078415e-03],\n",
              "       [1.7381143e-07, 4.9489057e-07, 5.8557242e-01, 1.0559105e-08,\n",
              "        4.1072923e-01, 3.6976589e-03],\n",
              "       ...,\n",
              "       [5.7090849e-05, 2.0071882e-06, 7.4286414e-03, 1.5873427e-04,\n",
              "        8.3591753e-01, 1.5643601e-01],\n",
              "       [2.7326422e-03, 2.1225368e-04, 1.8589132e-04, 8.0716068e-01,\n",
              "        2.4937050e-04, 1.8945906e-01],\n",
              "       [2.5110951e-02, 2.4631240e-03, 4.2709053e-06, 3.2113385e-01,\n",
              "        6.5127730e-01, 1.0596248e-05]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cmA2bFgsDW3D",
        "outputId": "7faced05-64e8-40f5-ba51-f215af4e2763"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5, 1, 2, 5, 3, 4, 2, 0, 3, 1, 3, 2, 1, 4, 3, 0, 5, 0, 2, 5, 0, 0,\n",
              "       1, 3, 2, 3, 2, 5, 4, 2, 2, 3, 1, 2, 5, 5, 3, 5, 3, 3, 4, 1, 3, 2,\n",
              "       3, 1, 5, 3, 1, 2, 4, 4, 5, 5, 5, 1, 2, 3, 2, 5, 0, 2, 4, 2, 5, 4,\n",
              "       3, 0, 1, 2, 5, 2, 1, 2, 4, 5, 4, 1, 5, 5, 3, 1, 5, 3, 2, 4, 2, 5,\n",
              "       0, 5, 0, 5, 4, 0, 2, 4, 0, 2, 2, 0, 2, 3, 5, 3, 5, 5, 3, 1, 2, 2,\n",
              "       2, 1, 3, 2, 1, 3, 4, 4, 1, 1, 2, 4, 4, 1, 4, 2, 0, 4, 5, 5, 3, 1,\n",
              "       2, 1, 5, 5, 1, 2, 3, 3, 0, 3, 3, 0, 1, 0, 1, 2, 1, 5, 1, 2, 2, 0,\n",
              "       1, 1, 1, 1, 1, 4, 0, 1, 5, 1, 4, 5, 5, 4, 1, 0, 3, 5, 2, 3, 0, 4,\n",
              "       1, 3, 1, 0, 5, 5, 3, 5, 4, 5, 4, 0, 4, 1, 2, 1, 5, 0, 4, 3, 2, 1,\n",
              "       0, 3, 5, 0, 4, 5, 4, 5, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_Ytest = y_test.astype(int)"
      ],
      "metadata": {
        "id": "0PHDKWJWDY3g"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_Ytest"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k68v2i-pDbZE",
        "outputId": "dd95448f-5205-47db-c681-37745e4750f2"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5, 1, 2, 5, 3, 4, 2, 0, 3, 1, 3, 2, 1, 4, 3, 0, 5, 0, 2, 5, 0, 0,\n",
              "       1, 3, 2, 3, 2, 5, 4, 2, 2, 3, 1, 2, 5, 5, 3, 5, 3, 3, 4, 1, 3, 2,\n",
              "       3, 1, 5, 3, 1, 2, 4, 4, 5, 5, 5, 1, 2, 3, 2, 5, 0, 2, 4, 2, 5, 4,\n",
              "       3, 0, 1, 2, 5, 2, 1, 2, 4, 5, 4, 1, 5, 5, 3, 1, 5, 3, 2, 4, 2, 5,\n",
              "       0, 5, 0, 5, 4, 0, 2, 4, 0, 2, 2, 0, 2, 3, 5, 3, 5, 5, 3, 1, 2, 2,\n",
              "       2, 1, 3, 2, 1, 3, 4, 4, 1, 1, 2, 4, 4, 1, 4, 2, 0, 4, 5, 5, 3, 1,\n",
              "       2, 1, 5, 5, 1, 2, 3, 3, 0, 3, 3, 0, 1, 0, 1, 2, 1, 5, 1, 2, 2, 0,\n",
              "       1, 1, 1, 1, 1, 4, 0, 1, 5, 1, 4, 5, 5, 4, 1, 0, 3, 5, 2, 3, 0, 4,\n",
              "       1, 3, 1, 0, 5, 5, 3, 5, 4, 5, 4, 0, 4, 1, 2, 1, 5, 0, 4, 3, 2, 1,\n",
              "       0, 3, 5, 0, 4, 5, 4, 5, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds1=predictions.argmax(axis=1)\n",
        "preds1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4_cAI39VFhtp",
        "outputId": "05e5a0a8-9441-48e5-b5d3-9092ca2dabb6"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5, 1, 2, 5, 3, 5, 2, 0, 3, 0, 3, 2, 1, 4, 3, 0, 5, 3, 2, 5, 0, 0,\n",
              "       1, 3, 2, 5, 2, 5, 4, 2, 2, 3, 1, 2, 5, 5, 1, 5, 3, 3, 4, 1, 3, 2,\n",
              "       3, 1, 5, 3, 1, 0, 4, 4, 5, 5, 5, 1, 2, 3, 2, 5, 0, 2, 4, 2, 5, 4,\n",
              "       3, 1, 1, 2, 5, 2, 1, 2, 4, 5, 4, 3, 5, 5, 3, 1, 5, 3, 2, 4, 2, 5,\n",
              "       0, 5, 0, 5, 4, 0, 3, 4, 3, 4, 2, 1, 2, 3, 5, 3, 5, 5, 5, 1, 2, 1,\n",
              "       2, 1, 3, 2, 1, 3, 5, 4, 0, 1, 2, 4, 4, 1, 4, 2, 0, 4, 5, 5, 5, 1,\n",
              "       4, 1, 5, 5, 1, 2, 3, 3, 0, 3, 5, 0, 1, 0, 1, 2, 1, 5, 0, 2, 2, 0,\n",
              "       1, 1, 1, 1, 1, 4, 0, 1, 5, 1, 4, 5, 2, 4, 1, 0, 5, 5, 2, 3, 3, 4,\n",
              "       1, 3, 1, 5, 5, 2, 3, 5, 4, 5, 0, 0, 4, 0, 2, 1, 5, 0, 4, 1, 2, 0,\n",
              "       1, 5, 5, 0, 4, 5, 4, 3, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "abc = preds1.astype(int).flatten()"
      ],
      "metadata": {
        "id": "H4WEmM60NfQn"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "c = confusion_matrix(new_Ytest, abc) \n",
        "c"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bKEBeEBlFjB8",
        "outputId": "9c34eb47-d9e0-42b0-aea8-ec085fa1e35f"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[18,  3,  0,  3,  0,  1],\n",
              "       [ 5, 33,  0,  1,  0,  0],\n",
              "       [ 1,  1, 33,  1,  2,  0],\n",
              "       [ 0,  2,  0, 25,  0,  6],\n",
              "       [ 1,  0,  0,  0, 27,  2],\n",
              "       [ 0,  0,  2,  1,  0, 39]])"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m4RjG7LWLSQx",
        "outputId": "c97c9476-f6a3-4734-b717-68df65c221d4"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5, 1, 2, 5, 3, 4, 2, 0, 3, 1, 3, 2, 1, 4, 3, 0, 5, 0, 2, 5, 0, 0,\n",
              "       1, 3, 2, 3, 2, 5, 4, 2, 2, 3, 1, 2, 5, 5, 3, 5, 3, 3, 4, 1, 3, 2,\n",
              "       3, 1, 5, 3, 1, 2, 4, 4, 5, 5, 5, 1, 2, 3, 2, 5, 0, 2, 4, 2, 5, 4,\n",
              "       3, 0, 1, 2, 5, 2, 1, 2, 4, 5, 4, 1, 5, 5, 3, 1, 5, 3, 2, 4, 2, 5,\n",
              "       0, 5, 0, 5, 4, 0, 2, 4, 0, 2, 2, 0, 2, 3, 5, 3, 5, 5, 3, 1, 2, 2,\n",
              "       2, 1, 3, 2, 1, 3, 4, 4, 1, 1, 2, 4, 4, 1, 4, 2, 0, 4, 5, 5, 3, 1,\n",
              "       2, 1, 5, 5, 1, 2, 3, 3, 0, 3, 3, 0, 1, 0, 1, 2, 1, 5, 1, 2, 2, 0,\n",
              "       1, 1, 1, 1, 1, 4, 0, 1, 5, 1, 4, 5, 5, 4, 1, 0, 3, 5, 2, 3, 0, 4,\n",
              "       1, 3, 1, 0, 5, 5, 3, 5, 4, 5, 4, 0, 4, 1, 2, 1, 5, 0, 4, 3, 2, 1,\n",
              "       0, 3, 5, 0, 4, 5, 4, 5, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('/content/drive/My Drive/graduation project/audio/paper_code/mariam/original_500 epoch_with_valid_Adam2_3')\n",
        "print(\"MODEL SAVED\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lsJBNeMWDl6Z",
        "outputId": "cf2a6e8f-1735-404e-ca49-180235fb1251"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/graduation project/audio/paper_code/mariam/original_500 epoch_with_valid_Adam2_3/assets\n",
            "MODEL SAVED\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_model=keras.models.load_model('/content/drive/My Drive/graduation project/audio/paper_code/mariam/original_500 epoch_with_valid_Adam2_3')\n",
        "new_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q3KjaO9GDoNl",
        "outputId": "9a89cf32-9792-4d64-a467-8a83e0159c3d"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d (Conv1D)             (None, 40, 128)           1152      \n",
            "                                                                 \n",
            " activation (Activation)     (None, 40, 128)           0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 40, 128)           0         \n",
            "                                                                 \n",
            " max_pooling1d (MaxPooling1D  (None, 8, 128)           0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv1d_1 (Conv1D)           (None, 8, 256)            262400    \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 8, 256)            0         \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 8, 256)            0         \n",
            "                                                                 \n",
            " max_pooling1d_1 (MaxPooling  (None, 1, 256)           0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 256)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 256)               65792     \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 256)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 256)               65792     \n",
            "                                                                 \n",
            " activation_3 (Activation)   (None, 256)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 6)                 1542      \n",
            "                                                                 \n",
            " activation_4 (Activation)   (None, 6)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 396,678\n",
            "Trainable params: 396,678\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss, acc =model.evaluate(x_testcnn, y_test)\n",
        "print(\"Restored model, accuracy: {:5.2f}%\".format(100*acc))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n3kzoqPkDqqS",
        "outputId": "7f1d862e-21d9-4590-d6f1-3a3e68289612"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7/7 [==============================] - 0s 7ms/step - loss: 0.7246 - accuracy: 0.8454\n",
            "Restored model, accuracy: 84.54%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss, acc =model.evaluate(X_train, y_train)\n",
        "print(\"Restored model train, accuracy: {:5.2f}%\".format(100*acc))"
      ],
      "metadata": {
        "id": "fJDTGH_OUX0z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a8e9096-97fb-4e0d-f97a-9ab371137e78"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "52/52 [==============================] - 1s 6ms/step - loss: 0.0522 - accuracy: 0.9867\n",
            "Restored model train, accuracy: 98.67%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix,accuracy_score\n",
        "import seaborn as sn\n",
        "\n",
        "print(classification_report(new_Ytest,abc))\n",
        "\n",
        "acc = float(accuracy_score(new_Ytest,abc))*100\n",
        "print(\"----accuracy score %s ----\" % acc)\n",
        "\n",
        "cm = confusion_matrix(new_Ytest,abc)\n",
        "#df_cm = pd.DataFrame(cm)\n",
        "class_names = ['neutral','calm', 'happy','sad','angry', 'fearful' ]\n",
        "df_cm = pd.DataFrame(cm, index=class_names, columns=class_names,)\n",
        "sn.heatmap(df_cm, annot=True, fmt='')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 508
        },
        "id": "SfSC3El94LZg",
        "outputId": "63474227-82ae-4cbe-eb14-0f68845bef61"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.72      0.72      0.72        25\n",
            "           1       0.85      0.85      0.85        39\n",
            "           2       0.94      0.87      0.90        38\n",
            "           3       0.81      0.76      0.78        33\n",
            "           4       0.93      0.90      0.92        30\n",
            "           5       0.81      0.93      0.87        42\n",
            "\n",
            "    accuracy                           0.85       207\n",
            "   macro avg       0.84      0.84      0.84       207\n",
            "weighted avg       0.85      0.85      0.85       207\n",
            "\n",
            "----accuracy score 84.54106280193237 ----\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "LGpgwFQqkpyU"
      },
      "execution_count": 37,
      "outputs": []
    }
  ]
}